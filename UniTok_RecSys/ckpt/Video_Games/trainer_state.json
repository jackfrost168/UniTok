{
  "best_metric": 0.6380993723869324,
  "best_model_checkpoint": "./ckpt/Video_Games/checkpoint-20215",
  "epoch": 85.0,
  "eval_steps": 1000,
  "global_step": 26435,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0322061191626409,
      "grad_norm": 20.46925926208496,
      "learning_rate": 8.064516129032258e-06,
      "loss": 21.6299,
      "step": 10
    },
    {
      "epoch": 0.0644122383252818,
      "grad_norm": 16.215070724487305,
      "learning_rate": 1.6129032258064517e-05,
      "loss": 20.0087,
      "step": 20
    },
    {
      "epoch": 0.0966183574879227,
      "grad_norm": 8.792262077331543,
      "learning_rate": 2.4193548387096773e-05,
      "loss": 17.4775,
      "step": 30
    },
    {
      "epoch": 0.1288244766505636,
      "grad_norm": 5.649039268493652,
      "learning_rate": 3.2258064516129034e-05,
      "loss": 15.3282,
      "step": 40
    },
    {
      "epoch": 0.1610305958132045,
      "grad_norm": 5.026443004608154,
      "learning_rate": 4.032258064516129e-05,
      "loss": 13.5195,
      "step": 50
    },
    {
      "epoch": 0.1932367149758454,
      "grad_norm": 4.512653827667236,
      "learning_rate": 4.838709677419355e-05,
      "loss": 11.4901,
      "step": 60
    },
    {
      "epoch": 0.22544283413848631,
      "grad_norm": 3.5311381816864014,
      "learning_rate": 5.6451612903225804e-05,
      "loss": 9.34,
      "step": 70
    },
    {
      "epoch": 0.2576489533011272,
      "grad_norm": 2.5265464782714844,
      "learning_rate": 6.451612903225807e-05,
      "loss": 7.5325,
      "step": 80
    },
    {
      "epoch": 0.2898550724637681,
      "grad_norm": 1.71126127243042,
      "learning_rate": 7.258064516129033e-05,
      "loss": 6.1765,
      "step": 90
    },
    {
      "epoch": 0.322061191626409,
      "grad_norm": 1.3821049928665161,
      "learning_rate": 8.064516129032258e-05,
      "loss": 5.4199,
      "step": 100
    },
    {
      "epoch": 0.35426731078904994,
      "grad_norm": 1.2139554023742676,
      "learning_rate": 8.870967741935484e-05,
      "loss": 5.1473,
      "step": 110
    },
    {
      "epoch": 0.3864734299516908,
      "grad_norm": 1.1675657033920288,
      "learning_rate": 9.67741935483871e-05,
      "loss": 4.8023,
      "step": 120
    },
    {
      "epoch": 0.41867954911433175,
      "grad_norm": 1.1664193868637085,
      "learning_rate": 0.00010483870967741936,
      "loss": 4.6361,
      "step": 130
    },
    {
      "epoch": 0.45088566827697263,
      "grad_norm": 1.1189208030700684,
      "learning_rate": 0.00011290322580645161,
      "loss": 4.5548,
      "step": 140
    },
    {
      "epoch": 0.4830917874396135,
      "grad_norm": 1.0837583541870117,
      "learning_rate": 0.00012096774193548387,
      "loss": 4.4288,
      "step": 150
    },
    {
      "epoch": 0.5152979066022544,
      "grad_norm": 1.177130937576294,
      "learning_rate": 0.00012903225806451613,
      "loss": 4.2668,
      "step": 160
    },
    {
      "epoch": 0.5475040257648953,
      "grad_norm": 1.1161229610443115,
      "learning_rate": 0.00013709677419354837,
      "loss": 4.2153,
      "step": 170
    },
    {
      "epoch": 0.5797101449275363,
      "grad_norm": 1.0320403575897217,
      "learning_rate": 0.00014516129032258066,
      "loss": 4.1657,
      "step": 180
    },
    {
      "epoch": 0.6119162640901772,
      "grad_norm": 1.0425324440002441,
      "learning_rate": 0.0001532258064516129,
      "loss": 4.0648,
      "step": 190
    },
    {
      "epoch": 0.644122383252818,
      "grad_norm": 0.9077115058898926,
      "learning_rate": 0.00016129032258064516,
      "loss": 4.0153,
      "step": 200
    },
    {
      "epoch": 0.6763285024154589,
      "grad_norm": 0.8617898225784302,
      "learning_rate": 0.00016935483870967742,
      "loss": 3.9579,
      "step": 210
    },
    {
      "epoch": 0.7085346215780999,
      "grad_norm": 0.887841522693634,
      "learning_rate": 0.0001774193548387097,
      "loss": 3.8831,
      "step": 220
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 0.9258098602294922,
      "learning_rate": 0.00018548387096774195,
      "loss": 3.8083,
      "step": 230
    },
    {
      "epoch": 0.7729468599033816,
      "grad_norm": 0.8674773573875427,
      "learning_rate": 0.0001935483870967742,
      "loss": 3.7755,
      "step": 240
    },
    {
      "epoch": 0.8051529790660226,
      "grad_norm": 0.9678040146827698,
      "learning_rate": 0.00020161290322580645,
      "loss": 3.748,
      "step": 250
    },
    {
      "epoch": 0.8373590982286635,
      "grad_norm": 0.791597306728363,
      "learning_rate": 0.00020967741935483871,
      "loss": 3.6702,
      "step": 260
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 0.8325536251068115,
      "learning_rate": 0.00021774193548387098,
      "loss": 3.5837,
      "step": 270
    },
    {
      "epoch": 0.9017713365539453,
      "grad_norm": 0.7451446056365967,
      "learning_rate": 0.00022580645161290321,
      "loss": 3.5926,
      "step": 280
    },
    {
      "epoch": 0.9339774557165862,
      "grad_norm": 0.7272723317146301,
      "learning_rate": 0.00023387096774193548,
      "loss": 3.4818,
      "step": 290
    },
    {
      "epoch": 0.966183574879227,
      "grad_norm": 0.7515087127685547,
      "learning_rate": 0.00024193548387096774,
      "loss": 3.4669,
      "step": 300
    },
    {
      "epoch": 0.998389694041868,
      "grad_norm": 0.6951474547386169,
      "learning_rate": 0.00025,
      "loss": 3.4368,
      "step": 310
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.5261269807815552,
      "eval_runtime": 7.1231,
      "eval_samples_per_second": 3411.845,
      "eval_steps_per_second": 13.337,
      "step": 311
    },
    {
      "epoch": 1.0289855072463767,
      "grad_norm": 0.6621975898742676,
      "learning_rate": 0.00025806451612903227,
      "loss": 3.1796,
      "step": 320
    },
    {
      "epoch": 1.0611916264090178,
      "grad_norm": 0.6474233269691467,
      "learning_rate": 0.00026612903225806453,
      "loss": 3.3185,
      "step": 330
    },
    {
      "epoch": 1.0933977455716586,
      "grad_norm": 0.6917455792427063,
      "learning_rate": 0.00027419354838709674,
      "loss": 3.3349,
      "step": 340
    },
    {
      "epoch": 1.1256038647342996,
      "grad_norm": 0.7212635278701782,
      "learning_rate": 0.00028225806451612906,
      "loss": 3.2724,
      "step": 350
    },
    {
      "epoch": 1.1578099838969405,
      "grad_norm": 0.6603254675865173,
      "learning_rate": 0.0002903225806451613,
      "loss": 3.1878,
      "step": 360
    },
    {
      "epoch": 1.1900161030595813,
      "grad_norm": 0.7492390275001526,
      "learning_rate": 0.0002983870967741936,
      "loss": 3.0909,
      "step": 370
    },
    {
      "epoch": 1.2222222222222223,
      "grad_norm": 0.5794734954833984,
      "learning_rate": 0.0003064516129032258,
      "loss": 3.0824,
      "step": 380
    },
    {
      "epoch": 1.2544283413848631,
      "grad_norm": 0.7959806323051453,
      "learning_rate": 0.00031451612903225806,
      "loss": 3.0394,
      "step": 390
    },
    {
      "epoch": 1.286634460547504,
      "grad_norm": 0.6503927707672119,
      "learning_rate": 0.0003225806451612903,
      "loss": 3.041,
      "step": 400
    },
    {
      "epoch": 1.318840579710145,
      "grad_norm": 0.5516787767410278,
      "learning_rate": 0.0003306451612903226,
      "loss": 2.9234,
      "step": 410
    },
    {
      "epoch": 1.3510466988727858,
      "grad_norm": 0.5342364311218262,
      "learning_rate": 0.00033870967741935485,
      "loss": 2.9082,
      "step": 420
    },
    {
      "epoch": 1.3832528180354267,
      "grad_norm": 0.5869259834289551,
      "learning_rate": 0.0003467741935483871,
      "loss": 2.892,
      "step": 430
    },
    {
      "epoch": 1.4154589371980677,
      "grad_norm": 0.5185460448265076,
      "learning_rate": 0.0003548387096774194,
      "loss": 2.8508,
      "step": 440
    },
    {
      "epoch": 1.4476650563607085,
      "grad_norm": 0.45872601866722107,
      "learning_rate": 0.00036290322580645164,
      "loss": 2.8051,
      "step": 450
    },
    {
      "epoch": 1.4798711755233493,
      "grad_norm": 0.6157260537147522,
      "learning_rate": 0.0003709677419354839,
      "loss": 2.7324,
      "step": 460
    },
    {
      "epoch": 1.5120772946859904,
      "grad_norm": 0.4894915223121643,
      "learning_rate": 0.0003790322580645161,
      "loss": 2.7705,
      "step": 470
    },
    {
      "epoch": 1.5442834138486312,
      "grad_norm": 0.6072127819061279,
      "learning_rate": 0.0003870967741935484,
      "loss": 2.6884,
      "step": 480
    },
    {
      "epoch": 1.576489533011272,
      "grad_norm": 0.4401993155479431,
      "learning_rate": 0.00039516129032258064,
      "loss": 2.6281,
      "step": 490
    },
    {
      "epoch": 1.608695652173913,
      "grad_norm": 0.4115806519985199,
      "learning_rate": 0.0004032258064516129,
      "loss": 2.6181,
      "step": 500
    },
    {
      "epoch": 1.640901771336554,
      "grad_norm": 0.4167308807373047,
      "learning_rate": 0.00041129032258064517,
      "loss": 2.6224,
      "step": 510
    },
    {
      "epoch": 1.6731078904991947,
      "grad_norm": 0.3821618854999542,
      "learning_rate": 0.00041935483870967743,
      "loss": 2.5217,
      "step": 520
    },
    {
      "epoch": 1.7053140096618358,
      "grad_norm": 0.4830729067325592,
      "learning_rate": 0.0004274193548387097,
      "loss": 2.4999,
      "step": 530
    },
    {
      "epoch": 1.7375201288244766,
      "grad_norm": 0.4113922417163849,
      "learning_rate": 0.00043548387096774196,
      "loss": 2.5153,
      "step": 540
    },
    {
      "epoch": 1.7697262479871174,
      "grad_norm": 0.3349143862724304,
      "learning_rate": 0.0004435483870967742,
      "loss": 2.472,
      "step": 550
    },
    {
      "epoch": 1.8019323671497585,
      "grad_norm": 0.5340683460235596,
      "learning_rate": 0.00045161290322580643,
      "loss": 2.4297,
      "step": 560
    },
    {
      "epoch": 1.8341384863123995,
      "grad_norm": 0.39696478843688965,
      "learning_rate": 0.0004596774193548387,
      "loss": 2.3979,
      "step": 570
    },
    {
      "epoch": 1.86634460547504,
      "grad_norm": 0.35559436678886414,
      "learning_rate": 0.00046774193548387096,
      "loss": 2.3986,
      "step": 580
    },
    {
      "epoch": 1.8985507246376812,
      "grad_norm": 0.3049986660480499,
      "learning_rate": 0.0004758064516129033,
      "loss": 2.3468,
      "step": 590
    },
    {
      "epoch": 1.9307568438003222,
      "grad_norm": 0.33107897639274597,
      "learning_rate": 0.0004838709677419355,
      "loss": 2.3095,
      "step": 600
    },
    {
      "epoch": 1.9629629629629628,
      "grad_norm": 0.5658414959907532,
      "learning_rate": 0.0004919354838709678,
      "loss": 2.2149,
      "step": 610
    },
    {
      "epoch": 1.9951690821256038,
      "grad_norm": 0.7594906091690063,
      "learning_rate": 0.0005,
      "loss": 2.2103,
      "step": 620
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.9987130165100098,
      "eval_runtime": 7.0657,
      "eval_samples_per_second": 3439.595,
      "eval_steps_per_second": 13.445,
      "step": 622
    },
    {
      "epoch": 2.025764895330113,
      "grad_norm": 0.2930505871772766,
      "learning_rate": 0.0004999999672541717,
      "loss": 2.0583,
      "step": 630
    },
    {
      "epoch": 2.0579710144927534,
      "grad_norm": 0.4598006010055542,
      "learning_rate": 0.0004999998690166953,
      "loss": 2.1755,
      "step": 640
    },
    {
      "epoch": 2.0901771336553945,
      "grad_norm": 0.3232862651348114,
      "learning_rate": 0.0004999997052875965,
      "loss": 2.1634,
      "step": 650
    },
    {
      "epoch": 2.1223832528180355,
      "grad_norm": 0.2674863934516907,
      "learning_rate": 0.0004999994760669183,
      "loss": 2.0982,
      "step": 660
    },
    {
      "epoch": 2.154589371980676,
      "grad_norm": 0.6857646107673645,
      "learning_rate": 0.0004999991813547206,
      "loss": 2.0956,
      "step": 670
    },
    {
      "epoch": 2.186795491143317,
      "grad_norm": 0.3313392698764801,
      "learning_rate": 0.0004999988211510808,
      "loss": 2.0689,
      "step": 680
    },
    {
      "epoch": 2.219001610305958,
      "grad_norm": 0.2917899191379547,
      "learning_rate": 0.0004999983954560932,
      "loss": 2.0494,
      "step": 690
    },
    {
      "epoch": 2.2512077294685993,
      "grad_norm": 0.27706944942474365,
      "learning_rate": 0.0004999979042698691,
      "loss": 2.0601,
      "step": 700
    },
    {
      "epoch": 2.28341384863124,
      "grad_norm": 0.25821080803871155,
      "learning_rate": 0.0004999973475925375,
      "loss": 2.025,
      "step": 710
    },
    {
      "epoch": 2.315619967793881,
      "grad_norm": 0.297362744808197,
      "learning_rate": 0.000499996725424244,
      "loss": 2.0344,
      "step": 720
    },
    {
      "epoch": 2.3478260869565215,
      "grad_norm": 0.41979026794433594,
      "learning_rate": 0.0004999960377651516,
      "loss": 1.9781,
      "step": 730
    },
    {
      "epoch": 2.3800322061191626,
      "grad_norm": 0.4227515459060669,
      "learning_rate": 0.0004999952846154406,
      "loss": 2.0254,
      "step": 740
    },
    {
      "epoch": 2.4122383252818036,
      "grad_norm": 0.27061769366264343,
      "learning_rate": 0.0004999944659753083,
      "loss": 1.9209,
      "step": 750
    },
    {
      "epoch": 2.4444444444444446,
      "grad_norm": 0.336558997631073,
      "learning_rate": 0.0004999935818449689,
      "loss": 1.8896,
      "step": 760
    },
    {
      "epoch": 2.4766505636070852,
      "grad_norm": 0.20749366283416748,
      "learning_rate": 0.0004999926322246543,
      "loss": 1.915,
      "step": 770
    },
    {
      "epoch": 2.5088566827697263,
      "grad_norm": 0.2545638084411621,
      "learning_rate": 0.0004999916171146131,
      "loss": 1.8899,
      "step": 780
    },
    {
      "epoch": 2.541062801932367,
      "grad_norm": 0.3104824721813202,
      "learning_rate": 0.0004999905365151113,
      "loss": 1.8783,
      "step": 790
    },
    {
      "epoch": 2.573268921095008,
      "grad_norm": 0.20609019696712494,
      "learning_rate": 0.0004999893904264319,
      "loss": 1.8889,
      "step": 800
    },
    {
      "epoch": 2.605475040257649,
      "grad_norm": 0.3196030855178833,
      "learning_rate": 0.0004999881788488752,
      "loss": 1.8683,
      "step": 810
    },
    {
      "epoch": 2.63768115942029,
      "grad_norm": 0.21895113587379456,
      "learning_rate": 0.0004999869017827586,
      "loss": 1.8192,
      "step": 820
    },
    {
      "epoch": 2.6698872785829306,
      "grad_norm": 0.21549458801746368,
      "learning_rate": 0.0004999855592284166,
      "loss": 1.8308,
      "step": 830
    },
    {
      "epoch": 2.7020933977455717,
      "grad_norm": 0.204609677195549,
      "learning_rate": 0.000499984151186201,
      "loss": 1.8235,
      "step": 840
    },
    {
      "epoch": 2.7342995169082127,
      "grad_norm": 0.275851309299469,
      "learning_rate": 0.0004999826776564806,
      "loss": 1.7953,
      "step": 850
    },
    {
      "epoch": 2.7665056360708533,
      "grad_norm": 0.21599729359149933,
      "learning_rate": 0.0004999811386396414,
      "loss": 1.7724,
      "step": 860
    },
    {
      "epoch": 2.7987117552334944,
      "grad_norm": 0.23229283094406128,
      "learning_rate": 0.0004999795341360865,
      "loss": 1.7939,
      "step": 870
    },
    {
      "epoch": 2.8309178743961354,
      "grad_norm": 0.23051784932613373,
      "learning_rate": 0.0004999778641462364,
      "loss": 1.781,
      "step": 880
    },
    {
      "epoch": 2.863123993558776,
      "grad_norm": 0.22471289336681366,
      "learning_rate": 0.0004999761286705285,
      "loss": 1.7843,
      "step": 890
    },
    {
      "epoch": 2.895330112721417,
      "grad_norm": 0.2210882306098938,
      "learning_rate": 0.0004999743277094175,
      "loss": 1.7572,
      "step": 900
    },
    {
      "epoch": 2.927536231884058,
      "grad_norm": 0.2641714811325073,
      "learning_rate": 0.0004999724612633749,
      "loss": 1.7465,
      "step": 910
    },
    {
      "epoch": 2.9597423510466987,
      "grad_norm": 0.2576981782913208,
      "learning_rate": 0.00049997052933289,
      "loss": 1.7348,
      "step": 920
    },
    {
      "epoch": 2.9919484702093397,
      "grad_norm": 0.17190608382225037,
      "learning_rate": 0.0004999685319184688,
      "loss": 1.7482,
      "step": 930
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.780514657497406,
      "eval_runtime": 7.0357,
      "eval_samples_per_second": 3454.263,
      "eval_steps_per_second": 13.503,
      "step": 933
    },
    {
      "epoch": 3.0225442834138487,
      "grad_norm": 0.2596467137336731,
      "learning_rate": 0.0004999664690206345,
      "loss": 1.6069,
      "step": 940
    },
    {
      "epoch": 3.0547504025764893,
      "grad_norm": 0.1580626666545868,
      "learning_rate": 0.0004999643406399275,
      "loss": 1.7237,
      "step": 950
    },
    {
      "epoch": 3.0869565217391304,
      "grad_norm": 0.18024414777755737,
      "learning_rate": 0.0004999621467769054,
      "loss": 1.7129,
      "step": 960
    },
    {
      "epoch": 3.1191626409017714,
      "grad_norm": 0.16354115307331085,
      "learning_rate": 0.000499959887432143,
      "loss": 1.704,
      "step": 970
    },
    {
      "epoch": 3.151368760064412,
      "grad_norm": 0.19418372213840485,
      "learning_rate": 0.0004999575626062319,
      "loss": 1.684,
      "step": 980
    },
    {
      "epoch": 3.183574879227053,
      "grad_norm": 0.18300557136535645,
      "learning_rate": 0.0004999551722997815,
      "loss": 1.6942,
      "step": 990
    },
    {
      "epoch": 3.215780998389694,
      "grad_norm": 0.15298089385032654,
      "learning_rate": 0.0004999527165134177,
      "loss": 1.6743,
      "step": 1000
    },
    {
      "epoch": 3.247987117552335,
      "grad_norm": 0.16674597561359406,
      "learning_rate": 0.000499950195247784,
      "loss": 1.6574,
      "step": 1010
    },
    {
      "epoch": 3.2801932367149758,
      "grad_norm": 0.1728413701057434,
      "learning_rate": 0.0004999476085035408,
      "loss": 1.6911,
      "step": 1020
    },
    {
      "epoch": 3.312399355877617,
      "grad_norm": 0.16801249980926514,
      "learning_rate": 0.0004999449562813657,
      "loss": 1.6825,
      "step": 1030
    },
    {
      "epoch": 3.3446054750402574,
      "grad_norm": 0.21491484344005585,
      "learning_rate": 0.0004999422385819536,
      "loss": 1.6337,
      "step": 1040
    },
    {
      "epoch": 3.3768115942028984,
      "grad_norm": 0.2685205638408661,
      "learning_rate": 0.0004999394554060165,
      "loss": 1.6548,
      "step": 1050
    },
    {
      "epoch": 3.4090177133655395,
      "grad_norm": 0.3964909613132477,
      "learning_rate": 0.0004999366067542833,
      "loss": 1.654,
      "step": 1060
    },
    {
      "epoch": 3.4412238325281805,
      "grad_norm": 0.30711501836776733,
      "learning_rate": 0.0004999336926275003,
      "loss": 1.6104,
      "step": 1070
    },
    {
      "epoch": 3.473429951690821,
      "grad_norm": 0.1568617820739746,
      "learning_rate": 0.000499930713026431,
      "loss": 1.6322,
      "step": 1080
    },
    {
      "epoch": 3.505636070853462,
      "grad_norm": 0.17973096668720245,
      "learning_rate": 0.000499927667951856,
      "loss": 1.6356,
      "step": 1090
    },
    {
      "epoch": 3.537842190016103,
      "grad_norm": 0.24090340733528137,
      "learning_rate": 0.0004999245574045728,
      "loss": 1.6301,
      "step": 1100
    },
    {
      "epoch": 3.570048309178744,
      "grad_norm": 0.15851722657680511,
      "learning_rate": 0.0004999213813853964,
      "loss": 1.5973,
      "step": 1110
    },
    {
      "epoch": 3.602254428341385,
      "grad_norm": 0.1879158616065979,
      "learning_rate": 0.0004999181398951588,
      "loss": 1.6214,
      "step": 1120
    },
    {
      "epoch": 3.634460547504026,
      "grad_norm": 0.2773658037185669,
      "learning_rate": 0.0004999148329347092,
      "loss": 1.6264,
      "step": 1130
    },
    {
      "epoch": 3.6666666666666665,
      "grad_norm": 0.21063664555549622,
      "learning_rate": 0.0004999114605049138,
      "loss": 1.603,
      "step": 1140
    },
    {
      "epoch": 3.6988727858293076,
      "grad_norm": 0.17988380789756775,
      "learning_rate": 0.0004999080226066562,
      "loss": 1.623,
      "step": 1150
    },
    {
      "epoch": 3.7310789049919486,
      "grad_norm": 0.2366563081741333,
      "learning_rate": 0.000499904519240837,
      "loss": 1.6016,
      "step": 1160
    },
    {
      "epoch": 3.763285024154589,
      "grad_norm": 0.2083662450313568,
      "learning_rate": 0.0004999009504083738,
      "loss": 1.5892,
      "step": 1170
    },
    {
      "epoch": 3.7954911433172303,
      "grad_norm": 0.15232379734516144,
      "learning_rate": 0.0004998973161102016,
      "loss": 1.5821,
      "step": 1180
    },
    {
      "epoch": 3.8276972624798713,
      "grad_norm": 0.17957237362861633,
      "learning_rate": 0.0004998936163472725,
      "loss": 1.6021,
      "step": 1190
    },
    {
      "epoch": 3.8599033816425123,
      "grad_norm": 0.186812162399292,
      "learning_rate": 0.0004998898511205558,
      "loss": 1.5899,
      "step": 1200
    },
    {
      "epoch": 3.892109500805153,
      "grad_norm": 0.21169763803482056,
      "learning_rate": 0.0004998860204310377,
      "loss": 1.567,
      "step": 1210
    },
    {
      "epoch": 3.924315619967794,
      "grad_norm": 0.19414977729320526,
      "learning_rate": 0.0004998821242797218,
      "loss": 1.6143,
      "step": 1220
    },
    {
      "epoch": 3.9565217391304346,
      "grad_norm": 0.19498679041862488,
      "learning_rate": 0.0004998781626676288,
      "loss": 1.5728,
      "step": 1230
    },
    {
      "epoch": 3.9887278582930756,
      "grad_norm": 0.16137081384658813,
      "learning_rate": 0.0004998741355957963,
      "loss": 1.579,
      "step": 1240
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.7185148596763611,
      "eval_runtime": 7.0634,
      "eval_samples_per_second": 3440.704,
      "eval_steps_per_second": 13.45,
      "step": 1244
    },
    {
      "epoch": 4.019323671497585,
      "grad_norm": 0.16265349090099335,
      "learning_rate": 0.0004998700430652794,
      "loss": 1.5112,
      "step": 1250
    },
    {
      "epoch": 4.051529790660226,
      "grad_norm": 0.1906200498342514,
      "learning_rate": 0.0004998658850771504,
      "loss": 1.576,
      "step": 1260
    },
    {
      "epoch": 4.083735909822867,
      "grad_norm": 0.18869012594223022,
      "learning_rate": 0.0004998616616324982,
      "loss": 1.5807,
      "step": 1270
    },
    {
      "epoch": 4.115942028985507,
      "grad_norm": 0.16209949553012848,
      "learning_rate": 0.0004998573727324295,
      "loss": 1.5891,
      "step": 1280
    },
    {
      "epoch": 4.148148148148148,
      "grad_norm": 0.1635400503873825,
      "learning_rate": 0.0004998530183780677,
      "loss": 1.5683,
      "step": 1290
    },
    {
      "epoch": 4.180354267310789,
      "grad_norm": 0.231106698513031,
      "learning_rate": 0.0004998485985705535,
      "loss": 1.5457,
      "step": 1300
    },
    {
      "epoch": 4.21256038647343,
      "grad_norm": 0.18477867543697357,
      "learning_rate": 0.0004998441133110447,
      "loss": 1.5699,
      "step": 1310
    },
    {
      "epoch": 4.244766505636071,
      "grad_norm": 0.18186110258102417,
      "learning_rate": 0.0004998395626007164,
      "loss": 1.5809,
      "step": 1320
    },
    {
      "epoch": 4.276972624798712,
      "grad_norm": 0.20305204391479492,
      "learning_rate": 0.0004998349464407606,
      "loss": 1.5648,
      "step": 1330
    },
    {
      "epoch": 4.309178743961352,
      "grad_norm": 0.17357654869556427,
      "learning_rate": 0.0004998302648323869,
      "loss": 1.552,
      "step": 1340
    },
    {
      "epoch": 4.341384863123993,
      "grad_norm": 0.1821649670600891,
      "learning_rate": 0.0004998255177768213,
      "loss": 1.5428,
      "step": 1350
    },
    {
      "epoch": 4.373590982286634,
      "grad_norm": 0.13007372617721558,
      "learning_rate": 0.0004998207052753076,
      "loss": 1.5616,
      "step": 1360
    },
    {
      "epoch": 4.405797101449275,
      "grad_norm": 0.166285440325737,
      "learning_rate": 0.0004998158273291064,
      "loss": 1.5413,
      "step": 1370
    },
    {
      "epoch": 4.438003220611916,
      "grad_norm": 0.2034415900707245,
      "learning_rate": 0.0004998108839394957,
      "loss": 1.5532,
      "step": 1380
    },
    {
      "epoch": 4.4702093397745575,
      "grad_norm": 0.16389763355255127,
      "learning_rate": 0.0004998058751077704,
      "loss": 1.5339,
      "step": 1390
    },
    {
      "epoch": 4.5024154589371985,
      "grad_norm": 0.16086870431900024,
      "learning_rate": 0.0004998008008352427,
      "loss": 1.5364,
      "step": 1400
    },
    {
      "epoch": 4.534621578099839,
      "grad_norm": 0.2646189033985138,
      "learning_rate": 0.0004997956611232418,
      "loss": 1.5365,
      "step": 1410
    },
    {
      "epoch": 4.56682769726248,
      "grad_norm": 0.1566678136587143,
      "learning_rate": 0.0004997904559731144,
      "loss": 1.5353,
      "step": 1420
    },
    {
      "epoch": 4.599033816425121,
      "grad_norm": 0.15407036244869232,
      "learning_rate": 0.0004997851853862236,
      "loss": 1.5329,
      "step": 1430
    },
    {
      "epoch": 4.631239935587762,
      "grad_norm": 0.16300219297409058,
      "learning_rate": 0.0004997798493639506,
      "loss": 1.5437,
      "step": 1440
    },
    {
      "epoch": 4.663446054750403,
      "grad_norm": 0.14151935279369354,
      "learning_rate": 0.000499774447907693,
      "loss": 1.5369,
      "step": 1450
    },
    {
      "epoch": 4.695652173913043,
      "grad_norm": 0.16858045756816864,
      "learning_rate": 0.0004997689810188659,
      "loss": 1.5549,
      "step": 1460
    },
    {
      "epoch": 4.727858293075684,
      "grad_norm": 0.22032113373279572,
      "learning_rate": 0.0004997634486989013,
      "loss": 1.5449,
      "step": 1470
    },
    {
      "epoch": 4.760064412238325,
      "grad_norm": 0.4345506727695465,
      "learning_rate": 0.0004997578509492487,
      "loss": 1.573,
      "step": 1480
    },
    {
      "epoch": 4.792270531400966,
      "grad_norm": 0.20135009288787842,
      "learning_rate": 0.0004997521877713743,
      "loss": 1.5553,
      "step": 1490
    },
    {
      "epoch": 4.824476650563607,
      "grad_norm": 0.1605483740568161,
      "learning_rate": 0.0004997464591667618,
      "loss": 1.5374,
      "step": 1500
    },
    {
      "epoch": 4.856682769726248,
      "grad_norm": 0.18288551270961761,
      "learning_rate": 0.000499740665136912,
      "loss": 1.5136,
      "step": 1510
    },
    {
      "epoch": 4.888888888888889,
      "grad_norm": 0.1705579161643982,
      "learning_rate": 0.0004997348056833425,
      "loss": 1.5203,
      "step": 1520
    },
    {
      "epoch": 4.921095008051529,
      "grad_norm": 0.1534719318151474,
      "learning_rate": 0.0004997288808075884,
      "loss": 1.5248,
      "step": 1530
    },
    {
      "epoch": 4.9533011272141705,
      "grad_norm": 0.17951245605945587,
      "learning_rate": 0.0004997228905112017,
      "loss": 1.5269,
      "step": 1540
    },
    {
      "epoch": 4.9855072463768115,
      "grad_norm": 0.15280380845069885,
      "learning_rate": 0.000499716834795752,
      "loss": 1.5155,
      "step": 1550
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.698837161064148,
      "eval_runtime": 7.1812,
      "eval_samples_per_second": 3384.239,
      "eval_steps_per_second": 13.229,
      "step": 1555
    },
    {
      "epoch": 5.0161030595813205,
      "grad_norm": 0.22782351076602936,
      "learning_rate": 0.0004997107136628253,
      "loss": 1.4502,
      "step": 1560
    },
    {
      "epoch": 5.048309178743962,
      "grad_norm": 0.3557616174221039,
      "learning_rate": 0.0004997045271140255,
      "loss": 1.5123,
      "step": 1570
    },
    {
      "epoch": 5.080515297906603,
      "grad_norm": 0.1882685124874115,
      "learning_rate": 0.0004996982751509729,
      "loss": 1.5292,
      "step": 1580
    },
    {
      "epoch": 5.112721417069243,
      "grad_norm": 0.13990433514118195,
      "learning_rate": 0.0004996919577753055,
      "loss": 1.5267,
      "step": 1590
    },
    {
      "epoch": 5.144927536231884,
      "grad_norm": 0.18306311964988708,
      "learning_rate": 0.0004996855749886782,
      "loss": 1.512,
      "step": 1600
    },
    {
      "epoch": 5.177133655394525,
      "grad_norm": 0.15472279489040375,
      "learning_rate": 0.0004996791267927632,
      "loss": 1.5261,
      "step": 1610
    },
    {
      "epoch": 5.209339774557166,
      "grad_norm": 0.15422868728637695,
      "learning_rate": 0.0004996726131892495,
      "loss": 1.5128,
      "step": 1620
    },
    {
      "epoch": 5.241545893719807,
      "grad_norm": 0.15512646734714508,
      "learning_rate": 0.0004996660341798437,
      "loss": 1.5181,
      "step": 1630
    },
    {
      "epoch": 5.273752012882448,
      "grad_norm": 0.17673395574092865,
      "learning_rate": 0.000499659389766269,
      "loss": 1.5335,
      "step": 1640
    },
    {
      "epoch": 5.305958132045088,
      "grad_norm": 0.1466742753982544,
      "learning_rate": 0.0004996526799502662,
      "loss": 1.5334,
      "step": 1650
    },
    {
      "epoch": 5.338164251207729,
      "grad_norm": 0.15994445979595184,
      "learning_rate": 0.000499645904733593,
      "loss": 1.5284,
      "step": 1660
    },
    {
      "epoch": 5.37037037037037,
      "grad_norm": 0.1486615538597107,
      "learning_rate": 0.0004996390641180243,
      "loss": 1.5111,
      "step": 1670
    },
    {
      "epoch": 5.402576489533011,
      "grad_norm": 0.19390860199928284,
      "learning_rate": 0.000499632158105352,
      "loss": 1.5185,
      "step": 1680
    },
    {
      "epoch": 5.434782608695652,
      "grad_norm": 0.16956686973571777,
      "learning_rate": 0.0004996251866973855,
      "loss": 1.5047,
      "step": 1690
    },
    {
      "epoch": 5.466988727858293,
      "grad_norm": 0.17534682154655457,
      "learning_rate": 0.0004996181498959508,
      "loss": 1.531,
      "step": 1700
    },
    {
      "epoch": 5.499194847020934,
      "grad_norm": 0.24666261672973633,
      "learning_rate": 0.0004996110477028914,
      "loss": 1.4703,
      "step": 1710
    },
    {
      "epoch": 5.531400966183575,
      "grad_norm": 0.18713361024856567,
      "learning_rate": 0.0004996038801200678,
      "loss": 1.5014,
      "step": 1720
    },
    {
      "epoch": 5.563607085346216,
      "grad_norm": 0.22596220672130585,
      "learning_rate": 0.0004995966471493579,
      "loss": 1.4915,
      "step": 1730
    },
    {
      "epoch": 5.595813204508857,
      "grad_norm": 0.21978287398815155,
      "learning_rate": 0.0004995893487926563,
      "loss": 1.5318,
      "step": 1740
    },
    {
      "epoch": 5.628019323671498,
      "grad_norm": 0.3348253071308136,
      "learning_rate": 0.0004995819850518748,
      "loss": 1.4914,
      "step": 1750
    },
    {
      "epoch": 5.660225442834139,
      "grad_norm": 0.18854422867298126,
      "learning_rate": 0.0004995745559289428,
      "loss": 1.515,
      "step": 1760
    },
    {
      "epoch": 5.692431561996779,
      "grad_norm": 0.1451537013053894,
      "learning_rate": 0.0004995670614258061,
      "loss": 1.4902,
      "step": 1770
    },
    {
      "epoch": 5.72463768115942,
      "grad_norm": 0.19248922169208527,
      "learning_rate": 0.0004995595015444283,
      "loss": 1.4857,
      "step": 1780
    },
    {
      "epoch": 5.756843800322061,
      "grad_norm": 0.17916832864284515,
      "learning_rate": 0.0004995518762867896,
      "loss": 1.4846,
      "step": 1790
    },
    {
      "epoch": 5.789049919484702,
      "grad_norm": 0.2654523253440857,
      "learning_rate": 0.0004995441856548879,
      "loss": 1.5164,
      "step": 1800
    },
    {
      "epoch": 5.821256038647343,
      "grad_norm": 0.17270347476005554,
      "learning_rate": 0.0004995364296507376,
      "loss": 1.4996,
      "step": 1810
    },
    {
      "epoch": 5.853462157809984,
      "grad_norm": 0.1607087105512619,
      "learning_rate": 0.0004995286082763706,
      "loss": 1.5095,
      "step": 1820
    },
    {
      "epoch": 5.885668276972625,
      "grad_norm": 0.13680624961853027,
      "learning_rate": 0.0004995207215338358,
      "loss": 1.5321,
      "step": 1830
    },
    {
      "epoch": 5.917874396135265,
      "grad_norm": 0.14636974036693573,
      "learning_rate": 0.0004995127694251993,
      "loss": 1.5165,
      "step": 1840
    },
    {
      "epoch": 5.950080515297906,
      "grad_norm": 0.16075943410396576,
      "learning_rate": 0.0004995047519525443,
      "loss": 1.5301,
      "step": 1850
    },
    {
      "epoch": 5.982286634460547,
      "grad_norm": 0.14485618472099304,
      "learning_rate": 0.0004994966691179711,
      "loss": 1.4966,
      "step": 1860
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.681813657283783,
      "eval_runtime": 6.8094,
      "eval_samples_per_second": 3569.039,
      "eval_steps_per_second": 13.951,
      "step": 1866
    },
    {
      "epoch": 6.012882447665056,
      "grad_norm": 0.15323597192764282,
      "learning_rate": 0.0004994885209235972,
      "loss": 1.4318,
      "step": 1870
    },
    {
      "epoch": 6.0450885668276975,
      "grad_norm": 0.15752916038036346,
      "learning_rate": 0.000499480307371557,
      "loss": 1.509,
      "step": 1880
    },
    {
      "epoch": 6.0772946859903385,
      "grad_norm": 0.1593698114156723,
      "learning_rate": 0.0004994720284640023,
      "loss": 1.5182,
      "step": 1890
    },
    {
      "epoch": 6.109500805152979,
      "grad_norm": 0.13460880517959595,
      "learning_rate": 0.0004994636842031017,
      "loss": 1.5013,
      "step": 1900
    },
    {
      "epoch": 6.14170692431562,
      "grad_norm": 0.16988429427146912,
      "learning_rate": 0.0004994552745910415,
      "loss": 1.4781,
      "step": 1910
    },
    {
      "epoch": 6.173913043478261,
      "grad_norm": 0.14512254297733307,
      "learning_rate": 0.0004994467996300245,
      "loss": 1.5154,
      "step": 1920
    },
    {
      "epoch": 6.206119162640902,
      "grad_norm": 0.15137061476707458,
      "learning_rate": 0.0004994382593222707,
      "loss": 1.4861,
      "step": 1930
    },
    {
      "epoch": 6.238325281803543,
      "grad_norm": 0.13684219121932983,
      "learning_rate": 0.0004994296536700177,
      "loss": 1.4813,
      "step": 1940
    },
    {
      "epoch": 6.270531400966184,
      "grad_norm": 0.4305441975593567,
      "learning_rate": 0.0004994209826755197,
      "loss": 1.4928,
      "step": 1950
    },
    {
      "epoch": 6.302737520128824,
      "grad_norm": 0.15618030726909637,
      "learning_rate": 0.0004994122463410482,
      "loss": 1.4938,
      "step": 1960
    },
    {
      "epoch": 6.334943639291465,
      "grad_norm": 0.15011779963970184,
      "learning_rate": 0.000499403444668892,
      "loss": 1.5102,
      "step": 1970
    },
    {
      "epoch": 6.367149758454106,
      "grad_norm": 0.19332218170166016,
      "learning_rate": 0.0004993945776613566,
      "loss": 1.4963,
      "step": 1980
    },
    {
      "epoch": 6.399355877616747,
      "grad_norm": 0.2255537360906601,
      "learning_rate": 0.000499385645320765,
      "loss": 1.5018,
      "step": 1990
    },
    {
      "epoch": 6.431561996779388,
      "grad_norm": 0.14743733406066895,
      "learning_rate": 0.0004993766476494572,
      "loss": 1.5047,
      "step": 2000
    },
    {
      "epoch": 6.463768115942029,
      "grad_norm": 0.17307958006858826,
      "learning_rate": 0.0004993675846497903,
      "loss": 1.4993,
      "step": 2010
    },
    {
      "epoch": 6.49597423510467,
      "grad_norm": 0.14936943352222443,
      "learning_rate": 0.0004993584563241383,
      "loss": 1.4578,
      "step": 2020
    },
    {
      "epoch": 6.5281803542673105,
      "grad_norm": 0.19452950358390808,
      "learning_rate": 0.0004993492626748929,
      "loss": 1.4962,
      "step": 2030
    },
    {
      "epoch": 6.5603864734299515,
      "grad_norm": 0.15621478855609894,
      "learning_rate": 0.0004993400037044621,
      "loss": 1.4881,
      "step": 2040
    },
    {
      "epoch": 6.592592592592593,
      "grad_norm": 0.2608316242694855,
      "learning_rate": 0.0004993306794152717,
      "loss": 1.5233,
      "step": 2050
    },
    {
      "epoch": 6.624798711755234,
      "grad_norm": 0.1697128862142563,
      "learning_rate": 0.0004993212898097643,
      "loss": 1.4721,
      "step": 2060
    },
    {
      "epoch": 6.657004830917875,
      "grad_norm": 0.15416836738586426,
      "learning_rate": 0.0004993118348903997,
      "loss": 1.4658,
      "step": 2070
    },
    {
      "epoch": 6.689210950080515,
      "grad_norm": 0.12774202227592468,
      "learning_rate": 0.0004993023146596547,
      "loss": 1.4768,
      "step": 2080
    },
    {
      "epoch": 6.721417069243156,
      "grad_norm": 0.17712374031543732,
      "learning_rate": 0.0004992927291200233,
      "loss": 1.4925,
      "step": 2090
    },
    {
      "epoch": 6.753623188405797,
      "grad_norm": 0.21966910362243652,
      "learning_rate": 0.0004992830782740165,
      "loss": 1.4674,
      "step": 2100
    },
    {
      "epoch": 6.785829307568438,
      "grad_norm": 0.13559846580028534,
      "learning_rate": 0.0004992733621241627,
      "loss": 1.5047,
      "step": 2110
    },
    {
      "epoch": 6.818035426731079,
      "grad_norm": 0.1398826390504837,
      "learning_rate": 0.0004992635806730072,
      "loss": 1.4707,
      "step": 2120
    },
    {
      "epoch": 6.85024154589372,
      "grad_norm": 0.1450495719909668,
      "learning_rate": 0.0004992537339231122,
      "loss": 1.4961,
      "step": 2130
    },
    {
      "epoch": 6.882447665056361,
      "grad_norm": 0.1516386866569519,
      "learning_rate": 0.0004992438218770574,
      "loss": 1.4534,
      "step": 2140
    },
    {
      "epoch": 6.914653784219001,
      "grad_norm": 0.15732821822166443,
      "learning_rate": 0.0004992338445374394,
      "loss": 1.4705,
      "step": 2150
    },
    {
      "epoch": 6.946859903381642,
      "grad_norm": 0.1710532009601593,
      "learning_rate": 0.0004992238019068718,
      "loss": 1.4809,
      "step": 2160
    },
    {
      "epoch": 6.979066022544283,
      "grad_norm": 0.18401676416397095,
      "learning_rate": 0.0004992136939879857,
      "loss": 1.4706,
      "step": 2170
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.67413330078125,
      "eval_runtime": 6.8153,
      "eval_samples_per_second": 3565.942,
      "eval_steps_per_second": 13.939,
      "step": 2177
    },
    {
      "epoch": 7.009661835748792,
      "grad_norm": 0.1388043314218521,
      "learning_rate": 0.0004992035207834287,
      "loss": 1.4055,
      "step": 2180
    },
    {
      "epoch": 7.041867954911433,
      "grad_norm": 0.1691674292087555,
      "learning_rate": 0.000499193282295866,
      "loss": 1.4795,
      "step": 2190
    },
    {
      "epoch": 7.074074074074074,
      "grad_norm": 0.21640919148921967,
      "learning_rate": 0.0004991829785279798,
      "loss": 1.4689,
      "step": 2200
    },
    {
      "epoch": 7.106280193236715,
      "grad_norm": 0.3144627809524536,
      "learning_rate": 0.0004991726094824694,
      "loss": 1.4788,
      "step": 2210
    },
    {
      "epoch": 7.138486312399356,
      "grad_norm": 0.16290386021137238,
      "learning_rate": 0.0004991621751620509,
      "loss": 1.4685,
      "step": 2220
    },
    {
      "epoch": 7.170692431561997,
      "grad_norm": 0.15262441337108612,
      "learning_rate": 0.000499151675569458,
      "loss": 1.4783,
      "step": 2230
    },
    {
      "epoch": 7.202898550724638,
      "grad_norm": 0.18490862846374512,
      "learning_rate": 0.000499141110707441,
      "loss": 1.4742,
      "step": 2240
    },
    {
      "epoch": 7.235104669887279,
      "grad_norm": 0.18654470145702362,
      "learning_rate": 0.0004991304805787677,
      "loss": 1.4441,
      "step": 2250
    },
    {
      "epoch": 7.26731078904992,
      "grad_norm": 0.24860942363739014,
      "learning_rate": 0.0004991197851862229,
      "loss": 1.4699,
      "step": 2260
    },
    {
      "epoch": 7.29951690821256,
      "grad_norm": 0.5185728669166565,
      "learning_rate": 0.0004991090245326082,
      "loss": 1.4627,
      "step": 2270
    },
    {
      "epoch": 7.331723027375201,
      "grad_norm": 0.15014035999774933,
      "learning_rate": 0.0004990981986207428,
      "loss": 1.4839,
      "step": 2280
    },
    {
      "epoch": 7.363929146537842,
      "grad_norm": 0.17780081927776337,
      "learning_rate": 0.0004990873074534625,
      "loss": 1.4484,
      "step": 2290
    },
    {
      "epoch": 7.396135265700483,
      "grad_norm": 0.19425107538700104,
      "learning_rate": 0.0004990763510336207,
      "loss": 1.4849,
      "step": 2300
    },
    {
      "epoch": 7.428341384863124,
      "grad_norm": 0.18264897167682648,
      "learning_rate": 0.0004990653293640873,
      "loss": 1.4802,
      "step": 2310
    },
    {
      "epoch": 7.460547504025765,
      "grad_norm": 0.15577220916748047,
      "learning_rate": 0.0004990542424477498,
      "loss": 1.4721,
      "step": 2320
    },
    {
      "epoch": 7.492753623188406,
      "grad_norm": 0.22140878438949585,
      "learning_rate": 0.0004990430902875125,
      "loss": 1.4754,
      "step": 2330
    },
    {
      "epoch": 7.524959742351046,
      "grad_norm": 0.14593856036663055,
      "learning_rate": 0.0004990318728862969,
      "loss": 1.4636,
      "step": 2340
    },
    {
      "epoch": 7.557165861513687,
      "grad_norm": 0.15408645570278168,
      "learning_rate": 0.0004990205902470418,
      "loss": 1.4952,
      "step": 2350
    },
    {
      "epoch": 7.5893719806763285,
      "grad_norm": 0.14019536972045898,
      "learning_rate": 0.0004990092423727025,
      "loss": 1.4819,
      "step": 2360
    },
    {
      "epoch": 7.6215780998389695,
      "grad_norm": 0.14229600131511688,
      "learning_rate": 0.0004989978292662522,
      "loss": 1.4551,
      "step": 2370
    },
    {
      "epoch": 7.6537842190016105,
      "grad_norm": 0.1441868543624878,
      "learning_rate": 0.0004989863509306803,
      "loss": 1.5075,
      "step": 2380
    },
    {
      "epoch": 7.685990338164252,
      "grad_norm": 0.22147230803966522,
      "learning_rate": 0.0004989748073689942,
      "loss": 1.5028,
      "step": 2390
    },
    {
      "epoch": 7.718196457326892,
      "grad_norm": 0.1969624161720276,
      "learning_rate": 0.0004989631985842175,
      "loss": 1.4715,
      "step": 2400
    },
    {
      "epoch": 7.750402576489533,
      "grad_norm": 0.17032621800899506,
      "learning_rate": 0.0004989515245793915,
      "loss": 1.471,
      "step": 2410
    },
    {
      "epoch": 7.782608695652174,
      "grad_norm": 0.1883520632982254,
      "learning_rate": 0.0004989397853575745,
      "loss": 1.4868,
      "step": 2420
    },
    {
      "epoch": 7.814814814814815,
      "grad_norm": 0.16143125295639038,
      "learning_rate": 0.0004989279809218416,
      "loss": 1.4625,
      "step": 2430
    },
    {
      "epoch": 7.847020933977456,
      "grad_norm": 0.16912728548049927,
      "learning_rate": 0.0004989161112752854,
      "loss": 1.4609,
      "step": 2440
    },
    {
      "epoch": 7.879227053140097,
      "grad_norm": 0.14774003624916077,
      "learning_rate": 0.0004989041764210152,
      "loss": 1.4694,
      "step": 2450
    },
    {
      "epoch": 7.911433172302738,
      "grad_norm": 0.1577022522687912,
      "learning_rate": 0.0004988921763621574,
      "loss": 1.4565,
      "step": 2460
    },
    {
      "epoch": 7.943639291465378,
      "grad_norm": 0.1669955998659134,
      "learning_rate": 0.0004988801111018558,
      "loss": 1.4787,
      "step": 2470
    },
    {
      "epoch": 7.975845410628019,
      "grad_norm": 0.15103675425052643,
      "learning_rate": 0.0004988679806432712,
      "loss": 1.4711,
      "step": 2480
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.6698843240737915,
      "eval_runtime": 6.7742,
      "eval_samples_per_second": 3587.57,
      "eval_steps_per_second": 14.024,
      "step": 2488
    },
    {
      "epoch": 8.006441223832528,
      "grad_norm": 0.18322691321372986,
      "learning_rate": 0.000498855784989581,
      "loss": 1.3879,
      "step": 2490
    },
    {
      "epoch": 8.03864734299517,
      "grad_norm": 0.19465041160583496,
      "learning_rate": 0.0004988435241439805,
      "loss": 1.464,
      "step": 2500
    },
    {
      "epoch": 8.07085346215781,
      "grad_norm": 0.16813217103481293,
      "learning_rate": 0.0004988311981096813,
      "loss": 1.4746,
      "step": 2510
    },
    {
      "epoch": 8.103059581320451,
      "grad_norm": 0.15198609232902527,
      "learning_rate": 0.0004988188068899126,
      "loss": 1.4701,
      "step": 2520
    },
    {
      "epoch": 8.135265700483092,
      "grad_norm": 0.15329675376415253,
      "learning_rate": 0.0004988063504879203,
      "loss": 1.4425,
      "step": 2530
    },
    {
      "epoch": 8.167471819645733,
      "grad_norm": 0.1620205044746399,
      "learning_rate": 0.0004987938289069677,
      "loss": 1.4677,
      "step": 2540
    },
    {
      "epoch": 8.199677938808374,
      "grad_norm": 0.1422613114118576,
      "learning_rate": 0.0004987812421503351,
      "loss": 1.449,
      "step": 2550
    },
    {
      "epoch": 8.231884057971014,
      "grad_norm": 0.16896875202655792,
      "learning_rate": 0.0004987685902213196,
      "loss": 1.4459,
      "step": 2560
    },
    {
      "epoch": 8.264090177133655,
      "grad_norm": 0.15905654430389404,
      "learning_rate": 0.0004987558731232357,
      "loss": 1.4982,
      "step": 2570
    },
    {
      "epoch": 8.296296296296296,
      "grad_norm": 0.14258162677288055,
      "learning_rate": 0.000498743090859415,
      "loss": 1.4608,
      "step": 2580
    },
    {
      "epoch": 8.328502415458937,
      "grad_norm": 0.14230123162269592,
      "learning_rate": 0.0004987302434332058,
      "loss": 1.4655,
      "step": 2590
    },
    {
      "epoch": 8.360708534621578,
      "grad_norm": 0.15525570511817932,
      "learning_rate": 0.0004987173308479738,
      "loss": 1.4512,
      "step": 2600
    },
    {
      "epoch": 8.392914653784219,
      "grad_norm": 0.1806885004043579,
      "learning_rate": 0.0004987043531071016,
      "loss": 1.4744,
      "step": 2610
    },
    {
      "epoch": 8.42512077294686,
      "grad_norm": 0.16052617132663727,
      "learning_rate": 0.000498691310213989,
      "loss": 1.4827,
      "step": 2620
    },
    {
      "epoch": 8.457326892109501,
      "grad_norm": 0.2634183466434479,
      "learning_rate": 0.0004986782021720529,
      "loss": 1.4624,
      "step": 2630
    },
    {
      "epoch": 8.489533011272142,
      "grad_norm": 0.1496460884809494,
      "learning_rate": 0.0004986650289847269,
      "loss": 1.4551,
      "step": 2640
    },
    {
      "epoch": 8.521739130434783,
      "grad_norm": 0.13991929590702057,
      "learning_rate": 0.0004986517906554621,
      "loss": 1.4374,
      "step": 2650
    },
    {
      "epoch": 8.553945249597424,
      "grad_norm": 0.19292835891246796,
      "learning_rate": 0.0004986384871877266,
      "loss": 1.4591,
      "step": 2660
    },
    {
      "epoch": 8.586151368760065,
      "grad_norm": 0.20914091169834137,
      "learning_rate": 0.0004986251185850052,
      "loss": 1.465,
      "step": 2670
    },
    {
      "epoch": 8.618357487922705,
      "grad_norm": 0.21014529466629028,
      "learning_rate": 0.0004986116848508004,
      "loss": 1.4948,
      "step": 2680
    },
    {
      "epoch": 8.650563607085346,
      "grad_norm": 0.17291803658008575,
      "learning_rate": 0.000498598185988631,
      "loss": 1.4834,
      "step": 2690
    },
    {
      "epoch": 8.682769726247987,
      "grad_norm": 0.15582413971424103,
      "learning_rate": 0.0004985846220020335,
      "loss": 1.4588,
      "step": 2700
    },
    {
      "epoch": 8.714975845410628,
      "grad_norm": 0.1995086371898651,
      "learning_rate": 0.0004985709928945611,
      "loss": 1.4582,
      "step": 2710
    },
    {
      "epoch": 8.747181964573269,
      "grad_norm": 0.15208062529563904,
      "learning_rate": 0.0004985572986697842,
      "loss": 1.4719,
      "step": 2720
    },
    {
      "epoch": 8.77938808373591,
      "grad_norm": 0.22253690659999847,
      "learning_rate": 0.0004985435393312903,
      "loss": 1.4589,
      "step": 2730
    },
    {
      "epoch": 8.81159420289855,
      "grad_norm": 0.1508904993534088,
      "learning_rate": 0.0004985297148826838,
      "loss": 1.4585,
      "step": 2740
    },
    {
      "epoch": 8.843800322061192,
      "grad_norm": 0.15758563578128815,
      "learning_rate": 0.0004985158253275862,
      "loss": 1.423,
      "step": 2750
    },
    {
      "epoch": 8.876006441223833,
      "grad_norm": 0.15661455690860748,
      "learning_rate": 0.0004985018706696363,
      "loss": 1.462,
      "step": 2760
    },
    {
      "epoch": 8.908212560386474,
      "grad_norm": 0.21732887625694275,
      "learning_rate": 0.0004984878509124895,
      "loss": 1.4784,
      "step": 2770
    },
    {
      "epoch": 8.940418679549115,
      "grad_norm": 0.20085912942886353,
      "learning_rate": 0.0004984737660598187,
      "loss": 1.4695,
      "step": 2780
    },
    {
      "epoch": 8.972624798711756,
      "grad_norm": 0.40083760023117065,
      "learning_rate": 0.0004984596161153135,
      "loss": 1.4654,
      "step": 2790
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.664337694644928,
      "eval_runtime": 6.7965,
      "eval_samples_per_second": 3575.811,
      "eval_steps_per_second": 13.978,
      "step": 2799
    },
    {
      "epoch": 9.003220611916264,
      "grad_norm": 0.16927556693553925,
      "learning_rate": 0.000498445401082681,
      "loss": 1.3671,
      "step": 2800
    },
    {
      "epoch": 9.035426731078905,
      "grad_norm": 0.18728037178516388,
      "learning_rate": 0.0004984311209656446,
      "loss": 1.4473,
      "step": 2810
    },
    {
      "epoch": 9.067632850241546,
      "grad_norm": 0.17875514924526215,
      "learning_rate": 0.0004984167757679458,
      "loss": 1.4483,
      "step": 2820
    },
    {
      "epoch": 9.099838969404187,
      "grad_norm": 0.14222152531147003,
      "learning_rate": 0.000498402365493342,
      "loss": 1.4619,
      "step": 2830
    },
    {
      "epoch": 9.132045088566828,
      "grad_norm": 0.14956548810005188,
      "learning_rate": 0.0004983878901456086,
      "loss": 1.4312,
      "step": 2840
    },
    {
      "epoch": 9.16425120772947,
      "grad_norm": 0.16686207056045532,
      "learning_rate": 0.0004983733497285375,
      "loss": 1.4726,
      "step": 2850
    },
    {
      "epoch": 9.19645732689211,
      "grad_norm": 0.15799598395824432,
      "learning_rate": 0.0004983587442459377,
      "loss": 1.4801,
      "step": 2860
    },
    {
      "epoch": 9.22866344605475,
      "grad_norm": 0.15626206994056702,
      "learning_rate": 0.0004983440737016356,
      "loss": 1.4536,
      "step": 2870
    },
    {
      "epoch": 9.26086956521739,
      "grad_norm": 0.16912665963172913,
      "learning_rate": 0.0004983293380994741,
      "loss": 1.4524,
      "step": 2880
    },
    {
      "epoch": 9.293075684380032,
      "grad_norm": 0.19092801213264465,
      "learning_rate": 0.0004983145374433138,
      "loss": 1.4702,
      "step": 2890
    },
    {
      "epoch": 9.325281803542673,
      "grad_norm": 0.21390308439731598,
      "learning_rate": 0.0004982996717370317,
      "loss": 1.4316,
      "step": 2900
    },
    {
      "epoch": 9.357487922705314,
      "grad_norm": 0.168642058968544,
      "learning_rate": 0.0004982847409845221,
      "loss": 1.4384,
      "step": 2910
    },
    {
      "epoch": 9.389694041867955,
      "grad_norm": 0.15528292953968048,
      "learning_rate": 0.0004982697451896966,
      "loss": 1.4512,
      "step": 2920
    },
    {
      "epoch": 9.421900161030596,
      "grad_norm": 0.14011017978191376,
      "learning_rate": 0.0004982546843564834,
      "loss": 1.4591,
      "step": 2930
    },
    {
      "epoch": 9.454106280193237,
      "grad_norm": 0.20795442163944244,
      "learning_rate": 0.000498239558488828,
      "loss": 1.4727,
      "step": 2940
    },
    {
      "epoch": 9.486312399355878,
      "grad_norm": 0.1777896285057068,
      "learning_rate": 0.0004982243675906929,
      "loss": 1.4685,
      "step": 2950
    },
    {
      "epoch": 9.518518518518519,
      "grad_norm": 0.16643109917640686,
      "learning_rate": 0.0004982091116660575,
      "loss": 1.4502,
      "step": 2960
    },
    {
      "epoch": 9.55072463768116,
      "grad_norm": 0.16809536516666412,
      "learning_rate": 0.0004981937907189184,
      "loss": 1.4517,
      "step": 2970
    },
    {
      "epoch": 9.582930756843801,
      "grad_norm": 0.15959493815898895,
      "learning_rate": 0.0004981784047532892,
      "loss": 1.4482,
      "step": 2980
    },
    {
      "epoch": 9.61513687600644,
      "grad_norm": 0.1512577086687088,
      "learning_rate": 0.0004981629537732005,
      "loss": 1.4581,
      "step": 2990
    },
    {
      "epoch": 9.647342995169081,
      "grad_norm": 0.20630690455436707,
      "learning_rate": 0.0004981474377827,
      "loss": 1.4822,
      "step": 3000
    },
    {
      "epoch": 9.679549114331722,
      "grad_norm": 0.16455413401126862,
      "learning_rate": 0.0004981318567858523,
      "loss": 1.4749,
      "step": 3010
    },
    {
      "epoch": 9.711755233494364,
      "grad_norm": 0.15607063472270966,
      "learning_rate": 0.000498116210786739,
      "loss": 1.4309,
      "step": 3020
    },
    {
      "epoch": 9.743961352657005,
      "grad_norm": 0.154608815908432,
      "learning_rate": 0.0004981004997894591,
      "loss": 1.4486,
      "step": 3030
    },
    {
      "epoch": 9.776167471819646,
      "grad_norm": 0.47524088621139526,
      "learning_rate": 0.0004980847237981281,
      "loss": 1.4327,
      "step": 3040
    },
    {
      "epoch": 9.808373590982287,
      "grad_norm": 0.16965101659297943,
      "learning_rate": 0.0004980688828168789,
      "loss": 1.4679,
      "step": 3050
    },
    {
      "epoch": 9.840579710144928,
      "grad_norm": 0.15649336576461792,
      "learning_rate": 0.0004980529768498613,
      "loss": 1.4621,
      "step": 3060
    },
    {
      "epoch": 9.872785829307569,
      "grad_norm": 0.15509161353111267,
      "learning_rate": 0.0004980370059012422,
      "loss": 1.4512,
      "step": 3070
    },
    {
      "epoch": 9.90499194847021,
      "grad_norm": 0.16355054080486298,
      "learning_rate": 0.0004980209699752053,
      "loss": 1.4288,
      "step": 3080
    },
    {
      "epoch": 9.93719806763285,
      "grad_norm": 0.17360931634902954,
      "learning_rate": 0.0004980048690759515,
      "loss": 1.4562,
      "step": 3090
    },
    {
      "epoch": 9.969404186795492,
      "grad_norm": 0.15015381574630737,
      "learning_rate": 0.0004979887032076989,
      "loss": 1.4595,
      "step": 3100
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.13452446460723877,
      "learning_rate": 0.0004979724723746821,
      "loss": 1.3748,
      "step": 3110
    },
    {
      "epoch": 10.0,
      "eval_loss": 0.6637845039367676,
      "eval_runtime": 6.8019,
      "eval_samples_per_second": 3572.947,
      "eval_steps_per_second": 13.967,
      "step": 3110
    },
    {
      "epoch": 10.032206119162641,
      "grad_norm": 0.17231424152851105,
      "learning_rate": 0.0004979561765811534,
      "loss": 1.442,
      "step": 3120
    },
    {
      "epoch": 10.064412238325282,
      "grad_norm": 0.17102305591106415,
      "learning_rate": 0.0004979398158313814,
      "loss": 1.4346,
      "step": 3130
    },
    {
      "epoch": 10.096618357487923,
      "grad_norm": 0.17447026073932648,
      "learning_rate": 0.0004979233901296523,
      "loss": 1.4494,
      "step": 3140
    },
    {
      "epoch": 10.128824476650564,
      "grad_norm": 0.17300409078598022,
      "learning_rate": 0.000497906899480269,
      "loss": 1.4423,
      "step": 3150
    },
    {
      "epoch": 10.161030595813205,
      "grad_norm": 0.15979628264904022,
      "learning_rate": 0.0004978903438875515,
      "loss": 1.4485,
      "step": 3160
    },
    {
      "epoch": 10.193236714975846,
      "grad_norm": 0.17477717995643616,
      "learning_rate": 0.000497873723355837,
      "loss": 1.4418,
      "step": 3170
    },
    {
      "epoch": 10.225442834138486,
      "grad_norm": 0.14996854960918427,
      "learning_rate": 0.0004978570378894791,
      "loss": 1.4545,
      "step": 3180
    },
    {
      "epoch": 10.257648953301127,
      "grad_norm": 0.1639929711818695,
      "learning_rate": 0.0004978402874928492,
      "loss": 1.4372,
      "step": 3190
    },
    {
      "epoch": 10.289855072463768,
      "grad_norm": 0.15222376585006714,
      "learning_rate": 0.0004978234721703353,
      "loss": 1.4325,
      "step": 3200
    },
    {
      "epoch": 10.322061191626409,
      "grad_norm": 0.1705433875322342,
      "learning_rate": 0.0004978065919263424,
      "loss": 1.4724,
      "step": 3210
    },
    {
      "epoch": 10.35426731078905,
      "grad_norm": 0.13422556221485138,
      "learning_rate": 0.0004977896467652925,
      "loss": 1.4339,
      "step": 3220
    },
    {
      "epoch": 10.38647342995169,
      "grad_norm": 0.128107488155365,
      "learning_rate": 0.0004977726366916246,
      "loss": 1.4664,
      "step": 3230
    },
    {
      "epoch": 10.418679549114332,
      "grad_norm": 0.17491969466209412,
      "learning_rate": 0.0004977555617097951,
      "loss": 1.4627,
      "step": 3240
    },
    {
      "epoch": 10.450885668276973,
      "grad_norm": 0.18472202122211456,
      "learning_rate": 0.0004977384218242767,
      "loss": 1.4411,
      "step": 3250
    },
    {
      "epoch": 10.483091787439614,
      "grad_norm": 0.17872639000415802,
      "learning_rate": 0.0004977212170395597,
      "loss": 1.4366,
      "step": 3260
    },
    {
      "epoch": 10.515297906602255,
      "grad_norm": 0.14733608067035675,
      "learning_rate": 0.0004977039473601511,
      "loss": 1.4704,
      "step": 3270
    },
    {
      "epoch": 10.547504025764896,
      "grad_norm": 0.14558690786361694,
      "learning_rate": 0.0004976866127905751,
      "loss": 1.443,
      "step": 3280
    },
    {
      "epoch": 10.579710144927537,
      "grad_norm": 0.17720754444599152,
      "learning_rate": 0.0004976692133353727,
      "loss": 1.4374,
      "step": 3290
    },
    {
      "epoch": 10.611916264090176,
      "grad_norm": 0.15321943163871765,
      "learning_rate": 0.0004976517489991018,
      "loss": 1.4484,
      "step": 3300
    },
    {
      "epoch": 10.644122383252817,
      "grad_norm": 0.19449803233146667,
      "learning_rate": 0.0004976342197863377,
      "loss": 1.4472,
      "step": 3310
    },
    {
      "epoch": 10.676328502415458,
      "grad_norm": 0.1654287725687027,
      "learning_rate": 0.0004976166257016724,
      "loss": 1.444,
      "step": 3320
    },
    {
      "epoch": 10.7085346215781,
      "grad_norm": 0.166047602891922,
      "learning_rate": 0.0004975989667497149,
      "loss": 1.4656,
      "step": 3330
    },
    {
      "epoch": 10.74074074074074,
      "grad_norm": 0.19113987684249878,
      "learning_rate": 0.0004975812429350914,
      "loss": 1.4408,
      "step": 3340
    },
    {
      "epoch": 10.772946859903382,
      "grad_norm": 0.1553245484828949,
      "learning_rate": 0.0004975634542624448,
      "loss": 1.4477,
      "step": 3350
    },
    {
      "epoch": 10.805152979066023,
      "grad_norm": 0.14946328103542328,
      "learning_rate": 0.0004975456007364353,
      "loss": 1.4441,
      "step": 3360
    },
    {
      "epoch": 10.837359098228664,
      "grad_norm": 0.1627034842967987,
      "learning_rate": 0.0004975276823617398,
      "loss": 1.4381,
      "step": 3370
    },
    {
      "epoch": 10.869565217391305,
      "grad_norm": 0.1398199051618576,
      "learning_rate": 0.0004975096991430523,
      "loss": 1.4579,
      "step": 3380
    },
    {
      "epoch": 10.901771336553946,
      "grad_norm": 0.16581642627716064,
      "learning_rate": 0.0004974916510850839,
      "loss": 1.4404,
      "step": 3390
    },
    {
      "epoch": 10.933977455716587,
      "grad_norm": 0.17333084344863892,
      "learning_rate": 0.0004974735381925626,
      "loss": 1.4595,
      "step": 3400
    },
    {
      "epoch": 10.966183574879228,
      "grad_norm": 0.17691880464553833,
      "learning_rate": 0.0004974553604702333,
      "loss": 1.4663,
      "step": 3410
    },
    {
      "epoch": 10.998389694041869,
      "grad_norm": 0.18843907117843628,
      "learning_rate": 0.0004974371179228579,
      "loss": 1.4113,
      "step": 3420
    },
    {
      "epoch": 11.0,
      "eval_loss": 0.6617839932441711,
      "eval_runtime": 6.9664,
      "eval_samples_per_second": 3488.624,
      "eval_steps_per_second": 13.637,
      "step": 3421
    },
    {
      "epoch": 11.028985507246377,
      "grad_norm": 0.17201443016529083,
      "learning_rate": 0.0004974188105552153,
      "loss": 1.3597,
      "step": 3430
    },
    {
      "epoch": 11.061191626409018,
      "grad_norm": 0.15231990814208984,
      "learning_rate": 0.0004974004383721017,
      "loss": 1.4318,
      "step": 3440
    },
    {
      "epoch": 11.093397745571659,
      "grad_norm": 0.18173383176326752,
      "learning_rate": 0.0004973820013783297,
      "loss": 1.4398,
      "step": 3450
    },
    {
      "epoch": 11.1256038647343,
      "grad_norm": 0.17618583142757416,
      "learning_rate": 0.0004973634995787294,
      "loss": 1.4581,
      "step": 3460
    },
    {
      "epoch": 11.157809983896941,
      "grad_norm": 0.1553281545639038,
      "learning_rate": 0.0004973449329781476,
      "loss": 1.4667,
      "step": 3470
    },
    {
      "epoch": 11.190016103059582,
      "grad_norm": 0.15881997346878052,
      "learning_rate": 0.0004973263015814479,
      "loss": 1.4406,
      "step": 3480
    },
    {
      "epoch": 11.222222222222221,
      "grad_norm": 0.15169285237789154,
      "learning_rate": 0.0004973076053935115,
      "loss": 1.446,
      "step": 3490
    },
    {
      "epoch": 11.254428341384862,
      "grad_norm": 0.1536540389060974,
      "learning_rate": 0.000497288844419236,
      "loss": 1.4375,
      "step": 3500
    },
    {
      "epoch": 11.286634460547504,
      "grad_norm": 0.1917647421360016,
      "learning_rate": 0.000497270018663536,
      "loss": 1.438,
      "step": 3510
    },
    {
      "epoch": 11.318840579710145,
      "grad_norm": 0.16653300821781158,
      "learning_rate": 0.0004972511281313433,
      "loss": 1.4308,
      "step": 3520
    },
    {
      "epoch": 11.351046698872786,
      "grad_norm": 0.173232764005661,
      "learning_rate": 0.0004972321728276066,
      "loss": 1.454,
      "step": 3530
    },
    {
      "epoch": 11.383252818035427,
      "grad_norm": 0.18066465854644775,
      "learning_rate": 0.0004972131527572918,
      "loss": 1.43,
      "step": 3540
    },
    {
      "epoch": 11.415458937198068,
      "grad_norm": 0.18977467715740204,
      "learning_rate": 0.0004971940679253811,
      "loss": 1.4559,
      "step": 3550
    },
    {
      "epoch": 11.447665056360709,
      "grad_norm": 0.17699788510799408,
      "learning_rate": 0.0004971749183368743,
      "loss": 1.4799,
      "step": 3560
    },
    {
      "epoch": 11.47987117552335,
      "grad_norm": 0.1489800214767456,
      "learning_rate": 0.000497155703996788,
      "loss": 1.4229,
      "step": 3570
    },
    {
      "epoch": 11.51207729468599,
      "grad_norm": 0.23678505420684814,
      "learning_rate": 0.0004971364249101558,
      "loss": 1.4331,
      "step": 3580
    },
    {
      "epoch": 11.544283413848632,
      "grad_norm": 0.1508471965789795,
      "learning_rate": 0.0004971170810820279,
      "loss": 1.4524,
      "step": 3590
    },
    {
      "epoch": 11.576489533011273,
      "grad_norm": 0.5479297041893005,
      "learning_rate": 0.0004970976725174719,
      "loss": 1.4272,
      "step": 3600
    },
    {
      "epoch": 11.608695652173914,
      "grad_norm": 0.18615397810935974,
      "learning_rate": 0.0004970781992215722,
      "loss": 1.4398,
      "step": 3610
    },
    {
      "epoch": 11.640901771336553,
      "grad_norm": 0.14682026207447052,
      "learning_rate": 0.0004970586611994302,
      "loss": 1.4388,
      "step": 3620
    },
    {
      "epoch": 11.673107890499194,
      "grad_norm": 0.14355406165122986,
      "learning_rate": 0.000497039058456164,
      "loss": 1.4496,
      "step": 3630
    },
    {
      "epoch": 11.705314009661835,
      "grad_norm": 0.20219703018665314,
      "learning_rate": 0.0004970193909969089,
      "loss": 1.4547,
      "step": 3640
    },
    {
      "epoch": 11.737520128824476,
      "grad_norm": 0.1922639012336731,
      "learning_rate": 0.0004969996588268175,
      "loss": 1.4402,
      "step": 3650
    },
    {
      "epoch": 11.769726247987117,
      "grad_norm": 0.18442879617214203,
      "learning_rate": 0.0004969798619510585,
      "loss": 1.4446,
      "step": 3660
    },
    {
      "epoch": 11.801932367149758,
      "grad_norm": 0.22222761809825897,
      "learning_rate": 0.0004969600003748184,
      "loss": 1.4388,
      "step": 3670
    },
    {
      "epoch": 11.8341384863124,
      "grad_norm": 0.1513354629278183,
      "learning_rate": 0.0004969400741032999,
      "loss": 1.4277,
      "step": 3680
    },
    {
      "epoch": 11.86634460547504,
      "grad_norm": 0.16533923149108887,
      "learning_rate": 0.0004969200831417233,
      "loss": 1.4513,
      "step": 3690
    },
    {
      "epoch": 11.898550724637682,
      "grad_norm": 0.16173170506954193,
      "learning_rate": 0.0004969000274953255,
      "loss": 1.4377,
      "step": 3700
    },
    {
      "epoch": 11.930756843800323,
      "grad_norm": 0.21154679358005524,
      "learning_rate": 0.0004968799071693602,
      "loss": 1.4238,
      "step": 3710
    },
    {
      "epoch": 11.962962962962964,
      "grad_norm": 0.23906590044498444,
      "learning_rate": 0.0004968597221690986,
      "loss": 1.4318,
      "step": 3720
    },
    {
      "epoch": 11.995169082125603,
      "grad_norm": 0.13879260420799255,
      "learning_rate": 0.0004968394724998283,
      "loss": 1.4392,
      "step": 3730
    },
    {
      "epoch": 12.0,
      "eval_loss": 0.656994640827179,
      "eval_runtime": 6.7915,
      "eval_samples_per_second": 3578.437,
      "eval_steps_per_second": 13.988,
      "step": 3732
    },
    {
      "epoch": 12.025764895330113,
      "grad_norm": 0.15939070284366608,
      "learning_rate": 0.000496819158166854,
      "loss": 1.38,
      "step": 3740
    },
    {
      "epoch": 12.057971014492754,
      "grad_norm": 0.1430894285440445,
      "learning_rate": 0.0004967987791754976,
      "loss": 1.4182,
      "step": 3750
    },
    {
      "epoch": 12.090177133655395,
      "grad_norm": 0.16801930963993073,
      "learning_rate": 0.0004967783355310973,
      "loss": 1.4425,
      "step": 3760
    },
    {
      "epoch": 12.122383252818036,
      "grad_norm": 0.15116995573043823,
      "learning_rate": 0.0004967578272390091,
      "loss": 1.4383,
      "step": 3770
    },
    {
      "epoch": 12.154589371980677,
      "grad_norm": 0.16393110156059265,
      "learning_rate": 0.0004967372543046053,
      "loss": 1.4435,
      "step": 3780
    },
    {
      "epoch": 12.186795491143318,
      "grad_norm": 0.18907159566879272,
      "learning_rate": 0.0004967166167332753,
      "loss": 1.4451,
      "step": 3790
    },
    {
      "epoch": 12.219001610305957,
      "grad_norm": 0.18367531895637512,
      "learning_rate": 0.0004966959145304254,
      "loss": 1.4411,
      "step": 3800
    },
    {
      "epoch": 12.251207729468598,
      "grad_norm": 0.18570490181446075,
      "learning_rate": 0.000496675147701479,
      "loss": 1.4311,
      "step": 3810
    },
    {
      "epoch": 12.28341384863124,
      "grad_norm": 0.16362647712230682,
      "learning_rate": 0.0004966543162518763,
      "loss": 1.445,
      "step": 3820
    },
    {
      "epoch": 12.31561996779388,
      "grad_norm": 0.18834024667739868,
      "learning_rate": 0.0004966334201870744,
      "loss": 1.4375,
      "step": 3830
    },
    {
      "epoch": 12.347826086956522,
      "grad_norm": 0.1456049382686615,
      "learning_rate": 0.0004966124595125474,
      "loss": 1.4372,
      "step": 3840
    },
    {
      "epoch": 12.380032206119163,
      "grad_norm": 0.1812659204006195,
      "learning_rate": 0.0004965914342337863,
      "loss": 1.419,
      "step": 3850
    },
    {
      "epoch": 12.412238325281804,
      "grad_norm": 0.18090420961380005,
      "learning_rate": 0.000496570344356299,
      "loss": 1.4678,
      "step": 3860
    },
    {
      "epoch": 12.444444444444445,
      "grad_norm": 0.15702365338802338,
      "learning_rate": 0.0004965491898856104,
      "loss": 1.4388,
      "step": 3870
    },
    {
      "epoch": 12.476650563607086,
      "grad_norm": 0.17507851123809814,
      "learning_rate": 0.0004965279708272621,
      "loss": 1.425,
      "step": 3880
    },
    {
      "epoch": 12.508856682769727,
      "grad_norm": 0.1855591982603073,
      "learning_rate": 0.0004965066871868131,
      "loss": 1.4521,
      "step": 3890
    },
    {
      "epoch": 12.541062801932368,
      "grad_norm": 0.19170992076396942,
      "learning_rate": 0.0004964853389698386,
      "loss": 1.4569,
      "step": 3900
    },
    {
      "epoch": 12.573268921095009,
      "grad_norm": 0.15879689157009125,
      "learning_rate": 0.0004964639261819314,
      "loss": 1.4343,
      "step": 3910
    },
    {
      "epoch": 12.605475040257648,
      "grad_norm": 0.16757982969284058,
      "learning_rate": 0.0004964424488287009,
      "loss": 1.4217,
      "step": 3920
    },
    {
      "epoch": 12.63768115942029,
      "grad_norm": 0.17476607859134674,
      "learning_rate": 0.0004964209069157735,
      "loss": 1.4293,
      "step": 3930
    },
    {
      "epoch": 12.66988727858293,
      "grad_norm": 0.18486259877681732,
      "learning_rate": 0.0004963993004487923,
      "loss": 1.4685,
      "step": 3940
    },
    {
      "epoch": 12.702093397745571,
      "grad_norm": 0.19332700967788696,
      "learning_rate": 0.0004963776294334175,
      "loss": 1.4211,
      "step": 3950
    },
    {
      "epoch": 12.734299516908212,
      "grad_norm": 0.1622408926486969,
      "learning_rate": 0.0004963558938753263,
      "loss": 1.42,
      "step": 3960
    },
    {
      "epoch": 12.766505636070853,
      "grad_norm": 0.18684075772762299,
      "learning_rate": 0.0004963340937802126,
      "loss": 1.4313,
      "step": 3970
    },
    {
      "epoch": 12.798711755233494,
      "grad_norm": 0.16396455466747284,
      "learning_rate": 0.0004963122291537874,
      "loss": 1.4531,
      "step": 3980
    },
    {
      "epoch": 12.830917874396135,
      "grad_norm": 0.14375890791416168,
      "learning_rate": 0.0004962903000017783,
      "loss": 1.4186,
      "step": 3990
    },
    {
      "epoch": 12.863123993558776,
      "grad_norm": 0.1506449431180954,
      "learning_rate": 0.0004962683063299302,
      "loss": 1.4348,
      "step": 4000
    },
    {
      "epoch": 12.895330112721417,
      "grad_norm": 0.1591147482395172,
      "learning_rate": 0.0004962462481440047,
      "loss": 1.4393,
      "step": 4010
    },
    {
      "epoch": 12.927536231884059,
      "grad_norm": 0.19391024112701416,
      "learning_rate": 0.0004962241254497801,
      "loss": 1.4276,
      "step": 4020
    },
    {
      "epoch": 12.9597423510467,
      "grad_norm": 0.15538917481899261,
      "learning_rate": 0.000496201938253052,
      "loss": 1.4259,
      "step": 4030
    },
    {
      "epoch": 12.99194847020934,
      "grad_norm": 0.16099223494529724,
      "learning_rate": 0.0004961796865596327,
      "loss": 1.4204,
      "step": 4040
    },
    {
      "epoch": 13.0,
      "eval_loss": 0.6572942733764648,
      "eval_runtime": 7.4934,
      "eval_samples_per_second": 3243.247,
      "eval_steps_per_second": 12.678,
      "step": 4043
    },
    {
      "epoch": 13.022544283413849,
      "grad_norm": 0.1536048799753189,
      "learning_rate": 0.0004961573703753514,
      "loss": 1.3679,
      "step": 4050
    },
    {
      "epoch": 13.05475040257649,
      "grad_norm": 0.16156728565692902,
      "learning_rate": 0.000496134989706054,
      "loss": 1.4163,
      "step": 4060
    },
    {
      "epoch": 13.08695652173913,
      "grad_norm": 0.16624794900417328,
      "learning_rate": 0.0004961125445576038,
      "loss": 1.4569,
      "step": 4070
    },
    {
      "epoch": 13.119162640901772,
      "grad_norm": 0.1948987990617752,
      "learning_rate": 0.0004960900349358806,
      "loss": 1.441,
      "step": 4080
    },
    {
      "epoch": 13.151368760064413,
      "grad_norm": 0.17339888215065002,
      "learning_rate": 0.0004960674608467809,
      "loss": 1.4249,
      "step": 4090
    },
    {
      "epoch": 13.183574879227054,
      "grad_norm": 0.15571779012680054,
      "learning_rate": 0.0004960448222962186,
      "loss": 1.4238,
      "step": 4100
    },
    {
      "epoch": 13.215780998389693,
      "grad_norm": 0.1595926582813263,
      "learning_rate": 0.0004960221192901243,
      "loss": 1.4114,
      "step": 4110
    },
    {
      "epoch": 13.247987117552334,
      "grad_norm": 0.19090227782726288,
      "learning_rate": 0.0004959993518344453,
      "loss": 1.4468,
      "step": 4120
    },
    {
      "epoch": 13.280193236714975,
      "grad_norm": 0.1714610457420349,
      "learning_rate": 0.0004959765199351458,
      "loss": 1.4212,
      "step": 4130
    },
    {
      "epoch": 13.312399355877616,
      "grad_norm": 0.16415318846702576,
      "learning_rate": 0.0004959536235982073,
      "loss": 1.4217,
      "step": 4140
    },
    {
      "epoch": 13.344605475040257,
      "grad_norm": 0.16280725598335266,
      "learning_rate": 0.0004959306628296277,
      "loss": 1.4174,
      "step": 4150
    },
    {
      "epoch": 13.376811594202898,
      "grad_norm": 0.15703067183494568,
      "learning_rate": 0.0004959076376354219,
      "loss": 1.4254,
      "step": 4160
    },
    {
      "epoch": 13.40901771336554,
      "grad_norm": 0.15860256552696228,
      "learning_rate": 0.0004958845480216217,
      "loss": 1.4451,
      "step": 4170
    },
    {
      "epoch": 13.44122383252818,
      "grad_norm": 0.17620819807052612,
      "learning_rate": 0.0004958613939942761,
      "loss": 1.4231,
      "step": 4180
    },
    {
      "epoch": 13.473429951690822,
      "grad_norm": 0.1576133668422699,
      "learning_rate": 0.0004958381755594504,
      "loss": 1.4491,
      "step": 4190
    },
    {
      "epoch": 13.505636070853463,
      "grad_norm": 0.16248013079166412,
      "learning_rate": 0.0004958148927232272,
      "loss": 1.4247,
      "step": 4200
    },
    {
      "epoch": 13.537842190016104,
      "grad_norm": 0.14844200015068054,
      "learning_rate": 0.0004957915454917057,
      "loss": 1.4392,
      "step": 4210
    },
    {
      "epoch": 13.570048309178745,
      "grad_norm": 0.15753553807735443,
      "learning_rate": 0.0004957681338710022,
      "loss": 1.4475,
      "step": 4220
    },
    {
      "epoch": 13.602254428341386,
      "grad_norm": 0.14858852326869965,
      "learning_rate": 0.0004957446578672497,
      "loss": 1.4483,
      "step": 4230
    },
    {
      "epoch": 13.634460547504025,
      "grad_norm": 0.15973429381847382,
      "learning_rate": 0.0004957211174865982,
      "loss": 1.4295,
      "step": 4240
    },
    {
      "epoch": 13.666666666666666,
      "grad_norm": 0.22608084976673126,
      "learning_rate": 0.0004956975127352146,
      "loss": 1.4305,
      "step": 4250
    },
    {
      "epoch": 13.698872785829307,
      "grad_norm": 0.16118043661117554,
      "learning_rate": 0.0004956738436192821,
      "loss": 1.4165,
      "step": 4260
    },
    {
      "epoch": 13.731078904991948,
      "grad_norm": 0.17461398243904114,
      "learning_rate": 0.0004956501101450018,
      "loss": 1.4302,
      "step": 4270
    },
    {
      "epoch": 13.76328502415459,
      "grad_norm": 0.15553459525108337,
      "learning_rate": 0.0004956263123185907,
      "loss": 1.4472,
      "step": 4280
    },
    {
      "epoch": 13.79549114331723,
      "grad_norm": 0.1613396853208542,
      "learning_rate": 0.0004956024501462831,
      "loss": 1.4368,
      "step": 4290
    },
    {
      "epoch": 13.827697262479871,
      "grad_norm": 0.15553706884384155,
      "learning_rate": 0.0004955785236343302,
      "loss": 1.4415,
      "step": 4300
    },
    {
      "epoch": 13.859903381642512,
      "grad_norm": 0.15800869464874268,
      "learning_rate": 0.0004955545327889998,
      "loss": 1.4481,
      "step": 4310
    },
    {
      "epoch": 13.892109500805153,
      "grad_norm": 0.15715350210666656,
      "learning_rate": 0.0004955304776165769,
      "loss": 1.4505,
      "step": 4320
    },
    {
      "epoch": 13.924315619967794,
      "grad_norm": 0.14956147968769073,
      "learning_rate": 0.000495506358123363,
      "loss": 1.4397,
      "step": 4330
    },
    {
      "epoch": 13.956521739130435,
      "grad_norm": 0.16963784396648407,
      "learning_rate": 0.0004954821743156767,
      "loss": 1.395,
      "step": 4340
    },
    {
      "epoch": 13.988727858293075,
      "grad_norm": 0.1620839536190033,
      "learning_rate": 0.0004954579261998532,
      "loss": 1.4213,
      "step": 4350
    },
    {
      "epoch": 14.0,
      "eval_loss": 0.6562114357948303,
      "eval_runtime": 7.5946,
      "eval_samples_per_second": 3200.056,
      "eval_steps_per_second": 12.509,
      "step": 4354
    },
    {
      "epoch": 14.019323671497585,
      "grad_norm": 0.17068970203399658,
      "learning_rate": 0.0004954336137822448,
      "loss": 1.3459,
      "step": 4360
    },
    {
      "epoch": 14.051529790660226,
      "grad_norm": 0.17650717496871948,
      "learning_rate": 0.0004954092370692206,
      "loss": 1.4528,
      "step": 4370
    },
    {
      "epoch": 14.083735909822867,
      "grad_norm": 0.1534167230129242,
      "learning_rate": 0.0004953847960671664,
      "loss": 1.4318,
      "step": 4380
    },
    {
      "epoch": 14.115942028985508,
      "grad_norm": 0.1677519828081131,
      "learning_rate": 0.0004953602907824849,
      "loss": 1.4283,
      "step": 4390
    },
    {
      "epoch": 14.148148148148149,
      "grad_norm": 0.2043144851922989,
      "learning_rate": 0.0004953357212215956,
      "loss": 1.4302,
      "step": 4400
    },
    {
      "epoch": 14.18035426731079,
      "grad_norm": 0.1449277102947235,
      "learning_rate": 0.0004953110873909352,
      "loss": 1.4446,
      "step": 4410
    },
    {
      "epoch": 14.21256038647343,
      "grad_norm": 0.1774360090494156,
      "learning_rate": 0.0004952863892969567,
      "loss": 1.4545,
      "step": 4420
    },
    {
      "epoch": 14.24476650563607,
      "grad_norm": 0.17198446393013,
      "learning_rate": 0.0004952616269461302,
      "loss": 1.4324,
      "step": 4430
    },
    {
      "epoch": 14.276972624798711,
      "grad_norm": 0.18998588621616364,
      "learning_rate": 0.0004952368003449427,
      "loss": 1.4341,
      "step": 4440
    },
    {
      "epoch": 14.309178743961352,
      "grad_norm": 0.15242792665958405,
      "learning_rate": 0.0004952119094998978,
      "loss": 1.4117,
      "step": 4450
    },
    {
      "epoch": 14.341384863123993,
      "grad_norm": 0.1775166392326355,
      "learning_rate": 0.0004951869544175163,
      "loss": 1.4202,
      "step": 4460
    },
    {
      "epoch": 14.373590982286634,
      "grad_norm": 0.18120448291301727,
      "learning_rate": 0.0004951619351043353,
      "loss": 1.423,
      "step": 4470
    },
    {
      "epoch": 14.405797101449275,
      "grad_norm": 0.20207242667675018,
      "learning_rate": 0.0004951368515669092,
      "loss": 1.4424,
      "step": 4480
    },
    {
      "epoch": 14.438003220611916,
      "grad_norm": 0.1746872365474701,
      "learning_rate": 0.0004951117038118091,
      "loss": 1.4458,
      "step": 4490
    },
    {
      "epoch": 14.470209339774557,
      "grad_norm": 0.156539186835289,
      "learning_rate": 0.0004950864918456227,
      "loss": 1.428,
      "step": 4500
    },
    {
      "epoch": 14.502415458937199,
      "grad_norm": 0.15969052910804749,
      "learning_rate": 0.0004950612156749549,
      "loss": 1.4161,
      "step": 4510
    },
    {
      "epoch": 14.53462157809984,
      "grad_norm": 0.2103261947631836,
      "learning_rate": 0.0004950358753064271,
      "loss": 1.4534,
      "step": 4520
    },
    {
      "epoch": 14.56682769726248,
      "grad_norm": 0.15656517446041107,
      "learning_rate": 0.0004950104707466775,
      "loss": 1.4033,
      "step": 4530
    },
    {
      "epoch": 14.59903381642512,
      "grad_norm": 0.15591031312942505,
      "learning_rate": 0.0004949850020023615,
      "loss": 1.4334,
      "step": 4540
    },
    {
      "epoch": 14.631239935587761,
      "grad_norm": 0.16249893605709076,
      "learning_rate": 0.0004949594690801509,
      "loss": 1.415,
      "step": 4550
    },
    {
      "epoch": 14.663446054750402,
      "grad_norm": 0.16478058695793152,
      "learning_rate": 0.0004949338719867346,
      "loss": 1.4102,
      "step": 4560
    },
    {
      "epoch": 14.695652173913043,
      "grad_norm": 0.16804006695747375,
      "learning_rate": 0.0004949082107288179,
      "loss": 1.4323,
      "step": 4570
    },
    {
      "epoch": 14.727858293075684,
      "grad_norm": 0.15048816800117493,
      "learning_rate": 0.0004948824853131237,
      "loss": 1.3894,
      "step": 4580
    },
    {
      "epoch": 14.760064412238325,
      "grad_norm": 0.1637336015701294,
      "learning_rate": 0.0004948566957463907,
      "loss": 1.4159,
      "step": 4590
    },
    {
      "epoch": 14.792270531400966,
      "grad_norm": 0.16031694412231445,
      "learning_rate": 0.000494830842035375,
      "loss": 1.4194,
      "step": 4600
    },
    {
      "epoch": 14.824476650563607,
      "grad_norm": 0.18640099465847015,
      "learning_rate": 0.0004948049241868497,
      "loss": 1.4281,
      "step": 4610
    },
    {
      "epoch": 14.856682769726248,
      "grad_norm": 0.16098783910274506,
      "learning_rate": 0.0004947789422076042,
      "loss": 1.432,
      "step": 4620
    },
    {
      "epoch": 14.88888888888889,
      "grad_norm": 0.14734598994255066,
      "learning_rate": 0.000494752896104445,
      "loss": 1.4219,
      "step": 4630
    },
    {
      "epoch": 14.92109500805153,
      "grad_norm": 0.1710859090089798,
      "learning_rate": 0.0004947267858841951,
      "loss": 1.4359,
      "step": 4640
    },
    {
      "epoch": 14.953301127214171,
      "grad_norm": 0.16678299009799957,
      "learning_rate": 0.0004947006115536948,
      "loss": 1.4233,
      "step": 4650
    },
    {
      "epoch": 14.985507246376812,
      "grad_norm": 0.1586005836725235,
      "learning_rate": 0.0004946743731198005,
      "loss": 1.4336,
      "step": 4660
    },
    {
      "epoch": 15.0,
      "eval_loss": 0.6521374583244324,
      "eval_runtime": 7.0934,
      "eval_samples_per_second": 3426.134,
      "eval_steps_per_second": 13.393,
      "step": 4665
    },
    {
      "epoch": 15.01610305958132,
      "grad_norm": 0.14826634526252747,
      "learning_rate": 0.0004946480705893862,
      "loss": 1.372,
      "step": 4670
    },
    {
      "epoch": 15.048309178743962,
      "grad_norm": 0.1522434651851654,
      "learning_rate": 0.0004946217039693421,
      "loss": 1.4069,
      "step": 4680
    },
    {
      "epoch": 15.080515297906603,
      "grad_norm": 0.17626895010471344,
      "learning_rate": 0.0004945952732665755,
      "loss": 1.4196,
      "step": 4690
    },
    {
      "epoch": 15.112721417069244,
      "grad_norm": 0.17882001399993896,
      "learning_rate": 0.0004945687784880102,
      "loss": 1.4313,
      "step": 4700
    },
    {
      "epoch": 15.144927536231885,
      "grad_norm": 0.20023031532764435,
      "learning_rate": 0.000494542219640587,
      "loss": 1.417,
      "step": 4710
    },
    {
      "epoch": 15.177133655394526,
      "grad_norm": 0.18863113224506378,
      "learning_rate": 0.0004945155967312635,
      "loss": 1.4273,
      "step": 4720
    },
    {
      "epoch": 15.209339774557165,
      "grad_norm": 0.17494891583919525,
      "learning_rate": 0.000494488909767014,
      "loss": 1.463,
      "step": 4730
    },
    {
      "epoch": 15.241545893719806,
      "grad_norm": 0.19647251069545746,
      "learning_rate": 0.0004944621587548295,
      "loss": 1.4301,
      "step": 4740
    },
    {
      "epoch": 15.273752012882447,
      "grad_norm": 0.2106785774230957,
      "learning_rate": 0.0004944353437017178,
      "loss": 1.4141,
      "step": 4750
    },
    {
      "epoch": 15.305958132045088,
      "grad_norm": 0.18439067900180817,
      "learning_rate": 0.0004944084646147038,
      "loss": 1.4271,
      "step": 4760
    },
    {
      "epoch": 15.33816425120773,
      "grad_norm": 0.17408126592636108,
      "learning_rate": 0.0004943815215008287,
      "loss": 1.4077,
      "step": 4770
    },
    {
      "epoch": 15.37037037037037,
      "grad_norm": 0.18110519647598267,
      "learning_rate": 0.000494354514367151,
      "loss": 1.4071,
      "step": 4780
    },
    {
      "epoch": 15.402576489533011,
      "grad_norm": 0.15832534432411194,
      "learning_rate": 0.0004943274432207453,
      "loss": 1.4097,
      "step": 4790
    },
    {
      "epoch": 15.434782608695652,
      "grad_norm": 0.21580827236175537,
      "learning_rate": 0.0004943003080687035,
      "loss": 1.4302,
      "step": 4800
    },
    {
      "epoch": 15.466988727858293,
      "grad_norm": 0.3186013102531433,
      "learning_rate": 0.0004942731089181342,
      "loss": 1.4318,
      "step": 4810
    },
    {
      "epoch": 15.499194847020934,
      "grad_norm": 0.18750053644180298,
      "learning_rate": 0.0004942458457761625,
      "loss": 1.4353,
      "step": 4820
    },
    {
      "epoch": 15.531400966183575,
      "grad_norm": 0.15377572178840637,
      "learning_rate": 0.0004942185186499306,
      "loss": 1.4249,
      "step": 4830
    },
    {
      "epoch": 15.563607085346217,
      "grad_norm": 0.16476841270923615,
      "learning_rate": 0.0004941911275465971,
      "loss": 1.4435,
      "step": 4840
    },
    {
      "epoch": 15.595813204508858,
      "grad_norm": 0.17062248289585114,
      "learning_rate": 0.0004941636724733377,
      "loss": 1.4152,
      "step": 4850
    },
    {
      "epoch": 15.628019323671497,
      "grad_norm": 0.17781352996826172,
      "learning_rate": 0.0004941361534373446,
      "loss": 1.4298,
      "step": 4860
    },
    {
      "epoch": 15.660225442834138,
      "grad_norm": 0.18422527611255646,
      "learning_rate": 0.0004941085704458271,
      "loss": 1.4398,
      "step": 4870
    },
    {
      "epoch": 15.692431561996779,
      "grad_norm": 0.1519620567560196,
      "learning_rate": 0.0004940809235060107,
      "loss": 1.4225,
      "step": 4880
    },
    {
      "epoch": 15.72463768115942,
      "grad_norm": 0.1581529825925827,
      "learning_rate": 0.0004940532126251382,
      "loss": 1.4233,
      "step": 4890
    },
    {
      "epoch": 15.756843800322061,
      "grad_norm": 0.34125158190727234,
      "learning_rate": 0.0004940254378104689,
      "loss": 1.4109,
      "step": 4900
    },
    {
      "epoch": 15.789049919484702,
      "grad_norm": 0.22954395413398743,
      "learning_rate": 0.0004939975990692789,
      "loss": 1.4446,
      "step": 4910
    },
    {
      "epoch": 15.821256038647343,
      "grad_norm": 0.17124825716018677,
      "learning_rate": 0.0004939696964088608,
      "loss": 1.4057,
      "step": 4920
    },
    {
      "epoch": 15.853462157809984,
      "grad_norm": 0.1896205097436905,
      "learning_rate": 0.0004939417298365245,
      "loss": 1.4313,
      "step": 4930
    },
    {
      "epoch": 15.885668276972625,
      "grad_norm": 0.16936175525188446,
      "learning_rate": 0.000493913699359596,
      "loss": 1.4278,
      "step": 4940
    },
    {
      "epoch": 15.917874396135266,
      "grad_norm": 0.172247052192688,
      "learning_rate": 0.0004938856049854184,
      "loss": 1.4066,
      "step": 4950
    },
    {
      "epoch": 15.950080515297907,
      "grad_norm": 0.16870085895061493,
      "learning_rate": 0.0004938574467213517,
      "loss": 1.4385,
      "step": 4960
    },
    {
      "epoch": 15.982286634460548,
      "grad_norm": 0.17251688241958618,
      "learning_rate": 0.0004938292245747724,
      "loss": 1.4313,
      "step": 4970
    },
    {
      "epoch": 16.0,
      "eval_loss": 0.6530383229255676,
      "eval_runtime": 7.077,
      "eval_samples_per_second": 3434.078,
      "eval_steps_per_second": 13.424,
      "step": 4976
    },
    {
      "epoch": 16.012882447665056,
      "grad_norm": 0.1794786900281906,
      "learning_rate": 0.0004938009385530736,
      "loss": 1.3439,
      "step": 4980
    },
    {
      "epoch": 16.045088566827697,
      "grad_norm": 0.16710038483142853,
      "learning_rate": 0.0004937725886636653,
      "loss": 1.4142,
      "step": 4990
    },
    {
      "epoch": 16.07729468599034,
      "grad_norm": 0.16267918050289154,
      "learning_rate": 0.0004937441749139742,
      "loss": 1.4182,
      "step": 5000
    },
    {
      "epoch": 16.10950080515298,
      "grad_norm": 0.167859748005867,
      "learning_rate": 0.000493715697311444,
      "loss": 1.4268,
      "step": 5010
    },
    {
      "epoch": 16.14170692431562,
      "grad_norm": 0.20637013018131256,
      "learning_rate": 0.0004936871558635346,
      "loss": 1.4087,
      "step": 5020
    },
    {
      "epoch": 16.17391304347826,
      "grad_norm": 0.1654568910598755,
      "learning_rate": 0.0004936585505777231,
      "loss": 1.424,
      "step": 5030
    },
    {
      "epoch": 16.206119162640903,
      "grad_norm": 0.18851745128631592,
      "learning_rate": 0.0004936298814615028,
      "loss": 1.408,
      "step": 5040
    },
    {
      "epoch": 16.238325281803544,
      "grad_norm": 0.1835298389196396,
      "learning_rate": 0.0004936011485223846,
      "loss": 1.4238,
      "step": 5050
    },
    {
      "epoch": 16.270531400966185,
      "grad_norm": 0.182979553937912,
      "learning_rate": 0.0004935723517678952,
      "loss": 1.4027,
      "step": 5060
    },
    {
      "epoch": 16.302737520128826,
      "grad_norm": 0.1925043910741806,
      "learning_rate": 0.0004935434912055784,
      "loss": 1.4394,
      "step": 5070
    },
    {
      "epoch": 16.334943639291467,
      "grad_norm": 0.18652866780757904,
      "learning_rate": 0.0004935145668429948,
      "loss": 1.4322,
      "step": 5080
    },
    {
      "epoch": 16.367149758454108,
      "grad_norm": 0.202348530292511,
      "learning_rate": 0.0004934855786877215,
      "loss": 1.4316,
      "step": 5090
    },
    {
      "epoch": 16.39935587761675,
      "grad_norm": 0.1802470088005066,
      "learning_rate": 0.0004934565267473527,
      "loss": 1.4201,
      "step": 5100
    },
    {
      "epoch": 16.431561996779386,
      "grad_norm": 0.19626709818840027,
      "learning_rate": 0.0004934274110294987,
      "loss": 1.4243,
      "step": 5110
    },
    {
      "epoch": 16.463768115942027,
      "grad_norm": 0.19132262468338013,
      "learning_rate": 0.0004933982315417871,
      "loss": 1.4082,
      "step": 5120
    },
    {
      "epoch": 16.49597423510467,
      "grad_norm": 0.174720898270607,
      "learning_rate": 0.0004933689882918618,
      "loss": 1.4283,
      "step": 5130
    },
    {
      "epoch": 16.52818035426731,
      "grad_norm": 0.20027123391628265,
      "learning_rate": 0.0004933396812873836,
      "loss": 1.4293,
      "step": 5140
    },
    {
      "epoch": 16.56038647342995,
      "grad_norm": 0.18918843567371368,
      "learning_rate": 0.0004933103105360299,
      "loss": 1.4133,
      "step": 5150
    },
    {
      "epoch": 16.59259259259259,
      "grad_norm": 0.18663959205150604,
      "learning_rate": 0.0004932808760454951,
      "loss": 1.4347,
      "step": 5160
    },
    {
      "epoch": 16.624798711755233,
      "grad_norm": 0.17566171288490295,
      "learning_rate": 0.0004932513778234897,
      "loss": 1.4152,
      "step": 5170
    },
    {
      "epoch": 16.657004830917874,
      "grad_norm": 0.1599319726228714,
      "learning_rate": 0.0004932218158777415,
      "loss": 1.4145,
      "step": 5180
    },
    {
      "epoch": 16.689210950080515,
      "grad_norm": 0.16356240212917328,
      "learning_rate": 0.0004931921902159946,
      "loss": 1.4166,
      "step": 5190
    },
    {
      "epoch": 16.721417069243156,
      "grad_norm": 0.1888025850057602,
      "learning_rate": 0.0004931625008460101,
      "loss": 1.4183,
      "step": 5200
    },
    {
      "epoch": 16.753623188405797,
      "grad_norm": 0.19924023747444153,
      "learning_rate": 0.0004931327477755654,
      "loss": 1.4169,
      "step": 5210
    },
    {
      "epoch": 16.785829307568438,
      "grad_norm": 0.19463402032852173,
      "learning_rate": 0.0004931029310124551,
      "loss": 1.4224,
      "step": 5220
    },
    {
      "epoch": 16.81803542673108,
      "grad_norm": 0.19884228706359863,
      "learning_rate": 0.0004930730505644899,
      "loss": 1.4376,
      "step": 5230
    },
    {
      "epoch": 16.85024154589372,
      "grad_norm": 0.18868635594844818,
      "learning_rate": 0.0004930431064394977,
      "loss": 1.4231,
      "step": 5240
    },
    {
      "epoch": 16.88244766505636,
      "grad_norm": 0.1682758629322052,
      "learning_rate": 0.0004930130986453227,
      "loss": 1.4355,
      "step": 5250
    },
    {
      "epoch": 16.914653784219002,
      "grad_norm": 0.18814854323863983,
      "learning_rate": 0.000492983027189826,
      "loss": 1.4387,
      "step": 5260
    },
    {
      "epoch": 16.946859903381643,
      "grad_norm": 0.185961052775383,
      "learning_rate": 0.0004929528920808855,
      "loss": 1.4274,
      "step": 5270
    },
    {
      "epoch": 16.979066022544284,
      "grad_norm": 0.1884402334690094,
      "learning_rate": 0.0004929226933263952,
      "loss": 1.4296,
      "step": 5280
    },
    {
      "epoch": 17.0,
      "eval_loss": 0.6508471965789795,
      "eval_runtime": 7.1637,
      "eval_samples_per_second": 3392.519,
      "eval_steps_per_second": 13.261,
      "step": 5287
    },
    {
      "epoch": 17.00966183574879,
      "grad_norm": 0.17900733649730682,
      "learning_rate": 0.0004928924309342666,
      "loss": 1.341,
      "step": 5290
    },
    {
      "epoch": 17.04186795491143,
      "grad_norm": 0.190139502286911,
      "learning_rate": 0.0004928621049124271,
      "loss": 1.4032,
      "step": 5300
    },
    {
      "epoch": 17.074074074074073,
      "grad_norm": 0.21870453655719757,
      "learning_rate": 0.0004928317152688212,
      "loss": 1.4195,
      "step": 5310
    },
    {
      "epoch": 17.106280193236714,
      "grad_norm": 0.15782351791858673,
      "learning_rate": 0.0004928012620114101,
      "loss": 1.4207,
      "step": 5320
    },
    {
      "epoch": 17.138486312399355,
      "grad_norm": 0.1793002188205719,
      "learning_rate": 0.0004927707451481715,
      "loss": 1.4192,
      "step": 5330
    },
    {
      "epoch": 17.170692431561996,
      "grad_norm": 0.1959090679883957,
      "learning_rate": 0.0004927401646870995,
      "loss": 1.4018,
      "step": 5340
    },
    {
      "epoch": 17.202898550724637,
      "grad_norm": 0.17806442081928253,
      "learning_rate": 0.0004927095206362056,
      "loss": 1.3986,
      "step": 5350
    },
    {
      "epoch": 17.235104669887278,
      "grad_norm": 0.2003398835659027,
      "learning_rate": 0.0004926788130035173,
      "loss": 1.4345,
      "step": 5360
    },
    {
      "epoch": 17.26731078904992,
      "grad_norm": 0.2122197151184082,
      "learning_rate": 0.000492648041797079,
      "loss": 1.4208,
      "step": 5370
    },
    {
      "epoch": 17.29951690821256,
      "grad_norm": 0.18430553376674652,
      "learning_rate": 0.0004926172070249518,
      "loss": 1.4027,
      "step": 5380
    },
    {
      "epoch": 17.3317230273752,
      "grad_norm": 0.15001337230205536,
      "learning_rate": 0.0004925863086952131,
      "loss": 1.4098,
      "step": 5390
    },
    {
      "epoch": 17.363929146537842,
      "grad_norm": 0.2012341022491455,
      "learning_rate": 0.0004925553468159576,
      "loss": 1.4308,
      "step": 5400
    },
    {
      "epoch": 17.396135265700483,
      "grad_norm": 0.19388575851917267,
      "learning_rate": 0.0004925243213952962,
      "loss": 1.4384,
      "step": 5410
    },
    {
      "epoch": 17.428341384863124,
      "grad_norm": 0.15555259585380554,
      "learning_rate": 0.0004924932324413562,
      "loss": 1.4039,
      "step": 5420
    },
    {
      "epoch": 17.460547504025765,
      "grad_norm": 0.1687229871749878,
      "learning_rate": 0.0004924620799622822,
      "loss": 1.4271,
      "step": 5430
    },
    {
      "epoch": 17.492753623188406,
      "grad_norm": 0.16860046982765198,
      "learning_rate": 0.0004924308639662351,
      "loss": 1.4396,
      "step": 5440
    },
    {
      "epoch": 17.524959742351047,
      "grad_norm": 0.16435463726520538,
      "learning_rate": 0.0004923995844613923,
      "loss": 1.4164,
      "step": 5450
    },
    {
      "epoch": 17.55716586151369,
      "grad_norm": 0.20286057889461517,
      "learning_rate": 0.0004923682414559481,
      "loss": 1.4129,
      "step": 5460
    },
    {
      "epoch": 17.58937198067633,
      "grad_norm": 0.16431307792663574,
      "learning_rate": 0.0004923368349581133,
      "loss": 1.4351,
      "step": 5470
    },
    {
      "epoch": 17.62157809983897,
      "grad_norm": 0.2641974985599518,
      "learning_rate": 0.0004923053649761153,
      "loss": 1.4184,
      "step": 5480
    },
    {
      "epoch": 17.65378421900161,
      "grad_norm": 0.18364174664020538,
      "learning_rate": 0.0004922738315181981,
      "loss": 1.4174,
      "step": 5490
    },
    {
      "epoch": 17.685990338164252,
      "grad_norm": 0.19025832414627075,
      "learning_rate": 0.0004922422345926227,
      "loss": 1.4199,
      "step": 5500
    },
    {
      "epoch": 17.718196457326894,
      "grad_norm": 0.1930478811264038,
      "learning_rate": 0.0004922105742076662,
      "loss": 1.4494,
      "step": 5510
    },
    {
      "epoch": 17.750402576489535,
      "grad_norm": 0.18418174982070923,
      "learning_rate": 0.0004921788503716226,
      "loss": 1.4221,
      "step": 5520
    },
    {
      "epoch": 17.782608695652176,
      "grad_norm": 0.1741497963666916,
      "learning_rate": 0.0004921470630928026,
      "loss": 1.4292,
      "step": 5530
    },
    {
      "epoch": 17.814814814814813,
      "grad_norm": 0.18094073235988617,
      "learning_rate": 0.0004921152123795333,
      "loss": 1.4155,
      "step": 5540
    },
    {
      "epoch": 17.847020933977454,
      "grad_norm": 0.1588863730430603,
      "learning_rate": 0.0004920832982401585,
      "loss": 1.4048,
      "step": 5550
    },
    {
      "epoch": 17.879227053140095,
      "grad_norm": 0.2774152159690857,
      "learning_rate": 0.0004920513206830388,
      "loss": 1.4374,
      "step": 5560
    },
    {
      "epoch": 17.911433172302736,
      "grad_norm": 0.17652027308940887,
      "learning_rate": 0.000492019279716551,
      "loss": 1.4284,
      "step": 5570
    },
    {
      "epoch": 17.943639291465377,
      "grad_norm": 0.20700104534626007,
      "learning_rate": 0.0004919871753490891,
      "loss": 1.4163,
      "step": 5580
    },
    {
      "epoch": 17.97584541062802,
      "grad_norm": 0.16963933408260345,
      "learning_rate": 0.000491955007589063,
      "loss": 1.4251,
      "step": 5590
    },
    {
      "epoch": 18.0,
      "eval_loss": 0.6490796804428101,
      "eval_runtime": 7.0813,
      "eval_samples_per_second": 3432.008,
      "eval_steps_per_second": 13.416,
      "step": 5598
    },
    {
      "epoch": 18.006441223832528,
      "grad_norm": 0.15834370255470276,
      "learning_rate": 0.0004919227764448999,
      "loss": 1.3515,
      "step": 5600
    },
    {
      "epoch": 18.03864734299517,
      "grad_norm": 0.19313588738441467,
      "learning_rate": 0.0004918904819250431,
      "loss": 1.428,
      "step": 5610
    },
    {
      "epoch": 18.07085346215781,
      "grad_norm": 0.18294398486614227,
      "learning_rate": 0.0004918581240379526,
      "loss": 1.4257,
      "step": 5620
    },
    {
      "epoch": 18.10305958132045,
      "grad_norm": 0.1754705160856247,
      "learning_rate": 0.0004918257027921053,
      "loss": 1.4365,
      "step": 5630
    },
    {
      "epoch": 18.135265700483092,
      "grad_norm": 0.19666758179664612,
      "learning_rate": 0.0004917932181959945,
      "loss": 1.4063,
      "step": 5640
    },
    {
      "epoch": 18.167471819645733,
      "grad_norm": 0.17984932661056519,
      "learning_rate": 0.00049176067025813,
      "loss": 1.4266,
      "step": 5650
    },
    {
      "epoch": 18.199677938808374,
      "grad_norm": 0.1749015748500824,
      "learning_rate": 0.0004917280589870381,
      "loss": 1.4174,
      "step": 5660
    },
    {
      "epoch": 18.231884057971016,
      "grad_norm": 0.16963188350200653,
      "learning_rate": 0.0004916953843912621,
      "loss": 1.413,
      "step": 5670
    },
    {
      "epoch": 18.264090177133657,
      "grad_norm": 0.18412694334983826,
      "learning_rate": 0.0004916626464793615,
      "loss": 1.4111,
      "step": 5680
    },
    {
      "epoch": 18.296296296296298,
      "grad_norm": 0.19946014881134033,
      "learning_rate": 0.0004916298452599127,
      "loss": 1.394,
      "step": 5690
    },
    {
      "epoch": 18.32850241545894,
      "grad_norm": 0.19216863811016083,
      "learning_rate": 0.0004915969807415085,
      "loss": 1.4131,
      "step": 5700
    },
    {
      "epoch": 18.36070853462158,
      "grad_norm": 0.16222521662712097,
      "learning_rate": 0.0004915640529327581,
      "loss": 1.3998,
      "step": 5710
    },
    {
      "epoch": 18.39291465378422,
      "grad_norm": 0.18441472947597504,
      "learning_rate": 0.0004915310618422877,
      "loss": 1.4141,
      "step": 5720
    },
    {
      "epoch": 18.42512077294686,
      "grad_norm": 0.19861438870429993,
      "learning_rate": 0.0004914980074787398,
      "loss": 1.4204,
      "step": 5730
    },
    {
      "epoch": 18.4573268921095,
      "grad_norm": 0.19458799064159393,
      "learning_rate": 0.0004914648898507735,
      "loss": 1.4183,
      "step": 5740
    },
    {
      "epoch": 18.48953301127214,
      "grad_norm": 0.2030230164527893,
      "learning_rate": 0.0004914317089670646,
      "loss": 1.443,
      "step": 5750
    },
    {
      "epoch": 18.52173913043478,
      "grad_norm": 0.17123831808567047,
      "learning_rate": 0.0004913984648363053,
      "loss": 1.4105,
      "step": 5760
    },
    {
      "epoch": 18.553945249597422,
      "grad_norm": 0.18425090610980988,
      "learning_rate": 0.0004913651574672044,
      "loss": 1.414,
      "step": 5770
    },
    {
      "epoch": 18.586151368760063,
      "grad_norm": 0.18651731312274933,
      "learning_rate": 0.0004913317868684876,
      "loss": 1.4318,
      "step": 5780
    },
    {
      "epoch": 18.618357487922705,
      "grad_norm": 0.2011377513408661,
      "learning_rate": 0.0004912983530488966,
      "loss": 1.4129,
      "step": 5790
    },
    {
      "epoch": 18.650563607085346,
      "grad_norm": 0.1973154991865158,
      "learning_rate": 0.00049126485601719,
      "loss": 1.4063,
      "step": 5800
    },
    {
      "epoch": 18.682769726247987,
      "grad_norm": 0.16968196630477905,
      "learning_rate": 0.000491231295782143,
      "loss": 1.4147,
      "step": 5810
    },
    {
      "epoch": 18.714975845410628,
      "grad_norm": 0.21768195927143097,
      "learning_rate": 0.0004911976723525472,
      "loss": 1.4128,
      "step": 5820
    },
    {
      "epoch": 18.74718196457327,
      "grad_norm": 0.19151516258716583,
      "learning_rate": 0.0004911639857372108,
      "loss": 1.4198,
      "step": 5830
    },
    {
      "epoch": 18.77938808373591,
      "grad_norm": 0.18843814730644226,
      "learning_rate": 0.0004911302359449586,
      "loss": 1.43,
      "step": 5840
    },
    {
      "epoch": 18.81159420289855,
      "grad_norm": 0.17039386928081512,
      "learning_rate": 0.0004910964229846319,
      "loss": 1.3903,
      "step": 5850
    },
    {
      "epoch": 18.843800322061192,
      "grad_norm": 0.18546165525913239,
      "learning_rate": 0.0004910625468650885,
      "loss": 1.4499,
      "step": 5860
    },
    {
      "epoch": 18.876006441223833,
      "grad_norm": 0.2527492642402649,
      "learning_rate": 0.000491028607595203,
      "loss": 1.4384,
      "step": 5870
    },
    {
      "epoch": 18.908212560386474,
      "grad_norm": 0.17942345142364502,
      "learning_rate": 0.000490994605183866,
      "loss": 1.4142,
      "step": 5880
    },
    {
      "epoch": 18.940418679549115,
      "grad_norm": 0.21375495195388794,
      "learning_rate": 0.0004909605396399855,
      "loss": 1.4326,
      "step": 5890
    },
    {
      "epoch": 18.972624798711756,
      "grad_norm": 0.19486087560653687,
      "learning_rate": 0.0004909264109724852,
      "loss": 1.4117,
      "step": 5900
    },
    {
      "epoch": 19.0,
      "eval_loss": 0.652837872505188,
      "eval_runtime": 7.1398,
      "eval_samples_per_second": 3403.874,
      "eval_steps_per_second": 13.306,
      "step": 5909
    },
    {
      "epoch": 19.003220611916262,
      "grad_norm": 0.20044556260108948,
      "learning_rate": 0.0004908922191903058,
      "loss": 1.351,
      "step": 5910
    },
    {
      "epoch": 19.035426731078903,
      "grad_norm": 0.22611935436725616,
      "learning_rate": 0.0004908579643024042,
      "loss": 1.4221,
      "step": 5920
    },
    {
      "epoch": 19.067632850241544,
      "grad_norm": 0.17687278985977173,
      "learning_rate": 0.0004908236463177543,
      "loss": 1.4055,
      "step": 5930
    },
    {
      "epoch": 19.099838969404185,
      "grad_norm": 0.18968816101551056,
      "learning_rate": 0.0004907892652453461,
      "loss": 1.4147,
      "step": 5940
    },
    {
      "epoch": 19.132045088566827,
      "grad_norm": 0.18859443068504333,
      "learning_rate": 0.0004907548210941865,
      "loss": 1.4239,
      "step": 5950
    },
    {
      "epoch": 19.164251207729468,
      "grad_norm": 0.18915969133377075,
      "learning_rate": 0.0004907203138732984,
      "loss": 1.4437,
      "step": 5960
    },
    {
      "epoch": 19.19645732689211,
      "grad_norm": 0.238846555352211,
      "learning_rate": 0.0004906857435917218,
      "loss": 1.4275,
      "step": 5970
    },
    {
      "epoch": 19.22866344605475,
      "grad_norm": 0.20255815982818604,
      "learning_rate": 0.0004906511102585129,
      "loss": 1.4144,
      "step": 5980
    },
    {
      "epoch": 19.26086956521739,
      "grad_norm": 0.2213265597820282,
      "learning_rate": 0.0004906164138827444,
      "loss": 1.4033,
      "step": 5990
    },
    {
      "epoch": 19.29307568438003,
      "grad_norm": 0.3290081024169922,
      "learning_rate": 0.0004905816544735056,
      "loss": 1.4041,
      "step": 6000
    },
    {
      "epoch": 19.325281803542673,
      "grad_norm": 0.20661894977092743,
      "learning_rate": 0.0004905468320399023,
      "loss": 1.4114,
      "step": 6010
    },
    {
      "epoch": 19.357487922705314,
      "grad_norm": 0.20985838770866394,
      "learning_rate": 0.000490511946591057,
      "loss": 1.4188,
      "step": 6020
    },
    {
      "epoch": 19.389694041867955,
      "grad_norm": 0.18608874082565308,
      "learning_rate": 0.0004904769981361083,
      "loss": 1.4193,
      "step": 6030
    },
    {
      "epoch": 19.421900161030596,
      "grad_norm": 0.1988030970096588,
      "learning_rate": 0.0004904419866842115,
      "loss": 1.406,
      "step": 6040
    },
    {
      "epoch": 19.454106280193237,
      "grad_norm": 0.20984096825122833,
      "learning_rate": 0.0004904069122445387,
      "loss": 1.4239,
      "step": 6050
    },
    {
      "epoch": 19.486312399355878,
      "grad_norm": 0.19718016684055328,
      "learning_rate": 0.0004903717748262781,
      "loss": 1.4451,
      "step": 6060
    },
    {
      "epoch": 19.51851851851852,
      "grad_norm": 0.18074931204319,
      "learning_rate": 0.0004903365744386344,
      "loss": 1.4092,
      "step": 6070
    },
    {
      "epoch": 19.55072463768116,
      "grad_norm": 0.18589696288108826,
      "learning_rate": 0.000490301311090829,
      "loss": 1.4027,
      "step": 6080
    },
    {
      "epoch": 19.5829307568438,
      "grad_norm": 0.1760825514793396,
      "learning_rate": 0.0004902659847920999,
      "loss": 1.4025,
      "step": 6090
    },
    {
      "epoch": 19.615136876006442,
      "grad_norm": 0.20398825407028198,
      "learning_rate": 0.0004902305955517011,
      "loss": 1.4272,
      "step": 6100
    },
    {
      "epoch": 19.647342995169083,
      "grad_norm": 0.19172656536102295,
      "learning_rate": 0.0004901951433789037,
      "loss": 1.4423,
      "step": 6110
    },
    {
      "epoch": 19.679549114331724,
      "grad_norm": 0.18901963531970978,
      "learning_rate": 0.0004901596282829949,
      "loss": 1.3946,
      "step": 6120
    },
    {
      "epoch": 19.711755233494365,
      "grad_norm": 0.2136085331439972,
      "learning_rate": 0.0004901240502732783,
      "loss": 1.404,
      "step": 6130
    },
    {
      "epoch": 19.743961352657006,
      "grad_norm": 0.23219150304794312,
      "learning_rate": 0.0004900884093590743,
      "loss": 1.4153,
      "step": 6140
    },
    {
      "epoch": 19.776167471819647,
      "grad_norm": 0.18484041094779968,
      "learning_rate": 0.0004900527055497196,
      "loss": 1.4054,
      "step": 6150
    },
    {
      "epoch": 19.808373590982285,
      "grad_norm": 0.18174627423286438,
      "learning_rate": 0.0004900169388545674,
      "loss": 1.4013,
      "step": 6160
    },
    {
      "epoch": 19.840579710144926,
      "grad_norm": 0.2045024186372757,
      "learning_rate": 0.0004899811092829873,
      "loss": 1.4236,
      "step": 6170
    },
    {
      "epoch": 19.872785829307567,
      "grad_norm": 0.22765211760997772,
      "learning_rate": 0.0004899452168443657,
      "loss": 1.4184,
      "step": 6180
    },
    {
      "epoch": 19.904991948470208,
      "grad_norm": 0.20425817370414734,
      "learning_rate": 0.000489909261548105,
      "loss": 1.4203,
      "step": 6190
    },
    {
      "epoch": 19.93719806763285,
      "grad_norm": 0.22300755977630615,
      "learning_rate": 0.0004898732434036243,
      "loss": 1.3927,
      "step": 6200
    },
    {
      "epoch": 19.96940418679549,
      "grad_norm": 0.47608134150505066,
      "learning_rate": 0.0004898371624203593,
      "loss": 1.4602,
      "step": 6210
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.22007597982883453,
      "learning_rate": 0.0004898010186077619,
      "loss": 1.3718,
      "step": 6220
    },
    {
      "epoch": 20.0,
      "eval_loss": 0.6562965512275696,
      "eval_runtime": 7.0999,
      "eval_samples_per_second": 3422.984,
      "eval_steps_per_second": 13.38,
      "step": 6220
    },
    {
      "epoch": 20.03220611916264,
      "grad_norm": 0.23428015410900116,
      "learning_rate": 0.0004897648119753005,
      "loss": 1.4028,
      "step": 6230
    },
    {
      "epoch": 20.064412238325282,
      "grad_norm": 0.24895615875720978,
      "learning_rate": 0.0004897285425324603,
      "loss": 1.4196,
      "step": 6240
    },
    {
      "epoch": 20.096618357487923,
      "grad_norm": 0.23907339572906494,
      "learning_rate": 0.0004896922102887423,
      "loss": 1.3809,
      "step": 6250
    },
    {
      "epoch": 20.128824476650564,
      "grad_norm": 0.3002638816833496,
      "learning_rate": 0.0004896558152536646,
      "loss": 1.4339,
      "step": 6260
    },
    {
      "epoch": 20.161030595813205,
      "grad_norm": 0.25953957438468933,
      "learning_rate": 0.0004896193574367615,
      "loss": 1.4394,
      "step": 6270
    },
    {
      "epoch": 20.193236714975846,
      "grad_norm": 0.194738507270813,
      "learning_rate": 0.0004895828368475835,
      "loss": 1.4202,
      "step": 6280
    },
    {
      "epoch": 20.225442834138487,
      "grad_norm": 0.2559700906276703,
      "learning_rate": 0.0004895462534956981,
      "loss": 1.4121,
      "step": 6290
    },
    {
      "epoch": 20.25764895330113,
      "grad_norm": 0.25093525648117065,
      "learning_rate": 0.0004895096073906886,
      "loss": 1.4397,
      "step": 6300
    },
    {
      "epoch": 20.28985507246377,
      "grad_norm": 0.19980160892009735,
      "learning_rate": 0.0004894728985421553,
      "loss": 1.4302,
      "step": 6310
    },
    {
      "epoch": 20.32206119162641,
      "grad_norm": 0.19593451917171478,
      "learning_rate": 0.0004894361269597145,
      "loss": 1.4171,
      "step": 6320
    },
    {
      "epoch": 20.35426731078905,
      "grad_norm": 0.21181192994117737,
      "learning_rate": 0.0004893992926529992,
      "loss": 1.3942,
      "step": 6330
    },
    {
      "epoch": 20.386473429951693,
      "grad_norm": 0.23813895881175995,
      "learning_rate": 0.0004893623956316589,
      "loss": 1.407,
      "step": 6340
    },
    {
      "epoch": 20.41867954911433,
      "grad_norm": 0.2533395290374756,
      "learning_rate": 0.0004893254359053592,
      "loss": 1.401,
      "step": 6350
    },
    {
      "epoch": 20.45088566827697,
      "grad_norm": 0.22957868874073029,
      "learning_rate": 0.0004892884134837824,
      "loss": 1.4062,
      "step": 6360
    },
    {
      "epoch": 20.483091787439612,
      "grad_norm": 0.20703479647636414,
      "learning_rate": 0.0004892513283766272,
      "loss": 1.4303,
      "step": 6370
    },
    {
      "epoch": 20.515297906602253,
      "grad_norm": 0.2149421125650406,
      "learning_rate": 0.0004892141805936084,
      "loss": 1.4128,
      "step": 6380
    },
    {
      "epoch": 20.547504025764894,
      "grad_norm": 0.23253385722637177,
      "learning_rate": 0.0004891769701444578,
      "loss": 1.4116,
      "step": 6390
    },
    {
      "epoch": 20.579710144927535,
      "grad_norm": 0.24006518721580505,
      "learning_rate": 0.0004891396970389232,
      "loss": 1.3907,
      "step": 6400
    },
    {
      "epoch": 20.611916264090176,
      "grad_norm": 0.17954763770103455,
      "learning_rate": 0.0004891023612867688,
      "loss": 1.419,
      "step": 6410
    },
    {
      "epoch": 20.644122383252817,
      "grad_norm": 0.20189595222473145,
      "learning_rate": 0.0004890649628977754,
      "loss": 1.4157,
      "step": 6420
    },
    {
      "epoch": 20.67632850241546,
      "grad_norm": 0.2168179601430893,
      "learning_rate": 0.00048902750188174,
      "loss": 1.4247,
      "step": 6430
    },
    {
      "epoch": 20.7085346215781,
      "grad_norm": 0.2570275664329529,
      "learning_rate": 0.0004889899782484765,
      "loss": 1.4027,
      "step": 6440
    },
    {
      "epoch": 20.74074074074074,
      "grad_norm": 0.29570069909095764,
      "learning_rate": 0.0004889523920078144,
      "loss": 1.4244,
      "step": 6450
    },
    {
      "epoch": 20.77294685990338,
      "grad_norm": 0.26084911823272705,
      "learning_rate": 0.0004889147431696003,
      "loss": 1.4285,
      "step": 6460
    },
    {
      "epoch": 20.805152979066023,
      "grad_norm": 0.18350239098072052,
      "learning_rate": 0.000488877031743697,
      "loss": 1.4364,
      "step": 6470
    },
    {
      "epoch": 20.837359098228664,
      "grad_norm": 0.21531465649604797,
      "learning_rate": 0.0004888392577399832,
      "loss": 1.4397,
      "step": 6480
    },
    {
      "epoch": 20.869565217391305,
      "grad_norm": 0.19726167619228363,
      "learning_rate": 0.0004888014211683549,
      "loss": 1.4319,
      "step": 6490
    },
    {
      "epoch": 20.901771336553946,
      "grad_norm": 0.20377814769744873,
      "learning_rate": 0.000488763522038724,
      "loss": 1.413,
      "step": 6500
    },
    {
      "epoch": 20.933977455716587,
      "grad_norm": 0.19862000644207,
      "learning_rate": 0.0004887255603610184,
      "loss": 1.4107,
      "step": 6510
    },
    {
      "epoch": 20.966183574879228,
      "grad_norm": 0.22505991160869598,
      "learning_rate": 0.0004886875361451833,
      "loss": 1.4299,
      "step": 6520
    },
    {
      "epoch": 20.99838969404187,
      "grad_norm": 0.22990164160728455,
      "learning_rate": 0.0004886494494011794,
      "loss": 1.4054,
      "step": 6530
    },
    {
      "epoch": 21.0,
      "eval_loss": 0.649522602558136,
      "eval_runtime": 7.1592,
      "eval_samples_per_second": 3394.641,
      "eval_steps_per_second": 13.27,
      "step": 6531
    },
    {
      "epoch": 21.028985507246375,
      "grad_norm": 0.20404276251792908,
      "learning_rate": 0.0004886113001389843,
      "loss": 1.3385,
      "step": 6540
    },
    {
      "epoch": 21.061191626409016,
      "grad_norm": 0.2036890834569931,
      "learning_rate": 0.0004885730883685918,
      "loss": 1.4116,
      "step": 6550
    },
    {
      "epoch": 21.093397745571657,
      "grad_norm": 0.19653227925300598,
      "learning_rate": 0.0004885348141000122,
      "loss": 1.4009,
      "step": 6560
    },
    {
      "epoch": 21.1256038647343,
      "grad_norm": 0.23174624145030975,
      "learning_rate": 0.0004884964773432719,
      "loss": 1.4149,
      "step": 6570
    },
    {
      "epoch": 21.15780998389694,
      "grad_norm": 0.2137216478586197,
      "learning_rate": 0.0004884580781084142,
      "loss": 1.4065,
      "step": 6580
    },
    {
      "epoch": 21.19001610305958,
      "grad_norm": 0.22490963339805603,
      "learning_rate": 0.000488419616405498,
      "loss": 1.4118,
      "step": 6590
    },
    {
      "epoch": 21.22222222222222,
      "grad_norm": 0.222395658493042,
      "learning_rate": 0.0004883810922445992,
      "loss": 1.4273,
      "step": 6600
    },
    {
      "epoch": 21.254428341384862,
      "grad_norm": 0.2837151885032654,
      "learning_rate": 0.0004883425056358097,
      "loss": 1.4253,
      "step": 6610
    },
    {
      "epoch": 21.286634460547504,
      "grad_norm": 0.208881676197052,
      "learning_rate": 0.0004883038565892382,
      "loss": 1.4239,
      "step": 6620
    },
    {
      "epoch": 21.318840579710145,
      "grad_norm": 0.20930960774421692,
      "learning_rate": 0.0004882651451150091,
      "loss": 1.3972,
      "step": 6630
    },
    {
      "epoch": 21.351046698872786,
      "grad_norm": 0.24064840376377106,
      "learning_rate": 0.00048822637122326374,
      "loss": 1.3964,
      "step": 6640
    },
    {
      "epoch": 21.383252818035427,
      "grad_norm": 0.22678808867931366,
      "learning_rate": 0.00048818753492415955,
      "loss": 1.4095,
      "step": 6650
    },
    {
      "epoch": 21.415458937198068,
      "grad_norm": 0.23118679225444794,
      "learning_rate": 0.0004881486362278703,
      "loss": 1.4264,
      "step": 6660
    },
    {
      "epoch": 21.44766505636071,
      "grad_norm": 0.19632741808891296,
      "learning_rate": 0.00048810967514458626,
      "loss": 1.4109,
      "step": 6670
    },
    {
      "epoch": 21.47987117552335,
      "grad_norm": 0.19025450944900513,
      "learning_rate": 0.0004880706516845138,
      "loss": 1.4216,
      "step": 6680
    },
    {
      "epoch": 21.51207729468599,
      "grad_norm": 0.19348309934139252,
      "learning_rate": 0.0004880315658578758,
      "loss": 1.4087,
      "step": 6690
    },
    {
      "epoch": 21.544283413848632,
      "grad_norm": 0.221424862742424,
      "learning_rate": 0.00048799241767491145,
      "loss": 1.4257,
      "step": 6700
    },
    {
      "epoch": 21.576489533011273,
      "grad_norm": 0.1756201982498169,
      "learning_rate": 0.00048795320714587625,
      "loss": 1.4315,
      "step": 6710
    },
    {
      "epoch": 21.608695652173914,
      "grad_norm": 0.19049449265003204,
      "learning_rate": 0.00048791393428104215,
      "loss": 1.4011,
      "step": 6720
    },
    {
      "epoch": 21.640901771336555,
      "grad_norm": 0.2122824341058731,
      "learning_rate": 0.0004878745990906972,
      "loss": 1.4289,
      "step": 6730
    },
    {
      "epoch": 21.673107890499196,
      "grad_norm": 0.20906904339790344,
      "learning_rate": 0.0004878352015851459,
      "loss": 1.4176,
      "step": 6740
    },
    {
      "epoch": 21.705314009661837,
      "grad_norm": 0.22285684943199158,
      "learning_rate": 0.00048779574177470927,
      "loss": 1.4063,
      "step": 6750
    },
    {
      "epoch": 21.737520128824478,
      "grad_norm": 0.24175047874450684,
      "learning_rate": 0.0004877562196697243,
      "loss": 1.4011,
      "step": 6760
    },
    {
      "epoch": 21.76972624798712,
      "grad_norm": 0.24222473800182343,
      "learning_rate": 0.00048771663528054444,
      "loss": 1.427,
      "step": 6770
    },
    {
      "epoch": 21.80193236714976,
      "grad_norm": 0.2256341129541397,
      "learning_rate": 0.00048767698861753954,
      "loss": 1.4096,
      "step": 6780
    },
    {
      "epoch": 21.834138486312398,
      "grad_norm": 0.19200997054576874,
      "learning_rate": 0.0004876372796910957,
      "loss": 1.4176,
      "step": 6790
    },
    {
      "epoch": 21.86634460547504,
      "grad_norm": 0.2233651727437973,
      "learning_rate": 0.00048759750851161545,
      "loss": 1.4066,
      "step": 6800
    },
    {
      "epoch": 21.89855072463768,
      "grad_norm": 0.19368503987789154,
      "learning_rate": 0.00048755767508951734,
      "loss": 1.4079,
      "step": 6810
    },
    {
      "epoch": 21.93075684380032,
      "grad_norm": 0.20397379994392395,
      "learning_rate": 0.0004875177794352363,
      "loss": 1.4167,
      "step": 6820
    },
    {
      "epoch": 21.962962962962962,
      "grad_norm": 0.2201479822397232,
      "learning_rate": 0.00048747782155922397,
      "loss": 1.3992,
      "step": 6830
    },
    {
      "epoch": 21.995169082125603,
      "grad_norm": 0.20404671132564545,
      "learning_rate": 0.00048743780147194785,
      "loss": 1.4122,
      "step": 6840
    },
    {
      "epoch": 22.0,
      "eval_loss": 0.6466196179389954,
      "eval_runtime": 7.2776,
      "eval_samples_per_second": 3339.445,
      "eval_steps_per_second": 13.054,
      "step": 6842
    },
    {
      "epoch": 22.025764895330113,
      "grad_norm": 0.18881095945835114,
      "learning_rate": 0.00048739771918389173,
      "loss": 1.3266,
      "step": 6850
    },
    {
      "epoch": 22.057971014492754,
      "grad_norm": 0.22981677949428558,
      "learning_rate": 0.000487357574705556,
      "loss": 1.4353,
      "step": 6860
    },
    {
      "epoch": 22.090177133655395,
      "grad_norm": 0.20258042216300964,
      "learning_rate": 0.00048731736804745706,
      "loss": 1.4039,
      "step": 6870
    },
    {
      "epoch": 22.122383252818036,
      "grad_norm": 0.34557783603668213,
      "learning_rate": 0.0004872770992201278,
      "loss": 1.4068,
      "step": 6880
    },
    {
      "epoch": 22.154589371980677,
      "grad_norm": 0.23842975497245789,
      "learning_rate": 0.00048723676823411727,
      "loss": 1.4032,
      "step": 6890
    },
    {
      "epoch": 22.186795491143318,
      "grad_norm": 0.23029376566410065,
      "learning_rate": 0.0004871963750999908,
      "loss": 1.4118,
      "step": 6900
    },
    {
      "epoch": 22.21900161030596,
      "grad_norm": 0.24403952062129974,
      "learning_rate": 0.00048715591982833017,
      "loss": 1.4236,
      "step": 6910
    },
    {
      "epoch": 22.2512077294686,
      "grad_norm": 0.18599767982959747,
      "learning_rate": 0.00048711540242973324,
      "loss": 1.4244,
      "step": 6920
    },
    {
      "epoch": 22.28341384863124,
      "grad_norm": 0.21861091256141663,
      "learning_rate": 0.0004870748229148142,
      "loss": 1.4147,
      "step": 6930
    },
    {
      "epoch": 22.315619967793882,
      "grad_norm": 0.2452477663755417,
      "learning_rate": 0.0004870341812942035,
      "loss": 1.413,
      "step": 6940
    },
    {
      "epoch": 22.347826086956523,
      "grad_norm": 0.21154478192329407,
      "learning_rate": 0.00048699347757854796,
      "loss": 1.3971,
      "step": 6950
    },
    {
      "epoch": 22.380032206119164,
      "grad_norm": 0.2217128574848175,
      "learning_rate": 0.0004869527117785105,
      "loss": 1.4003,
      "step": 6960
    },
    {
      "epoch": 22.412238325281802,
      "grad_norm": 0.21749946475028992,
      "learning_rate": 0.0004869118839047705,
      "loss": 1.4032,
      "step": 6970
    },
    {
      "epoch": 22.444444444444443,
      "grad_norm": 0.20993807911872864,
      "learning_rate": 0.0004868709939680235,
      "loss": 1.4115,
      "step": 6980
    },
    {
      "epoch": 22.476650563607084,
      "grad_norm": 0.20255310833454132,
      "learning_rate": 0.00048683004197898116,
      "loss": 1.4095,
      "step": 6990
    },
    {
      "epoch": 22.508856682769725,
      "grad_norm": 0.2278473824262619,
      "learning_rate": 0.0004867890279483717,
      "loss": 1.408,
      "step": 7000
    },
    {
      "epoch": 22.541062801932366,
      "grad_norm": 0.20067766308784485,
      "learning_rate": 0.00048674795188693933,
      "loss": 1.4146,
      "step": 7010
    },
    {
      "epoch": 22.573268921095007,
      "grad_norm": 0.19908641278743744,
      "learning_rate": 0.0004867068138054447,
      "loss": 1.41,
      "step": 7020
    },
    {
      "epoch": 22.605475040257648,
      "grad_norm": 0.2209005355834961,
      "learning_rate": 0.0004866656137146645,
      "loss": 1.4157,
      "step": 7030
    },
    {
      "epoch": 22.63768115942029,
      "grad_norm": 0.20890647172927856,
      "learning_rate": 0.0004866243516253918,
      "loss": 1.4368,
      "step": 7040
    },
    {
      "epoch": 22.66988727858293,
      "grad_norm": 0.22147361934185028,
      "learning_rate": 0.000486583027548436,
      "loss": 1.4253,
      "step": 7050
    },
    {
      "epoch": 22.70209339774557,
      "grad_norm": 0.2652909755706787,
      "learning_rate": 0.0004865416414946225,
      "loss": 1.3976,
      "step": 7060
    },
    {
      "epoch": 22.734299516908212,
      "grad_norm": 0.18512780964374542,
      "learning_rate": 0.0004865001934747931,
      "loss": 1.4285,
      "step": 7070
    },
    {
      "epoch": 22.766505636070853,
      "grad_norm": 0.23187820613384247,
      "learning_rate": 0.00048645868349980585,
      "loss": 1.4093,
      "step": 7080
    },
    {
      "epoch": 22.798711755233494,
      "grad_norm": 0.21997547149658203,
      "learning_rate": 0.0004864171115805349,
      "loss": 1.4158,
      "step": 7090
    },
    {
      "epoch": 22.830917874396135,
      "grad_norm": 0.1996869444847107,
      "learning_rate": 0.0004863754777278708,
      "loss": 1.4088,
      "step": 7100
    },
    {
      "epoch": 22.863123993558776,
      "grad_norm": 0.19240032136440277,
      "learning_rate": 0.00048633378195272017,
      "loss": 1.3961,
      "step": 7110
    },
    {
      "epoch": 22.895330112721417,
      "grad_norm": 0.20396798849105835,
      "learning_rate": 0.00048629202426600596,
      "loss": 1.4096,
      "step": 7120
    },
    {
      "epoch": 22.92753623188406,
      "grad_norm": 0.18740436434745789,
      "learning_rate": 0.0004862502046786671,
      "loss": 1.4023,
      "step": 7130
    },
    {
      "epoch": 22.9597423510467,
      "grad_norm": 0.22572843730449677,
      "learning_rate": 0.0004862083232016592,
      "loss": 1.4094,
      "step": 7140
    },
    {
      "epoch": 22.99194847020934,
      "grad_norm": 0.2696857154369354,
      "learning_rate": 0.00048616637984595363,
      "loss": 1.4072,
      "step": 7150
    },
    {
      "epoch": 23.0,
      "eval_loss": 0.6490798592567444,
      "eval_runtime": 7.1247,
      "eval_samples_per_second": 3411.112,
      "eval_steps_per_second": 13.334,
      "step": 7153
    },
    {
      "epoch": 23.022544283413847,
      "grad_norm": 0.25594237446784973,
      "learning_rate": 0.00048612437462253823,
      "loss": 1.3309,
      "step": 7160
    },
    {
      "epoch": 23.054750402576488,
      "grad_norm": 0.2331198900938034,
      "learning_rate": 0.0004860823075424169,
      "loss": 1.3962,
      "step": 7170
    },
    {
      "epoch": 23.08695652173913,
      "grad_norm": 0.2196783721446991,
      "learning_rate": 0.0004860401786166099,
      "loss": 1.4041,
      "step": 7180
    },
    {
      "epoch": 23.11916264090177,
      "grad_norm": 0.21173419058322906,
      "learning_rate": 0.00048599798785615354,
      "loss": 1.4262,
      "step": 7190
    },
    {
      "epoch": 23.15136876006441,
      "grad_norm": 0.2039770483970642,
      "learning_rate": 0.0004859557352721004,
      "loss": 1.4038,
      "step": 7200
    },
    {
      "epoch": 23.183574879227052,
      "grad_norm": 0.2874465882778168,
      "learning_rate": 0.00048591342087551926,
      "loss": 1.4028,
      "step": 7210
    },
    {
      "epoch": 23.215780998389693,
      "grad_norm": 0.22064609825611115,
      "learning_rate": 0.0004858710446774951,
      "loss": 1.4114,
      "step": 7220
    },
    {
      "epoch": 23.247987117552334,
      "grad_norm": 0.1952279657125473,
      "learning_rate": 0.000485828606689129,
      "loss": 1.4205,
      "step": 7230
    },
    {
      "epoch": 23.280193236714975,
      "grad_norm": 0.22216548025608063,
      "learning_rate": 0.00048578610692153834,
      "loss": 1.4148,
      "step": 7240
    },
    {
      "epoch": 23.312399355877616,
      "grad_norm": 0.22223468124866486,
      "learning_rate": 0.0004857435453858566,
      "loss": 1.4208,
      "step": 7250
    },
    {
      "epoch": 23.344605475040257,
      "grad_norm": 0.23117919266223907,
      "learning_rate": 0.00048570092209323357,
      "loss": 1.4313,
      "step": 7260
    },
    {
      "epoch": 23.3768115942029,
      "grad_norm": 0.22416329383850098,
      "learning_rate": 0.0004856582370548351,
      "loss": 1.4253,
      "step": 7270
    },
    {
      "epoch": 23.40901771336554,
      "grad_norm": 0.22895745933055878,
      "learning_rate": 0.0004856154902818432,
      "loss": 1.4081,
      "step": 7280
    },
    {
      "epoch": 23.44122383252818,
      "grad_norm": 0.22239814698696136,
      "learning_rate": 0.0004855726817854561,
      "loss": 1.4192,
      "step": 7290
    },
    {
      "epoch": 23.47342995169082,
      "grad_norm": 0.21680022776126862,
      "learning_rate": 0.0004855298115768883,
      "loss": 1.4034,
      "step": 7300
    },
    {
      "epoch": 23.505636070853463,
      "grad_norm": 0.26596230268478394,
      "learning_rate": 0.0004854868796673702,
      "loss": 1.4071,
      "step": 7310
    },
    {
      "epoch": 23.537842190016104,
      "grad_norm": 0.22674719989299774,
      "learning_rate": 0.0004854438860681486,
      "loss": 1.4021,
      "step": 7320
    },
    {
      "epoch": 23.570048309178745,
      "grad_norm": 0.22435979545116425,
      "learning_rate": 0.00048540083079048646,
      "loss": 1.4115,
      "step": 7330
    },
    {
      "epoch": 23.602254428341386,
      "grad_norm": 0.20334361493587494,
      "learning_rate": 0.00048535771384566277,
      "loss": 1.4203,
      "step": 7340
    },
    {
      "epoch": 23.634460547504027,
      "grad_norm": 0.18781942129135132,
      "learning_rate": 0.00048531453524497273,
      "loss": 1.3851,
      "step": 7350
    },
    {
      "epoch": 23.666666666666668,
      "grad_norm": 0.20536252856254578,
      "learning_rate": 0.0004852712949997276,
      "loss": 1.3989,
      "step": 7360
    },
    {
      "epoch": 23.69887278582931,
      "grad_norm": 0.25733914971351624,
      "learning_rate": 0.000485227993121255,
      "loss": 1.3997,
      "step": 7370
    },
    {
      "epoch": 23.73107890499195,
      "grad_norm": 0.23229049146175385,
      "learning_rate": 0.0004851846296208986,
      "loss": 1.4094,
      "step": 7380
    },
    {
      "epoch": 23.76328502415459,
      "grad_norm": 0.21648119390010834,
      "learning_rate": 0.00048514120451001816,
      "loss": 1.4011,
      "step": 7390
    },
    {
      "epoch": 23.79549114331723,
      "grad_norm": 0.22036519646644592,
      "learning_rate": 0.00048509771779998957,
      "loss": 1.4016,
      "step": 7400
    },
    {
      "epoch": 23.82769726247987,
      "grad_norm": 0.2005765289068222,
      "learning_rate": 0.00048505416950220487,
      "loss": 1.4065,
      "step": 7410
    },
    {
      "epoch": 23.85990338164251,
      "grad_norm": 0.20606067776679993,
      "learning_rate": 0.0004850105596280723,
      "loss": 1.4189,
      "step": 7420
    },
    {
      "epoch": 23.89210950080515,
      "grad_norm": 0.2112749069929123,
      "learning_rate": 0.00048496688818901624,
      "loss": 1.4075,
      "step": 7430
    },
    {
      "epoch": 23.924315619967793,
      "grad_norm": 0.22147975862026215,
      "learning_rate": 0.0004849231551964771,
      "loss": 1.4257,
      "step": 7440
    },
    {
      "epoch": 23.956521739130434,
      "grad_norm": 0.2096937596797943,
      "learning_rate": 0.0004848793606619115,
      "loss": 1.4305,
      "step": 7450
    },
    {
      "epoch": 23.988727858293075,
      "grad_norm": 0.1924692839384079,
      "learning_rate": 0.00048483550459679206,
      "loss": 1.409,
      "step": 7460
    },
    {
      "epoch": 24.0,
      "eval_loss": 0.6493122577667236,
      "eval_runtime": 7.1052,
      "eval_samples_per_second": 3420.468,
      "eval_steps_per_second": 13.371,
      "step": 7464
    },
    {
      "epoch": 24.019323671497585,
      "grad_norm": 0.18146874010562897,
      "learning_rate": 0.00048479158701260767,
      "loss": 1.318,
      "step": 7470
    },
    {
      "epoch": 24.051529790660226,
      "grad_norm": 0.20330500602722168,
      "learning_rate": 0.0004847476079208633,
      "loss": 1.4064,
      "step": 7480
    },
    {
      "epoch": 24.083735909822867,
      "grad_norm": 0.26986247301101685,
      "learning_rate": 0.00048470356733307994,
      "loss": 1.4043,
      "step": 7490
    },
    {
      "epoch": 24.115942028985508,
      "grad_norm": 0.24056491255760193,
      "learning_rate": 0.00048465946526079476,
      "loss": 1.3919,
      "step": 7500
    },
    {
      "epoch": 24.14814814814815,
      "grad_norm": 0.20519660413265228,
      "learning_rate": 0.0004846153017155611,
      "loss": 1.3997,
      "step": 7510
    },
    {
      "epoch": 24.18035426731079,
      "grad_norm": 0.23851341009140015,
      "learning_rate": 0.00048457107670894827,
      "loss": 1.4061,
      "step": 7520
    },
    {
      "epoch": 24.21256038647343,
      "grad_norm": 0.25259095430374146,
      "learning_rate": 0.0004845267902525418,
      "loss": 1.4032,
      "step": 7530
    },
    {
      "epoch": 24.244766505636072,
      "grad_norm": 0.23772619664669037,
      "learning_rate": 0.00048448244235794314,
      "loss": 1.4028,
      "step": 7540
    },
    {
      "epoch": 24.276972624798713,
      "grad_norm": 0.21004831790924072,
      "learning_rate": 0.00048443803303677016,
      "loss": 1.4021,
      "step": 7550
    },
    {
      "epoch": 24.309178743961354,
      "grad_norm": 0.20185020565986633,
      "learning_rate": 0.00048439356230065646,
      "loss": 1.4099,
      "step": 7560
    },
    {
      "epoch": 24.341384863123995,
      "grad_norm": 0.24513447284698486,
      "learning_rate": 0.0004843490301612519,
      "loss": 1.3959,
      "step": 7570
    },
    {
      "epoch": 24.373590982286636,
      "grad_norm": 0.343968003988266,
      "learning_rate": 0.00048430443663022245,
      "loss": 1.4153,
      "step": 7580
    },
    {
      "epoch": 24.405797101449274,
      "grad_norm": 0.21197627484798431,
      "learning_rate": 0.0004842597817192501,
      "loss": 1.4055,
      "step": 7590
    },
    {
      "epoch": 24.438003220611915,
      "grad_norm": 0.21698880195617676,
      "learning_rate": 0.0004842150654400331,
      "loss": 1.393,
      "step": 7600
    },
    {
      "epoch": 24.470209339774556,
      "grad_norm": 0.26162752509117126,
      "learning_rate": 0.0004841702878042854,
      "loss": 1.418,
      "step": 7610
    },
    {
      "epoch": 24.502415458937197,
      "grad_norm": 0.28665482997894287,
      "learning_rate": 0.0004841254488237373,
      "loss": 1.4109,
      "step": 7620
    },
    {
      "epoch": 24.534621578099838,
      "grad_norm": 0.23442776501178741,
      "learning_rate": 0.0004840805485101353,
      "loss": 1.4024,
      "step": 7630
    },
    {
      "epoch": 24.56682769726248,
      "grad_norm": 0.2088736742734909,
      "learning_rate": 0.0004840355868752415,
      "loss": 1.4346,
      "step": 7640
    },
    {
      "epoch": 24.59903381642512,
      "grad_norm": 0.23767367005348206,
      "learning_rate": 0.00048399056393083454,
      "loss": 1.4164,
      "step": 7650
    },
    {
      "epoch": 24.63123993558776,
      "grad_norm": 0.25902166962623596,
      "learning_rate": 0.00048394547968870895,
      "loss": 1.3893,
      "step": 7660
    },
    {
      "epoch": 24.663446054750402,
      "grad_norm": 0.22253522276878357,
      "learning_rate": 0.00048390033416067515,
      "loss": 1.4136,
      "step": 7670
    },
    {
      "epoch": 24.695652173913043,
      "grad_norm": 0.2395961731672287,
      "learning_rate": 0.00048385512735855984,
      "loss": 1.4105,
      "step": 7680
    },
    {
      "epoch": 24.727858293075684,
      "grad_norm": 0.2070479691028595,
      "learning_rate": 0.00048380985929420575,
      "loss": 1.4181,
      "step": 7690
    },
    {
      "epoch": 24.760064412238325,
      "grad_norm": 0.23636837303638458,
      "learning_rate": 0.0004837645299794714,
      "loss": 1.4347,
      "step": 7700
    },
    {
      "epoch": 24.792270531400966,
      "grad_norm": 0.22688767313957214,
      "learning_rate": 0.0004837191394262318,
      "loss": 1.4062,
      "step": 7710
    },
    {
      "epoch": 24.824476650563607,
      "grad_norm": 0.20295396447181702,
      "learning_rate": 0.00048367368764637767,
      "loss": 1.3998,
      "step": 7720
    },
    {
      "epoch": 24.85668276972625,
      "grad_norm": 0.24388979375362396,
      "learning_rate": 0.00048362817465181585,
      "loss": 1.4118,
      "step": 7730
    },
    {
      "epoch": 24.88888888888889,
      "grad_norm": 0.3064308762550354,
      "learning_rate": 0.0004835826004544692,
      "loss": 1.4247,
      "step": 7740
    },
    {
      "epoch": 24.92109500805153,
      "grad_norm": 0.23296645283699036,
      "learning_rate": 0.0004835369650662767,
      "loss": 1.4043,
      "step": 7750
    },
    {
      "epoch": 24.95330112721417,
      "grad_norm": 0.18894842267036438,
      "learning_rate": 0.0004834912684991932,
      "loss": 1.4122,
      "step": 7760
    },
    {
      "epoch": 24.985507246376812,
      "grad_norm": 0.24470169842243195,
      "learning_rate": 0.00048344551076518984,
      "loss": 1.3981,
      "step": 7770
    },
    {
      "epoch": 25.0,
      "eval_loss": 0.6475232839584351,
      "eval_runtime": 7.1117,
      "eval_samples_per_second": 3417.335,
      "eval_steps_per_second": 13.358,
      "step": 7775
    },
    {
      "epoch": 25.01610305958132,
      "grad_norm": 0.20133145153522491,
      "learning_rate": 0.0004833996918762534,
      "loss": 1.3084,
      "step": 7780
    },
    {
      "epoch": 25.04830917874396,
      "grad_norm": 0.22522443532943726,
      "learning_rate": 0.0004833538118443871,
      "loss": 1.4023,
      "step": 7790
    },
    {
      "epoch": 25.0805152979066,
      "grad_norm": 0.2502509653568268,
      "learning_rate": 0.00048330787068160986,
      "loss": 1.4074,
      "step": 7800
    },
    {
      "epoch": 25.112721417069242,
      "grad_norm": 0.23488686978816986,
      "learning_rate": 0.0004832618683999568,
      "loss": 1.3945,
      "step": 7810
    },
    {
      "epoch": 25.144927536231883,
      "grad_norm": 0.18663866817951202,
      "learning_rate": 0.00048321580501147886,
      "loss": 1.3985,
      "step": 7820
    },
    {
      "epoch": 25.177133655394524,
      "grad_norm": 0.19974246621131897,
      "learning_rate": 0.0004831696805282433,
      "loss": 1.3922,
      "step": 7830
    },
    {
      "epoch": 25.209339774557165,
      "grad_norm": 0.19594891369342804,
      "learning_rate": 0.0004831234949623331,
      "loss": 1.4074,
      "step": 7840
    },
    {
      "epoch": 25.241545893719806,
      "grad_norm": 0.18962804973125458,
      "learning_rate": 0.0004830772483258472,
      "loss": 1.4058,
      "step": 7850
    },
    {
      "epoch": 25.273752012882447,
      "grad_norm": 0.19312559068202972,
      "learning_rate": 0.00048303094063090093,
      "loss": 1.3988,
      "step": 7860
    },
    {
      "epoch": 25.305958132045088,
      "grad_norm": 0.2756975293159485,
      "learning_rate": 0.00048298457188962517,
      "loss": 1.423,
      "step": 7870
    },
    {
      "epoch": 25.33816425120773,
      "grad_norm": 0.25502970814704895,
      "learning_rate": 0.0004829381421141671,
      "loss": 1.4055,
      "step": 7880
    },
    {
      "epoch": 25.37037037037037,
      "grad_norm": 0.26230186223983765,
      "learning_rate": 0.0004828916513166897,
      "loss": 1.4064,
      "step": 7890
    },
    {
      "epoch": 25.40257648953301,
      "grad_norm": 0.23253300786018372,
      "learning_rate": 0.00048284509950937207,
      "loss": 1.3995,
      "step": 7900
    },
    {
      "epoch": 25.434782608695652,
      "grad_norm": 0.24397940933704376,
      "learning_rate": 0.0004827984867044092,
      "loss": 1.422,
      "step": 7910
    },
    {
      "epoch": 25.466988727858293,
      "grad_norm": 0.25403091311454773,
      "learning_rate": 0.000482751812914012,
      "loss": 1.4094,
      "step": 7920
    },
    {
      "epoch": 25.499194847020934,
      "grad_norm": 0.3827838599681854,
      "learning_rate": 0.0004827050781504075,
      "loss": 1.3988,
      "step": 7930
    },
    {
      "epoch": 25.531400966183575,
      "grad_norm": 0.27314916253089905,
      "learning_rate": 0.00048265828242583875,
      "loss": 1.4119,
      "step": 7940
    },
    {
      "epoch": 25.563607085346217,
      "grad_norm": 0.2726290225982666,
      "learning_rate": 0.0004826114257525646,
      "loss": 1.4201,
      "step": 7950
    },
    {
      "epoch": 25.595813204508858,
      "grad_norm": 0.25754162669181824,
      "learning_rate": 0.0004825645081428599,
      "loss": 1.4108,
      "step": 7960
    },
    {
      "epoch": 25.6280193236715,
      "grad_norm": 0.32350441813468933,
      "learning_rate": 0.0004825175296090155,
      "loss": 1.4063,
      "step": 7970
    },
    {
      "epoch": 25.66022544283414,
      "grad_norm": 0.23530836403369904,
      "learning_rate": 0.00048247049016333823,
      "loss": 1.4019,
      "step": 7980
    },
    {
      "epoch": 25.69243156199678,
      "grad_norm": 0.20981499552726746,
      "learning_rate": 0.00048242338981815085,
      "loss": 1.4251,
      "step": 7990
    },
    {
      "epoch": 25.72463768115942,
      "grad_norm": 0.2419915646314621,
      "learning_rate": 0.00048237622858579213,
      "loss": 1.3949,
      "step": 8000
    },
    {
      "epoch": 25.756843800322063,
      "grad_norm": 0.32294797897338867,
      "learning_rate": 0.00048232900647861667,
      "loss": 1.4043,
      "step": 8010
    },
    {
      "epoch": 25.789049919484704,
      "grad_norm": 0.24002647399902344,
      "learning_rate": 0.0004822817235089951,
      "loss": 1.4221,
      "step": 8020
    },
    {
      "epoch": 25.82125603864734,
      "grad_norm": 0.24598178267478943,
      "learning_rate": 0.00048223437968931407,
      "loss": 1.3873,
      "step": 8030
    },
    {
      "epoch": 25.853462157809982,
      "grad_norm": 0.2337820827960968,
      "learning_rate": 0.00048218697503197585,
      "loss": 1.4128,
      "step": 8040
    },
    {
      "epoch": 25.885668276972623,
      "grad_norm": 0.20095063745975494,
      "learning_rate": 0.0004821395095493991,
      "loss": 1.4231,
      "step": 8050
    },
    {
      "epoch": 25.917874396135264,
      "grad_norm": 0.2756698429584503,
      "learning_rate": 0.00048209198325401817,
      "loss": 1.4069,
      "step": 8060
    },
    {
      "epoch": 25.950080515297905,
      "grad_norm": 0.2341713309288025,
      "learning_rate": 0.00048204439615828326,
      "loss": 1.4145,
      "step": 8070
    },
    {
      "epoch": 25.982286634460547,
      "grad_norm": 0.2559620141983032,
      "learning_rate": 0.00048199674827466066,
      "loss": 1.4131,
      "step": 8080
    },
    {
      "epoch": 26.0,
      "eval_loss": 0.6453018188476562,
      "eval_runtime": 7.0832,
      "eval_samples_per_second": 3431.083,
      "eval_steps_per_second": 13.412,
      "step": 8086
    },
    {
      "epoch": 26.012882447665056,
      "grad_norm": 0.20046848058700562,
      "learning_rate": 0.0004819490396156325,
      "loss": 1.303,
      "step": 8090
    },
    {
      "epoch": 26.045088566827697,
      "grad_norm": 0.20642806589603424,
      "learning_rate": 0.00048190127019369697,
      "loss": 1.4296,
      "step": 8100
    },
    {
      "epoch": 26.07729468599034,
      "grad_norm": 0.21358969807624817,
      "learning_rate": 0.0004818534400213679,
      "loss": 1.4163,
      "step": 8110
    },
    {
      "epoch": 26.10950080515298,
      "grad_norm": 0.19990448653697968,
      "learning_rate": 0.00048180554911117523,
      "loss": 1.4162,
      "step": 8120
    },
    {
      "epoch": 26.14170692431562,
      "grad_norm": 0.27086058259010315,
      "learning_rate": 0.0004817575974756649,
      "loss": 1.3987,
      "step": 8130
    },
    {
      "epoch": 26.17391304347826,
      "grad_norm": 0.1933933049440384,
      "learning_rate": 0.0004817095851273985,
      "loss": 1.3976,
      "step": 8140
    },
    {
      "epoch": 26.206119162640903,
      "grad_norm": 0.2317163497209549,
      "learning_rate": 0.00048166151207895377,
      "loss": 1.4076,
      "step": 8150
    },
    {
      "epoch": 26.238325281803544,
      "grad_norm": 0.19224298000335693,
      "learning_rate": 0.0004816133783429242,
      "loss": 1.4021,
      "step": 8160
    },
    {
      "epoch": 26.270531400966185,
      "grad_norm": 0.18827871978282928,
      "learning_rate": 0.00048156518393191916,
      "loss": 1.4134,
      "step": 8170
    },
    {
      "epoch": 26.302737520128826,
      "grad_norm": 0.2279384285211563,
      "learning_rate": 0.0004815169288585641,
      "loss": 1.4312,
      "step": 8180
    },
    {
      "epoch": 26.334943639291467,
      "grad_norm": 0.206229567527771,
      "learning_rate": 0.0004814686131355001,
      "loss": 1.3819,
      "step": 8190
    },
    {
      "epoch": 26.367149758454108,
      "grad_norm": 0.2083781510591507,
      "learning_rate": 0.0004814202367753844,
      "loss": 1.4065,
      "step": 8200
    },
    {
      "epoch": 26.39935587761675,
      "grad_norm": 0.18637046217918396,
      "learning_rate": 0.0004813717997908899,
      "loss": 1.3793,
      "step": 8210
    },
    {
      "epoch": 26.431561996779386,
      "grad_norm": 0.2436920702457428,
      "learning_rate": 0.00048132330219470554,
      "loss": 1.3973,
      "step": 8220
    },
    {
      "epoch": 26.463768115942027,
      "grad_norm": 0.29505544900894165,
      "learning_rate": 0.000481274743999536,
      "loss": 1.4188,
      "step": 8230
    },
    {
      "epoch": 26.49597423510467,
      "grad_norm": 0.21306991577148438,
      "learning_rate": 0.00048122612521810196,
      "loss": 1.4133,
      "step": 8240
    },
    {
      "epoch": 26.52818035426731,
      "grad_norm": 0.19764529168605804,
      "learning_rate": 0.0004811774458631399,
      "loss": 1.384,
      "step": 8250
    },
    {
      "epoch": 26.56038647342995,
      "grad_norm": 0.21198412775993347,
      "learning_rate": 0.0004811287059474022,
      "loss": 1.3756,
      "step": 8260
    },
    {
      "epoch": 26.59259259259259,
      "grad_norm": 0.2563552260398865,
      "learning_rate": 0.0004810799054836571,
      "loss": 1.4152,
      "step": 8270
    },
    {
      "epoch": 26.624798711755233,
      "grad_norm": 0.2262057065963745,
      "learning_rate": 0.0004810310444846886,
      "loss": 1.3996,
      "step": 8280
    },
    {
      "epoch": 26.657004830917874,
      "grad_norm": 0.2107423096895218,
      "learning_rate": 0.0004809821229632968,
      "loss": 1.4148,
      "step": 8290
    },
    {
      "epoch": 26.689210950080515,
      "grad_norm": 0.20903705060482025,
      "learning_rate": 0.0004809331409322974,
      "loss": 1.4072,
      "step": 8300
    },
    {
      "epoch": 26.721417069243156,
      "grad_norm": 0.2684166431427002,
      "learning_rate": 0.00048088409840452205,
      "loss": 1.4033,
      "step": 8310
    },
    {
      "epoch": 26.753623188405797,
      "grad_norm": 0.2359970211982727,
      "learning_rate": 0.0004808349953928184,
      "loss": 1.4196,
      "step": 8320
    },
    {
      "epoch": 26.785829307568438,
      "grad_norm": 0.197775736451149,
      "learning_rate": 0.00048078583191004965,
      "loss": 1.4033,
      "step": 8330
    },
    {
      "epoch": 26.81803542673108,
      "grad_norm": 0.20393793284893036,
      "learning_rate": 0.00048073660796909504,
      "loss": 1.4026,
      "step": 8340
    },
    {
      "epoch": 26.85024154589372,
      "grad_norm": 0.2114088237285614,
      "learning_rate": 0.0004806873235828495,
      "loss": 1.4095,
      "step": 8350
    },
    {
      "epoch": 26.88244766505636,
      "grad_norm": 0.2500607371330261,
      "learning_rate": 0.0004806379787642241,
      "loss": 1.3969,
      "step": 8360
    },
    {
      "epoch": 26.914653784219002,
      "grad_norm": 0.2500561773777008,
      "learning_rate": 0.00048058857352614536,
      "loss": 1.3936,
      "step": 8370
    },
    {
      "epoch": 26.946859903381643,
      "grad_norm": 0.21355143189430237,
      "learning_rate": 0.00048053910788155584,
      "loss": 1.4158,
      "step": 8380
    },
    {
      "epoch": 26.979066022544284,
      "grad_norm": 0.25925320386886597,
      "learning_rate": 0.000480489581843414,
      "loss": 1.4196,
      "step": 8390
    },
    {
      "epoch": 27.0,
      "eval_loss": 0.645269513130188,
      "eval_runtime": 7.2722,
      "eval_samples_per_second": 3341.926,
      "eval_steps_per_second": 13.064,
      "step": 8397
    },
    {
      "epoch": 27.00966183574879,
      "grad_norm": 0.23709960281848907,
      "learning_rate": 0.0004804399954246939,
      "loss": 1.3259,
      "step": 8400
    },
    {
      "epoch": 27.04186795491143,
      "grad_norm": 0.20458047091960907,
      "learning_rate": 0.0004803903486383856,
      "loss": 1.3974,
      "step": 8410
    },
    {
      "epoch": 27.074074074074073,
      "grad_norm": 0.25891298055648804,
      "learning_rate": 0.00048034064149749477,
      "loss": 1.3917,
      "step": 8420
    },
    {
      "epoch": 27.106280193236714,
      "grad_norm": 0.2574378252029419,
      "learning_rate": 0.00048029087401504314,
      "loss": 1.4288,
      "step": 8430
    },
    {
      "epoch": 27.138486312399355,
      "grad_norm": 0.22947891056537628,
      "learning_rate": 0.0004802410462040681,
      "loss": 1.3962,
      "step": 8440
    },
    {
      "epoch": 27.170692431561996,
      "grad_norm": 0.22524116933345795,
      "learning_rate": 0.00048019115807762286,
      "loss": 1.3794,
      "step": 8450
    },
    {
      "epoch": 27.202898550724637,
      "grad_norm": 0.25903773307800293,
      "learning_rate": 0.0004801412096487765,
      "loss": 1.3823,
      "step": 8460
    },
    {
      "epoch": 27.235104669887278,
      "grad_norm": 0.2343006134033203,
      "learning_rate": 0.00048009120093061376,
      "loss": 1.397,
      "step": 8470
    },
    {
      "epoch": 27.26731078904992,
      "grad_norm": 0.22314617037773132,
      "learning_rate": 0.0004800411319362352,
      "loss": 1.3874,
      "step": 8480
    },
    {
      "epoch": 27.29951690821256,
      "grad_norm": 0.22698773443698883,
      "learning_rate": 0.0004799910026787574,
      "loss": 1.4265,
      "step": 8490
    },
    {
      "epoch": 27.3317230273752,
      "grad_norm": 0.3026920557022095,
      "learning_rate": 0.00047994081317131256,
      "loss": 1.4017,
      "step": 8500
    },
    {
      "epoch": 27.363929146537842,
      "grad_norm": 0.25018051266670227,
      "learning_rate": 0.0004798905634270484,
      "loss": 1.4208,
      "step": 8510
    },
    {
      "epoch": 27.396135265700483,
      "grad_norm": 0.22291390597820282,
      "learning_rate": 0.00047984025345912894,
      "loss": 1.4145,
      "step": 8520
    },
    {
      "epoch": 27.428341384863124,
      "grad_norm": 0.24502518773078918,
      "learning_rate": 0.0004797898832807336,
      "loss": 1.4095,
      "step": 8530
    },
    {
      "epoch": 27.460547504025765,
      "grad_norm": 0.25856876373291016,
      "learning_rate": 0.00047973945290505766,
      "loss": 1.4253,
      "step": 8540
    },
    {
      "epoch": 27.492753623188406,
      "grad_norm": 0.30621466040611267,
      "learning_rate": 0.00047968896234531225,
      "loss": 1.4101,
      "step": 8550
    },
    {
      "epoch": 27.524959742351047,
      "grad_norm": 0.19264893233776093,
      "learning_rate": 0.0004796384116147242,
      "loss": 1.4104,
      "step": 8560
    },
    {
      "epoch": 27.55716586151369,
      "grad_norm": 0.2604641020298004,
      "learning_rate": 0.00047958780072653614,
      "loss": 1.4004,
      "step": 8570
    },
    {
      "epoch": 27.58937198067633,
      "grad_norm": 0.2335198074579239,
      "learning_rate": 0.0004795371296940064,
      "loss": 1.396,
      "step": 8580
    },
    {
      "epoch": 27.62157809983897,
      "grad_norm": 0.3590925931930542,
      "learning_rate": 0.00047948639853040903,
      "loss": 1.4001,
      "step": 8590
    },
    {
      "epoch": 27.65378421900161,
      "grad_norm": 0.21805228292942047,
      "learning_rate": 0.000479435607249034,
      "loss": 1.421,
      "step": 8600
    },
    {
      "epoch": 27.685990338164252,
      "grad_norm": 0.2356807142496109,
      "learning_rate": 0.000479384755863187,
      "loss": 1.3968,
      "step": 8610
    },
    {
      "epoch": 27.718196457326894,
      "grad_norm": 0.2358023226261139,
      "learning_rate": 0.0004793338443861892,
      "loss": 1.3936,
      "step": 8620
    },
    {
      "epoch": 27.750402576489535,
      "grad_norm": 0.23918446898460388,
      "learning_rate": 0.00047928287283137785,
      "loss": 1.4112,
      "step": 8630
    },
    {
      "epoch": 27.782608695652176,
      "grad_norm": 0.27576595544815063,
      "learning_rate": 0.0004792318412121057,
      "loss": 1.4163,
      "step": 8640
    },
    {
      "epoch": 27.814814814814813,
      "grad_norm": 0.24264098703861237,
      "learning_rate": 0.0004791807495417414,
      "loss": 1.3817,
      "step": 8650
    },
    {
      "epoch": 27.847020933977454,
      "grad_norm": 0.210118368268013,
      "learning_rate": 0.00047912959783366936,
      "loss": 1.4338,
      "step": 8660
    },
    {
      "epoch": 27.879227053140095,
      "grad_norm": 0.2401842474937439,
      "learning_rate": 0.0004790783861012894,
      "loss": 1.4114,
      "step": 8670
    },
    {
      "epoch": 27.911433172302736,
      "grad_norm": 0.20549489557743073,
      "learning_rate": 0.0004790271143580174,
      "loss": 1.3961,
      "step": 8680
    },
    {
      "epoch": 27.943639291465377,
      "grad_norm": 0.258940190076828,
      "learning_rate": 0.0004789757826172849,
      "loss": 1.3926,
      "step": 8690
    },
    {
      "epoch": 27.97584541062802,
      "grad_norm": 0.2631029188632965,
      "learning_rate": 0.00047892439089253897,
      "loss": 1.4071,
      "step": 8700
    },
    {
      "epoch": 28.0,
      "eval_loss": 0.6455366611480713,
      "eval_runtime": 7.1197,
      "eval_samples_per_second": 3413.464,
      "eval_steps_per_second": 13.343,
      "step": 8708
    },
    {
      "epoch": 28.006441223832528,
      "grad_norm": 0.1990589201450348,
      "learning_rate": 0.00047887293919724263,
      "loss": 1.3181,
      "step": 8710
    },
    {
      "epoch": 28.03864734299517,
      "grad_norm": 0.24783819913864136,
      "learning_rate": 0.00047882142754487444,
      "loss": 1.4022,
      "step": 8720
    },
    {
      "epoch": 28.07085346215781,
      "grad_norm": 0.24726438522338867,
      "learning_rate": 0.00047876985594892885,
      "loss": 1.3901,
      "step": 8730
    },
    {
      "epoch": 28.10305958132045,
      "grad_norm": 0.20654365420341492,
      "learning_rate": 0.0004787182244229158,
      "loss": 1.4205,
      "step": 8740
    },
    {
      "epoch": 28.135265700483092,
      "grad_norm": 0.23598290979862213,
      "learning_rate": 0.000478666532980361,
      "loss": 1.4156,
      "step": 8750
    },
    {
      "epoch": 28.167471819645733,
      "grad_norm": 0.26306620240211487,
      "learning_rate": 0.00047861478163480596,
      "loss": 1.3847,
      "step": 8760
    },
    {
      "epoch": 28.199677938808374,
      "grad_norm": 0.20950011909008026,
      "learning_rate": 0.0004785629703998078,
      "loss": 1.3959,
      "step": 8770
    },
    {
      "epoch": 28.231884057971016,
      "grad_norm": 0.2297913283109665,
      "learning_rate": 0.0004785110992889392,
      "loss": 1.4131,
      "step": 8780
    },
    {
      "epoch": 28.264090177133657,
      "grad_norm": 1.3266675472259521,
      "learning_rate": 0.00047845916831578886,
      "loss": 1.4023,
      "step": 8790
    },
    {
      "epoch": 28.296296296296298,
      "grad_norm": 0.200520321726799,
      "learning_rate": 0.0004784071774939609,
      "loss": 1.3892,
      "step": 8800
    },
    {
      "epoch": 28.32850241545894,
      "grad_norm": 0.25745460391044617,
      "learning_rate": 0.00047835512683707505,
      "loss": 1.4132,
      "step": 8810
    },
    {
      "epoch": 28.36070853462158,
      "grad_norm": 0.2851267457008362,
      "learning_rate": 0.000478303016358767,
      "loss": 1.4133,
      "step": 8820
    },
    {
      "epoch": 28.39291465378422,
      "grad_norm": 0.22576552629470825,
      "learning_rate": 0.00047825084607268787,
      "loss": 1.3984,
      "step": 8830
    },
    {
      "epoch": 28.42512077294686,
      "grad_norm": 0.2679518163204193,
      "learning_rate": 0.0004781986159925046,
      "loss": 1.4261,
      "step": 8840
    },
    {
      "epoch": 28.4573268921095,
      "grad_norm": 0.22733043134212494,
      "learning_rate": 0.0004781463261318997,
      "loss": 1.3852,
      "step": 8850
    },
    {
      "epoch": 28.48953301127214,
      "grad_norm": 0.23858070373535156,
      "learning_rate": 0.00047809397650457134,
      "loss": 1.4166,
      "step": 8860
    },
    {
      "epoch": 28.52173913043478,
      "grad_norm": 0.25076907873153687,
      "learning_rate": 0.00047804156712423333,
      "loss": 1.4117,
      "step": 8870
    },
    {
      "epoch": 28.553945249597422,
      "grad_norm": 0.2666204869747162,
      "learning_rate": 0.00047798909800461534,
      "loss": 1.4087,
      "step": 8880
    },
    {
      "epoch": 28.586151368760063,
      "grad_norm": 0.22752682864665985,
      "learning_rate": 0.0004779365691594624,
      "loss": 1.3779,
      "step": 8890
    },
    {
      "epoch": 28.618357487922705,
      "grad_norm": 0.2321881800889969,
      "learning_rate": 0.00047788398060253533,
      "loss": 1.3947,
      "step": 8900
    },
    {
      "epoch": 28.650563607085346,
      "grad_norm": 0.27631810307502747,
      "learning_rate": 0.00047783133234761055,
      "loss": 1.4006,
      "step": 8910
    },
    {
      "epoch": 28.682769726247987,
      "grad_norm": 0.21036311984062195,
      "learning_rate": 0.0004777786244084803,
      "loss": 1.3811,
      "step": 8920
    },
    {
      "epoch": 28.714975845410628,
      "grad_norm": 0.21515829861164093,
      "learning_rate": 0.0004777258567989521,
      "loss": 1.4084,
      "step": 8930
    },
    {
      "epoch": 28.74718196457327,
      "grad_norm": 0.24414636194705963,
      "learning_rate": 0.0004776730295328495,
      "loss": 1.3912,
      "step": 8940
    },
    {
      "epoch": 28.77938808373591,
      "grad_norm": 0.26131293177604675,
      "learning_rate": 0.0004776201426240113,
      "loss": 1.3918,
      "step": 8950
    },
    {
      "epoch": 28.81159420289855,
      "grad_norm": 0.22900773584842682,
      "learning_rate": 0.0004775671960862922,
      "loss": 1.4097,
      "step": 8960
    },
    {
      "epoch": 28.843800322061192,
      "grad_norm": 0.2849568724632263,
      "learning_rate": 0.0004775141899335623,
      "loss": 1.4072,
      "step": 8970
    },
    {
      "epoch": 28.876006441223833,
      "grad_norm": 0.23502959311008453,
      "learning_rate": 0.0004774611241797077,
      "loss": 1.4149,
      "step": 8980
    },
    {
      "epoch": 28.908212560386474,
      "grad_norm": 0.26947876811027527,
      "learning_rate": 0.0004774079988386296,
      "loss": 1.4093,
      "step": 8990
    },
    {
      "epoch": 28.940418679549115,
      "grad_norm": 0.24783341586589813,
      "learning_rate": 0.0004773548139242452,
      "loss": 1.3957,
      "step": 9000
    },
    {
      "epoch": 28.972624798711756,
      "grad_norm": 0.25013092160224915,
      "learning_rate": 0.0004773015694504872,
      "loss": 1.3982,
      "step": 9010
    },
    {
      "epoch": 29.0,
      "eval_loss": 0.6472808718681335,
      "eval_runtime": 7.1051,
      "eval_samples_per_second": 3420.516,
      "eval_steps_per_second": 13.371,
      "step": 9019
    },
    {
      "epoch": 29.003220611916262,
      "grad_norm": 0.29647284746170044,
      "learning_rate": 0.0004772482654313037,
      "loss": 1.3451,
      "step": 9020
    },
    {
      "epoch": 29.035426731078903,
      "grad_norm": 0.27553677558898926,
      "learning_rate": 0.0004771949018806588,
      "loss": 1.3925,
      "step": 9030
    },
    {
      "epoch": 29.067632850241544,
      "grad_norm": 0.27037477493286133,
      "learning_rate": 0.00047714147881253177,
      "loss": 1.4061,
      "step": 9040
    },
    {
      "epoch": 29.099838969404185,
      "grad_norm": 0.49059590697288513,
      "learning_rate": 0.00047708799624091784,
      "loss": 1.4032,
      "step": 9050
    },
    {
      "epoch": 29.132045088566827,
      "grad_norm": 0.34583184123039246,
      "learning_rate": 0.0004770344541798276,
      "loss": 1.394,
      "step": 9060
    },
    {
      "epoch": 29.164251207729468,
      "grad_norm": 0.2832137942314148,
      "learning_rate": 0.0004769808526432872,
      "loss": 1.3935,
      "step": 9070
    },
    {
      "epoch": 29.19645732689211,
      "grad_norm": 0.2731361985206604,
      "learning_rate": 0.0004769271916453386,
      "loss": 1.4023,
      "step": 9080
    },
    {
      "epoch": 29.22866344605475,
      "grad_norm": 0.22449034452438354,
      "learning_rate": 0.000476873471200039,
      "loss": 1.3812,
      "step": 9090
    },
    {
      "epoch": 29.26086956521739,
      "grad_norm": 0.29802992939949036,
      "learning_rate": 0.0004768196913214615,
      "loss": 1.3949,
      "step": 9100
    },
    {
      "epoch": 29.29307568438003,
      "grad_norm": 0.245111346244812,
      "learning_rate": 0.0004767658520236947,
      "loss": 1.3862,
      "step": 9110
    },
    {
      "epoch": 29.325281803542673,
      "grad_norm": 0.3418118953704834,
      "learning_rate": 0.0004767119533208425,
      "loss": 1.4075,
      "step": 9120
    },
    {
      "epoch": 29.357487922705314,
      "grad_norm": 0.3020727336406708,
      "learning_rate": 0.00047665799522702467,
      "loss": 1.403,
      "step": 9130
    },
    {
      "epoch": 29.389694041867955,
      "grad_norm": 0.2316233366727829,
      "learning_rate": 0.00047660397775637655,
      "loss": 1.3971,
      "step": 9140
    },
    {
      "epoch": 29.421900161030596,
      "grad_norm": 0.30462220311164856,
      "learning_rate": 0.0004765499009230486,
      "loss": 1.3943,
      "step": 9150
    },
    {
      "epoch": 29.454106280193237,
      "grad_norm": 0.25707265734672546,
      "learning_rate": 0.0004764957647412075,
      "loss": 1.4109,
      "step": 9160
    },
    {
      "epoch": 29.486312399355878,
      "grad_norm": 0.2725256085395813,
      "learning_rate": 0.0004764415692250349,
      "loss": 1.3958,
      "step": 9170
    },
    {
      "epoch": 29.51851851851852,
      "grad_norm": 0.2712472081184387,
      "learning_rate": 0.0004763873143887283,
      "loss": 1.4035,
      "step": 9180
    },
    {
      "epoch": 29.55072463768116,
      "grad_norm": 0.24627964198589325,
      "learning_rate": 0.00047633300024650064,
      "loss": 1.4031,
      "step": 9190
    },
    {
      "epoch": 29.5829307568438,
      "grad_norm": 0.24012164771556854,
      "learning_rate": 0.0004762786268125803,
      "loss": 1.4433,
      "step": 9200
    },
    {
      "epoch": 29.615136876006442,
      "grad_norm": 0.24581968784332275,
      "learning_rate": 0.0004762241941012115,
      "loss": 1.3843,
      "step": 9210
    },
    {
      "epoch": 29.647342995169083,
      "grad_norm": 0.2779240012168884,
      "learning_rate": 0.00047616970212665367,
      "loss": 1.3944,
      "step": 9220
    },
    {
      "epoch": 29.679549114331724,
      "grad_norm": 0.23939363658428192,
      "learning_rate": 0.000476115150903182,
      "loss": 1.4129,
      "step": 9230
    },
    {
      "epoch": 29.711755233494365,
      "grad_norm": 0.2711055874824524,
      "learning_rate": 0.00047606054044508695,
      "loss": 1.4024,
      "step": 9240
    },
    {
      "epoch": 29.743961352657006,
      "grad_norm": 0.2676958739757538,
      "learning_rate": 0.0004760058707666747,
      "loss": 1.4029,
      "step": 9250
    },
    {
      "epoch": 29.776167471819647,
      "grad_norm": 0.2234688401222229,
      "learning_rate": 0.00047595114188226685,
      "loss": 1.3863,
      "step": 9260
    },
    {
      "epoch": 29.808373590982285,
      "grad_norm": 0.3310888111591339,
      "learning_rate": 0.0004758963538062006,
      "loss": 1.3914,
      "step": 9270
    },
    {
      "epoch": 29.840579710144926,
      "grad_norm": 0.2798500657081604,
      "learning_rate": 0.0004758415065528286,
      "loss": 1.4013,
      "step": 9280
    },
    {
      "epoch": 29.872785829307567,
      "grad_norm": 0.24443015456199646,
      "learning_rate": 0.000475786600136519,
      "loss": 1.4364,
      "step": 9290
    },
    {
      "epoch": 29.904991948470208,
      "grad_norm": 0.27563363313674927,
      "learning_rate": 0.0004757316345716554,
      "loss": 1.3938,
      "step": 9300
    },
    {
      "epoch": 29.93719806763285,
      "grad_norm": 0.2623158097267151,
      "learning_rate": 0.00047567660987263684,
      "loss": 1.4038,
      "step": 9310
    },
    {
      "epoch": 29.96940418679549,
      "grad_norm": 0.2531081438064575,
      "learning_rate": 0.0004756215260538782,
      "loss": 1.4279,
      "step": 9320
    },
    {
      "epoch": 30.0,
      "grad_norm": 1.5990968942642212,
      "learning_rate": 0.0004755663831298094,
      "loss": 1.3424,
      "step": 9330
    },
    {
      "epoch": 30.0,
      "eval_loss": 0.6434204578399658,
      "eval_runtime": 7.0926,
      "eval_samples_per_second": 3426.532,
      "eval_steps_per_second": 13.394,
      "step": 9330
    },
    {
      "epoch": 30.03220611916264,
      "grad_norm": 0.22127032279968262,
      "learning_rate": 0.0004755111811148762,
      "loss": 1.4129,
      "step": 9340
    },
    {
      "epoch": 30.064412238325282,
      "grad_norm": 0.23446029424667358,
      "learning_rate": 0.0004754559200235396,
      "loss": 1.3959,
      "step": 9350
    },
    {
      "epoch": 30.096618357487923,
      "grad_norm": 0.21634739637374878,
      "learning_rate": 0.0004754005998702762,
      "loss": 1.3872,
      "step": 9360
    },
    {
      "epoch": 30.128824476650564,
      "grad_norm": 0.25984543561935425,
      "learning_rate": 0.0004753452206695779,
      "loss": 1.3956,
      "step": 9370
    },
    {
      "epoch": 30.161030595813205,
      "grad_norm": 0.20501840114593506,
      "learning_rate": 0.0004752897824359524,
      "loss": 1.395,
      "step": 9380
    },
    {
      "epoch": 30.193236714975846,
      "grad_norm": 0.22572171688079834,
      "learning_rate": 0.00047523428518392254,
      "loss": 1.3792,
      "step": 9390
    },
    {
      "epoch": 30.225442834138487,
      "grad_norm": 0.27385103702545166,
      "learning_rate": 0.0004751787289280268,
      "loss": 1.3895,
      "step": 9400
    },
    {
      "epoch": 30.25764895330113,
      "grad_norm": 0.2790328562259674,
      "learning_rate": 0.000475123113682819,
      "loss": 1.3973,
      "step": 9410
    },
    {
      "epoch": 30.28985507246377,
      "grad_norm": 0.25196510553359985,
      "learning_rate": 0.0004750674394628686,
      "loss": 1.412,
      "step": 9420
    },
    {
      "epoch": 30.32206119162641,
      "grad_norm": 0.25925925374031067,
      "learning_rate": 0.0004750117062827603,
      "loss": 1.4069,
      "step": 9430
    },
    {
      "epoch": 30.35426731078905,
      "grad_norm": 0.2518523931503296,
      "learning_rate": 0.0004749559141570943,
      "loss": 1.4244,
      "step": 9440
    },
    {
      "epoch": 30.386473429951693,
      "grad_norm": 0.361094206571579,
      "learning_rate": 0.00047490006310048637,
      "loss": 1.4099,
      "step": 9450
    },
    {
      "epoch": 30.41867954911433,
      "grad_norm": 0.25502124428749084,
      "learning_rate": 0.0004748441531275676,
      "loss": 1.4056,
      "step": 9460
    },
    {
      "epoch": 30.45088566827697,
      "grad_norm": 0.21495282649993896,
      "learning_rate": 0.0004747881842529844,
      "loss": 1.4001,
      "step": 9470
    },
    {
      "epoch": 30.483091787439612,
      "grad_norm": 0.2407461702823639,
      "learning_rate": 0.000474732156491399,
      "loss": 1.407,
      "step": 9480
    },
    {
      "epoch": 30.515297906602253,
      "grad_norm": 0.2198246568441391,
      "learning_rate": 0.00047467606985748855,
      "loss": 1.3866,
      "step": 9490
    },
    {
      "epoch": 30.547504025764894,
      "grad_norm": 0.22287173569202423,
      "learning_rate": 0.0004746199243659461,
      "loss": 1.3965,
      "step": 9500
    },
    {
      "epoch": 30.579710144927535,
      "grad_norm": 0.26703253388404846,
      "learning_rate": 0.00047456372003147976,
      "loss": 1.3848,
      "step": 9510
    },
    {
      "epoch": 30.611916264090176,
      "grad_norm": 0.21131253242492676,
      "learning_rate": 0.0004745074568688131,
      "loss": 1.4058,
      "step": 9520
    },
    {
      "epoch": 30.644122383252817,
      "grad_norm": 0.22038841247558594,
      "learning_rate": 0.00047445113489268543,
      "loss": 1.3782,
      "step": 9530
    },
    {
      "epoch": 30.67632850241546,
      "grad_norm": 0.26749110221862793,
      "learning_rate": 0.00047439475411785106,
      "loss": 1.3878,
      "step": 9540
    },
    {
      "epoch": 30.7085346215781,
      "grad_norm": 0.27282285690307617,
      "learning_rate": 0.00047433831455907994,
      "loss": 1.4109,
      "step": 9550
    },
    {
      "epoch": 30.74074074074074,
      "grad_norm": 0.22027231752872467,
      "learning_rate": 0.00047428181623115727,
      "loss": 1.4129,
      "step": 9560
    },
    {
      "epoch": 30.77294685990338,
      "grad_norm": 0.23151426017284393,
      "learning_rate": 0.0004742252591488838,
      "loss": 1.4023,
      "step": 9570
    },
    {
      "epoch": 30.805152979066023,
      "grad_norm": 0.2212987095117569,
      "learning_rate": 0.00047416864332707566,
      "loss": 1.3965,
      "step": 9580
    },
    {
      "epoch": 30.837359098228664,
      "grad_norm": 0.5283384323120117,
      "learning_rate": 0.0004741119687805641,
      "loss": 1.4044,
      "step": 9590
    },
    {
      "epoch": 30.869565217391305,
      "grad_norm": 0.39053401350975037,
      "learning_rate": 0.00047405523552419615,
      "loss": 1.421,
      "step": 9600
    },
    {
      "epoch": 30.901771336553946,
      "grad_norm": 0.3462090492248535,
      "learning_rate": 0.00047399844357283395,
      "loss": 1.4201,
      "step": 9610
    },
    {
      "epoch": 30.933977455716587,
      "grad_norm": 0.2590491771697998,
      "learning_rate": 0.0004739415929413552,
      "loss": 1.4103,
      "step": 9620
    },
    {
      "epoch": 30.966183574879228,
      "grad_norm": 0.23679488897323608,
      "learning_rate": 0.00047388468364465265,
      "loss": 1.3945,
      "step": 9630
    },
    {
      "epoch": 30.99838969404187,
      "grad_norm": 0.27729812264442444,
      "learning_rate": 0.00047382771569763485,
      "loss": 1.4045,
      "step": 9640
    },
    {
      "epoch": 31.0,
      "eval_loss": 0.6448561549186707,
      "eval_runtime": 7.1081,
      "eval_samples_per_second": 3419.076,
      "eval_steps_per_second": 13.365,
      "step": 9641
    },
    {
      "epoch": 31.028985507246375,
      "grad_norm": 0.2757585942745209,
      "learning_rate": 0.00047377068911522537,
      "loss": 1.33,
      "step": 9650
    },
    {
      "epoch": 31.061191626409016,
      "grad_norm": 0.37798428535461426,
      "learning_rate": 0.0004737136039123633,
      "loss": 1.3993,
      "step": 9660
    },
    {
      "epoch": 31.093397745571657,
      "grad_norm": 0.3107633590698242,
      "learning_rate": 0.0004736564601040032,
      "loss": 1.3995,
      "step": 9670
    },
    {
      "epoch": 31.1256038647343,
      "grad_norm": 0.25802281498908997,
      "learning_rate": 0.0004735992577051146,
      "loss": 1.3955,
      "step": 9680
    },
    {
      "epoch": 31.15780998389694,
      "grad_norm": 0.24314281344413757,
      "learning_rate": 0.00047354199673068276,
      "loss": 1.3959,
      "step": 9690
    },
    {
      "epoch": 31.19001610305958,
      "grad_norm": 0.3326745927333832,
      "learning_rate": 0.00047348467719570813,
      "loss": 1.4076,
      "step": 9700
    },
    {
      "epoch": 31.22222222222222,
      "grad_norm": 0.24799473583698273,
      "learning_rate": 0.00047342729911520657,
      "loss": 1.4006,
      "step": 9710
    },
    {
      "epoch": 31.254428341384862,
      "grad_norm": 0.31244954466819763,
      "learning_rate": 0.00047336986250420907,
      "loss": 1.3942,
      "step": 9720
    },
    {
      "epoch": 31.286634460547504,
      "grad_norm": 0.25723257660865784,
      "learning_rate": 0.0004733123673777622,
      "loss": 1.4136,
      "step": 9730
    },
    {
      "epoch": 31.318840579710145,
      "grad_norm": 0.27344968914985657,
      "learning_rate": 0.00047325481375092775,
      "loss": 1.4088,
      "step": 9740
    },
    {
      "epoch": 31.351046698872786,
      "grad_norm": 0.2187715470790863,
      "learning_rate": 0.00047319720163878294,
      "loss": 1.3989,
      "step": 9750
    },
    {
      "epoch": 31.383252818035427,
      "grad_norm": 0.38193395733833313,
      "learning_rate": 0.00047313953105642006,
      "loss": 1.4042,
      "step": 9760
    },
    {
      "epoch": 31.415458937198068,
      "grad_norm": 0.46005576848983765,
      "learning_rate": 0.000473081802018947,
      "loss": 1.3857,
      "step": 9770
    },
    {
      "epoch": 31.44766505636071,
      "grad_norm": 0.27736690640449524,
      "learning_rate": 0.0004730240145414868,
      "loss": 1.4133,
      "step": 9780
    },
    {
      "epoch": 31.47987117552335,
      "grad_norm": 0.2807108759880066,
      "learning_rate": 0.00047296616863917783,
      "loss": 1.4219,
      "step": 9790
    },
    {
      "epoch": 31.51207729468599,
      "grad_norm": 0.3419455587863922,
      "learning_rate": 0.00047290826432717383,
      "loss": 1.4008,
      "step": 9800
    },
    {
      "epoch": 31.544283413848632,
      "grad_norm": 0.3483244776725769,
      "learning_rate": 0.0004728503016206437,
      "loss": 1.3878,
      "step": 9810
    },
    {
      "epoch": 31.576489533011273,
      "grad_norm": 0.30787989497184753,
      "learning_rate": 0.0004727922805347719,
      "loss": 1.4169,
      "step": 9820
    },
    {
      "epoch": 31.608695652173914,
      "grad_norm": 0.29673177003860474,
      "learning_rate": 0.00047273420108475783,
      "loss": 1.415,
      "step": 9830
    },
    {
      "epoch": 31.640901771336555,
      "grad_norm": 0.27909326553344727,
      "learning_rate": 0.00047267606328581653,
      "loss": 1.4032,
      "step": 9840
    },
    {
      "epoch": 31.673107890499196,
      "grad_norm": 0.2741982638835907,
      "learning_rate": 0.0004726178671531781,
      "loss": 1.3958,
      "step": 9850
    },
    {
      "epoch": 31.705314009661837,
      "grad_norm": 0.21615467965602875,
      "learning_rate": 0.0004725596127020879,
      "loss": 1.4009,
      "step": 9860
    },
    {
      "epoch": 31.737520128824478,
      "grad_norm": 0.23088471591472626,
      "learning_rate": 0.0004725012999478068,
      "loss": 1.3848,
      "step": 9870
    },
    {
      "epoch": 31.76972624798712,
      "grad_norm": 0.25547587871551514,
      "learning_rate": 0.0004724429289056107,
      "loss": 1.3861,
      "step": 9880
    },
    {
      "epoch": 31.80193236714976,
      "grad_norm": 0.3005034029483795,
      "learning_rate": 0.0004723844995907909,
      "loss": 1.3713,
      "step": 9890
    },
    {
      "epoch": 31.834138486312398,
      "grad_norm": 0.26987990736961365,
      "learning_rate": 0.00047232601201865394,
      "loss": 1.3868,
      "step": 9900
    },
    {
      "epoch": 31.86634460547504,
      "grad_norm": 0.26483452320098877,
      "learning_rate": 0.00047226746620452156,
      "loss": 1.3825,
      "step": 9910
    },
    {
      "epoch": 31.89855072463768,
      "grad_norm": 0.33379700779914856,
      "learning_rate": 0.0004722088621637309,
      "loss": 1.4047,
      "step": 9920
    },
    {
      "epoch": 31.93075684380032,
      "grad_norm": 0.2578255832195282,
      "learning_rate": 0.00047215019991163413,
      "loss": 1.3972,
      "step": 9930
    },
    {
      "epoch": 31.962962962962962,
      "grad_norm": 0.30962005257606506,
      "learning_rate": 0.00047209147946359893,
      "loss": 1.4182,
      "step": 9940
    },
    {
      "epoch": 31.995169082125603,
      "grad_norm": 0.30538439750671387,
      "learning_rate": 0.000472032700835008,
      "loss": 1.3954,
      "step": 9950
    },
    {
      "epoch": 32.0,
      "eval_loss": 0.6460011601448059,
      "eval_runtime": 7.1259,
      "eval_samples_per_second": 3410.525,
      "eval_steps_per_second": 13.332,
      "step": 9952
    },
    {
      "epoch": 32.02576489533011,
      "grad_norm": 0.32240545749664307,
      "learning_rate": 0.00047197386404125954,
      "loss": 1.3319,
      "step": 9960
    },
    {
      "epoch": 32.05797101449275,
      "grad_norm": 0.4139496088027954,
      "learning_rate": 0.0004719149690977666,
      "loss": 1.379,
      "step": 9970
    },
    {
      "epoch": 32.090177133655395,
      "grad_norm": 0.28974199295043945,
      "learning_rate": 0.00047185601601995787,
      "loss": 1.3763,
      "step": 9980
    },
    {
      "epoch": 32.12238325281803,
      "grad_norm": 0.24449913203716278,
      "learning_rate": 0.00047179700482327696,
      "loss": 1.3959,
      "step": 9990
    },
    {
      "epoch": 32.15458937198068,
      "grad_norm": 0.23529233038425446,
      "learning_rate": 0.00047173793552318297,
      "loss": 1.4014,
      "step": 10000
    },
    {
      "epoch": 32.186795491143315,
      "grad_norm": 0.2916155159473419,
      "learning_rate": 0.00047167880813514995,
      "loss": 1.3901,
      "step": 10010
    },
    {
      "epoch": 32.21900161030596,
      "grad_norm": 0.2827526032924652,
      "learning_rate": 0.00047161962267466736,
      "loss": 1.3933,
      "step": 10020
    },
    {
      "epoch": 32.2512077294686,
      "grad_norm": 0.2720605432987213,
      "learning_rate": 0.00047156037915723983,
      "loss": 1.4084,
      "step": 10030
    },
    {
      "epoch": 32.28341384863124,
      "grad_norm": 0.2664353847503662,
      "learning_rate": 0.00047150107759838717,
      "loss": 1.3684,
      "step": 10040
    },
    {
      "epoch": 32.31561996779388,
      "grad_norm": 0.2609650790691376,
      "learning_rate": 0.00047144171801364443,
      "loss": 1.4166,
      "step": 10050
    },
    {
      "epoch": 32.34782608695652,
      "grad_norm": 0.30306610465049744,
      "learning_rate": 0.0004713823004185618,
      "loss": 1.409,
      "step": 10060
    },
    {
      "epoch": 32.38003220611916,
      "grad_norm": 0.33245840668678284,
      "learning_rate": 0.0004713228248287048,
      "loss": 1.3998,
      "step": 10070
    },
    {
      "epoch": 32.412238325281805,
      "grad_norm": 0.248899444937706,
      "learning_rate": 0.00047126329125965385,
      "loss": 1.3964,
      "step": 10080
    },
    {
      "epoch": 32.44444444444444,
      "grad_norm": 0.25844573974609375,
      "learning_rate": 0.0004712036997270049,
      "loss": 1.407,
      "step": 10090
    },
    {
      "epoch": 32.47665056360709,
      "grad_norm": 0.3383541703224182,
      "learning_rate": 0.0004711440502463691,
      "loss": 1.4077,
      "step": 10100
    },
    {
      "epoch": 32.508856682769725,
      "grad_norm": 0.2722202241420746,
      "learning_rate": 0.0004710843428333723,
      "loss": 1.4218,
      "step": 10110
    },
    {
      "epoch": 32.54106280193237,
      "grad_norm": 0.29451772570610046,
      "learning_rate": 0.000471024577503656,
      "loss": 1.4036,
      "step": 10120
    },
    {
      "epoch": 32.57326892109501,
      "grad_norm": 0.31594419479370117,
      "learning_rate": 0.0004709647542728768,
      "loss": 1.3924,
      "step": 10130
    },
    {
      "epoch": 32.60547504025765,
      "grad_norm": 0.2982633411884308,
      "learning_rate": 0.0004709048731567063,
      "loss": 1.4044,
      "step": 10140
    },
    {
      "epoch": 32.63768115942029,
      "grad_norm": 0.395984411239624,
      "learning_rate": 0.0004708449341708313,
      "loss": 1.3741,
      "step": 10150
    },
    {
      "epoch": 32.669887278582934,
      "grad_norm": 0.25342637300491333,
      "learning_rate": 0.000470784937330954,
      "loss": 1.4143,
      "step": 10160
    },
    {
      "epoch": 32.70209339774557,
      "grad_norm": 0.30317428708076477,
      "learning_rate": 0.00047072488265279135,
      "loss": 1.3936,
      "step": 10170
    },
    {
      "epoch": 32.734299516908216,
      "grad_norm": 0.22657327353954315,
      "learning_rate": 0.00047066477015207577,
      "loss": 1.4099,
      "step": 10180
    },
    {
      "epoch": 32.76650563607085,
      "grad_norm": 0.32610419392585754,
      "learning_rate": 0.0004706045998445548,
      "loss": 1.3935,
      "step": 10190
    },
    {
      "epoch": 32.7987117552335,
      "grad_norm": 0.22963248193264008,
      "learning_rate": 0.00047054437174599096,
      "loss": 1.3906,
      "step": 10200
    },
    {
      "epoch": 32.830917874396135,
      "grad_norm": 0.28019365668296814,
      "learning_rate": 0.000470484085872162,
      "loss": 1.3859,
      "step": 10210
    },
    {
      "epoch": 32.86312399355877,
      "grad_norm": 0.23583848774433136,
      "learning_rate": 0.00047042374223886085,
      "loss": 1.4126,
      "step": 10220
    },
    {
      "epoch": 32.89533011272142,
      "grad_norm": 0.32686105370521545,
      "learning_rate": 0.0004703633408618955,
      "loss": 1.4011,
      "step": 10230
    },
    {
      "epoch": 32.927536231884055,
      "grad_norm": 0.24269451200962067,
      "learning_rate": 0.00047030288175708914,
      "loss": 1.4089,
      "step": 10240
    },
    {
      "epoch": 32.9597423510467,
      "grad_norm": 0.24537494778633118,
      "learning_rate": 0.00047024236494028,
      "loss": 1.4198,
      "step": 10250
    },
    {
      "epoch": 32.99194847020934,
      "grad_norm": 0.19047296047210693,
      "learning_rate": 0.00047018179042732143,
      "loss": 1.3972,
      "step": 10260
    },
    {
      "epoch": 33.0,
      "eval_loss": 0.644914984703064,
      "eval_runtime": 7.1161,
      "eval_samples_per_second": 3415.231,
      "eval_steps_per_second": 13.35,
      "step": 10263
    },
    {
      "epoch": 33.02254428341385,
      "grad_norm": 0.33051377534866333,
      "learning_rate": 0.000470121158234082,
      "loss": 1.3365,
      "step": 10270
    },
    {
      "epoch": 33.05475040257649,
      "grad_norm": 0.23955535888671875,
      "learning_rate": 0.00047006046837644533,
      "loss": 1.3958,
      "step": 10280
    },
    {
      "epoch": 33.08695652173913,
      "grad_norm": 0.2224087119102478,
      "learning_rate": 0.0004699997208703101,
      "loss": 1.4081,
      "step": 10290
    },
    {
      "epoch": 33.11916264090177,
      "grad_norm": 0.22258387506008148,
      "learning_rate": 0.00046993891573159004,
      "loss": 1.3913,
      "step": 10300
    },
    {
      "epoch": 33.151368760064415,
      "grad_norm": 0.25347381830215454,
      "learning_rate": 0.0004698780529762142,
      "loss": 1.4075,
      "step": 10310
    },
    {
      "epoch": 33.18357487922705,
      "grad_norm": 0.2568289637565613,
      "learning_rate": 0.00046981713262012656,
      "loss": 1.4171,
      "step": 10320
    },
    {
      "epoch": 33.2157809983897,
      "grad_norm": 0.20579324662685394,
      "learning_rate": 0.0004697561546792862,
      "loss": 1.3823,
      "step": 10330
    },
    {
      "epoch": 33.247987117552334,
      "grad_norm": 0.25227364897727966,
      "learning_rate": 0.00046969511916966736,
      "loss": 1.3917,
      "step": 10340
    },
    {
      "epoch": 33.28019323671498,
      "grad_norm": 0.2471579909324646,
      "learning_rate": 0.0004696340261072591,
      "loss": 1.3932,
      "step": 10350
    },
    {
      "epoch": 33.312399355877616,
      "grad_norm": 0.24753133952617645,
      "learning_rate": 0.0004695728755080661,
      "loss": 1.3787,
      "step": 10360
    },
    {
      "epoch": 33.34460547504026,
      "grad_norm": 0.2547573447227478,
      "learning_rate": 0.00046951166738810754,
      "loss": 1.4086,
      "step": 10370
    },
    {
      "epoch": 33.3768115942029,
      "grad_norm": 0.21866443753242493,
      "learning_rate": 0.0004694504017634179,
      "loss": 1.4201,
      "step": 10380
    },
    {
      "epoch": 33.409017713365536,
      "grad_norm": 0.3298514783382416,
      "learning_rate": 0.0004693890786500469,
      "loss": 1.4041,
      "step": 10390
    },
    {
      "epoch": 33.44122383252818,
      "grad_norm": 0.2571091949939728,
      "learning_rate": 0.00046932769806405894,
      "loss": 1.401,
      "step": 10400
    },
    {
      "epoch": 33.47342995169082,
      "grad_norm": 0.23012207448482513,
      "learning_rate": 0.0004692662600215339,
      "loss": 1.3924,
      "step": 10410
    },
    {
      "epoch": 33.50563607085346,
      "grad_norm": 0.23323369026184082,
      "learning_rate": 0.00046920476453856633,
      "loss": 1.3838,
      "step": 10420
    },
    {
      "epoch": 33.5378421900161,
      "grad_norm": 0.21915267407894135,
      "learning_rate": 0.00046914321163126605,
      "loss": 1.3876,
      "step": 10430
    },
    {
      "epoch": 33.570048309178745,
      "grad_norm": 0.2619079649448395,
      "learning_rate": 0.0004690816013157578,
      "loss": 1.4052,
      "step": 10440
    },
    {
      "epoch": 33.60225442834138,
      "grad_norm": 0.26405584812164307,
      "learning_rate": 0.0004690199336081816,
      "loss": 1.4183,
      "step": 10450
    },
    {
      "epoch": 33.63446054750403,
      "grad_norm": 0.2333861142396927,
      "learning_rate": 0.0004689582085246922,
      "loss": 1.3978,
      "step": 10460
    },
    {
      "epoch": 33.666666666666664,
      "grad_norm": 0.2674642503261566,
      "learning_rate": 0.00046889642608145945,
      "loss": 1.3924,
      "step": 10470
    },
    {
      "epoch": 33.69887278582931,
      "grad_norm": 0.25819912552833557,
      "learning_rate": 0.00046883458629466847,
      "loss": 1.4008,
      "step": 10480
    },
    {
      "epoch": 33.731078904991946,
      "grad_norm": 0.3471972942352295,
      "learning_rate": 0.0004687726891805191,
      "loss": 1.4146,
      "step": 10490
    },
    {
      "epoch": 33.76328502415459,
      "grad_norm": 0.34157702326774597,
      "learning_rate": 0.0004687107347552263,
      "loss": 1.4032,
      "step": 10500
    },
    {
      "epoch": 33.79549114331723,
      "grad_norm": 0.24819731712341309,
      "learning_rate": 0.00046864872303502015,
      "loss": 1.4001,
      "step": 10510
    },
    {
      "epoch": 33.82769726247987,
      "grad_norm": 0.3163784444332123,
      "learning_rate": 0.00046858665403614556,
      "loss": 1.3862,
      "step": 10520
    },
    {
      "epoch": 33.85990338164251,
      "grad_norm": 0.5103539228439331,
      "learning_rate": 0.0004685245277748626,
      "loss": 1.3974,
      "step": 10530
    },
    {
      "epoch": 33.892109500805155,
      "grad_norm": 0.3749309182167053,
      "learning_rate": 0.00046846234426744626,
      "loss": 1.3987,
      "step": 10540
    },
    {
      "epoch": 33.92431561996779,
      "grad_norm": 0.2861188054084778,
      "learning_rate": 0.00046840010353018654,
      "loss": 1.3947,
      "step": 10550
    },
    {
      "epoch": 33.95652173913044,
      "grad_norm": 0.6337875127792358,
      "learning_rate": 0.00046833780557938845,
      "loss": 1.3884,
      "step": 10560
    },
    {
      "epoch": 33.988727858293075,
      "grad_norm": 0.28020086884498596,
      "learning_rate": 0.000468275450431372,
      "loss": 1.3908,
      "step": 10570
    },
    {
      "epoch": 34.0,
      "eval_loss": 0.6458006501197815,
      "eval_runtime": 7.0812,
      "eval_samples_per_second": 3432.058,
      "eval_steps_per_second": 13.416,
      "step": 10574
    },
    {
      "epoch": 34.01932367149758,
      "grad_norm": 0.38558229804039,
      "learning_rate": 0.000468213038102472,
      "loss": 1.3238,
      "step": 10580
    },
    {
      "epoch": 34.051529790660226,
      "grad_norm": 0.362548828125,
      "learning_rate": 0.0004681505686090386,
      "loss": 1.3995,
      "step": 10590
    },
    {
      "epoch": 34.08373590982286,
      "grad_norm": 0.34684351086616516,
      "learning_rate": 0.0004680880419674366,
      "loss": 1.3974,
      "step": 10600
    },
    {
      "epoch": 34.11594202898551,
      "grad_norm": 0.40974217653274536,
      "learning_rate": 0.000468025458194046,
      "loss": 1.4002,
      "step": 10610
    },
    {
      "epoch": 34.148148148148145,
      "grad_norm": 0.29583704471588135,
      "learning_rate": 0.0004679628173052616,
      "loss": 1.3879,
      "step": 10620
    },
    {
      "epoch": 34.18035426731079,
      "grad_norm": 0.3361557126045227,
      "learning_rate": 0.0004679001193174931,
      "loss": 1.4038,
      "step": 10630
    },
    {
      "epoch": 34.21256038647343,
      "grad_norm": 0.324034720659256,
      "learning_rate": 0.0004678373642471655,
      "loss": 1.4082,
      "step": 10640
    },
    {
      "epoch": 34.24476650563607,
      "grad_norm": 0.31203529238700867,
      "learning_rate": 0.0004677745521107184,
      "loss": 1.3762,
      "step": 10650
    },
    {
      "epoch": 34.27697262479871,
      "grad_norm": 0.4169946610927582,
      "learning_rate": 0.0004677116829246065,
      "loss": 1.396,
      "step": 10660
    },
    {
      "epoch": 34.309178743961354,
      "grad_norm": 0.32024499773979187,
      "learning_rate": 0.0004676487567052995,
      "loss": 1.3953,
      "step": 10670
    },
    {
      "epoch": 34.34138486312399,
      "grad_norm": 0.32861611247062683,
      "learning_rate": 0.0004675857734692818,
      "loss": 1.38,
      "step": 10680
    },
    {
      "epoch": 34.373590982286636,
      "grad_norm": 0.31530138850212097,
      "learning_rate": 0.0004675227332330531,
      "loss": 1.4026,
      "step": 10690
    },
    {
      "epoch": 34.405797101449274,
      "grad_norm": 0.38318437337875366,
      "learning_rate": 0.00046745963601312773,
      "loss": 1.3836,
      "step": 10700
    },
    {
      "epoch": 34.43800322061192,
      "grad_norm": 0.33389943838119507,
      "learning_rate": 0.0004673964818260351,
      "loss": 1.4065,
      "step": 10710
    },
    {
      "epoch": 34.470209339774556,
      "grad_norm": 0.5568963885307312,
      "learning_rate": 0.0004673332706883194,
      "loss": 1.3824,
      "step": 10720
    },
    {
      "epoch": 34.5024154589372,
      "grad_norm": 0.3362477719783783,
      "learning_rate": 0.00046727000261654006,
      "loss": 1.4169,
      "step": 10730
    },
    {
      "epoch": 34.53462157809984,
      "grad_norm": 0.3181484341621399,
      "learning_rate": 0.000467206677627271,
      "loss": 1.4265,
      "step": 10740
    },
    {
      "epoch": 34.56682769726248,
      "grad_norm": 0.3432794213294983,
      "learning_rate": 0.00046714329573710125,
      "loss": 1.4041,
      "step": 10750
    },
    {
      "epoch": 34.59903381642512,
      "grad_norm": 0.3549642860889435,
      "learning_rate": 0.0004670798569626349,
      "loss": 1.3996,
      "step": 10760
    },
    {
      "epoch": 34.631239935587764,
      "grad_norm": 0.29336145520210266,
      "learning_rate": 0.0004670163613204906,
      "loss": 1.3936,
      "step": 10770
    },
    {
      "epoch": 34.6634460547504,
      "grad_norm": 0.2996690571308136,
      "learning_rate": 0.0004669528088273023,
      "loss": 1.3969,
      "step": 10780
    },
    {
      "epoch": 34.69565217391305,
      "grad_norm": 0.3360198140144348,
      "learning_rate": 0.0004668891994997185,
      "loss": 1.3892,
      "step": 10790
    },
    {
      "epoch": 34.727858293075684,
      "grad_norm": 0.32632264494895935,
      "learning_rate": 0.00046682553335440283,
      "loss": 1.4117,
      "step": 10800
    },
    {
      "epoch": 34.76006441223833,
      "grad_norm": 0.31290850043296814,
      "learning_rate": 0.00046676181040803343,
      "loss": 1.3999,
      "step": 10810
    },
    {
      "epoch": 34.792270531400966,
      "grad_norm": 0.29264819622039795,
      "learning_rate": 0.00046669803067730394,
      "loss": 1.4077,
      "step": 10820
    },
    {
      "epoch": 34.824476650563604,
      "grad_norm": 0.26397767663002014,
      "learning_rate": 0.0004666341941789223,
      "loss": 1.4168,
      "step": 10830
    },
    {
      "epoch": 34.85668276972625,
      "grad_norm": 0.22981813549995422,
      "learning_rate": 0.00046657030092961155,
      "loss": 1.3914,
      "step": 10840
    },
    {
      "epoch": 34.888888888888886,
      "grad_norm": 0.34071189165115356,
      "learning_rate": 0.00046650635094610973,
      "loss": 1.3848,
      "step": 10850
    },
    {
      "epoch": 34.92109500805153,
      "grad_norm": 0.24861082434654236,
      "learning_rate": 0.0004664423442451694,
      "loss": 1.3657,
      "step": 10860
    },
    {
      "epoch": 34.95330112721417,
      "grad_norm": 0.2520831525325775,
      "learning_rate": 0.00046637828084355825,
      "loss": 1.4102,
      "step": 10870
    },
    {
      "epoch": 34.98550724637681,
      "grad_norm": 0.3772149384021759,
      "learning_rate": 0.0004663141607580589,
      "loss": 1.3959,
      "step": 10880
    },
    {
      "epoch": 35.0,
      "eval_loss": 0.6474084854125977,
      "eval_runtime": 7.0763,
      "eval_samples_per_second": 3434.398,
      "eval_steps_per_second": 13.425,
      "step": 10885
    },
    {
      "epoch": 35.01610305958132,
      "grad_norm": 0.39593392610549927,
      "learning_rate": 0.00046624998400546854,
      "loss": 1.3296,
      "step": 10890
    },
    {
      "epoch": 35.04830917874396,
      "grad_norm": 0.26464319229125977,
      "learning_rate": 0.0004661857506025993,
      "loss": 1.4053,
      "step": 10900
    },
    {
      "epoch": 35.0805152979066,
      "grad_norm": 0.21370342373847961,
      "learning_rate": 0.0004661214605662783,
      "loss": 1.4095,
      "step": 10910
    },
    {
      "epoch": 35.112721417069245,
      "grad_norm": 0.2721054255962372,
      "learning_rate": 0.00046605711391334726,
      "loss": 1.3895,
      "step": 10920
    },
    {
      "epoch": 35.14492753623188,
      "grad_norm": 0.2747138440608978,
      "learning_rate": 0.000465992710660663,
      "loss": 1.4025,
      "step": 10930
    },
    {
      "epoch": 35.17713365539453,
      "grad_norm": 0.254687637090683,
      "learning_rate": 0.0004659282508250969,
      "loss": 1.396,
      "step": 10940
    },
    {
      "epoch": 35.209339774557165,
      "grad_norm": 0.34285831451416016,
      "learning_rate": 0.00046586373442353534,
      "loss": 1.3729,
      "step": 10950
    },
    {
      "epoch": 35.24154589371981,
      "grad_norm": 0.3222384750843048,
      "learning_rate": 0.0004657991614728795,
      "loss": 1.3824,
      "step": 10960
    },
    {
      "epoch": 35.27375201288245,
      "grad_norm": 0.3188832104206085,
      "learning_rate": 0.00046573453199004526,
      "loss": 1.4075,
      "step": 10970
    },
    {
      "epoch": 35.30595813204509,
      "grad_norm": 0.3108741343021393,
      "learning_rate": 0.00046566984599196343,
      "loss": 1.4003,
      "step": 10980
    },
    {
      "epoch": 35.33816425120773,
      "grad_norm": 0.2813665568828583,
      "learning_rate": 0.0004656051034955796,
      "loss": 1.3881,
      "step": 10990
    },
    {
      "epoch": 35.370370370370374,
      "grad_norm": 0.43955445289611816,
      "learning_rate": 0.00046554030451785404,
      "loss": 1.3839,
      "step": 11000
    },
    {
      "epoch": 35.40257648953301,
      "grad_norm": 0.2691418528556824,
      "learning_rate": 0.00046547544907576206,
      "loss": 1.3723,
      "step": 11010
    },
    {
      "epoch": 35.43478260869565,
      "grad_norm": 0.26451215147972107,
      "learning_rate": 0.0004654105371862936,
      "loss": 1.4174,
      "step": 11020
    },
    {
      "epoch": 35.46698872785829,
      "grad_norm": 0.2827233672142029,
      "learning_rate": 0.0004653455688664533,
      "loss": 1.4039,
      "step": 11030
    },
    {
      "epoch": 35.49919484702093,
      "grad_norm": 0.302864670753479,
      "learning_rate": 0.0004652805441332607,
      "loss": 1.405,
      "step": 11040
    },
    {
      "epoch": 35.531400966183575,
      "grad_norm": 0.24109122157096863,
      "learning_rate": 0.0004652154630037503,
      "loss": 1.3986,
      "step": 11050
    },
    {
      "epoch": 35.56360708534621,
      "grad_norm": 0.26988592743873596,
      "learning_rate": 0.00046515032549497093,
      "loss": 1.3943,
      "step": 11060
    },
    {
      "epoch": 35.59581320450886,
      "grad_norm": 0.20870010554790497,
      "learning_rate": 0.0004650851316239867,
      "loss": 1.421,
      "step": 11070
    },
    {
      "epoch": 35.628019323671495,
      "grad_norm": 0.20248505473136902,
      "learning_rate": 0.000465019881407876,
      "loss": 1.4058,
      "step": 11080
    },
    {
      "epoch": 35.66022544283414,
      "grad_norm": 0.2431572526693344,
      "learning_rate": 0.0004649545748637323,
      "loss": 1.3857,
      "step": 11090
    },
    {
      "epoch": 35.69243156199678,
      "grad_norm": 0.235902339220047,
      "learning_rate": 0.0004648892120086638,
      "loss": 1.4022,
      "step": 11100
    },
    {
      "epoch": 35.72463768115942,
      "grad_norm": 0.24877607822418213,
      "learning_rate": 0.0004648237928597933,
      "loss": 1.4118,
      "step": 11110
    },
    {
      "epoch": 35.75684380032206,
      "grad_norm": 0.23956875503063202,
      "learning_rate": 0.00046475831743425847,
      "loss": 1.3849,
      "step": 11120
    },
    {
      "epoch": 35.789049919484704,
      "grad_norm": 0.2455136924982071,
      "learning_rate": 0.0004646927857492117,
      "loss": 1.389,
      "step": 11130
    },
    {
      "epoch": 35.82125603864734,
      "grad_norm": 0.2937189042568207,
      "learning_rate": 0.00046462719782182,
      "loss": 1.4008,
      "step": 11140
    },
    {
      "epoch": 35.853462157809986,
      "grad_norm": 0.304567813873291,
      "learning_rate": 0.00046456155366926533,
      "loss": 1.3853,
      "step": 11150
    },
    {
      "epoch": 35.88566827697262,
      "grad_norm": 0.29406383633613586,
      "learning_rate": 0.0004644958533087443,
      "loss": 1.4087,
      "step": 11160
    },
    {
      "epoch": 35.91787439613527,
      "grad_norm": 0.22675397992134094,
      "learning_rate": 0.0004644300967574681,
      "loss": 1.3988,
      "step": 11170
    },
    {
      "epoch": 35.950080515297905,
      "grad_norm": 0.25961872935295105,
      "learning_rate": 0.0004643642840326627,
      "loss": 1.3926,
      "step": 11180
    },
    {
      "epoch": 35.98228663446055,
      "grad_norm": 0.2660083770751953,
      "learning_rate": 0.00046429841515156913,
      "loss": 1.3873,
      "step": 11190
    },
    {
      "epoch": 36.0,
      "eval_loss": 0.6436715126037598,
      "eval_runtime": 7.0845,
      "eval_samples_per_second": 3430.427,
      "eval_steps_per_second": 13.409,
      "step": 11196
    },
    {
      "epoch": 36.012882447665056,
      "grad_norm": 0.41201239824295044,
      "learning_rate": 0.0004642324901314425,
      "loss": 1.3205,
      "step": 11200
    },
    {
      "epoch": 36.045088566827694,
      "grad_norm": 0.2492692619562149,
      "learning_rate": 0.00046416650898955316,
      "loss": 1.4122,
      "step": 11210
    },
    {
      "epoch": 36.07729468599034,
      "grad_norm": 0.2866324782371521,
      "learning_rate": 0.0004641004717431859,
      "loss": 1.389,
      "step": 11220
    },
    {
      "epoch": 36.109500805152976,
      "grad_norm": 0.3180396556854248,
      "learning_rate": 0.00046403437840964037,
      "loss": 1.3879,
      "step": 11230
    },
    {
      "epoch": 36.14170692431562,
      "grad_norm": 0.2494661808013916,
      "learning_rate": 0.0004639682290062307,
      "loss": 1.3873,
      "step": 11240
    },
    {
      "epoch": 36.17391304347826,
      "grad_norm": 0.25834348797798157,
      "learning_rate": 0.0004639020235502859,
      "loss": 1.3821,
      "step": 11250
    },
    {
      "epoch": 36.2061191626409,
      "grad_norm": 0.2408941090106964,
      "learning_rate": 0.00046383576205914946,
      "loss": 1.3818,
      "step": 11260
    },
    {
      "epoch": 36.23832528180354,
      "grad_norm": 0.22603558003902435,
      "learning_rate": 0.00046376944455017976,
      "loss": 1.4091,
      "step": 11270
    },
    {
      "epoch": 36.270531400966185,
      "grad_norm": 0.24568648636341095,
      "learning_rate": 0.00046370307104074993,
      "loss": 1.4036,
      "step": 11280
    },
    {
      "epoch": 36.30273752012882,
      "grad_norm": 0.23874229192733765,
      "learning_rate": 0.0004636366415482474,
      "loss": 1.3794,
      "step": 11290
    },
    {
      "epoch": 36.33494363929147,
      "grad_norm": 0.24606657028198242,
      "learning_rate": 0.0004635701560900745,
      "loss": 1.4009,
      "step": 11300
    },
    {
      "epoch": 36.367149758454104,
      "grad_norm": 0.298115611076355,
      "learning_rate": 0.0004635036146836483,
      "loss": 1.3941,
      "step": 11310
    },
    {
      "epoch": 36.39935587761675,
      "grad_norm": 0.20289930701255798,
      "learning_rate": 0.00046343701734640044,
      "loss": 1.3814,
      "step": 11320
    },
    {
      "epoch": 36.43156199677939,
      "grad_norm": 0.2293018251657486,
      "learning_rate": 0.000463370364095777,
      "loss": 1.375,
      "step": 11330
    },
    {
      "epoch": 36.46376811594203,
      "grad_norm": 0.1985125094652176,
      "learning_rate": 0.0004633036549492392,
      "loss": 1.4007,
      "step": 11340
    },
    {
      "epoch": 36.49597423510467,
      "grad_norm": 0.23474399745464325,
      "learning_rate": 0.00046323688992426244,
      "loss": 1.3911,
      "step": 11350
    },
    {
      "epoch": 36.52818035426731,
      "grad_norm": 0.26862311363220215,
      "learning_rate": 0.0004631700690383369,
      "loss": 1.4002,
      "step": 11360
    },
    {
      "epoch": 36.56038647342995,
      "grad_norm": 0.2590104639530182,
      "learning_rate": 0.00046310319230896744,
      "loss": 1.4015,
      "step": 11370
    },
    {
      "epoch": 36.592592592592595,
      "grad_norm": 0.2271191030740738,
      "learning_rate": 0.00046303625975367365,
      "loss": 1.3863,
      "step": 11380
    },
    {
      "epoch": 36.62479871175523,
      "grad_norm": 0.2778213322162628,
      "learning_rate": 0.00046296927138998945,
      "loss": 1.4005,
      "step": 11390
    },
    {
      "epoch": 36.65700483091788,
      "grad_norm": 0.3913595676422119,
      "learning_rate": 0.0004629022272354637,
      "loss": 1.4091,
      "step": 11400
    },
    {
      "epoch": 36.689210950080515,
      "grad_norm": 0.21889054775238037,
      "learning_rate": 0.0004628351273076597,
      "loss": 1.3989,
      "step": 11410
    },
    {
      "epoch": 36.72141706924316,
      "grad_norm": 0.30883485078811646,
      "learning_rate": 0.0004627679716241553,
      "loss": 1.4042,
      "step": 11420
    },
    {
      "epoch": 36.7536231884058,
      "grad_norm": 0.36388030648231506,
      "learning_rate": 0.00046270076020254314,
      "loss": 1.4037,
      "step": 11430
    },
    {
      "epoch": 36.78582930756844,
      "grad_norm": 0.24194326996803284,
      "learning_rate": 0.0004626334930604303,
      "loss": 1.381,
      "step": 11440
    },
    {
      "epoch": 36.81803542673108,
      "grad_norm": 0.2588423788547516,
      "learning_rate": 0.00046256617021543867,
      "loss": 1.4062,
      "step": 11450
    },
    {
      "epoch": 36.85024154589372,
      "grad_norm": 0.2353362739086151,
      "learning_rate": 0.00046249879168520447,
      "loss": 1.3874,
      "step": 11460
    },
    {
      "epoch": 36.88244766505636,
      "grad_norm": 0.2504693269729614,
      "learning_rate": 0.00046243135748737864,
      "loss": 1.4117,
      "step": 11470
    },
    {
      "epoch": 36.914653784219,
      "grad_norm": 0.27130183577537537,
      "learning_rate": 0.0004623638676396266,
      "loss": 1.3847,
      "step": 11480
    },
    {
      "epoch": 36.94685990338164,
      "grad_norm": 0.2561824917793274,
      "learning_rate": 0.0004622963221596286,
      "loss": 1.382,
      "step": 11490
    },
    {
      "epoch": 36.97906602254428,
      "grad_norm": 0.28372323513031006,
      "learning_rate": 0.00046222872106507925,
      "loss": 1.4138,
      "step": 11500
    },
    {
      "epoch": 37.0,
      "eval_loss": 0.6412056684494019,
      "eval_runtime": 7.0642,
      "eval_samples_per_second": 3440.281,
      "eval_steps_per_second": 13.448,
      "step": 11507
    },
    {
      "epoch": 37.009661835748794,
      "grad_norm": 0.2812618911266327,
      "learning_rate": 0.00046216106437368775,
      "loss": 1.3307,
      "step": 11510
    },
    {
      "epoch": 37.04186795491143,
      "grad_norm": 0.28723934292793274,
      "learning_rate": 0.00046209335210317795,
      "loss": 1.4336,
      "step": 11520
    },
    {
      "epoch": 37.074074074074076,
      "grad_norm": 0.2914220094680786,
      "learning_rate": 0.00046202558427128806,
      "loss": 1.4017,
      "step": 11530
    },
    {
      "epoch": 37.106280193236714,
      "grad_norm": 0.21693304181098938,
      "learning_rate": 0.0004619577608957711,
      "loss": 1.4179,
      "step": 11540
    },
    {
      "epoch": 37.13848631239936,
      "grad_norm": 0.24088351428508759,
      "learning_rate": 0.0004618898819943946,
      "loss": 1.3804,
      "step": 11550
    },
    {
      "epoch": 37.170692431561996,
      "grad_norm": 0.2706131637096405,
      "learning_rate": 0.0004618219475849405,
      "loss": 1.4029,
      "step": 11560
    },
    {
      "epoch": 37.20289855072464,
      "grad_norm": 0.2706097662448883,
      "learning_rate": 0.00046175395768520536,
      "loss": 1.3964,
      "step": 11570
    },
    {
      "epoch": 37.23510466988728,
      "grad_norm": 0.263223797082901,
      "learning_rate": 0.0004616859123130002,
      "loss": 1.3896,
      "step": 11580
    },
    {
      "epoch": 37.26731078904992,
      "grad_norm": 0.24555373191833496,
      "learning_rate": 0.0004616178114861507,
      "loss": 1.3979,
      "step": 11590
    },
    {
      "epoch": 37.29951690821256,
      "grad_norm": 0.7194082140922546,
      "learning_rate": 0.00046154965522249693,
      "loss": 1.398,
      "step": 11600
    },
    {
      "epoch": 37.331723027375205,
      "grad_norm": 0.24226908385753632,
      "learning_rate": 0.00046148144353989364,
      "loss": 1.4029,
      "step": 11610
    },
    {
      "epoch": 37.36392914653784,
      "grad_norm": 0.24228742718696594,
      "learning_rate": 0.0004614131764562099,
      "loss": 1.3843,
      "step": 11620
    },
    {
      "epoch": 37.39613526570048,
      "grad_norm": 0.2417072355747223,
      "learning_rate": 0.00046134485398932964,
      "loss": 1.3787,
      "step": 11630
    },
    {
      "epoch": 37.428341384863124,
      "grad_norm": 0.25813934206962585,
      "learning_rate": 0.00046127647615715086,
      "loss": 1.3894,
      "step": 11640
    },
    {
      "epoch": 37.46054750402576,
      "grad_norm": 0.2694825828075409,
      "learning_rate": 0.00046120804297758634,
      "loss": 1.4021,
      "step": 11650
    },
    {
      "epoch": 37.492753623188406,
      "grad_norm": 0.22464148700237274,
      "learning_rate": 0.00046113955446856324,
      "loss": 1.3848,
      "step": 11660
    },
    {
      "epoch": 37.524959742351044,
      "grad_norm": 0.2521652281284332,
      "learning_rate": 0.0004610710106480234,
      "loss": 1.3976,
      "step": 11670
    },
    {
      "epoch": 37.55716586151369,
      "grad_norm": 0.27889159321784973,
      "learning_rate": 0.00046100241153392284,
      "loss": 1.4048,
      "step": 11680
    },
    {
      "epoch": 37.589371980676326,
      "grad_norm": 0.23447616398334503,
      "learning_rate": 0.00046093375714423236,
      "loss": 1.3822,
      "step": 11690
    },
    {
      "epoch": 37.62157809983897,
      "grad_norm": 0.2449360489845276,
      "learning_rate": 0.000460865047496937,
      "loss": 1.3878,
      "step": 11700
    },
    {
      "epoch": 37.65378421900161,
      "grad_norm": 0.28071051836013794,
      "learning_rate": 0.0004607962826100365,
      "loss": 1.4003,
      "step": 11710
    },
    {
      "epoch": 37.68599033816425,
      "grad_norm": 0.5954666137695312,
      "learning_rate": 0.00046072746250154495,
      "loss": 1.3899,
      "step": 11720
    },
    {
      "epoch": 37.71819645732689,
      "grad_norm": 0.2528994679450989,
      "learning_rate": 0.00046065858718949095,
      "loss": 1.409,
      "step": 11730
    },
    {
      "epoch": 37.750402576489535,
      "grad_norm": 0.2786107063293457,
      "learning_rate": 0.00046058965669191744,
      "loss": 1.3821,
      "step": 11740
    },
    {
      "epoch": 37.78260869565217,
      "grad_norm": 0.28573840856552124,
      "learning_rate": 0.00046052067102688186,
      "loss": 1.392,
      "step": 11750
    },
    {
      "epoch": 37.81481481481482,
      "grad_norm": 0.24212028086185455,
      "learning_rate": 0.0004604516302124564,
      "loss": 1.3934,
      "step": 11760
    },
    {
      "epoch": 37.847020933977454,
      "grad_norm": 0.30656716227531433,
      "learning_rate": 0.0004603825342667273,
      "loss": 1.3962,
      "step": 11770
    },
    {
      "epoch": 37.8792270531401,
      "grad_norm": 0.23840536177158356,
      "learning_rate": 0.0004603133832077953,
      "loss": 1.362,
      "step": 11780
    },
    {
      "epoch": 37.911433172302736,
      "grad_norm": 0.30495598912239075,
      "learning_rate": 0.0004602441770537758,
      "loss": 1.3811,
      "step": 11790
    },
    {
      "epoch": 37.94363929146538,
      "grad_norm": 0.3125704526901245,
      "learning_rate": 0.00046017491582279845,
      "loss": 1.4008,
      "step": 11800
    },
    {
      "epoch": 37.97584541062802,
      "grad_norm": 0.4406016767024994,
      "learning_rate": 0.0004601055995330075,
      "loss": 1.3891,
      "step": 11810
    },
    {
      "epoch": 38.0,
      "eval_loss": 0.6430474519729614,
      "eval_runtime": 7.2404,
      "eval_samples_per_second": 3356.595,
      "eval_steps_per_second": 13.121,
      "step": 11818
    },
    {
      "epoch": 38.006441223832525,
      "grad_norm": 0.3290843069553375,
      "learning_rate": 0.00046003622820256127,
      "loss": 1.3274,
      "step": 11820
    },
    {
      "epoch": 38.03864734299517,
      "grad_norm": 0.3415166437625885,
      "learning_rate": 0.00045996680184963294,
      "loss": 1.3893,
      "step": 11830
    },
    {
      "epoch": 38.07085346215781,
      "grad_norm": 0.35899460315704346,
      "learning_rate": 0.00045989732049240976,
      "loss": 1.3962,
      "step": 11840
    },
    {
      "epoch": 38.10305958132045,
      "grad_norm": 0.39130115509033203,
      "learning_rate": 0.00045982778414909353,
      "loss": 1.3779,
      "step": 11850
    },
    {
      "epoch": 38.13526570048309,
      "grad_norm": 0.28152209520339966,
      "learning_rate": 0.00045975819283790065,
      "loss": 1.3704,
      "step": 11860
    },
    {
      "epoch": 38.16747181964573,
      "grad_norm": 0.41182029247283936,
      "learning_rate": 0.0004596885465770615,
      "loss": 1.3878,
      "step": 11870
    },
    {
      "epoch": 38.19967793880837,
      "grad_norm": 0.3635933995246887,
      "learning_rate": 0.0004596188453848212,
      "loss": 1.4005,
      "step": 11880
    },
    {
      "epoch": 38.231884057971016,
      "grad_norm": 0.31929832696914673,
      "learning_rate": 0.00045954908927943905,
      "loss": 1.4117,
      "step": 11890
    },
    {
      "epoch": 38.26409017713365,
      "grad_norm": 0.2811014652252197,
      "learning_rate": 0.0004594792782791889,
      "loss": 1.3636,
      "step": 11900
    },
    {
      "epoch": 38.2962962962963,
      "grad_norm": 0.29604873061180115,
      "learning_rate": 0.0004594094124023588,
      "loss": 1.4093,
      "step": 11910
    },
    {
      "epoch": 38.328502415458935,
      "grad_norm": 0.2657112181186676,
      "learning_rate": 0.0004593394916672514,
      "loss": 1.3847,
      "step": 11920
    },
    {
      "epoch": 38.36070853462158,
      "grad_norm": 0.302175909280777,
      "learning_rate": 0.0004592695160921836,
      "loss": 1.3935,
      "step": 11930
    },
    {
      "epoch": 38.39291465378422,
      "grad_norm": 0.2958369851112366,
      "learning_rate": 0.0004591994856954865,
      "loss": 1.3723,
      "step": 11940
    },
    {
      "epoch": 38.42512077294686,
      "grad_norm": 0.231694757938385,
      "learning_rate": 0.0004591294004955059,
      "loss": 1.3852,
      "step": 11950
    },
    {
      "epoch": 38.4573268921095,
      "grad_norm": 0.3082444965839386,
      "learning_rate": 0.0004590592605106017,
      "loss": 1.3813,
      "step": 11960
    },
    {
      "epoch": 38.489533011272144,
      "grad_norm": 0.28219085931777954,
      "learning_rate": 0.0004589890657591482,
      "loss": 1.4175,
      "step": 11970
    },
    {
      "epoch": 38.52173913043478,
      "grad_norm": 0.27678966522216797,
      "learning_rate": 0.00045891881625953425,
      "loss": 1.401,
      "step": 11980
    },
    {
      "epoch": 38.553945249597426,
      "grad_norm": 0.28305989503860474,
      "learning_rate": 0.00045884851203016266,
      "loss": 1.3792,
      "step": 11990
    },
    {
      "epoch": 38.58615136876006,
      "grad_norm": 0.4658315181732178,
      "learning_rate": 0.0004587781530894509,
      "loss": 1.3776,
      "step": 12000
    },
    {
      "epoch": 38.61835748792271,
      "grad_norm": 0.22098109126091003,
      "learning_rate": 0.0004587077394558307,
      "loss": 1.3935,
      "step": 12010
    },
    {
      "epoch": 38.650563607085346,
      "grad_norm": 0.29404911398887634,
      "learning_rate": 0.00045863727114774805,
      "loss": 1.3859,
      "step": 12020
    },
    {
      "epoch": 38.68276972624799,
      "grad_norm": 0.2970823645591736,
      "learning_rate": 0.0004585667481836633,
      "loss": 1.4016,
      "step": 12030
    },
    {
      "epoch": 38.71497584541063,
      "grad_norm": 0.33487632870674133,
      "learning_rate": 0.000458496170582051,
      "loss": 1.4044,
      "step": 12040
    },
    {
      "epoch": 38.74718196457327,
      "grad_norm": 0.23596541583538055,
      "learning_rate": 0.0004584255383614003,
      "loss": 1.3975,
      "step": 12050
    },
    {
      "epoch": 38.77938808373591,
      "grad_norm": 0.2401226907968521,
      "learning_rate": 0.0004583548515402144,
      "loss": 1.4146,
      "step": 12060
    },
    {
      "epoch": 38.81159420289855,
      "grad_norm": 0.28375867009162903,
      "learning_rate": 0.0004582841101370109,
      "loss": 1.4046,
      "step": 12070
    },
    {
      "epoch": 38.84380032206119,
      "grad_norm": 0.27551373839378357,
      "learning_rate": 0.00045821331417032166,
      "loss": 1.3878,
      "step": 12080
    },
    {
      "epoch": 38.87600644122383,
      "grad_norm": 0.20835018157958984,
      "learning_rate": 0.00045814246365869285,
      "loss": 1.3923,
      "step": 12090
    },
    {
      "epoch": 38.908212560386474,
      "grad_norm": 0.26828092336654663,
      "learning_rate": 0.0004580715586206851,
      "loss": 1.4015,
      "step": 12100
    },
    {
      "epoch": 38.94041867954911,
      "grad_norm": 0.2943337559700012,
      "learning_rate": 0.00045800059907487284,
      "loss": 1.4047,
      "step": 12110
    },
    {
      "epoch": 38.972624798711756,
      "grad_norm": 0.23225823044776917,
      "learning_rate": 0.0004579295850398454,
      "loss": 1.4302,
      "step": 12120
    },
    {
      "epoch": 39.0,
      "eval_loss": 0.6447542905807495,
      "eval_runtime": 7.1002,
      "eval_samples_per_second": 3422.84,
      "eval_steps_per_second": 13.38,
      "step": 12129
    },
    {
      "epoch": 39.00322061191626,
      "grad_norm": 0.2297549545764923,
      "learning_rate": 0.00045785851653420604,
      "loss": 1.3273,
      "step": 12130
    },
    {
      "epoch": 39.03542673107891,
      "grad_norm": 0.2813861668109894,
      "learning_rate": 0.0004577873935765722,
      "loss": 1.3884,
      "step": 12140
    },
    {
      "epoch": 39.067632850241544,
      "grad_norm": 0.2365788072347641,
      "learning_rate": 0.0004577162161855758,
      "loss": 1.4084,
      "step": 12150
    },
    {
      "epoch": 39.09983896940419,
      "grad_norm": 0.2888905704021454,
      "learning_rate": 0.000457644984379863,
      "loss": 1.3999,
      "step": 12160
    },
    {
      "epoch": 39.13204508856683,
      "grad_norm": 0.2711615264415741,
      "learning_rate": 0.00045757369817809413,
      "loss": 1.3685,
      "step": 12170
    },
    {
      "epoch": 39.16425120772947,
      "grad_norm": 0.23016729950904846,
      "learning_rate": 0.00045750235759894366,
      "loss": 1.3975,
      "step": 12180
    },
    {
      "epoch": 39.19645732689211,
      "grad_norm": 0.2557474374771118,
      "learning_rate": 0.0004574309626611006,
      "loss": 1.4054,
      "step": 12190
    },
    {
      "epoch": 39.22866344605475,
      "grad_norm": 0.23401884734630585,
      "learning_rate": 0.00045735951338326804,
      "loss": 1.3923,
      "step": 12200
    },
    {
      "epoch": 39.26086956521739,
      "grad_norm": 0.2592778503894806,
      "learning_rate": 0.0004572880097841632,
      "loss": 1.4016,
      "step": 12210
    },
    {
      "epoch": 39.293075684380035,
      "grad_norm": 0.2725060284137726,
      "learning_rate": 0.0004572164518825177,
      "loss": 1.4031,
      "step": 12220
    },
    {
      "epoch": 39.32528180354267,
      "grad_norm": 0.3192499279975891,
      "learning_rate": 0.0004571448396970773,
      "loss": 1.3815,
      "step": 12230
    },
    {
      "epoch": 39.35748792270532,
      "grad_norm": 0.27061718702316284,
      "learning_rate": 0.000457073173246602,
      "loss": 1.4165,
      "step": 12240
    },
    {
      "epoch": 39.389694041867955,
      "grad_norm": 0.247251495718956,
      "learning_rate": 0.00045700145254986614,
      "loss": 1.3669,
      "step": 12250
    },
    {
      "epoch": 39.42190016103059,
      "grad_norm": 0.2817343473434448,
      "learning_rate": 0.00045692967762565797,
      "loss": 1.3847,
      "step": 12260
    },
    {
      "epoch": 39.45410628019324,
      "grad_norm": 0.25533410906791687,
      "learning_rate": 0.0004568578484927802,
      "loss": 1.3966,
      "step": 12270
    },
    {
      "epoch": 39.486312399355874,
      "grad_norm": 0.22768783569335938,
      "learning_rate": 0.00045678596517004965,
      "loss": 1.3914,
      "step": 12280
    },
    {
      "epoch": 39.51851851851852,
      "grad_norm": 0.3286890983581543,
      "learning_rate": 0.00045671402767629733,
      "loss": 1.3886,
      "step": 12290
    },
    {
      "epoch": 39.55072463768116,
      "grad_norm": 0.2473941296339035,
      "learning_rate": 0.00045664203603036857,
      "loss": 1.3914,
      "step": 12300
    },
    {
      "epoch": 39.5829307568438,
      "grad_norm": 0.3502262830734253,
      "learning_rate": 0.0004565699902511227,
      "loss": 1.3814,
      "step": 12310
    },
    {
      "epoch": 39.61513687600644,
      "grad_norm": 0.24517883360385895,
      "learning_rate": 0.0004564978903574333,
      "loss": 1.3888,
      "step": 12320
    },
    {
      "epoch": 39.64734299516908,
      "grad_norm": 0.2857411205768585,
      "learning_rate": 0.0004564257363681881,
      "loss": 1.3781,
      "step": 12330
    },
    {
      "epoch": 39.67954911433172,
      "grad_norm": 0.2759784162044525,
      "learning_rate": 0.0004563535283022892,
      "loss": 1.4058,
      "step": 12340
    },
    {
      "epoch": 39.711755233494365,
      "grad_norm": 0.19876410067081451,
      "learning_rate": 0.00045628126617865253,
      "loss": 1.3931,
      "step": 12350
    },
    {
      "epoch": 39.743961352657,
      "grad_norm": 0.2469865083694458,
      "learning_rate": 0.0004562089500162084,
      "loss": 1.3859,
      "step": 12360
    },
    {
      "epoch": 39.77616747181965,
      "grad_norm": 0.28213953971862793,
      "learning_rate": 0.00045613657983390127,
      "loss": 1.3754,
      "step": 12370
    },
    {
      "epoch": 39.808373590982285,
      "grad_norm": 0.2619170844554901,
      "learning_rate": 0.0004560641556506897,
      "loss": 1.4012,
      "step": 12380
    },
    {
      "epoch": 39.84057971014493,
      "grad_norm": 0.2726370096206665,
      "learning_rate": 0.0004559916774855464,
      "loss": 1.4165,
      "step": 12390
    },
    {
      "epoch": 39.87278582930757,
      "grad_norm": 0.2861132323741913,
      "learning_rate": 0.0004559191453574582,
      "loss": 1.3892,
      "step": 12400
    },
    {
      "epoch": 39.90499194847021,
      "grad_norm": 0.28387394547462463,
      "learning_rate": 0.00045584655928542617,
      "loss": 1.401,
      "step": 12410
    },
    {
      "epoch": 39.93719806763285,
      "grad_norm": 0.2841750979423523,
      "learning_rate": 0.00045577391928846537,
      "loss": 1.3719,
      "step": 12420
    },
    {
      "epoch": 39.969404186795494,
      "grad_norm": 0.2128843516111374,
      "learning_rate": 0.0004557012253856051,
      "loss": 1.3679,
      "step": 12430
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.33284345269203186,
      "learning_rate": 0.00045562847759588864,
      "loss": 1.3345,
      "step": 12440
    },
    {
      "epoch": 40.0,
      "eval_loss": 0.6427592039108276,
      "eval_runtime": 7.0975,
      "eval_samples_per_second": 3424.171,
      "eval_steps_per_second": 13.385,
      "step": 12440
    },
    {
      "epoch": 40.03220611916264,
      "grad_norm": 0.2328856885433197,
      "learning_rate": 0.00045555567593837364,
      "loss": 1.3855,
      "step": 12450
    },
    {
      "epoch": 40.06441223832528,
      "grad_norm": 0.3336922824382782,
      "learning_rate": 0.00045548282043213163,
      "loss": 1.3919,
      "step": 12460
    },
    {
      "epoch": 40.09661835748792,
      "grad_norm": 0.26919808983802795,
      "learning_rate": 0.0004554099110962483,
      "loss": 1.3984,
      "step": 12470
    },
    {
      "epoch": 40.128824476650564,
      "grad_norm": 0.23832082748413086,
      "learning_rate": 0.0004553369479498235,
      "loss": 1.4059,
      "step": 12480
    },
    {
      "epoch": 40.1610305958132,
      "grad_norm": 0.3340868055820465,
      "learning_rate": 0.00045526393101197104,
      "loss": 1.403,
      "step": 12490
    },
    {
      "epoch": 40.193236714975846,
      "grad_norm": 0.3153804838657379,
      "learning_rate": 0.0004551908603018191,
      "loss": 1.3895,
      "step": 12500
    },
    {
      "epoch": 40.225442834138484,
      "grad_norm": 0.32081273198127747,
      "learning_rate": 0.00045511773583850964,
      "loss": 1.3861,
      "step": 12510
    },
    {
      "epoch": 40.25764895330113,
      "grad_norm": 0.32590577006340027,
      "learning_rate": 0.0004550445576411988,
      "loss": 1.3783,
      "step": 12520
    },
    {
      "epoch": 40.289855072463766,
      "grad_norm": 0.30274319648742676,
      "learning_rate": 0.000454971325729057,
      "loss": 1.3958,
      "step": 12530
    },
    {
      "epoch": 40.32206119162641,
      "grad_norm": 0.24735750257968903,
      "learning_rate": 0.0004548980401212683,
      "loss": 1.3891,
      "step": 12540
    },
    {
      "epoch": 40.35426731078905,
      "grad_norm": 0.26392391324043274,
      "learning_rate": 0.00045482470083703125,
      "loss": 1.3891,
      "step": 12550
    },
    {
      "epoch": 40.38647342995169,
      "grad_norm": 0.26558777689933777,
      "learning_rate": 0.0004547513078955583,
      "loss": 1.3755,
      "step": 12560
    },
    {
      "epoch": 40.41867954911433,
      "grad_norm": 0.25926658511161804,
      "learning_rate": 0.00045467786131607593,
      "loss": 1.3884,
      "step": 12570
    },
    {
      "epoch": 40.450885668276975,
      "grad_norm": 0.4612464904785156,
      "learning_rate": 0.00045460436111782466,
      "loss": 1.4125,
      "step": 12580
    },
    {
      "epoch": 40.48309178743961,
      "grad_norm": 0.29361075162887573,
      "learning_rate": 0.00045453080732005914,
      "loss": 1.3952,
      "step": 12590
    },
    {
      "epoch": 40.51529790660226,
      "grad_norm": 0.23374487459659576,
      "learning_rate": 0.0004544571999420479,
      "loss": 1.3846,
      "step": 12600
    },
    {
      "epoch": 40.547504025764894,
      "grad_norm": 0.33044612407684326,
      "learning_rate": 0.00045438353900307377,
      "loss": 1.3995,
      "step": 12610
    },
    {
      "epoch": 40.57971014492754,
      "grad_norm": 0.2331305593252182,
      "learning_rate": 0.0004543098245224334,
      "loss": 1.397,
      "step": 12620
    },
    {
      "epoch": 40.611916264090176,
      "grad_norm": 0.27474069595336914,
      "learning_rate": 0.00045423605651943747,
      "loss": 1.4072,
      "step": 12630
    },
    {
      "epoch": 40.64412238325282,
      "grad_norm": 0.3882516622543335,
      "learning_rate": 0.0004541622350134108,
      "loss": 1.4071,
      "step": 12640
    },
    {
      "epoch": 40.67632850241546,
      "grad_norm": 0.33153897523880005,
      "learning_rate": 0.00045408836002369207,
      "loss": 1.3922,
      "step": 12650
    },
    {
      "epoch": 40.7085346215781,
      "grad_norm": 0.29438719153404236,
      "learning_rate": 0.0004540144315696342,
      "loss": 1.3882,
      "step": 12660
    },
    {
      "epoch": 40.74074074074074,
      "grad_norm": 0.3146742582321167,
      "learning_rate": 0.0004539404496706039,
      "loss": 1.375,
      "step": 12670
    },
    {
      "epoch": 40.772946859903385,
      "grad_norm": 0.28041642904281616,
      "learning_rate": 0.0004538664143459819,
      "loss": 1.3825,
      "step": 12680
    },
    {
      "epoch": 40.80515297906602,
      "grad_norm": 0.24317485094070435,
      "learning_rate": 0.00045379232561516304,
      "loss": 1.392,
      "step": 12690
    },
    {
      "epoch": 40.83735909822866,
      "grad_norm": 0.28221240639686584,
      "learning_rate": 0.0004537181834975561,
      "loss": 1.3894,
      "step": 12700
    },
    {
      "epoch": 40.869565217391305,
      "grad_norm": 0.3168346583843231,
      "learning_rate": 0.00045364398801258396,
      "loss": 1.3945,
      "step": 12710
    },
    {
      "epoch": 40.90177133655394,
      "grad_norm": 0.3676297962665558,
      "learning_rate": 0.00045356973917968314,
      "loss": 1.3832,
      "step": 12720
    },
    {
      "epoch": 40.93397745571659,
      "grad_norm": 0.2636978030204773,
      "learning_rate": 0.00045349543701830446,
      "loss": 1.397,
      "step": 12730
    },
    {
      "epoch": 40.966183574879224,
      "grad_norm": 0.22942636907100677,
      "learning_rate": 0.00045342108154791265,
      "loss": 1.3984,
      "step": 12740
    },
    {
      "epoch": 40.99838969404187,
      "grad_norm": 0.22601830959320068,
      "learning_rate": 0.0004533466727879863,
      "loss": 1.3757,
      "step": 12750
    },
    {
      "epoch": 41.0,
      "eval_loss": 0.6421109437942505,
      "eval_runtime": 7.1135,
      "eval_samples_per_second": 3416.479,
      "eval_steps_per_second": 13.355,
      "step": 12751
    },
    {
      "epoch": 41.028985507246375,
      "grad_norm": 0.26994889974594116,
      "learning_rate": 0.00045327221075801803,
      "loss": 1.3286,
      "step": 12760
    },
    {
      "epoch": 41.06119162640902,
      "grad_norm": 0.2804205119609833,
      "learning_rate": 0.00045319769547751446,
      "loss": 1.395,
      "step": 12770
    },
    {
      "epoch": 41.09339774557166,
      "grad_norm": 0.24027493596076965,
      "learning_rate": 0.000453123126965996,
      "loss": 1.3863,
      "step": 12780
    },
    {
      "epoch": 41.1256038647343,
      "grad_norm": 0.25820228457450867,
      "learning_rate": 0.0004530485052429972,
      "loss": 1.3954,
      "step": 12790
    },
    {
      "epoch": 41.15780998389694,
      "grad_norm": 0.28865280747413635,
      "learning_rate": 0.0004529738303280664,
      "loss": 1.3836,
      "step": 12800
    },
    {
      "epoch": 41.190016103059584,
      "grad_norm": 0.2744935154914856,
      "learning_rate": 0.000452899102240766,
      "loss": 1.3811,
      "step": 12810
    },
    {
      "epoch": 41.22222222222222,
      "grad_norm": 0.3472100794315338,
      "learning_rate": 0.0004528243210006722,
      "loss": 1.4055,
      "step": 12820
    },
    {
      "epoch": 41.254428341384866,
      "grad_norm": 0.5448499321937561,
      "learning_rate": 0.0004527494866273753,
      "loss": 1.3948,
      "step": 12830
    },
    {
      "epoch": 41.2866344605475,
      "grad_norm": 0.3075864017009735,
      "learning_rate": 0.0004526745991404793,
      "loss": 1.382,
      "step": 12840
    },
    {
      "epoch": 41.31884057971015,
      "grad_norm": 0.28927186131477356,
      "learning_rate": 0.0004525996585596023,
      "loss": 1.4031,
      "step": 12850
    },
    {
      "epoch": 41.351046698872786,
      "grad_norm": 0.29243966937065125,
      "learning_rate": 0.0004525246649043761,
      "loss": 1.3674,
      "step": 12860
    },
    {
      "epoch": 41.38325281803543,
      "grad_norm": 0.27176332473754883,
      "learning_rate": 0.00045244961819444665,
      "loss": 1.3928,
      "step": 12870
    },
    {
      "epoch": 41.41545893719807,
      "grad_norm": 0.3529474139213562,
      "learning_rate": 0.00045237451844947364,
      "loss": 1.4013,
      "step": 12880
    },
    {
      "epoch": 41.447665056360705,
      "grad_norm": 0.3899163007736206,
      "learning_rate": 0.00045229936568913075,
      "loss": 1.405,
      "step": 12890
    },
    {
      "epoch": 41.47987117552335,
      "grad_norm": 0.3523520827293396,
      "learning_rate": 0.0004522241599331054,
      "loss": 1.385,
      "step": 12900
    },
    {
      "epoch": 41.51207729468599,
      "grad_norm": 0.347001314163208,
      "learning_rate": 0.0004521489012010991,
      "loss": 1.3954,
      "step": 12910
    },
    {
      "epoch": 41.54428341384863,
      "grad_norm": 0.329532265663147,
      "learning_rate": 0.00045207358951282706,
      "loss": 1.4001,
      "step": 12920
    },
    {
      "epoch": 41.57648953301127,
      "grad_norm": 0.30022794008255005,
      "learning_rate": 0.0004519982248880185,
      "loss": 1.3713,
      "step": 12930
    },
    {
      "epoch": 41.608695652173914,
      "grad_norm": 0.29409176111221313,
      "learning_rate": 0.00045192280734641623,
      "loss": 1.3979,
      "step": 12940
    },
    {
      "epoch": 41.64090177133655,
      "grad_norm": 0.2571384906768799,
      "learning_rate": 0.0004518473369077774,
      "loss": 1.3936,
      "step": 12950
    },
    {
      "epoch": 41.673107890499196,
      "grad_norm": 0.32341670989990234,
      "learning_rate": 0.0004517718135918726,
      "loss": 1.4115,
      "step": 12960
    },
    {
      "epoch": 41.70531400966183,
      "grad_norm": 0.3289779722690582,
      "learning_rate": 0.00045169623741848637,
      "loss": 1.3851,
      "step": 12970
    },
    {
      "epoch": 41.73752012882448,
      "grad_norm": 0.2524321973323822,
      "learning_rate": 0.00045162060840741724,
      "loss": 1.3859,
      "step": 12980
    },
    {
      "epoch": 41.769726247987116,
      "grad_norm": 0.2756359875202179,
      "learning_rate": 0.00045154492657847753,
      "loss": 1.4068,
      "step": 12990
    },
    {
      "epoch": 41.80193236714976,
      "grad_norm": 0.3335529565811157,
      "learning_rate": 0.0004514691919514933,
      "loss": 1.3688,
      "step": 13000
    },
    {
      "epoch": 41.8341384863124,
      "grad_norm": 0.2675916850566864,
      "learning_rate": 0.0004513934045463044,
      "loss": 1.3907,
      "step": 13010
    },
    {
      "epoch": 41.86634460547504,
      "grad_norm": 0.26199984550476074,
      "learning_rate": 0.00045131756438276466,
      "loss": 1.3904,
      "step": 13020
    },
    {
      "epoch": 41.89855072463768,
      "grad_norm": 0.235898956656456,
      "learning_rate": 0.00045124167148074174,
      "loss": 1.3874,
      "step": 13030
    },
    {
      "epoch": 41.930756843800324,
      "grad_norm": 0.3247818946838379,
      "learning_rate": 0.00045116572586011703,
      "loss": 1.389,
      "step": 13040
    },
    {
      "epoch": 41.96296296296296,
      "grad_norm": 0.2567856013774872,
      "learning_rate": 0.00045108972754078565,
      "loss": 1.3662,
      "step": 13050
    },
    {
      "epoch": 41.99516908212561,
      "grad_norm": 0.546295702457428,
      "learning_rate": 0.00045101367654265675,
      "loss": 1.4136,
      "step": 13060
    },
    {
      "epoch": 42.0,
      "eval_loss": 0.6408606767654419,
      "eval_runtime": 7.1444,
      "eval_samples_per_second": 3401.679,
      "eval_steps_per_second": 13.297,
      "step": 13062
    },
    {
      "epoch": 42.02576489533011,
      "grad_norm": 0.27304285764694214,
      "learning_rate": 0.0004509375728856531,
      "loss": 1.3138,
      "step": 13070
    },
    {
      "epoch": 42.05797101449275,
      "grad_norm": 0.30252864956855774,
      "learning_rate": 0.00045086141658971123,
      "loss": 1.3845,
      "step": 13080
    },
    {
      "epoch": 42.090177133655395,
      "grad_norm": 0.3290488123893738,
      "learning_rate": 0.0004507852076747817,
      "loss": 1.3751,
      "step": 13090
    },
    {
      "epoch": 42.12238325281803,
      "grad_norm": 0.32676491141319275,
      "learning_rate": 0.0004507089461608286,
      "loss": 1.4143,
      "step": 13100
    },
    {
      "epoch": 42.15458937198068,
      "grad_norm": 0.34653767943382263,
      "learning_rate": 0.00045063263206782995,
      "loss": 1.4028,
      "step": 13110
    },
    {
      "epoch": 42.186795491143315,
      "grad_norm": 0.3158086836338043,
      "learning_rate": 0.0004505562654157775,
      "loss": 1.3768,
      "step": 13120
    },
    {
      "epoch": 42.21900161030596,
      "grad_norm": 0.300492525100708,
      "learning_rate": 0.00045047984622467675,
      "loss": 1.3918,
      "step": 13130
    },
    {
      "epoch": 42.2512077294686,
      "grad_norm": 0.3450983166694641,
      "learning_rate": 0.0004504033745145469,
      "loss": 1.3973,
      "step": 13140
    },
    {
      "epoch": 42.28341384863124,
      "grad_norm": 0.33341553807258606,
      "learning_rate": 0.0004503268503054212,
      "loss": 1.3993,
      "step": 13150
    },
    {
      "epoch": 42.31561996779388,
      "grad_norm": 0.281890869140625,
      "learning_rate": 0.00045025027361734614,
      "loss": 1.3718,
      "step": 13160
    },
    {
      "epoch": 42.34782608695652,
      "grad_norm": 0.25860166549682617,
      "learning_rate": 0.00045017364447038255,
      "loss": 1.3779,
      "step": 13170
    },
    {
      "epoch": 42.38003220611916,
      "grad_norm": 0.29974281787872314,
      "learning_rate": 0.00045009696288460444,
      "loss": 1.3875,
      "step": 13180
    },
    {
      "epoch": 42.412238325281805,
      "grad_norm": 0.250128835439682,
      "learning_rate": 0.00045002022888010007,
      "loss": 1.3783,
      "step": 13190
    },
    {
      "epoch": 42.44444444444444,
      "grad_norm": 0.3105257451534271,
      "learning_rate": 0.00044994344247697104,
      "loss": 1.4119,
      "step": 13200
    },
    {
      "epoch": 42.47665056360709,
      "grad_norm": 0.2574846148490906,
      "learning_rate": 0.0004498666036953328,
      "loss": 1.3625,
      "step": 13210
    },
    {
      "epoch": 42.508856682769725,
      "grad_norm": 0.263109028339386,
      "learning_rate": 0.00044978971255531475,
      "loss": 1.3915,
      "step": 13220
    },
    {
      "epoch": 42.54106280193237,
      "grad_norm": 0.22974887490272522,
      "learning_rate": 0.00044971276907705953,
      "loss": 1.3693,
      "step": 13230
    },
    {
      "epoch": 42.57326892109501,
      "grad_norm": 0.2852816879749298,
      "learning_rate": 0.00044963577328072395,
      "loss": 1.4091,
      "step": 13240
    },
    {
      "epoch": 42.60547504025765,
      "grad_norm": 0.2583523094654083,
      "learning_rate": 0.0004495587251864783,
      "loss": 1.3903,
      "step": 13250
    },
    {
      "epoch": 42.63768115942029,
      "grad_norm": 0.2241898775100708,
      "learning_rate": 0.0004494816248145066,
      "loss": 1.3825,
      "step": 13260
    },
    {
      "epoch": 42.669887278582934,
      "grad_norm": 0.23797853291034698,
      "learning_rate": 0.00044940447218500657,
      "loss": 1.3875,
      "step": 13270
    },
    {
      "epoch": 42.70209339774557,
      "grad_norm": 0.31111153960227966,
      "learning_rate": 0.0004493272673181896,
      "loss": 1.3863,
      "step": 13280
    },
    {
      "epoch": 42.734299516908216,
      "grad_norm": 0.28982430696487427,
      "learning_rate": 0.0004492500102342808,
      "loss": 1.3936,
      "step": 13290
    },
    {
      "epoch": 42.76650563607085,
      "grad_norm": 0.23619893193244934,
      "learning_rate": 0.00044917270095351893,
      "loss": 1.3687,
      "step": 13300
    },
    {
      "epoch": 42.7987117552335,
      "grad_norm": 0.24976350367069244,
      "learning_rate": 0.0004490953394961565,
      "loss": 1.403,
      "step": 13310
    },
    {
      "epoch": 42.830917874396135,
      "grad_norm": 0.33219438791275024,
      "learning_rate": 0.0004490179258824596,
      "loss": 1.4041,
      "step": 13320
    },
    {
      "epoch": 42.86312399355877,
      "grad_norm": 0.309185653924942,
      "learning_rate": 0.0004489404601327081,
      "loss": 1.3872,
      "step": 13330
    },
    {
      "epoch": 42.89533011272142,
      "grad_norm": 0.2804431915283203,
      "learning_rate": 0.0004488629422671952,
      "loss": 1.4018,
      "step": 13340
    },
    {
      "epoch": 42.927536231884055,
      "grad_norm": 0.3186799883842468,
      "learning_rate": 0.00044878537230622827,
      "loss": 1.3835,
      "step": 13350
    },
    {
      "epoch": 42.9597423510467,
      "grad_norm": 0.27025678753852844,
      "learning_rate": 0.0004487077502701279,
      "loss": 1.4031,
      "step": 13360
    },
    {
      "epoch": 42.99194847020934,
      "grad_norm": 0.38620325922966003,
      "learning_rate": 0.00044863007617922845,
      "loss": 1.3996,
      "step": 13370
    },
    {
      "epoch": 43.0,
      "eval_loss": 0.6424320340156555,
      "eval_runtime": 7.0573,
      "eval_samples_per_second": 3443.679,
      "eval_steps_per_second": 13.461,
      "step": 13373
    },
    {
      "epoch": 43.02254428341385,
      "grad_norm": 0.21204090118408203,
      "learning_rate": 0.000448552350053878,
      "loss": 1.2973,
      "step": 13380
    },
    {
      "epoch": 43.05475040257649,
      "grad_norm": 0.34484660625457764,
      "learning_rate": 0.00044847457191443825,
      "loss": 1.381,
      "step": 13390
    },
    {
      "epoch": 43.08695652173913,
      "grad_norm": 0.46253183484077454,
      "learning_rate": 0.00044839674178128445,
      "loss": 1.3871,
      "step": 13400
    },
    {
      "epoch": 43.11916264090177,
      "grad_norm": 0.25672850012779236,
      "learning_rate": 0.00044831885967480537,
      "loss": 1.3858,
      "step": 13410
    },
    {
      "epoch": 43.151368760064415,
      "grad_norm": 0.31754398345947266,
      "learning_rate": 0.00044824092561540364,
      "loss": 1.386,
      "step": 13420
    },
    {
      "epoch": 43.18357487922705,
      "grad_norm": 0.2468142807483673,
      "learning_rate": 0.0004481629396234954,
      "loss": 1.3919,
      "step": 13430
    },
    {
      "epoch": 43.2157809983897,
      "grad_norm": 0.27482935786247253,
      "learning_rate": 0.00044808490171951027,
      "loss": 1.3946,
      "step": 13440
    },
    {
      "epoch": 43.247987117552334,
      "grad_norm": 0.25753679871559143,
      "learning_rate": 0.0004480068119238917,
      "loss": 1.3803,
      "step": 13450
    },
    {
      "epoch": 43.28019323671498,
      "grad_norm": 0.3262351155281067,
      "learning_rate": 0.00044792867025709657,
      "loss": 1.3934,
      "step": 13460
    },
    {
      "epoch": 43.312399355877616,
      "grad_norm": 0.28046858310699463,
      "learning_rate": 0.00044785047673959535,
      "loss": 1.403,
      "step": 13470
    },
    {
      "epoch": 43.34460547504026,
      "grad_norm": 0.37552696466445923,
      "learning_rate": 0.00044777223139187217,
      "loss": 1.3971,
      "step": 13480
    },
    {
      "epoch": 43.3768115942029,
      "grad_norm": 0.2688879370689392,
      "learning_rate": 0.0004476939342344246,
      "loss": 1.3816,
      "step": 13490
    },
    {
      "epoch": 43.409017713365536,
      "grad_norm": 0.29585564136505127,
      "learning_rate": 0.0004476155852877641,
      "loss": 1.3889,
      "step": 13500
    },
    {
      "epoch": 43.44122383252818,
      "grad_norm": 0.38679036498069763,
      "learning_rate": 0.0004475371845724153,
      "loss": 1.4027,
      "step": 13510
    },
    {
      "epoch": 43.47342995169082,
      "grad_norm": 0.3752477765083313,
      "learning_rate": 0.00044745873210891665,
      "loss": 1.383,
      "step": 13520
    },
    {
      "epoch": 43.50563607085346,
      "grad_norm": 0.22588005661964417,
      "learning_rate": 0.00044738022791781997,
      "loss": 1.3973,
      "step": 13530
    },
    {
      "epoch": 43.5378421900161,
      "grad_norm": 0.282013475894928,
      "learning_rate": 0.00044730167201969086,
      "loss": 1.4009,
      "step": 13540
    },
    {
      "epoch": 43.570048309178745,
      "grad_norm": 0.23405879735946655,
      "learning_rate": 0.0004472230644351083,
      "loss": 1.3861,
      "step": 13550
    },
    {
      "epoch": 43.60225442834138,
      "grad_norm": 0.22631217539310455,
      "learning_rate": 0.00044714440518466486,
      "loss": 1.389,
      "step": 13560
    },
    {
      "epoch": 43.63446054750403,
      "grad_norm": 0.32449910044670105,
      "learning_rate": 0.0004470656942889666,
      "loss": 1.3778,
      "step": 13570
    },
    {
      "epoch": 43.666666666666664,
      "grad_norm": 0.22356447577476501,
      "learning_rate": 0.0004469869317686332,
      "loss": 1.3821,
      "step": 13580
    },
    {
      "epoch": 43.69887278582931,
      "grad_norm": 0.23893867433071136,
      "learning_rate": 0.0004469081176442978,
      "loss": 1.3916,
      "step": 13590
    },
    {
      "epoch": 43.731078904991946,
      "grad_norm": 0.24861744046211243,
      "learning_rate": 0.0004468292519366071,
      "loss": 1.3944,
      "step": 13600
    },
    {
      "epoch": 43.76328502415459,
      "grad_norm": 0.27845802903175354,
      "learning_rate": 0.0004467503346662211,
      "loss": 1.4029,
      "step": 13610
    },
    {
      "epoch": 43.79549114331723,
      "grad_norm": 0.3064621686935425,
      "learning_rate": 0.00044667136585381376,
      "loss": 1.4172,
      "step": 13620
    },
    {
      "epoch": 43.82769726247987,
      "grad_norm": 0.21371454000473022,
      "learning_rate": 0.00044659234552007213,
      "loss": 1.3781,
      "step": 13630
    },
    {
      "epoch": 43.85990338164251,
      "grad_norm": 0.2522454857826233,
      "learning_rate": 0.0004465132736856969,
      "loss": 1.3601,
      "step": 13640
    },
    {
      "epoch": 43.892109500805155,
      "grad_norm": 0.2396925985813141,
      "learning_rate": 0.00044643415037140223,
      "loss": 1.3903,
      "step": 13650
    },
    {
      "epoch": 43.92431561996779,
      "grad_norm": 0.2838725745677948,
      "learning_rate": 0.0004463549755979159,
      "loss": 1.4074,
      "step": 13660
    },
    {
      "epoch": 43.95652173913044,
      "grad_norm": 0.29946988821029663,
      "learning_rate": 0.00044627574938597894,
      "loss": 1.3671,
      "step": 13670
    },
    {
      "epoch": 43.988727858293075,
      "grad_norm": 0.2974143624305725,
      "learning_rate": 0.00044619647175634606,
      "loss": 1.36,
      "step": 13680
    },
    {
      "epoch": 44.0,
      "eval_loss": 0.6406372785568237,
      "eval_runtime": 7.2648,
      "eval_samples_per_second": 3345.294,
      "eval_steps_per_second": 13.077,
      "step": 13684
    },
    {
      "epoch": 44.01932367149758,
      "grad_norm": 0.27541542053222656,
      "learning_rate": 0.00044611714272978535,
      "loss": 1.3422,
      "step": 13690
    },
    {
      "epoch": 44.051529790660226,
      "grad_norm": 0.22910168766975403,
      "learning_rate": 0.00044603776232707813,
      "loss": 1.3651,
      "step": 13700
    },
    {
      "epoch": 44.08373590982286,
      "grad_norm": 0.23502874374389648,
      "learning_rate": 0.0004459583305690198,
      "loss": 1.3914,
      "step": 13710
    },
    {
      "epoch": 44.11594202898551,
      "grad_norm": 0.41431179642677307,
      "learning_rate": 0.0004458788474764186,
      "loss": 1.4253,
      "step": 13720
    },
    {
      "epoch": 44.148148148148145,
      "grad_norm": 0.2819870114326477,
      "learning_rate": 0.0004457993130700965,
      "loss": 1.381,
      "step": 13730
    },
    {
      "epoch": 44.18035426731079,
      "grad_norm": 0.25588053464889526,
      "learning_rate": 0.00044571972737088885,
      "loss": 1.3774,
      "step": 13740
    },
    {
      "epoch": 44.21256038647343,
      "grad_norm": 0.26233524084091187,
      "learning_rate": 0.0004456400903996445,
      "loss": 1.3762,
      "step": 13750
    },
    {
      "epoch": 44.24476650563607,
      "grad_norm": 0.3071296811103821,
      "learning_rate": 0.0004455604021772256,
      "loss": 1.4036,
      "step": 13760
    },
    {
      "epoch": 44.27697262479871,
      "grad_norm": 0.2881069779396057,
      "learning_rate": 0.0004454806627245078,
      "loss": 1.3863,
      "step": 13770
    },
    {
      "epoch": 44.309178743961354,
      "grad_norm": 0.2361849695444107,
      "learning_rate": 0.00044540087206238025,
      "loss": 1.3988,
      "step": 13780
    },
    {
      "epoch": 44.34138486312399,
      "grad_norm": 0.3202221989631653,
      "learning_rate": 0.00044532103021174536,
      "loss": 1.3672,
      "step": 13790
    },
    {
      "epoch": 44.373590982286636,
      "grad_norm": 0.3717081844806671,
      "learning_rate": 0.0004452411371935191,
      "loss": 1.3957,
      "step": 13800
    },
    {
      "epoch": 44.405797101449274,
      "grad_norm": 0.2738661468029022,
      "learning_rate": 0.00044516119302863075,
      "loss": 1.4199,
      "step": 13810
    },
    {
      "epoch": 44.43800322061192,
      "grad_norm": 0.2970689535140991,
      "learning_rate": 0.00044508119773802295,
      "loss": 1.3894,
      "step": 13820
    },
    {
      "epoch": 44.470209339774556,
      "grad_norm": 0.31426483392715454,
      "learning_rate": 0.0004450011513426519,
      "loss": 1.4,
      "step": 13830
    },
    {
      "epoch": 44.5024154589372,
      "grad_norm": 0.3005955219268799,
      "learning_rate": 0.000444921053863487,
      "loss": 1.3872,
      "step": 13840
    },
    {
      "epoch": 44.53462157809984,
      "grad_norm": 0.30950844287872314,
      "learning_rate": 0.00044484090532151123,
      "loss": 1.388,
      "step": 13850
    },
    {
      "epoch": 44.56682769726248,
      "grad_norm": 0.242197185754776,
      "learning_rate": 0.00044476070573772075,
      "loss": 1.4094,
      "step": 13860
    },
    {
      "epoch": 44.59903381642512,
      "grad_norm": 0.28016355633735657,
      "learning_rate": 0.0004446804551331252,
      "loss": 1.396,
      "step": 13870
    },
    {
      "epoch": 44.631239935587764,
      "grad_norm": 0.23878255486488342,
      "learning_rate": 0.0004446001535287475,
      "loss": 1.3766,
      "step": 13880
    },
    {
      "epoch": 44.6634460547504,
      "grad_norm": 0.2600216865539551,
      "learning_rate": 0.000444519800945624,
      "loss": 1.3776,
      "step": 13890
    },
    {
      "epoch": 44.69565217391305,
      "grad_norm": 0.2605138421058655,
      "learning_rate": 0.0004444393974048044,
      "loss": 1.3894,
      "step": 13900
    },
    {
      "epoch": 44.727858293075684,
      "grad_norm": 0.2903819680213928,
      "learning_rate": 0.0004443589429273519,
      "loss": 1.3708,
      "step": 13910
    },
    {
      "epoch": 44.76006441223833,
      "grad_norm": 0.26201102137565613,
      "learning_rate": 0.00044427843753434273,
      "loss": 1.3787,
      "step": 13920
    },
    {
      "epoch": 44.792270531400966,
      "grad_norm": 0.2603895962238312,
      "learning_rate": 0.0004441978812468666,
      "loss": 1.3829,
      "step": 13930
    },
    {
      "epoch": 44.824476650563604,
      "grad_norm": 0.6638569235801697,
      "learning_rate": 0.00044411727408602666,
      "loss": 1.4024,
      "step": 13940
    },
    {
      "epoch": 44.85668276972625,
      "grad_norm": 0.28496232628822327,
      "learning_rate": 0.0004440366160729392,
      "loss": 1.3864,
      "step": 13950
    },
    {
      "epoch": 44.888888888888886,
      "grad_norm": 0.3051494061946869,
      "learning_rate": 0.00044395590722873403,
      "loss": 1.3687,
      "step": 13960
    },
    {
      "epoch": 44.92109500805153,
      "grad_norm": 0.2563264071941376,
      "learning_rate": 0.00044387514757455413,
      "loss": 1.3783,
      "step": 13970
    },
    {
      "epoch": 44.95330112721417,
      "grad_norm": 0.267991840839386,
      "learning_rate": 0.0004437943371315558,
      "loss": 1.3894,
      "step": 13980
    },
    {
      "epoch": 44.98550724637681,
      "grad_norm": 0.3003862798213959,
      "learning_rate": 0.00044371347592090873,
      "loss": 1.3795,
      "step": 13990
    },
    {
      "epoch": 45.0,
      "eval_loss": 0.6425638198852539,
      "eval_runtime": 7.0594,
      "eval_samples_per_second": 3442.661,
      "eval_steps_per_second": 13.457,
      "step": 13995
    },
    {
      "epoch": 45.01610305958132,
      "grad_norm": 0.2825664281845093,
      "learning_rate": 0.0004436325639637958,
      "loss": 1.3172,
      "step": 14000
    },
    {
      "epoch": 45.04830917874396,
      "grad_norm": 0.3841220736503601,
      "learning_rate": 0.00044355160128141326,
      "loss": 1.395,
      "step": 14010
    },
    {
      "epoch": 45.0805152979066,
      "grad_norm": 0.3101707994937897,
      "learning_rate": 0.00044347058789497067,
      "loss": 1.3792,
      "step": 14020
    },
    {
      "epoch": 45.112721417069245,
      "grad_norm": 0.5161691308021545,
      "learning_rate": 0.00044338952382569086,
      "loss": 1.4099,
      "step": 14030
    },
    {
      "epoch": 45.14492753623188,
      "grad_norm": 0.24138271808624268,
      "learning_rate": 0.00044330840909480984,
      "loss": 1.3741,
      "step": 14040
    },
    {
      "epoch": 45.17713365539453,
      "grad_norm": 0.25643789768218994,
      "learning_rate": 0.000443227243723577,
      "loss": 1.3565,
      "step": 14050
    },
    {
      "epoch": 45.209339774557165,
      "grad_norm": 0.22681233286857605,
      "learning_rate": 0.00044314602773325493,
      "loss": 1.3834,
      "step": 14060
    },
    {
      "epoch": 45.24154589371981,
      "grad_norm": 0.5486558079719543,
      "learning_rate": 0.00044306476114511944,
      "loss": 1.3865,
      "step": 14070
    },
    {
      "epoch": 45.27375201288245,
      "grad_norm": 0.3506430685520172,
      "learning_rate": 0.00044298344398045986,
      "loss": 1.41,
      "step": 14080
    },
    {
      "epoch": 45.30595813204509,
      "grad_norm": 0.29475706815719604,
      "learning_rate": 0.00044290207626057843,
      "loss": 1.3789,
      "step": 14090
    },
    {
      "epoch": 45.33816425120773,
      "grad_norm": 0.3055821359157562,
      "learning_rate": 0.0004428206580067908,
      "loss": 1.4084,
      "step": 14100
    },
    {
      "epoch": 45.370370370370374,
      "grad_norm": 0.27807602286338806,
      "learning_rate": 0.00044273918924042584,
      "loss": 1.3858,
      "step": 14110
    },
    {
      "epoch": 45.40257648953301,
      "grad_norm": 0.2375219166278839,
      "learning_rate": 0.0004426576699828256,
      "loss": 1.3601,
      "step": 14120
    },
    {
      "epoch": 45.43478260869565,
      "grad_norm": 0.28162598609924316,
      "learning_rate": 0.00044257610025534556,
      "loss": 1.3724,
      "step": 14130
    },
    {
      "epoch": 45.46698872785829,
      "grad_norm": 0.35836392641067505,
      "learning_rate": 0.00044249448007935413,
      "loss": 1.3888,
      "step": 14140
    },
    {
      "epoch": 45.49919484702093,
      "grad_norm": 0.2732972204685211,
      "learning_rate": 0.0004424128094762331,
      "loss": 1.3776,
      "step": 14150
    },
    {
      "epoch": 45.531400966183575,
      "grad_norm": 0.25460198521614075,
      "learning_rate": 0.00044233108846737743,
      "loss": 1.3863,
      "step": 14160
    },
    {
      "epoch": 45.56360708534621,
      "grad_norm": 0.2370402216911316,
      "learning_rate": 0.0004422493170741954,
      "loss": 1.3759,
      "step": 14170
    },
    {
      "epoch": 45.59581320450886,
      "grad_norm": 0.2712081968784332,
      "learning_rate": 0.0004421674953181081,
      "loss": 1.374,
      "step": 14180
    },
    {
      "epoch": 45.628019323671495,
      "grad_norm": 0.23018257319927216,
      "learning_rate": 0.00044208562322055046,
      "loss": 1.3924,
      "step": 14190
    },
    {
      "epoch": 45.66022544283414,
      "grad_norm": 0.23247867822647095,
      "learning_rate": 0.00044200370080297,
      "loss": 1.3836,
      "step": 14200
    },
    {
      "epoch": 45.69243156199678,
      "grad_norm": 0.32428932189941406,
      "learning_rate": 0.00044192172808682777,
      "loss": 1.3821,
      "step": 14210
    },
    {
      "epoch": 45.72463768115942,
      "grad_norm": 0.257241815328598,
      "learning_rate": 0.0004418397050935979,
      "loss": 1.4094,
      "step": 14220
    },
    {
      "epoch": 45.75684380032206,
      "grad_norm": 0.23303087055683136,
      "learning_rate": 0.00044175763184476757,
      "loss": 1.3968,
      "step": 14230
    },
    {
      "epoch": 45.789049919484704,
      "grad_norm": 0.2171684354543686,
      "learning_rate": 0.00044167550836183726,
      "loss": 1.383,
      "step": 14240
    },
    {
      "epoch": 45.82125603864734,
      "grad_norm": 0.2326781153678894,
      "learning_rate": 0.0004415933346663207,
      "loss": 1.3944,
      "step": 14250
    },
    {
      "epoch": 45.853462157809986,
      "grad_norm": 0.32257020473480225,
      "learning_rate": 0.0004415111107797445,
      "loss": 1.3934,
      "step": 14260
    },
    {
      "epoch": 45.88566827697262,
      "grad_norm": 0.2513253688812256,
      "learning_rate": 0.0004414288367236487,
      "loss": 1.3724,
      "step": 14270
    },
    {
      "epoch": 45.91787439613527,
      "grad_norm": 0.28411078453063965,
      "learning_rate": 0.00044134651251958625,
      "loss": 1.4004,
      "step": 14280
    },
    {
      "epoch": 45.950080515297905,
      "grad_norm": 0.2697876989841461,
      "learning_rate": 0.0004412641381891234,
      "loss": 1.4131,
      "step": 14290
    },
    {
      "epoch": 45.98228663446055,
      "grad_norm": 0.23799291253089905,
      "learning_rate": 0.0004411817137538395,
      "loss": 1.4198,
      "step": 14300
    },
    {
      "epoch": 46.0,
      "eval_loss": 0.6419665813446045,
      "eval_runtime": 7.0743,
      "eval_samples_per_second": 3435.389,
      "eval_steps_per_second": 13.429,
      "step": 14306
    },
    {
      "epoch": 46.012882447665056,
      "grad_norm": 0.24934333562850952,
      "learning_rate": 0.0004410992392353269,
      "loss": 1.3005,
      "step": 14310
    },
    {
      "epoch": 46.045088566827694,
      "grad_norm": 0.29536136984825134,
      "learning_rate": 0.00044101671465519133,
      "loss": 1.3776,
      "step": 14320
    },
    {
      "epoch": 46.07729468599034,
      "grad_norm": 0.2263353317975998,
      "learning_rate": 0.0004409341400350514,
      "loss": 1.3923,
      "step": 14330
    },
    {
      "epoch": 46.109500805152976,
      "grad_norm": 0.2058895379304886,
      "learning_rate": 0.0004408515153965388,
      "loss": 1.3973,
      "step": 14340
    },
    {
      "epoch": 46.14170692431562,
      "grad_norm": 0.2536568343639374,
      "learning_rate": 0.0004407688407612986,
      "loss": 1.3821,
      "step": 14350
    },
    {
      "epoch": 46.17391304347826,
      "grad_norm": 0.20507492125034332,
      "learning_rate": 0.00044068611615098865,
      "loss": 1.3746,
      "step": 14360
    },
    {
      "epoch": 46.2061191626409,
      "grad_norm": 0.20488229393959045,
      "learning_rate": 0.0004406033415872801,
      "loss": 1.3729,
      "step": 14370
    },
    {
      "epoch": 46.23832528180354,
      "grad_norm": 0.25094103813171387,
      "learning_rate": 0.0004405205170918572,
      "loss": 1.3777,
      "step": 14380
    },
    {
      "epoch": 46.270531400966185,
      "grad_norm": 0.3159372806549072,
      "learning_rate": 0.00044043764268641706,
      "loss": 1.3686,
      "step": 14390
    },
    {
      "epoch": 46.30273752012882,
      "grad_norm": 0.23193645477294922,
      "learning_rate": 0.00044035471839267017,
      "loss": 1.375,
      "step": 14400
    },
    {
      "epoch": 46.33494363929147,
      "grad_norm": 0.21423350274562836,
      "learning_rate": 0.0004402717442323397,
      "loss": 1.386,
      "step": 14410
    },
    {
      "epoch": 46.367149758454104,
      "grad_norm": 0.2277335524559021,
      "learning_rate": 0.00044018872022716235,
      "loss": 1.3947,
      "step": 14420
    },
    {
      "epoch": 46.39935587761675,
      "grad_norm": 0.2471368908882141,
      "learning_rate": 0.00044010564639888753,
      "loss": 1.3882,
      "step": 14430
    },
    {
      "epoch": 46.43156199677939,
      "grad_norm": 0.2246270626783371,
      "learning_rate": 0.0004400225227692777,
      "loss": 1.4046,
      "step": 14440
    },
    {
      "epoch": 46.46376811594203,
      "grad_norm": 0.2336946427822113,
      "learning_rate": 0.0004399393493601087,
      "loss": 1.4023,
      "step": 14450
    },
    {
      "epoch": 46.49597423510467,
      "grad_norm": 0.25078442692756653,
      "learning_rate": 0.00043985612619316906,
      "loss": 1.3912,
      "step": 14460
    },
    {
      "epoch": 46.52818035426731,
      "grad_norm": 0.2483130842447281,
      "learning_rate": 0.0004397728532902605,
      "loss": 1.4064,
      "step": 14470
    },
    {
      "epoch": 46.56038647342995,
      "grad_norm": 0.18699736893177032,
      "learning_rate": 0.0004396895306731977,
      "loss": 1.3833,
      "step": 14480
    },
    {
      "epoch": 46.592592592592595,
      "grad_norm": 0.2397056370973587,
      "learning_rate": 0.00043960615836380844,
      "loss": 1.3624,
      "step": 14490
    },
    {
      "epoch": 46.62479871175523,
      "grad_norm": 0.36234816908836365,
      "learning_rate": 0.00043952273638393356,
      "loss": 1.3817,
      "step": 14500
    },
    {
      "epoch": 46.65700483091788,
      "grad_norm": 0.2470211535692215,
      "learning_rate": 0.00043943926475542675,
      "loss": 1.3904,
      "step": 14510
    },
    {
      "epoch": 46.689210950080515,
      "grad_norm": 0.5250781178474426,
      "learning_rate": 0.0004393557435001547,
      "loss": 1.3672,
      "step": 14520
    },
    {
      "epoch": 46.72141706924316,
      "grad_norm": 0.21028786897659302,
      "learning_rate": 0.0004392721726399973,
      "loss": 1.4058,
      "step": 14530
    },
    {
      "epoch": 46.7536231884058,
      "grad_norm": 0.1743345856666565,
      "learning_rate": 0.0004391885521968474,
      "loss": 1.3971,
      "step": 14540
    },
    {
      "epoch": 46.78582930756844,
      "grad_norm": 0.23504790663719177,
      "learning_rate": 0.0004391048821926106,
      "loss": 1.3785,
      "step": 14550
    },
    {
      "epoch": 46.81803542673108,
      "grad_norm": 0.21691641211509705,
      "learning_rate": 0.0004390211626492058,
      "loss": 1.3929,
      "step": 14560
    },
    {
      "epoch": 46.85024154589372,
      "grad_norm": 0.203721284866333,
      "learning_rate": 0.0004389373935885646,
      "loss": 1.3871,
      "step": 14570
    },
    {
      "epoch": 46.88244766505636,
      "grad_norm": 0.29993385076522827,
      "learning_rate": 0.00043885357503263176,
      "loss": 1.3943,
      "step": 14580
    },
    {
      "epoch": 46.914653784219,
      "grad_norm": 0.24751657247543335,
      "learning_rate": 0.00043876970700336496,
      "loss": 1.4014,
      "step": 14590
    },
    {
      "epoch": 46.94685990338164,
      "grad_norm": 0.28200840950012207,
      "learning_rate": 0.00043868578952273475,
      "loss": 1.3721,
      "step": 14600
    },
    {
      "epoch": 46.97906602254428,
      "grad_norm": 0.29693925380706787,
      "learning_rate": 0.0004386018226127248,
      "loss": 1.4191,
      "step": 14610
    },
    {
      "epoch": 47.0,
      "eval_loss": 0.6442644000053406,
      "eval_runtime": 7.087,
      "eval_samples_per_second": 3429.255,
      "eval_steps_per_second": 13.405,
      "step": 14617
    },
    {
      "epoch": 47.009661835748794,
      "grad_norm": 0.2365017831325531,
      "learning_rate": 0.00043851780629533164,
      "loss": 1.3137,
      "step": 14620
    },
    {
      "epoch": 47.04186795491143,
      "grad_norm": 0.21541975438594818,
      "learning_rate": 0.00043843374059256466,
      "loss": 1.3838,
      "step": 14630
    },
    {
      "epoch": 47.074074074074076,
      "grad_norm": 0.3129158914089203,
      "learning_rate": 0.00043834962552644633,
      "loss": 1.3995,
      "step": 14640
    },
    {
      "epoch": 47.106280193236714,
      "grad_norm": 0.2917079031467438,
      "learning_rate": 0.00043826546111901186,
      "loss": 1.3884,
      "step": 14650
    },
    {
      "epoch": 47.13848631239936,
      "grad_norm": 0.43058809638023376,
      "learning_rate": 0.00043818124739230976,
      "loss": 1.375,
      "step": 14660
    },
    {
      "epoch": 47.170692431561996,
      "grad_norm": 0.321633517742157,
      "learning_rate": 0.00043809698436840104,
      "loss": 1.3829,
      "step": 14670
    },
    {
      "epoch": 47.20289855072464,
      "grad_norm": 0.29509589076042175,
      "learning_rate": 0.0004380126720693598,
      "loss": 1.3856,
      "step": 14680
    },
    {
      "epoch": 47.23510466988728,
      "grad_norm": 0.24767521023750305,
      "learning_rate": 0.0004379283105172731,
      "loss": 1.4002,
      "step": 14690
    },
    {
      "epoch": 47.26731078904992,
      "grad_norm": 0.23716981709003448,
      "learning_rate": 0.0004378438997342409,
      "loss": 1.3608,
      "step": 14700
    },
    {
      "epoch": 47.29951690821256,
      "grad_norm": 0.317526251077652,
      "learning_rate": 0.00043775943974237594,
      "loss": 1.3732,
      "step": 14710
    },
    {
      "epoch": 47.331723027375205,
      "grad_norm": 0.2294854074716568,
      "learning_rate": 0.0004376749305638039,
      "loss": 1.3953,
      "step": 14720
    },
    {
      "epoch": 47.36392914653784,
      "grad_norm": 0.2244500070810318,
      "learning_rate": 0.0004375903722206634,
      "loss": 1.3961,
      "step": 14730
    },
    {
      "epoch": 47.39613526570048,
      "grad_norm": 0.2886172831058502,
      "learning_rate": 0.0004375057647351059,
      "loss": 1.3865,
      "step": 14740
    },
    {
      "epoch": 47.428341384863124,
      "grad_norm": 0.23874150216579437,
      "learning_rate": 0.0004374211081292957,
      "loss": 1.3804,
      "step": 14750
    },
    {
      "epoch": 47.46054750402576,
      "grad_norm": 0.23178477585315704,
      "learning_rate": 0.0004373364024254101,
      "loss": 1.3736,
      "step": 14760
    },
    {
      "epoch": 47.492753623188406,
      "grad_norm": 0.24876216053962708,
      "learning_rate": 0.0004372516476456391,
      "loss": 1.379,
      "step": 14770
    },
    {
      "epoch": 47.524959742351044,
      "grad_norm": 0.22692373394966125,
      "learning_rate": 0.00043716684381218555,
      "loss": 1.3724,
      "step": 14780
    },
    {
      "epoch": 47.55716586151369,
      "grad_norm": 0.2665765881538391,
      "learning_rate": 0.0004370819909472654,
      "loss": 1.3797,
      "step": 14790
    },
    {
      "epoch": 47.589371980676326,
      "grad_norm": 0.2569880783557892,
      "learning_rate": 0.0004369970890731071,
      "loss": 1.377,
      "step": 14800
    },
    {
      "epoch": 47.62157809983897,
      "grad_norm": 0.22388772666454315,
      "learning_rate": 0.0004369121382119523,
      "loss": 1.3866,
      "step": 14810
    },
    {
      "epoch": 47.65378421900161,
      "grad_norm": 0.2191704660654068,
      "learning_rate": 0.00043682713838605504,
      "loss": 1.3938,
      "step": 14820
    },
    {
      "epoch": 47.68599033816425,
      "grad_norm": 0.22992128133773804,
      "learning_rate": 0.00043674208961768263,
      "loss": 1.3902,
      "step": 14830
    },
    {
      "epoch": 47.71819645732689,
      "grad_norm": 0.20584958791732788,
      "learning_rate": 0.00043665699192911497,
      "loss": 1.3871,
      "step": 14840
    },
    {
      "epoch": 47.750402576489535,
      "grad_norm": 0.24556513130664825,
      "learning_rate": 0.0004365718453426447,
      "loss": 1.3984,
      "step": 14850
    },
    {
      "epoch": 47.78260869565217,
      "grad_norm": 0.24379906058311462,
      "learning_rate": 0.0004364866498805776,
      "loss": 1.3825,
      "step": 14860
    },
    {
      "epoch": 47.81481481481482,
      "grad_norm": 0.2261495739221573,
      "learning_rate": 0.0004364014055652319,
      "loss": 1.4056,
      "step": 14870
    },
    {
      "epoch": 47.847020933977454,
      "grad_norm": 0.2758018970489502,
      "learning_rate": 0.0004363161124189387,
      "loss": 1.3947,
      "step": 14880
    },
    {
      "epoch": 47.8792270531401,
      "grad_norm": 0.27855414152145386,
      "learning_rate": 0.0004362307704640421,
      "loss": 1.3911,
      "step": 14890
    },
    {
      "epoch": 47.911433172302736,
      "grad_norm": 0.3227490186691284,
      "learning_rate": 0.0004361453797228987,
      "loss": 1.3788,
      "step": 14900
    },
    {
      "epoch": 47.94363929146538,
      "grad_norm": 0.27731233835220337,
      "learning_rate": 0.0004360599402178782,
      "loss": 1.4007,
      "step": 14910
    },
    {
      "epoch": 47.97584541062802,
      "grad_norm": 0.26453134417533875,
      "learning_rate": 0.0004359744519713628,
      "loss": 1.3872,
      "step": 14920
    },
    {
      "epoch": 48.0,
      "eval_loss": 0.6418107748031616,
      "eval_runtime": 7.0359,
      "eval_samples_per_second": 3454.133,
      "eval_steps_per_second": 13.502,
      "step": 14928
    },
    {
      "epoch": 48.006441223832525,
      "grad_norm": 0.2590075433254242,
      "learning_rate": 0.00043588891500574755,
      "loss": 1.3043,
      "step": 14930
    },
    {
      "epoch": 48.03864734299517,
      "grad_norm": 0.24782097339630127,
      "learning_rate": 0.00043580332934344023,
      "loss": 1.3739,
      "step": 14940
    },
    {
      "epoch": 48.07085346215781,
      "grad_norm": 0.34484776854515076,
      "learning_rate": 0.00043571769500686165,
      "loss": 1.3699,
      "step": 14950
    },
    {
      "epoch": 48.10305958132045,
      "grad_norm": 0.4046395719051361,
      "learning_rate": 0.0004356320120184449,
      "loss": 1.3905,
      "step": 14960
    },
    {
      "epoch": 48.13526570048309,
      "grad_norm": 0.3683865964412689,
      "learning_rate": 0.0004355462804006362,
      "loss": 1.3688,
      "step": 14970
    },
    {
      "epoch": 48.16747181964573,
      "grad_norm": 0.35014429688453674,
      "learning_rate": 0.00043546050017589434,
      "loss": 1.399,
      "step": 14980
    },
    {
      "epoch": 48.19967793880837,
      "grad_norm": 0.3544788956642151,
      "learning_rate": 0.00043537467136669085,
      "loss": 1.3967,
      "step": 14990
    },
    {
      "epoch": 48.231884057971016,
      "grad_norm": 0.22755123674869537,
      "learning_rate": 0.00043528879399551,
      "loss": 1.3737,
      "step": 15000
    },
    {
      "epoch": 48.26409017713365,
      "grad_norm": 0.26831236481666565,
      "learning_rate": 0.0004352028680848489,
      "loss": 1.3914,
      "step": 15010
    },
    {
      "epoch": 48.2962962962963,
      "grad_norm": 0.2511375844478607,
      "learning_rate": 0.0004351168936572171,
      "loss": 1.3788,
      "step": 15020
    },
    {
      "epoch": 48.328502415458935,
      "grad_norm": 0.2145502269268036,
      "learning_rate": 0.00043503087073513725,
      "loss": 1.3814,
      "step": 15030
    },
    {
      "epoch": 48.36070853462158,
      "grad_norm": 0.303984135389328,
      "learning_rate": 0.00043494479934114426,
      "loss": 1.3805,
      "step": 15040
    },
    {
      "epoch": 48.39291465378422,
      "grad_norm": 0.4130922257900238,
      "learning_rate": 0.0004348586794977862,
      "loss": 1.3891,
      "step": 15050
    },
    {
      "epoch": 48.42512077294686,
      "grad_norm": 0.21420828998088837,
      "learning_rate": 0.0004347725112276234,
      "loss": 1.3868,
      "step": 15060
    },
    {
      "epoch": 48.4573268921095,
      "grad_norm": 0.2886607348918915,
      "learning_rate": 0.00043468629455322913,
      "loss": 1.3959,
      "step": 15070
    },
    {
      "epoch": 48.489533011272144,
      "grad_norm": 0.2476440668106079,
      "learning_rate": 0.00043460002949718924,
      "loss": 1.3907,
      "step": 15080
    },
    {
      "epoch": 48.52173913043478,
      "grad_norm": 0.2722724974155426,
      "learning_rate": 0.00043451371608210245,
      "loss": 1.398,
      "step": 15090
    },
    {
      "epoch": 48.553945249597426,
      "grad_norm": 0.2543254494667053,
      "learning_rate": 0.0004344273543305798,
      "loss": 1.3754,
      "step": 15100
    },
    {
      "epoch": 48.58615136876006,
      "grad_norm": 0.24929919838905334,
      "learning_rate": 0.0004343409442652453,
      "loss": 1.3716,
      "step": 15110
    },
    {
      "epoch": 48.61835748792271,
      "grad_norm": 0.21836301684379578,
      "learning_rate": 0.0004342544859087355,
      "loss": 1.3665,
      "step": 15120
    },
    {
      "epoch": 48.650563607085346,
      "grad_norm": 0.20928554236888885,
      "learning_rate": 0.00043416797928369955,
      "loss": 1.3873,
      "step": 15130
    },
    {
      "epoch": 48.68276972624799,
      "grad_norm": 0.35826539993286133,
      "learning_rate": 0.0004340814244127993,
      "loss": 1.3876,
      "step": 15140
    },
    {
      "epoch": 48.71497584541063,
      "grad_norm": 0.2194812148809433,
      "learning_rate": 0.0004339948213187094,
      "loss": 1.4006,
      "step": 15150
    },
    {
      "epoch": 48.74718196457327,
      "grad_norm": 0.3372389078140259,
      "learning_rate": 0.00043390817002411663,
      "loss": 1.3822,
      "step": 15160
    },
    {
      "epoch": 48.77938808373591,
      "grad_norm": 0.299215704202652,
      "learning_rate": 0.0004338214705517211,
      "loss": 1.3882,
      "step": 15170
    },
    {
      "epoch": 48.81159420289855,
      "grad_norm": 0.21091151237487793,
      "learning_rate": 0.000433734722924235,
      "loss": 1.3704,
      "step": 15180
    },
    {
      "epoch": 48.84380032206119,
      "grad_norm": 0.22769267857074738,
      "learning_rate": 0.0004336479271643833,
      "loss": 1.3984,
      "step": 15190
    },
    {
      "epoch": 48.87600644122383,
      "grad_norm": 0.3150727152824402,
      "learning_rate": 0.0004335610832949037,
      "loss": 1.4052,
      "step": 15200
    },
    {
      "epoch": 48.908212560386474,
      "grad_norm": 0.29162126779556274,
      "learning_rate": 0.0004334741913385463,
      "loss": 1.4148,
      "step": 15210
    },
    {
      "epoch": 48.94041867954911,
      "grad_norm": 0.8515332341194153,
      "learning_rate": 0.00043338725131807386,
      "loss": 1.3842,
      "step": 15220
    },
    {
      "epoch": 48.972624798711756,
      "grad_norm": 0.266413152217865,
      "learning_rate": 0.0004333002632562618,
      "loss": 1.382,
      "step": 15230
    },
    {
      "epoch": 49.0,
      "eval_loss": 0.6400119066238403,
      "eval_runtime": 7.2699,
      "eval_samples_per_second": 3342.96,
      "eval_steps_per_second": 13.068,
      "step": 15239
    },
    {
      "epoch": 49.00322061191626,
      "grad_norm": 0.5407330393791199,
      "learning_rate": 0.00043321322717589816,
      "loss": 1.303,
      "step": 15240
    },
    {
      "epoch": 49.03542673107891,
      "grad_norm": 0.25803273916244507,
      "learning_rate": 0.0004331261430997835,
      "loss": 1.4029,
      "step": 15250
    },
    {
      "epoch": 49.067632850241544,
      "grad_norm": 0.32936719059944153,
      "learning_rate": 0.0004330390110507308,
      "loss": 1.3863,
      "step": 15260
    },
    {
      "epoch": 49.09983896940419,
      "grad_norm": 0.47060704231262207,
      "learning_rate": 0.0004329518310515659,
      "loss": 1.364,
      "step": 15270
    },
    {
      "epoch": 49.13204508856683,
      "grad_norm": 0.5487316846847534,
      "learning_rate": 0.00043286460312512686,
      "loss": 1.3692,
      "step": 15280
    },
    {
      "epoch": 49.16425120772947,
      "grad_norm": 0.38486751914024353,
      "learning_rate": 0.0004327773272942647,
      "loss": 1.3907,
      "step": 15290
    },
    {
      "epoch": 49.19645732689211,
      "grad_norm": 0.2757336497306824,
      "learning_rate": 0.0004326900035818427,
      "loss": 1.404,
      "step": 15300
    },
    {
      "epoch": 49.22866344605475,
      "grad_norm": 0.23091977834701538,
      "learning_rate": 0.0004326026320107367,
      "loss": 1.3883,
      "step": 15310
    },
    {
      "epoch": 49.26086956521739,
      "grad_norm": 0.2690019905567169,
      "learning_rate": 0.00043251521260383516,
      "loss": 1.3995,
      "step": 15320
    },
    {
      "epoch": 49.293075684380035,
      "grad_norm": 0.3143121600151062,
      "learning_rate": 0.00043242774538403904,
      "loss": 1.3843,
      "step": 15330
    },
    {
      "epoch": 49.32528180354267,
      "grad_norm": 0.23695290088653564,
      "learning_rate": 0.0004323402303742619,
      "loss": 1.3775,
      "step": 15340
    },
    {
      "epoch": 49.35748792270532,
      "grad_norm": 0.2936911880970001,
      "learning_rate": 0.00043225266759742964,
      "loss": 1.3769,
      "step": 15350
    },
    {
      "epoch": 49.389694041867955,
      "grad_norm": 0.25611162185668945,
      "learning_rate": 0.00043216505707648095,
      "loss": 1.3873,
      "step": 15360
    },
    {
      "epoch": 49.42190016103059,
      "grad_norm": 0.22464598715305328,
      "learning_rate": 0.0004320773988343667,
      "loss": 1.3831,
      "step": 15370
    },
    {
      "epoch": 49.45410628019324,
      "grad_norm": 0.33465930819511414,
      "learning_rate": 0.00043198969289405054,
      "loss": 1.4053,
      "step": 15380
    },
    {
      "epoch": 49.486312399355874,
      "grad_norm": 0.3234577775001526,
      "learning_rate": 0.00043190193927850843,
      "loss": 1.3845,
      "step": 15390
    },
    {
      "epoch": 49.51851851851852,
      "grad_norm": 0.3786839246749878,
      "learning_rate": 0.00043181413801072886,
      "loss": 1.3986,
      "step": 15400
    },
    {
      "epoch": 49.55072463768116,
      "grad_norm": 0.2568833827972412,
      "learning_rate": 0.0004317262891137129,
      "loss": 1.3681,
      "step": 15410
    },
    {
      "epoch": 49.5829307568438,
      "grad_norm": 0.27493709325790405,
      "learning_rate": 0.000431638392610474,
      "loss": 1.3701,
      "step": 15420
    },
    {
      "epoch": 49.61513687600644,
      "grad_norm": 0.19969472289085388,
      "learning_rate": 0.0004315504485240381,
      "loss": 1.3916,
      "step": 15430
    },
    {
      "epoch": 49.64734299516908,
      "grad_norm": 0.2528415322303772,
      "learning_rate": 0.00043146245687744367,
      "loss": 1.3983,
      "step": 15440
    },
    {
      "epoch": 49.67954911433172,
      "grad_norm": 0.24391700327396393,
      "learning_rate": 0.00043137441769374157,
      "loss": 1.3772,
      "step": 15450
    },
    {
      "epoch": 49.711755233494365,
      "grad_norm": 0.25191259384155273,
      "learning_rate": 0.0004312863309959951,
      "loss": 1.3958,
      "step": 15460
    },
    {
      "epoch": 49.743961352657,
      "grad_norm": 0.2533705234527588,
      "learning_rate": 0.00043119819680728,
      "loss": 1.3583,
      "step": 15470
    },
    {
      "epoch": 49.77616747181965,
      "grad_norm": 0.21652869880199432,
      "learning_rate": 0.00043111001515068454,
      "loss": 1.3671,
      "step": 15480
    },
    {
      "epoch": 49.808373590982285,
      "grad_norm": 0.27585074305534363,
      "learning_rate": 0.00043102178604930943,
      "loss": 1.4071,
      "step": 15490
    },
    {
      "epoch": 49.84057971014493,
      "grad_norm": 0.3327223062515259,
      "learning_rate": 0.0004309335095262675,
      "loss": 1.3782,
      "step": 15500
    },
    {
      "epoch": 49.87278582930757,
      "grad_norm": 0.2602255344390869,
      "learning_rate": 0.00043084518560468463,
      "loss": 1.3853,
      "step": 15510
    },
    {
      "epoch": 49.90499194847021,
      "grad_norm": 0.2464493364095688,
      "learning_rate": 0.00043075681430769844,
      "loss": 1.392,
      "step": 15520
    },
    {
      "epoch": 49.93719806763285,
      "grad_norm": 0.24924775958061218,
      "learning_rate": 0.00043066839565845933,
      "loss": 1.3841,
      "step": 15530
    },
    {
      "epoch": 49.969404186795494,
      "grad_norm": 0.21328112483024597,
      "learning_rate": 0.00043057992968013013,
      "loss": 1.3938,
      "step": 15540
    },
    {
      "epoch": 50.0,
      "grad_norm": 0.2103128582239151,
      "learning_rate": 0.0004304914163958859,
      "loss": 1.3027,
      "step": 15550
    },
    {
      "epoch": 50.0,
      "eval_loss": 0.6432890295982361,
      "eval_runtime": 7.0579,
      "eval_samples_per_second": 3443.359,
      "eval_steps_per_second": 13.46,
      "step": 15550
    },
    {
      "epoch": 50.03220611916264,
      "grad_norm": 0.25125762820243835,
      "learning_rate": 0.0004304028558289141,
      "loss": 1.3987,
      "step": 15560
    },
    {
      "epoch": 50.06441223832528,
      "grad_norm": 0.2818126082420349,
      "learning_rate": 0.0004303142480024149,
      "loss": 1.3854,
      "step": 15570
    },
    {
      "epoch": 50.09661835748792,
      "grad_norm": 0.21022461354732513,
      "learning_rate": 0.00043022559293960026,
      "loss": 1.3611,
      "step": 15580
    },
    {
      "epoch": 50.128824476650564,
      "grad_norm": 0.2728439271450043,
      "learning_rate": 0.00043013689066369505,
      "loss": 1.393,
      "step": 15590
    },
    {
      "epoch": 50.1610305958132,
      "grad_norm": 0.2751763164997101,
      "learning_rate": 0.00043004814119793625,
      "loss": 1.3856,
      "step": 15600
    },
    {
      "epoch": 50.193236714975846,
      "grad_norm": 0.3219703435897827,
      "learning_rate": 0.0004299593445655733,
      "loss": 1.3799,
      "step": 15610
    },
    {
      "epoch": 50.225442834138484,
      "grad_norm": 0.2421211302280426,
      "learning_rate": 0.0004298705007898679,
      "loss": 1.3789,
      "step": 15620
    },
    {
      "epoch": 50.25764895330113,
      "grad_norm": 0.319046288728714,
      "learning_rate": 0.0004297816098940941,
      "loss": 1.362,
      "step": 15630
    },
    {
      "epoch": 50.289855072463766,
      "grad_norm": 0.35219091176986694,
      "learning_rate": 0.0004296926719015385,
      "loss": 1.3784,
      "step": 15640
    },
    {
      "epoch": 50.32206119162641,
      "grad_norm": 0.7853711843490601,
      "learning_rate": 0.0004296036868354998,
      "loss": 1.3851,
      "step": 15650
    },
    {
      "epoch": 50.35426731078905,
      "grad_norm": 0.2396191656589508,
      "learning_rate": 0.00042951465471928907,
      "loss": 1.3975,
      "step": 15660
    },
    {
      "epoch": 50.38647342995169,
      "grad_norm": 0.23277483880519867,
      "learning_rate": 0.0004294255755762299,
      "loss": 1.3839,
      "step": 15670
    },
    {
      "epoch": 50.41867954911433,
      "grad_norm": 0.24628636240959167,
      "learning_rate": 0.0004293364494296579,
      "loss": 1.3885,
      "step": 15680
    },
    {
      "epoch": 50.450885668276975,
      "grad_norm": 0.23712612688541412,
      "learning_rate": 0.00042924727630292125,
      "loss": 1.3743,
      "step": 15690
    },
    {
      "epoch": 50.48309178743961,
      "grad_norm": 0.3483787477016449,
      "learning_rate": 0.00042915805621938024,
      "loss": 1.3861,
      "step": 15700
    },
    {
      "epoch": 50.51529790660226,
      "grad_norm": 0.32937753200531006,
      "learning_rate": 0.00042906878920240764,
      "loss": 1.375,
      "step": 15710
    },
    {
      "epoch": 50.547504025764894,
      "grad_norm": 0.25330087542533875,
      "learning_rate": 0.0004289794752753884,
      "loss": 1.3913,
      "step": 15720
    },
    {
      "epoch": 50.57971014492754,
      "grad_norm": 0.22061075270175934,
      "learning_rate": 0.00042889011446171975,
      "loss": 1.3743,
      "step": 15730
    },
    {
      "epoch": 50.611916264090176,
      "grad_norm": 0.28512656688690186,
      "learning_rate": 0.0004288007067848113,
      "loss": 1.3973,
      "step": 15740
    },
    {
      "epoch": 50.64412238325282,
      "grad_norm": 0.23735475540161133,
      "learning_rate": 0.0004287112522680848,
      "loss": 1.3829,
      "step": 15750
    },
    {
      "epoch": 50.67632850241546,
      "grad_norm": 0.31823626160621643,
      "learning_rate": 0.0004286217509349745,
      "loss": 1.3883,
      "step": 15760
    },
    {
      "epoch": 50.7085346215781,
      "grad_norm": 0.2555101215839386,
      "learning_rate": 0.0004285322028089266,
      "loss": 1.4024,
      "step": 15770
    },
    {
      "epoch": 50.74074074074074,
      "grad_norm": 0.22570070624351501,
      "learning_rate": 0.0004284426079133997,
      "loss": 1.3831,
      "step": 15780
    },
    {
      "epoch": 50.772946859903385,
      "grad_norm": 0.29643532633781433,
      "learning_rate": 0.00042835296627186494,
      "loss": 1.3736,
      "step": 15790
    },
    {
      "epoch": 50.80515297906602,
      "grad_norm": 0.2630564272403717,
      "learning_rate": 0.0004282632779078051,
      "loss": 1.4044,
      "step": 15800
    },
    {
      "epoch": 50.83735909822866,
      "grad_norm": 0.2560108006000519,
      "learning_rate": 0.00042817354284471575,
      "loss": 1.3955,
      "step": 15810
    },
    {
      "epoch": 50.869565217391305,
      "grad_norm": 0.25702792406082153,
      "learning_rate": 0.00042808376110610436,
      "loss": 1.3764,
      "step": 15820
    },
    {
      "epoch": 50.90177133655394,
      "grad_norm": 0.23306792974472046,
      "learning_rate": 0.00042799393271549094,
      "loss": 1.3788,
      "step": 15830
    },
    {
      "epoch": 50.93397745571659,
      "grad_norm": 0.23060768842697144,
      "learning_rate": 0.0004279040576964073,
      "loss": 1.3565,
      "step": 15840
    },
    {
      "epoch": 50.966183574879224,
      "grad_norm": 0.2385288029909134,
      "learning_rate": 0.0004278141360723978,
      "loss": 1.3794,
      "step": 15850
    },
    {
      "epoch": 50.99838969404187,
      "grad_norm": 0.2767559885978699,
      "learning_rate": 0.00042772416786701894,
      "loss": 1.3896,
      "step": 15860
    },
    {
      "epoch": 51.0,
      "eval_loss": 0.6399871110916138,
      "eval_runtime": 7.0987,
      "eval_samples_per_second": 3423.604,
      "eval_steps_per_second": 13.383,
      "step": 15861
    },
    {
      "epoch": 51.028985507246375,
      "grad_norm": 0.4826098084449768,
      "learning_rate": 0.0004276341531038393,
      "loss": 1.3099,
      "step": 15870
    },
    {
      "epoch": 51.06119162640902,
      "grad_norm": 0.2733643651008606,
      "learning_rate": 0.0004275440918064398,
      "loss": 1.3857,
      "step": 15880
    },
    {
      "epoch": 51.09339774557166,
      "grad_norm": 0.30254656076431274,
      "learning_rate": 0.00042745398399841357,
      "loss": 1.3788,
      "step": 15890
    },
    {
      "epoch": 51.1256038647343,
      "grad_norm": 0.2813802659511566,
      "learning_rate": 0.0004273638297033657,
      "loss": 1.3648,
      "step": 15900
    },
    {
      "epoch": 51.15780998389694,
      "grad_norm": 0.3109825849533081,
      "learning_rate": 0.0004272736289449137,
      "loss": 1.3929,
      "step": 15910
    },
    {
      "epoch": 51.190016103059584,
      "grad_norm": 0.3243425488471985,
      "learning_rate": 0.0004271833817466871,
      "loss": 1.3841,
      "step": 15920
    },
    {
      "epoch": 51.22222222222222,
      "grad_norm": 0.2685398459434509,
      "learning_rate": 0.00042709308813232774,
      "loss": 1.3795,
      "step": 15930
    },
    {
      "epoch": 51.254428341384866,
      "grad_norm": 0.3200247585773468,
      "learning_rate": 0.0004270027481254894,
      "loss": 1.4022,
      "step": 15940
    },
    {
      "epoch": 51.2866344605475,
      "grad_norm": 0.41398540139198303,
      "learning_rate": 0.00042691236174983825,
      "loss": 1.3753,
      "step": 15950
    },
    {
      "epoch": 51.31884057971015,
      "grad_norm": 0.23780220746994019,
      "learning_rate": 0.0004268219290290525,
      "loss": 1.3767,
      "step": 15960
    },
    {
      "epoch": 51.351046698872786,
      "grad_norm": 0.268052875995636,
      "learning_rate": 0.00042673144998682245,
      "loss": 1.394,
      "step": 15970
    },
    {
      "epoch": 51.38325281803543,
      "grad_norm": 0.201248899102211,
      "learning_rate": 0.00042664092464685067,
      "loss": 1.3658,
      "step": 15980
    },
    {
      "epoch": 51.41545893719807,
      "grad_norm": 0.26115119457244873,
      "learning_rate": 0.00042655035303285175,
      "loss": 1.3728,
      "step": 15990
    },
    {
      "epoch": 51.447665056360705,
      "grad_norm": 0.3070079982280731,
      "learning_rate": 0.0004264597351685523,
      "loss": 1.386,
      "step": 16000
    },
    {
      "epoch": 51.47987117552335,
      "grad_norm": 0.28743064403533936,
      "learning_rate": 0.00042636907107769143,
      "loss": 1.3741,
      "step": 16010
    },
    {
      "epoch": 51.51207729468599,
      "grad_norm": 0.2987706661224365,
      "learning_rate": 0.0004262783607840199,
      "loss": 1.3843,
      "step": 16020
    },
    {
      "epoch": 51.54428341384863,
      "grad_norm": 0.2779640853404999,
      "learning_rate": 0.0004261876043113008,
      "loss": 1.3992,
      "step": 16030
    },
    {
      "epoch": 51.57648953301127,
      "grad_norm": 0.24935653805732727,
      "learning_rate": 0.0004260968016833094,
      "loss": 1.3821,
      "step": 16040
    },
    {
      "epoch": 51.608695652173914,
      "grad_norm": 0.23977628350257874,
      "learning_rate": 0.00042600595292383286,
      "loss": 1.3628,
      "step": 16050
    },
    {
      "epoch": 51.64090177133655,
      "grad_norm": 0.2487127035856247,
      "learning_rate": 0.0004259150580566706,
      "loss": 1.4038,
      "step": 16060
    },
    {
      "epoch": 51.673107890499196,
      "grad_norm": 0.24030031263828278,
      "learning_rate": 0.00042582411710563394,
      "loss": 1.3775,
      "step": 16070
    },
    {
      "epoch": 51.70531400966183,
      "grad_norm": 0.29929640889167786,
      "learning_rate": 0.0004257331300945465,
      "loss": 1.3798,
      "step": 16080
    },
    {
      "epoch": 51.73752012882448,
      "grad_norm": 0.22216762602329254,
      "learning_rate": 0.0004256420970472438,
      "loss": 1.3677,
      "step": 16090
    },
    {
      "epoch": 51.769726247987116,
      "grad_norm": 0.2517257630825043,
      "learning_rate": 0.0004255510179875733,
      "loss": 1.3839,
      "step": 16100
    },
    {
      "epoch": 51.80193236714976,
      "grad_norm": 0.2761436104774475,
      "learning_rate": 0.000425459892939395,
      "loss": 1.4233,
      "step": 16110
    },
    {
      "epoch": 51.8341384863124,
      "grad_norm": 0.27765288949012756,
      "learning_rate": 0.00042536872192658034,
      "loss": 1.3834,
      "step": 16120
    },
    {
      "epoch": 51.86634460547504,
      "grad_norm": 0.2944421172142029,
      "learning_rate": 0.0004252775049730132,
      "loss": 1.3689,
      "step": 16130
    },
    {
      "epoch": 51.89855072463768,
      "grad_norm": 0.3095256984233856,
      "learning_rate": 0.0004251862421025893,
      "loss": 1.3879,
      "step": 16140
    },
    {
      "epoch": 51.930756843800324,
      "grad_norm": 0.26861488819122314,
      "learning_rate": 0.00042509493333921656,
      "loss": 1.4021,
      "step": 16150
    },
    {
      "epoch": 51.96296296296296,
      "grad_norm": 0.24593870341777802,
      "learning_rate": 0.00042500357870681475,
      "loss": 1.3842,
      "step": 16160
    },
    {
      "epoch": 51.99516908212561,
      "grad_norm": 0.2296641618013382,
      "learning_rate": 0.0004249121782293159,
      "loss": 1.3886,
      "step": 16170
    },
    {
      "epoch": 52.0,
      "eval_loss": 0.6418410539627075,
      "eval_runtime": 7.1278,
      "eval_samples_per_second": 3409.602,
      "eval_steps_per_second": 13.328,
      "step": 16172
    },
    {
      "epoch": 52.02576489533011,
      "grad_norm": 0.27150997519493103,
      "learning_rate": 0.0004248207319306636,
      "loss": 1.3216,
      "step": 16180
    },
    {
      "epoch": 52.05797101449275,
      "grad_norm": 0.35925036668777466,
      "learning_rate": 0.000424729239834814,
      "loss": 1.3877,
      "step": 16190
    },
    {
      "epoch": 52.090177133655395,
      "grad_norm": 0.32733070850372314,
      "learning_rate": 0.0004246377019657348,
      "loss": 1.3723,
      "step": 16200
    },
    {
      "epoch": 52.12238325281803,
      "grad_norm": 0.26608723402023315,
      "learning_rate": 0.00042454611834740597,
      "loss": 1.3757,
      "step": 16210
    },
    {
      "epoch": 52.15458937198068,
      "grad_norm": 0.22047187387943268,
      "learning_rate": 0.00042445448900381926,
      "loss": 1.3821,
      "step": 16220
    },
    {
      "epoch": 52.186795491143315,
      "grad_norm": 0.3229110538959503,
      "learning_rate": 0.00042436281395897863,
      "loss": 1.4036,
      "step": 16230
    },
    {
      "epoch": 52.21900161030596,
      "grad_norm": 0.2693948745727539,
      "learning_rate": 0.0004242710932368998,
      "loss": 1.3908,
      "step": 16240
    },
    {
      "epoch": 52.2512077294686,
      "grad_norm": 0.317722350358963,
      "learning_rate": 0.00042417932686161054,
      "loss": 1.3654,
      "step": 16250
    },
    {
      "epoch": 52.28341384863124,
      "grad_norm": 0.2758874297142029,
      "learning_rate": 0.0004240875148571506,
      "loss": 1.3763,
      "step": 16260
    },
    {
      "epoch": 52.31561996779388,
      "grad_norm": 0.26532605290412903,
      "learning_rate": 0.0004239956572475716,
      "loss": 1.3772,
      "step": 16270
    },
    {
      "epoch": 52.34782608695652,
      "grad_norm": 0.32153329253196716,
      "learning_rate": 0.0004239037540569373,
      "loss": 1.3878,
      "step": 16280
    },
    {
      "epoch": 52.38003220611916,
      "grad_norm": 0.24837058782577515,
      "learning_rate": 0.0004238118053093232,
      "loss": 1.401,
      "step": 16290
    },
    {
      "epoch": 52.412238325281805,
      "grad_norm": 0.2649609446525574,
      "learning_rate": 0.0004237198110288166,
      "loss": 1.3758,
      "step": 16300
    },
    {
      "epoch": 52.44444444444444,
      "grad_norm": 0.3092993199825287,
      "learning_rate": 0.00042362777123951733,
      "loss": 1.3906,
      "step": 16310
    },
    {
      "epoch": 52.47665056360709,
      "grad_norm": 0.22231850028038025,
      "learning_rate": 0.0004235356859655365,
      "loss": 1.3637,
      "step": 16320
    },
    {
      "epoch": 52.508856682769725,
      "grad_norm": 0.2831113338470459,
      "learning_rate": 0.0004234435552309973,
      "loss": 1.3691,
      "step": 16330
    },
    {
      "epoch": 52.54106280193237,
      "grad_norm": 0.27323660254478455,
      "learning_rate": 0.00042335137906003513,
      "loss": 1.3775,
      "step": 16340
    },
    {
      "epoch": 52.57326892109501,
      "grad_norm": 0.2883375585079193,
      "learning_rate": 0.00042325915747679695,
      "loss": 1.3942,
      "step": 16350
    },
    {
      "epoch": 52.60547504025765,
      "grad_norm": 0.2932799458503723,
      "learning_rate": 0.0004231668905054417,
      "loss": 1.3774,
      "step": 16360
    },
    {
      "epoch": 52.63768115942029,
      "grad_norm": 0.2676735818386078,
      "learning_rate": 0.00042307457817014035,
      "loss": 1.3843,
      "step": 16370
    },
    {
      "epoch": 52.669887278582934,
      "grad_norm": 0.31453076004981995,
      "learning_rate": 0.00042298222049507556,
      "loss": 1.3929,
      "step": 16380
    },
    {
      "epoch": 52.70209339774557,
      "grad_norm": 0.3047650456428528,
      "learning_rate": 0.000422889817504442,
      "loss": 1.3692,
      "step": 16390
    },
    {
      "epoch": 52.734299516908216,
      "grad_norm": 0.23482827842235565,
      "learning_rate": 0.0004227973692224462,
      "loss": 1.3728,
      "step": 16400
    },
    {
      "epoch": 52.76650563607085,
      "grad_norm": 0.20329636335372925,
      "learning_rate": 0.00042270487567330653,
      "loss": 1.3842,
      "step": 16410
    },
    {
      "epoch": 52.7987117552335,
      "grad_norm": 0.20695213973522186,
      "learning_rate": 0.000422612336881253,
      "loss": 1.3764,
      "step": 16420
    },
    {
      "epoch": 52.830917874396135,
      "grad_norm": 0.30772244930267334,
      "learning_rate": 0.000422519752870528,
      "loss": 1.376,
      "step": 16430
    },
    {
      "epoch": 52.86312399355877,
      "grad_norm": 0.2189423143863678,
      "learning_rate": 0.0004224271236653853,
      "loss": 1.369,
      "step": 16440
    },
    {
      "epoch": 52.89533011272142,
      "grad_norm": 0.2606186866760254,
      "learning_rate": 0.0004223344492900906,
      "loss": 1.3945,
      "step": 16450
    },
    {
      "epoch": 52.927536231884055,
      "grad_norm": 0.2685336470603943,
      "learning_rate": 0.0004222417297689217,
      "loss": 1.3909,
      "step": 16460
    },
    {
      "epoch": 52.9597423510467,
      "grad_norm": 0.22650249302387238,
      "learning_rate": 0.00042214896512616774,
      "loss": 1.4008,
      "step": 16470
    },
    {
      "epoch": 52.99194847020934,
      "grad_norm": 0.23339414596557617,
      "learning_rate": 0.0004220561553861302,
      "loss": 1.3842,
      "step": 16480
    },
    {
      "epoch": 53.0,
      "eval_loss": 0.6419622898101807,
      "eval_runtime": 7.0718,
      "eval_samples_per_second": 3436.602,
      "eval_steps_per_second": 13.434,
      "step": 16483
    },
    {
      "epoch": 53.02254428341385,
      "grad_norm": 0.24060283601284027,
      "learning_rate": 0.000421963300573122,
      "loss": 1.328,
      "step": 16490
    },
    {
      "epoch": 53.05475040257649,
      "grad_norm": 0.21226133406162262,
      "learning_rate": 0.00042187040071146805,
      "loss": 1.3749,
      "step": 16500
    },
    {
      "epoch": 53.08695652173913,
      "grad_norm": 0.2306455671787262,
      "learning_rate": 0.00042177745582550497,
      "loss": 1.3957,
      "step": 16510
    },
    {
      "epoch": 53.11916264090177,
      "grad_norm": 0.3512727618217468,
      "learning_rate": 0.0004216844659395813,
      "loss": 1.3876,
      "step": 16520
    },
    {
      "epoch": 53.151368760064415,
      "grad_norm": 0.30226200819015503,
      "learning_rate": 0.00042159143107805717,
      "loss": 1.3685,
      "step": 16530
    },
    {
      "epoch": 53.18357487922705,
      "grad_norm": 0.2974243760108948,
      "learning_rate": 0.0004214983512653048,
      "loss": 1.3939,
      "step": 16540
    },
    {
      "epoch": 53.2157809983897,
      "grad_norm": 0.33537814021110535,
      "learning_rate": 0.0004214052265257077,
      "loss": 1.3801,
      "step": 16550
    },
    {
      "epoch": 53.247987117552334,
      "grad_norm": 0.27890825271606445,
      "learning_rate": 0.0004213120568836618,
      "loss": 1.3549,
      "step": 16560
    },
    {
      "epoch": 53.28019323671498,
      "grad_norm": 0.40219801664352417,
      "learning_rate": 0.0004212188423635741,
      "loss": 1.3863,
      "step": 16570
    },
    {
      "epoch": 53.312399355877616,
      "grad_norm": 0.2379063367843628,
      "learning_rate": 0.0004211255829898639,
      "loss": 1.3616,
      "step": 16580
    },
    {
      "epoch": 53.34460547504026,
      "grad_norm": 0.26271459460258484,
      "learning_rate": 0.00042103227878696205,
      "loss": 1.3753,
      "step": 16590
    },
    {
      "epoch": 53.3768115942029,
      "grad_norm": 0.40706485509872437,
      "learning_rate": 0.00042093892977931104,
      "loss": 1.3598,
      "step": 16600
    },
    {
      "epoch": 53.409017713365536,
      "grad_norm": 0.3108064830303192,
      "learning_rate": 0.0004208455359913652,
      "loss": 1.4093,
      "step": 16610
    },
    {
      "epoch": 53.44122383252818,
      "grad_norm": 0.28746530413627625,
      "learning_rate": 0.00042075209744759067,
      "loss": 1.378,
      "step": 16620
    },
    {
      "epoch": 53.47342995169082,
      "grad_norm": 0.2811610698699951,
      "learning_rate": 0.00042065861417246513,
      "loss": 1.4124,
      "step": 16630
    },
    {
      "epoch": 53.50563607085346,
      "grad_norm": 0.2793084383010864,
      "learning_rate": 0.00042056508619047817,
      "loss": 1.3823,
      "step": 16640
    },
    {
      "epoch": 53.5378421900161,
      "grad_norm": 0.3908992409706116,
      "learning_rate": 0.0004204715135261309,
      "loss": 1.3697,
      "step": 16650
    },
    {
      "epoch": 53.570048309178745,
      "grad_norm": 0.2799133360385895,
      "learning_rate": 0.00042037789620393636,
      "loss": 1.3965,
      "step": 16660
    },
    {
      "epoch": 53.60225442834138,
      "grad_norm": 0.4821802079677582,
      "learning_rate": 0.0004202842342484191,
      "loss": 1.3772,
      "step": 16670
    },
    {
      "epoch": 53.63446054750403,
      "grad_norm": 0.3214739263057709,
      "learning_rate": 0.0004201905276841153,
      "loss": 1.4058,
      "step": 16680
    },
    {
      "epoch": 53.666666666666664,
      "grad_norm": 0.3525926172733307,
      "learning_rate": 0.0004200967765355732,
      "loss": 1.3843,
      "step": 16690
    },
    {
      "epoch": 53.69887278582931,
      "grad_norm": 0.2386236935853958,
      "learning_rate": 0.00042000298082735233,
      "loss": 1.3912,
      "step": 16700
    },
    {
      "epoch": 53.731078904991946,
      "grad_norm": 0.28722259402275085,
      "learning_rate": 0.00041990914058402396,
      "loss": 1.3804,
      "step": 16710
    },
    {
      "epoch": 53.76328502415459,
      "grad_norm": 0.23142105340957642,
      "learning_rate": 0.0004198152558301713,
      "loss": 1.3898,
      "step": 16720
    },
    {
      "epoch": 53.79549114331723,
      "grad_norm": 0.2933328449726105,
      "learning_rate": 0.00041972132659038886,
      "loss": 1.3713,
      "step": 16730
    },
    {
      "epoch": 53.82769726247987,
      "grad_norm": 0.26176637411117554,
      "learning_rate": 0.00041962735288928306,
      "loss": 1.3795,
      "step": 16740
    },
    {
      "epoch": 53.85990338164251,
      "grad_norm": 0.7242515683174133,
      "learning_rate": 0.0004195333347514718,
      "loss": 1.3753,
      "step": 16750
    },
    {
      "epoch": 53.892109500805155,
      "grad_norm": 0.24640916287899017,
      "learning_rate": 0.00041943927220158475,
      "loss": 1.3682,
      "step": 16760
    },
    {
      "epoch": 53.92431561996779,
      "grad_norm": 0.2694946825504303,
      "learning_rate": 0.00041934516526426316,
      "loss": 1.3718,
      "step": 16770
    },
    {
      "epoch": 53.95652173913044,
      "grad_norm": 0.25448164343833923,
      "learning_rate": 0.00041925101396415984,
      "loss": 1.3781,
      "step": 16780
    },
    {
      "epoch": 53.988727858293075,
      "grad_norm": 0.2655618488788605,
      "learning_rate": 0.00041915681832593936,
      "loss": 1.3899,
      "step": 16790
    },
    {
      "epoch": 54.0,
      "eval_loss": 0.641476035118103,
      "eval_runtime": 7.2387,
      "eval_samples_per_second": 3357.388,
      "eval_steps_per_second": 13.124,
      "step": 16794
    },
    {
      "epoch": 54.01932367149758,
      "grad_norm": 0.30256929993629456,
      "learning_rate": 0.00041906257837427777,
      "loss": 1.3034,
      "step": 16800
    },
    {
      "epoch": 54.051529790660226,
      "grad_norm": 0.35194599628448486,
      "learning_rate": 0.0004189682941338629,
      "loss": 1.3902,
      "step": 16810
    },
    {
      "epoch": 54.08373590982286,
      "grad_norm": 0.2718949317932129,
      "learning_rate": 0.00041887396562939394,
      "loss": 1.3905,
      "step": 16820
    },
    {
      "epoch": 54.11594202898551,
      "grad_norm": 0.3374288082122803,
      "learning_rate": 0.00041877959288558187,
      "loss": 1.368,
      "step": 16830
    },
    {
      "epoch": 54.148148148148145,
      "grad_norm": 0.39647066593170166,
      "learning_rate": 0.0004186851759271493,
      "loss": 1.3875,
      "step": 16840
    },
    {
      "epoch": 54.18035426731079,
      "grad_norm": 0.21872949600219727,
      "learning_rate": 0.00041859071477883013,
      "loss": 1.3701,
      "step": 16850
    },
    {
      "epoch": 54.21256038647343,
      "grad_norm": 0.31528353691101074,
      "learning_rate": 0.00041849620946537015,
      "loss": 1.3552,
      "step": 16860
    },
    {
      "epoch": 54.24476650563607,
      "grad_norm": 0.3364016115665436,
      "learning_rate": 0.0004184016600115266,
      "loss": 1.3683,
      "step": 16870
    },
    {
      "epoch": 54.27697262479871,
      "grad_norm": 0.33921948075294495,
      "learning_rate": 0.0004183070664420683,
      "loss": 1.377,
      "step": 16880
    },
    {
      "epoch": 54.309178743961354,
      "grad_norm": 0.22813190519809723,
      "learning_rate": 0.00041821242878177544,
      "loss": 1.3868,
      "step": 16890
    },
    {
      "epoch": 54.34138486312399,
      "grad_norm": 0.2774306833744049,
      "learning_rate": 0.0004181177470554401,
      "loss": 1.3707,
      "step": 16900
    },
    {
      "epoch": 54.373590982286636,
      "grad_norm": 0.3341074585914612,
      "learning_rate": 0.00041802302128786574,
      "loss": 1.3712,
      "step": 16910
    },
    {
      "epoch": 54.405797101449274,
      "grad_norm": 0.2722313702106476,
      "learning_rate": 0.0004179282515038672,
      "loss": 1.4,
      "step": 16920
    },
    {
      "epoch": 54.43800322061192,
      "grad_norm": 0.4337460398674011,
      "learning_rate": 0.00041783343772827116,
      "loss": 1.3896,
      "step": 16930
    },
    {
      "epoch": 54.470209339774556,
      "grad_norm": 0.2993960380554199,
      "learning_rate": 0.0004177385799859156,
      "loss": 1.3651,
      "step": 16940
    },
    {
      "epoch": 54.5024154589372,
      "grad_norm": 0.3706751763820648,
      "learning_rate": 0.00041764367830164997,
      "loss": 1.3817,
      "step": 16950
    },
    {
      "epoch": 54.53462157809984,
      "grad_norm": 0.3233802318572998,
      "learning_rate": 0.0004175487327003356,
      "loss": 1.3752,
      "step": 16960
    },
    {
      "epoch": 54.56682769726248,
      "grad_norm": 0.23819749057292938,
      "learning_rate": 0.0004174537432068449,
      "loss": 1.377,
      "step": 16970
    },
    {
      "epoch": 54.59903381642512,
      "grad_norm": 0.21272918581962585,
      "learning_rate": 0.00041735870984606187,
      "loss": 1.3909,
      "step": 16980
    },
    {
      "epoch": 54.631239935587764,
      "grad_norm": 0.21253974735736847,
      "learning_rate": 0.0004172636326428823,
      "loss": 1.3909,
      "step": 16990
    },
    {
      "epoch": 54.6634460547504,
      "grad_norm": 0.2756127417087555,
      "learning_rate": 0.000417168511622213,
      "loss": 1.3695,
      "step": 17000
    },
    {
      "epoch": 54.69565217391305,
      "grad_norm": 0.27061927318573,
      "learning_rate": 0.00041707334680897277,
      "loss": 1.4141,
      "step": 17010
    },
    {
      "epoch": 54.727858293075684,
      "grad_norm": 0.2596678137779236,
      "learning_rate": 0.0004169781382280914,
      "loss": 1.4124,
      "step": 17020
    },
    {
      "epoch": 54.76006441223833,
      "grad_norm": 0.2863655388355255,
      "learning_rate": 0.00041688288590451043,
      "loss": 1.3823,
      "step": 17030
    },
    {
      "epoch": 54.792270531400966,
      "grad_norm": 0.3711210787296295,
      "learning_rate": 0.0004167875898631828,
      "loss": 1.3619,
      "step": 17040
    },
    {
      "epoch": 54.824476650563604,
      "grad_norm": 0.22599337995052338,
      "learning_rate": 0.0004166922501290729,
      "loss": 1.4033,
      "step": 17050
    },
    {
      "epoch": 54.85668276972625,
      "grad_norm": 0.26849859952926636,
      "learning_rate": 0.00041659686672715655,
      "loss": 1.3994,
      "step": 17060
    },
    {
      "epoch": 54.888888888888886,
      "grad_norm": 0.20646686851978302,
      "learning_rate": 0.000416501439682421,
      "loss": 1.3924,
      "step": 17070
    },
    {
      "epoch": 54.92109500805153,
      "grad_norm": 0.22945834696292877,
      "learning_rate": 0.00041640596901986495,
      "loss": 1.409,
      "step": 17080
    },
    {
      "epoch": 54.95330112721417,
      "grad_norm": 0.3465804159641266,
      "learning_rate": 0.0004163104547644986,
      "loss": 1.3774,
      "step": 17090
    },
    {
      "epoch": 54.98550724637681,
      "grad_norm": 0.20557783544063568,
      "learning_rate": 0.00041621489694134334,
      "loss": 1.3701,
      "step": 17100
    },
    {
      "epoch": 55.0,
      "eval_loss": 0.6434891223907471,
      "eval_runtime": 7.1075,
      "eval_samples_per_second": 3419.33,
      "eval_steps_per_second": 13.366,
      "step": 17105
    },
    {
      "epoch": 55.01610305958132,
      "grad_norm": 0.6352505087852478,
      "learning_rate": 0.0004161192955754323,
      "loss": 1.2998,
      "step": 17110
    },
    {
      "epoch": 55.04830917874396,
      "grad_norm": 0.2335343211889267,
      "learning_rate": 0.0004160236506918098,
      "loss": 1.3757,
      "step": 17120
    },
    {
      "epoch": 55.0805152979066,
      "grad_norm": 0.3030850291252136,
      "learning_rate": 0.00041592796231553153,
      "loss": 1.3911,
      "step": 17130
    },
    {
      "epoch": 55.112721417069245,
      "grad_norm": 0.2491614669561386,
      "learning_rate": 0.0004158322304716647,
      "loss": 1.3826,
      "step": 17140
    },
    {
      "epoch": 55.14492753623188,
      "grad_norm": 0.2559606432914734,
      "learning_rate": 0.0004157364551852879,
      "loss": 1.3985,
      "step": 17150
    },
    {
      "epoch": 55.17713365539453,
      "grad_norm": 0.3599603772163391,
      "learning_rate": 0.000415640636481491,
      "loss": 1.3694,
      "step": 17160
    },
    {
      "epoch": 55.209339774557165,
      "grad_norm": 0.2410062998533249,
      "learning_rate": 0.00041554477438537533,
      "loss": 1.3777,
      "step": 17170
    },
    {
      "epoch": 55.24154589371981,
      "grad_norm": 0.22839275002479553,
      "learning_rate": 0.00041544886892205357,
      "loss": 1.3646,
      "step": 17180
    },
    {
      "epoch": 55.27375201288245,
      "grad_norm": 0.396910160779953,
      "learning_rate": 0.00041535292011664966,
      "loss": 1.384,
      "step": 17190
    },
    {
      "epoch": 55.30595813204509,
      "grad_norm": 0.27308377623558044,
      "learning_rate": 0.00041525692799429916,
      "loss": 1.3803,
      "step": 17200
    },
    {
      "epoch": 55.33816425120773,
      "grad_norm": 0.4079796075820923,
      "learning_rate": 0.00041516089258014866,
      "loss": 1.4,
      "step": 17210
    },
    {
      "epoch": 55.370370370370374,
      "grad_norm": 0.25059714913368225,
      "learning_rate": 0.00041506481389935626,
      "loss": 1.3791,
      "step": 17220
    },
    {
      "epoch": 55.40257648953301,
      "grad_norm": 0.22967298328876495,
      "learning_rate": 0.0004149686919770914,
      "loss": 1.3787,
      "step": 17230
    },
    {
      "epoch": 55.43478260869565,
      "grad_norm": 0.3226275146007538,
      "learning_rate": 0.0004148725268385348,
      "loss": 1.3754,
      "step": 17240
    },
    {
      "epoch": 55.46698872785829,
      "grad_norm": 0.34245505928993225,
      "learning_rate": 0.00041477631850887856,
      "loss": 1.3865,
      "step": 17250
    },
    {
      "epoch": 55.49919484702093,
      "grad_norm": 0.2583460211753845,
      "learning_rate": 0.00041468006701332594,
      "loss": 1.3692,
      "step": 17260
    },
    {
      "epoch": 55.531400966183575,
      "grad_norm": 0.2549372911453247,
      "learning_rate": 0.00041458377237709164,
      "loss": 1.3691,
      "step": 17270
    },
    {
      "epoch": 55.56360708534621,
      "grad_norm": 0.29921960830688477,
      "learning_rate": 0.00041448743462540186,
      "loss": 1.3947,
      "step": 17280
    },
    {
      "epoch": 55.59581320450886,
      "grad_norm": 0.2801704406738281,
      "learning_rate": 0.0004143910537834935,
      "loss": 1.3607,
      "step": 17290
    },
    {
      "epoch": 55.628019323671495,
      "grad_norm": 0.25068458914756775,
      "learning_rate": 0.0004142946298766155,
      "loss": 1.3783,
      "step": 17300
    },
    {
      "epoch": 55.66022544283414,
      "grad_norm": 0.2532346248626709,
      "learning_rate": 0.00041419816293002744,
      "loss": 1.3826,
      "step": 17310
    },
    {
      "epoch": 55.69243156199678,
      "grad_norm": 0.2609615623950958,
      "learning_rate": 0.0004141016529690006,
      "loss": 1.3748,
      "step": 17320
    },
    {
      "epoch": 55.72463768115942,
      "grad_norm": 0.18770766258239746,
      "learning_rate": 0.00041400510001881723,
      "loss": 1.3858,
      "step": 17330
    },
    {
      "epoch": 55.75684380032206,
      "grad_norm": 0.30484655499458313,
      "learning_rate": 0.0004139085041047711,
      "loss": 1.3835,
      "step": 17340
    },
    {
      "epoch": 55.789049919484704,
      "grad_norm": 0.28580981492996216,
      "learning_rate": 0.0004138118652521671,
      "loss": 1.3956,
      "step": 17350
    },
    {
      "epoch": 55.82125603864734,
      "grad_norm": 0.2955562472343445,
      "learning_rate": 0.0004137151834863213,
      "loss": 1.3985,
      "step": 17360
    },
    {
      "epoch": 55.853462157809986,
      "grad_norm": 0.19723810255527496,
      "learning_rate": 0.0004136184588325611,
      "loss": 1.414,
      "step": 17370
    },
    {
      "epoch": 55.88566827697262,
      "grad_norm": 0.2615506052970886,
      "learning_rate": 0.0004135216913162253,
      "loss": 1.3981,
      "step": 17380
    },
    {
      "epoch": 55.91787439613527,
      "grad_norm": 0.24317017197608948,
      "learning_rate": 0.0004134248809626636,
      "loss": 1.3667,
      "step": 17390
    },
    {
      "epoch": 55.950080515297905,
      "grad_norm": 0.2616065442562103,
      "learning_rate": 0.0004133280277972371,
      "loss": 1.3753,
      "step": 17400
    },
    {
      "epoch": 55.98228663446055,
      "grad_norm": 0.2566261887550354,
      "learning_rate": 0.00041323113184531815,
      "loss": 1.374,
      "step": 17410
    },
    {
      "epoch": 56.0,
      "eval_loss": 0.643131673336029,
      "eval_runtime": 7.0754,
      "eval_samples_per_second": 3434.874,
      "eval_steps_per_second": 13.427,
      "step": 17416
    },
    {
      "epoch": 56.012882447665056,
      "grad_norm": 0.22110499441623688,
      "learning_rate": 0.00041313419313229017,
      "loss": 1.2916,
      "step": 17420
    },
    {
      "epoch": 56.045088566827694,
      "grad_norm": 0.2211941033601761,
      "learning_rate": 0.000413037211683548,
      "loss": 1.3726,
      "step": 17430
    },
    {
      "epoch": 56.07729468599034,
      "grad_norm": 1.4158270359039307,
      "learning_rate": 0.00041294018752449744,
      "loss": 1.3541,
      "step": 17440
    },
    {
      "epoch": 56.109500805152976,
      "grad_norm": 0.235340416431427,
      "learning_rate": 0.00041284312068055564,
      "loss": 1.3819,
      "step": 17450
    },
    {
      "epoch": 56.14170692431562,
      "grad_norm": 0.2417457401752472,
      "learning_rate": 0.0004127460111771507,
      "loss": 1.3785,
      "step": 17460
    },
    {
      "epoch": 56.17391304347826,
      "grad_norm": 0.1948724389076233,
      "learning_rate": 0.0004126488590397224,
      "loss": 1.3823,
      "step": 17470
    },
    {
      "epoch": 56.2061191626409,
      "grad_norm": 0.39493387937545776,
      "learning_rate": 0.00041255166429372104,
      "loss": 1.3653,
      "step": 17480
    },
    {
      "epoch": 56.23832528180354,
      "grad_norm": 0.29194897413253784,
      "learning_rate": 0.00041245442696460856,
      "loss": 1.3783,
      "step": 17490
    },
    {
      "epoch": 56.270531400966185,
      "grad_norm": 0.24225963652133942,
      "learning_rate": 0.0004123571470778579,
      "loss": 1.3904,
      "step": 17500
    },
    {
      "epoch": 56.30273752012882,
      "grad_norm": 0.20118626952171326,
      "learning_rate": 0.00041225982465895305,
      "loss": 1.3876,
      "step": 17510
    },
    {
      "epoch": 56.33494363929147,
      "grad_norm": 0.279080331325531,
      "learning_rate": 0.00041216245973338926,
      "loss": 1.3702,
      "step": 17520
    },
    {
      "epoch": 56.367149758454104,
      "grad_norm": 0.2392357438802719,
      "learning_rate": 0.00041206505232667303,
      "loss": 1.3864,
      "step": 17530
    },
    {
      "epoch": 56.39935587761675,
      "grad_norm": 0.27202799916267395,
      "learning_rate": 0.00041196760246432177,
      "loss": 1.3859,
      "step": 17540
    },
    {
      "epoch": 56.43156199677939,
      "grad_norm": 0.25916099548339844,
      "learning_rate": 0.0004118701101718639,
      "loss": 1.3859,
      "step": 17550
    },
    {
      "epoch": 56.46376811594203,
      "grad_norm": 0.34214845299720764,
      "learning_rate": 0.0004117725754748394,
      "loss": 1.3773,
      "step": 17560
    },
    {
      "epoch": 56.49597423510467,
      "grad_norm": 0.24627389013767242,
      "learning_rate": 0.0004116749983987991,
      "loss": 1.3735,
      "step": 17570
    },
    {
      "epoch": 56.52818035426731,
      "grad_norm": 0.19975413382053375,
      "learning_rate": 0.0004115773789693047,
      "loss": 1.3921,
      "step": 17580
    },
    {
      "epoch": 56.56038647342995,
      "grad_norm": 0.23807118833065033,
      "learning_rate": 0.0004114797172119295,
      "loss": 1.3891,
      "step": 17590
    },
    {
      "epoch": 56.592592592592595,
      "grad_norm": 0.27841413021087646,
      "learning_rate": 0.0004113820131522575,
      "loss": 1.3784,
      "step": 17600
    },
    {
      "epoch": 56.62479871175523,
      "grad_norm": 0.2064104974269867,
      "learning_rate": 0.00041128426681588383,
      "loss": 1.3699,
      "step": 17610
    },
    {
      "epoch": 56.65700483091788,
      "grad_norm": 0.22400692105293274,
      "learning_rate": 0.00041118647822841495,
      "loss": 1.3926,
      "step": 17620
    },
    {
      "epoch": 56.689210950080515,
      "grad_norm": 0.22831006348133087,
      "learning_rate": 0.00041108864741546807,
      "loss": 1.3649,
      "step": 17630
    },
    {
      "epoch": 56.72141706924316,
      "grad_norm": 0.2695063650608063,
      "learning_rate": 0.0004109907744026716,
      "loss": 1.374,
      "step": 17640
    },
    {
      "epoch": 56.7536231884058,
      "grad_norm": 0.2867185175418854,
      "learning_rate": 0.0004108928592156651,
      "loss": 1.393,
      "step": 17650
    },
    {
      "epoch": 56.78582930756844,
      "grad_norm": 0.26628926396369934,
      "learning_rate": 0.000410794901880099,
      "loss": 1.3776,
      "step": 17660
    },
    {
      "epoch": 56.81803542673108,
      "grad_norm": 0.3410552144050598,
      "learning_rate": 0.0004106969024216348,
      "loss": 1.4011,
      "step": 17670
    },
    {
      "epoch": 56.85024154589372,
      "grad_norm": 0.22403031587600708,
      "learning_rate": 0.0004105988608659453,
      "loss": 1.3783,
      "step": 17680
    },
    {
      "epoch": 56.88244766505636,
      "grad_norm": 0.19727475941181183,
      "learning_rate": 0.0004105007772387139,
      "loss": 1.3826,
      "step": 17690
    },
    {
      "epoch": 56.914653784219,
      "grad_norm": 0.21319906413555145,
      "learning_rate": 0.0004104026515656353,
      "loss": 1.3771,
      "step": 17700
    },
    {
      "epoch": 56.94685990338164,
      "grad_norm": 0.2329283058643341,
      "learning_rate": 0.0004103044838724151,
      "loss": 1.3771,
      "step": 17710
    },
    {
      "epoch": 56.97906602254428,
      "grad_norm": 0.24760591983795166,
      "learning_rate": 0.00041020627418477014,
      "loss": 1.3812,
      "step": 17720
    },
    {
      "epoch": 57.0,
      "eval_loss": 0.6407954692840576,
      "eval_runtime": 7.0508,
      "eval_samples_per_second": 3446.826,
      "eval_steps_per_second": 13.474,
      "step": 17727
    },
    {
      "epoch": 57.009661835748794,
      "grad_norm": 0.7209638953208923,
      "learning_rate": 0.00041010802252842786,
      "loss": 1.307,
      "step": 17730
    },
    {
      "epoch": 57.04186795491143,
      "grad_norm": 0.2204657644033432,
      "learning_rate": 0.00041000972892912715,
      "loss": 1.3727,
      "step": 17740
    },
    {
      "epoch": 57.074074074074076,
      "grad_norm": 0.26298287510871887,
      "learning_rate": 0.0004099113934126174,
      "loss": 1.3721,
      "step": 17750
    },
    {
      "epoch": 57.106280193236714,
      "grad_norm": 0.20327873528003693,
      "learning_rate": 0.0004098130160046594,
      "loss": 1.3915,
      "step": 17760
    },
    {
      "epoch": 57.13848631239936,
      "grad_norm": 0.4205734431743622,
      "learning_rate": 0.0004097145967310247,
      "loss": 1.3686,
      "step": 17770
    },
    {
      "epoch": 57.170692431561996,
      "grad_norm": 0.27654343843460083,
      "learning_rate": 0.0004096161356174959,
      "loss": 1.3721,
      "step": 17780
    },
    {
      "epoch": 57.20289855072464,
      "grad_norm": 0.23149636387825012,
      "learning_rate": 0.0004095176326898664,
      "loss": 1.388,
      "step": 17790
    },
    {
      "epoch": 57.23510466988728,
      "grad_norm": 0.2616887390613556,
      "learning_rate": 0.0004094190879739409,
      "loss": 1.3796,
      "step": 17800
    },
    {
      "epoch": 57.26731078904992,
      "grad_norm": 0.2725014090538025,
      "learning_rate": 0.0004093205014955347,
      "loss": 1.3778,
      "step": 17810
    },
    {
      "epoch": 57.29951690821256,
      "grad_norm": 0.23813046514987946,
      "learning_rate": 0.000409221873280474,
      "loss": 1.3803,
      "step": 17820
    },
    {
      "epoch": 57.331723027375205,
      "grad_norm": 0.3158741593360901,
      "learning_rate": 0.0004091232033545964,
      "loss": 1.3686,
      "step": 17830
    },
    {
      "epoch": 57.36392914653784,
      "grad_norm": 0.3969869613647461,
      "learning_rate": 0.00040902449174374996,
      "loss": 1.3916,
      "step": 17840
    },
    {
      "epoch": 57.39613526570048,
      "grad_norm": 0.3391154110431671,
      "learning_rate": 0.00040892573847379387,
      "loss": 1.3892,
      "step": 17850
    },
    {
      "epoch": 57.428341384863124,
      "grad_norm": 0.2371666580438614,
      "learning_rate": 0.00040882694357059817,
      "loss": 1.3805,
      "step": 17860
    },
    {
      "epoch": 57.46054750402576,
      "grad_norm": 0.2621913254261017,
      "learning_rate": 0.00040872810706004385,
      "loss": 1.373,
      "step": 17870
    },
    {
      "epoch": 57.492753623188406,
      "grad_norm": 0.23809418082237244,
      "learning_rate": 0.0004086292289680228,
      "loss": 1.3878,
      "step": 17880
    },
    {
      "epoch": 57.524959742351044,
      "grad_norm": 0.45540380477905273,
      "learning_rate": 0.00040853030932043775,
      "loss": 1.3871,
      "step": 17890
    },
    {
      "epoch": 57.55716586151369,
      "grad_norm": 0.23675379157066345,
      "learning_rate": 0.00040843134814320226,
      "loss": 1.3868,
      "step": 17900
    },
    {
      "epoch": 57.589371980676326,
      "grad_norm": 0.2682201564311981,
      "learning_rate": 0.000408332345462241,
      "loss": 1.373,
      "step": 17910
    },
    {
      "epoch": 57.62157809983897,
      "grad_norm": 0.2737369239330292,
      "learning_rate": 0.0004082333013034893,
      "loss": 1.3599,
      "step": 17920
    },
    {
      "epoch": 57.65378421900161,
      "grad_norm": 0.246322900056839,
      "learning_rate": 0.00040813421569289344,
      "loss": 1.363,
      "step": 17930
    },
    {
      "epoch": 57.68599033816425,
      "grad_norm": 0.3043482303619385,
      "learning_rate": 0.00040803508865641056,
      "loss": 1.3788,
      "step": 17940
    },
    {
      "epoch": 57.71819645732689,
      "grad_norm": 0.2558891177177429,
      "learning_rate": 0.0004079359202200086,
      "loss": 1.382,
      "step": 17950
    },
    {
      "epoch": 57.750402576489535,
      "grad_norm": 0.2695169448852539,
      "learning_rate": 0.0004078367104096663,
      "loss": 1.3695,
      "step": 17960
    },
    {
      "epoch": 57.78260869565217,
      "grad_norm": 0.2792210578918457,
      "learning_rate": 0.0004077374592513735,
      "loss": 1.3868,
      "step": 17970
    },
    {
      "epoch": 57.81481481481482,
      "grad_norm": 0.24278265237808228,
      "learning_rate": 0.00040763816677113064,
      "loss": 1.38,
      "step": 17980
    },
    {
      "epoch": 57.847020933977454,
      "grad_norm": 0.25958195328712463,
      "learning_rate": 0.000407538832994949,
      "loss": 1.3841,
      "step": 17990
    },
    {
      "epoch": 57.8792270531401,
      "grad_norm": 0.24543051421642303,
      "learning_rate": 0.0004074394579488506,
      "loss": 1.3699,
      "step": 18000
    },
    {
      "epoch": 57.911433172302736,
      "grad_norm": 0.28815969824790955,
      "learning_rate": 0.00040734004165886864,
      "loss": 1.3631,
      "step": 18010
    },
    {
      "epoch": 57.94363929146538,
      "grad_norm": 0.24835191667079926,
      "learning_rate": 0.0004072405841510466,
      "loss": 1.3802,
      "step": 18020
    },
    {
      "epoch": 57.97584541062802,
      "grad_norm": 0.20384007692337036,
      "learning_rate": 0.00040714108545143924,
      "loss": 1.3813,
      "step": 18030
    },
    {
      "epoch": 58.0,
      "eval_loss": 0.6398523449897766,
      "eval_runtime": 7.0919,
      "eval_samples_per_second": 3426.878,
      "eval_steps_per_second": 13.396,
      "step": 18038
    },
    {
      "epoch": 58.006441223832525,
      "grad_norm": 0.1858278065919876,
      "learning_rate": 0.0004070415455861118,
      "loss": 1.3391,
      "step": 18040
    },
    {
      "epoch": 58.03864734299517,
      "grad_norm": 0.39506882429122925,
      "learning_rate": 0.00040694196458114035,
      "loss": 1.3887,
      "step": 18050
    },
    {
      "epoch": 58.07085346215781,
      "grad_norm": 0.22968174517154694,
      "learning_rate": 0.00040684234246261196,
      "loss": 1.3886,
      "step": 18060
    },
    {
      "epoch": 58.10305958132045,
      "grad_norm": 0.23621127009391785,
      "learning_rate": 0.0004067426792566242,
      "loss": 1.3765,
      "step": 18070
    },
    {
      "epoch": 58.13526570048309,
      "grad_norm": 0.2857353091239929,
      "learning_rate": 0.00040664297498928535,
      "loss": 1.363,
      "step": 18080
    },
    {
      "epoch": 58.16747181964573,
      "grad_norm": 0.2519245445728302,
      "learning_rate": 0.000406543229686715,
      "loss": 1.3671,
      "step": 18090
    },
    {
      "epoch": 58.19967793880837,
      "grad_norm": 0.27313464879989624,
      "learning_rate": 0.00040644344337504267,
      "loss": 1.3975,
      "step": 18100
    },
    {
      "epoch": 58.231884057971016,
      "grad_norm": 0.26357710361480713,
      "learning_rate": 0.0004063436160804092,
      "loss": 1.3886,
      "step": 18110
    },
    {
      "epoch": 58.26409017713365,
      "grad_norm": 0.23578664660453796,
      "learning_rate": 0.0004062437478289661,
      "loss": 1.3715,
      "step": 18120
    },
    {
      "epoch": 58.2962962962963,
      "grad_norm": 0.23138394951820374,
      "learning_rate": 0.00040614383864687545,
      "loss": 1.3527,
      "step": 18130
    },
    {
      "epoch": 58.328502415458935,
      "grad_norm": 0.2445584535598755,
      "learning_rate": 0.00040604388856031005,
      "loss": 1.389,
      "step": 18140
    },
    {
      "epoch": 58.36070853462158,
      "grad_norm": 0.29385340213775635,
      "learning_rate": 0.0004059438975954536,
      "loss": 1.3727,
      "step": 18150
    },
    {
      "epoch": 58.39291465378422,
      "grad_norm": 0.2270403653383255,
      "learning_rate": 0.0004058438657785004,
      "loss": 1.4021,
      "step": 18160
    },
    {
      "epoch": 58.42512077294686,
      "grad_norm": 0.3077169954776764,
      "learning_rate": 0.0004057437931356553,
      "loss": 1.3662,
      "step": 18170
    },
    {
      "epoch": 58.4573268921095,
      "grad_norm": 0.318061888217926,
      "learning_rate": 0.0004056436796931342,
      "loss": 1.3773,
      "step": 18180
    },
    {
      "epoch": 58.489533011272144,
      "grad_norm": 0.23237961530685425,
      "learning_rate": 0.00040554352547716326,
      "loss": 1.3841,
      "step": 18190
    },
    {
      "epoch": 58.52173913043478,
      "grad_norm": 0.28526973724365234,
      "learning_rate": 0.0004054433305139797,
      "loss": 1.396,
      "step": 18200
    },
    {
      "epoch": 58.553945249597426,
      "grad_norm": 0.27466991543769836,
      "learning_rate": 0.00040534309482983123,
      "loss": 1.3824,
      "step": 18210
    },
    {
      "epoch": 58.58615136876006,
      "grad_norm": 0.2896402180194855,
      "learning_rate": 0.0004052428184509762,
      "loss": 1.3649,
      "step": 18220
    },
    {
      "epoch": 58.61835748792271,
      "grad_norm": 0.2523319125175476,
      "learning_rate": 0.0004051425014036837,
      "loss": 1.3828,
      "step": 18230
    },
    {
      "epoch": 58.650563607085346,
      "grad_norm": 0.299721360206604,
      "learning_rate": 0.00040504214371423354,
      "loss": 1.357,
      "step": 18240
    },
    {
      "epoch": 58.68276972624799,
      "grad_norm": 0.28021010756492615,
      "learning_rate": 0.00040494174540891593,
      "loss": 1.3889,
      "step": 18250
    },
    {
      "epoch": 58.71497584541063,
      "grad_norm": 0.24552124738693237,
      "learning_rate": 0.00040484130651403195,
      "loss": 1.3531,
      "step": 18260
    },
    {
      "epoch": 58.74718196457327,
      "grad_norm": 0.2982965111732483,
      "learning_rate": 0.00040474082705589323,
      "loss": 1.384,
      "step": 18270
    },
    {
      "epoch": 58.77938808373591,
      "grad_norm": 0.31037119030952454,
      "learning_rate": 0.0004046403070608221,
      "loss": 1.3812,
      "step": 18280
    },
    {
      "epoch": 58.81159420289855,
      "grad_norm": 0.23463505506515503,
      "learning_rate": 0.0004045397465551513,
      "loss": 1.3957,
      "step": 18290
    },
    {
      "epoch": 58.84380032206119,
      "grad_norm": 0.31130969524383545,
      "learning_rate": 0.00040443914556522446,
      "loss": 1.367,
      "step": 18300
    },
    {
      "epoch": 58.87600644122383,
      "grad_norm": 0.2369629144668579,
      "learning_rate": 0.00040433850411739563,
      "loss": 1.3877,
      "step": 18310
    },
    {
      "epoch": 58.908212560386474,
      "grad_norm": 0.29384440183639526,
      "learning_rate": 0.0004042378222380295,
      "loss": 1.3745,
      "step": 18320
    },
    {
      "epoch": 58.94041867954911,
      "grad_norm": 0.22804610431194305,
      "learning_rate": 0.00040413709995350147,
      "loss": 1.3684,
      "step": 18330
    },
    {
      "epoch": 58.972624798711756,
      "grad_norm": 0.22156062722206116,
      "learning_rate": 0.00040403633729019716,
      "loss": 1.3805,
      "step": 18340
    },
    {
      "epoch": 59.0,
      "eval_loss": 0.6392723917961121,
      "eval_runtime": 7.0665,
      "eval_samples_per_second": 3439.179,
      "eval_steps_per_second": 13.444,
      "step": 18349
    },
    {
      "epoch": 59.00322061191626,
      "grad_norm": 0.41318953037261963,
      "learning_rate": 0.00040393553427451326,
      "loss": 1.2922,
      "step": 18350
    },
    {
      "epoch": 59.03542673107891,
      "grad_norm": 0.28515562415122986,
      "learning_rate": 0.0004038346909328567,
      "loss": 1.387,
      "step": 18360
    },
    {
      "epoch": 59.067632850241544,
      "grad_norm": 0.4232611060142517,
      "learning_rate": 0.00040373380729164524,
      "loss": 1.3709,
      "step": 18370
    },
    {
      "epoch": 59.09983896940419,
      "grad_norm": 0.2531910538673401,
      "learning_rate": 0.00040363288337730676,
      "loss": 1.386,
      "step": 18380
    },
    {
      "epoch": 59.13204508856683,
      "grad_norm": 0.2631847858428955,
      "learning_rate": 0.0004035319192162801,
      "loss": 1.3733,
      "step": 18390
    },
    {
      "epoch": 59.16425120772947,
      "grad_norm": 0.27930834889411926,
      "learning_rate": 0.0004034309148350144,
      "loss": 1.3817,
      "step": 18400
    },
    {
      "epoch": 59.19645732689211,
      "grad_norm": 0.3191494047641754,
      "learning_rate": 0.00040332987025996957,
      "loss": 1.3741,
      "step": 18410
    },
    {
      "epoch": 59.22866344605475,
      "grad_norm": 0.3056226074695587,
      "learning_rate": 0.0004032287855176159,
      "loss": 1.349,
      "step": 18420
    },
    {
      "epoch": 59.26086956521739,
      "grad_norm": 0.2819201350212097,
      "learning_rate": 0.0004031276606344342,
      "loss": 1.3658,
      "step": 18430
    },
    {
      "epoch": 59.293075684380035,
      "grad_norm": 0.26900967955589294,
      "learning_rate": 0.00040302649563691575,
      "loss": 1.3594,
      "step": 18440
    },
    {
      "epoch": 59.32528180354267,
      "grad_norm": 0.2728637158870697,
      "learning_rate": 0.00040292529055156246,
      "loss": 1.3707,
      "step": 18450
    },
    {
      "epoch": 59.35748792270532,
      "grad_norm": 0.2543644905090332,
      "learning_rate": 0.00040282404540488664,
      "loss": 1.3886,
      "step": 18460
    },
    {
      "epoch": 59.389694041867955,
      "grad_norm": 0.23174108564853668,
      "learning_rate": 0.0004027227602234112,
      "loss": 1.3484,
      "step": 18470
    },
    {
      "epoch": 59.42190016103059,
      "grad_norm": 0.2583175301551819,
      "learning_rate": 0.00040262143503366944,
      "loss": 1.377,
      "step": 18480
    },
    {
      "epoch": 59.45410628019324,
      "grad_norm": 0.2476731240749359,
      "learning_rate": 0.00040252006986220523,
      "loss": 1.3705,
      "step": 18490
    },
    {
      "epoch": 59.486312399355874,
      "grad_norm": 0.2501637935638428,
      "learning_rate": 0.0004024186647355728,
      "loss": 1.3764,
      "step": 18500
    },
    {
      "epoch": 59.51851851851852,
      "grad_norm": 0.24680474400520325,
      "learning_rate": 0.00040231721968033693,
      "loss": 1.3985,
      "step": 18510
    },
    {
      "epoch": 59.55072463768116,
      "grad_norm": 0.23523804545402527,
      "learning_rate": 0.00040221573472307284,
      "loss": 1.3886,
      "step": 18520
    },
    {
      "epoch": 59.5829307568438,
      "grad_norm": 0.20425955951213837,
      "learning_rate": 0.0004021142098903662,
      "loss": 1.3922,
      "step": 18530
    },
    {
      "epoch": 59.61513687600644,
      "grad_norm": 0.3109659254550934,
      "learning_rate": 0.00040201264520881307,
      "loss": 1.3702,
      "step": 18540
    },
    {
      "epoch": 59.64734299516908,
      "grad_norm": 0.2350907027721405,
      "learning_rate": 0.00040191104070502016,
      "loss": 1.3763,
      "step": 18550
    },
    {
      "epoch": 59.67954911433172,
      "grad_norm": 0.25689226388931274,
      "learning_rate": 0.00040180939640560435,
      "loss": 1.385,
      "step": 18560
    },
    {
      "epoch": 59.711755233494365,
      "grad_norm": 0.2529226243495941,
      "learning_rate": 0.00040170771233719304,
      "loss": 1.3739,
      "step": 18570
    },
    {
      "epoch": 59.743961352657,
      "grad_norm": 0.24319078028202057,
      "learning_rate": 0.0004016059885264241,
      "loss": 1.3859,
      "step": 18580
    },
    {
      "epoch": 59.77616747181965,
      "grad_norm": 0.2534709572792053,
      "learning_rate": 0.00040150422499994577,
      "loss": 1.3697,
      "step": 18590
    },
    {
      "epoch": 59.808373590982285,
      "grad_norm": 0.2319941371679306,
      "learning_rate": 0.00040140242178441667,
      "loss": 1.3846,
      "step": 18600
    },
    {
      "epoch": 59.84057971014493,
      "grad_norm": 0.26353514194488525,
      "learning_rate": 0.0004013005789065059,
      "loss": 1.3858,
      "step": 18610
    },
    {
      "epoch": 59.87278582930757,
      "grad_norm": 0.24335536360740662,
      "learning_rate": 0.00040119869639289286,
      "loss": 1.3895,
      "step": 18620
    },
    {
      "epoch": 59.90499194847021,
      "grad_norm": 0.2777186930179596,
      "learning_rate": 0.00040109677427026735,
      "loss": 1.3872,
      "step": 18630
    },
    {
      "epoch": 59.93719806763285,
      "grad_norm": 0.2804470956325531,
      "learning_rate": 0.00040099481256532964,
      "loss": 1.3777,
      "step": 18640
    },
    {
      "epoch": 59.969404186795494,
      "grad_norm": 0.22555571794509888,
      "learning_rate": 0.00040089281130479014,
      "loss": 1.3935,
      "step": 18650
    },
    {
      "epoch": 60.0,
      "grad_norm": 0.26065635681152344,
      "learning_rate": 0.0004007907705153699,
      "loss": 1.2966,
      "step": 18660
    },
    {
      "epoch": 60.0,
      "eval_loss": 0.6388007998466492,
      "eval_runtime": 7.118,
      "eval_samples_per_second": 3414.288,
      "eval_steps_per_second": 13.346,
      "step": 18660
    },
    {
      "epoch": 60.03220611916264,
      "grad_norm": 0.3143942654132843,
      "learning_rate": 0.00040068869022380027,
      "loss": 1.371,
      "step": 18670
    },
    {
      "epoch": 60.06441223832528,
      "grad_norm": 0.21334533393383026,
      "learning_rate": 0.00040058657045682265,
      "loss": 1.3708,
      "step": 18680
    },
    {
      "epoch": 60.09661835748792,
      "grad_norm": 0.2373311072587967,
      "learning_rate": 0.00040048441124118926,
      "loss": 1.3701,
      "step": 18690
    },
    {
      "epoch": 60.128824476650564,
      "grad_norm": 0.23666779696941376,
      "learning_rate": 0.0004003822126036623,
      "loss": 1.3934,
      "step": 18700
    },
    {
      "epoch": 60.1610305958132,
      "grad_norm": 0.23507794737815857,
      "learning_rate": 0.0004002799745710144,
      "loss": 1.3687,
      "step": 18710
    },
    {
      "epoch": 60.193236714975846,
      "grad_norm": 0.3049113154411316,
      "learning_rate": 0.00040017769717002845,
      "loss": 1.3877,
      "step": 18720
    },
    {
      "epoch": 60.225442834138484,
      "grad_norm": 0.3238256871700287,
      "learning_rate": 0.0004000753804274978,
      "loss": 1.3564,
      "step": 18730
    },
    {
      "epoch": 60.25764895330113,
      "grad_norm": 0.30526626110076904,
      "learning_rate": 0.00039997302437022597,
      "loss": 1.3682,
      "step": 18740
    },
    {
      "epoch": 60.289855072463766,
      "grad_norm": 0.24213121831417084,
      "learning_rate": 0.0003998706290250269,
      "loss": 1.3822,
      "step": 18750
    },
    {
      "epoch": 60.32206119162641,
      "grad_norm": 0.2603185474872589,
      "learning_rate": 0.0003997681944187247,
      "loss": 1.3772,
      "step": 18760
    },
    {
      "epoch": 60.35426731078905,
      "grad_norm": 0.21774744987487793,
      "learning_rate": 0.00039966572057815373,
      "loss": 1.3936,
      "step": 18770
    },
    {
      "epoch": 60.38647342995169,
      "grad_norm": 0.31546345353126526,
      "learning_rate": 0.00039956320753015893,
      "loss": 1.3595,
      "step": 18780
    },
    {
      "epoch": 60.41867954911433,
      "grad_norm": 0.26161614060401917,
      "learning_rate": 0.0003994606553015952,
      "loss": 1.3785,
      "step": 18790
    },
    {
      "epoch": 60.450885668276975,
      "grad_norm": 0.2999705672264099,
      "learning_rate": 0.0003993580639193277,
      "loss": 1.3769,
      "step": 18800
    },
    {
      "epoch": 60.48309178743961,
      "grad_norm": 0.28172945976257324,
      "learning_rate": 0.00039925543341023207,
      "loss": 1.3842,
      "step": 18810
    },
    {
      "epoch": 60.51529790660226,
      "grad_norm": 0.362111896276474,
      "learning_rate": 0.000399152763801194,
      "loss": 1.3805,
      "step": 18820
    },
    {
      "epoch": 60.547504025764894,
      "grad_norm": 0.2896343469619751,
      "learning_rate": 0.0003990500551191096,
      "loss": 1.4053,
      "step": 18830
    },
    {
      "epoch": 60.57971014492754,
      "grad_norm": 0.2821989357471466,
      "learning_rate": 0.000398947307390885,
      "loss": 1.3808,
      "step": 18840
    },
    {
      "epoch": 60.611916264090176,
      "grad_norm": 0.28864601254463196,
      "learning_rate": 0.0003988445206434368,
      "loss": 1.3769,
      "step": 18850
    },
    {
      "epoch": 60.64412238325282,
      "grad_norm": 0.34995871782302856,
      "learning_rate": 0.0003987416949036916,
      "loss": 1.3704,
      "step": 18860
    },
    {
      "epoch": 60.67632850241546,
      "grad_norm": 0.27798992395401,
      "learning_rate": 0.00039863883019858635,
      "loss": 1.3858,
      "step": 18870
    },
    {
      "epoch": 60.7085346215781,
      "grad_norm": 0.2441827654838562,
      "learning_rate": 0.00039853592655506823,
      "loss": 1.3749,
      "step": 18880
    },
    {
      "epoch": 60.74074074074074,
      "grad_norm": 0.23067989945411682,
      "learning_rate": 0.0003984329840000943,
      "loss": 1.3515,
      "step": 18890
    },
    {
      "epoch": 60.772946859903385,
      "grad_norm": 0.2645334303379059,
      "learning_rate": 0.00039833000256063244,
      "loss": 1.3872,
      "step": 18900
    },
    {
      "epoch": 60.80515297906602,
      "grad_norm": 0.23271991312503815,
      "learning_rate": 0.00039822698226366017,
      "loss": 1.4131,
      "step": 18910
    },
    {
      "epoch": 60.83735909822866,
      "grad_norm": 0.27395039796829224,
      "learning_rate": 0.0003981239231361653,
      "loss": 1.3657,
      "step": 18920
    },
    {
      "epoch": 60.869565217391305,
      "grad_norm": 0.46331843733787537,
      "learning_rate": 0.000398020825205146,
      "loss": 1.4034,
      "step": 18930
    },
    {
      "epoch": 60.90177133655394,
      "grad_norm": 0.2809463441371918,
      "learning_rate": 0.00039791768849761045,
      "loss": 1.3693,
      "step": 18940
    },
    {
      "epoch": 60.93397745571659,
      "grad_norm": 0.3276316821575165,
      "learning_rate": 0.00039781451304057695,
      "loss": 1.3659,
      "step": 18950
    },
    {
      "epoch": 60.966183574879224,
      "grad_norm": 0.27129510045051575,
      "learning_rate": 0.0003977112988610742,
      "loss": 1.3727,
      "step": 18960
    },
    {
      "epoch": 60.99838969404187,
      "grad_norm": 0.2730216383934021,
      "learning_rate": 0.00039760804598614076,
      "loss": 1.3542,
      "step": 18970
    },
    {
      "epoch": 61.0,
      "eval_loss": 0.6417885422706604,
      "eval_runtime": 7.2361,
      "eval_samples_per_second": 3358.592,
      "eval_steps_per_second": 13.129,
      "step": 18971
    },
    {
      "epoch": 61.028985507246375,
      "grad_norm": 0.2714344561100006,
      "learning_rate": 0.0003975047544428254,
      "loss": 1.2806,
      "step": 18980
    },
    {
      "epoch": 61.06119162640902,
      "grad_norm": 0.25407275557518005,
      "learning_rate": 0.00039740142425818715,
      "loss": 1.3725,
      "step": 18990
    },
    {
      "epoch": 61.09339774557166,
      "grad_norm": 0.23425965011119843,
      "learning_rate": 0.00039729805545929496,
      "loss": 1.3939,
      "step": 19000
    },
    {
      "epoch": 61.1256038647343,
      "grad_norm": 0.270123690366745,
      "learning_rate": 0.00039719464807322813,
      "loss": 1.3695,
      "step": 19010
    },
    {
      "epoch": 61.15780998389694,
      "grad_norm": 0.22405150532722473,
      "learning_rate": 0.00039709120212707584,
      "loss": 1.3766,
      "step": 19020
    },
    {
      "epoch": 61.190016103059584,
      "grad_norm": 0.34098395705223083,
      "learning_rate": 0.0003969877176479375,
      "loss": 1.3791,
      "step": 19030
    },
    {
      "epoch": 61.22222222222222,
      "grad_norm": 0.25194546580314636,
      "learning_rate": 0.0003968841946629227,
      "loss": 1.3756,
      "step": 19040
    },
    {
      "epoch": 61.254428341384866,
      "grad_norm": 0.25425049662590027,
      "learning_rate": 0.00039678063319915083,
      "loss": 1.3908,
      "step": 19050
    },
    {
      "epoch": 61.2866344605475,
      "grad_norm": 0.2625525891780853,
      "learning_rate": 0.0003966770332837517,
      "loss": 1.3699,
      "step": 19060
    },
    {
      "epoch": 61.31884057971015,
      "grad_norm": 0.25478148460388184,
      "learning_rate": 0.00039657339494386483,
      "loss": 1.3828,
      "step": 19070
    },
    {
      "epoch": 61.351046698872786,
      "grad_norm": 0.5241255164146423,
      "learning_rate": 0.00039646971820664025,
      "loss": 1.3744,
      "step": 19080
    },
    {
      "epoch": 61.38325281803543,
      "grad_norm": 0.30900368094444275,
      "learning_rate": 0.00039636600309923766,
      "loss": 1.3815,
      "step": 19090
    },
    {
      "epoch": 61.41545893719807,
      "grad_norm": 0.2625150680541992,
      "learning_rate": 0.0003962622496488269,
      "loss": 1.3975,
      "step": 19100
    },
    {
      "epoch": 61.447665056360705,
      "grad_norm": 0.2170362025499344,
      "learning_rate": 0.0003961584578825881,
      "loss": 1.3805,
      "step": 19110
    },
    {
      "epoch": 61.47987117552335,
      "grad_norm": 0.2621667683124542,
      "learning_rate": 0.00039605462782771106,
      "loss": 1.3772,
      "step": 19120
    },
    {
      "epoch": 61.51207729468599,
      "grad_norm": 0.26380589604377747,
      "learning_rate": 0.00039595075951139594,
      "loss": 1.378,
      "step": 19130
    },
    {
      "epoch": 61.54428341384863,
      "grad_norm": 0.251249760389328,
      "learning_rate": 0.0003958468529608526,
      "loss": 1.3805,
      "step": 19140
    },
    {
      "epoch": 61.57648953301127,
      "grad_norm": 0.2637087106704712,
      "learning_rate": 0.0003957429082033013,
      "loss": 1.3691,
      "step": 19150
    },
    {
      "epoch": 61.608695652173914,
      "grad_norm": 0.24661096930503845,
      "learning_rate": 0.0003956389252659718,
      "loss": 1.3601,
      "step": 19160
    },
    {
      "epoch": 61.64090177133655,
      "grad_norm": 0.2467547059059143,
      "learning_rate": 0.0003955349041761045,
      "loss": 1.3685,
      "step": 19170
    },
    {
      "epoch": 61.673107890499196,
      "grad_norm": 0.23505659401416779,
      "learning_rate": 0.0003954308449609492,
      "loss": 1.3721,
      "step": 19180
    },
    {
      "epoch": 61.70531400966183,
      "grad_norm": 0.22095289826393127,
      "learning_rate": 0.00039532674764776606,
      "loss": 1.3805,
      "step": 19190
    },
    {
      "epoch": 61.73752012882448,
      "grad_norm": 0.2511959969997406,
      "learning_rate": 0.0003952226122638251,
      "loss": 1.3839,
      "step": 19200
    },
    {
      "epoch": 61.769726247987116,
      "grad_norm": 0.2512018084526062,
      "learning_rate": 0.00039511843883640625,
      "loss": 1.3629,
      "step": 19210
    },
    {
      "epoch": 61.80193236714976,
      "grad_norm": 0.21874403953552246,
      "learning_rate": 0.0003950142273927996,
      "loss": 1.3745,
      "step": 19220
    },
    {
      "epoch": 61.8341384863124,
      "grad_norm": 0.26617467403411865,
      "learning_rate": 0.0003949099779603049,
      "loss": 1.3769,
      "step": 19230
    },
    {
      "epoch": 61.86634460547504,
      "grad_norm": 0.25491541624069214,
      "learning_rate": 0.0003948056905662321,
      "loss": 1.3871,
      "step": 19240
    },
    {
      "epoch": 61.89855072463768,
      "grad_norm": 0.2103959172964096,
      "learning_rate": 0.0003947013652379011,
      "loss": 1.3924,
      "step": 19250
    },
    {
      "epoch": 61.930756843800324,
      "grad_norm": 0.2027233988046646,
      "learning_rate": 0.0003945970020026415,
      "loss": 1.3667,
      "step": 19260
    },
    {
      "epoch": 61.96296296296296,
      "grad_norm": 0.4718332290649414,
      "learning_rate": 0.00039449260088779306,
      "loss": 1.38,
      "step": 19270
    },
    {
      "epoch": 61.99516908212561,
      "grad_norm": 0.24806492030620575,
      "learning_rate": 0.0003943881619207055,
      "loss": 1.3719,
      "step": 19280
    },
    {
      "epoch": 62.0,
      "eval_loss": 0.6397904753684998,
      "eval_runtime": 7.1464,
      "eval_samples_per_second": 3400.752,
      "eval_steps_per_second": 13.293,
      "step": 19282
    },
    {
      "epoch": 62.02576489533011,
      "grad_norm": 0.239990696310997,
      "learning_rate": 0.00039428368512873813,
      "loss": 1.3275,
      "step": 19290
    },
    {
      "epoch": 62.05797101449275,
      "grad_norm": 0.31879597902297974,
      "learning_rate": 0.00039417917053926043,
      "loss": 1.3764,
      "step": 19300
    },
    {
      "epoch": 62.090177133655395,
      "grad_norm": 0.1959502249956131,
      "learning_rate": 0.00039407461817965195,
      "loss": 1.3804,
      "step": 19310
    },
    {
      "epoch": 62.12238325281803,
      "grad_norm": 0.27562814950942993,
      "learning_rate": 0.00039397002807730166,
      "loss": 1.3843,
      "step": 19320
    },
    {
      "epoch": 62.15458937198068,
      "grad_norm": 0.236052468419075,
      "learning_rate": 0.00039386540025960874,
      "loss": 1.3781,
      "step": 19330
    },
    {
      "epoch": 62.186795491143315,
      "grad_norm": 0.219566211104393,
      "learning_rate": 0.0003937607347539823,
      "loss": 1.4052,
      "step": 19340
    },
    {
      "epoch": 62.21900161030596,
      "grad_norm": 0.275691419839859,
      "learning_rate": 0.00039365603158784116,
      "loss": 1.3642,
      "step": 19350
    },
    {
      "epoch": 62.2512077294686,
      "grad_norm": 0.25460976362228394,
      "learning_rate": 0.00039355129078861396,
      "loss": 1.3905,
      "step": 19360
    },
    {
      "epoch": 62.28341384863124,
      "grad_norm": 0.22718225419521332,
      "learning_rate": 0.0003934465123837394,
      "loss": 1.3788,
      "step": 19370
    },
    {
      "epoch": 62.31561996779388,
      "grad_norm": 0.22360002994537354,
      "learning_rate": 0.0003933416964006659,
      "loss": 1.3665,
      "step": 19380
    },
    {
      "epoch": 62.34782608695652,
      "grad_norm": 0.21139436960220337,
      "learning_rate": 0.00039323684286685155,
      "loss": 1.3803,
      "step": 19390
    },
    {
      "epoch": 62.38003220611916,
      "grad_norm": 0.2612963616847992,
      "learning_rate": 0.0003931319518097649,
      "loss": 1.3561,
      "step": 19400
    },
    {
      "epoch": 62.412238325281805,
      "grad_norm": 0.28361713886260986,
      "learning_rate": 0.00039302702325688356,
      "loss": 1.3358,
      "step": 19410
    },
    {
      "epoch": 62.44444444444444,
      "grad_norm": 0.24950823187828064,
      "learning_rate": 0.0003929220572356954,
      "loss": 1.3583,
      "step": 19420
    },
    {
      "epoch": 62.47665056360709,
      "grad_norm": 0.27099093794822693,
      "learning_rate": 0.00039281705377369806,
      "loss": 1.3641,
      "step": 19430
    },
    {
      "epoch": 62.508856682769725,
      "grad_norm": 0.22542721033096313,
      "learning_rate": 0.00039271201289839896,
      "loss": 1.3796,
      "step": 19440
    },
    {
      "epoch": 62.54106280193237,
      "grad_norm": 0.22094877064228058,
      "learning_rate": 0.00039260693463731523,
      "loss": 1.3484,
      "step": 19450
    },
    {
      "epoch": 62.57326892109501,
      "grad_norm": 0.27450796961784363,
      "learning_rate": 0.0003925018190179739,
      "loss": 1.3735,
      "step": 19460
    },
    {
      "epoch": 62.60547504025765,
      "grad_norm": 0.27072498202323914,
      "learning_rate": 0.0003923966660679117,
      "loss": 1.3964,
      "step": 19470
    },
    {
      "epoch": 62.63768115942029,
      "grad_norm": 0.21416014432907104,
      "learning_rate": 0.0003922914758146753,
      "loss": 1.3621,
      "step": 19480
    },
    {
      "epoch": 62.669887278582934,
      "grad_norm": 0.251407653093338,
      "learning_rate": 0.00039218624828582093,
      "loss": 1.3898,
      "step": 19490
    },
    {
      "epoch": 62.70209339774557,
      "grad_norm": 0.24411191046237946,
      "learning_rate": 0.0003920809835089148,
      "loss": 1.3758,
      "step": 19500
    },
    {
      "epoch": 62.734299516908216,
      "grad_norm": 0.26653510332107544,
      "learning_rate": 0.0003919756815115326,
      "loss": 1.3775,
      "step": 19510
    },
    {
      "epoch": 62.76650563607085,
      "grad_norm": 0.22671663761138916,
      "learning_rate": 0.00039187034232126015,
      "loss": 1.388,
      "step": 19520
    },
    {
      "epoch": 62.7987117552335,
      "grad_norm": 0.2541598379611969,
      "learning_rate": 0.00039176496596569265,
      "loss": 1.372,
      "step": 19530
    },
    {
      "epoch": 62.830917874396135,
      "grad_norm": 0.23684252798557281,
      "learning_rate": 0.0003916595524724353,
      "loss": 1.3843,
      "step": 19540
    },
    {
      "epoch": 62.86312399355877,
      "grad_norm": 0.22815516591072083,
      "learning_rate": 0.00039155410186910285,
      "loss": 1.3667,
      "step": 19550
    },
    {
      "epoch": 62.89533011272142,
      "grad_norm": 0.20667904615402222,
      "learning_rate": 0.0003914486141833198,
      "loss": 1.3811,
      "step": 19560
    },
    {
      "epoch": 62.927536231884055,
      "grad_norm": 0.2783561646938324,
      "learning_rate": 0.0003913430894427205,
      "loss": 1.3608,
      "step": 19570
    },
    {
      "epoch": 62.9597423510467,
      "grad_norm": 0.22113437950611115,
      "learning_rate": 0.0003912375276749488,
      "loss": 1.3687,
      "step": 19580
    },
    {
      "epoch": 62.99194847020934,
      "grad_norm": 0.21741485595703125,
      "learning_rate": 0.0003911319289076585,
      "loss": 1.3847,
      "step": 19590
    },
    {
      "epoch": 63.0,
      "eval_loss": 0.6425623893737793,
      "eval_runtime": 7.0638,
      "eval_samples_per_second": 3440.498,
      "eval_steps_per_second": 13.449,
      "step": 19593
    },
    {
      "epoch": 63.02254428341385,
      "grad_norm": 0.2448275089263916,
      "learning_rate": 0.0003910262931685127,
      "loss": 1.2908,
      "step": 19600
    },
    {
      "epoch": 63.05475040257649,
      "grad_norm": 0.26507893204689026,
      "learning_rate": 0.0003909206204851847,
      "loss": 1.3702,
      "step": 19610
    },
    {
      "epoch": 63.08695652173913,
      "grad_norm": 0.23894938826560974,
      "learning_rate": 0.0003908149108853572,
      "loss": 1.3783,
      "step": 19620
    },
    {
      "epoch": 63.11916264090177,
      "grad_norm": 0.23053264617919922,
      "learning_rate": 0.00039070916439672246,
      "loss": 1.3773,
      "step": 19630
    },
    {
      "epoch": 63.151368760064415,
      "grad_norm": 0.2389005422592163,
      "learning_rate": 0.00039060338104698254,
      "loss": 1.3837,
      "step": 19640
    },
    {
      "epoch": 63.18357487922705,
      "grad_norm": 0.22418838739395142,
      "learning_rate": 0.00039049756086384925,
      "loss": 1.3377,
      "step": 19650
    },
    {
      "epoch": 63.2157809983897,
      "grad_norm": 0.21480584144592285,
      "learning_rate": 0.00039039170387504383,
      "loss": 1.3609,
      "step": 19660
    },
    {
      "epoch": 63.247987117552334,
      "grad_norm": 0.2709123194217682,
      "learning_rate": 0.00039028581010829743,
      "loss": 1.3919,
      "step": 19670
    },
    {
      "epoch": 63.28019323671498,
      "grad_norm": 0.7302508354187012,
      "learning_rate": 0.0003901798795913506,
      "loss": 1.3526,
      "step": 19680
    },
    {
      "epoch": 63.312399355877616,
      "grad_norm": 0.24866218864917755,
      "learning_rate": 0.00039007391235195343,
      "loss": 1.378,
      "step": 19690
    },
    {
      "epoch": 63.34460547504026,
      "grad_norm": 0.32191142439842224,
      "learning_rate": 0.0003899679084178661,
      "loss": 1.3709,
      "step": 19700
    },
    {
      "epoch": 63.3768115942029,
      "grad_norm": 0.2613305151462555,
      "learning_rate": 0.00038986186781685795,
      "loss": 1.3601,
      "step": 19710
    },
    {
      "epoch": 63.409017713365536,
      "grad_norm": 0.2212880402803421,
      "learning_rate": 0.00038975579057670803,
      "loss": 1.3745,
      "step": 19720
    },
    {
      "epoch": 63.44122383252818,
      "grad_norm": 0.2549896240234375,
      "learning_rate": 0.0003896496767252051,
      "loss": 1.3948,
      "step": 19730
    },
    {
      "epoch": 63.47342995169082,
      "grad_norm": 0.23651649057865143,
      "learning_rate": 0.0003895435262901475,
      "loss": 1.3595,
      "step": 19740
    },
    {
      "epoch": 63.50563607085346,
      "grad_norm": 0.2776554822921753,
      "learning_rate": 0.000389437339299343,
      "loss": 1.3806,
      "step": 19750
    },
    {
      "epoch": 63.5378421900161,
      "grad_norm": 0.2096925675868988,
      "learning_rate": 0.0003893311157806091,
      "loss": 1.3669,
      "step": 19760
    },
    {
      "epoch": 63.570048309178745,
      "grad_norm": 0.416232168674469,
      "learning_rate": 0.00038922485576177283,
      "loss": 1.387,
      "step": 19770
    },
    {
      "epoch": 63.60225442834138,
      "grad_norm": 0.23415915668010712,
      "learning_rate": 0.0003891185592706708,
      "loss": 1.3931,
      "step": 19780
    },
    {
      "epoch": 63.63446054750403,
      "grad_norm": 0.2215237319469452,
      "learning_rate": 0.00038901222633514897,
      "loss": 1.3919,
      "step": 19790
    },
    {
      "epoch": 63.666666666666664,
      "grad_norm": 0.21204601228237152,
      "learning_rate": 0.0003889058569830632,
      "loss": 1.3712,
      "step": 19800
    },
    {
      "epoch": 63.69887278582931,
      "grad_norm": 0.2814076542854309,
      "learning_rate": 0.0003887994512422787,
      "loss": 1.3721,
      "step": 19810
    },
    {
      "epoch": 63.731078904991946,
      "grad_norm": 0.22034652531147003,
      "learning_rate": 0.00038869300914067017,
      "loss": 1.3839,
      "step": 19820
    },
    {
      "epoch": 63.76328502415459,
      "grad_norm": 0.21329918503761292,
      "learning_rate": 0.0003885865307061218,
      "loss": 1.3624,
      "step": 19830
    },
    {
      "epoch": 63.79549114331723,
      "grad_norm": 0.22887426614761353,
      "learning_rate": 0.0003884800159665276,
      "loss": 1.3607,
      "step": 19840
    },
    {
      "epoch": 63.82769726247987,
      "grad_norm": 0.30659258365631104,
      "learning_rate": 0.00038837346494979065,
      "loss": 1.3881,
      "step": 19850
    },
    {
      "epoch": 63.85990338164251,
      "grad_norm": 0.21603535115718842,
      "learning_rate": 0.00038826687768382396,
      "loss": 1.3968,
      "step": 19860
    },
    {
      "epoch": 63.892109500805155,
      "grad_norm": 0.23987381160259247,
      "learning_rate": 0.00038816025419654974,
      "loss": 1.3544,
      "step": 19870
    },
    {
      "epoch": 63.92431561996779,
      "grad_norm": 0.2417575716972351,
      "learning_rate": 0.00038805359451589975,
      "loss": 1.3478,
      "step": 19880
    },
    {
      "epoch": 63.95652173913044,
      "grad_norm": 0.27929335832595825,
      "learning_rate": 0.00038794689866981534,
      "loss": 1.3884,
      "step": 19890
    },
    {
      "epoch": 63.988727858293075,
      "grad_norm": 0.2914746105670929,
      "learning_rate": 0.0003878401666862472,
      "loss": 1.3788,
      "step": 19900
    },
    {
      "epoch": 64.0,
      "eval_loss": 0.6420342326164246,
      "eval_runtime": 7.0743,
      "eval_samples_per_second": 3435.41,
      "eval_steps_per_second": 13.429,
      "step": 19904
    },
    {
      "epoch": 64.01932367149759,
      "grad_norm": 0.2947905659675598,
      "learning_rate": 0.0003877333985931556,
      "loss": 1.3108,
      "step": 19910
    },
    {
      "epoch": 64.05152979066023,
      "grad_norm": 0.34219253063201904,
      "learning_rate": 0.0003876265944185101,
      "loss": 1.3688,
      "step": 19920
    },
    {
      "epoch": 64.08373590982286,
      "grad_norm": 0.24841123819351196,
      "learning_rate": 0.00038751975419029004,
      "loss": 1.3735,
      "step": 19930
    },
    {
      "epoch": 64.1159420289855,
      "grad_norm": 0.22865237295627594,
      "learning_rate": 0.00038741287793648383,
      "loss": 1.3727,
      "step": 19940
    },
    {
      "epoch": 64.14814814814815,
      "grad_norm": 0.2750466763973236,
      "learning_rate": 0.00038730596568508957,
      "loss": 1.3777,
      "step": 19950
    },
    {
      "epoch": 64.18035426731079,
      "grad_norm": 0.24525539577007294,
      "learning_rate": 0.0003871990174641146,
      "loss": 1.3546,
      "step": 19960
    },
    {
      "epoch": 64.21256038647343,
      "grad_norm": 0.2835727334022522,
      "learning_rate": 0.0003870920333015758,
      "loss": 1.372,
      "step": 19970
    },
    {
      "epoch": 64.24476650563606,
      "grad_norm": 0.1954641193151474,
      "learning_rate": 0.0003869850132254996,
      "loss": 1.3764,
      "step": 19980
    },
    {
      "epoch": 64.27697262479872,
      "grad_norm": 0.25199341773986816,
      "learning_rate": 0.0003868779572639216,
      "loss": 1.3728,
      "step": 19990
    },
    {
      "epoch": 64.30917874396135,
      "grad_norm": 0.2158827930688858,
      "learning_rate": 0.0003867708654448868,
      "loss": 1.3574,
      "step": 20000
    },
    {
      "epoch": 64.34138486312399,
      "grad_norm": 0.23509308695793152,
      "learning_rate": 0.00038666373779644984,
      "loss": 1.3817,
      "step": 20010
    },
    {
      "epoch": 64.37359098228663,
      "grad_norm": 0.2436463087797165,
      "learning_rate": 0.00038655657434667436,
      "loss": 1.362,
      "step": 20020
    },
    {
      "epoch": 64.40579710144928,
      "grad_norm": 2.0871574878692627,
      "learning_rate": 0.0003864493751236339,
      "loss": 1.3626,
      "step": 20030
    },
    {
      "epoch": 64.43800322061192,
      "grad_norm": 0.23933057487010956,
      "learning_rate": 0.0003863421401554108,
      "loss": 1.3769,
      "step": 20040
    },
    {
      "epoch": 64.47020933977456,
      "grad_norm": 0.21393537521362305,
      "learning_rate": 0.0003862348694700972,
      "loss": 1.3695,
      "step": 20050
    },
    {
      "epoch": 64.5024154589372,
      "grad_norm": 0.24491117894649506,
      "learning_rate": 0.0003861275630957945,
      "loss": 1.3956,
      "step": 20060
    },
    {
      "epoch": 64.53462157809984,
      "grad_norm": 0.23022592067718506,
      "learning_rate": 0.0003860202210606133,
      "loss": 1.3561,
      "step": 20070
    },
    {
      "epoch": 64.56682769726248,
      "grad_norm": 0.2596384584903717,
      "learning_rate": 0.00038591284339267354,
      "loss": 1.3588,
      "step": 20080
    },
    {
      "epoch": 64.59903381642512,
      "grad_norm": 0.19975990056991577,
      "learning_rate": 0.0003858054301201047,
      "loss": 1.3885,
      "step": 20090
    },
    {
      "epoch": 64.63123993558776,
      "grad_norm": 0.21777932345867157,
      "learning_rate": 0.0003856979812710455,
      "loss": 1.3928,
      "step": 20100
    },
    {
      "epoch": 64.66344605475041,
      "grad_norm": 0.2990502119064331,
      "learning_rate": 0.0003855904968736439,
      "loss": 1.3832,
      "step": 20110
    },
    {
      "epoch": 64.69565217391305,
      "grad_norm": 0.2644859254360199,
      "learning_rate": 0.00038548297695605716,
      "loss": 1.3701,
      "step": 20120
    },
    {
      "epoch": 64.72785829307568,
      "grad_norm": 0.2214028388261795,
      "learning_rate": 0.000385375421546452,
      "loss": 1.3863,
      "step": 20130
    },
    {
      "epoch": 64.76006441223832,
      "grad_norm": 0.24894577264785767,
      "learning_rate": 0.00038526783067300435,
      "loss": 1.3664,
      "step": 20140
    },
    {
      "epoch": 64.79227053140096,
      "grad_norm": 0.21000808477401733,
      "learning_rate": 0.0003851602043638994,
      "loss": 1.382,
      "step": 20150
    },
    {
      "epoch": 64.82447665056361,
      "grad_norm": 0.25678718090057373,
      "learning_rate": 0.0003850525426473317,
      "loss": 1.3798,
      "step": 20160
    },
    {
      "epoch": 64.85668276972625,
      "grad_norm": 0.20954765379428864,
      "learning_rate": 0.00038494484555150486,
      "loss": 1.3625,
      "step": 20170
    },
    {
      "epoch": 64.88888888888889,
      "grad_norm": 0.245953768491745,
      "learning_rate": 0.0003848371131046322,
      "loss": 1.3551,
      "step": 20180
    },
    {
      "epoch": 64.92109500805152,
      "grad_norm": 0.9631129503250122,
      "learning_rate": 0.0003847293453349358,
      "loss": 1.3662,
      "step": 20190
    },
    {
      "epoch": 64.95330112721417,
      "grad_norm": 0.24486686289310455,
      "learning_rate": 0.00038462154227064725,
      "loss": 1.3878,
      "step": 20200
    },
    {
      "epoch": 64.98550724637681,
      "grad_norm": 0.22736729681491852,
      "learning_rate": 0.0003845137039400074,
      "loss": 1.3927,
      "step": 20210
    },
    {
      "epoch": 65.0,
      "eval_loss": 0.6380993723869324,
      "eval_runtime": 7.0861,
      "eval_samples_per_second": 3429.662,
      "eval_steps_per_second": 13.406,
      "step": 20215
    },
    {
      "epoch": 65.01610305958133,
      "grad_norm": 0.24847351014614105,
      "learning_rate": 0.0003844058303712664,
      "loss": 1.2994,
      "step": 20220
    },
    {
      "epoch": 65.04830917874396,
      "grad_norm": 0.23353271186351776,
      "learning_rate": 0.00038429792159268327,
      "loss": 1.3723,
      "step": 20230
    },
    {
      "epoch": 65.0805152979066,
      "grad_norm": 0.24887488782405853,
      "learning_rate": 0.0003841899776325267,
      "loss": 1.3763,
      "step": 20240
    },
    {
      "epoch": 65.11272141706924,
      "grad_norm": 0.26329806447029114,
      "learning_rate": 0.00038408199851907443,
      "loss": 1.3673,
      "step": 20250
    },
    {
      "epoch": 65.14492753623189,
      "grad_norm": 0.23384632170200348,
      "learning_rate": 0.00038397398428061325,
      "loss": 1.3833,
      "step": 20260
    },
    {
      "epoch": 65.17713365539453,
      "grad_norm": 0.27639973163604736,
      "learning_rate": 0.0003838659349454394,
      "loss": 1.3683,
      "step": 20270
    },
    {
      "epoch": 65.20933977455717,
      "grad_norm": 0.24564988911151886,
      "learning_rate": 0.00038375785054185806,
      "loss": 1.3782,
      "step": 20280
    },
    {
      "epoch": 65.2415458937198,
      "grad_norm": 0.2195780724287033,
      "learning_rate": 0.0003836497310981839,
      "loss": 1.3754,
      "step": 20290
    },
    {
      "epoch": 65.27375201288245,
      "grad_norm": 0.3031330406665802,
      "learning_rate": 0.00038354157664274055,
      "loss": 1.3526,
      "step": 20300
    },
    {
      "epoch": 65.30595813204509,
      "grad_norm": 0.23066484928131104,
      "learning_rate": 0.0003834333872038608,
      "loss": 1.3442,
      "step": 20310
    },
    {
      "epoch": 65.33816425120773,
      "grad_norm": 0.21700270473957062,
      "learning_rate": 0.00038332516280988673,
      "loss": 1.3811,
      "step": 20320
    },
    {
      "epoch": 65.37037037037037,
      "grad_norm": 0.21362079679965973,
      "learning_rate": 0.00038321690348916946,
      "loss": 1.38,
      "step": 20330
    },
    {
      "epoch": 65.402576489533,
      "grad_norm": 0.24789264798164368,
      "learning_rate": 0.0003831086092700695,
      "loss": 1.3648,
      "step": 20340
    },
    {
      "epoch": 65.43478260869566,
      "grad_norm": 0.22164906561374664,
      "learning_rate": 0.00038300028018095606,
      "loss": 1.3654,
      "step": 20350
    },
    {
      "epoch": 65.4669887278583,
      "grad_norm": 0.22130577266216278,
      "learning_rate": 0.000382891916250208,
      "loss": 1.3548,
      "step": 20360
    },
    {
      "epoch": 65.49919484702093,
      "grad_norm": 0.2769533395767212,
      "learning_rate": 0.0003827835175062129,
      "loss": 1.3777,
      "step": 20370
    },
    {
      "epoch": 65.53140096618357,
      "grad_norm": 0.2791008949279785,
      "learning_rate": 0.0003826750839773675,
      "loss": 1.3702,
      "step": 20380
    },
    {
      "epoch": 65.56360708534622,
      "grad_norm": 0.22025853395462036,
      "learning_rate": 0.0003825666156920781,
      "loss": 1.3736,
      "step": 20390
    },
    {
      "epoch": 65.59581320450886,
      "grad_norm": 0.2766055464744568,
      "learning_rate": 0.00038245811267875946,
      "loss": 1.3866,
      "step": 20400
    },
    {
      "epoch": 65.6280193236715,
      "grad_norm": 0.25771084427833557,
      "learning_rate": 0.0003823495749658359,
      "loss": 1.3709,
      "step": 20410
    },
    {
      "epoch": 65.66022544283413,
      "grad_norm": 0.20895957946777344,
      "learning_rate": 0.0003822410025817406,
      "loss": 1.3742,
      "step": 20420
    },
    {
      "epoch": 65.69243156199678,
      "grad_norm": 0.2271602302789688,
      "learning_rate": 0.00038213239555491606,
      "loss": 1.358,
      "step": 20430
    },
    {
      "epoch": 65.72463768115942,
      "grad_norm": 0.30474212765693665,
      "learning_rate": 0.0003820237539138135,
      "loss": 1.3758,
      "step": 20440
    },
    {
      "epoch": 65.75684380032206,
      "grad_norm": 0.2375688999891281,
      "learning_rate": 0.00038191507768689346,
      "loss": 1.358,
      "step": 20450
    },
    {
      "epoch": 65.7890499194847,
      "grad_norm": 0.20578519999980927,
      "learning_rate": 0.00038180636690262563,
      "loss": 1.393,
      "step": 20460
    },
    {
      "epoch": 65.82125603864735,
      "grad_norm": 0.28711646795272827,
      "learning_rate": 0.0003816976215894884,
      "loss": 1.3959,
      "step": 20470
    },
    {
      "epoch": 65.85346215780999,
      "grad_norm": 0.35612913966178894,
      "learning_rate": 0.00038158884177596955,
      "loss": 1.3604,
      "step": 20480
    },
    {
      "epoch": 65.88566827697262,
      "grad_norm": 0.42318540811538696,
      "learning_rate": 0.0003814800274905657,
      "loss": 1.3835,
      "step": 20490
    },
    {
      "epoch": 65.91787439613526,
      "grad_norm": 0.22681015729904175,
      "learning_rate": 0.00038137117876178264,
      "loss": 1.3728,
      "step": 20500
    },
    {
      "epoch": 65.95008051529791,
      "grad_norm": 0.2695021331310272,
      "learning_rate": 0.0003812622956181349,
      "loss": 1.373,
      "step": 20510
    },
    {
      "epoch": 65.98228663446055,
      "grad_norm": 0.24766415357589722,
      "learning_rate": 0.0003811533780881464,
      "loss": 1.3882,
      "step": 20520
    },
    {
      "epoch": 66.0,
      "eval_loss": 0.6409472823143005,
      "eval_runtime": 7.2636,
      "eval_samples_per_second": 3345.84,
      "eval_steps_per_second": 13.079,
      "step": 20526
    },
    {
      "epoch": 66.01288244766505,
      "grad_norm": 0.276879221200943,
      "learning_rate": 0.00038104442620034995,
      "loss": 1.3059,
      "step": 20530
    },
    {
      "epoch": 66.0450885668277,
      "grad_norm": 0.25002023577690125,
      "learning_rate": 0.0003809354399832872,
      "loss": 1.3644,
      "step": 20540
    },
    {
      "epoch": 66.07729468599034,
      "grad_norm": 0.23753465712070465,
      "learning_rate": 0.0003808264194655089,
      "loss": 1.359,
      "step": 20550
    },
    {
      "epoch": 66.10950080515298,
      "grad_norm": 0.25016218423843384,
      "learning_rate": 0.0003807173646755749,
      "loss": 1.3536,
      "step": 20560
    },
    {
      "epoch": 66.14170692431561,
      "grad_norm": 0.3047877550125122,
      "learning_rate": 0.0003806082756420537,
      "loss": 1.3696,
      "step": 20570
    },
    {
      "epoch": 66.17391304347827,
      "grad_norm": 0.387300044298172,
      "learning_rate": 0.00038049915239352317,
      "loss": 1.3574,
      "step": 20580
    },
    {
      "epoch": 66.2061191626409,
      "grad_norm": 0.2263995110988617,
      "learning_rate": 0.00038038999495857,
      "loss": 1.3766,
      "step": 20590
    },
    {
      "epoch": 66.23832528180354,
      "grad_norm": 0.27266034483909607,
      "learning_rate": 0.0003802808033657896,
      "loss": 1.3643,
      "step": 20600
    },
    {
      "epoch": 66.27053140096618,
      "grad_norm": 0.22704455256462097,
      "learning_rate": 0.00038017157764378665,
      "loss": 1.384,
      "step": 20610
    },
    {
      "epoch": 66.30273752012883,
      "grad_norm": 0.21768736839294434,
      "learning_rate": 0.0003800623178211746,
      "loss": 1.3555,
      "step": 20620
    },
    {
      "epoch": 66.33494363929147,
      "grad_norm": 0.23129181563854218,
      "learning_rate": 0.00037995302392657593,
      "loss": 1.3683,
      "step": 20630
    },
    {
      "epoch": 66.3671497584541,
      "grad_norm": 0.25653624534606934,
      "learning_rate": 0.0003798436959886219,
      "loss": 1.3664,
      "step": 20640
    },
    {
      "epoch": 66.39935587761674,
      "grad_norm": 0.21088048815727234,
      "learning_rate": 0.00037973433403595293,
      "loss": 1.3928,
      "step": 20650
    },
    {
      "epoch": 66.4315619967794,
      "grad_norm": 0.24185407161712646,
      "learning_rate": 0.0003796249380972181,
      "loss": 1.388,
      "step": 20660
    },
    {
      "epoch": 66.46376811594203,
      "grad_norm": 0.2792479991912842,
      "learning_rate": 0.0003795155082010754,
      "loss": 1.3544,
      "step": 20670
    },
    {
      "epoch": 66.49597423510467,
      "grad_norm": 0.21278943121433258,
      "learning_rate": 0.00037940604437619195,
      "loss": 1.3938,
      "step": 20680
    },
    {
      "epoch": 66.5281803542673,
      "grad_norm": 0.23033158481121063,
      "learning_rate": 0.0003792965466512437,
      "loss": 1.3732,
      "step": 20690
    },
    {
      "epoch": 66.56038647342996,
      "grad_norm": 0.2224789261817932,
      "learning_rate": 0.0003791870150549152,
      "loss": 1.3721,
      "step": 20700
    },
    {
      "epoch": 66.5925925925926,
      "grad_norm": 0.2973765432834625,
      "learning_rate": 0.0003790774496159002,
      "loss": 1.3627,
      "step": 20710
    },
    {
      "epoch": 66.62479871175523,
      "grad_norm": 0.23619408905506134,
      "learning_rate": 0.00037896785036290104,
      "loss": 1.3887,
      "step": 20720
    },
    {
      "epoch": 66.65700483091787,
      "grad_norm": 0.27463364601135254,
      "learning_rate": 0.00037885821732462925,
      "loss": 1.3796,
      "step": 20730
    },
    {
      "epoch": 66.68921095008052,
      "grad_norm": 0.2553025782108307,
      "learning_rate": 0.00037874855052980494,
      "loss": 1.3886,
      "step": 20740
    },
    {
      "epoch": 66.72141706924316,
      "grad_norm": 0.23939074575901031,
      "learning_rate": 0.00037863885000715726,
      "loss": 1.3732,
      "step": 20750
    },
    {
      "epoch": 66.7536231884058,
      "grad_norm": 0.22780710458755493,
      "learning_rate": 0.0003785291157854238,
      "loss": 1.3677,
      "step": 20760
    },
    {
      "epoch": 66.78582930756843,
      "grad_norm": 0.2562524974346161,
      "learning_rate": 0.0003784193478933516,
      "loss": 1.3737,
      "step": 20770
    },
    {
      "epoch": 66.81803542673107,
      "grad_norm": 0.28652092814445496,
      "learning_rate": 0.000378309546359696,
      "loss": 1.3677,
      "step": 20780
    },
    {
      "epoch": 66.85024154589372,
      "grad_norm": 0.2538701891899109,
      "learning_rate": 0.00037819971121322136,
      "loss": 1.3662,
      "step": 20790
    },
    {
      "epoch": 66.88244766505636,
      "grad_norm": 0.20915906131267548,
      "learning_rate": 0.00037808984248270086,
      "loss": 1.3713,
      "step": 20800
    },
    {
      "epoch": 66.914653784219,
      "grad_norm": 0.2915743887424469,
      "learning_rate": 0.0003779799401969164,
      "loss": 1.375,
      "step": 20810
    },
    {
      "epoch": 66.94685990338164,
      "grad_norm": 0.2246035635471344,
      "learning_rate": 0.00037787000438465864,
      "loss": 1.3759,
      "step": 20820
    },
    {
      "epoch": 66.97906602254429,
      "grad_norm": 0.19388413429260254,
      "learning_rate": 0.00037776003507472734,
      "loss": 1.349,
      "step": 20830
    },
    {
      "epoch": 67.0,
      "eval_loss": 0.6394791603088379,
      "eval_runtime": 7.1148,
      "eval_samples_per_second": 3415.836,
      "eval_steps_per_second": 13.352,
      "step": 20837
    },
    {
      "epoch": 67.00966183574879,
      "grad_norm": 0.1938859075307846,
      "learning_rate": 0.0003776500322959305,
      "loss": 1.2933,
      "step": 20840
    },
    {
      "epoch": 67.04186795491144,
      "grad_norm": 0.27748623490333557,
      "learning_rate": 0.0003775399960770853,
      "loss": 1.3453,
      "step": 20850
    },
    {
      "epoch": 67.07407407407408,
      "grad_norm": 0.3343583047389984,
      "learning_rate": 0.00037742992644701766,
      "loss": 1.3714,
      "step": 20860
    },
    {
      "epoch": 67.10628019323671,
      "grad_norm": 0.20677867531776428,
      "learning_rate": 0.00037731982343456206,
      "loss": 1.3818,
      "step": 20870
    },
    {
      "epoch": 67.13848631239935,
      "grad_norm": 0.31922855973243713,
      "learning_rate": 0.00037720968706856175,
      "loss": 1.3894,
      "step": 20880
    },
    {
      "epoch": 67.170692431562,
      "grad_norm": 0.2041582316160202,
      "learning_rate": 0.00037709951737786883,
      "loss": 1.3707,
      "step": 20890
    },
    {
      "epoch": 67.20289855072464,
      "grad_norm": 0.30782753229141235,
      "learning_rate": 0.0003769893143913442,
      "loss": 1.3638,
      "step": 20900
    },
    {
      "epoch": 67.23510466988728,
      "grad_norm": 0.2268424928188324,
      "learning_rate": 0.00037687907813785713,
      "loss": 1.3799,
      "step": 20910
    },
    {
      "epoch": 67.26731078904992,
      "grad_norm": 0.19313205778598785,
      "learning_rate": 0.000376768808646286,
      "loss": 1.3605,
      "step": 20920
    },
    {
      "epoch": 67.29951690821257,
      "grad_norm": 0.24874362349510193,
      "learning_rate": 0.0003766585059455178,
      "loss": 1.3513,
      "step": 20930
    },
    {
      "epoch": 67.3317230273752,
      "grad_norm": 0.2630015015602112,
      "learning_rate": 0.0003765481700644479,
      "loss": 1.355,
      "step": 20940
    },
    {
      "epoch": 67.36392914653784,
      "grad_norm": 0.22209377586841583,
      "learning_rate": 0.0003764378010319809,
      "loss": 1.3752,
      "step": 20950
    },
    {
      "epoch": 67.39613526570048,
      "grad_norm": 0.2789505422115326,
      "learning_rate": 0.0003763273988770296,
      "loss": 1.3746,
      "step": 20960
    },
    {
      "epoch": 67.42834138486312,
      "grad_norm": 0.22809039056301117,
      "learning_rate": 0.0003762169636285158,
      "loss": 1.3788,
      "step": 20970
    },
    {
      "epoch": 67.46054750402577,
      "grad_norm": 0.23683717846870422,
      "learning_rate": 0.00037610649531536985,
      "loss": 1.3415,
      "step": 20980
    },
    {
      "epoch": 67.4927536231884,
      "grad_norm": 0.2634047269821167,
      "learning_rate": 0.00037599599396653067,
      "loss": 1.3833,
      "step": 20990
    },
    {
      "epoch": 67.52495974235104,
      "grad_norm": 0.25965607166290283,
      "learning_rate": 0.000375885459610946,
      "loss": 1.3979,
      "step": 21000
    },
    {
      "epoch": 67.55716586151368,
      "grad_norm": 0.2635021209716797,
      "learning_rate": 0.0003757748922775721,
      "loss": 1.371,
      "step": 21010
    },
    {
      "epoch": 67.58937198067633,
      "grad_norm": 0.22260096669197083,
      "learning_rate": 0.000375664291995374,
      "loss": 1.3795,
      "step": 21020
    },
    {
      "epoch": 67.62157809983897,
      "grad_norm": 0.2025729864835739,
      "learning_rate": 0.00037555365879332527,
      "loss": 1.3745,
      "step": 21030
    },
    {
      "epoch": 67.65378421900161,
      "grad_norm": 0.21427537500858307,
      "learning_rate": 0.00037544299270040807,
      "loss": 1.3804,
      "step": 21040
    },
    {
      "epoch": 67.68599033816425,
      "grad_norm": 0.2615622580051422,
      "learning_rate": 0.00037533229374561315,
      "loss": 1.3773,
      "step": 21050
    },
    {
      "epoch": 67.7181964573269,
      "grad_norm": 0.35687822103500366,
      "learning_rate": 0.00037522156195794,
      "loss": 1.3708,
      "step": 21060
    },
    {
      "epoch": 67.75040257648953,
      "grad_norm": 0.4566718339920044,
      "learning_rate": 0.0003751107973663969,
      "loss": 1.3727,
      "step": 21070
    },
    {
      "epoch": 67.78260869565217,
      "grad_norm": 0.27137503027915955,
      "learning_rate": 0.000375,
      "loss": 1.3779,
      "step": 21080
    },
    {
      "epoch": 67.81481481481481,
      "grad_norm": 0.2437557727098465,
      "learning_rate": 0.0003748891698877749,
      "loss": 1.3746,
      "step": 21090
    },
    {
      "epoch": 67.84702093397746,
      "grad_norm": 0.2280091792345047,
      "learning_rate": 0.00037477830705875525,
      "loss": 1.361,
      "step": 21100
    },
    {
      "epoch": 67.8792270531401,
      "grad_norm": 0.24830131232738495,
      "learning_rate": 0.0003746674115419834,
      "loss": 1.3546,
      "step": 21110
    },
    {
      "epoch": 67.91143317230274,
      "grad_norm": 0.30074095726013184,
      "learning_rate": 0.0003745564833665103,
      "loss": 1.3656,
      "step": 21120
    },
    {
      "epoch": 67.94363929146537,
      "grad_norm": 0.3175746500492096,
      "learning_rate": 0.0003744455225613954,
      "loss": 1.3812,
      "step": 21130
    },
    {
      "epoch": 67.97584541062803,
      "grad_norm": 0.29867151379585266,
      "learning_rate": 0.0003743345291557068,
      "loss": 1.375,
      "step": 21140
    },
    {
      "epoch": 68.0,
      "eval_loss": 0.6387653946876526,
      "eval_runtime": 7.0941,
      "eval_samples_per_second": 3425.787,
      "eval_steps_per_second": 13.391,
      "step": 21148
    },
    {
      "epoch": 68.00644122383252,
      "grad_norm": 0.19169186055660248,
      "learning_rate": 0.000374223503178521,
      "loss": 1.2942,
      "step": 21150
    },
    {
      "epoch": 68.03864734299516,
      "grad_norm": 0.22005487978458405,
      "learning_rate": 0.00037411244465892314,
      "loss": 1.3606,
      "step": 21160
    },
    {
      "epoch": 68.07085346215781,
      "grad_norm": 0.22472037374973297,
      "learning_rate": 0.00037400135362600684,
      "loss": 1.362,
      "step": 21170
    },
    {
      "epoch": 68.10305958132045,
      "grad_norm": 0.22149242460727692,
      "learning_rate": 0.0003738902301088741,
      "loss": 1.3551,
      "step": 21180
    },
    {
      "epoch": 68.13526570048309,
      "grad_norm": 0.23405225574970245,
      "learning_rate": 0.0003737790741366358,
      "loss": 1.363,
      "step": 21190
    },
    {
      "epoch": 68.16747181964573,
      "grad_norm": 0.2609497904777527,
      "learning_rate": 0.00037366788573841105,
      "loss": 1.3841,
      "step": 21200
    },
    {
      "epoch": 68.19967793880838,
      "grad_norm": 0.2429264485836029,
      "learning_rate": 0.0003735566649433274,
      "loss": 1.3558,
      "step": 21210
    },
    {
      "epoch": 68.23188405797102,
      "grad_norm": 0.22687697410583496,
      "learning_rate": 0.00037344541178052106,
      "loss": 1.3759,
      "step": 21220
    },
    {
      "epoch": 68.26409017713365,
      "grad_norm": 0.20656852424144745,
      "learning_rate": 0.0003733341262791365,
      "loss": 1.367,
      "step": 21230
    },
    {
      "epoch": 68.29629629629629,
      "grad_norm": 0.3354852795600891,
      "learning_rate": 0.0003732228084683271,
      "loss": 1.3759,
      "step": 21240
    },
    {
      "epoch": 68.32850241545894,
      "grad_norm": 0.24515172839164734,
      "learning_rate": 0.00037311145837725415,
      "loss": 1.3672,
      "step": 21250
    },
    {
      "epoch": 68.36070853462158,
      "grad_norm": 0.3708181083202362,
      "learning_rate": 0.0003730000760350878,
      "loss": 1.3614,
      "step": 21260
    },
    {
      "epoch": 68.39291465378422,
      "grad_norm": 0.21083694696426392,
      "learning_rate": 0.00037288866147100637,
      "loss": 1.3511,
      "step": 21270
    },
    {
      "epoch": 68.42512077294685,
      "grad_norm": 0.24014367163181305,
      "learning_rate": 0.0003727772147141969,
      "loss": 1.365,
      "step": 21280
    },
    {
      "epoch": 68.4573268921095,
      "grad_norm": 0.2418901026248932,
      "learning_rate": 0.00037266573579385466,
      "loss": 1.3721,
      "step": 21290
    },
    {
      "epoch": 68.48953301127214,
      "grad_norm": 0.23074939846992493,
      "learning_rate": 0.00037255422473918336,
      "loss": 1.3664,
      "step": 21300
    },
    {
      "epoch": 68.52173913043478,
      "grad_norm": 0.25181931257247925,
      "learning_rate": 0.00037244268157939525,
      "loss": 1.4054,
      "step": 21310
    },
    {
      "epoch": 68.55394524959742,
      "grad_norm": 0.2516576647758484,
      "learning_rate": 0.0003723311063437109,
      "loss": 1.3539,
      "step": 21320
    },
    {
      "epoch": 68.58615136876007,
      "grad_norm": 0.272737592458725,
      "learning_rate": 0.00037221949906135926,
      "loss": 1.3715,
      "step": 21330
    },
    {
      "epoch": 68.61835748792271,
      "grad_norm": 0.22622889280319214,
      "learning_rate": 0.0003721078597615778,
      "loss": 1.3622,
      "step": 21340
    },
    {
      "epoch": 68.65056360708535,
      "grad_norm": 0.2439921498298645,
      "learning_rate": 0.0003719961884736122,
      "loss": 1.3765,
      "step": 21350
    },
    {
      "epoch": 68.68276972624798,
      "grad_norm": 0.25209304690361023,
      "learning_rate": 0.00037188448522671656,
      "loss": 1.3555,
      "step": 21360
    },
    {
      "epoch": 68.71497584541063,
      "grad_norm": 0.224209725856781,
      "learning_rate": 0.00037177275005015364,
      "loss": 1.3786,
      "step": 21370
    },
    {
      "epoch": 68.74718196457327,
      "grad_norm": 0.259712815284729,
      "learning_rate": 0.00037166098297319405,
      "loss": 1.385,
      "step": 21380
    },
    {
      "epoch": 68.77938808373591,
      "grad_norm": 0.2657604217529297,
      "learning_rate": 0.0003715491840251172,
      "loss": 1.3987,
      "step": 21390
    },
    {
      "epoch": 68.81159420289855,
      "grad_norm": 0.21789632737636566,
      "learning_rate": 0.00037143735323521063,
      "loss": 1.3706,
      "step": 21400
    },
    {
      "epoch": 68.84380032206118,
      "grad_norm": 0.2010899931192398,
      "learning_rate": 0.00037132549063277035,
      "loss": 1.3676,
      "step": 21410
    },
    {
      "epoch": 68.87600644122384,
      "grad_norm": 0.3686459958553314,
      "learning_rate": 0.00037121359624710037,
      "loss": 1.3709,
      "step": 21420
    },
    {
      "epoch": 68.90821256038647,
      "grad_norm": 0.26333698630332947,
      "learning_rate": 0.0003711016701075136,
      "loss": 1.3499,
      "step": 21430
    },
    {
      "epoch": 68.94041867954911,
      "grad_norm": 0.2116038203239441,
      "learning_rate": 0.00037098971224333095,
      "loss": 1.3822,
      "step": 21440
    },
    {
      "epoch": 68.97262479871175,
      "grad_norm": 0.22299525141716003,
      "learning_rate": 0.0003708777226838813,
      "loss": 1.3844,
      "step": 21450
    },
    {
      "epoch": 69.0,
      "eval_loss": 0.6388161778450012,
      "eval_runtime": 7.1034,
      "eval_samples_per_second": 3421.296,
      "eval_steps_per_second": 13.374,
      "step": 21459
    },
    {
      "epoch": 69.00322061191626,
      "grad_norm": 0.31040042638778687,
      "learning_rate": 0.0003707657014585025,
      "loss": 1.2857,
      "step": 21460
    },
    {
      "epoch": 69.0354267310789,
      "grad_norm": 0.22062964737415314,
      "learning_rate": 0.00037065364859654033,
      "loss": 1.3559,
      "step": 21470
    },
    {
      "epoch": 69.06763285024155,
      "grad_norm": 0.20841218531131744,
      "learning_rate": 0.0003705415641273488,
      "loss": 1.3667,
      "step": 21480
    },
    {
      "epoch": 69.09983896940419,
      "grad_norm": 0.21949400007724762,
      "learning_rate": 0.00037042944808029035,
      "loss": 1.373,
      "step": 21490
    },
    {
      "epoch": 69.13204508856683,
      "grad_norm": 0.3021756410598755,
      "learning_rate": 0.0003703173004847356,
      "loss": 1.3638,
      "step": 21500
    },
    {
      "epoch": 69.16425120772946,
      "grad_norm": 0.26042184233665466,
      "learning_rate": 0.00037020512137006355,
      "loss": 1.3649,
      "step": 21510
    },
    {
      "epoch": 69.19645732689212,
      "grad_norm": 0.22907213866710663,
      "learning_rate": 0.0003700929107656614,
      "loss": 1.3618,
      "step": 21520
    },
    {
      "epoch": 69.22866344605475,
      "grad_norm": 0.2436787188053131,
      "learning_rate": 0.00036998066870092445,
      "loss": 1.3739,
      "step": 21530
    },
    {
      "epoch": 69.26086956521739,
      "grad_norm": 0.20736612379550934,
      "learning_rate": 0.00036986839520525646,
      "loss": 1.3729,
      "step": 21540
    },
    {
      "epoch": 69.29307568438003,
      "grad_norm": 0.218057319521904,
      "learning_rate": 0.00036975609030806935,
      "loss": 1.3736,
      "step": 21550
    },
    {
      "epoch": 69.32528180354268,
      "grad_norm": 0.24080529808998108,
      "learning_rate": 0.00036964375403878325,
      "loss": 1.3807,
      "step": 21560
    },
    {
      "epoch": 69.35748792270532,
      "grad_norm": 0.2279788851737976,
      "learning_rate": 0.0003695313864268265,
      "loss": 1.3431,
      "step": 21570
    },
    {
      "epoch": 69.38969404186795,
      "grad_norm": 0.270137757062912,
      "learning_rate": 0.0003694189875016357,
      "loss": 1.3821,
      "step": 21580
    },
    {
      "epoch": 69.42190016103059,
      "grad_norm": 0.25614693760871887,
      "learning_rate": 0.00036930655729265556,
      "loss": 1.3796,
      "step": 21590
    },
    {
      "epoch": 69.45410628019323,
      "grad_norm": 0.18728069961071014,
      "learning_rate": 0.000369194095829339,
      "loss": 1.384,
      "step": 21600
    },
    {
      "epoch": 69.48631239935588,
      "grad_norm": 0.20785930752754211,
      "learning_rate": 0.0003690816031411474,
      "loss": 1.3521,
      "step": 21610
    },
    {
      "epoch": 69.51851851851852,
      "grad_norm": 0.24366140365600586,
      "learning_rate": 0.0003689690792575498,
      "loss": 1.3628,
      "step": 21620
    },
    {
      "epoch": 69.55072463768116,
      "grad_norm": 0.22549210488796234,
      "learning_rate": 0.0003688565242080238,
      "loss": 1.3716,
      "step": 21630
    },
    {
      "epoch": 69.5829307568438,
      "grad_norm": 0.3096090257167816,
      "learning_rate": 0.0003687439380220552,
      "loss": 1.3711,
      "step": 21640
    },
    {
      "epoch": 69.61513687600645,
      "grad_norm": 0.23799146711826324,
      "learning_rate": 0.0003686313207291377,
      "loss": 1.3939,
      "step": 21650
    },
    {
      "epoch": 69.64734299516908,
      "grad_norm": 0.23798920214176178,
      "learning_rate": 0.00036851867235877323,
      "loss": 1.3691,
      "step": 21660
    },
    {
      "epoch": 69.67954911433172,
      "grad_norm": 0.2113317996263504,
      "learning_rate": 0.000368405992940472,
      "loss": 1.3833,
      "step": 21670
    },
    {
      "epoch": 69.71175523349436,
      "grad_norm": 0.23183874785900116,
      "learning_rate": 0.0003682932825037523,
      "loss": 1.3433,
      "step": 21680
    },
    {
      "epoch": 69.74396135265701,
      "grad_norm": 0.220161572098732,
      "learning_rate": 0.0003681805410781403,
      "loss": 1.3744,
      "step": 21690
    },
    {
      "epoch": 69.77616747181965,
      "grad_norm": 0.24357527494430542,
      "learning_rate": 0.0003680677686931707,
      "loss": 1.3624,
      "step": 21700
    },
    {
      "epoch": 69.80837359098228,
      "grad_norm": 0.25526851415634155,
      "learning_rate": 0.00036795496537838604,
      "loss": 1.3703,
      "step": 21710
    },
    {
      "epoch": 69.84057971014492,
      "grad_norm": 0.19723042845726013,
      "learning_rate": 0.0003678421311633369,
      "loss": 1.3929,
      "step": 21720
    },
    {
      "epoch": 69.87278582930757,
      "grad_norm": 0.21313631534576416,
      "learning_rate": 0.0003677292660775823,
      "loss": 1.3736,
      "step": 21730
    },
    {
      "epoch": 69.90499194847021,
      "grad_norm": 0.3037756681442261,
      "learning_rate": 0.00036761637015068893,
      "loss": 1.3589,
      "step": 21740
    },
    {
      "epoch": 69.93719806763285,
      "grad_norm": 0.7002348899841309,
      "learning_rate": 0.0003675034434122318,
      "loss": 1.3532,
      "step": 21750
    },
    {
      "epoch": 69.96940418679549,
      "grad_norm": 0.20813371241092682,
      "learning_rate": 0.0003673904858917941,
      "loss": 1.3762,
      "step": 21760
    },
    {
      "epoch": 70.0,
      "grad_norm": 0.23675361275672913,
      "learning_rate": 0.00036727749761896665,
      "loss": 1.288,
      "step": 21770
    },
    {
      "epoch": 70.0,
      "eval_loss": 0.640586793422699,
      "eval_runtime": 7.0919,
      "eval_samples_per_second": 3426.846,
      "eval_steps_per_second": 13.395,
      "step": 21770
    },
    {
      "epoch": 70.03220611916264,
      "grad_norm": 0.23681257665157318,
      "learning_rate": 0.00036716447862334897,
      "loss": 1.3774,
      "step": 21780
    },
    {
      "epoch": 70.06441223832527,
      "grad_norm": 0.2713564932346344,
      "learning_rate": 0.0003670514289345479,
      "loss": 1.3766,
      "step": 21790
    },
    {
      "epoch": 70.09661835748793,
      "grad_norm": 0.21462713181972504,
      "learning_rate": 0.0003669383485821789,
      "loss": 1.3713,
      "step": 21800
    },
    {
      "epoch": 70.12882447665056,
      "grad_norm": 0.26267528533935547,
      "learning_rate": 0.0003668252375958652,
      "loss": 1.3622,
      "step": 21810
    },
    {
      "epoch": 70.1610305958132,
      "grad_norm": 0.25286510586738586,
      "learning_rate": 0.00036671209600523815,
      "loss": 1.3697,
      "step": 21820
    },
    {
      "epoch": 70.19323671497584,
      "grad_norm": 0.22409434616565704,
      "learning_rate": 0.0003665989238399369,
      "loss": 1.3606,
      "step": 21830
    },
    {
      "epoch": 70.22544283413849,
      "grad_norm": 0.27959346771240234,
      "learning_rate": 0.00036648572112960893,
      "loss": 1.3681,
      "step": 21840
    },
    {
      "epoch": 70.25764895330113,
      "grad_norm": 0.25272271037101746,
      "learning_rate": 0.00036637248790390967,
      "loss": 1.388,
      "step": 21850
    },
    {
      "epoch": 70.28985507246377,
      "grad_norm": 0.22158953547477722,
      "learning_rate": 0.00036625922419250215,
      "loss": 1.3582,
      "step": 21860
    },
    {
      "epoch": 70.3220611916264,
      "grad_norm": 0.21808882057666779,
      "learning_rate": 0.0003661459300250579,
      "loss": 1.3765,
      "step": 21870
    },
    {
      "epoch": 70.35426731078906,
      "grad_norm": 0.23354826867580414,
      "learning_rate": 0.00036603260543125626,
      "loss": 1.3527,
      "step": 21880
    },
    {
      "epoch": 70.38647342995169,
      "grad_norm": 0.2013271152973175,
      "learning_rate": 0.0003659192504407843,
      "loss": 1.3665,
      "step": 21890
    },
    {
      "epoch": 70.41867954911433,
      "grad_norm": 0.22100207209587097,
      "learning_rate": 0.00036580586508333735,
      "loss": 1.3703,
      "step": 21900
    },
    {
      "epoch": 70.45088566827697,
      "grad_norm": 0.2142261117696762,
      "learning_rate": 0.0003656924493886186,
      "loss": 1.3631,
      "step": 21910
    },
    {
      "epoch": 70.48309178743962,
      "grad_norm": 0.2436065822839737,
      "learning_rate": 0.00036557900338633916,
      "loss": 1.3515,
      "step": 21920
    },
    {
      "epoch": 70.51529790660226,
      "grad_norm": 0.18234746158123016,
      "learning_rate": 0.00036546552710621803,
      "loss": 1.3625,
      "step": 21930
    },
    {
      "epoch": 70.5475040257649,
      "grad_norm": 0.1830376833677292,
      "learning_rate": 0.00036535202057798235,
      "loss": 1.3622,
      "step": 21940
    },
    {
      "epoch": 70.57971014492753,
      "grad_norm": 0.24976982176303864,
      "learning_rate": 0.00036523848383136694,
      "loss": 1.3563,
      "step": 21950
    },
    {
      "epoch": 70.61191626409018,
      "grad_norm": 0.21013598144054413,
      "learning_rate": 0.0003651249168961146,
      "loss": 1.3685,
      "step": 21960
    },
    {
      "epoch": 70.64412238325282,
      "grad_norm": 0.18694554269313812,
      "learning_rate": 0.00036501131980197623,
      "loss": 1.3847,
      "step": 21970
    },
    {
      "epoch": 70.67632850241546,
      "grad_norm": 0.24914489686489105,
      "learning_rate": 0.0003648976925787103,
      "loss": 1.3667,
      "step": 21980
    },
    {
      "epoch": 70.7085346215781,
      "grad_norm": 0.22466373443603516,
      "learning_rate": 0.0003647840352560835,
      "loss": 1.3623,
      "step": 21990
    },
    {
      "epoch": 70.74074074074075,
      "grad_norm": 0.21069665253162384,
      "learning_rate": 0.00036467034786387013,
      "loss": 1.3479,
      "step": 22000
    },
    {
      "epoch": 70.77294685990339,
      "grad_norm": 0.188224196434021,
      "learning_rate": 0.0003645566304318526,
      "loss": 1.3707,
      "step": 22010
    },
    {
      "epoch": 70.80515297906602,
      "grad_norm": 0.2147824466228485,
      "learning_rate": 0.00036444288298982105,
      "loss": 1.3681,
      "step": 22020
    },
    {
      "epoch": 70.83735909822866,
      "grad_norm": 0.24038365483283997,
      "learning_rate": 0.0003643291055675735,
      "loss": 1.3738,
      "step": 22030
    },
    {
      "epoch": 70.8695652173913,
      "grad_norm": 0.21912220120429993,
      "learning_rate": 0.00036421529819491574,
      "loss": 1.3842,
      "step": 22040
    },
    {
      "epoch": 70.90177133655395,
      "grad_norm": 0.22514787316322327,
      "learning_rate": 0.0003641014609016617,
      "loss": 1.3713,
      "step": 22050
    },
    {
      "epoch": 70.93397745571659,
      "grad_norm": 0.1969272494316101,
      "learning_rate": 0.0003639875937176328,
      "loss": 1.3621,
      "step": 22060
    },
    {
      "epoch": 70.96618357487922,
      "grad_norm": 0.20649944245815277,
      "learning_rate": 0.00036387369667265844,
      "loss": 1.366,
      "step": 22070
    },
    {
      "epoch": 70.99838969404186,
      "grad_norm": 0.19598914682865143,
      "learning_rate": 0.0003637597697965761,
      "loss": 1.3683,
      "step": 22080
    },
    {
      "epoch": 71.0,
      "eval_loss": 0.6390606164932251,
      "eval_runtime": 7.2991,
      "eval_samples_per_second": 3329.579,
      "eval_steps_per_second": 13.015,
      "step": 22081
    },
    {
      "epoch": 71.02898550724638,
      "grad_norm": 0.1808958351612091,
      "learning_rate": 0.00036364581311923043,
      "loss": 1.2757,
      "step": 22090
    },
    {
      "epoch": 71.06119162640901,
      "grad_norm": 0.20677563548088074,
      "learning_rate": 0.00036353182667047453,
      "loss": 1.3652,
      "step": 22100
    },
    {
      "epoch": 71.09339774557166,
      "grad_norm": 0.21120356023311615,
      "learning_rate": 0.000363417810480169,
      "loss": 1.3546,
      "step": 22110
    },
    {
      "epoch": 71.1256038647343,
      "grad_norm": 0.23169323801994324,
      "learning_rate": 0.0003633037645781823,
      "loss": 1.3637,
      "step": 22120
    },
    {
      "epoch": 71.15780998389694,
      "grad_norm": 0.19642791152000427,
      "learning_rate": 0.00036318968899439044,
      "loss": 1.3706,
      "step": 22130
    },
    {
      "epoch": 71.19001610305958,
      "grad_norm": 0.2150573879480362,
      "learning_rate": 0.00036307558375867766,
      "loss": 1.3755,
      "step": 22140
    },
    {
      "epoch": 71.22222222222223,
      "grad_norm": 0.22458671033382416,
      "learning_rate": 0.00036296144890093576,
      "loss": 1.3651,
      "step": 22150
    },
    {
      "epoch": 71.25442834138487,
      "grad_norm": 0.27200090885162354,
      "learning_rate": 0.00036284728445106396,
      "loss": 1.3605,
      "step": 22160
    },
    {
      "epoch": 71.2866344605475,
      "grad_norm": 0.28533506393432617,
      "learning_rate": 0.00036273309043896986,
      "loss": 1.356,
      "step": 22170
    },
    {
      "epoch": 71.31884057971014,
      "grad_norm": 0.18264001607894897,
      "learning_rate": 0.0003626188668945682,
      "loss": 1.3474,
      "step": 22180
    },
    {
      "epoch": 71.35104669887279,
      "grad_norm": 0.25852853059768677,
      "learning_rate": 0.00036250461384778205,
      "loss": 1.3745,
      "step": 22190
    },
    {
      "epoch": 71.38325281803543,
      "grad_norm": 0.1928037405014038,
      "learning_rate": 0.0003623903313285417,
      "loss": 1.3659,
      "step": 22200
    },
    {
      "epoch": 71.41545893719807,
      "grad_norm": 0.20971372723579407,
      "learning_rate": 0.00036227601936678533,
      "loss": 1.3687,
      "step": 22210
    },
    {
      "epoch": 71.4476650563607,
      "grad_norm": 0.3093366324901581,
      "learning_rate": 0.0003621616779924589,
      "loss": 1.3721,
      "step": 22220
    },
    {
      "epoch": 71.47987117552334,
      "grad_norm": 0.23379845917224884,
      "learning_rate": 0.0003620473072355161,
      "loss": 1.3577,
      "step": 22230
    },
    {
      "epoch": 71.512077294686,
      "grad_norm": 0.21621260046958923,
      "learning_rate": 0.0003619329071259182,
      "loss": 1.3801,
      "step": 22240
    },
    {
      "epoch": 71.54428341384863,
      "grad_norm": 0.1675937920808792,
      "learning_rate": 0.0003618184776936342,
      "loss": 1.3631,
      "step": 22250
    },
    {
      "epoch": 71.57648953301127,
      "grad_norm": 0.21415995061397552,
      "learning_rate": 0.00036170401896864075,
      "loss": 1.3707,
      "step": 22260
    },
    {
      "epoch": 71.6086956521739,
      "grad_norm": 0.2138792723417282,
      "learning_rate": 0.0003615895309809223,
      "loss": 1.3735,
      "step": 22270
    },
    {
      "epoch": 71.64090177133656,
      "grad_norm": 0.1666075587272644,
      "learning_rate": 0.0003614750137604709,
      "loss": 1.3572,
      "step": 22280
    },
    {
      "epoch": 71.6731078904992,
      "grad_norm": 0.22893041372299194,
      "learning_rate": 0.00036136046733728613,
      "loss": 1.3753,
      "step": 22290
    },
    {
      "epoch": 71.70531400966183,
      "grad_norm": 0.19184674322605133,
      "learning_rate": 0.00036124589174137535,
      "loss": 1.3711,
      "step": 22300
    },
    {
      "epoch": 71.73752012882447,
      "grad_norm": 0.20790249109268188,
      "learning_rate": 0.0003611312870027536,
      "loss": 1.365,
      "step": 22310
    },
    {
      "epoch": 71.76972624798712,
      "grad_norm": 0.21732358634471893,
      "learning_rate": 0.00036101665315144355,
      "loss": 1.3803,
      "step": 22320
    },
    {
      "epoch": 71.80193236714976,
      "grad_norm": 0.21735738217830658,
      "learning_rate": 0.0003609019902174754,
      "loss": 1.3819,
      "step": 22330
    },
    {
      "epoch": 71.8341384863124,
      "grad_norm": 0.2061578631401062,
      "learning_rate": 0.00036078729823088687,
      "loss": 1.3692,
      "step": 22340
    },
    {
      "epoch": 71.86634460547504,
      "grad_norm": 0.32644641399383545,
      "learning_rate": 0.0003606725772217235,
      "loss": 1.3537,
      "step": 22350
    },
    {
      "epoch": 71.89855072463769,
      "grad_norm": 0.19086343050003052,
      "learning_rate": 0.0003605578272200386,
      "loss": 1.3648,
      "step": 22360
    },
    {
      "epoch": 71.93075684380032,
      "grad_norm": 0.23148280382156372,
      "learning_rate": 0.0003604430482558925,
      "loss": 1.3664,
      "step": 22370
    },
    {
      "epoch": 71.96296296296296,
      "grad_norm": 0.3326570987701416,
      "learning_rate": 0.0003603282403593537,
      "loss": 1.3811,
      "step": 22380
    },
    {
      "epoch": 71.9951690821256,
      "grad_norm": 0.21870550513267517,
      "learning_rate": 0.0003602134035604979,
      "loss": 1.3728,
      "step": 22390
    },
    {
      "epoch": 72.0,
      "eval_loss": 0.641572117805481,
      "eval_runtime": 7.0937,
      "eval_samples_per_second": 3425.978,
      "eval_steps_per_second": 13.392,
      "step": 22392
    },
    {
      "epoch": 72.02576489533011,
      "grad_norm": 0.22723248600959778,
      "learning_rate": 0.0003600985378894086,
      "loss": 1.3019,
      "step": 22400
    },
    {
      "epoch": 72.05797101449275,
      "grad_norm": 0.232329323887825,
      "learning_rate": 0.0003599836433761767,
      "loss": 1.3591,
      "step": 22410
    },
    {
      "epoch": 72.09017713365539,
      "grad_norm": 0.19830283522605896,
      "learning_rate": 0.00035986872005090074,
      "loss": 1.3663,
      "step": 22420
    },
    {
      "epoch": 72.12238325281804,
      "grad_norm": 0.2223137468099594,
      "learning_rate": 0.00035975376794368687,
      "loss": 1.3637,
      "step": 22430
    },
    {
      "epoch": 72.15458937198068,
      "grad_norm": 0.20724916458129883,
      "learning_rate": 0.0003596387870846486,
      "loss": 1.3619,
      "step": 22440
    },
    {
      "epoch": 72.18679549114331,
      "grad_norm": 0.18700167536735535,
      "learning_rate": 0.0003595237775039071,
      "loss": 1.3428,
      "step": 22450
    },
    {
      "epoch": 72.21900161030595,
      "grad_norm": 0.19246618449687958,
      "learning_rate": 0.00035940873923159117,
      "loss": 1.3941,
      "step": 22460
    },
    {
      "epoch": 72.2512077294686,
      "grad_norm": 0.2502456605434418,
      "learning_rate": 0.0003592936722978368,
      "loss": 1.3396,
      "step": 22470
    },
    {
      "epoch": 72.28341384863124,
      "grad_norm": 0.24289171397686005,
      "learning_rate": 0.00035917857673278787,
      "loss": 1.3609,
      "step": 22480
    },
    {
      "epoch": 72.31561996779388,
      "grad_norm": 0.379807710647583,
      "learning_rate": 0.00035906345256659543,
      "loss": 1.3633,
      "step": 22490
    },
    {
      "epoch": 72.34782608695652,
      "grad_norm": 0.24149495363235474,
      "learning_rate": 0.00035894829982941823,
      "loss": 1.3755,
      "step": 22500
    },
    {
      "epoch": 72.38003220611917,
      "grad_norm": 0.2177041620016098,
      "learning_rate": 0.0003588331185514225,
      "loss": 1.3632,
      "step": 22510
    },
    {
      "epoch": 72.4122383252818,
      "grad_norm": 0.22203142940998077,
      "learning_rate": 0.00035871790876278176,
      "loss": 1.3662,
      "step": 22520
    },
    {
      "epoch": 72.44444444444444,
      "grad_norm": 0.3274964392185211,
      "learning_rate": 0.00035860267049367726,
      "loss": 1.3645,
      "step": 22530
    },
    {
      "epoch": 72.47665056360708,
      "grad_norm": 0.1971367746591568,
      "learning_rate": 0.0003584874037742975,
      "loss": 1.3788,
      "step": 22540
    },
    {
      "epoch": 72.50885668276973,
      "grad_norm": 0.22940422594547272,
      "learning_rate": 0.0003583721086348385,
      "loss": 1.362,
      "step": 22550
    },
    {
      "epoch": 72.54106280193237,
      "grad_norm": 0.24649088084697723,
      "learning_rate": 0.0003582567851055039,
      "loss": 1.3671,
      "step": 22560
    },
    {
      "epoch": 72.573268921095,
      "grad_norm": 0.35488268733024597,
      "learning_rate": 0.00035814143321650436,
      "loss": 1.3351,
      "step": 22570
    },
    {
      "epoch": 72.60547504025764,
      "grad_norm": 0.19501039385795593,
      "learning_rate": 0.0003580260529980584,
      "loss": 1.3825,
      "step": 22580
    },
    {
      "epoch": 72.6376811594203,
      "grad_norm": 0.24143296480178833,
      "learning_rate": 0.00035791064448039176,
      "loss": 1.3797,
      "step": 22590
    },
    {
      "epoch": 72.66988727858293,
      "grad_norm": 0.2493652105331421,
      "learning_rate": 0.00035779520769373764,
      "loss": 1.3809,
      "step": 22600
    },
    {
      "epoch": 72.70209339774557,
      "grad_norm": 0.2649385929107666,
      "learning_rate": 0.0003576797426683365,
      "loss": 1.3812,
      "step": 22610
    },
    {
      "epoch": 72.73429951690821,
      "grad_norm": 0.22406300902366638,
      "learning_rate": 0.0003575642494344365,
      "loss": 1.3569,
      "step": 22620
    },
    {
      "epoch": 72.76650563607086,
      "grad_norm": 0.2043197751045227,
      "learning_rate": 0.00035744872802229296,
      "loss": 1.3645,
      "step": 22630
    },
    {
      "epoch": 72.7987117552335,
      "grad_norm": 0.2472936362028122,
      "learning_rate": 0.0003573331784621685,
      "loss": 1.3689,
      "step": 22640
    },
    {
      "epoch": 72.83091787439614,
      "grad_norm": 0.2561072111129761,
      "learning_rate": 0.0003572176007843334,
      "loss": 1.3435,
      "step": 22650
    },
    {
      "epoch": 72.86312399355877,
      "grad_norm": 0.45308226346969604,
      "learning_rate": 0.00035710199501906516,
      "loss": 1.3724,
      "step": 22660
    },
    {
      "epoch": 72.89533011272141,
      "grad_norm": 0.20674103498458862,
      "learning_rate": 0.0003569863611966484,
      "loss": 1.3521,
      "step": 22670
    },
    {
      "epoch": 72.92753623188406,
      "grad_norm": 0.22973814606666565,
      "learning_rate": 0.00035687069934737565,
      "loss": 1.3663,
      "step": 22680
    },
    {
      "epoch": 72.9597423510467,
      "grad_norm": 0.226684108376503,
      "learning_rate": 0.00035675500950154625,
      "loss": 1.38,
      "step": 22690
    },
    {
      "epoch": 72.99194847020934,
      "grad_norm": 0.2046048939228058,
      "learning_rate": 0.0003566392916894672,
      "loss": 1.3533,
      "step": 22700
    },
    {
      "epoch": 73.0,
      "eval_loss": 0.6396750807762146,
      "eval_runtime": 7.051,
      "eval_samples_per_second": 3446.728,
      "eval_steps_per_second": 13.473,
      "step": 22703
    },
    {
      "epoch": 73.02254428341385,
      "grad_norm": 0.23141469061374664,
      "learning_rate": 0.00035652354594145256,
      "loss": 1.3107,
      "step": 22710
    },
    {
      "epoch": 73.05475040257649,
      "grad_norm": 0.20557962357997894,
      "learning_rate": 0.00035640777228782396,
      "loss": 1.3597,
      "step": 22720
    },
    {
      "epoch": 73.08695652173913,
      "grad_norm": 0.21259239315986633,
      "learning_rate": 0.00035629197075891017,
      "loss": 1.3447,
      "step": 22730
    },
    {
      "epoch": 73.11916264090178,
      "grad_norm": 0.28814274072647095,
      "learning_rate": 0.0003561761413850474,
      "loss": 1.3712,
      "step": 22740
    },
    {
      "epoch": 73.15136876006441,
      "grad_norm": 0.200928196310997,
      "learning_rate": 0.00035606028419657903,
      "loss": 1.3282,
      "step": 22750
    },
    {
      "epoch": 73.18357487922705,
      "grad_norm": 0.2031739354133606,
      "learning_rate": 0.0003559443992238558,
      "loss": 1.3307,
      "step": 22760
    },
    {
      "epoch": 73.21578099838969,
      "grad_norm": 0.20442740619182587,
      "learning_rate": 0.0003558284864972357,
      "loss": 1.3586,
      "step": 22770
    },
    {
      "epoch": 73.24798711755234,
      "grad_norm": 0.21963278949260712,
      "learning_rate": 0.00035571254604708396,
      "loss": 1.3768,
      "step": 22780
    },
    {
      "epoch": 73.28019323671498,
      "grad_norm": 0.24421928822994232,
      "learning_rate": 0.0003555965779037732,
      "loss": 1.3711,
      "step": 22790
    },
    {
      "epoch": 73.31239935587762,
      "grad_norm": 0.2566988170146942,
      "learning_rate": 0.0003554805820976831,
      "loss": 1.3534,
      "step": 22800
    },
    {
      "epoch": 73.34460547504025,
      "grad_norm": 0.24067403376102448,
      "learning_rate": 0.0003553645586592007,
      "loss": 1.3735,
      "step": 22810
    },
    {
      "epoch": 73.3768115942029,
      "grad_norm": 0.23199138045310974,
      "learning_rate": 0.00035524850761872024,
      "loss": 1.3646,
      "step": 22820
    },
    {
      "epoch": 73.40901771336554,
      "grad_norm": 0.1992367058992386,
      "learning_rate": 0.00035513242900664344,
      "loss": 1.3792,
      "step": 22830
    },
    {
      "epoch": 73.44122383252818,
      "grad_norm": 0.20390355587005615,
      "learning_rate": 0.00035501632285337873,
      "loss": 1.3407,
      "step": 22840
    },
    {
      "epoch": 73.47342995169082,
      "grad_norm": 0.19447247684001923,
      "learning_rate": 0.0003549001891893422,
      "loss": 1.372,
      "step": 22850
    },
    {
      "epoch": 73.50563607085346,
      "grad_norm": 0.2253718227148056,
      "learning_rate": 0.00035478402804495706,
      "loss": 1.3698,
      "step": 22860
    },
    {
      "epoch": 73.53784219001611,
      "grad_norm": 0.29125645756721497,
      "learning_rate": 0.0003546678394506535,
      "loss": 1.3855,
      "step": 22870
    },
    {
      "epoch": 73.57004830917874,
      "grad_norm": 0.2597270607948303,
      "learning_rate": 0.00035455162343686907,
      "loss": 1.3807,
      "step": 22880
    },
    {
      "epoch": 73.60225442834138,
      "grad_norm": 0.22121798992156982,
      "learning_rate": 0.0003544353800340486,
      "loss": 1.3789,
      "step": 22890
    },
    {
      "epoch": 73.63446054750402,
      "grad_norm": 0.21488402783870697,
      "learning_rate": 0.000354319109272644,
      "loss": 1.3763,
      "step": 22900
    },
    {
      "epoch": 73.66666666666667,
      "grad_norm": 0.23592188954353333,
      "learning_rate": 0.0003542028111831141,
      "loss": 1.3589,
      "step": 22910
    },
    {
      "epoch": 73.69887278582931,
      "grad_norm": 0.22774764895439148,
      "learning_rate": 0.00035408648579592534,
      "loss": 1.3643,
      "step": 22920
    },
    {
      "epoch": 73.73107890499195,
      "grad_norm": 0.24991051852703094,
      "learning_rate": 0.000353970133141551,
      "loss": 1.3592,
      "step": 22930
    },
    {
      "epoch": 73.76328502415458,
      "grad_norm": 0.23474718630313873,
      "learning_rate": 0.00035385375325047166,
      "loss": 1.3616,
      "step": 22940
    },
    {
      "epoch": 73.79549114331724,
      "grad_norm": 0.2287965714931488,
      "learning_rate": 0.00035373734615317483,
      "loss": 1.3623,
      "step": 22950
    },
    {
      "epoch": 73.82769726247987,
      "grad_norm": 0.2483915239572525,
      "learning_rate": 0.00035362091188015544,
      "loss": 1.3616,
      "step": 22960
    },
    {
      "epoch": 73.85990338164251,
      "grad_norm": 0.21422426402568817,
      "learning_rate": 0.00035350445046191526,
      "loss": 1.3792,
      "step": 22970
    },
    {
      "epoch": 73.89210950080515,
      "grad_norm": 0.23030802607536316,
      "learning_rate": 0.0003533879619289634,
      "loss": 1.358,
      "step": 22980
    },
    {
      "epoch": 73.9243156199678,
      "grad_norm": 0.20568722486495972,
      "learning_rate": 0.00035327144631181585,
      "loss": 1.3619,
      "step": 22990
    },
    {
      "epoch": 73.95652173913044,
      "grad_norm": 0.22508354485034943,
      "learning_rate": 0.00035315490364099596,
      "loss": 1.3679,
      "step": 23000
    },
    {
      "epoch": 73.98872785829307,
      "grad_norm": 0.2665833532810211,
      "learning_rate": 0.0003530383339470339,
      "loss": 1.3581,
      "step": 23010
    },
    {
      "epoch": 74.0,
      "eval_loss": 0.6404687166213989,
      "eval_runtime": 7.0548,
      "eval_samples_per_second": 3444.896,
      "eval_steps_per_second": 13.466,
      "step": 23014
    },
    {
      "epoch": 74.01932367149759,
      "grad_norm": 0.18457801640033722,
      "learning_rate": 0.000352921737260467,
      "loss": 1.2888,
      "step": 23020
    },
    {
      "epoch": 74.05152979066023,
      "grad_norm": 0.21331050992012024,
      "learning_rate": 0.0003528051136118399,
      "loss": 1.3594,
      "step": 23030
    },
    {
      "epoch": 74.08373590982286,
      "grad_norm": 0.2779948115348816,
      "learning_rate": 0.000352688463031704,
      "loss": 1.3471,
      "step": 23040
    },
    {
      "epoch": 74.1159420289855,
      "grad_norm": 0.19572295248508453,
      "learning_rate": 0.00035257178555061776,
      "loss": 1.3436,
      "step": 23050
    },
    {
      "epoch": 74.14814814814815,
      "grad_norm": 0.22188043594360352,
      "learning_rate": 0.00035245508119914685,
      "loss": 1.3713,
      "step": 23060
    },
    {
      "epoch": 74.18035426731079,
      "grad_norm": 0.3013221025466919,
      "learning_rate": 0.00035233835000786405,
      "loss": 1.379,
      "step": 23070
    },
    {
      "epoch": 74.21256038647343,
      "grad_norm": 0.21431410312652588,
      "learning_rate": 0.0003522215920073488,
      "loss": 1.3513,
      "step": 23080
    },
    {
      "epoch": 74.24476650563606,
      "grad_norm": 0.2110431045293808,
      "learning_rate": 0.000352104807228188,
      "loss": 1.3568,
      "step": 23090
    },
    {
      "epoch": 74.27697262479872,
      "grad_norm": 0.2171594798564911,
      "learning_rate": 0.0003519879957009753,
      "loss": 1.3555,
      "step": 23100
    },
    {
      "epoch": 74.30917874396135,
      "grad_norm": 0.25044432282447815,
      "learning_rate": 0.0003518711574563113,
      "loss": 1.3507,
      "step": 23110
    },
    {
      "epoch": 74.34138486312399,
      "grad_norm": 0.2627415359020233,
      "learning_rate": 0.00035175429252480393,
      "loss": 1.3668,
      "step": 23120
    },
    {
      "epoch": 74.37359098228663,
      "grad_norm": 0.21540363132953644,
      "learning_rate": 0.00035163740093706775,
      "loss": 1.3699,
      "step": 23130
    },
    {
      "epoch": 74.40579710144928,
      "grad_norm": 0.26693782210350037,
      "learning_rate": 0.00035152048272372457,
      "loss": 1.345,
      "step": 23140
    },
    {
      "epoch": 74.43800322061192,
      "grad_norm": 0.33167263865470886,
      "learning_rate": 0.0003514035379154029,
      "loss": 1.3598,
      "step": 23150
    },
    {
      "epoch": 74.47020933977456,
      "grad_norm": 0.18525467813014984,
      "learning_rate": 0.00035128656654273853,
      "loss": 1.3381,
      "step": 23160
    },
    {
      "epoch": 74.5024154589372,
      "grad_norm": 0.2290841042995453,
      "learning_rate": 0.000351169568636374,
      "loss": 1.3649,
      "step": 23170
    },
    {
      "epoch": 74.53462157809984,
      "grad_norm": 0.3991239070892334,
      "learning_rate": 0.0003510525442269589,
      "loss": 1.3652,
      "step": 23180
    },
    {
      "epoch": 74.56682769726248,
      "grad_norm": 0.2571495771408081,
      "learning_rate": 0.0003509354933451496,
      "loss": 1.3903,
      "step": 23190
    },
    {
      "epoch": 74.59903381642512,
      "grad_norm": 0.1991337388753891,
      "learning_rate": 0.00035081841602160955,
      "loss": 1.3661,
      "step": 23200
    },
    {
      "epoch": 74.63123993558776,
      "grad_norm": 0.17994002997875214,
      "learning_rate": 0.00035070131228700927,
      "loss": 1.3738,
      "step": 23210
    },
    {
      "epoch": 74.66344605475041,
      "grad_norm": 0.2321133017539978,
      "learning_rate": 0.0003505841821720258,
      "loss": 1.3782,
      "step": 23220
    },
    {
      "epoch": 74.69565217391305,
      "grad_norm": 0.20987512171268463,
      "learning_rate": 0.0003504670257073435,
      "loss": 1.3601,
      "step": 23230
    },
    {
      "epoch": 74.72785829307568,
      "grad_norm": 0.21839076280593872,
      "learning_rate": 0.0003503498429236534,
      "loss": 1.3654,
      "step": 23240
    },
    {
      "epoch": 74.76006441223832,
      "grad_norm": 0.19059816002845764,
      "learning_rate": 0.0003502326338516534,
      "loss": 1.3702,
      "step": 23250
    },
    {
      "epoch": 74.79227053140096,
      "grad_norm": 0.255028635263443,
      "learning_rate": 0.00035011539852204844,
      "loss": 1.3802,
      "step": 23260
    },
    {
      "epoch": 74.82447665056361,
      "grad_norm": 0.18808545172214508,
      "learning_rate": 0.0003499981369655504,
      "loss": 1.3585,
      "step": 23270
    },
    {
      "epoch": 74.85668276972625,
      "grad_norm": 0.22126734256744385,
      "learning_rate": 0.0003498808492128776,
      "loss": 1.3535,
      "step": 23280
    },
    {
      "epoch": 74.88888888888889,
      "grad_norm": 0.17663539946079254,
      "learning_rate": 0.00034976353529475563,
      "loss": 1.3594,
      "step": 23290
    },
    {
      "epoch": 74.92109500805152,
      "grad_norm": 0.19804562628269196,
      "learning_rate": 0.000349646195241917,
      "loss": 1.3681,
      "step": 23300
    },
    {
      "epoch": 74.95330112721417,
      "grad_norm": 0.19707834720611572,
      "learning_rate": 0.00034952882908510064,
      "loss": 1.363,
      "step": 23310
    },
    {
      "epoch": 74.98550724637681,
      "grad_norm": 0.19158193469047546,
      "learning_rate": 0.00034941143685505267,
      "loss": 1.351,
      "step": 23320
    },
    {
      "epoch": 75.0,
      "eval_loss": 0.6413511633872986,
      "eval_runtime": 7.2383,
      "eval_samples_per_second": 3357.576,
      "eval_steps_per_second": 13.125,
      "step": 23325
    },
    {
      "epoch": 75.01610305958133,
      "grad_norm": 0.21345680952072144,
      "learning_rate": 0.000349294018582526,
      "loss": 1.3056,
      "step": 23330
    },
    {
      "epoch": 75.04830917874396,
      "grad_norm": 0.27716320753097534,
      "learning_rate": 0.0003491765742982802,
      "loss": 1.3467,
      "step": 23340
    },
    {
      "epoch": 75.0805152979066,
      "grad_norm": 0.2265530377626419,
      "learning_rate": 0.0003490591040330817,
      "loss": 1.3725,
      "step": 23350
    },
    {
      "epoch": 75.11272141706924,
      "grad_norm": 0.2218528836965561,
      "learning_rate": 0.000348941607817704,
      "loss": 1.3507,
      "step": 23360
    },
    {
      "epoch": 75.14492753623189,
      "grad_norm": 0.20017842948436737,
      "learning_rate": 0.0003488240856829271,
      "loss": 1.3736,
      "step": 23370
    },
    {
      "epoch": 75.17713365539453,
      "grad_norm": 0.20649603009223938,
      "learning_rate": 0.0003487065376595377,
      "loss": 1.3839,
      "step": 23380
    },
    {
      "epoch": 75.20933977455717,
      "grad_norm": 0.2817552089691162,
      "learning_rate": 0.00034858896377832965,
      "loss": 1.3734,
      "step": 23390
    },
    {
      "epoch": 75.2415458937198,
      "grad_norm": 0.22036950290203094,
      "learning_rate": 0.0003484713640701034,
      "loss": 1.3536,
      "step": 23400
    },
    {
      "epoch": 75.27375201288245,
      "grad_norm": 0.4000481963157654,
      "learning_rate": 0.000348353738565666,
      "loss": 1.3665,
      "step": 23410
    },
    {
      "epoch": 75.30595813204509,
      "grad_norm": 0.23499396443367004,
      "learning_rate": 0.0003482360872958315,
      "loss": 1.3389,
      "step": 23420
    },
    {
      "epoch": 75.33816425120773,
      "grad_norm": 0.2249390035867691,
      "learning_rate": 0.00034811841029142065,
      "loss": 1.3844,
      "step": 23430
    },
    {
      "epoch": 75.37037037037037,
      "grad_norm": 0.18008475005626678,
      "learning_rate": 0.0003480007075832608,
      "loss": 1.38,
      "step": 23440
    },
    {
      "epoch": 75.402576489533,
      "grad_norm": 0.2124369889497757,
      "learning_rate": 0.0003478829792021862,
      "loss": 1.3684,
      "step": 23450
    },
    {
      "epoch": 75.43478260869566,
      "grad_norm": 0.19218182563781738,
      "learning_rate": 0.0003477652251790377,
      "loss": 1.3445,
      "step": 23460
    },
    {
      "epoch": 75.4669887278583,
      "grad_norm": 0.18457700312137604,
      "learning_rate": 0.000347647445544663,
      "loss": 1.352,
      "step": 23470
    },
    {
      "epoch": 75.49919484702093,
      "grad_norm": 0.20239219069480896,
      "learning_rate": 0.00034752964032991633,
      "loss": 1.3949,
      "step": 23480
    },
    {
      "epoch": 75.53140096618357,
      "grad_norm": 0.21535822749137878,
      "learning_rate": 0.00034741180956565887,
      "loss": 1.3627,
      "step": 23490
    },
    {
      "epoch": 75.56360708534622,
      "grad_norm": 0.178694486618042,
      "learning_rate": 0.0003472939532827582,
      "loss": 1.3531,
      "step": 23500
    },
    {
      "epoch": 75.59581320450886,
      "grad_norm": 0.2944899797439575,
      "learning_rate": 0.0003471760715120888,
      "loss": 1.3708,
      "step": 23510
    },
    {
      "epoch": 75.6280193236715,
      "grad_norm": 0.20710547268390656,
      "learning_rate": 0.00034705816428453175,
      "loss": 1.3723,
      "step": 23520
    },
    {
      "epoch": 75.66022544283413,
      "grad_norm": 0.19610874354839325,
      "learning_rate": 0.00034694023163097477,
      "loss": 1.3741,
      "step": 23530
    },
    {
      "epoch": 75.69243156199678,
      "grad_norm": 0.21984511613845825,
      "learning_rate": 0.00034682227358231245,
      "loss": 1.3533,
      "step": 23540
    },
    {
      "epoch": 75.72463768115942,
      "grad_norm": 0.21572110056877136,
      "learning_rate": 0.00034670429016944563,
      "loss": 1.3631,
      "step": 23550
    },
    {
      "epoch": 75.75684380032206,
      "grad_norm": 0.23368652164936066,
      "learning_rate": 0.00034658628142328216,
      "loss": 1.3463,
      "step": 23560
    },
    {
      "epoch": 75.7890499194847,
      "grad_norm": 0.20400087535381317,
      "learning_rate": 0.0003464682473747364,
      "loss": 1.36,
      "step": 23570
    },
    {
      "epoch": 75.82125603864735,
      "grad_norm": 0.2737446427345276,
      "learning_rate": 0.0003463501880547293,
      "loss": 1.3501,
      "step": 23580
    },
    {
      "epoch": 75.85346215780999,
      "grad_norm": 0.21208937466144562,
      "learning_rate": 0.00034623210349418835,
      "loss": 1.3546,
      "step": 23590
    },
    {
      "epoch": 75.88566827697262,
      "grad_norm": 0.20304320752620697,
      "learning_rate": 0.0003461139937240479,
      "loss": 1.3663,
      "step": 23600
    },
    {
      "epoch": 75.91787439613526,
      "grad_norm": 0.21433071792125702,
      "learning_rate": 0.00034599585877524887,
      "loss": 1.348,
      "step": 23610
    },
    {
      "epoch": 75.95008051529791,
      "grad_norm": 0.2021053433418274,
      "learning_rate": 0.0003458776986787384,
      "loss": 1.3481,
      "step": 23620
    },
    {
      "epoch": 75.98228663446055,
      "grad_norm": 0.21881824731826782,
      "learning_rate": 0.0003457595134654707,
      "loss": 1.3681,
      "step": 23630
    },
    {
      "epoch": 76.0,
      "eval_loss": 0.641210675239563,
      "eval_runtime": 7.2483,
      "eval_samples_per_second": 3352.918,
      "eval_steps_per_second": 13.106,
      "step": 23636
    },
    {
      "epoch": 76.01288244766505,
      "grad_norm": 0.17773650586605072,
      "learning_rate": 0.00034564130316640636,
      "loss": 1.3182,
      "step": 23640
    },
    {
      "epoch": 76.0450885668277,
      "grad_norm": 0.19743521511554718,
      "learning_rate": 0.0003455230678125123,
      "loss": 1.3398,
      "step": 23650
    },
    {
      "epoch": 76.07729468599034,
      "grad_norm": 0.17357496917247772,
      "learning_rate": 0.00034540480743476255,
      "loss": 1.3495,
      "step": 23660
    },
    {
      "epoch": 76.10950080515298,
      "grad_norm": 0.31892573833465576,
      "learning_rate": 0.00034528652206413713,
      "loss": 1.3577,
      "step": 23670
    },
    {
      "epoch": 76.14170692431561,
      "grad_norm": 0.22088570892810822,
      "learning_rate": 0.000345168211731623,
      "loss": 1.3701,
      "step": 23680
    },
    {
      "epoch": 76.17391304347827,
      "grad_norm": 0.2131596952676773,
      "learning_rate": 0.00034504987646821343,
      "loss": 1.3498,
      "step": 23690
    },
    {
      "epoch": 76.2061191626409,
      "grad_norm": 0.2075592577457428,
      "learning_rate": 0.0003449315163049084,
      "loss": 1.3579,
      "step": 23700
    },
    {
      "epoch": 76.23832528180354,
      "grad_norm": 0.22036437690258026,
      "learning_rate": 0.0003448131312727143,
      "loss": 1.3339,
      "step": 23710
    },
    {
      "epoch": 76.27053140096618,
      "grad_norm": 0.19627133011817932,
      "learning_rate": 0.000344694721402644,
      "loss": 1.3591,
      "step": 23720
    },
    {
      "epoch": 76.30273752012883,
      "grad_norm": 0.2615688443183899,
      "learning_rate": 0.000344576286725717,
      "loss": 1.3766,
      "step": 23730
    },
    {
      "epoch": 76.33494363929147,
      "grad_norm": 0.1742030829191208,
      "learning_rate": 0.00034445782727295923,
      "loss": 1.3609,
      "step": 23740
    },
    {
      "epoch": 76.3671497584541,
      "grad_norm": 0.1772538423538208,
      "learning_rate": 0.00034433934307540303,
      "loss": 1.3588,
      "step": 23750
    },
    {
      "epoch": 76.39935587761674,
      "grad_norm": 0.2205907702445984,
      "learning_rate": 0.00034422083416408737,
      "loss": 1.3725,
      "step": 23760
    },
    {
      "epoch": 76.4315619967794,
      "grad_norm": 0.18867076933383942,
      "learning_rate": 0.00034410230057005766,
      "loss": 1.3688,
      "step": 23770
    },
    {
      "epoch": 76.46376811594203,
      "grad_norm": 0.24811702966690063,
      "learning_rate": 0.0003439837423243657,
      "loss": 1.3789,
      "step": 23780
    },
    {
      "epoch": 76.49597423510467,
      "grad_norm": 0.20031684637069702,
      "learning_rate": 0.0003438651594580698,
      "loss": 1.3644,
      "step": 23790
    },
    {
      "epoch": 76.5281803542673,
      "grad_norm": 0.19100959599018097,
      "learning_rate": 0.00034374655200223464,
      "loss": 1.3629,
      "step": 23800
    },
    {
      "epoch": 76.56038647342996,
      "grad_norm": 0.21459800004959106,
      "learning_rate": 0.00034362791998793164,
      "loss": 1.3599,
      "step": 23810
    },
    {
      "epoch": 76.5925925925926,
      "grad_norm": 0.19798651337623596,
      "learning_rate": 0.00034350926344623817,
      "loss": 1.3456,
      "step": 23820
    },
    {
      "epoch": 76.62479871175523,
      "grad_norm": 0.2041277140378952,
      "learning_rate": 0.0003433905824082384,
      "loss": 1.3695,
      "step": 23830
    },
    {
      "epoch": 76.65700483091787,
      "grad_norm": 0.18031629920005798,
      "learning_rate": 0.0003432718769050228,
      "loss": 1.354,
      "step": 23840
    },
    {
      "epoch": 76.68921095008052,
      "grad_norm": 0.1956900954246521,
      "learning_rate": 0.00034315314696768836,
      "loss": 1.3692,
      "step": 23850
    },
    {
      "epoch": 76.72141706924316,
      "grad_norm": 0.19307465851306915,
      "learning_rate": 0.0003430343926273381,
      "loss": 1.3639,
      "step": 23860
    },
    {
      "epoch": 76.7536231884058,
      "grad_norm": 0.18000665307044983,
      "learning_rate": 0.00034291561391508186,
      "loss": 1.3615,
      "step": 23870
    },
    {
      "epoch": 76.78582930756843,
      "grad_norm": 0.20763011276721954,
      "learning_rate": 0.0003427968108620358,
      "loss": 1.3627,
      "step": 23880
    },
    {
      "epoch": 76.81803542673107,
      "grad_norm": 0.24974186718463898,
      "learning_rate": 0.00034267798349932213,
      "loss": 1.3575,
      "step": 23890
    },
    {
      "epoch": 76.85024154589372,
      "grad_norm": 0.22660210728645325,
      "learning_rate": 0.00034255913185806975,
      "loss": 1.3636,
      "step": 23900
    },
    {
      "epoch": 76.88244766505636,
      "grad_norm": 0.1957845389842987,
      "learning_rate": 0.00034244025596941386,
      "loss": 1.3526,
      "step": 23910
    },
    {
      "epoch": 76.914653784219,
      "grad_norm": 0.16847513616085052,
      "learning_rate": 0.00034232135586449594,
      "loss": 1.3664,
      "step": 23920
    },
    {
      "epoch": 76.94685990338164,
      "grad_norm": 0.19766518473625183,
      "learning_rate": 0.00034220243157446383,
      "loss": 1.3532,
      "step": 23930
    },
    {
      "epoch": 76.97906602254429,
      "grad_norm": 0.2296469360589981,
      "learning_rate": 0.00034208348313047185,
      "loss": 1.3701,
      "step": 23940
    },
    {
      "epoch": 77.0,
      "eval_loss": 0.6394674777984619,
      "eval_runtime": 7.0956,
      "eval_samples_per_second": 3425.097,
      "eval_steps_per_second": 13.389,
      "step": 23947
    },
    {
      "epoch": 77.00966183574879,
      "grad_norm": 0.1999955028295517,
      "learning_rate": 0.00034196451056368036,
      "loss": 1.3072,
      "step": 23950
    },
    {
      "epoch": 77.04186795491144,
      "grad_norm": 0.2365119904279709,
      "learning_rate": 0.0003418455139052562,
      "loss": 1.3538,
      "step": 23960
    },
    {
      "epoch": 77.07407407407408,
      "grad_norm": 0.23046821355819702,
      "learning_rate": 0.00034172649318637264,
      "loss": 1.3457,
      "step": 23970
    },
    {
      "epoch": 77.10628019323671,
      "grad_norm": 0.20644763112068176,
      "learning_rate": 0.0003416074484382091,
      "loss": 1.3453,
      "step": 23980
    },
    {
      "epoch": 77.13848631239935,
      "grad_norm": 0.2710960805416107,
      "learning_rate": 0.00034148837969195136,
      "loss": 1.3444,
      "step": 23990
    },
    {
      "epoch": 77.170692431562,
      "grad_norm": 0.19475053250789642,
      "learning_rate": 0.0003413692869787913,
      "loss": 1.3619,
      "step": 24000
    },
    {
      "epoch": 77.20289855072464,
      "grad_norm": 0.18242524564266205,
      "learning_rate": 0.00034125017032992744,
      "loss": 1.3569,
      "step": 24010
    },
    {
      "epoch": 77.23510466988728,
      "grad_norm": 0.25229233503341675,
      "learning_rate": 0.0003411310297765643,
      "loss": 1.3634,
      "step": 24020
    },
    {
      "epoch": 77.26731078904992,
      "grad_norm": 0.3753925561904907,
      "learning_rate": 0.00034101186534991266,
      "loss": 1.3566,
      "step": 24030
    },
    {
      "epoch": 77.29951690821257,
      "grad_norm": 0.19929374754428864,
      "learning_rate": 0.00034089267708118965,
      "loss": 1.3507,
      "step": 24040
    },
    {
      "epoch": 77.3317230273752,
      "grad_norm": 0.22909443080425262,
      "learning_rate": 0.00034077346500161864,
      "loss": 1.3588,
      "step": 24050
    },
    {
      "epoch": 77.36392914653784,
      "grad_norm": 0.19489513337612152,
      "learning_rate": 0.0003406542291424293,
      "loss": 1.3532,
      "step": 24060
    },
    {
      "epoch": 77.39613526570048,
      "grad_norm": 0.25301602482795715,
      "learning_rate": 0.0003405349695348572,
      "loss": 1.3844,
      "step": 24070
    },
    {
      "epoch": 77.42834138486312,
      "grad_norm": 0.27241843938827515,
      "learning_rate": 0.0003404156862101447,
      "loss": 1.3464,
      "step": 24080
    },
    {
      "epoch": 77.46054750402577,
      "grad_norm": 0.23960623145103455,
      "learning_rate": 0.0003402963791995398,
      "loss": 1.3412,
      "step": 24090
    },
    {
      "epoch": 77.4927536231884,
      "grad_norm": 0.24248868227005005,
      "learning_rate": 0.000340177048534297,
      "loss": 1.3689,
      "step": 24100
    },
    {
      "epoch": 77.52495974235104,
      "grad_norm": 0.23973789811134338,
      "learning_rate": 0.00034005769424567706,
      "loss": 1.3729,
      "step": 24110
    },
    {
      "epoch": 77.55716586151368,
      "grad_norm": 0.23370859026908875,
      "learning_rate": 0.0003399383163649468,
      "loss": 1.3555,
      "step": 24120
    },
    {
      "epoch": 77.58937198067633,
      "grad_norm": 0.21967194974422455,
      "learning_rate": 0.0003398189149233791,
      "loss": 1.3764,
      "step": 24130
    },
    {
      "epoch": 77.62157809983897,
      "grad_norm": 0.3332442343235016,
      "learning_rate": 0.0003396994899522533,
      "loss": 1.3625,
      "step": 24140
    },
    {
      "epoch": 77.65378421900161,
      "grad_norm": 0.22002288699150085,
      "learning_rate": 0.0003395800414828548,
      "loss": 1.3884,
      "step": 24150
    },
    {
      "epoch": 77.68599033816425,
      "grad_norm": 0.19618408381938934,
      "learning_rate": 0.0003394605695464748,
      "loss": 1.3424,
      "step": 24160
    },
    {
      "epoch": 77.7181964573269,
      "grad_norm": 0.18905635178089142,
      "learning_rate": 0.0003393410741744113,
      "loss": 1.3716,
      "step": 24170
    },
    {
      "epoch": 77.75040257648953,
      "grad_norm": 0.1830960214138031,
      "learning_rate": 0.00033922155539796797,
      "loss": 1.3577,
      "step": 24180
    },
    {
      "epoch": 77.78260869565217,
      "grad_norm": 0.17408955097198486,
      "learning_rate": 0.0003391020132484547,
      "loss": 1.353,
      "step": 24190
    },
    {
      "epoch": 77.81481481481481,
      "grad_norm": 0.2027273178100586,
      "learning_rate": 0.00033898244775718765,
      "loss": 1.3671,
      "step": 24200
    },
    {
      "epoch": 77.84702093397746,
      "grad_norm": 0.18541808426380157,
      "learning_rate": 0.000338862858955489,
      "loss": 1.3422,
      "step": 24210
    },
    {
      "epoch": 77.8792270531401,
      "grad_norm": 0.17823173105716705,
      "learning_rate": 0.00033874324687468684,
      "loss": 1.3681,
      "step": 24220
    },
    {
      "epoch": 77.91143317230274,
      "grad_norm": 0.20232447981834412,
      "learning_rate": 0.00033862361154611564,
      "loss": 1.3508,
      "step": 24230
    },
    {
      "epoch": 77.94363929146537,
      "grad_norm": 0.19196727871894836,
      "learning_rate": 0.000338503953001116,
      "loss": 1.3818,
      "step": 24240
    },
    {
      "epoch": 77.97584541062803,
      "grad_norm": 0.19342531263828278,
      "learning_rate": 0.0003383842712710343,
      "loss": 1.3493,
      "step": 24250
    },
    {
      "epoch": 78.0,
      "eval_loss": 0.6411289572715759,
      "eval_runtime": 7.0737,
      "eval_samples_per_second": 3435.664,
      "eval_steps_per_second": 13.43,
      "step": 24258
    },
    {
      "epoch": 78.00644122383252,
      "grad_norm": 0.21663494408130646,
      "learning_rate": 0.00033826456638722316,
      "loss": 1.3119,
      "step": 24260
    },
    {
      "epoch": 78.03864734299516,
      "grad_norm": 0.2283150553703308,
      "learning_rate": 0.0003381448383810413,
      "loss": 1.3672,
      "step": 24270
    },
    {
      "epoch": 78.07085346215781,
      "grad_norm": 0.22057905793190002,
      "learning_rate": 0.00033802508728385353,
      "loss": 1.3256,
      "step": 24280
    },
    {
      "epoch": 78.10305958132045,
      "grad_norm": 0.21802939474582672,
      "learning_rate": 0.00033790531312703054,
      "loss": 1.3717,
      "step": 24290
    },
    {
      "epoch": 78.13526570048309,
      "grad_norm": 0.2152627557516098,
      "learning_rate": 0.00033778551594194916,
      "loss": 1.3459,
      "step": 24300
    },
    {
      "epoch": 78.16747181964573,
      "grad_norm": 0.19483281672000885,
      "learning_rate": 0.0003376656957599924,
      "loss": 1.3594,
      "step": 24310
    },
    {
      "epoch": 78.19967793880838,
      "grad_norm": 0.22516094148159027,
      "learning_rate": 0.00033754585261254905,
      "loss": 1.3708,
      "step": 24320
    },
    {
      "epoch": 78.23188405797102,
      "grad_norm": 0.3314296305179596,
      "learning_rate": 0.000337425986531014,
      "loss": 1.3659,
      "step": 24330
    },
    {
      "epoch": 78.26409017713365,
      "grad_norm": 0.19756673276424408,
      "learning_rate": 0.0003373060975467881,
      "loss": 1.3541,
      "step": 24340
    },
    {
      "epoch": 78.29629629629629,
      "grad_norm": 0.2162230908870697,
      "learning_rate": 0.0003371861856912784,
      "loss": 1.3633,
      "step": 24350
    },
    {
      "epoch": 78.32850241545894,
      "grad_norm": 0.2540818750858307,
      "learning_rate": 0.0003370662509958977,
      "loss": 1.3527,
      "step": 24360
    },
    {
      "epoch": 78.36070853462158,
      "grad_norm": 0.21747608482837677,
      "learning_rate": 0.00033694629349206504,
      "loss": 1.3727,
      "step": 24370
    },
    {
      "epoch": 78.39291465378422,
      "grad_norm": 0.23945556581020355,
      "learning_rate": 0.00033682631321120505,
      "loss": 1.3464,
      "step": 24380
    },
    {
      "epoch": 78.42512077294685,
      "grad_norm": 0.1738324761390686,
      "learning_rate": 0.00033670631018474875,
      "loss": 1.368,
      "step": 24390
    },
    {
      "epoch": 78.4573268921095,
      "grad_norm": 0.1913738250732422,
      "learning_rate": 0.00033658628444413284,
      "loss": 1.3567,
      "step": 24400
    },
    {
      "epoch": 78.48953301127214,
      "grad_norm": 0.18229812383651733,
      "learning_rate": 0.0003364662360208001,
      "loss": 1.3367,
      "step": 24410
    },
    {
      "epoch": 78.52173913043478,
      "grad_norm": 0.20397977530956268,
      "learning_rate": 0.0003363461649461992,
      "loss": 1.3683,
      "step": 24420
    },
    {
      "epoch": 78.55394524959742,
      "grad_norm": 0.24319657683372498,
      "learning_rate": 0.0003362260712517847,
      "loss": 1.3342,
      "step": 24430
    },
    {
      "epoch": 78.58615136876007,
      "grad_norm": 0.25147029757499695,
      "learning_rate": 0.00033610595496901723,
      "loss": 1.324,
      "step": 24440
    },
    {
      "epoch": 78.61835748792271,
      "grad_norm": 0.27612870931625366,
      "learning_rate": 0.00033598581612936316,
      "loss": 1.3735,
      "step": 24450
    },
    {
      "epoch": 78.65056360708535,
      "grad_norm": 0.20312725007534027,
      "learning_rate": 0.000335865654764295,
      "loss": 1.3662,
      "step": 24460
    },
    {
      "epoch": 78.68276972624798,
      "grad_norm": 0.24003863334655762,
      "learning_rate": 0.00033574547090529076,
      "loss": 1.3645,
      "step": 24470
    },
    {
      "epoch": 78.71497584541063,
      "grad_norm": 0.1806136816740036,
      "learning_rate": 0.0003356252645838348,
      "loss": 1.3755,
      "step": 24480
    },
    {
      "epoch": 78.74718196457327,
      "grad_norm": 0.2987843453884125,
      "learning_rate": 0.0003355050358314172,
      "loss": 1.3618,
      "step": 24490
    },
    {
      "epoch": 78.77938808373591,
      "grad_norm": 0.27600663900375366,
      "learning_rate": 0.00033538478467953374,
      "loss": 1.364,
      "step": 24500
    },
    {
      "epoch": 78.81159420289855,
      "grad_norm": 0.20779211819171906,
      "learning_rate": 0.00033526451115968624,
      "loss": 1.3731,
      "step": 24510
    },
    {
      "epoch": 78.84380032206118,
      "grad_norm": 0.2210620790719986,
      "learning_rate": 0.0003351442153033825,
      "loss": 1.3493,
      "step": 24520
    },
    {
      "epoch": 78.87600644122384,
      "grad_norm": 0.2108900249004364,
      "learning_rate": 0.0003350238971421358,
      "loss": 1.359,
      "step": 24530
    },
    {
      "epoch": 78.90821256038647,
      "grad_norm": 0.24802222847938538,
      "learning_rate": 0.0003349035567074656,
      "loss": 1.3453,
      "step": 24540
    },
    {
      "epoch": 78.94041867954911,
      "grad_norm": 0.18423759937286377,
      "learning_rate": 0.00033478319403089704,
      "loss": 1.375,
      "step": 24550
    },
    {
      "epoch": 78.97262479871175,
      "grad_norm": 0.2632327377796173,
      "learning_rate": 0.0003346628091439612,
      "loss": 1.3589,
      "step": 24560
    },
    {
      "epoch": 79.0,
      "eval_loss": 0.6434610486030579,
      "eval_runtime": 7.0789,
      "eval_samples_per_second": 3433.169,
      "eval_steps_per_second": 13.42,
      "step": 24569
    },
    {
      "epoch": 79.00322061191626,
      "grad_norm": 0.2058020532131195,
      "learning_rate": 0.00033454240207819475,
      "loss": 1.2861,
      "step": 24570
    },
    {
      "epoch": 79.0354267310789,
      "grad_norm": 0.25767168402671814,
      "learning_rate": 0.00033442197286514055,
      "loss": 1.3547,
      "step": 24580
    },
    {
      "epoch": 79.06763285024155,
      "grad_norm": 0.23233571648597717,
      "learning_rate": 0.00033430152153634683,
      "loss": 1.3656,
      "step": 24590
    },
    {
      "epoch": 79.09983896940419,
      "grad_norm": 0.18844687938690186,
      "learning_rate": 0.0003341810481233679,
      "loss": 1.3375,
      "step": 24600
    },
    {
      "epoch": 79.13204508856683,
      "grad_norm": 0.2328719198703766,
      "learning_rate": 0.0003340605526577637,
      "loss": 1.3557,
      "step": 24610
    },
    {
      "epoch": 79.16425120772946,
      "grad_norm": 0.21921122074127197,
      "learning_rate": 0.00033394003517110015,
      "loss": 1.356,
      "step": 24620
    },
    {
      "epoch": 79.19645732689212,
      "grad_norm": 0.21237696707248688,
      "learning_rate": 0.00033381949569494875,
      "loss": 1.3589,
      "step": 24630
    },
    {
      "epoch": 79.22866344605475,
      "grad_norm": 0.20971991121768951,
      "learning_rate": 0.0003336989342608868,
      "loss": 1.3735,
      "step": 24640
    },
    {
      "epoch": 79.26086956521739,
      "grad_norm": 0.20462577044963837,
      "learning_rate": 0.00033357835090049736,
      "loss": 1.3414,
      "step": 24650
    },
    {
      "epoch": 79.29307568438003,
      "grad_norm": 0.23076710104942322,
      "learning_rate": 0.00033345774564536934,
      "loss": 1.3551,
      "step": 24660
    },
    {
      "epoch": 79.32528180354268,
      "grad_norm": 0.16840922832489014,
      "learning_rate": 0.0003333371185270972,
      "loss": 1.3487,
      "step": 24670
    },
    {
      "epoch": 79.35748792270532,
      "grad_norm": 0.19039902091026306,
      "learning_rate": 0.00033321646957728125,
      "loss": 1.3381,
      "step": 24680
    },
    {
      "epoch": 79.38969404186795,
      "grad_norm": 0.20145931839942932,
      "learning_rate": 0.00033309579882752745,
      "loss": 1.3664,
      "step": 24690
    },
    {
      "epoch": 79.42190016103059,
      "grad_norm": 0.30819937586784363,
      "learning_rate": 0.0003329751063094476,
      "loss": 1.3602,
      "step": 24700
    },
    {
      "epoch": 79.45410628019323,
      "grad_norm": 0.23324288427829742,
      "learning_rate": 0.00033285439205465897,
      "loss": 1.3654,
      "step": 24710
    },
    {
      "epoch": 79.48631239935588,
      "grad_norm": 0.20560845732688904,
      "learning_rate": 0.00033273365609478477,
      "loss": 1.3825,
      "step": 24720
    },
    {
      "epoch": 79.51851851851852,
      "grad_norm": 0.2235013097524643,
      "learning_rate": 0.0003326128984614538,
      "loss": 1.3593,
      "step": 24730
    },
    {
      "epoch": 79.55072463768116,
      "grad_norm": 0.21744400262832642,
      "learning_rate": 0.0003324921191863005,
      "loss": 1.3774,
      "step": 24740
    },
    {
      "epoch": 79.5829307568438,
      "grad_norm": 0.22629112005233765,
      "learning_rate": 0.000332371318300965,
      "loss": 1.3712,
      "step": 24750
    },
    {
      "epoch": 79.61513687600645,
      "grad_norm": 0.2434726506471634,
      "learning_rate": 0.00033225049583709314,
      "loss": 1.3616,
      "step": 24760
    },
    {
      "epoch": 79.64734299516908,
      "grad_norm": 0.2597803771495819,
      "learning_rate": 0.00033212965182633636,
      "loss": 1.3604,
      "step": 24770
    },
    {
      "epoch": 79.67954911433172,
      "grad_norm": 0.2424488216638565,
      "learning_rate": 0.00033200878630035166,
      "loss": 1.361,
      "step": 24780
    },
    {
      "epoch": 79.71175523349436,
      "grad_norm": 0.19926007091999054,
      "learning_rate": 0.00033188789929080193,
      "loss": 1.3605,
      "step": 24790
    },
    {
      "epoch": 79.74396135265701,
      "grad_norm": 0.17686927318572998,
      "learning_rate": 0.00033176699082935546,
      "loss": 1.3473,
      "step": 24800
    },
    {
      "epoch": 79.77616747181965,
      "grad_norm": 0.18778762221336365,
      "learning_rate": 0.00033164606094768614,
      "loss": 1.3445,
      "step": 24810
    },
    {
      "epoch": 79.80837359098228,
      "grad_norm": 0.19512584805488586,
      "learning_rate": 0.00033152510967747375,
      "loss": 1.3612,
      "step": 24820
    },
    {
      "epoch": 79.84057971014492,
      "grad_norm": 0.22756457328796387,
      "learning_rate": 0.0003314041370504034,
      "loss": 1.3889,
      "step": 24830
    },
    {
      "epoch": 79.87278582930757,
      "grad_norm": 0.18292509019374847,
      "learning_rate": 0.0003312831430981658,
      "loss": 1.3485,
      "step": 24840
    },
    {
      "epoch": 79.90499194847021,
      "grad_norm": 0.25745075941085815,
      "learning_rate": 0.00033116212785245743,
      "loss": 1.3597,
      "step": 24850
    },
    {
      "epoch": 79.93719806763285,
      "grad_norm": 0.20579566061496735,
      "learning_rate": 0.00033104109134498026,
      "loss": 1.3492,
      "step": 24860
    },
    {
      "epoch": 79.96940418679549,
      "grad_norm": 0.2121778279542923,
      "learning_rate": 0.00033092003360744165,
      "loss": 1.3186,
      "step": 24870
    },
    {
      "epoch": 80.0,
      "grad_norm": 0.16541382670402527,
      "learning_rate": 0.0003307989546715549,
      "loss": 1.2938,
      "step": 24880
    },
    {
      "epoch": 80.0,
      "eval_loss": 0.6406958103179932,
      "eval_runtime": 7.0531,
      "eval_samples_per_second": 3445.701,
      "eval_steps_per_second": 13.469,
      "step": 24880
    },
    {
      "epoch": 80.03220611916264,
      "grad_norm": 0.23984074592590332,
      "learning_rate": 0.00033067785456903856,
      "loss": 1.3553,
      "step": 24890
    },
    {
      "epoch": 80.06441223832527,
      "grad_norm": 0.20053315162658691,
      "learning_rate": 0.0003305567333316168,
      "loss": 1.3228,
      "step": 24900
    },
    {
      "epoch": 80.09661835748793,
      "grad_norm": 0.2281210869550705,
      "learning_rate": 0.0003304355909910193,
      "loss": 1.3538,
      "step": 24910
    },
    {
      "epoch": 80.12882447665056,
      "grad_norm": 0.23073412477970123,
      "learning_rate": 0.00033031442757898145,
      "loss": 1.3533,
      "step": 24920
    },
    {
      "epoch": 80.1610305958132,
      "grad_norm": 0.22892242670059204,
      "learning_rate": 0.0003301932431272439,
      "loss": 1.3509,
      "step": 24930
    },
    {
      "epoch": 80.19323671497584,
      "grad_norm": 0.17570151388645172,
      "learning_rate": 0.000330072037667553,
      "loss": 1.3672,
      "step": 24940
    },
    {
      "epoch": 80.22544283413849,
      "grad_norm": 0.19501721858978271,
      "learning_rate": 0.00032995081123166043,
      "loss": 1.3521,
      "step": 24950
    },
    {
      "epoch": 80.25764895330113,
      "grad_norm": 0.1980506330728531,
      "learning_rate": 0.0003298295638513236,
      "loss": 1.3526,
      "step": 24960
    },
    {
      "epoch": 80.28985507246377,
      "grad_norm": 0.22001366317272186,
      "learning_rate": 0.0003297082955583052,
      "loss": 1.3548,
      "step": 24970
    },
    {
      "epoch": 80.3220611916264,
      "grad_norm": 0.200129896402359,
      "learning_rate": 0.0003295870063843735,
      "loss": 1.3612,
      "step": 24980
    },
    {
      "epoch": 80.35426731078906,
      "grad_norm": 0.2177777737379074,
      "learning_rate": 0.0003294656963613022,
      "loss": 1.3429,
      "step": 24990
    },
    {
      "epoch": 80.38647342995169,
      "grad_norm": 0.25256988406181335,
      "learning_rate": 0.00032934436552087054,
      "loss": 1.3748,
      "step": 25000
    },
    {
      "epoch": 80.41867954911433,
      "grad_norm": 0.19473163783550262,
      "learning_rate": 0.0003292230138948631,
      "loss": 1.3606,
      "step": 25010
    },
    {
      "epoch": 80.45088566827697,
      "grad_norm": 0.19944080710411072,
      "learning_rate": 0.00032910164151506984,
      "loss": 1.3784,
      "step": 25020
    },
    {
      "epoch": 80.48309178743962,
      "grad_norm": 0.21692070364952087,
      "learning_rate": 0.00032898024841328656,
      "loss": 1.3681,
      "step": 25030
    },
    {
      "epoch": 80.51529790660226,
      "grad_norm": 0.20064370334148407,
      "learning_rate": 0.0003288588346213139,
      "loss": 1.3439,
      "step": 25040
    },
    {
      "epoch": 80.5475040257649,
      "grad_norm": 0.16332067549228668,
      "learning_rate": 0.00032873740017095833,
      "loss": 1.3594,
      "step": 25050
    },
    {
      "epoch": 80.57971014492753,
      "grad_norm": 0.18360953032970428,
      "learning_rate": 0.00032861594509403177,
      "loss": 1.3551,
      "step": 25060
    },
    {
      "epoch": 80.61191626409018,
      "grad_norm": 0.1987047642469406,
      "learning_rate": 0.0003284944694223512,
      "loss": 1.3541,
      "step": 25070
    },
    {
      "epoch": 80.64412238325282,
      "grad_norm": 0.22386004030704498,
      "learning_rate": 0.0003283729731877393,
      "loss": 1.3375,
      "step": 25080
    },
    {
      "epoch": 80.67632850241546,
      "grad_norm": 0.1691986471414566,
      "learning_rate": 0.0003282514564220239,
      "loss": 1.3649,
      "step": 25090
    },
    {
      "epoch": 80.7085346215781,
      "grad_norm": 0.19327914714813232,
      "learning_rate": 0.0003281299191570386,
      "loss": 1.3558,
      "step": 25100
    },
    {
      "epoch": 80.74074074074075,
      "grad_norm": 0.1922934651374817,
      "learning_rate": 0.00032800836142462175,
      "loss": 1.355,
      "step": 25110
    },
    {
      "epoch": 80.77294685990339,
      "grad_norm": 0.19384242594242096,
      "learning_rate": 0.00032788678325661777,
      "loss": 1.3508,
      "step": 25120
    },
    {
      "epoch": 80.80515297906602,
      "grad_norm": 0.22022710740566254,
      "learning_rate": 0.00032776518468487584,
      "loss": 1.3861,
      "step": 25130
    },
    {
      "epoch": 80.83735909822866,
      "grad_norm": 0.20253118872642517,
      "learning_rate": 0.00032764356574125074,
      "loss": 1.3444,
      "step": 25140
    },
    {
      "epoch": 80.8695652173913,
      "grad_norm": 0.4353983700275421,
      "learning_rate": 0.00032752192645760274,
      "loss": 1.3484,
      "step": 25150
    },
    {
      "epoch": 80.90177133655395,
      "grad_norm": 0.21946793794631958,
      "learning_rate": 0.00032740026686579714,
      "loss": 1.3875,
      "step": 25160
    },
    {
      "epoch": 80.93397745571659,
      "grad_norm": 0.2394460290670395,
      "learning_rate": 0.00032727858699770475,
      "loss": 1.3671,
      "step": 25170
    },
    {
      "epoch": 80.96618357487922,
      "grad_norm": 0.23723404109477997,
      "learning_rate": 0.0003271568868852016,
      "loss": 1.3434,
      "step": 25180
    },
    {
      "epoch": 80.99838969404186,
      "grad_norm": 0.2229200303554535,
      "learning_rate": 0.0003270351665601691,
      "loss": 1.3336,
      "step": 25190
    },
    {
      "epoch": 81.0,
      "eval_loss": 0.6421457529067993,
      "eval_runtime": 7.2465,
      "eval_samples_per_second": 3353.752,
      "eval_steps_per_second": 13.11,
      "step": 25191
    },
    {
      "epoch": 81.02898550724638,
      "grad_norm": 0.2298334538936615,
      "learning_rate": 0.0003269134260544938,
      "loss": 1.2706,
      "step": 25200
    },
    {
      "epoch": 81.06119162640901,
      "grad_norm": 0.24475304782390594,
      "learning_rate": 0.00032679166540006783,
      "loss": 1.3446,
      "step": 25210
    },
    {
      "epoch": 81.09339774557166,
      "grad_norm": 0.2039763629436493,
      "learning_rate": 0.00032666988462878827,
      "loss": 1.3488,
      "step": 25220
    },
    {
      "epoch": 81.1256038647343,
      "grad_norm": 0.2332824021577835,
      "learning_rate": 0.0003265480837725577,
      "loss": 1.3843,
      "step": 25230
    },
    {
      "epoch": 81.15780998389694,
      "grad_norm": 0.23448146879673004,
      "learning_rate": 0.0003264262628632838,
      "loss": 1.3674,
      "step": 25240
    },
    {
      "epoch": 81.19001610305958,
      "grad_norm": 0.21276502311229706,
      "learning_rate": 0.00032630442193287967,
      "loss": 1.3612,
      "step": 25250
    },
    {
      "epoch": 81.22222222222223,
      "grad_norm": 0.21173420548439026,
      "learning_rate": 0.00032618256101326346,
      "loss": 1.385,
      "step": 25260
    },
    {
      "epoch": 81.25442834138487,
      "grad_norm": 0.20407871901988983,
      "learning_rate": 0.00032606068013635883,
      "loss": 1.3367,
      "step": 25270
    },
    {
      "epoch": 81.2866344605475,
      "grad_norm": 0.3933996856212616,
      "learning_rate": 0.00032593877933409434,
      "loss": 1.3341,
      "step": 25280
    },
    {
      "epoch": 81.31884057971014,
      "grad_norm": 0.21339990198612213,
      "learning_rate": 0.00032581685863840396,
      "loss": 1.3395,
      "step": 25290
    },
    {
      "epoch": 81.35104669887279,
      "grad_norm": 0.4666999876499176,
      "learning_rate": 0.000325694918081227,
      "loss": 1.3668,
      "step": 25300
    },
    {
      "epoch": 81.38325281803543,
      "grad_norm": 0.2148156613111496,
      "learning_rate": 0.00032557295769450757,
      "loss": 1.3594,
      "step": 25310
    },
    {
      "epoch": 81.41545893719807,
      "grad_norm": 0.18305674195289612,
      "learning_rate": 0.00032545097751019537,
      "loss": 1.3591,
      "step": 25320
    },
    {
      "epoch": 81.4476650563607,
      "grad_norm": 0.22607451677322388,
      "learning_rate": 0.00032532897756024515,
      "loss": 1.38,
      "step": 25330
    },
    {
      "epoch": 81.47987117552334,
      "grad_norm": 0.22694100439548492,
      "learning_rate": 0.00032520695787661687,
      "loss": 1.3452,
      "step": 25340
    },
    {
      "epoch": 81.512077294686,
      "grad_norm": 0.1995806097984314,
      "learning_rate": 0.00032508491849127534,
      "loss": 1.3406,
      "step": 25350
    },
    {
      "epoch": 81.54428341384863,
      "grad_norm": 0.20701821148395538,
      "learning_rate": 0.00032496285943619114,
      "loss": 1.3283,
      "step": 25360
    },
    {
      "epoch": 81.57648953301127,
      "grad_norm": 0.19261996448040009,
      "learning_rate": 0.00032484078074333957,
      "loss": 1.3369,
      "step": 25370
    },
    {
      "epoch": 81.6086956521739,
      "grad_norm": 0.23986200988292694,
      "learning_rate": 0.000324718682444701,
      "loss": 1.3428,
      "step": 25380
    },
    {
      "epoch": 81.64090177133656,
      "grad_norm": 0.24938355386257172,
      "learning_rate": 0.0003245965645722613,
      "loss": 1.3463,
      "step": 25390
    },
    {
      "epoch": 81.6731078904992,
      "grad_norm": 0.18881073594093323,
      "learning_rate": 0.0003244744271580112,
      "loss": 1.3728,
      "step": 25400
    },
    {
      "epoch": 81.70531400966183,
      "grad_norm": 0.2328180968761444,
      "learning_rate": 0.0003243522702339467,
      "loss": 1.3484,
      "step": 25410
    },
    {
      "epoch": 81.73752012882447,
      "grad_norm": 0.24324022233486176,
      "learning_rate": 0.00032423009383206875,
      "loss": 1.3565,
      "step": 25420
    },
    {
      "epoch": 81.76972624798712,
      "grad_norm": 0.2420501559972763,
      "learning_rate": 0.0003241078979843835,
      "loss": 1.3719,
      "step": 25430
    },
    {
      "epoch": 81.80193236714976,
      "grad_norm": 0.2393185794353485,
      "learning_rate": 0.00032398568272290224,
      "loss": 1.3709,
      "step": 25440
    },
    {
      "epoch": 81.8341384863124,
      "grad_norm": 0.20820750296115875,
      "learning_rate": 0.00032386344807964123,
      "loss": 1.361,
      "step": 25450
    },
    {
      "epoch": 81.86634460547504,
      "grad_norm": 0.21111081540584564,
      "learning_rate": 0.00032374119408662194,
      "loss": 1.36,
      "step": 25460
    },
    {
      "epoch": 81.89855072463769,
      "grad_norm": 0.2018134444952011,
      "learning_rate": 0.0003236189207758707,
      "loss": 1.3634,
      "step": 25470
    },
    {
      "epoch": 81.93075684380032,
      "grad_norm": 0.24231582880020142,
      "learning_rate": 0.0003234966281794193,
      "loss": 1.3668,
      "step": 25480
    },
    {
      "epoch": 81.96296296296296,
      "grad_norm": 0.205814391374588,
      "learning_rate": 0.000323374316329304,
      "loss": 1.3318,
      "step": 25490
    },
    {
      "epoch": 81.9951690821256,
      "grad_norm": 0.22353480756282806,
      "learning_rate": 0.0003232519852575666,
      "loss": 1.3649,
      "step": 25500
    },
    {
      "epoch": 82.0,
      "eval_loss": 0.6404650211334229,
      "eval_runtime": 7.0746,
      "eval_samples_per_second": 3435.258,
      "eval_steps_per_second": 13.428,
      "step": 25502
    },
    {
      "epoch": 82.02576489533011,
      "grad_norm": 0.23428578674793243,
      "learning_rate": 0.0003231296349962537,
      "loss": 1.2701,
      "step": 25510
    },
    {
      "epoch": 82.05797101449275,
      "grad_norm": 0.2520260512828827,
      "learning_rate": 0.00032300726557741704,
      "loss": 1.3448,
      "step": 25520
    },
    {
      "epoch": 82.09017713365539,
      "grad_norm": 0.2258690595626831,
      "learning_rate": 0.00032288487703311324,
      "loss": 1.341,
      "step": 25530
    },
    {
      "epoch": 82.12238325281804,
      "grad_norm": 0.21806514263153076,
      "learning_rate": 0.0003227624693954042,
      "loss": 1.3597,
      "step": 25540
    },
    {
      "epoch": 82.15458937198068,
      "grad_norm": 0.22466275095939636,
      "learning_rate": 0.0003226400426963564,
      "loss": 1.3598,
      "step": 25550
    },
    {
      "epoch": 82.18679549114331,
      "grad_norm": 0.20205141603946686,
      "learning_rate": 0.00032251759696804165,
      "loss": 1.3504,
      "step": 25560
    },
    {
      "epoch": 82.21900161030595,
      "grad_norm": 0.20399999618530273,
      "learning_rate": 0.00032239513224253675,
      "loss": 1.3434,
      "step": 25570
    },
    {
      "epoch": 82.2512077294686,
      "grad_norm": 0.2186635285615921,
      "learning_rate": 0.0003222726485519232,
      "loss": 1.3474,
      "step": 25580
    },
    {
      "epoch": 82.28341384863124,
      "grad_norm": 0.17879866063594818,
      "learning_rate": 0.0003221501459282877,
      "loss": 1.3577,
      "step": 25590
    },
    {
      "epoch": 82.31561996779388,
      "grad_norm": 0.22961196303367615,
      "learning_rate": 0.00032202762440372183,
      "loss": 1.367,
      "step": 25600
    },
    {
      "epoch": 82.34782608695652,
      "grad_norm": 0.20957233011722565,
      "learning_rate": 0.0003219050840103222,
      "loss": 1.3643,
      "step": 25610
    },
    {
      "epoch": 82.38003220611917,
      "grad_norm": 0.17979088425636292,
      "learning_rate": 0.00032178252478019033,
      "loss": 1.3423,
      "step": 25620
    },
    {
      "epoch": 82.4122383252818,
      "grad_norm": 0.2619403302669525,
      "learning_rate": 0.0003216599467454325,
      "loss": 1.3685,
      "step": 25630
    },
    {
      "epoch": 82.44444444444444,
      "grad_norm": 0.31827205419540405,
      "learning_rate": 0.0003215373499381602,
      "loss": 1.3496,
      "step": 25640
    },
    {
      "epoch": 82.47665056360708,
      "grad_norm": 0.2673921287059784,
      "learning_rate": 0.0003214147343904897,
      "loss": 1.3623,
      "step": 25650
    },
    {
      "epoch": 82.50885668276973,
      "grad_norm": 0.3546977639198303,
      "learning_rate": 0.0003212921001345421,
      "loss": 1.3521,
      "step": 25660
    },
    {
      "epoch": 82.54106280193237,
      "grad_norm": 0.2384776920080185,
      "learning_rate": 0.00032116944720244353,
      "loss": 1.3362,
      "step": 25670
    },
    {
      "epoch": 82.573268921095,
      "grad_norm": 0.21897335350513458,
      "learning_rate": 0.0003210467756263249,
      "loss": 1.3611,
      "step": 25680
    },
    {
      "epoch": 82.60547504025764,
      "grad_norm": 0.2328691929578781,
      "learning_rate": 0.0003209240854383222,
      "loss": 1.3479,
      "step": 25690
    },
    {
      "epoch": 82.6376811594203,
      "grad_norm": 0.18294252455234528,
      "learning_rate": 0.000320801376670576,
      "loss": 1.3558,
      "step": 25700
    },
    {
      "epoch": 82.66988727858293,
      "grad_norm": 0.19266098737716675,
      "learning_rate": 0.0003206786493552321,
      "loss": 1.3615,
      "step": 25710
    },
    {
      "epoch": 82.70209339774557,
      "grad_norm": 0.18561795353889465,
      "learning_rate": 0.0003205559035244408,
      "loss": 1.3608,
      "step": 25720
    },
    {
      "epoch": 82.73429951690821,
      "grad_norm": 0.21998749673366547,
      "learning_rate": 0.00032043313921035745,
      "loss": 1.3554,
      "step": 25730
    },
    {
      "epoch": 82.76650563607086,
      "grad_norm": 0.2040708214044571,
      "learning_rate": 0.0003203103564451422,
      "loss": 1.3436,
      "step": 25740
    },
    {
      "epoch": 82.7987117552335,
      "grad_norm": 0.2478589564561844,
      "learning_rate": 0.0003201875552609601,
      "loss": 1.3621,
      "step": 25750
    },
    {
      "epoch": 82.83091787439614,
      "grad_norm": 0.19611194729804993,
      "learning_rate": 0.00032006473568998084,
      "loss": 1.3479,
      "step": 25760
    },
    {
      "epoch": 82.86312399355877,
      "grad_norm": 0.30437469482421875,
      "learning_rate": 0.0003199418977643792,
      "loss": 1.3483,
      "step": 25770
    },
    {
      "epoch": 82.89533011272141,
      "grad_norm": 0.21203134953975677,
      "learning_rate": 0.0003198190415163346,
      "loss": 1.3438,
      "step": 25780
    },
    {
      "epoch": 82.92753623188406,
      "grad_norm": 0.1982985883951187,
      "learning_rate": 0.0003196961669780311,
      "loss": 1.3605,
      "step": 25790
    },
    {
      "epoch": 82.9597423510467,
      "grad_norm": 0.20827564597129822,
      "learning_rate": 0.00031957327418165787,
      "loss": 1.375,
      "step": 25800
    },
    {
      "epoch": 82.99194847020934,
      "grad_norm": 0.19632744789123535,
      "learning_rate": 0.0003194503631594088,
      "loss": 1.3604,
      "step": 25810
    },
    {
      "epoch": 83.0,
      "eval_loss": 0.6406853795051575,
      "eval_runtime": 7.0591,
      "eval_samples_per_second": 3442.813,
      "eval_steps_per_second": 13.458,
      "step": 25813
    },
    {
      "epoch": 83.02254428341385,
      "grad_norm": 0.21200963854789734,
      "learning_rate": 0.00031932743394348217,
      "loss": 1.2954,
      "step": 25820
    },
    {
      "epoch": 83.05475040257649,
      "grad_norm": 0.2257174253463745,
      "learning_rate": 0.0003192044865660817,
      "loss": 1.3401,
      "step": 25830
    },
    {
      "epoch": 83.08695652173913,
      "grad_norm": 0.2375604808330536,
      "learning_rate": 0.0003190815210594153,
      "loss": 1.3491,
      "step": 25840
    },
    {
      "epoch": 83.11916264090178,
      "grad_norm": 0.25994548201560974,
      "learning_rate": 0.0003189585374556959,
      "loss": 1.3515,
      "step": 25850
    },
    {
      "epoch": 83.15136876006441,
      "grad_norm": 0.2369852513074875,
      "learning_rate": 0.00031883553578714095,
      "loss": 1.3411,
      "step": 25860
    },
    {
      "epoch": 83.18357487922705,
      "grad_norm": 0.27865174412727356,
      "learning_rate": 0.00031871251608597297,
      "loss": 1.3364,
      "step": 25870
    },
    {
      "epoch": 83.21578099838969,
      "grad_norm": 0.24724805355072021,
      "learning_rate": 0.000318589478384419,
      "loss": 1.3293,
      "step": 25880
    },
    {
      "epoch": 83.24798711755234,
      "grad_norm": 0.24560965597629547,
      "learning_rate": 0.00031846642271471067,
      "loss": 1.3613,
      "step": 25890
    },
    {
      "epoch": 83.28019323671498,
      "grad_norm": 0.19466765224933624,
      "learning_rate": 0.00031834334910908453,
      "loss": 1.358,
      "step": 25900
    },
    {
      "epoch": 83.31239935587762,
      "grad_norm": 0.26872000098228455,
      "learning_rate": 0.0003182202575997818,
      "loss": 1.3762,
      "step": 25910
    },
    {
      "epoch": 83.34460547504025,
      "grad_norm": 0.23179659247398376,
      "learning_rate": 0.00031809714821904835,
      "loss": 1.3606,
      "step": 25920
    },
    {
      "epoch": 83.3768115942029,
      "grad_norm": 0.23637427389621735,
      "learning_rate": 0.0003179740209991346,
      "loss": 1.355,
      "step": 25930
    },
    {
      "epoch": 83.40901771336554,
      "grad_norm": 0.23987340927124023,
      "learning_rate": 0.000317850875972296,
      "loss": 1.3535,
      "step": 25940
    },
    {
      "epoch": 83.44122383252818,
      "grad_norm": 0.2590967118740082,
      "learning_rate": 0.00031772771317079224,
      "loss": 1.3689,
      "step": 25950
    },
    {
      "epoch": 83.47342995169082,
      "grad_norm": 0.1933777928352356,
      "learning_rate": 0.00031760453262688794,
      "loss": 1.3457,
      "step": 25960
    },
    {
      "epoch": 83.50563607085346,
      "grad_norm": 0.21482506394386292,
      "learning_rate": 0.0003174813343728522,
      "loss": 1.3445,
      "step": 25970
    },
    {
      "epoch": 83.53784219001611,
      "grad_norm": 0.23373717069625854,
      "learning_rate": 0.0003173581184409591,
      "loss": 1.3612,
      "step": 25980
    },
    {
      "epoch": 83.57004830917874,
      "grad_norm": 0.2484009563922882,
      "learning_rate": 0.0003172348848634868,
      "loss": 1.3654,
      "step": 25990
    },
    {
      "epoch": 83.60225442834138,
      "grad_norm": 0.17234106361865997,
      "learning_rate": 0.0003171116336727185,
      "loss": 1.3446,
      "step": 26000
    },
    {
      "epoch": 83.63446054750402,
      "grad_norm": 0.2035706788301468,
      "learning_rate": 0.00031698836490094207,
      "loss": 1.3474,
      "step": 26010
    },
    {
      "epoch": 83.66666666666667,
      "grad_norm": 0.2373853325843811,
      "learning_rate": 0.00031686507858044954,
      "loss": 1.3595,
      "step": 26020
    },
    {
      "epoch": 83.69887278582931,
      "grad_norm": 0.2156534492969513,
      "learning_rate": 0.00031674177474353793,
      "loss": 1.3506,
      "step": 26030
    },
    {
      "epoch": 83.73107890499195,
      "grad_norm": 0.19302204251289368,
      "learning_rate": 0.0003166184534225087,
      "loss": 1.3348,
      "step": 26040
    },
    {
      "epoch": 83.76328502415458,
      "grad_norm": 0.27520179748535156,
      "learning_rate": 0.00031649511464966815,
      "loss": 1.3205,
      "step": 26050
    },
    {
      "epoch": 83.79549114331724,
      "grad_norm": 0.21113494038581848,
      "learning_rate": 0.00031637175845732654,
      "loss": 1.3487,
      "step": 26060
    },
    {
      "epoch": 83.82769726247987,
      "grad_norm": 0.19992053508758545,
      "learning_rate": 0.00031624838487779927,
      "loss": 1.3466,
      "step": 26070
    },
    {
      "epoch": 83.85990338164251,
      "grad_norm": 0.2260325849056244,
      "learning_rate": 0.0003161249939434062,
      "loss": 1.3595,
      "step": 26080
    },
    {
      "epoch": 83.89210950080515,
      "grad_norm": 0.20982688665390015,
      "learning_rate": 0.00031600158568647143,
      "loss": 1.3626,
      "step": 26090
    },
    {
      "epoch": 83.9243156199678,
      "grad_norm": 0.2273852527141571,
      "learning_rate": 0.00031587816013932396,
      "loss": 1.3521,
      "step": 26100
    },
    {
      "epoch": 83.95652173913044,
      "grad_norm": 0.21386392414569855,
      "learning_rate": 0.00031575471733429706,
      "loss": 1.3727,
      "step": 26110
    },
    {
      "epoch": 83.98872785829307,
      "grad_norm": 0.20765678584575653,
      "learning_rate": 0.0003156312573037287,
      "loss": 1.3644,
      "step": 26120
    },
    {
      "epoch": 84.0,
      "eval_loss": 0.6395949721336365,
      "eval_runtime": 7.0638,
      "eval_samples_per_second": 3440.495,
      "eval_steps_per_second": 13.449,
      "step": 26124
    },
    {
      "epoch": 84.01932367149759,
      "grad_norm": 0.2012501358985901,
      "learning_rate": 0.00031550778007996127,
      "loss": 1.2782,
      "step": 26130
    },
    {
      "epoch": 84.05152979066023,
      "grad_norm": 0.25822514295578003,
      "learning_rate": 0.0003153842856953417,
      "loss": 1.34,
      "step": 26140
    },
    {
      "epoch": 84.08373590982286,
      "grad_norm": 0.19513648748397827,
      "learning_rate": 0.0003152607741822213,
      "loss": 1.3402,
      "step": 26150
    },
    {
      "epoch": 84.1159420289855,
      "grad_norm": 0.25019320845603943,
      "learning_rate": 0.00031513724557295607,
      "loss": 1.3396,
      "step": 26160
    },
    {
      "epoch": 84.14814814814815,
      "grad_norm": 0.22149530053138733,
      "learning_rate": 0.0003150136998999064,
      "loss": 1.3496,
      "step": 26170
    },
    {
      "epoch": 84.18035426731079,
      "grad_norm": 0.247812420129776,
      "learning_rate": 0.00031489013719543705,
      "loss": 1.3558,
      "step": 26180
    },
    {
      "epoch": 84.21256038647343,
      "grad_norm": 0.22364534437656403,
      "learning_rate": 0.0003147665574919173,
      "loss": 1.3592,
      "step": 26190
    },
    {
      "epoch": 84.24476650563606,
      "grad_norm": 0.3092246651649475,
      "learning_rate": 0.0003146429608217211,
      "loss": 1.3316,
      "step": 26200
    },
    {
      "epoch": 84.27697262479872,
      "grad_norm": 0.21100908517837524,
      "learning_rate": 0.00031451934721722635,
      "loss": 1.3313,
      "step": 26210
    },
    {
      "epoch": 84.30917874396135,
      "grad_norm": 0.2505571246147156,
      "learning_rate": 0.0003143957167108159,
      "loss": 1.3544,
      "step": 26220
    },
    {
      "epoch": 84.34138486312399,
      "grad_norm": 0.23739495873451233,
      "learning_rate": 0.00031427206933487686,
      "loss": 1.3417,
      "step": 26230
    },
    {
      "epoch": 84.37359098228663,
      "grad_norm": 0.4703872799873352,
      "learning_rate": 0.00031414840512180046,
      "loss": 1.3577,
      "step": 26240
    },
    {
      "epoch": 84.40579710144928,
      "grad_norm": 0.19149328768253326,
      "learning_rate": 0.000314024724103983,
      "loss": 1.3573,
      "step": 26250
    },
    {
      "epoch": 84.43800322061192,
      "grad_norm": 0.2382100224494934,
      "learning_rate": 0.0003139010263138244,
      "loss": 1.351,
      "step": 26260
    },
    {
      "epoch": 84.47020933977456,
      "grad_norm": 0.2040639966726303,
      "learning_rate": 0.0003137773117837294,
      "loss": 1.3571,
      "step": 26270
    },
    {
      "epoch": 84.5024154589372,
      "grad_norm": 0.23755036294460297,
      "learning_rate": 0.0003136535805461074,
      "loss": 1.3594,
      "step": 26280
    },
    {
      "epoch": 84.53462157809984,
      "grad_norm": 0.23641371726989746,
      "learning_rate": 0.0003135298326333715,
      "loss": 1.3737,
      "step": 26290
    },
    {
      "epoch": 84.56682769726248,
      "grad_norm": 0.2061881422996521,
      "learning_rate": 0.00031340606807793957,
      "loss": 1.3598,
      "step": 26300
    },
    {
      "epoch": 84.59903381642512,
      "grad_norm": 0.22360847890377045,
      "learning_rate": 0.00031328228691223406,
      "loss": 1.3752,
      "step": 26310
    },
    {
      "epoch": 84.63123993558776,
      "grad_norm": 0.1967061460018158,
      "learning_rate": 0.00031315848916868127,
      "loss": 1.359,
      "step": 26320
    },
    {
      "epoch": 84.66344605475041,
      "grad_norm": 0.18019309639930725,
      "learning_rate": 0.000313034674879712,
      "loss": 1.3653,
      "step": 26330
    },
    {
      "epoch": 84.69565217391305,
      "grad_norm": 0.22878196835517883,
      "learning_rate": 0.0003129108440777617,
      "loss": 1.3618,
      "step": 26340
    },
    {
      "epoch": 84.72785829307568,
      "grad_norm": 0.1847551465034485,
      "learning_rate": 0.00031278699679526976,
      "loss": 1.346,
      "step": 26350
    },
    {
      "epoch": 84.76006441223832,
      "grad_norm": 0.1824943572282791,
      "learning_rate": 0.0003126631330646801,
      "loss": 1.3557,
      "step": 26360
    },
    {
      "epoch": 84.79227053140096,
      "grad_norm": 0.1919170767068863,
      "learning_rate": 0.0003125392529184409,
      "loss": 1.3513,
      "step": 26370
    },
    {
      "epoch": 84.82447665056361,
      "grad_norm": 0.18756309151649475,
      "learning_rate": 0.00031241535638900454,
      "loss": 1.3535,
      "step": 26380
    },
    {
      "epoch": 84.85668276972625,
      "grad_norm": 0.19999782741069794,
      "learning_rate": 0.00031229144350882783,
      "loss": 1.3519,
      "step": 26390
    },
    {
      "epoch": 84.88888888888889,
      "grad_norm": 0.24915166199207306,
      "learning_rate": 0.0003121675143103717,
      "loss": 1.3503,
      "step": 26400
    },
    {
      "epoch": 84.92109500805152,
      "grad_norm": 0.19638915359973907,
      "learning_rate": 0.0003120435688261017,
      "loss": 1.3399,
      "step": 26410
    },
    {
      "epoch": 84.95330112721417,
      "grad_norm": 0.20832666754722595,
      "learning_rate": 0.00031191960708848714,
      "loss": 1.3474,
      "step": 26420
    },
    {
      "epoch": 84.98550724637681,
      "grad_norm": 0.21710795164108276,
      "learning_rate": 0.0003117956291300021,
      "loss": 1.3414,
      "step": 26430
    },
    {
      "epoch": 85.0,
      "eval_loss": 0.6411810517311096,
      "eval_runtime": 7.0995,
      "eval_samples_per_second": 3423.188,
      "eval_steps_per_second": 13.381,
      "step": 26435
    },
    {
      "epoch": 85.0,
      "step": 26435,
      "total_flos": 3.649214126699315e+16,
      "train_loss": 1.4829216266413459,
      "train_runtime": 7631.2225,
      "train_samples_per_second": 4163.71,
      "train_steps_per_second": 8.125
    }
  ],
  "logging_steps": 10,
  "max_steps": 62000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 200,
  "save_steps": 1000,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 20,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 20
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.649214126699315e+16,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
