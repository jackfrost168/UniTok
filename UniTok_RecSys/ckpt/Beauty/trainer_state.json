{
  "best_metric": 1.08894944190979,
  "best_model_checkpoint": "./ckpt/Beauty/checkpoint-10794",
  "epoch": 62.0,
  "eval_steps": 1000,
  "global_step": 15934,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.038910505836575876,
      "grad_norm": 13.343559265136719,
      "learning_rate": 9.72762645914397e-06,
      "loss": 21.7174,
      "step": 10
    },
    {
      "epoch": 0.07782101167315175,
      "grad_norm": 9.262212753295898,
      "learning_rate": 1.945525291828794e-05,
      "loss": 20.4779,
      "step": 20
    },
    {
      "epoch": 0.11673151750972763,
      "grad_norm": 5.638319492340088,
      "learning_rate": 2.918287937743191e-05,
      "loss": 18.7834,
      "step": 30
    },
    {
      "epoch": 0.1556420233463035,
      "grad_norm": 3.6718058586120605,
      "learning_rate": 3.891050583657588e-05,
      "loss": 17.2128,
      "step": 40
    },
    {
      "epoch": 0.19455252918287938,
      "grad_norm": 3.6860709190368652,
      "learning_rate": 4.863813229571985e-05,
      "loss": 15.9576,
      "step": 50
    },
    {
      "epoch": 0.23346303501945526,
      "grad_norm": 3.5200531482696533,
      "learning_rate": 5.836575875486382e-05,
      "loss": 14.4202,
      "step": 60
    },
    {
      "epoch": 0.2723735408560311,
      "grad_norm": 3.097569227218628,
      "learning_rate": 6.809338521400777e-05,
      "loss": 12.5637,
      "step": 70
    },
    {
      "epoch": 0.311284046692607,
      "grad_norm": 2.5849030017852783,
      "learning_rate": 7.782101167315176e-05,
      "loss": 10.9005,
      "step": 80
    },
    {
      "epoch": 0.35019455252918286,
      "grad_norm": 2.1213388442993164,
      "learning_rate": 8.754863813229571e-05,
      "loss": 9.5369,
      "step": 90
    },
    {
      "epoch": 0.38910505836575876,
      "grad_norm": 1.6883838176727295,
      "learning_rate": 9.72762645914397e-05,
      "loss": 8.3779,
      "step": 100
    },
    {
      "epoch": 0.4280155642023346,
      "grad_norm": 1.4797401428222656,
      "learning_rate": 0.00010700389105058365,
      "loss": 7.71,
      "step": 110
    },
    {
      "epoch": 0.4669260700389105,
      "grad_norm": 1.353445291519165,
      "learning_rate": 0.00011673151750972763,
      "loss": 7.2691,
      "step": 120
    },
    {
      "epoch": 0.5058365758754864,
      "grad_norm": 1.2804168462753296,
      "learning_rate": 0.0001264591439688716,
      "loss": 6.9231,
      "step": 130
    },
    {
      "epoch": 0.5447470817120622,
      "grad_norm": 1.2532227039337158,
      "learning_rate": 0.00013618677042801555,
      "loss": 6.6897,
      "step": 140
    },
    {
      "epoch": 0.5836575875486382,
      "grad_norm": 1.2409321069717407,
      "learning_rate": 0.00014591439688715956,
      "loss": 6.4885,
      "step": 150
    },
    {
      "epoch": 0.622568093385214,
      "grad_norm": 1.1216762065887451,
      "learning_rate": 0.0001556420233463035,
      "loss": 6.3844,
      "step": 160
    },
    {
      "epoch": 0.6614785992217899,
      "grad_norm": 1.0883182287216187,
      "learning_rate": 0.00016536964980544747,
      "loss": 6.1955,
      "step": 170
    },
    {
      "epoch": 0.7003891050583657,
      "grad_norm": 1.1536253690719604,
      "learning_rate": 0.00017509727626459142,
      "loss": 6.1424,
      "step": 180
    },
    {
      "epoch": 0.7392996108949417,
      "grad_norm": 1.0142452716827393,
      "learning_rate": 0.00018482490272373543,
      "loss": 6.0334,
      "step": 190
    },
    {
      "epoch": 0.7782101167315175,
      "grad_norm": 1.1367346048355103,
      "learning_rate": 0.0001945525291828794,
      "loss": 5.9263,
      "step": 200
    },
    {
      "epoch": 0.8171206225680934,
      "grad_norm": 1.0608881711959839,
      "learning_rate": 0.00020428015564202335,
      "loss": 5.8732,
      "step": 210
    },
    {
      "epoch": 0.8560311284046692,
      "grad_norm": 1.0748978853225708,
      "learning_rate": 0.0002140077821011673,
      "loss": 5.7753,
      "step": 220
    },
    {
      "epoch": 0.8949416342412452,
      "grad_norm": 0.9648357629776001,
      "learning_rate": 0.00022373540856031129,
      "loss": 5.6825,
      "step": 230
    },
    {
      "epoch": 0.933852140077821,
      "grad_norm": 0.9879982471466064,
      "learning_rate": 0.00023346303501945527,
      "loss": 5.6084,
      "step": 240
    },
    {
      "epoch": 0.9727626459143969,
      "grad_norm": 0.9213452339172363,
      "learning_rate": 0.00024319066147859923,
      "loss": 5.5806,
      "step": 250
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.6312637329101562,
      "eval_runtime": 6.2057,
      "eval_samples_per_second": 3603.611,
      "eval_steps_per_second": 14.18,
      "step": 257
    },
    {
      "epoch": 1.0116731517509727,
      "grad_norm": 0.852921187877655,
      "learning_rate": 0.0002529182879377432,
      "loss": 5.4715,
      "step": 260
    },
    {
      "epoch": 1.0505836575875487,
      "grad_norm": 0.8527508974075317,
      "learning_rate": 0.0002626459143968872,
      "loss": 5.4009,
      "step": 270
    },
    {
      "epoch": 1.0894941634241244,
      "grad_norm": 0.7943172454833984,
      "learning_rate": 0.0002723735408560311,
      "loss": 5.3454,
      "step": 280
    },
    {
      "epoch": 1.1284046692607004,
      "grad_norm": 0.7312952876091003,
      "learning_rate": 0.0002821011673151751,
      "loss": 5.2843,
      "step": 290
    },
    {
      "epoch": 1.1673151750972763,
      "grad_norm": 0.92561274766922,
      "learning_rate": 0.0002918287937743191,
      "loss": 5.1826,
      "step": 300
    },
    {
      "epoch": 1.206225680933852,
      "grad_norm": 0.795880138874054,
      "learning_rate": 0.000301556420233463,
      "loss": 5.1442,
      "step": 310
    },
    {
      "epoch": 1.245136186770428,
      "grad_norm": 0.7058795094490051,
      "learning_rate": 0.000311284046692607,
      "loss": 5.0773,
      "step": 320
    },
    {
      "epoch": 1.2840466926070038,
      "grad_norm": 0.751083254814148,
      "learning_rate": 0.000321011673151751,
      "loss": 4.9932,
      "step": 330
    },
    {
      "epoch": 1.3229571984435797,
      "grad_norm": 0.8230538964271545,
      "learning_rate": 0.00033073929961089494,
      "loss": 4.9135,
      "step": 340
    },
    {
      "epoch": 1.3618677042801557,
      "grad_norm": 0.7300767302513123,
      "learning_rate": 0.00034046692607003895,
      "loss": 4.8329,
      "step": 350
    },
    {
      "epoch": 1.4007782101167314,
      "grad_norm": 0.7200730443000793,
      "learning_rate": 0.00035019455252918285,
      "loss": 4.779,
      "step": 360
    },
    {
      "epoch": 1.4396887159533074,
      "grad_norm": 0.6544426083564758,
      "learning_rate": 0.00035992217898832686,
      "loss": 4.7209,
      "step": 370
    },
    {
      "epoch": 1.4785992217898833,
      "grad_norm": 0.7229019403457642,
      "learning_rate": 0.00036964980544747087,
      "loss": 4.6763,
      "step": 380
    },
    {
      "epoch": 1.517509727626459,
      "grad_norm": 0.8129440546035767,
      "learning_rate": 0.00037937743190661477,
      "loss": 4.5974,
      "step": 390
    },
    {
      "epoch": 1.556420233463035,
      "grad_norm": 0.6465190649032593,
      "learning_rate": 0.0003891050583657588,
      "loss": 4.4903,
      "step": 400
    },
    {
      "epoch": 1.595330739299611,
      "grad_norm": 0.6032371520996094,
      "learning_rate": 0.00039883268482490274,
      "loss": 4.437,
      "step": 410
    },
    {
      "epoch": 1.6342412451361867,
      "grad_norm": 0.6063521504402161,
      "learning_rate": 0.0004085603112840467,
      "loss": 4.3596,
      "step": 420
    },
    {
      "epoch": 1.6731517509727627,
      "grad_norm": 0.6415802836418152,
      "learning_rate": 0.0004182879377431907,
      "loss": 4.3052,
      "step": 430
    },
    {
      "epoch": 1.7120622568093387,
      "grad_norm": 0.5516770482063293,
      "learning_rate": 0.0004280155642023346,
      "loss": 4.2295,
      "step": 440
    },
    {
      "epoch": 1.7509727626459144,
      "grad_norm": 0.6341537237167358,
      "learning_rate": 0.0004377431906614786,
      "loss": 4.1612,
      "step": 450
    },
    {
      "epoch": 1.7898832684824901,
      "grad_norm": 0.5398585200309753,
      "learning_rate": 0.00044747081712062257,
      "loss": 4.0886,
      "step": 460
    },
    {
      "epoch": 1.8287937743190663,
      "grad_norm": 1.7381539344787598,
      "learning_rate": 0.00045719844357976653,
      "loss": 4.0371,
      "step": 470
    },
    {
      "epoch": 1.867704280155642,
      "grad_norm": 0.638008177280426,
      "learning_rate": 0.00046692607003891054,
      "loss": 3.9849,
      "step": 480
    },
    {
      "epoch": 1.9066147859922178,
      "grad_norm": 0.5233559608459473,
      "learning_rate": 0.0004766536964980545,
      "loss": 3.8904,
      "step": 490
    },
    {
      "epoch": 1.9455252918287937,
      "grad_norm": 0.5231006741523743,
      "learning_rate": 0.00048638132295719845,
      "loss": 3.8427,
      "step": 500
    },
    {
      "epoch": 1.9844357976653697,
      "grad_norm": 0.5269901156425476,
      "learning_rate": 0.0004961089494163424,
      "loss": 3.7559,
      "step": 510
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.8078696727752686,
      "eval_runtime": 6.2086,
      "eval_samples_per_second": 3601.94,
      "eval_steps_per_second": 14.174,
      "step": 514
    },
    {
      "epoch": 2.0233463035019454,
      "grad_norm": 0.5672866106033325,
      "learning_rate": 0.0004999999828479661,
      "loss": 3.706,
      "step": 520
    },
    {
      "epoch": 2.062256809338521,
      "grad_norm": 0.7781631350517273,
      "learning_rate": 0.0004999998780299894,
      "loss": 3.6071,
      "step": 530
    },
    {
      "epoch": 2.1011673151750974,
      "grad_norm": 0.4706602394580841,
      "learning_rate": 0.000499999677922984,
      "loss": 3.5486,
      "step": 540
    },
    {
      "epoch": 2.140077821011673,
      "grad_norm": 0.5011422634124756,
      "learning_rate": 0.0004999993825270258,
      "loss": 3.5297,
      "step": 550
    },
    {
      "epoch": 2.178988326848249,
      "grad_norm": 0.4366331398487091,
      "learning_rate": 0.0004999989918422276,
      "loss": 3.4401,
      "step": 560
    },
    {
      "epoch": 2.217898832684825,
      "grad_norm": 0.40861865878105164,
      "learning_rate": 0.0004999985058687382,
      "loss": 3.3884,
      "step": 570
    },
    {
      "epoch": 2.2568093385214008,
      "grad_norm": 0.5074920058250427,
      "learning_rate": 0.0004999979246067428,
      "loss": 3.3484,
      "step": 580
    },
    {
      "epoch": 2.2957198443579765,
      "grad_norm": 0.4182111620903015,
      "learning_rate": 0.0004999972480564631,
      "loss": 3.2474,
      "step": 590
    },
    {
      "epoch": 2.3346303501945527,
      "grad_norm": 0.6127949953079224,
      "learning_rate": 0.0004999964762181569,
      "loss": 3.2476,
      "step": 600
    },
    {
      "epoch": 2.3735408560311284,
      "grad_norm": 0.3743703365325928,
      "learning_rate": 0.0004999956090921184,
      "loss": 3.1639,
      "step": 610
    },
    {
      "epoch": 2.412451361867704,
      "grad_norm": 0.34595584869384766,
      "learning_rate": 0.000499994646678678,
      "loss": 3.1488,
      "step": 620
    },
    {
      "epoch": 2.4513618677042803,
      "grad_norm": 0.4414803683757782,
      "learning_rate": 0.0004999935889782027,
      "loss": 3.0985,
      "step": 630
    },
    {
      "epoch": 2.490272373540856,
      "grad_norm": 0.3446873128414154,
      "learning_rate": 0.0004999924359910955,
      "loss": 3.0736,
      "step": 640
    },
    {
      "epoch": 2.529182879377432,
      "grad_norm": 0.4064788520336151,
      "learning_rate": 0.000499991187717796,
      "loss": 3.0091,
      "step": 650
    },
    {
      "epoch": 2.5680933852140075,
      "grad_norm": 0.36015570163726807,
      "learning_rate": 0.00049998984415878,
      "loss": 2.9789,
      "step": 660
    },
    {
      "epoch": 2.6070038910505837,
      "grad_norm": 0.4314556121826172,
      "learning_rate": 0.0004999884053145595,
      "loss": 2.9475,
      "step": 670
    },
    {
      "epoch": 2.6459143968871595,
      "grad_norm": 1.6120182275772095,
      "learning_rate": 0.000499986871185683,
      "loss": 2.9172,
      "step": 680
    },
    {
      "epoch": 2.6848249027237356,
      "grad_norm": 1.0705475807189941,
      "learning_rate": 0.0004999852417727351,
      "loss": 2.8868,
      "step": 690
    },
    {
      "epoch": 2.7237354085603114,
      "grad_norm": 0.31342461705207825,
      "learning_rate": 0.000499983517076337,
      "loss": 2.8789,
      "step": 700
    },
    {
      "epoch": 2.762645914396887,
      "grad_norm": 0.30829954147338867,
      "learning_rate": 0.0004999816970971461,
      "loss": 2.8508,
      "step": 710
    },
    {
      "epoch": 2.801556420233463,
      "grad_norm": 0.27860918641090393,
      "learning_rate": 0.0004999797818358559,
      "loss": 2.8024,
      "step": 720
    },
    {
      "epoch": 2.840466926070039,
      "grad_norm": 0.29138293862342834,
      "learning_rate": 0.0004999777712931967,
      "loss": 2.7962,
      "step": 730
    },
    {
      "epoch": 2.8793774319066148,
      "grad_norm": 0.2993102967739105,
      "learning_rate": 0.0004999756654699346,
      "loss": 2.7823,
      "step": 740
    },
    {
      "epoch": 2.9182879377431905,
      "grad_norm": 0.31197091937065125,
      "learning_rate": 0.0004999734643668724,
      "loss": 2.7828,
      "step": 750
    },
    {
      "epoch": 2.9571984435797667,
      "grad_norm": 0.32148611545562744,
      "learning_rate": 0.000499971167984849,
      "loss": 2.7355,
      "step": 760
    },
    {
      "epoch": 2.9961089494163424,
      "grad_norm": 0.39344245195388794,
      "learning_rate": 0.0004999687763247397,
      "loss": 2.7356,
      "step": 770
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.335511565208435,
      "eval_runtime": 6.1639,
      "eval_samples_per_second": 3628.04,
      "eval_steps_per_second": 14.277,
      "step": 771
    },
    {
      "epoch": 3.035019455252918,
      "grad_norm": 0.26359617710113525,
      "learning_rate": 0.000499966289387456,
      "loss": 2.703,
      "step": 780
    },
    {
      "epoch": 3.0739299610894943,
      "grad_norm": 0.27191755175590515,
      "learning_rate": 0.0004999637071739459,
      "loss": 2.6707,
      "step": 790
    },
    {
      "epoch": 3.11284046692607,
      "grad_norm": 0.3043501675128937,
      "learning_rate": 0.0004999610296851936,
      "loss": 2.6632,
      "step": 800
    },
    {
      "epoch": 3.151750972762646,
      "grad_norm": 0.2628742754459381,
      "learning_rate": 0.0004999582569222197,
      "loss": 2.6496,
      "step": 810
    },
    {
      "epoch": 3.190661478599222,
      "grad_norm": 0.2540435492992401,
      "learning_rate": 0.000499955388886081,
      "loss": 2.6288,
      "step": 820
    },
    {
      "epoch": 3.2295719844357977,
      "grad_norm": 0.31049779057502747,
      "learning_rate": 0.0004999524255778707,
      "loss": 2.6091,
      "step": 830
    },
    {
      "epoch": 3.2684824902723735,
      "grad_norm": 0.2358531951904297,
      "learning_rate": 0.0004999493669987182,
      "loss": 2.6013,
      "step": 840
    },
    {
      "epoch": 3.307392996108949,
      "grad_norm": 0.2498132437467575,
      "learning_rate": 0.0004999462131497894,
      "loss": 2.5893,
      "step": 850
    },
    {
      "epoch": 3.3463035019455254,
      "grad_norm": 0.2983761131763458,
      "learning_rate": 0.0004999429640322864,
      "loss": 2.5642,
      "step": 860
    },
    {
      "epoch": 3.385214007782101,
      "grad_norm": 0.26239606738090515,
      "learning_rate": 0.0004999396196474475,
      "loss": 2.5704,
      "step": 870
    },
    {
      "epoch": 3.424124513618677,
      "grad_norm": 0.2915056347846985,
      "learning_rate": 0.0004999361799965476,
      "loss": 2.5798,
      "step": 880
    },
    {
      "epoch": 3.463035019455253,
      "grad_norm": 0.23050986230373383,
      "learning_rate": 0.0004999326450808977,
      "loss": 2.5621,
      "step": 890
    },
    {
      "epoch": 3.501945525291829,
      "grad_norm": 0.23862901329994202,
      "learning_rate": 0.000499929014901845,
      "loss": 2.5454,
      "step": 900
    },
    {
      "epoch": 3.5408560311284045,
      "grad_norm": 0.2413332760334015,
      "learning_rate": 0.0004999252894607734,
      "loss": 2.5368,
      "step": 910
    },
    {
      "epoch": 3.5797665369649807,
      "grad_norm": 0.2631851136684418,
      "learning_rate": 0.0004999214687591028,
      "loss": 2.5401,
      "step": 920
    },
    {
      "epoch": 3.6186770428015564,
      "grad_norm": 0.2639019787311554,
      "learning_rate": 0.0004999175527982894,
      "loss": 2.5141,
      "step": 930
    },
    {
      "epoch": 3.657587548638132,
      "grad_norm": 0.2309967428445816,
      "learning_rate": 0.0004999135415798258,
      "loss": 2.5294,
      "step": 940
    },
    {
      "epoch": 3.6964980544747084,
      "grad_norm": 0.2706328332424164,
      "learning_rate": 0.000499909435105241,
      "loss": 2.5214,
      "step": 950
    },
    {
      "epoch": 3.735408560311284,
      "grad_norm": 0.22470726072788239,
      "learning_rate": 0.0004999052333761002,
      "loss": 2.4973,
      "step": 960
    },
    {
      "epoch": 3.77431906614786,
      "grad_norm": 0.2537280023097992,
      "learning_rate": 0.0004999009363940047,
      "loss": 2.4881,
      "step": 970
    },
    {
      "epoch": 3.8132295719844356,
      "grad_norm": 0.23576918244361877,
      "learning_rate": 0.0004998965441605927,
      "loss": 2.4782,
      "step": 980
    },
    {
      "epoch": 3.8521400778210118,
      "grad_norm": 0.2360137403011322,
      "learning_rate": 0.000499892056677538,
      "loss": 2.483,
      "step": 990
    },
    {
      "epoch": 3.8910505836575875,
      "grad_norm": 0.24137821793556213,
      "learning_rate": 0.0004998874739465511,
      "loss": 2.4925,
      "step": 1000
    },
    {
      "epoch": 3.9299610894941637,
      "grad_norm": 0.23720517754554749,
      "learning_rate": 0.0004998827959693789,
      "loss": 2.4631,
      "step": 1010
    },
    {
      "epoch": 3.9688715953307394,
      "grad_norm": 0.2526400685310364,
      "learning_rate": 0.0004998780227478043,
      "loss": 2.4601,
      "step": 1020
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.2258074283599854,
      "eval_runtime": 6.2262,
      "eval_samples_per_second": 3591.732,
      "eval_steps_per_second": 14.134,
      "step": 1028
    },
    {
      "epoch": 4.007782101167315,
      "grad_norm": 0.24679479002952576,
      "learning_rate": 0.0004998731542836467,
      "loss": 2.4601,
      "step": 1030
    },
    {
      "epoch": 4.046692607003891,
      "grad_norm": 0.23946037888526917,
      "learning_rate": 0.0004998681905787616,
      "loss": 2.4419,
      "step": 1040
    },
    {
      "epoch": 4.085603112840467,
      "grad_norm": 0.29030168056488037,
      "learning_rate": 0.0004998631316350412,
      "loss": 2.4248,
      "step": 1050
    },
    {
      "epoch": 4.124513618677042,
      "grad_norm": 0.22454024851322174,
      "learning_rate": 0.0004998579774544136,
      "loss": 2.4471,
      "step": 1060
    },
    {
      "epoch": 4.163424124513619,
      "grad_norm": 0.2193949818611145,
      "learning_rate": 0.0004998527280388433,
      "loss": 2.4303,
      "step": 1070
    },
    {
      "epoch": 4.202334630350195,
      "grad_norm": 0.2278742790222168,
      "learning_rate": 0.0004998473833903312,
      "loss": 2.4415,
      "step": 1080
    },
    {
      "epoch": 4.2412451361867705,
      "grad_norm": 0.24740123748779297,
      "learning_rate": 0.0004998419435109145,
      "loss": 2.4243,
      "step": 1090
    },
    {
      "epoch": 4.280155642023346,
      "grad_norm": 0.23573599755764008,
      "learning_rate": 0.0004998364084026666,
      "loss": 2.4328,
      "step": 1100
    },
    {
      "epoch": 4.319066147859922,
      "grad_norm": 0.5515843629837036,
      "learning_rate": 0.0004998307780676972,
      "loss": 2.4124,
      "step": 1110
    },
    {
      "epoch": 4.357976653696498,
      "grad_norm": 0.24344800412654877,
      "learning_rate": 0.0004998250525081524,
      "loss": 2.4211,
      "step": 1120
    },
    {
      "epoch": 4.396887159533074,
      "grad_norm": 0.23736000061035156,
      "learning_rate": 0.0004998192317262146,
      "loss": 2.3917,
      "step": 1130
    },
    {
      "epoch": 4.43579766536965,
      "grad_norm": 0.2455781102180481,
      "learning_rate": 0.0004998133157241022,
      "loss": 2.4104,
      "step": 1140
    },
    {
      "epoch": 4.474708171206226,
      "grad_norm": 0.24570831656455994,
      "learning_rate": 0.0004998073045040704,
      "loss": 2.3994,
      "step": 1150
    },
    {
      "epoch": 4.5136186770428015,
      "grad_norm": 0.22863875329494476,
      "learning_rate": 0.0004998011980684102,
      "loss": 2.3957,
      "step": 1160
    },
    {
      "epoch": 4.552529182879377,
      "grad_norm": 0.21431128680706024,
      "learning_rate": 0.0004997949964194492,
      "loss": 2.4277,
      "step": 1170
    },
    {
      "epoch": 4.591439688715953,
      "grad_norm": 0.2590683102607727,
      "learning_rate": 0.0004997886995595512,
      "loss": 2.38,
      "step": 1180
    },
    {
      "epoch": 4.630350194552529,
      "grad_norm": 0.2519156038761139,
      "learning_rate": 0.0004997823074911163,
      "loss": 2.3942,
      "step": 1190
    },
    {
      "epoch": 4.669260700389105,
      "grad_norm": 0.24593891203403473,
      "learning_rate": 0.0004997758202165808,
      "loss": 2.387,
      "step": 1200
    },
    {
      "epoch": 4.708171206225681,
      "grad_norm": 0.29065564274787903,
      "learning_rate": 0.0004997692377384173,
      "loss": 2.3862,
      "step": 1210
    },
    {
      "epoch": 4.747081712062257,
      "grad_norm": 0.22537454962730408,
      "learning_rate": 0.000499762560059135,
      "loss": 2.3779,
      "step": 1220
    },
    {
      "epoch": 4.785992217898833,
      "grad_norm": 0.22078387439250946,
      "learning_rate": 0.000499755787181279,
      "loss": 2.3784,
      "step": 1230
    },
    {
      "epoch": 4.824902723735408,
      "grad_norm": 0.21552737057209015,
      "learning_rate": 0.0004997489191074307,
      "loss": 2.3781,
      "step": 1240
    },
    {
      "epoch": 4.863813229571985,
      "grad_norm": 0.27653583884239197,
      "learning_rate": 0.0004997419558402083,
      "loss": 2.3697,
      "step": 1250
    },
    {
      "epoch": 4.902723735408561,
      "grad_norm": 0.24209728837013245,
      "learning_rate": 0.0004997348973822654,
      "loss": 2.3746,
      "step": 1260
    },
    {
      "epoch": 4.941634241245136,
      "grad_norm": 0.23357070982456207,
      "learning_rate": 0.0004997277437362927,
      "loss": 2.3642,
      "step": 1270
    },
    {
      "epoch": 4.980544747081712,
      "grad_norm": 0.24774490296840668,
      "learning_rate": 0.0004997204949050166,
      "loss": 2.3782,
      "step": 1280
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.1777126789093018,
      "eval_runtime": 6.413,
      "eval_samples_per_second": 3487.117,
      "eval_steps_per_second": 13.722,
      "step": 1285
    },
    {
      "epoch": 5.019455252918288,
      "grad_norm": 0.22500959038734436,
      "learning_rate": 0.0004997131508912004,
      "loss": 2.358,
      "step": 1290
    },
    {
      "epoch": 5.058365758754864,
      "grad_norm": 0.26199138164520264,
      "learning_rate": 0.0004997057116976431,
      "loss": 2.3531,
      "step": 1300
    },
    {
      "epoch": 5.097276264591439,
      "grad_norm": 0.22682631015777588,
      "learning_rate": 0.0004996981773271802,
      "loss": 2.3246,
      "step": 1310
    },
    {
      "epoch": 5.136186770428016,
      "grad_norm": 0.23024214804172516,
      "learning_rate": 0.0004996905477826834,
      "loss": 2.3665,
      "step": 1320
    },
    {
      "epoch": 5.175097276264592,
      "grad_norm": 0.22549259662628174,
      "learning_rate": 0.0004996828230670609,
      "loss": 2.3749,
      "step": 1330
    },
    {
      "epoch": 5.214007782101167,
      "grad_norm": 0.220504030585289,
      "learning_rate": 0.000499675003183257,
      "loss": 2.3612,
      "step": 1340
    },
    {
      "epoch": 5.252918287937743,
      "grad_norm": 0.23563718795776367,
      "learning_rate": 0.0004996670881342523,
      "loss": 2.3494,
      "step": 1350
    },
    {
      "epoch": 5.291828793774319,
      "grad_norm": 0.2255713939666748,
      "learning_rate": 0.0004996590779230636,
      "loss": 2.361,
      "step": 1360
    },
    {
      "epoch": 5.330739299610895,
      "grad_norm": 0.28293776512145996,
      "learning_rate": 0.000499650972552744,
      "loss": 2.3546,
      "step": 1370
    },
    {
      "epoch": 5.369649805447471,
      "grad_norm": 0.20598389208316803,
      "learning_rate": 0.0004996427720263829,
      "loss": 2.3499,
      "step": 1380
    },
    {
      "epoch": 5.408560311284047,
      "grad_norm": 0.29020941257476807,
      "learning_rate": 0.0004996344763471063,
      "loss": 2.3355,
      "step": 1390
    },
    {
      "epoch": 5.447470817120623,
      "grad_norm": 0.24014043807983398,
      "learning_rate": 0.0004996260855180758,
      "loss": 2.3457,
      "step": 1400
    },
    {
      "epoch": 5.4863813229571985,
      "grad_norm": 0.24512852728366852,
      "learning_rate": 0.0004996175995424896,
      "loss": 2.3316,
      "step": 1410
    },
    {
      "epoch": 5.525291828793774,
      "grad_norm": 0.22083649039268494,
      "learning_rate": 0.0004996090184235826,
      "loss": 2.3434,
      "step": 1420
    },
    {
      "epoch": 5.56420233463035,
      "grad_norm": 0.23555126786231995,
      "learning_rate": 0.000499600342164625,
      "loss": 2.3435,
      "step": 1430
    },
    {
      "epoch": 5.603112840466926,
      "grad_norm": 0.25252851843833923,
      "learning_rate": 0.0004995915707689243,
      "loss": 2.3454,
      "step": 1440
    },
    {
      "epoch": 5.642023346303502,
      "grad_norm": 0.2689085304737091,
      "learning_rate": 0.0004995827042398233,
      "loss": 2.3136,
      "step": 1450
    },
    {
      "epoch": 5.680933852140078,
      "grad_norm": 0.23306919634342194,
      "learning_rate": 0.000499573742580702,
      "loss": 2.3247,
      "step": 1460
    },
    {
      "epoch": 5.719844357976654,
      "grad_norm": 0.24911580979824066,
      "learning_rate": 0.0004995646857949759,
      "loss": 2.3244,
      "step": 1470
    },
    {
      "epoch": 5.7587548638132295,
      "grad_norm": 0.22501344978809357,
      "learning_rate": 0.0004995555338860971,
      "loss": 2.3107,
      "step": 1480
    },
    {
      "epoch": 5.797665369649805,
      "grad_norm": 0.21480415761470795,
      "learning_rate": 0.000499546286857554,
      "loss": 2.3161,
      "step": 1490
    },
    {
      "epoch": 5.836575875486381,
      "grad_norm": 0.24933584034442902,
      "learning_rate": 0.000499536944712871,
      "loss": 2.3068,
      "step": 1500
    },
    {
      "epoch": 5.875486381322958,
      "grad_norm": 0.21986301243305206,
      "learning_rate": 0.0004995275074556092,
      "loss": 2.3125,
      "step": 1510
    },
    {
      "epoch": 5.914396887159533,
      "grad_norm": 0.21797575056552887,
      "learning_rate": 0.0004995179750893653,
      "loss": 2.3056,
      "step": 1520
    },
    {
      "epoch": 5.953307392996109,
      "grad_norm": 0.28293147683143616,
      "learning_rate": 0.0004995083476177729,
      "loss": 2.3317,
      "step": 1530
    },
    {
      "epoch": 5.992217898832685,
      "grad_norm": 0.23472747206687927,
      "learning_rate": 0.0004994986250445014,
      "loss": 2.3069,
      "step": 1540
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.1572177410125732,
      "eval_runtime": 6.1499,
      "eval_samples_per_second": 3636.339,
      "eval_steps_per_second": 14.309,
      "step": 1542
    },
    {
      "epoch": 6.031128404669261,
      "grad_norm": 0.2596561312675476,
      "learning_rate": 0.0004994888073732568,
      "loss": 2.3121,
      "step": 1550
    },
    {
      "epoch": 6.070038910505836,
      "grad_norm": 0.2875543236732483,
      "learning_rate": 0.000499478894607781,
      "loss": 2.3064,
      "step": 1560
    },
    {
      "epoch": 6.108949416342412,
      "grad_norm": 0.30450284481048584,
      "learning_rate": 0.0004994688867518523,
      "loss": 2.3138,
      "step": 1570
    },
    {
      "epoch": 6.147859922178989,
      "grad_norm": 0.22922737896442413,
      "learning_rate": 0.0004994587838092854,
      "loss": 2.3197,
      "step": 1580
    },
    {
      "epoch": 6.186770428015564,
      "grad_norm": 0.22063659131526947,
      "learning_rate": 0.0004994485857839311,
      "loss": 2.31,
      "step": 1590
    },
    {
      "epoch": 6.22568093385214,
      "grad_norm": 0.3058089315891266,
      "learning_rate": 0.0004994382926796763,
      "loss": 2.3095,
      "step": 1600
    },
    {
      "epoch": 6.264591439688716,
      "grad_norm": 0.22815559804439545,
      "learning_rate": 0.0004994279045004445,
      "loss": 2.2767,
      "step": 1610
    },
    {
      "epoch": 6.303501945525292,
      "grad_norm": 0.24685989320278168,
      "learning_rate": 0.0004994174212501949,
      "loss": 2.2978,
      "step": 1620
    },
    {
      "epoch": 6.342412451361867,
      "grad_norm": 0.24119462072849274,
      "learning_rate": 0.0004994068429329236,
      "loss": 2.2948,
      "step": 1630
    },
    {
      "epoch": 6.381322957198444,
      "grad_norm": 0.24074368178844452,
      "learning_rate": 0.0004993961695526623,
      "loss": 2.3059,
      "step": 1640
    },
    {
      "epoch": 6.42023346303502,
      "grad_norm": 0.24853608012199402,
      "learning_rate": 0.0004993854011134794,
      "loss": 2.2931,
      "step": 1650
    },
    {
      "epoch": 6.4591439688715955,
      "grad_norm": 0.2603747546672821,
      "learning_rate": 0.0004993745376194792,
      "loss": 2.3043,
      "step": 1660
    },
    {
      "epoch": 6.498054474708171,
      "grad_norm": 0.2759154438972473,
      "learning_rate": 0.0004993635790748027,
      "loss": 2.2935,
      "step": 1670
    },
    {
      "epoch": 6.536964980544747,
      "grad_norm": 0.26089006662368774,
      "learning_rate": 0.0004993525254836266,
      "loss": 2.2876,
      "step": 1680
    },
    {
      "epoch": 6.575875486381323,
      "grad_norm": 0.24501322209835052,
      "learning_rate": 0.000499341376850164,
      "loss": 2.2886,
      "step": 1690
    },
    {
      "epoch": 6.614785992217898,
      "grad_norm": 0.23711127042770386,
      "learning_rate": 0.0004993301331786643,
      "loss": 2.2865,
      "step": 1700
    },
    {
      "epoch": 6.653696498054475,
      "grad_norm": 0.22964660823345184,
      "learning_rate": 0.0004993187944734131,
      "loss": 2.2833,
      "step": 1710
    },
    {
      "epoch": 6.692607003891051,
      "grad_norm": 0.2285328209400177,
      "learning_rate": 0.0004993073607387324,
      "loss": 2.2926,
      "step": 1720
    },
    {
      "epoch": 6.7315175097276265,
      "grad_norm": 0.24737219512462616,
      "learning_rate": 0.00049929583197898,
      "loss": 2.2767,
      "step": 1730
    },
    {
      "epoch": 6.770428015564202,
      "grad_norm": 0.22225092351436615,
      "learning_rate": 0.0004992842081985502,
      "loss": 2.2792,
      "step": 1740
    },
    {
      "epoch": 6.809338521400778,
      "grad_norm": 0.23769758641719818,
      "learning_rate": 0.0004992724894018737,
      "loss": 2.2881,
      "step": 1750
    },
    {
      "epoch": 6.848249027237354,
      "grad_norm": 0.24534893035888672,
      "learning_rate": 0.0004992606755934169,
      "loss": 2.2915,
      "step": 1760
    },
    {
      "epoch": 6.88715953307393,
      "grad_norm": 0.3743338882923126,
      "learning_rate": 0.0004992487667776828,
      "loss": 2.293,
      "step": 1770
    },
    {
      "epoch": 6.926070038910506,
      "grad_norm": 0.24418219923973083,
      "learning_rate": 0.0004992367629592106,
      "loss": 2.2941,
      "step": 1780
    },
    {
      "epoch": 6.964980544747082,
      "grad_norm": 0.22563360631465912,
      "learning_rate": 0.0004992246641425756,
      "loss": 2.2722,
      "step": 1790
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.1466453075408936,
      "eval_runtime": 6.1814,
      "eval_samples_per_second": 3617.797,
      "eval_steps_per_second": 14.236,
      "step": 1799
    },
    {
      "epoch": 7.003891050583658,
      "grad_norm": 0.37568432092666626,
      "learning_rate": 0.0004992124703323893,
      "loss": 2.2833,
      "step": 1800
    },
    {
      "epoch": 7.042801556420233,
      "grad_norm": 0.22919631004333496,
      "learning_rate": 0.0004992001815332995,
      "loss": 2.263,
      "step": 1810
    },
    {
      "epoch": 7.081712062256809,
      "grad_norm": 0.23904019594192505,
      "learning_rate": 0.0004991877977499901,
      "loss": 2.2752,
      "step": 1820
    },
    {
      "epoch": 7.120622568093385,
      "grad_norm": 0.24785320460796356,
      "learning_rate": 0.0004991753189871813,
      "loss": 2.2653,
      "step": 1830
    },
    {
      "epoch": 7.159533073929961,
      "grad_norm": 0.259400337934494,
      "learning_rate": 0.0004991627452496294,
      "loss": 2.2633,
      "step": 1840
    },
    {
      "epoch": 7.198443579766537,
      "grad_norm": 0.23845508694648743,
      "learning_rate": 0.0004991500765421271,
      "loss": 2.2758,
      "step": 1850
    },
    {
      "epoch": 7.237354085603113,
      "grad_norm": 0.2698279917240143,
      "learning_rate": 0.000499137312869503,
      "loss": 2.2701,
      "step": 1860
    },
    {
      "epoch": 7.276264591439689,
      "grad_norm": 0.25817278027534485,
      "learning_rate": 0.000499124454236622,
      "loss": 2.2634,
      "step": 1870
    },
    {
      "epoch": 7.315175097276264,
      "grad_norm": 0.26824918389320374,
      "learning_rate": 0.0004991115006483855,
      "loss": 2.2597,
      "step": 1880
    },
    {
      "epoch": 7.35408560311284,
      "grad_norm": 0.2667708694934845,
      "learning_rate": 0.0004990984521097306,
      "loss": 2.2753,
      "step": 1890
    },
    {
      "epoch": 7.392996108949417,
      "grad_norm": 0.23210026323795319,
      "learning_rate": 0.0004990853086256309,
      "loss": 2.2753,
      "step": 1900
    },
    {
      "epoch": 7.4319066147859925,
      "grad_norm": 0.31541499495506287,
      "learning_rate": 0.0004990720702010964,
      "loss": 2.2586,
      "step": 1910
    },
    {
      "epoch": 7.470817120622568,
      "grad_norm": 0.2407739907503128,
      "learning_rate": 0.0004990587368411725,
      "loss": 2.2551,
      "step": 1920
    },
    {
      "epoch": 7.509727626459144,
      "grad_norm": 0.23898561298847198,
      "learning_rate": 0.0004990453085509417,
      "loss": 2.2672,
      "step": 1930
    },
    {
      "epoch": 7.54863813229572,
      "grad_norm": 0.25406214594841003,
      "learning_rate": 0.000499031785335522,
      "loss": 2.255,
      "step": 1940
    },
    {
      "epoch": 7.587548638132295,
      "grad_norm": 0.23517879843711853,
      "learning_rate": 0.0004990181672000682,
      "loss": 2.2671,
      "step": 1950
    },
    {
      "epoch": 7.626459143968871,
      "grad_norm": 0.2947292923927307,
      "learning_rate": 0.0004990044541497706,
      "loss": 2.2266,
      "step": 1960
    },
    {
      "epoch": 7.665369649805448,
      "grad_norm": 0.272034227848053,
      "learning_rate": 0.0004989906461898562,
      "loss": 2.2825,
      "step": 1970
    },
    {
      "epoch": 7.7042801556420235,
      "grad_norm": 0.2472998946905136,
      "learning_rate": 0.0004989767433255879,
      "loss": 2.2701,
      "step": 1980
    },
    {
      "epoch": 7.743190661478599,
      "grad_norm": 0.29005277156829834,
      "learning_rate": 0.0004989627455622649,
      "loss": 2.263,
      "step": 1990
    },
    {
      "epoch": 7.782101167315175,
      "grad_norm": 0.2644212543964386,
      "learning_rate": 0.0004989486529052225,
      "loss": 2.2926,
      "step": 2000
    },
    {
      "epoch": 7.821011673151751,
      "grad_norm": 0.23543086647987366,
      "learning_rate": 0.0004989344653598323,
      "loss": 2.2543,
      "step": 2010
    },
    {
      "epoch": 7.859922178988327,
      "grad_norm": 0.2468234896659851,
      "learning_rate": 0.000498920182931502,
      "loss": 2.2506,
      "step": 2020
    },
    {
      "epoch": 7.898832684824903,
      "grad_norm": 0.2318841814994812,
      "learning_rate": 0.0004989058056256752,
      "loss": 2.2645,
      "step": 2030
    },
    {
      "epoch": 7.937743190661479,
      "grad_norm": 0.2580443024635315,
      "learning_rate": 0.0004988913334478322,
      "loss": 2.2725,
      "step": 2040
    },
    {
      "epoch": 7.976653696498055,
      "grad_norm": 0.3776925802230835,
      "learning_rate": 0.0004988767664034889,
      "loss": 2.2524,
      "step": 2050
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.1366398334503174,
      "eval_runtime": 6.1575,
      "eval_samples_per_second": 3631.803,
      "eval_steps_per_second": 14.291,
      "step": 2056
    },
    {
      "epoch": 8.01556420233463,
      "grad_norm": 0.2459133118391037,
      "learning_rate": 0.0004988621044981978,
      "loss": 2.2667,
      "step": 2060
    },
    {
      "epoch": 8.054474708171206,
      "grad_norm": 0.2519013583660126,
      "learning_rate": 0.0004988473477375474,
      "loss": 2.2416,
      "step": 2070
    },
    {
      "epoch": 8.093385214007782,
      "grad_norm": 0.2605147659778595,
      "learning_rate": 0.0004988324961271621,
      "loss": 2.2533,
      "step": 2080
    },
    {
      "epoch": 8.132295719844358,
      "grad_norm": 0.2892589569091797,
      "learning_rate": 0.0004988175496727029,
      "loss": 2.2613,
      "step": 2090
    },
    {
      "epoch": 8.171206225680933,
      "grad_norm": 0.2537495791912079,
      "learning_rate": 0.0004988025083798666,
      "loss": 2.2403,
      "step": 2100
    },
    {
      "epoch": 8.210116731517509,
      "grad_norm": 0.24419109523296356,
      "learning_rate": 0.0004987873722543864,
      "loss": 2.2446,
      "step": 2110
    },
    {
      "epoch": 8.249027237354085,
      "grad_norm": 0.2717210650444031,
      "learning_rate": 0.0004987721413020316,
      "loss": 2.2597,
      "step": 2120
    },
    {
      "epoch": 8.287937743190662,
      "grad_norm": 0.2538714110851288,
      "learning_rate": 0.0004987568155286071,
      "loss": 2.2278,
      "step": 2130
    },
    {
      "epoch": 8.326848249027238,
      "grad_norm": 0.2515554428100586,
      "learning_rate": 0.0004987413949399551,
      "loss": 2.2293,
      "step": 2140
    },
    {
      "epoch": 8.365758754863814,
      "grad_norm": 0.24817673861980438,
      "learning_rate": 0.0004987258795419528,
      "loss": 2.257,
      "step": 2150
    },
    {
      "epoch": 8.40466926070039,
      "grad_norm": 0.2804388403892517,
      "learning_rate": 0.0004987102693405143,
      "loss": 2.2478,
      "step": 2160
    },
    {
      "epoch": 8.443579766536965,
      "grad_norm": 0.24481971561908722,
      "learning_rate": 0.0004986945643415891,
      "loss": 2.2395,
      "step": 2170
    },
    {
      "epoch": 8.482490272373541,
      "grad_norm": 0.2445867508649826,
      "learning_rate": 0.0004986787645511636,
      "loss": 2.2394,
      "step": 2180
    },
    {
      "epoch": 8.521400778210117,
      "grad_norm": 0.3628457486629486,
      "learning_rate": 0.0004986628699752599,
      "loss": 2.2523,
      "step": 2190
    },
    {
      "epoch": 8.560311284046692,
      "grad_norm": 0.26716163754463196,
      "learning_rate": 0.0004986468806199363,
      "loss": 2.2298,
      "step": 2200
    },
    {
      "epoch": 8.599221789883268,
      "grad_norm": 0.23709535598754883,
      "learning_rate": 0.0004986307964912872,
      "loss": 2.2332,
      "step": 2210
    },
    {
      "epoch": 8.638132295719844,
      "grad_norm": 0.25158068537712097,
      "learning_rate": 0.0004986146175954432,
      "loss": 2.2379,
      "step": 2220
    },
    {
      "epoch": 8.67704280155642,
      "grad_norm": 0.24519002437591553,
      "learning_rate": 0.0004985983439385711,
      "loss": 2.2394,
      "step": 2230
    },
    {
      "epoch": 8.715953307392995,
      "grad_norm": 0.2595006227493286,
      "learning_rate": 0.0004985819755268736,
      "loss": 2.2371,
      "step": 2240
    },
    {
      "epoch": 8.754863813229573,
      "grad_norm": 0.2594461143016815,
      "learning_rate": 0.0004985655123665897,
      "loss": 2.2389,
      "step": 2250
    },
    {
      "epoch": 8.793774319066149,
      "grad_norm": 0.333141028881073,
      "learning_rate": 0.0004985489544639943,
      "loss": 2.2323,
      "step": 2260
    },
    {
      "epoch": 8.832684824902724,
      "grad_norm": 0.2532672584056854,
      "learning_rate": 0.0004985323018253985,
      "loss": 2.2521,
      "step": 2270
    },
    {
      "epoch": 8.8715953307393,
      "grad_norm": 0.2797950506210327,
      "learning_rate": 0.0004985155544571499,
      "loss": 2.254,
      "step": 2280
    },
    {
      "epoch": 8.910505836575876,
      "grad_norm": 0.2775614857673645,
      "learning_rate": 0.0004984987123656315,
      "loss": 2.2299,
      "step": 2290
    },
    {
      "epoch": 8.949416342412452,
      "grad_norm": 0.24356214702129364,
      "learning_rate": 0.000498481775557263,
      "loss": 2.237,
      "step": 2300
    },
    {
      "epoch": 8.988326848249027,
      "grad_norm": 0.2899724841117859,
      "learning_rate": 0.0004984647440384999,
      "loss": 2.2552,
      "step": 2310
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.1258052587509155,
      "eval_runtime": 6.1855,
      "eval_samples_per_second": 3615.362,
      "eval_steps_per_second": 14.227,
      "step": 2313
    },
    {
      "epoch": 9.027237354085603,
      "grad_norm": 0.26377758383750916,
      "learning_rate": 0.0004984476178158338,
      "loss": 2.2136,
      "step": 2320
    },
    {
      "epoch": 9.066147859922179,
      "grad_norm": 0.258645236492157,
      "learning_rate": 0.0004984303968957925,
      "loss": 2.2247,
      "step": 2330
    },
    {
      "epoch": 9.105058365758754,
      "grad_norm": 0.30354374647140503,
      "learning_rate": 0.00049841308128494,
      "loss": 2.2381,
      "step": 2340
    },
    {
      "epoch": 9.14396887159533,
      "grad_norm": 0.35207828879356384,
      "learning_rate": 0.0004983956709898761,
      "loss": 2.2336,
      "step": 2350
    },
    {
      "epoch": 9.182879377431906,
      "grad_norm": 0.268795907497406,
      "learning_rate": 0.0004983781660172368,
      "loss": 2.2204,
      "step": 2360
    },
    {
      "epoch": 9.221789883268482,
      "grad_norm": 0.2701951563358307,
      "learning_rate": 0.0004983605663736945,
      "loss": 2.2296,
      "step": 2370
    },
    {
      "epoch": 9.26070038910506,
      "grad_norm": 0.3460206687450409,
      "learning_rate": 0.000498342872065957,
      "loss": 2.2245,
      "step": 2380
    },
    {
      "epoch": 9.299610894941635,
      "grad_norm": 0.2788049876689911,
      "learning_rate": 0.000498325083100769,
      "loss": 2.2302,
      "step": 2390
    },
    {
      "epoch": 9.33852140077821,
      "grad_norm": 0.27169814705848694,
      "learning_rate": 0.0004983071994849106,
      "loss": 2.2381,
      "step": 2400
    },
    {
      "epoch": 9.377431906614786,
      "grad_norm": 0.2843479812145233,
      "learning_rate": 0.0004982892212251984,
      "loss": 2.2151,
      "step": 2410
    },
    {
      "epoch": 9.416342412451362,
      "grad_norm": 0.2649386525154114,
      "learning_rate": 0.0004982711483284849,
      "loss": 2.2408,
      "step": 2420
    },
    {
      "epoch": 9.455252918287938,
      "grad_norm": 0.29879358410835266,
      "learning_rate": 0.0004982529808016587,
      "loss": 2.2147,
      "step": 2430
    },
    {
      "epoch": 9.494163424124514,
      "grad_norm": 0.2384650558233261,
      "learning_rate": 0.0004982347186516443,
      "loss": 2.2144,
      "step": 2440
    },
    {
      "epoch": 9.53307392996109,
      "grad_norm": 0.26309850811958313,
      "learning_rate": 0.0004982163618854028,
      "loss": 2.2296,
      "step": 2450
    },
    {
      "epoch": 9.571984435797665,
      "grad_norm": 0.2693263590335846,
      "learning_rate": 0.0004981979105099307,
      "loss": 2.2282,
      "step": 2460
    },
    {
      "epoch": 9.61089494163424,
      "grad_norm": 0.2857387661933899,
      "learning_rate": 0.0004981793645322609,
      "loss": 2.2421,
      "step": 2470
    },
    {
      "epoch": 9.649805447470817,
      "grad_norm": 0.2622051239013672,
      "learning_rate": 0.0004981607239594625,
      "loss": 2.2239,
      "step": 2480
    },
    {
      "epoch": 9.688715953307392,
      "grad_norm": 0.3111575245857239,
      "learning_rate": 0.0004981419887986401,
      "loss": 2.2463,
      "step": 2490
    },
    {
      "epoch": 9.727626459143968,
      "grad_norm": 0.34685176610946655,
      "learning_rate": 0.0004981231590569351,
      "loss": 2.2236,
      "step": 2500
    },
    {
      "epoch": 9.766536964980546,
      "grad_norm": 0.2939132750034332,
      "learning_rate": 0.0004981042347415244,
      "loss": 2.2257,
      "step": 2510
    },
    {
      "epoch": 9.805447470817121,
      "grad_norm": 0.263369619846344,
      "learning_rate": 0.0004980852158596211,
      "loss": 2.2265,
      "step": 2520
    },
    {
      "epoch": 9.844357976653697,
      "grad_norm": 0.2560364305973053,
      "learning_rate": 0.0004980661024184746,
      "loss": 2.2231,
      "step": 2530
    },
    {
      "epoch": 9.883268482490273,
      "grad_norm": 0.24678905308246613,
      "learning_rate": 0.0004980468944253696,
      "loss": 2.2199,
      "step": 2540
    },
    {
      "epoch": 9.922178988326849,
      "grad_norm": 0.258269727230072,
      "learning_rate": 0.000498027591887628,
      "loss": 2.2246,
      "step": 2550
    },
    {
      "epoch": 9.961089494163424,
      "grad_norm": 0.24733920395374298,
      "learning_rate": 0.0004980081948126066,
      "loss": 2.24,
      "step": 2560
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.41642093658447266,
      "learning_rate": 0.0004979887032076989,
      "loss": 2.2289,
      "step": 2570
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.1227320432662964,
      "eval_runtime": 6.4243,
      "eval_samples_per_second": 3480.989,
      "eval_steps_per_second": 13.698,
      "step": 2570
    },
    {
      "epoch": 10.038910505836576,
      "grad_norm": 0.2703228294849396,
      "learning_rate": 0.0004979691170803342,
      "loss": 2.2185,
      "step": 2580
    },
    {
      "epoch": 10.077821011673151,
      "grad_norm": 0.27380117774009705,
      "learning_rate": 0.0004979494364379779,
      "loss": 2.2195,
      "step": 2590
    },
    {
      "epoch": 10.116731517509727,
      "grad_norm": 0.3350885808467865,
      "learning_rate": 0.0004979296612881313,
      "loss": 2.2146,
      "step": 2600
    },
    {
      "epoch": 10.155642023346303,
      "grad_norm": 0.2688641846179962,
      "learning_rate": 0.0004979097916383321,
      "loss": 2.2187,
      "step": 2610
    },
    {
      "epoch": 10.194552529182879,
      "grad_norm": 0.26759615540504456,
      "learning_rate": 0.0004978898274961534,
      "loss": 2.2171,
      "step": 2620
    },
    {
      "epoch": 10.233463035019454,
      "grad_norm": 0.28584006428718567,
      "learning_rate": 0.000497869768869205,
      "loss": 2.2036,
      "step": 2630
    },
    {
      "epoch": 10.272373540856032,
      "grad_norm": 0.3221796154975891,
      "learning_rate": 0.0004978496157651321,
      "loss": 2.1983,
      "step": 2640
    },
    {
      "epoch": 10.311284046692608,
      "grad_norm": 0.252229779958725,
      "learning_rate": 0.0004978293681916163,
      "loss": 2.219,
      "step": 2650
    },
    {
      "epoch": 10.350194552529183,
      "grad_norm": 0.28493520617485046,
      "learning_rate": 0.000497809026156375,
      "loss": 2.1962,
      "step": 2660
    },
    {
      "epoch": 10.38910505836576,
      "grad_norm": 0.2626427412033081,
      "learning_rate": 0.0004977885896671618,
      "loss": 2.2197,
      "step": 2670
    },
    {
      "epoch": 10.428015564202335,
      "grad_norm": 0.28619253635406494,
      "learning_rate": 0.0004977680587317661,
      "loss": 2.2205,
      "step": 2680
    },
    {
      "epoch": 10.46692607003891,
      "grad_norm": 0.28932222723960876,
      "learning_rate": 0.0004977474333580135,
      "loss": 2.2189,
      "step": 2690
    },
    {
      "epoch": 10.505836575875486,
      "grad_norm": 0.27907508611679077,
      "learning_rate": 0.0004977267135537655,
      "loss": 2.2055,
      "step": 2700
    },
    {
      "epoch": 10.544747081712062,
      "grad_norm": 0.29201287031173706,
      "learning_rate": 0.0004977058993269196,
      "loss": 2.2263,
      "step": 2710
    },
    {
      "epoch": 10.583657587548638,
      "grad_norm": 0.27483928203582764,
      "learning_rate": 0.000497684990685409,
      "loss": 2.2003,
      "step": 2720
    },
    {
      "epoch": 10.622568093385214,
      "grad_norm": 0.25528252124786377,
      "learning_rate": 0.0004976639876372034,
      "loss": 2.2219,
      "step": 2730
    },
    {
      "epoch": 10.66147859922179,
      "grad_norm": 0.29901525378227234,
      "learning_rate": 0.0004976428901903084,
      "loss": 2.2181,
      "step": 2740
    },
    {
      "epoch": 10.700389105058365,
      "grad_norm": 0.26151978969573975,
      "learning_rate": 0.000497621698352765,
      "loss": 2.2033,
      "step": 2750
    },
    {
      "epoch": 10.739299610894943,
      "grad_norm": 0.24982589483261108,
      "learning_rate": 0.000497600412132651,
      "loss": 2.2261,
      "step": 2760
    },
    {
      "epoch": 10.778210116731518,
      "grad_norm": 0.2609434723854065,
      "learning_rate": 0.0004975790315380795,
      "loss": 2.2029,
      "step": 2770
    },
    {
      "epoch": 10.817120622568094,
      "grad_norm": 0.2478034496307373,
      "learning_rate": 0.0004975575565772,
      "loss": 2.2125,
      "step": 2780
    },
    {
      "epoch": 10.85603112840467,
      "grad_norm": 0.26011213660240173,
      "learning_rate": 0.0004975359872581978,
      "loss": 2.2051,
      "step": 2790
    },
    {
      "epoch": 10.894941634241246,
      "grad_norm": 0.25948262214660645,
      "learning_rate": 0.0004975143235892941,
      "loss": 2.2057,
      "step": 2800
    },
    {
      "epoch": 10.933852140077821,
      "grad_norm": 0.2767178416252136,
      "learning_rate": 0.0004974925655787463,
      "loss": 2.1996,
      "step": 2810
    },
    {
      "epoch": 10.972762645914397,
      "grad_norm": 0.24631701409816742,
      "learning_rate": 0.0004974707132348473,
      "loss": 2.2135,
      "step": 2820
    },
    {
      "epoch": 11.0,
      "eval_loss": 1.1178914308547974,
      "eval_runtime": 6.1878,
      "eval_samples_per_second": 3614.029,
      "eval_steps_per_second": 14.221,
      "step": 2827
    },
    {
      "epoch": 11.011673151750973,
      "grad_norm": 0.2667461633682251,
      "learning_rate": 0.0004974487665659268,
      "loss": 2.2162,
      "step": 2830
    },
    {
      "epoch": 11.050583657587548,
      "grad_norm": 0.26570528745651245,
      "learning_rate": 0.0004974267255803493,
      "loss": 2.203,
      "step": 2840
    },
    {
      "epoch": 11.089494163424124,
      "grad_norm": 0.2938839793205261,
      "learning_rate": 0.0004974045902865162,
      "loss": 2.1968,
      "step": 2850
    },
    {
      "epoch": 11.1284046692607,
      "grad_norm": 0.31411945819854736,
      "learning_rate": 0.0004973823606928645,
      "loss": 2.2076,
      "step": 2860
    },
    {
      "epoch": 11.167315175097276,
      "grad_norm": 0.39556074142456055,
      "learning_rate": 0.000497360036807867,
      "loss": 2.205,
      "step": 2870
    },
    {
      "epoch": 11.206225680933851,
      "grad_norm": 0.27575019001960754,
      "learning_rate": 0.0004973376186400328,
      "loss": 2.1957,
      "step": 2880
    },
    {
      "epoch": 11.245136186770427,
      "grad_norm": 0.27273860573768616,
      "learning_rate": 0.0004973151061979065,
      "loss": 2.2046,
      "step": 2890
    },
    {
      "epoch": 11.284046692607005,
      "grad_norm": 0.29691630601882935,
      "learning_rate": 0.0004972924994900691,
      "loss": 2.2083,
      "step": 2900
    },
    {
      "epoch": 11.32295719844358,
      "grad_norm": 0.2668417692184448,
      "learning_rate": 0.000497269798525137,
      "loss": 2.2114,
      "step": 2910
    },
    {
      "epoch": 11.361867704280156,
      "grad_norm": 0.26923078298568726,
      "learning_rate": 0.000497247003311763,
      "loss": 2.1849,
      "step": 2920
    },
    {
      "epoch": 11.400778210116732,
      "grad_norm": 0.26119500398635864,
      "learning_rate": 0.0004972241138586356,
      "loss": 2.2033,
      "step": 2930
    },
    {
      "epoch": 11.439688715953308,
      "grad_norm": 0.26751136779785156,
      "learning_rate": 0.0004972011301744793,
      "loss": 2.2049,
      "step": 2940
    },
    {
      "epoch": 11.478599221789883,
      "grad_norm": 0.264344722032547,
      "learning_rate": 0.0004971780522680546,
      "loss": 2.2012,
      "step": 2950
    },
    {
      "epoch": 11.517509727626459,
      "grad_norm": 0.29254135489463806,
      "learning_rate": 0.0004971548801481575,
      "loss": 2.1835,
      "step": 2960
    },
    {
      "epoch": 11.556420233463035,
      "grad_norm": 0.25876283645629883,
      "learning_rate": 0.0004971316138236202,
      "loss": 2.2145,
      "step": 2970
    },
    {
      "epoch": 11.59533073929961,
      "grad_norm": 0.3080747723579407,
      "learning_rate": 0.0004971082533033111,
      "loss": 2.1982,
      "step": 2980
    },
    {
      "epoch": 11.634241245136186,
      "grad_norm": 0.2814551889896393,
      "learning_rate": 0.0004970847985961341,
      "loss": 2.2075,
      "step": 2990
    },
    {
      "epoch": 11.673151750972762,
      "grad_norm": 0.25602594017982483,
      "learning_rate": 0.0004970612497110289,
      "loss": 2.2121,
      "step": 3000
    },
    {
      "epoch": 11.712062256809338,
      "grad_norm": 0.36767229437828064,
      "learning_rate": 0.0004970376066569716,
      "loss": 2.2003,
      "step": 3010
    },
    {
      "epoch": 11.750972762645915,
      "grad_norm": 0.26241353154182434,
      "learning_rate": 0.0004970138694429737,
      "loss": 2.1954,
      "step": 3020
    },
    {
      "epoch": 11.789883268482491,
      "grad_norm": 0.2871676981449127,
      "learning_rate": 0.0004969900380780829,
      "loss": 2.1914,
      "step": 3030
    },
    {
      "epoch": 11.828793774319067,
      "grad_norm": 0.26169919967651367,
      "learning_rate": 0.0004969661125713826,
      "loss": 2.2018,
      "step": 3040
    },
    {
      "epoch": 11.867704280155642,
      "grad_norm": 0.2842484414577484,
      "learning_rate": 0.0004969420929319921,
      "loss": 2.2051,
      "step": 3050
    },
    {
      "epoch": 11.906614785992218,
      "grad_norm": 0.2653142511844635,
      "learning_rate": 0.0004969179791690668,
      "loss": 2.1907,
      "step": 3060
    },
    {
      "epoch": 11.945525291828794,
      "grad_norm": 0.27340632677078247,
      "learning_rate": 0.0004968937712917978,
      "loss": 2.1903,
      "step": 3070
    },
    {
      "epoch": 11.98443579766537,
      "grad_norm": 0.290507435798645,
      "learning_rate": 0.0004968694693094119,
      "loss": 2.1817,
      "step": 3080
    },
    {
      "epoch": 12.0,
      "eval_loss": 1.1151015758514404,
      "eval_runtime": 6.2368,
      "eval_samples_per_second": 3585.626,
      "eval_steps_per_second": 14.11,
      "step": 3084
    },
    {
      "epoch": 12.023346303501945,
      "grad_norm": 0.25336071848869324,
      "learning_rate": 0.0004968450732311722,
      "loss": 2.1978,
      "step": 3090
    },
    {
      "epoch": 12.062256809338521,
      "grad_norm": 0.2662050127983093,
      "learning_rate": 0.0004968205830663772,
      "loss": 2.1796,
      "step": 3100
    },
    {
      "epoch": 12.101167315175097,
      "grad_norm": 0.3265174925327301,
      "learning_rate": 0.0004967959988243616,
      "loss": 2.1677,
      "step": 3110
    },
    {
      "epoch": 12.140077821011673,
      "grad_norm": 0.29213660955429077,
      "learning_rate": 0.0004967713205144958,
      "loss": 2.1807,
      "step": 3120
    },
    {
      "epoch": 12.178988326848248,
      "grad_norm": 0.25267329812049866,
      "learning_rate": 0.0004967465481461862,
      "loss": 2.1913,
      "step": 3130
    },
    {
      "epoch": 12.217898832684824,
      "grad_norm": 0.2780775725841522,
      "learning_rate": 0.0004967216817288747,
      "loss": 2.196,
      "step": 3140
    },
    {
      "epoch": 12.2568093385214,
      "grad_norm": 0.27140969038009644,
      "learning_rate": 0.0004966967212720396,
      "loss": 2.1959,
      "step": 3150
    },
    {
      "epoch": 12.295719844357977,
      "grad_norm": 0.40886127948760986,
      "learning_rate": 0.0004966716667851945,
      "loss": 2.1898,
      "step": 3160
    },
    {
      "epoch": 12.334630350194553,
      "grad_norm": 0.321241557598114,
      "learning_rate": 0.0004966465182778891,
      "loss": 2.1819,
      "step": 3170
    },
    {
      "epoch": 12.373540856031129,
      "grad_norm": 0.2545238435268402,
      "learning_rate": 0.0004966212757597091,
      "loss": 2.1924,
      "step": 3180
    },
    {
      "epoch": 12.412451361867705,
      "grad_norm": 0.27874743938446045,
      "learning_rate": 0.0004965959392402756,
      "loss": 2.2009,
      "step": 3190
    },
    {
      "epoch": 12.45136186770428,
      "grad_norm": 0.26083922386169434,
      "learning_rate": 0.0004965705087292459,
      "loss": 2.1862,
      "step": 3200
    },
    {
      "epoch": 12.490272373540856,
      "grad_norm": 0.28363409638404846,
      "learning_rate": 0.0004965449842363129,
      "loss": 2.1982,
      "step": 3210
    },
    {
      "epoch": 12.529182879377432,
      "grad_norm": 0.2690861225128174,
      "learning_rate": 0.0004965193657712057,
      "loss": 2.2008,
      "step": 3220
    },
    {
      "epoch": 12.568093385214008,
      "grad_norm": 0.2509395480155945,
      "learning_rate": 0.0004964936533436886,
      "loss": 2.2018,
      "step": 3230
    },
    {
      "epoch": 12.607003891050583,
      "grad_norm": 0.29666751623153687,
      "learning_rate": 0.0004964678469635622,
      "loss": 2.1781,
      "step": 3240
    },
    {
      "epoch": 12.645914396887159,
      "grad_norm": 0.2815932035446167,
      "learning_rate": 0.0004964419466406628,
      "loss": 2.1838,
      "step": 3250
    },
    {
      "epoch": 12.684824902723735,
      "grad_norm": 0.29871445894241333,
      "learning_rate": 0.0004964159523848624,
      "loss": 2.199,
      "step": 3260
    },
    {
      "epoch": 12.72373540856031,
      "grad_norm": 0.28068649768829346,
      "learning_rate": 0.000496389864206069,
      "loss": 2.1779,
      "step": 3270
    },
    {
      "epoch": 12.762645914396888,
      "grad_norm": 0.258105993270874,
      "learning_rate": 0.0004963636821142261,
      "loss": 2.1862,
      "step": 3280
    },
    {
      "epoch": 12.801556420233464,
      "grad_norm": 0.27259567379951477,
      "learning_rate": 0.0004963374061193133,
      "loss": 2.193,
      "step": 3290
    },
    {
      "epoch": 12.84046692607004,
      "grad_norm": 0.3028172254562378,
      "learning_rate": 0.0004963110362313459,
      "loss": 2.1911,
      "step": 3300
    },
    {
      "epoch": 12.879377431906615,
      "grad_norm": 0.31416961550712585,
      "learning_rate": 0.0004962845724603747,
      "loss": 2.1762,
      "step": 3310
    },
    {
      "epoch": 12.918287937743191,
      "grad_norm": 0.28152307868003845,
      "learning_rate": 0.0004962580148164867,
      "loss": 2.1741,
      "step": 3320
    },
    {
      "epoch": 12.957198443579767,
      "grad_norm": 0.2987872064113617,
      "learning_rate": 0.0004962313633098045,
      "loss": 2.1873,
      "step": 3330
    },
    {
      "epoch": 12.996108949416342,
      "grad_norm": 0.26219066977500916,
      "learning_rate": 0.0004962046179504867,
      "loss": 2.1919,
      "step": 3340
    },
    {
      "epoch": 13.0,
      "eval_loss": 1.1104156970977783,
      "eval_runtime": 6.1874,
      "eval_samples_per_second": 3614.273,
      "eval_steps_per_second": 14.222,
      "step": 3341
    },
    {
      "epoch": 13.035019455252918,
      "grad_norm": 0.25147053599357605,
      "learning_rate": 0.0004961777787487271,
      "loss": 2.1769,
      "step": 3350
    },
    {
      "epoch": 13.073929961089494,
      "grad_norm": 0.2565317451953888,
      "learning_rate": 0.0004961508457147558,
      "loss": 2.1825,
      "step": 3360
    },
    {
      "epoch": 13.11284046692607,
      "grad_norm": 0.2694418728351593,
      "learning_rate": 0.0004961238188588384,
      "loss": 2.1669,
      "step": 3370
    },
    {
      "epoch": 13.151750972762645,
      "grad_norm": 0.26905813813209534,
      "learning_rate": 0.0004960966981912765,
      "loss": 2.179,
      "step": 3380
    },
    {
      "epoch": 13.190661478599221,
      "grad_norm": 0.2939467430114746,
      "learning_rate": 0.0004960694837224073,
      "loss": 2.183,
      "step": 3390
    },
    {
      "epoch": 13.229571984435797,
      "grad_norm": 0.27619192004203796,
      "learning_rate": 0.0004960421754626038,
      "loss": 2.1882,
      "step": 3400
    },
    {
      "epoch": 13.268482490272374,
      "grad_norm": 0.2891333997249603,
      "learning_rate": 0.0004960147734222745,
      "loss": 2.1812,
      "step": 3410
    },
    {
      "epoch": 13.30739299610895,
      "grad_norm": 0.24556128680706024,
      "learning_rate": 0.0004959872776118641,
      "loss": 2.1709,
      "step": 3420
    },
    {
      "epoch": 13.346303501945526,
      "grad_norm": 0.2981877028942108,
      "learning_rate": 0.0004959596880418526,
      "loss": 2.1845,
      "step": 3430
    },
    {
      "epoch": 13.385214007782102,
      "grad_norm": 0.2631285488605499,
      "learning_rate": 0.0004959320047227561,
      "loss": 2.1704,
      "step": 3440
    },
    {
      "epoch": 13.424124513618677,
      "grad_norm": 0.2724960744380951,
      "learning_rate": 0.0004959042276651263,
      "loss": 2.174,
      "step": 3450
    },
    {
      "epoch": 13.463035019455253,
      "grad_norm": 0.2890663743019104,
      "learning_rate": 0.0004958763568795503,
      "loss": 2.1823,
      "step": 3460
    },
    {
      "epoch": 13.501945525291829,
      "grad_norm": 0.300791472196579,
      "learning_rate": 0.0004958483923766515,
      "loss": 2.1731,
      "step": 3470
    },
    {
      "epoch": 13.540856031128405,
      "grad_norm": 0.2666970491409302,
      "learning_rate": 0.0004958203341670888,
      "loss": 2.177,
      "step": 3480
    },
    {
      "epoch": 13.57976653696498,
      "grad_norm": 0.2919989228248596,
      "learning_rate": 0.0004957921822615565,
      "loss": 2.1762,
      "step": 3490
    },
    {
      "epoch": 13.618677042801556,
      "grad_norm": 0.2771342694759369,
      "learning_rate": 0.0004957639366707851,
      "loss": 2.1798,
      "step": 3500
    },
    {
      "epoch": 13.657587548638132,
      "grad_norm": 0.26898398995399475,
      "learning_rate": 0.0004957355974055405,
      "loss": 2.1852,
      "step": 3510
    },
    {
      "epoch": 13.696498054474707,
      "grad_norm": 0.312147855758667,
      "learning_rate": 0.0004957071644766244,
      "loss": 2.1825,
      "step": 3520
    },
    {
      "epoch": 13.735408560311285,
      "grad_norm": 0.28389972448349,
      "learning_rate": 0.0004956786378948742,
      "loss": 2.1732,
      "step": 3530
    },
    {
      "epoch": 13.77431906614786,
      "grad_norm": 0.31256383657455444,
      "learning_rate": 0.0004956500176711629,
      "loss": 2.1761,
      "step": 3540
    },
    {
      "epoch": 13.813229571984436,
      "grad_norm": 0.27135229110717773,
      "learning_rate": 0.0004956213038163995,
      "loss": 2.1786,
      "step": 3550
    },
    {
      "epoch": 13.852140077821012,
      "grad_norm": 0.2778770923614502,
      "learning_rate": 0.0004955924963415281,
      "loss": 2.1867,
      "step": 3560
    },
    {
      "epoch": 13.891050583657588,
      "grad_norm": 0.29842856526374817,
      "learning_rate": 0.0004955635952575292,
      "loss": 2.1801,
      "step": 3570
    },
    {
      "epoch": 13.929961089494164,
      "grad_norm": 0.29940202832221985,
      "learning_rate": 0.0004955346005754186,
      "loss": 2.1651,
      "step": 3580
    },
    {
      "epoch": 13.96887159533074,
      "grad_norm": 0.24821661412715912,
      "learning_rate": 0.0004955055123062475,
      "loss": 2.1925,
      "step": 3590
    },
    {
      "epoch": 14.0,
      "eval_loss": 1.109405755996704,
      "eval_runtime": 6.1833,
      "eval_samples_per_second": 3616.671,
      "eval_steps_per_second": 14.232,
      "step": 3598
    },
    {
      "epoch": 14.007782101167315,
      "grad_norm": 0.27562516927719116,
      "learning_rate": 0.0004954763304611034,
      "loss": 2.1722,
      "step": 3600
    },
    {
      "epoch": 14.04669260700389,
      "grad_norm": 0.31015560030937195,
      "learning_rate": 0.000495447055051109,
      "loss": 2.184,
      "step": 3610
    },
    {
      "epoch": 14.085603112840467,
      "grad_norm": 0.2834100127220154,
      "learning_rate": 0.0004954176860874228,
      "loss": 2.1756,
      "step": 3620
    },
    {
      "epoch": 14.124513618677042,
      "grad_norm": 0.2692784368991852,
      "learning_rate": 0.0004953882235812391,
      "loss": 2.1587,
      "step": 3630
    },
    {
      "epoch": 14.163424124513618,
      "grad_norm": 0.33536508679389954,
      "learning_rate": 0.0004953586675437875,
      "loss": 2.1582,
      "step": 3640
    },
    {
      "epoch": 14.202334630350194,
      "grad_norm": 0.2883826494216919,
      "learning_rate": 0.0004953290179863336,
      "loss": 2.1527,
      "step": 3650
    },
    {
      "epoch": 14.24124513618677,
      "grad_norm": 0.27374354004859924,
      "learning_rate": 0.0004952992749201786,
      "loss": 2.1682,
      "step": 3660
    },
    {
      "epoch": 14.280155642023347,
      "grad_norm": 0.26838651299476624,
      "learning_rate": 0.000495269438356659,
      "loss": 2.1691,
      "step": 3670
    },
    {
      "epoch": 14.319066147859923,
      "grad_norm": 0.28226831555366516,
      "learning_rate": 0.0004952395083071475,
      "loss": 2.1735,
      "step": 3680
    },
    {
      "epoch": 14.357976653696499,
      "grad_norm": 0.2677221894264221,
      "learning_rate": 0.000495209484783052,
      "loss": 2.1757,
      "step": 3690
    },
    {
      "epoch": 14.396887159533074,
      "grad_norm": 0.30172035098075867,
      "learning_rate": 0.000495179367795816,
      "loss": 2.1696,
      "step": 3700
    },
    {
      "epoch": 14.43579766536965,
      "grad_norm": 0.2852126359939575,
      "learning_rate": 0.0004951491573569191,
      "loss": 2.1744,
      "step": 3710
    },
    {
      "epoch": 14.474708171206226,
      "grad_norm": 0.26754680275917053,
      "learning_rate": 0.0004951188534778758,
      "loss": 2.1716,
      "step": 3720
    },
    {
      "epoch": 14.513618677042802,
      "grad_norm": 0.26737263798713684,
      "learning_rate": 0.000495088456170237,
      "loss": 2.1611,
      "step": 3730
    },
    {
      "epoch": 14.552529182879377,
      "grad_norm": 0.2893199324607849,
      "learning_rate": 0.0004950579654455886,
      "loss": 2.1812,
      "step": 3740
    },
    {
      "epoch": 14.591439688715953,
      "grad_norm": 0.29701775312423706,
      "learning_rate": 0.0004950273813155524,
      "loss": 2.1608,
      "step": 3750
    },
    {
      "epoch": 14.630350194552529,
      "grad_norm": 0.2510831654071808,
      "learning_rate": 0.0004949967037917857,
      "loss": 2.1641,
      "step": 3760
    },
    {
      "epoch": 14.669260700389104,
      "grad_norm": 0.2532551884651184,
      "learning_rate": 0.0004949659328859815,
      "loss": 2.1738,
      "step": 3770
    },
    {
      "epoch": 14.70817120622568,
      "grad_norm": 0.29615727066993713,
      "learning_rate": 0.0004949350686098682,
      "loss": 2.1807,
      "step": 3780
    },
    {
      "epoch": 14.747081712062258,
      "grad_norm": 0.2832369804382324,
      "learning_rate": 0.00049490411097521,
      "loss": 2.169,
      "step": 3790
    },
    {
      "epoch": 14.785992217898833,
      "grad_norm": 0.2835540771484375,
      "learning_rate": 0.0004948730599938066,
      "loss": 2.1735,
      "step": 3800
    },
    {
      "epoch": 14.82490272373541,
      "grad_norm": 0.2752859890460968,
      "learning_rate": 0.0004948419156774933,
      "loss": 2.1653,
      "step": 3810
    },
    {
      "epoch": 14.863813229571985,
      "grad_norm": 0.27806371450424194,
      "learning_rate": 0.000494810678038141,
      "loss": 2.1791,
      "step": 3820
    },
    {
      "epoch": 14.90272373540856,
      "grad_norm": 0.303785502910614,
      "learning_rate": 0.0004947793470876559,
      "loss": 2.1717,
      "step": 3830
    },
    {
      "epoch": 14.941634241245136,
      "grad_norm": 0.30578815937042236,
      "learning_rate": 0.0004947479228379802,
      "loss": 2.1701,
      "step": 3840
    },
    {
      "epoch": 14.980544747081712,
      "grad_norm": 0.2639409005641937,
      "learning_rate": 0.0004947164053010913,
      "loss": 2.1829,
      "step": 3850
    },
    {
      "epoch": 15.0,
      "eval_loss": 1.1075340509414673,
      "eval_runtime": 6.4033,
      "eval_samples_per_second": 3492.407,
      "eval_steps_per_second": 13.743,
      "step": 3855
    },
    {
      "epoch": 15.019455252918288,
      "grad_norm": 0.27774232625961304,
      "learning_rate": 0.0004946847944890025,
      "loss": 2.1704,
      "step": 3860
    },
    {
      "epoch": 15.058365758754864,
      "grad_norm": 0.2943687438964844,
      "learning_rate": 0.0004946530904137623,
      "loss": 2.1656,
      "step": 3870
    },
    {
      "epoch": 15.09727626459144,
      "grad_norm": 0.2671329379081726,
      "learning_rate": 0.0004946212930874549,
      "loss": 2.1583,
      "step": 3880
    },
    {
      "epoch": 15.136186770428015,
      "grad_norm": 0.27264299988746643,
      "learning_rate": 0.0004945894025222002,
      "loss": 2.1674,
      "step": 3890
    },
    {
      "epoch": 15.17509727626459,
      "grad_norm": 0.300164133310318,
      "learning_rate": 0.0004945574187301534,
      "loss": 2.1735,
      "step": 3900
    },
    {
      "epoch": 15.214007782101167,
      "grad_norm": 0.30449479818344116,
      "learning_rate": 0.0004945253417235053,
      "loss": 2.174,
      "step": 3910
    },
    {
      "epoch": 15.252918287937742,
      "grad_norm": 0.27828988432884216,
      "learning_rate": 0.0004944931715144822,
      "loss": 2.167,
      "step": 3920
    },
    {
      "epoch": 15.29182879377432,
      "grad_norm": 0.2923029959201813,
      "learning_rate": 0.0004944609081153461,
      "loss": 2.1658,
      "step": 3930
    },
    {
      "epoch": 15.330739299610896,
      "grad_norm": 0.2846859097480774,
      "learning_rate": 0.0004944285515383944,
      "loss": 2.1607,
      "step": 3940
    },
    {
      "epoch": 15.369649805447471,
      "grad_norm": 0.26905688643455505,
      "learning_rate": 0.0004943961017959599,
      "loss": 2.1589,
      "step": 3950
    },
    {
      "epoch": 15.408560311284047,
      "grad_norm": 0.28229832649230957,
      "learning_rate": 0.0004943635589004111,
      "loss": 2.1519,
      "step": 3960
    },
    {
      "epoch": 15.447470817120623,
      "grad_norm": 0.28961777687072754,
      "learning_rate": 0.000494330922864152,
      "loss": 2.1555,
      "step": 3970
    },
    {
      "epoch": 15.486381322957198,
      "grad_norm": 0.2688402235507965,
      "learning_rate": 0.0004942981936996219,
      "loss": 2.1561,
      "step": 3980
    },
    {
      "epoch": 15.525291828793774,
      "grad_norm": 0.30490195751190186,
      "learning_rate": 0.0004942653714192957,
      "loss": 2.1622,
      "step": 3990
    },
    {
      "epoch": 15.56420233463035,
      "grad_norm": 0.3102216124534607,
      "learning_rate": 0.000494232456035684,
      "loss": 2.1525,
      "step": 4000
    },
    {
      "epoch": 15.603112840466926,
      "grad_norm": 0.30393412709236145,
      "learning_rate": 0.0004941994475613326,
      "loss": 2.1741,
      "step": 4010
    },
    {
      "epoch": 15.642023346303501,
      "grad_norm": 0.2757686376571655,
      "learning_rate": 0.0004941663460088228,
      "loss": 2.1691,
      "step": 4020
    },
    {
      "epoch": 15.680933852140077,
      "grad_norm": 0.27600201964378357,
      "learning_rate": 0.0004941331513907717,
      "loss": 2.1624,
      "step": 4030
    },
    {
      "epoch": 15.719844357976653,
      "grad_norm": 0.25180622935295105,
      "learning_rate": 0.0004940998637198312,
      "loss": 2.164,
      "step": 4040
    },
    {
      "epoch": 15.75875486381323,
      "grad_norm": 0.29844921827316284,
      "learning_rate": 0.0004940664830086897,
      "loss": 2.1648,
      "step": 4050
    },
    {
      "epoch": 15.797665369649806,
      "grad_norm": 0.28184106945991516,
      "learning_rate": 0.0004940330092700701,
      "loss": 2.1756,
      "step": 4060
    },
    {
      "epoch": 15.836575875486382,
      "grad_norm": 0.27657657861709595,
      "learning_rate": 0.0004939994425167311,
      "loss": 2.1379,
      "step": 4070
    },
    {
      "epoch": 15.875486381322958,
      "grad_norm": 0.3648754954338074,
      "learning_rate": 0.000493965782761467,
      "loss": 2.1636,
      "step": 4080
    },
    {
      "epoch": 15.914396887159533,
      "grad_norm": 0.310217946767807,
      "learning_rate": 0.0004939320300171075,
      "loss": 2.1674,
      "step": 4090
    },
    {
      "epoch": 15.95330739299611,
      "grad_norm": 0.2749623656272888,
      "learning_rate": 0.0004938981842965176,
      "loss": 2.1531,
      "step": 4100
    },
    {
      "epoch": 15.992217898832685,
      "grad_norm": 0.38321468234062195,
      "learning_rate": 0.0004938642456125975,
      "loss": 2.163,
      "step": 4110
    },
    {
      "epoch": 16.0,
      "eval_loss": 1.1048952341079712,
      "eval_runtime": 6.1932,
      "eval_samples_per_second": 3610.867,
      "eval_steps_per_second": 14.209,
      "step": 4112
    },
    {
      "epoch": 16.03112840466926,
      "grad_norm": 0.2899002730846405,
      "learning_rate": 0.0004938302139782837,
      "loss": 2.1615,
      "step": 4120
    },
    {
      "epoch": 16.070038910505836,
      "grad_norm": 0.2931850850582123,
      "learning_rate": 0.0004937960894065472,
      "loss": 2.1509,
      "step": 4130
    },
    {
      "epoch": 16.108949416342412,
      "grad_norm": 0.41094979643821716,
      "learning_rate": 0.0004937618719103949,
      "loss": 2.1601,
      "step": 4140
    },
    {
      "epoch": 16.147859922178988,
      "grad_norm": 0.2882039546966553,
      "learning_rate": 0.0004937275615028691,
      "loss": 2.1589,
      "step": 4150
    },
    {
      "epoch": 16.186770428015564,
      "grad_norm": 0.2832862138748169,
      "learning_rate": 0.0004936931581970472,
      "loss": 2.1686,
      "step": 4160
    },
    {
      "epoch": 16.22568093385214,
      "grad_norm": 0.2924655079841614,
      "learning_rate": 0.0004936586620060423,
      "loss": 2.1548,
      "step": 4170
    },
    {
      "epoch": 16.264591439688715,
      "grad_norm": 0.3087724447250366,
      "learning_rate": 0.0004936240729430031,
      "loss": 2.1678,
      "step": 4180
    },
    {
      "epoch": 16.30350194552529,
      "grad_norm": 0.34348809719085693,
      "learning_rate": 0.0004935893910211132,
      "loss": 2.1478,
      "step": 4190
    },
    {
      "epoch": 16.342412451361866,
      "grad_norm": 0.3041517734527588,
      "learning_rate": 0.0004935546162535919,
      "loss": 2.1644,
      "step": 4200
    },
    {
      "epoch": 16.381322957198442,
      "grad_norm": 0.29087817668914795,
      "learning_rate": 0.0004935197486536937,
      "loss": 2.1553,
      "step": 4210
    },
    {
      "epoch": 16.420233463035018,
      "grad_norm": 0.31476593017578125,
      "learning_rate": 0.0004934847882347088,
      "loss": 2.1512,
      "step": 4220
    },
    {
      "epoch": 16.459143968871594,
      "grad_norm": 0.2738117277622223,
      "learning_rate": 0.0004934497350099625,
      "loss": 2.1431,
      "step": 4230
    },
    {
      "epoch": 16.49805447470817,
      "grad_norm": 0.2784726321697235,
      "learning_rate": 0.0004934145889928155,
      "loss": 2.168,
      "step": 4240
    },
    {
      "epoch": 16.53696498054475,
      "grad_norm": 0.28861597180366516,
      "learning_rate": 0.000493379350196664,
      "loss": 2.1531,
      "step": 4250
    },
    {
      "epoch": 16.575875486381324,
      "grad_norm": 0.28125956654548645,
      "learning_rate": 0.0004933440186349395,
      "loss": 2.1655,
      "step": 4260
    },
    {
      "epoch": 16.6147859922179,
      "grad_norm": 0.2888078987598419,
      "learning_rate": 0.0004933085943211087,
      "loss": 2.1543,
      "step": 4270
    },
    {
      "epoch": 16.653696498054476,
      "grad_norm": 0.306439071893692,
      "learning_rate": 0.0004932730772686741,
      "loss": 2.1529,
      "step": 4280
    },
    {
      "epoch": 16.69260700389105,
      "grad_norm": 0.2933623492717743,
      "learning_rate": 0.0004932374674911729,
      "loss": 2.179,
      "step": 4290
    },
    {
      "epoch": 16.731517509727627,
      "grad_norm": 0.2810063362121582,
      "learning_rate": 0.0004932017650021783,
      "loss": 2.168,
      "step": 4300
    },
    {
      "epoch": 16.770428015564203,
      "grad_norm": 0.28578677773475647,
      "learning_rate": 0.0004931659698152982,
      "loss": 2.1509,
      "step": 4310
    },
    {
      "epoch": 16.80933852140078,
      "grad_norm": 0.30225786566734314,
      "learning_rate": 0.0004931300819441765,
      "loss": 2.1468,
      "step": 4320
    },
    {
      "epoch": 16.848249027237355,
      "grad_norm": 0.29042088985443115,
      "learning_rate": 0.0004930941014024919,
      "loss": 2.162,
      "step": 4330
    },
    {
      "epoch": 16.88715953307393,
      "grad_norm": 0.2907184660434723,
      "learning_rate": 0.0004930580282039586,
      "loss": 2.1607,
      "step": 4340
    },
    {
      "epoch": 16.926070038910506,
      "grad_norm": 0.39885300397872925,
      "learning_rate": 0.0004930218623623263,
      "loss": 2.1499,
      "step": 4350
    },
    {
      "epoch": 16.964980544747082,
      "grad_norm": 0.29131031036376953,
      "learning_rate": 0.0004929856038913795,
      "loss": 2.15,
      "step": 4360
    },
    {
      "epoch": 17.0,
      "eval_loss": 1.103155255317688,
      "eval_runtime": 6.1785,
      "eval_samples_per_second": 3619.476,
      "eval_steps_per_second": 14.243,
      "step": 4369
    },
    {
      "epoch": 17.003891050583658,
      "grad_norm": 0.2891359031200409,
      "learning_rate": 0.0004929492528049388,
      "loss": 2.1443,
      "step": 4370
    },
    {
      "epoch": 17.042801556420233,
      "grad_norm": 0.28370919823646545,
      "learning_rate": 0.0004929128091168592,
      "loss": 2.1528,
      "step": 4380
    },
    {
      "epoch": 17.08171206225681,
      "grad_norm": 0.3004554510116577,
      "learning_rate": 0.0004928762728410316,
      "loss": 2.1464,
      "step": 4390
    },
    {
      "epoch": 17.120622568093385,
      "grad_norm": 0.2767234742641449,
      "learning_rate": 0.0004928396439913823,
      "loss": 2.149,
      "step": 4400
    },
    {
      "epoch": 17.15953307392996,
      "grad_norm": 0.31651145219802856,
      "learning_rate": 0.0004928029225818722,
      "loss": 2.1448,
      "step": 4410
    },
    {
      "epoch": 17.198443579766536,
      "grad_norm": 0.32852885127067566,
      "learning_rate": 0.0004927661086264982,
      "loss": 2.1456,
      "step": 4420
    },
    {
      "epoch": 17.237354085603112,
      "grad_norm": 0.2914060652256012,
      "learning_rate": 0.000492729202139292,
      "loss": 2.1462,
      "step": 4430
    },
    {
      "epoch": 17.276264591439688,
      "grad_norm": 0.2824475169181824,
      "learning_rate": 0.0004926922031343209,
      "loss": 2.1456,
      "step": 4440
    },
    {
      "epoch": 17.315175097276263,
      "grad_norm": 0.29002323746681213,
      "learning_rate": 0.000492655111625687,
      "loss": 2.144,
      "step": 4450
    },
    {
      "epoch": 17.35408560311284,
      "grad_norm": 0.2926461100578308,
      "learning_rate": 0.0004926179276275283,
      "loss": 2.1438,
      "step": 4460
    },
    {
      "epoch": 17.392996108949415,
      "grad_norm": 0.3105069398880005,
      "learning_rate": 0.0004925806511540175,
      "loss": 2.1534,
      "step": 4470
    },
    {
      "epoch": 17.43190661478599,
      "grad_norm": 0.3070802092552185,
      "learning_rate": 0.0004925432822193629,
      "loss": 2.1543,
      "step": 4480
    },
    {
      "epoch": 17.470817120622566,
      "grad_norm": 0.3197941184043884,
      "learning_rate": 0.0004925058208378078,
      "loss": 2.1492,
      "step": 4490
    },
    {
      "epoch": 17.509727626459146,
      "grad_norm": 0.2507922053337097,
      "learning_rate": 0.000492468267023631,
      "loss": 2.1413,
      "step": 4500
    },
    {
      "epoch": 17.54863813229572,
      "grad_norm": 0.31249573826789856,
      "learning_rate": 0.0004924306207911462,
      "loss": 2.1428,
      "step": 4510
    },
    {
      "epoch": 17.587548638132297,
      "grad_norm": 0.28460636734962463,
      "learning_rate": 0.0004923928821547025,
      "loss": 2.1509,
      "step": 4520
    },
    {
      "epoch": 17.626459143968873,
      "grad_norm": 0.2644801735877991,
      "learning_rate": 0.0004923550511286844,
      "loss": 2.147,
      "step": 4530
    },
    {
      "epoch": 17.66536964980545,
      "grad_norm": 0.2862177789211273,
      "learning_rate": 0.0004923171277275112,
      "loss": 2.1562,
      "step": 4540
    },
    {
      "epoch": 17.704280155642024,
      "grad_norm": 0.31304824352264404,
      "learning_rate": 0.0004922791119656378,
      "loss": 2.1585,
      "step": 4550
    },
    {
      "epoch": 17.7431906614786,
      "grad_norm": 0.3226660192012787,
      "learning_rate": 0.0004922410038575541,
      "loss": 2.1437,
      "step": 4560
    },
    {
      "epoch": 17.782101167315176,
      "grad_norm": 0.27930206060409546,
      "learning_rate": 0.0004922028034177853,
      "loss": 2.1573,
      "step": 4570
    },
    {
      "epoch": 17.82101167315175,
      "grad_norm": 0.2729235291481018,
      "learning_rate": 0.0004921645106608916,
      "loss": 2.1581,
      "step": 4580
    },
    {
      "epoch": 17.859922178988327,
      "grad_norm": 0.26319044828414917,
      "learning_rate": 0.0004921261256014686,
      "loss": 2.1348,
      "step": 4590
    },
    {
      "epoch": 17.898832684824903,
      "grad_norm": 0.26662689447402954,
      "learning_rate": 0.0004920876482541471,
      "loss": 2.1577,
      "step": 4600
    },
    {
      "epoch": 17.93774319066148,
      "grad_norm": 0.3084677457809448,
      "learning_rate": 0.0004920490786335928,
      "loss": 2.1672,
      "step": 4610
    },
    {
      "epoch": 17.976653696498055,
      "grad_norm": 0.2880820631980896,
      "learning_rate": 0.000492010416754507,
      "loss": 2.1525,
      "step": 4620
    },
    {
      "epoch": 18.0,
      "eval_loss": 1.1024560928344727,
      "eval_runtime": 6.1852,
      "eval_samples_per_second": 3615.569,
      "eval_steps_per_second": 14.228,
      "step": 4626
    },
    {
      "epoch": 18.01556420233463,
      "grad_norm": 0.29098397493362427,
      "learning_rate": 0.0004919716626316257,
      "loss": 2.1503,
      "step": 4630
    },
    {
      "epoch": 18.054474708171206,
      "grad_norm": 0.2800155580043793,
      "learning_rate": 0.0004919328162797204,
      "loss": 2.1512,
      "step": 4640
    },
    {
      "epoch": 18.09338521400778,
      "grad_norm": 0.3137517273426056,
      "learning_rate": 0.0004918938777135975,
      "loss": 2.1334,
      "step": 4650
    },
    {
      "epoch": 18.132295719844358,
      "grad_norm": 0.3331289291381836,
      "learning_rate": 0.0004918548469480988,
      "loss": 2.1324,
      "step": 4660
    },
    {
      "epoch": 18.171206225680933,
      "grad_norm": 0.28466877341270447,
      "learning_rate": 0.0004918157239981011,
      "loss": 2.1298,
      "step": 4670
    },
    {
      "epoch": 18.21011673151751,
      "grad_norm": 0.30600520968437195,
      "learning_rate": 0.0004917765088785163,
      "loss": 2.1419,
      "step": 4680
    },
    {
      "epoch": 18.249027237354085,
      "grad_norm": 0.3050651550292969,
      "learning_rate": 0.0004917372016042916,
      "loss": 2.1361,
      "step": 4690
    },
    {
      "epoch": 18.28793774319066,
      "grad_norm": 0.3194796144962311,
      "learning_rate": 0.0004916978021904092,
      "loss": 2.1486,
      "step": 4700
    },
    {
      "epoch": 18.326848249027236,
      "grad_norm": 0.29581117630004883,
      "learning_rate": 0.0004916583106518862,
      "loss": 2.147,
      "step": 4710
    },
    {
      "epoch": 18.365758754863812,
      "grad_norm": 0.31266582012176514,
      "learning_rate": 0.0004916187270037755,
      "loss": 2.1386,
      "step": 4720
    },
    {
      "epoch": 18.404669260700388,
      "grad_norm": 0.2977710962295532,
      "learning_rate": 0.0004915790512611642,
      "loss": 2.1339,
      "step": 4730
    },
    {
      "epoch": 18.443579766536963,
      "grad_norm": 0.2798180878162384,
      "learning_rate": 0.0004915392834391752,
      "loss": 2.1386,
      "step": 4740
    },
    {
      "epoch": 18.48249027237354,
      "grad_norm": 0.283759206533432,
      "learning_rate": 0.0004914994235529662,
      "loss": 2.1496,
      "step": 4750
    },
    {
      "epoch": 18.52140077821012,
      "grad_norm": 0.299131840467453,
      "learning_rate": 0.0004914594716177301,
      "loss": 2.156,
      "step": 4760
    },
    {
      "epoch": 18.560311284046694,
      "grad_norm": 0.2698080241680145,
      "learning_rate": 0.0004914194276486948,
      "loss": 2.1366,
      "step": 4770
    },
    {
      "epoch": 18.59922178988327,
      "grad_norm": 0.28356632590293884,
      "learning_rate": 0.0004913792916611232,
      "loss": 2.1394,
      "step": 4780
    },
    {
      "epoch": 18.638132295719846,
      "grad_norm": 0.2882935404777527,
      "learning_rate": 0.0004913390636703135,
      "loss": 2.1547,
      "step": 4790
    },
    {
      "epoch": 18.67704280155642,
      "grad_norm": 0.28718042373657227,
      "learning_rate": 0.0004912987436915989,
      "loss": 2.1477,
      "step": 4800
    },
    {
      "epoch": 18.715953307392997,
      "grad_norm": 0.3450605273246765,
      "learning_rate": 0.0004912583317403476,
      "loss": 2.1486,
      "step": 4810
    },
    {
      "epoch": 18.754863813229573,
      "grad_norm": 0.3006226122379303,
      "learning_rate": 0.0004912178278319627,
      "loss": 2.1534,
      "step": 4820
    },
    {
      "epoch": 18.79377431906615,
      "grad_norm": 0.27299684286117554,
      "learning_rate": 0.0004911772319818827,
      "loss": 2.149,
      "step": 4830
    },
    {
      "epoch": 18.832684824902724,
      "grad_norm": 0.29694780707359314,
      "learning_rate": 0.0004911365442055809,
      "loss": 2.1568,
      "step": 4840
    },
    {
      "epoch": 18.8715953307393,
      "grad_norm": 0.3035542964935303,
      "learning_rate": 0.0004910957645185656,
      "loss": 2.1599,
      "step": 4850
    },
    {
      "epoch": 18.910505836575876,
      "grad_norm": 0.28410637378692627,
      "learning_rate": 0.0004910548929363805,
      "loss": 2.143,
      "step": 4860
    },
    {
      "epoch": 18.94941634241245,
      "grad_norm": 0.34314629435539246,
      "learning_rate": 0.0004910139294746037,
      "loss": 2.1426,
      "step": 4870
    },
    {
      "epoch": 18.988326848249027,
      "grad_norm": 0.2877053916454315,
      "learning_rate": 0.0004909728741488491,
      "loss": 2.1502,
      "step": 4880
    },
    {
      "epoch": 19.0,
      "eval_loss": 1.1003618240356445,
      "eval_runtime": 6.1769,
      "eval_samples_per_second": 3620.407,
      "eval_steps_per_second": 14.247,
      "step": 4883
    },
    {
      "epoch": 19.027237354085603,
      "grad_norm": 0.2749641239643097,
      "learning_rate": 0.0004909317269747649,
      "loss": 2.1422,
      "step": 4890
    },
    {
      "epoch": 19.06614785992218,
      "grad_norm": 0.27410992980003357,
      "learning_rate": 0.0004908904879680347,
      "loss": 2.1182,
      "step": 4900
    },
    {
      "epoch": 19.105058365758754,
      "grad_norm": 0.29113924503326416,
      "learning_rate": 0.000490849157144377,
      "loss": 2.139,
      "step": 4910
    },
    {
      "epoch": 19.14396887159533,
      "grad_norm": 0.32282555103302,
      "learning_rate": 0.0004908077345195452,
      "loss": 2.139,
      "step": 4920
    },
    {
      "epoch": 19.182879377431906,
      "grad_norm": 0.30443882942199707,
      "learning_rate": 0.0004907662201093279,
      "loss": 2.1391,
      "step": 4930
    },
    {
      "epoch": 19.22178988326848,
      "grad_norm": 0.32621651887893677,
      "learning_rate": 0.0004907246139295487,
      "loss": 2.1462,
      "step": 4940
    },
    {
      "epoch": 19.260700389105057,
      "grad_norm": 0.31468918919563293,
      "learning_rate": 0.0004906829159960658,
      "loss": 2.1481,
      "step": 4950
    },
    {
      "epoch": 19.299610894941633,
      "grad_norm": 0.35916510224342346,
      "learning_rate": 0.0004906411263247728,
      "loss": 2.1351,
      "step": 4960
    },
    {
      "epoch": 19.33852140077821,
      "grad_norm": 0.32027992606163025,
      "learning_rate": 0.000490599244931598,
      "loss": 2.1324,
      "step": 4970
    },
    {
      "epoch": 19.377431906614785,
      "grad_norm": 0.3664097487926483,
      "learning_rate": 0.0004905572718325049,
      "loss": 2.1435,
      "step": 4980
    },
    {
      "epoch": 19.41634241245136,
      "grad_norm": 0.31480348110198975,
      "learning_rate": 0.0004905152070434917,
      "loss": 2.1626,
      "step": 4990
    },
    {
      "epoch": 19.455252918287936,
      "grad_norm": 0.311755508184433,
      "learning_rate": 0.0004904730505805916,
      "loss": 2.1419,
      "step": 5000
    },
    {
      "epoch": 19.494163424124515,
      "grad_norm": 0.5218414068222046,
      "learning_rate": 0.000490430802459873,
      "loss": 2.1324,
      "step": 5010
    },
    {
      "epoch": 19.53307392996109,
      "grad_norm": 0.3145993947982788,
      "learning_rate": 0.0004903884626974389,
      "loss": 2.1317,
      "step": 5020
    },
    {
      "epoch": 19.571984435797667,
      "grad_norm": 0.30116450786590576,
      "learning_rate": 0.0004903460313094274,
      "loss": 2.1472,
      "step": 5030
    },
    {
      "epoch": 19.610894941634243,
      "grad_norm": 0.28402408957481384,
      "learning_rate": 0.0004903035083120113,
      "loss": 2.1323,
      "step": 5040
    },
    {
      "epoch": 19.64980544747082,
      "grad_norm": 0.3338998854160309,
      "learning_rate": 0.0004902608937213988,
      "loss": 2.1355,
      "step": 5050
    },
    {
      "epoch": 19.688715953307394,
      "grad_norm": 0.2811555862426758,
      "learning_rate": 0.0004902181875538327,
      "loss": 2.1396,
      "step": 5060
    },
    {
      "epoch": 19.72762645914397,
      "grad_norm": 0.2814657390117645,
      "learning_rate": 0.0004901753898255906,
      "loss": 2.1387,
      "step": 5070
    },
    {
      "epoch": 19.766536964980546,
      "grad_norm": 0.31893637776374817,
      "learning_rate": 0.000490132500552985,
      "loss": 2.1384,
      "step": 5080
    },
    {
      "epoch": 19.80544747081712,
      "grad_norm": 0.37321510910987854,
      "learning_rate": 0.0004900895197523637,
      "loss": 2.138,
      "step": 5090
    },
    {
      "epoch": 19.844357976653697,
      "grad_norm": 0.34131374955177307,
      "learning_rate": 0.0004900464474401089,
      "loss": 2.1553,
      "step": 5100
    },
    {
      "epoch": 19.883268482490273,
      "grad_norm": 0.3338703513145447,
      "learning_rate": 0.000490003283632638,
      "loss": 2.1401,
      "step": 5110
    },
    {
      "epoch": 19.92217898832685,
      "grad_norm": 0.32312336564064026,
      "learning_rate": 0.0004899600283464031,
      "loss": 2.1518,
      "step": 5120
    },
    {
      "epoch": 19.961089494163424,
      "grad_norm": 0.3385741412639618,
      "learning_rate": 0.0004899166815978913,
      "loss": 2.1385,
      "step": 5130
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.39765647053718567,
      "learning_rate": 0.0004898732434036243,
      "loss": 2.1435,
      "step": 5140
    },
    {
      "epoch": 20.0,
      "eval_loss": 1.0983409881591797,
      "eval_runtime": 6.4079,
      "eval_samples_per_second": 3489.886,
      "eval_steps_per_second": 13.733,
      "step": 5140
    },
    {
      "epoch": 20.038910505836576,
      "grad_norm": 0.27288538217544556,
      "learning_rate": 0.0004898297137801591,
      "loss": 2.1308,
      "step": 5150
    },
    {
      "epoch": 20.07782101167315,
      "grad_norm": 0.3101827800273895,
      "learning_rate": 0.0004897860927440871,
      "loss": 2.1539,
      "step": 5160
    },
    {
      "epoch": 20.116731517509727,
      "grad_norm": 0.28992679715156555,
      "learning_rate": 0.0004897423803120347,
      "loss": 2.142,
      "step": 5170
    },
    {
      "epoch": 20.155642023346303,
      "grad_norm": 0.3075322210788727,
      "learning_rate": 0.0004896985765006635,
      "loss": 2.1427,
      "step": 5180
    },
    {
      "epoch": 20.19455252918288,
      "grad_norm": 0.33369529247283936,
      "learning_rate": 0.0004896546813266691,
      "loss": 2.1435,
      "step": 5190
    },
    {
      "epoch": 20.233463035019454,
      "grad_norm": 0.28364109992980957,
      "learning_rate": 0.0004896106948067829,
      "loss": 2.1156,
      "step": 5200
    },
    {
      "epoch": 20.27237354085603,
      "grad_norm": 0.30984941124916077,
      "learning_rate": 0.0004895666169577702,
      "loss": 2.132,
      "step": 5210
    },
    {
      "epoch": 20.311284046692606,
      "grad_norm": 0.3018934428691864,
      "learning_rate": 0.0004895224477964319,
      "loss": 2.1267,
      "step": 5220
    },
    {
      "epoch": 20.35019455252918,
      "grad_norm": 0.28396400809288025,
      "learning_rate": 0.0004894781873396033,
      "loss": 2.137,
      "step": 5230
    },
    {
      "epoch": 20.389105058365757,
      "grad_norm": 0.3395703434944153,
      "learning_rate": 0.0004894338356041543,
      "loss": 2.1338,
      "step": 5240
    },
    {
      "epoch": 20.428015564202333,
      "grad_norm": 0.3022322654724121,
      "learning_rate": 0.0004893893926069901,
      "loss": 2.1277,
      "step": 5250
    },
    {
      "epoch": 20.46692607003891,
      "grad_norm": 0.3299442529678345,
      "learning_rate": 0.0004893448583650504,
      "loss": 2.1336,
      "step": 5260
    },
    {
      "epoch": 20.505836575875485,
      "grad_norm": 0.309615820646286,
      "learning_rate": 0.0004893002328953096,
      "loss": 2.1237,
      "step": 5270
    },
    {
      "epoch": 20.544747081712064,
      "grad_norm": 0.3108656704425812,
      "learning_rate": 0.0004892555162147769,
      "loss": 2.1304,
      "step": 5280
    },
    {
      "epoch": 20.58365758754864,
      "grad_norm": 0.2997373938560486,
      "learning_rate": 0.0004892107083404966,
      "loss": 2.1461,
      "step": 5290
    },
    {
      "epoch": 20.622568093385215,
      "grad_norm": 0.3134582042694092,
      "learning_rate": 0.0004891658092895474,
      "loss": 2.1293,
      "step": 5300
    },
    {
      "epoch": 20.66147859922179,
      "grad_norm": 0.3159967362880707,
      "learning_rate": 0.0004891208190790429,
      "loss": 2.1393,
      "step": 5310
    },
    {
      "epoch": 20.700389105058367,
      "grad_norm": 0.3115094304084778,
      "learning_rate": 0.0004890757377261312,
      "loss": 2.1238,
      "step": 5320
    },
    {
      "epoch": 20.739299610894943,
      "grad_norm": 0.28248584270477295,
      "learning_rate": 0.0004890305652479957,
      "loss": 2.1254,
      "step": 5330
    },
    {
      "epoch": 20.77821011673152,
      "grad_norm": 0.32080793380737305,
      "learning_rate": 0.0004889853016618536,
      "loss": 2.1338,
      "step": 5340
    },
    {
      "epoch": 20.817120622568094,
      "grad_norm": 0.28484588861465454,
      "learning_rate": 0.000488939946984958,
      "loss": 2.1367,
      "step": 5350
    },
    {
      "epoch": 20.85603112840467,
      "grad_norm": 0.3098631203174591,
      "learning_rate": 0.0004888945012345958,
      "loss": 2.1425,
      "step": 5360
    },
    {
      "epoch": 20.894941634241246,
      "grad_norm": 0.29185912013053894,
      "learning_rate": 0.0004888489644280891,
      "loss": 2.1307,
      "step": 5370
    },
    {
      "epoch": 20.93385214007782,
      "grad_norm": 0.2805815041065216,
      "learning_rate": 0.0004888033365827944,
      "loss": 2.1365,
      "step": 5380
    },
    {
      "epoch": 20.972762645914397,
      "grad_norm": 0.3046380579471588,
      "learning_rate": 0.0004887576177161031,
      "loss": 2.1417,
      "step": 5390
    },
    {
      "epoch": 21.0,
      "eval_loss": 1.0991750955581665,
      "eval_runtime": 6.1898,
      "eval_samples_per_second": 3612.908,
      "eval_steps_per_second": 14.217,
      "step": 5397
    },
    {
      "epoch": 21.011673151750973,
      "grad_norm": 0.3149586319923401,
      "learning_rate": 0.0004887118078454412,
      "loss": 2.1216,
      "step": 5400
    },
    {
      "epoch": 21.05058365758755,
      "grad_norm": 0.3095441162586212,
      "learning_rate": 0.0004886659069882695,
      "loss": 2.115,
      "step": 5410
    },
    {
      "epoch": 21.089494163424124,
      "grad_norm": 0.3007139563560486,
      "learning_rate": 0.0004886199151620834,
      "loss": 2.1186,
      "step": 5420
    },
    {
      "epoch": 21.1284046692607,
      "grad_norm": 0.3121755123138428,
      "learning_rate": 0.0004885738323844128,
      "loss": 2.1364,
      "step": 5430
    },
    {
      "epoch": 21.167315175097276,
      "grad_norm": 0.2997518479824066,
      "learning_rate": 0.0004885276586728227,
      "loss": 2.1235,
      "step": 5440
    },
    {
      "epoch": 21.20622568093385,
      "grad_norm": 0.3089170455932617,
      "learning_rate": 0.0004884813940449122,
      "loss": 2.1287,
      "step": 5450
    },
    {
      "epoch": 21.245136186770427,
      "grad_norm": 0.3237074911594391,
      "learning_rate": 0.0004884350385183157,
      "loss": 2.1245,
      "step": 5460
    },
    {
      "epoch": 21.284046692607003,
      "grad_norm": 0.30688801407814026,
      "learning_rate": 0.0004883885921107015,
      "loss": 2.1351,
      "step": 5470
    },
    {
      "epoch": 21.32295719844358,
      "grad_norm": 0.2955406904220581,
      "learning_rate": 0.0004883420548397732,
      "loss": 2.1442,
      "step": 5480
    },
    {
      "epoch": 21.361867704280154,
      "grad_norm": 0.33798104524612427,
      "learning_rate": 0.0004882954267232688,
      "loss": 2.1368,
      "step": 5490
    },
    {
      "epoch": 21.40077821011673,
      "grad_norm": 0.2966732978820801,
      "learning_rate": 0.000488248707778961,
      "loss": 2.1273,
      "step": 5500
    },
    {
      "epoch": 21.439688715953306,
      "grad_norm": 0.29758337140083313,
      "learning_rate": 0.00048820189802465665,
      "loss": 2.1116,
      "step": 5510
    },
    {
      "epoch": 21.47859922178988,
      "grad_norm": 0.3112175464630127,
      "learning_rate": 0.00048815499747819794,
      "loss": 2.1275,
      "step": 5520
    },
    {
      "epoch": 21.51750972762646,
      "grad_norm": 0.31949514150619507,
      "learning_rate": 0.00048810800615746105,
      "loss": 2.1222,
      "step": 5530
    },
    {
      "epoch": 21.556420233463037,
      "grad_norm": 0.31057029962539673,
      "learning_rate": 0.0004880609240803571,
      "loss": 2.1318,
      "step": 5540
    },
    {
      "epoch": 21.595330739299612,
      "grad_norm": 0.3028990626335144,
      "learning_rate": 0.00048801375126483184,
      "loss": 2.1268,
      "step": 5550
    },
    {
      "epoch": 21.634241245136188,
      "grad_norm": 0.2823008894920349,
      "learning_rate": 0.0004879664877288653,
      "loss": 2.1329,
      "step": 5560
    },
    {
      "epoch": 21.673151750972764,
      "grad_norm": 0.3413579761981964,
      "learning_rate": 0.00048791913349047243,
      "loss": 2.1361,
      "step": 5570
    },
    {
      "epoch": 21.71206225680934,
      "grad_norm": 0.29114747047424316,
      "learning_rate": 0.0004878716885677026,
      "loss": 2.1351,
      "step": 5580
    },
    {
      "epoch": 21.750972762645915,
      "grad_norm": 0.28626951575279236,
      "learning_rate": 0.00048782415297863956,
      "loss": 2.1336,
      "step": 5590
    },
    {
      "epoch": 21.78988326848249,
      "grad_norm": 0.30985555052757263,
      "learning_rate": 0.00048777652674140195,
      "loss": 2.1281,
      "step": 5600
    },
    {
      "epoch": 21.828793774319067,
      "grad_norm": 0.31199488043785095,
      "learning_rate": 0.00048772880987414284,
      "loss": 2.1373,
      "step": 5610
    },
    {
      "epoch": 21.867704280155642,
      "grad_norm": 0.3237616717815399,
      "learning_rate": 0.00048768100239504966,
      "loss": 2.1327,
      "step": 5620
    },
    {
      "epoch": 21.90661478599222,
      "grad_norm": 0.30158278346061707,
      "learning_rate": 0.00048763310432234467,
      "loss": 2.1343,
      "step": 5630
    },
    {
      "epoch": 21.945525291828794,
      "grad_norm": 0.2809193432331085,
      "learning_rate": 0.00048758511567428446,
      "loss": 2.1361,
      "step": 5640
    },
    {
      "epoch": 21.98443579766537,
      "grad_norm": 0.2729133367538452,
      "learning_rate": 0.0004875370364691601,
      "loss": 2.1189,
      "step": 5650
    },
    {
      "epoch": 22.0,
      "eval_loss": 1.0972275733947754,
      "eval_runtime": 6.2061,
      "eval_samples_per_second": 3603.363,
      "eval_steps_per_second": 14.179,
      "step": 5654
    },
    {
      "epoch": 22.023346303501945,
      "grad_norm": 0.3018293082714081,
      "learning_rate": 0.00048748886672529755,
      "loss": 2.1062,
      "step": 5660
    },
    {
      "epoch": 22.06225680933852,
      "grad_norm": 0.34578701853752136,
      "learning_rate": 0.00048744060646105695,
      "loss": 2.1263,
      "step": 5670
    },
    {
      "epoch": 22.101167315175097,
      "grad_norm": 0.2979227602481842,
      "learning_rate": 0.0004873922556948328,
      "loss": 2.123,
      "step": 5680
    },
    {
      "epoch": 22.140077821011673,
      "grad_norm": 0.3126676678657532,
      "learning_rate": 0.00048734381444505437,
      "loss": 2.1236,
      "step": 5690
    },
    {
      "epoch": 22.17898832684825,
      "grad_norm": 0.3658595085144043,
      "learning_rate": 0.0004872952827301854,
      "loss": 2.1237,
      "step": 5700
    },
    {
      "epoch": 22.217898832684824,
      "grad_norm": 0.2920982539653778,
      "learning_rate": 0.0004872466605687241,
      "loss": 2.1318,
      "step": 5710
    },
    {
      "epoch": 22.2568093385214,
      "grad_norm": 0.34379252791404724,
      "learning_rate": 0.0004871979479792031,
      "loss": 2.1186,
      "step": 5720
    },
    {
      "epoch": 22.295719844357976,
      "grad_norm": 0.3070466220378876,
      "learning_rate": 0.0004871491449801894,
      "loss": 2.1231,
      "step": 5730
    },
    {
      "epoch": 22.33463035019455,
      "grad_norm": 0.3491499722003937,
      "learning_rate": 0.0004871002515902847,
      "loss": 2.1205,
      "step": 5740
    },
    {
      "epoch": 22.373540856031127,
      "grad_norm": 0.3152882158756256,
      "learning_rate": 0.000487051267828125,
      "loss": 2.1313,
      "step": 5750
    },
    {
      "epoch": 22.412451361867703,
      "grad_norm": 0.30146852135658264,
      "learning_rate": 0.00048700219371238066,
      "loss": 2.1418,
      "step": 5760
    },
    {
      "epoch": 22.45136186770428,
      "grad_norm": 0.28680330514907837,
      "learning_rate": 0.00048695302926175674,
      "loss": 2.1083,
      "step": 5770
    },
    {
      "epoch": 22.490272373540854,
      "grad_norm": 0.2907404899597168,
      "learning_rate": 0.00048690377449499246,
      "loss": 2.1292,
      "step": 5780
    },
    {
      "epoch": 22.529182879377434,
      "grad_norm": 0.3273750841617584,
      "learning_rate": 0.0004868544294308617,
      "loss": 2.132,
      "step": 5790
    },
    {
      "epoch": 22.56809338521401,
      "grad_norm": 0.295699805021286,
      "learning_rate": 0.0004868049940881725,
      "loss": 2.136,
      "step": 5800
    },
    {
      "epoch": 22.607003891050585,
      "grad_norm": 0.31791603565216064,
      "learning_rate": 0.0004867554684857675,
      "loss": 2.132,
      "step": 5810
    },
    {
      "epoch": 22.64591439688716,
      "grad_norm": 0.32634681463241577,
      "learning_rate": 0.00048670585264252373,
      "loss": 2.1252,
      "step": 5820
    },
    {
      "epoch": 22.684824902723737,
      "grad_norm": 0.3077599108219147,
      "learning_rate": 0.0004866561465773527,
      "loss": 2.1273,
      "step": 5830
    },
    {
      "epoch": 22.723735408560312,
      "grad_norm": 0.2746761739253998,
      "learning_rate": 0.0004866063503092,
      "loss": 2.1299,
      "step": 5840
    },
    {
      "epoch": 22.762645914396888,
      "grad_norm": 0.28560471534729004,
      "learning_rate": 0.00048655646385704584,
      "loss": 2.1305,
      "step": 5850
    },
    {
      "epoch": 22.801556420233464,
      "grad_norm": 0.32206490635871887,
      "learning_rate": 0.0004865064872399048,
      "loss": 2.1201,
      "step": 5860
    },
    {
      "epoch": 22.84046692607004,
      "grad_norm": 0.32704025506973267,
      "learning_rate": 0.0004864564204768257,
      "loss": 2.1141,
      "step": 5870
    },
    {
      "epoch": 22.879377431906615,
      "grad_norm": 0.2598032057285309,
      "learning_rate": 0.0004864062635868919,
      "loss": 2.1282,
      "step": 5880
    },
    {
      "epoch": 22.91828793774319,
      "grad_norm": 0.3285791873931885,
      "learning_rate": 0.00048635601658922095,
      "loss": 2.1081,
      "step": 5890
    },
    {
      "epoch": 22.957198443579767,
      "grad_norm": 0.30377379059791565,
      "learning_rate": 0.00048630567950296483,
      "loss": 2.1182,
      "step": 5900
    },
    {
      "epoch": 22.996108949416342,
      "grad_norm": 0.25645267963409424,
      "learning_rate": 0.0004862552523473099,
      "loss": 2.1335,
      "step": 5910
    },
    {
      "epoch": 23.0,
      "eval_loss": 1.0966686010360718,
      "eval_runtime": 6.1827,
      "eval_samples_per_second": 3617.028,
      "eval_steps_per_second": 14.233,
      "step": 5911
    },
    {
      "epoch": 23.035019455252918,
      "grad_norm": 0.33680781722068787,
      "learning_rate": 0.0004862047351414767,
      "loss": 2.116,
      "step": 5920
    },
    {
      "epoch": 23.073929961089494,
      "grad_norm": 0.2907363176345825,
      "learning_rate": 0.0004861541279047201,
      "loss": 2.1176,
      "step": 5930
    },
    {
      "epoch": 23.11284046692607,
      "grad_norm": 0.2906895577907562,
      "learning_rate": 0.0004861034306563296,
      "loss": 2.1245,
      "step": 5940
    },
    {
      "epoch": 23.151750972762645,
      "grad_norm": 0.30723294615745544,
      "learning_rate": 0.0004860526434156286,
      "loss": 2.1101,
      "step": 5950
    },
    {
      "epoch": 23.19066147859922,
      "grad_norm": 0.32017120718955994,
      "learning_rate": 0.00048600176620197514,
      "loss": 2.0997,
      "step": 5960
    },
    {
      "epoch": 23.229571984435797,
      "grad_norm": 0.3161314129829407,
      "learning_rate": 0.0004859507990347611,
      "loss": 2.1131,
      "step": 5970
    },
    {
      "epoch": 23.268482490272373,
      "grad_norm": 0.26657578349113464,
      "learning_rate": 0.00048589974193341323,
      "loss": 2.1322,
      "step": 5980
    },
    {
      "epoch": 23.30739299610895,
      "grad_norm": 0.3035370409488678,
      "learning_rate": 0.0004858485949173921,
      "loss": 2.111,
      "step": 5990
    },
    {
      "epoch": 23.346303501945524,
      "grad_norm": 0.3336077928543091,
      "learning_rate": 0.0004857973580061928,
      "loss": 2.1176,
      "step": 6000
    },
    {
      "epoch": 23.3852140077821,
      "grad_norm": 0.3242804706096649,
      "learning_rate": 0.00048574603121934455,
      "loss": 2.1287,
      "step": 6010
    },
    {
      "epoch": 23.424124513618676,
      "grad_norm": 0.2961452305316925,
      "learning_rate": 0.000485694614576411,
      "loss": 2.1262,
      "step": 6020
    },
    {
      "epoch": 23.46303501945525,
      "grad_norm": 0.29723718762397766,
      "learning_rate": 0.00048564310809698965,
      "loss": 2.1234,
      "step": 6030
    },
    {
      "epoch": 23.50194552529183,
      "grad_norm": 0.3049996495246887,
      "learning_rate": 0.0004855915118007128,
      "loss": 2.119,
      "step": 6040
    },
    {
      "epoch": 23.540856031128406,
      "grad_norm": 0.2907009720802307,
      "learning_rate": 0.0004855398257072466,
      "loss": 2.1126,
      "step": 6050
    },
    {
      "epoch": 23.579766536964982,
      "grad_norm": 0.3098416030406952,
      "learning_rate": 0.00048548804983629146,
      "loss": 2.1229,
      "step": 6060
    },
    {
      "epoch": 23.618677042801558,
      "grad_norm": 0.3116200268268585,
      "learning_rate": 0.0004854361842075823,
      "loss": 2.1158,
      "step": 6070
    },
    {
      "epoch": 23.657587548638134,
      "grad_norm": 0.29203200340270996,
      "learning_rate": 0.00048538422884088775,
      "loss": 2.1287,
      "step": 6080
    },
    {
      "epoch": 23.69649805447471,
      "grad_norm": 0.3334124684333801,
      "learning_rate": 0.00048533218375601105,
      "loss": 2.1252,
      "step": 6090
    },
    {
      "epoch": 23.735408560311285,
      "grad_norm": 0.3041871190071106,
      "learning_rate": 0.00048528004897278957,
      "loss": 2.1309,
      "step": 6100
    },
    {
      "epoch": 23.77431906614786,
      "grad_norm": 0.299265593290329,
      "learning_rate": 0.0004852278245110948,
      "loss": 2.1095,
      "step": 6110
    },
    {
      "epoch": 23.813229571984436,
      "grad_norm": 0.30477941036224365,
      "learning_rate": 0.0004851755103908323,
      "loss": 2.1232,
      "step": 6120
    },
    {
      "epoch": 23.852140077821012,
      "grad_norm": 0.3384915590286255,
      "learning_rate": 0.00048512310663194206,
      "loss": 2.1161,
      "step": 6130
    },
    {
      "epoch": 23.891050583657588,
      "grad_norm": 0.3029603064060211,
      "learning_rate": 0.000485070613254398,
      "loss": 2.1335,
      "step": 6140
    },
    {
      "epoch": 23.929961089494164,
      "grad_norm": 0.3157176077365875,
      "learning_rate": 0.00048501803027820836,
      "loss": 2.1245,
      "step": 6150
    },
    {
      "epoch": 23.96887159533074,
      "grad_norm": 0.28150486946105957,
      "learning_rate": 0.00048496535772341547,
      "loss": 2.1303,
      "step": 6160
    },
    {
      "epoch": 24.0,
      "eval_loss": 1.0964754819869995,
      "eval_runtime": 6.2135,
      "eval_samples_per_second": 3599.103,
      "eval_steps_per_second": 14.163,
      "step": 6168
    },
    {
      "epoch": 24.007782101167315,
      "grad_norm": 0.30985772609710693,
      "learning_rate": 0.0004849125956100958,
      "loss": 2.1121,
      "step": 6170
    },
    {
      "epoch": 24.04669260700389,
      "grad_norm": 0.3462197184562683,
      "learning_rate": 0.00048485974395836,
      "loss": 2.1067,
      "step": 6180
    },
    {
      "epoch": 24.085603112840467,
      "grad_norm": 0.3263542950153351,
      "learning_rate": 0.0004848068027883528,
      "loss": 2.1219,
      "step": 6190
    },
    {
      "epoch": 24.124513618677042,
      "grad_norm": 0.3012196719646454,
      "learning_rate": 0.000484753772120253,
      "loss": 2.1176,
      "step": 6200
    },
    {
      "epoch": 24.163424124513618,
      "grad_norm": 0.34114399552345276,
      "learning_rate": 0.0004847006519742736,
      "loss": 2.1062,
      "step": 6210
    },
    {
      "epoch": 24.202334630350194,
      "grad_norm": 0.28671565651893616,
      "learning_rate": 0.00048464744237066164,
      "loss": 2.1142,
      "step": 6220
    },
    {
      "epoch": 24.24124513618677,
      "grad_norm": 0.34192246198654175,
      "learning_rate": 0.0004845941433296984,
      "loss": 2.111,
      "step": 6230
    },
    {
      "epoch": 24.280155642023345,
      "grad_norm": 0.3040418028831482,
      "learning_rate": 0.0004845407548716991,
      "loss": 2.1143,
      "step": 6240
    },
    {
      "epoch": 24.31906614785992,
      "grad_norm": 0.29499486088752747,
      "learning_rate": 0.00048448727701701303,
      "loss": 2.107,
      "step": 6250
    },
    {
      "epoch": 24.357976653696497,
      "grad_norm": 0.3013460636138916,
      "learning_rate": 0.00048443370978602367,
      "loss": 2.1171,
      "step": 6260
    },
    {
      "epoch": 24.396887159533073,
      "grad_norm": 0.31114253401756287,
      "learning_rate": 0.0004843800531991485,
      "loss": 2.1187,
      "step": 6270
    },
    {
      "epoch": 24.43579766536965,
      "grad_norm": 0.32039231061935425,
      "learning_rate": 0.00048432630727683905,
      "loss": 2.1202,
      "step": 6280
    },
    {
      "epoch": 24.474708171206224,
      "grad_norm": 0.3330904245376587,
      "learning_rate": 0.000484272472039581,
      "loss": 2.1252,
      "step": 6290
    },
    {
      "epoch": 24.5136186770428,
      "grad_norm": 0.28077927231788635,
      "learning_rate": 0.00048421854750789386,
      "loss": 2.1123,
      "step": 6300
    },
    {
      "epoch": 24.55252918287938,
      "grad_norm": 0.3195094168186188,
      "learning_rate": 0.0004841645337023313,
      "loss": 2.1212,
      "step": 6310
    },
    {
      "epoch": 24.591439688715955,
      "grad_norm": 0.3032221496105194,
      "learning_rate": 0.00048411043064348116,
      "loss": 2.1333,
      "step": 6320
    },
    {
      "epoch": 24.63035019455253,
      "grad_norm": 0.3186478614807129,
      "learning_rate": 0.000484056238351965,
      "loss": 2.1199,
      "step": 6330
    },
    {
      "epoch": 24.669260700389106,
      "grad_norm": 0.28948190808296204,
      "learning_rate": 0.0004840019568484387,
      "loss": 2.1051,
      "step": 6340
    },
    {
      "epoch": 24.708171206225682,
      "grad_norm": 0.31430163979530334,
      "learning_rate": 0.000483947586153592,
      "loss": 2.1167,
      "step": 6350
    },
    {
      "epoch": 24.747081712062258,
      "grad_norm": 0.3143167495727539,
      "learning_rate": 0.0004838931262881485,
      "loss": 2.1267,
      "step": 6360
    },
    {
      "epoch": 24.785992217898833,
      "grad_norm": 0.28544384241104126,
      "learning_rate": 0.00048383857727286595,
      "loss": 2.1197,
      "step": 6370
    },
    {
      "epoch": 24.82490272373541,
      "grad_norm": 0.3021796941757202,
      "learning_rate": 0.00048378393912853617,
      "loss": 2.1168,
      "step": 6380
    },
    {
      "epoch": 24.863813229571985,
      "grad_norm": 0.3593851327896118,
      "learning_rate": 0.0004837292118759847,
      "loss": 2.1222,
      "step": 6390
    },
    {
      "epoch": 24.90272373540856,
      "grad_norm": 0.31636959314346313,
      "learning_rate": 0.0004836743955360713,
      "loss": 2.1095,
      "step": 6400
    },
    {
      "epoch": 24.941634241245136,
      "grad_norm": 0.3522903323173523,
      "learning_rate": 0.0004836194901296894,
      "loss": 2.1129,
      "step": 6410
    },
    {
      "epoch": 24.980544747081712,
      "grad_norm": 0.3042867183685303,
      "learning_rate": 0.0004835644956777667,
      "loss": 2.1211,
      "step": 6420
    },
    {
      "epoch": 25.0,
      "eval_loss": 1.0965193510055542,
      "eval_runtime": 6.1866,
      "eval_samples_per_second": 3614.761,
      "eval_steps_per_second": 14.224,
      "step": 6425
    },
    {
      "epoch": 25.019455252918288,
      "grad_norm": 0.3258706331253052,
      "learning_rate": 0.0004835094122012647,
      "loss": 2.1164,
      "step": 6430
    },
    {
      "epoch": 25.058365758754864,
      "grad_norm": 0.2983059287071228,
      "learning_rate": 0.0004834542397211786,
      "loss": 2.1157,
      "step": 6440
    },
    {
      "epoch": 25.09727626459144,
      "grad_norm": 0.3355168402194977,
      "learning_rate": 0.0004833989782585379,
      "loss": 2.1098,
      "step": 6450
    },
    {
      "epoch": 25.136186770428015,
      "grad_norm": 0.31693795323371887,
      "learning_rate": 0.00048334362783440584,
      "loss": 2.1093,
      "step": 6460
    },
    {
      "epoch": 25.17509727626459,
      "grad_norm": 0.3118458390235901,
      "learning_rate": 0.0004832881884698795,
      "loss": 2.1179,
      "step": 6470
    },
    {
      "epoch": 25.214007782101167,
      "grad_norm": 0.31388941407203674,
      "learning_rate": 0.00048323266018609015,
      "loss": 2.1152,
      "step": 6480
    },
    {
      "epoch": 25.252918287937742,
      "grad_norm": 0.34818434715270996,
      "learning_rate": 0.0004831770430042025,
      "loss": 2.1188,
      "step": 6490
    },
    {
      "epoch": 25.291828793774318,
      "grad_norm": 0.29904261231422424,
      "learning_rate": 0.00048312133694541556,
      "loss": 2.1013,
      "step": 6500
    },
    {
      "epoch": 25.330739299610894,
      "grad_norm": 0.2967541217803955,
      "learning_rate": 0.0004830655420309619,
      "loss": 2.1061,
      "step": 6510
    },
    {
      "epoch": 25.36964980544747,
      "grad_norm": 0.28590837121009827,
      "learning_rate": 0.0004830096582821083,
      "loss": 2.1145,
      "step": 6520
    },
    {
      "epoch": 25.408560311284045,
      "grad_norm": 0.31217849254608154,
      "learning_rate": 0.00048295368572015497,
      "loss": 2.1127,
      "step": 6530
    },
    {
      "epoch": 25.44747081712062,
      "grad_norm": 0.3039005994796753,
      "learning_rate": 0.00048289762436643635,
      "loss": 2.1148,
      "step": 6540
    },
    {
      "epoch": 25.486381322957197,
      "grad_norm": 0.2758658230304718,
      "learning_rate": 0.0004828414742423206,
      "loss": 2.1188,
      "step": 6550
    },
    {
      "epoch": 25.525291828793776,
      "grad_norm": 0.3541506826877594,
      "learning_rate": 0.00048278523536920964,
      "loss": 2.117,
      "step": 6560
    },
    {
      "epoch": 25.56420233463035,
      "grad_norm": 0.31646859645843506,
      "learning_rate": 0.0004827289077685393,
      "loss": 2.0972,
      "step": 6570
    },
    {
      "epoch": 25.603112840466927,
      "grad_norm": 0.28525182604789734,
      "learning_rate": 0.0004826724914617791,
      "loss": 2.1176,
      "step": 6580
    },
    {
      "epoch": 25.642023346303503,
      "grad_norm": 0.29799506068229675,
      "learning_rate": 0.00048261598647043256,
      "loss": 2.1062,
      "step": 6590
    },
    {
      "epoch": 25.68093385214008,
      "grad_norm": 0.2849074900150299,
      "learning_rate": 0.00048255939281603694,
      "loss": 2.1143,
      "step": 6600
    },
    {
      "epoch": 25.719844357976655,
      "grad_norm": 0.33490604162216187,
      "learning_rate": 0.0004825027105201632,
      "loss": 2.1069,
      "step": 6610
    },
    {
      "epoch": 25.75875486381323,
      "grad_norm": 0.2971446216106415,
      "learning_rate": 0.0004824459396044162,
      "loss": 2.1186,
      "step": 6620
    },
    {
      "epoch": 25.797665369649806,
      "grad_norm": 0.3207922577857971,
      "learning_rate": 0.00048238908009043445,
      "loss": 2.112,
      "step": 6630
    },
    {
      "epoch": 25.836575875486382,
      "grad_norm": 0.2948072552680969,
      "learning_rate": 0.00048233213199989043,
      "loss": 2.1006,
      "step": 6640
    },
    {
      "epoch": 25.875486381322958,
      "grad_norm": 0.3114720582962036,
      "learning_rate": 0.00048227509535449025,
      "loss": 2.1238,
      "step": 6650
    },
    {
      "epoch": 25.914396887159533,
      "grad_norm": 0.40537312626838684,
      "learning_rate": 0.0004822179701759737,
      "loss": 2.1237,
      "step": 6660
    },
    {
      "epoch": 25.95330739299611,
      "grad_norm": 0.27210190892219543,
      "learning_rate": 0.00048216075648611445,
      "loss": 2.1115,
      "step": 6670
    },
    {
      "epoch": 25.992217898832685,
      "grad_norm": 0.31496575474739075,
      "learning_rate": 0.00048210345430671985,
      "loss": 2.1081,
      "step": 6680
    },
    {
      "epoch": 26.0,
      "eval_loss": 1.0961552858352661,
      "eval_runtime": 6.1829,
      "eval_samples_per_second": 3616.886,
      "eval_steps_per_second": 14.233,
      "step": 6682
    },
    {
      "epoch": 26.03112840466926,
      "grad_norm": 0.29863736033439636,
      "learning_rate": 0.00048204606365963103,
      "loss": 2.1015,
      "step": 6690
    },
    {
      "epoch": 26.070038910505836,
      "grad_norm": 0.34794723987579346,
      "learning_rate": 0.0004819885845667228,
      "loss": 2.1131,
      "step": 6700
    },
    {
      "epoch": 26.108949416342412,
      "grad_norm": 0.32180240750312805,
      "learning_rate": 0.00048193101704990354,
      "loss": 2.1012,
      "step": 6710
    },
    {
      "epoch": 26.147859922178988,
      "grad_norm": 0.31337055563926697,
      "learning_rate": 0.00048187336113111564,
      "loss": 2.0965,
      "step": 6720
    },
    {
      "epoch": 26.186770428015564,
      "grad_norm": 0.334377259016037,
      "learning_rate": 0.0004818156168323349,
      "loss": 2.1045,
      "step": 6730
    },
    {
      "epoch": 26.22568093385214,
      "grad_norm": 0.29956844449043274,
      "learning_rate": 0.00048175778417557097,
      "loss": 2.1157,
      "step": 6740
    },
    {
      "epoch": 26.264591439688715,
      "grad_norm": 0.32893529534339905,
      "learning_rate": 0.0004816998631828672,
      "loss": 2.1119,
      "step": 6750
    },
    {
      "epoch": 26.30350194552529,
      "grad_norm": 0.2998574674129486,
      "learning_rate": 0.0004816418538763004,
      "loss": 2.1004,
      "step": 6760
    },
    {
      "epoch": 26.342412451361866,
      "grad_norm": 0.30336958169937134,
      "learning_rate": 0.00048158375627798127,
      "loss": 2.1146,
      "step": 6770
    },
    {
      "epoch": 26.381322957198442,
      "grad_norm": 0.3446207046508789,
      "learning_rate": 0.00048152557041005405,
      "loss": 2.1219,
      "step": 6780
    },
    {
      "epoch": 26.420233463035018,
      "grad_norm": 0.2867722809314728,
      "learning_rate": 0.00048146729629469675,
      "loss": 2.1045,
      "step": 6790
    },
    {
      "epoch": 26.459143968871594,
      "grad_norm": 0.3360957205295563,
      "learning_rate": 0.00048140893395412076,
      "loss": 2.1141,
      "step": 6800
    },
    {
      "epoch": 26.49805447470817,
      "grad_norm": 0.2946581244468689,
      "learning_rate": 0.0004813504834105713,
      "loss": 2.1005,
      "step": 6810
    },
    {
      "epoch": 26.53696498054475,
      "grad_norm": 0.29733285307884216,
      "learning_rate": 0.0004812919446863272,
      "loss": 2.1054,
      "step": 6820
    },
    {
      "epoch": 26.575875486381324,
      "grad_norm": 0.323697566986084,
      "learning_rate": 0.0004812333178037009,
      "loss": 2.0936,
      "step": 6830
    },
    {
      "epoch": 26.6147859922179,
      "grad_norm": 0.29225462675094604,
      "learning_rate": 0.0004811746027850383,
      "loss": 2.1198,
      "step": 6840
    },
    {
      "epoch": 26.653696498054476,
      "grad_norm": 0.32047951221466064,
      "learning_rate": 0.0004811157996527191,
      "loss": 2.1097,
      "step": 6850
    },
    {
      "epoch": 26.69260700389105,
      "grad_norm": 0.3000648617744446,
      "learning_rate": 0.0004810569084291564,
      "loss": 2.1143,
      "step": 6860
    },
    {
      "epoch": 26.731517509727627,
      "grad_norm": 0.2867833077907562,
      "learning_rate": 0.000480997929136797,
      "loss": 2.1216,
      "step": 6870
    },
    {
      "epoch": 26.770428015564203,
      "grad_norm": 0.2826350927352905,
      "learning_rate": 0.0004809388617981213,
      "loss": 2.1066,
      "step": 6880
    },
    {
      "epoch": 26.80933852140078,
      "grad_norm": 0.3040502369403839,
      "learning_rate": 0.00048087970643564303,
      "loss": 2.1088,
      "step": 6890
    },
    {
      "epoch": 26.848249027237355,
      "grad_norm": 0.3017665147781372,
      "learning_rate": 0.0004808204630719097,
      "loss": 2.1104,
      "step": 6900
    },
    {
      "epoch": 26.88715953307393,
      "grad_norm": 0.2988549768924713,
      "learning_rate": 0.00048076113172950243,
      "loss": 2.1097,
      "step": 6910
    },
    {
      "epoch": 26.926070038910506,
      "grad_norm": 0.31571534276008606,
      "learning_rate": 0.00048070171243103554,
      "loss": 2.1021,
      "step": 6920
    },
    {
      "epoch": 26.964980544747082,
      "grad_norm": 0.3125109374523163,
      "learning_rate": 0.00048064220519915713,
      "loss": 2.1006,
      "step": 6930
    },
    {
      "epoch": 27.0,
      "eval_loss": 1.0925365686416626,
      "eval_runtime": 6.4485,
      "eval_samples_per_second": 3467.948,
      "eval_steps_per_second": 13.647,
      "step": 6939
    },
    {
      "epoch": 27.003891050583658,
      "grad_norm": 0.2817721664905548,
      "learning_rate": 0.0004805826100565488,
      "loss": 2.1032,
      "step": 6940
    },
    {
      "epoch": 27.042801556420233,
      "grad_norm": 0.3060317039489746,
      "learning_rate": 0.0004805229270259256,
      "loss": 2.1075,
      "step": 6950
    },
    {
      "epoch": 27.08171206225681,
      "grad_norm": 0.2873961627483368,
      "learning_rate": 0.000480463156130036,
      "loss": 2.0976,
      "step": 6960
    },
    {
      "epoch": 27.120622568093385,
      "grad_norm": 0.27745571732521057,
      "learning_rate": 0.0004804032973916622,
      "loss": 2.0828,
      "step": 6970
    },
    {
      "epoch": 27.15953307392996,
      "grad_norm": 0.3181682527065277,
      "learning_rate": 0.00048034335083361963,
      "loss": 2.1137,
      "step": 6980
    },
    {
      "epoch": 27.198443579766536,
      "grad_norm": 0.2848545014858246,
      "learning_rate": 0.00048028331647875734,
      "loss": 2.0979,
      "step": 6990
    },
    {
      "epoch": 27.237354085603112,
      "grad_norm": 0.2872583866119385,
      "learning_rate": 0.00048022319434995784,
      "loss": 2.1111,
      "step": 7000
    },
    {
      "epoch": 27.276264591439688,
      "grad_norm": 0.30618152022361755,
      "learning_rate": 0.00048016298447013694,
      "loss": 2.1101,
      "step": 7010
    },
    {
      "epoch": 27.315175097276263,
      "grad_norm": 0.2934185266494751,
      "learning_rate": 0.0004801026868622441,
      "loss": 2.1048,
      "step": 7020
    },
    {
      "epoch": 27.35408560311284,
      "grad_norm": 0.31141194701194763,
      "learning_rate": 0.0004800423015492622,
      "loss": 2.108,
      "step": 7030
    },
    {
      "epoch": 27.392996108949415,
      "grad_norm": 0.3091072738170624,
      "learning_rate": 0.0004799818285542074,
      "loss": 2.1117,
      "step": 7040
    },
    {
      "epoch": 27.43190661478599,
      "grad_norm": 0.34854087233543396,
      "learning_rate": 0.00047992126790012923,
      "loss": 2.1042,
      "step": 7050
    },
    {
      "epoch": 27.470817120622566,
      "grad_norm": 0.29720592498779297,
      "learning_rate": 0.0004798606196101111,
      "loss": 2.1084,
      "step": 7060
    },
    {
      "epoch": 27.509727626459146,
      "grad_norm": 0.3114392161369324,
      "learning_rate": 0.00047979988370726914,
      "loss": 2.0932,
      "step": 7070
    },
    {
      "epoch": 27.54863813229572,
      "grad_norm": 0.31689608097076416,
      "learning_rate": 0.00047973906021475345,
      "loss": 2.0984,
      "step": 7080
    },
    {
      "epoch": 27.587548638132297,
      "grad_norm": 0.2781203091144562,
      "learning_rate": 0.0004796781491557472,
      "loss": 2.1092,
      "step": 7090
    },
    {
      "epoch": 27.626459143968873,
      "grad_norm": 0.3771519958972931,
      "learning_rate": 0.000479617150553467,
      "loss": 2.1185,
      "step": 7100
    },
    {
      "epoch": 27.66536964980545,
      "grad_norm": 0.31107616424560547,
      "learning_rate": 0.00047955606443116295,
      "loss": 2.1019,
      "step": 7110
    },
    {
      "epoch": 27.704280155642024,
      "grad_norm": 0.32451117038726807,
      "learning_rate": 0.00047949489081211826,
      "loss": 2.1134,
      "step": 7120
    },
    {
      "epoch": 27.7431906614786,
      "grad_norm": 0.32502421736717224,
      "learning_rate": 0.0004794336297196498,
      "loss": 2.1312,
      "step": 7130
    },
    {
      "epoch": 27.782101167315176,
      "grad_norm": 0.28248482942581177,
      "learning_rate": 0.0004793722811771075,
      "loss": 2.1129,
      "step": 7140
    },
    {
      "epoch": 27.82101167315175,
      "grad_norm": 0.3899685740470886,
      "learning_rate": 0.00047931084520787487,
      "loss": 2.0881,
      "step": 7150
    },
    {
      "epoch": 27.859922178988327,
      "grad_norm": 0.2962501049041748,
      "learning_rate": 0.00047924932183536853,
      "loss": 2.1215,
      "step": 7160
    },
    {
      "epoch": 27.898832684824903,
      "grad_norm": 0.29176434874534607,
      "learning_rate": 0.00047918771108303843,
      "loss": 2.0904,
      "step": 7170
    },
    {
      "epoch": 27.93774319066148,
      "grad_norm": 0.27217137813568115,
      "learning_rate": 0.000479126012974368,
      "loss": 2.1038,
      "step": 7180
    },
    {
      "epoch": 27.976653696498055,
      "grad_norm": 0.30905017256736755,
      "learning_rate": 0.0004790642275328739,
      "loss": 2.1055,
      "step": 7190
    },
    {
      "epoch": 28.0,
      "eval_loss": 1.0930293798446655,
      "eval_runtime": 6.1681,
      "eval_samples_per_second": 3625.581,
      "eval_steps_per_second": 14.267,
      "step": 7196
    },
    {
      "epoch": 28.01556420233463,
      "grad_norm": 0.3634878098964691,
      "learning_rate": 0.00047900235478210595,
      "loss": 2.0836,
      "step": 7200
    },
    {
      "epoch": 28.054474708171206,
      "grad_norm": 0.3338581621646881,
      "learning_rate": 0.0004789403947456474,
      "loss": 2.0913,
      "step": 7210
    },
    {
      "epoch": 28.09338521400778,
      "grad_norm": 0.2974452078342438,
      "learning_rate": 0.0004788783474471146,
      "loss": 2.0937,
      "step": 7220
    },
    {
      "epoch": 28.132295719844358,
      "grad_norm": 0.3183263838291168,
      "learning_rate": 0.0004788162129101574,
      "loss": 2.0948,
      "step": 7230
    },
    {
      "epoch": 28.171206225680933,
      "grad_norm": 0.33026212453842163,
      "learning_rate": 0.00047875399115845875,
      "loss": 2.1028,
      "step": 7240
    },
    {
      "epoch": 28.21011673151751,
      "grad_norm": 0.3324229419231415,
      "learning_rate": 0.0004786916822157348,
      "loss": 2.0933,
      "step": 7250
    },
    {
      "epoch": 28.249027237354085,
      "grad_norm": 0.32210931181907654,
      "learning_rate": 0.00047862928610573497,
      "loss": 2.1077,
      "step": 7260
    },
    {
      "epoch": 28.28793774319066,
      "grad_norm": 0.3240593671798706,
      "learning_rate": 0.0004785668028522421,
      "loss": 2.0912,
      "step": 7270
    },
    {
      "epoch": 28.326848249027236,
      "grad_norm": 0.31232061982154846,
      "learning_rate": 0.00047850423247907184,
      "loss": 2.0919,
      "step": 7280
    },
    {
      "epoch": 28.365758754863812,
      "grad_norm": 0.43722859025001526,
      "learning_rate": 0.0004784415750100735,
      "loss": 2.0839,
      "step": 7290
    },
    {
      "epoch": 28.404669260700388,
      "grad_norm": 0.3273443281650543,
      "learning_rate": 0.00047837883046912924,
      "loss": 2.0989,
      "step": 7300
    },
    {
      "epoch": 28.443579766536963,
      "grad_norm": 0.3055156171321869,
      "learning_rate": 0.0004783159988801545,
      "loss": 2.1027,
      "step": 7310
    },
    {
      "epoch": 28.48249027237354,
      "grad_norm": 0.31095555424690247,
      "learning_rate": 0.00047825308026709813,
      "loss": 2.1013,
      "step": 7320
    },
    {
      "epoch": 28.52140077821012,
      "grad_norm": 0.3273286521434784,
      "learning_rate": 0.0004781900746539417,
      "loss": 2.0993,
      "step": 7330
    },
    {
      "epoch": 28.560311284046694,
      "grad_norm": 0.3163702189922333,
      "learning_rate": 0.00047812698206470044,
      "loss": 2.1017,
      "step": 7340
    },
    {
      "epoch": 28.59922178988327,
      "grad_norm": 0.28724509477615356,
      "learning_rate": 0.00047806380252342237,
      "loss": 2.1101,
      "step": 7350
    },
    {
      "epoch": 28.638132295719846,
      "grad_norm": 0.33833372592926025,
      "learning_rate": 0.0004780005360541887,
      "loss": 2.0872,
      "step": 7360
    },
    {
      "epoch": 28.67704280155642,
      "grad_norm": 0.32186996936798096,
      "learning_rate": 0.00047793718268111394,
      "loss": 2.0938,
      "step": 7370
    },
    {
      "epoch": 28.715953307392997,
      "grad_norm": 0.29800140857696533,
      "learning_rate": 0.0004778737424283457,
      "loss": 2.1025,
      "step": 7380
    },
    {
      "epoch": 28.754863813229573,
      "grad_norm": 0.30051764845848083,
      "learning_rate": 0.0004778102153200645,
      "loss": 2.1243,
      "step": 7390
    },
    {
      "epoch": 28.79377431906615,
      "grad_norm": 0.308670312166214,
      "learning_rate": 0.00047774660138048407,
      "loss": 2.1231,
      "step": 7400
    },
    {
      "epoch": 28.832684824902724,
      "grad_norm": 0.3004368841648102,
      "learning_rate": 0.00047768290063385146,
      "loss": 2.105,
      "step": 7410
    },
    {
      "epoch": 28.8715953307393,
      "grad_norm": 0.30998197197914124,
      "learning_rate": 0.00047761911310444636,
      "loss": 2.109,
      "step": 7420
    },
    {
      "epoch": 28.910505836575876,
      "grad_norm": 0.28374287486076355,
      "learning_rate": 0.00047755523881658197,
      "loss": 2.101,
      "step": 7430
    },
    {
      "epoch": 28.94941634241245,
      "grad_norm": 0.3095645606517792,
      "learning_rate": 0.00047749127779460435,
      "loss": 2.1049,
      "step": 7440
    },
    {
      "epoch": 28.988326848249027,
      "grad_norm": 0.34755101799964905,
      "learning_rate": 0.00047742723006289256,
      "loss": 2.0933,
      "step": 7450
    },
    {
      "epoch": 29.0,
      "eval_loss": 1.0950520038604736,
      "eval_runtime": 6.2048,
      "eval_samples_per_second": 3604.166,
      "eval_steps_per_second": 14.183,
      "step": 7453
    },
    {
      "epoch": 29.027237354085603,
      "grad_norm": 0.30143028497695923,
      "learning_rate": 0.0004773630956458588,
      "loss": 2.0946,
      "step": 7460
    },
    {
      "epoch": 29.06614785992218,
      "grad_norm": 0.31463032960891724,
      "learning_rate": 0.00047729887456794847,
      "loss": 2.1037,
      "step": 7470
    },
    {
      "epoch": 29.105058365758754,
      "grad_norm": 0.2869671881198883,
      "learning_rate": 0.0004772345668536397,
      "loss": 2.0932,
      "step": 7480
    },
    {
      "epoch": 29.14396887159533,
      "grad_norm": 0.3032402992248535,
      "learning_rate": 0.0004771701725274438,
      "loss": 2.0936,
      "step": 7490
    },
    {
      "epoch": 29.182879377431906,
      "grad_norm": 0.3147531747817993,
      "learning_rate": 0.00047710569161390506,
      "loss": 2.0935,
      "step": 7500
    },
    {
      "epoch": 29.22178988326848,
      "grad_norm": 0.32282671332359314,
      "learning_rate": 0.0004770411241376008,
      "loss": 2.0835,
      "step": 7510
    },
    {
      "epoch": 29.260700389105057,
      "grad_norm": 0.31430256366729736,
      "learning_rate": 0.00047697647012314137,
      "loss": 2.0868,
      "step": 7520
    },
    {
      "epoch": 29.299610894941633,
      "grad_norm": 0.3123592138290405,
      "learning_rate": 0.00047691172959517003,
      "loss": 2.1033,
      "step": 7530
    },
    {
      "epoch": 29.33852140077821,
      "grad_norm": 0.3313980996608734,
      "learning_rate": 0.0004768469025783629,
      "loss": 2.0842,
      "step": 7540
    },
    {
      "epoch": 29.377431906614785,
      "grad_norm": 0.31519243121147156,
      "learning_rate": 0.00047678198909742946,
      "loss": 2.1139,
      "step": 7550
    },
    {
      "epoch": 29.41634241245136,
      "grad_norm": 0.3242683708667755,
      "learning_rate": 0.00047671698917711177,
      "loss": 2.0875,
      "step": 7560
    },
    {
      "epoch": 29.455252918287936,
      "grad_norm": 0.3795795440673828,
      "learning_rate": 0.0004766519028421849,
      "loss": 2.1197,
      "step": 7570
    },
    {
      "epoch": 29.494163424124515,
      "grad_norm": 0.3148595988750458,
      "learning_rate": 0.00047658673011745703,
      "loss": 2.0977,
      "step": 7580
    },
    {
      "epoch": 29.53307392996109,
      "grad_norm": 0.31276267766952515,
      "learning_rate": 0.00047652147102776897,
      "loss": 2.0901,
      "step": 7590
    },
    {
      "epoch": 29.571984435797667,
      "grad_norm": 0.31302210688591003,
      "learning_rate": 0.00047645612559799483,
      "loss": 2.0969,
      "step": 7600
    },
    {
      "epoch": 29.610894941634243,
      "grad_norm": 0.3081890642642975,
      "learning_rate": 0.00047639069385304136,
      "loss": 2.0992,
      "step": 7610
    },
    {
      "epoch": 29.64980544747082,
      "grad_norm": 0.3261546492576599,
      "learning_rate": 0.0004763251758178483,
      "loss": 2.0941,
      "step": 7620
    },
    {
      "epoch": 29.688715953307394,
      "grad_norm": 0.3052258789539337,
      "learning_rate": 0.0004762595715173882,
      "loss": 2.1002,
      "step": 7630
    },
    {
      "epoch": 29.72762645914397,
      "grad_norm": 0.2965031564235687,
      "learning_rate": 0.0004761938809766666,
      "loss": 2.0994,
      "step": 7640
    },
    {
      "epoch": 29.766536964980546,
      "grad_norm": 0.30291545391082764,
      "learning_rate": 0.00047612810422072193,
      "loss": 2.0914,
      "step": 7650
    },
    {
      "epoch": 29.80544747081712,
      "grad_norm": 0.3119681477546692,
      "learning_rate": 0.00047606224127462525,
      "loss": 2.0957,
      "step": 7660
    },
    {
      "epoch": 29.844357976653697,
      "grad_norm": 0.2995319068431854,
      "learning_rate": 0.0004759962921634808,
      "loss": 2.0859,
      "step": 7670
    },
    {
      "epoch": 29.883268482490273,
      "grad_norm": 0.3222832977771759,
      "learning_rate": 0.0004759302569124254,
      "loss": 2.096,
      "step": 7680
    },
    {
      "epoch": 29.92217898832685,
      "grad_norm": 0.41001954674720764,
      "learning_rate": 0.0004758641355466288,
      "loss": 2.097,
      "step": 7690
    },
    {
      "epoch": 29.961089494163424,
      "grad_norm": 0.31459102034568787,
      "learning_rate": 0.0004757979280912937,
      "loss": 2.0971,
      "step": 7700
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.4315572679042816,
      "learning_rate": 0.0004757316345716554,
      "loss": 2.1054,
      "step": 7710
    },
    {
      "epoch": 30.0,
      "eval_loss": 1.0900591611862183,
      "eval_runtime": 6.1826,
      "eval_samples_per_second": 3617.084,
      "eval_steps_per_second": 14.233,
      "step": 7710
    },
    {
      "epoch": 30.038910505836576,
      "grad_norm": 0.3766585886478424,
      "learning_rate": 0.000475665255012982,
      "loss": 2.106,
      "step": 7720
    },
    {
      "epoch": 30.07782101167315,
      "grad_norm": 0.31832465529441833,
      "learning_rate": 0.0004755987894405746,
      "loss": 2.0779,
      "step": 7730
    },
    {
      "epoch": 30.116731517509727,
      "grad_norm": 0.29259881377220154,
      "learning_rate": 0.0004755322378797669,
      "loss": 2.0752,
      "step": 7740
    },
    {
      "epoch": 30.155642023346303,
      "grad_norm": 0.2886183559894562,
      "learning_rate": 0.00047546560035592557,
      "loss": 2.0949,
      "step": 7750
    },
    {
      "epoch": 30.19455252918288,
      "grad_norm": 0.3151682913303375,
      "learning_rate": 0.0004753988768944498,
      "loss": 2.0932,
      "step": 7760
    },
    {
      "epoch": 30.233463035019454,
      "grad_norm": 0.3206607699394226,
      "learning_rate": 0.00047533206752077177,
      "loss": 2.0931,
      "step": 7770
    },
    {
      "epoch": 30.27237354085603,
      "grad_norm": 0.30808430910110474,
      "learning_rate": 0.00047526517226035615,
      "loss": 2.1017,
      "step": 7780
    },
    {
      "epoch": 30.311284046692606,
      "grad_norm": 0.31915155053138733,
      "learning_rate": 0.0004751981911387006,
      "loss": 2.0924,
      "step": 7790
    },
    {
      "epoch": 30.35019455252918,
      "grad_norm": 0.28224387764930725,
      "learning_rate": 0.0004751311241813354,
      "loss": 2.0967,
      "step": 7800
    },
    {
      "epoch": 30.389105058365757,
      "grad_norm": 0.2948428690433502,
      "learning_rate": 0.0004750639714138235,
      "loss": 2.0943,
      "step": 7810
    },
    {
      "epoch": 30.428015564202333,
      "grad_norm": 0.3122663199901581,
      "learning_rate": 0.0004749967328617606,
      "loss": 2.0856,
      "step": 7820
    },
    {
      "epoch": 30.46692607003891,
      "grad_norm": 0.30960968136787415,
      "learning_rate": 0.00047492940855077504,
      "loss": 2.0963,
      "step": 7830
    },
    {
      "epoch": 30.505836575875485,
      "grad_norm": 0.2872404456138611,
      "learning_rate": 0.00047486199850652804,
      "loss": 2.0756,
      "step": 7840
    },
    {
      "epoch": 30.544747081712064,
      "grad_norm": 0.28238794207572937,
      "learning_rate": 0.00047479450275471325,
      "loss": 2.0928,
      "step": 7850
    },
    {
      "epoch": 30.58365758754864,
      "grad_norm": 0.31824254989624023,
      "learning_rate": 0.00047472692132105723,
      "loss": 2.0867,
      "step": 7860
    },
    {
      "epoch": 30.622568093385215,
      "grad_norm": 0.29284945130348206,
      "learning_rate": 0.00047465925423131894,
      "loss": 2.0911,
      "step": 7870
    },
    {
      "epoch": 30.66147859922179,
      "grad_norm": 0.3000488877296448,
      "learning_rate": 0.00047459150151129013,
      "loss": 2.092,
      "step": 7880
    },
    {
      "epoch": 30.700389105058367,
      "grad_norm": 0.2965580224990845,
      "learning_rate": 0.00047452366318679527,
      "loss": 2.105,
      "step": 7890
    },
    {
      "epoch": 30.739299610894943,
      "grad_norm": 0.30240485072135925,
      "learning_rate": 0.00047445573928369127,
      "loss": 2.0928,
      "step": 7900
    },
    {
      "epoch": 30.77821011673152,
      "grad_norm": 0.3134812116622925,
      "learning_rate": 0.00047438772982786784,
      "loss": 2.1016,
      "step": 7910
    },
    {
      "epoch": 30.817120622568094,
      "grad_norm": 0.30657124519348145,
      "learning_rate": 0.0004743196348452471,
      "loss": 2.0896,
      "step": 7920
    },
    {
      "epoch": 30.85603112840467,
      "grad_norm": 0.3092533051967621,
      "learning_rate": 0.00047425145436178395,
      "loss": 2.0779,
      "step": 7930
    },
    {
      "epoch": 30.894941634241246,
      "grad_norm": 0.3159211575984955,
      "learning_rate": 0.0004741831884034659,
      "loss": 2.1008,
      "step": 7940
    },
    {
      "epoch": 30.93385214007782,
      "grad_norm": 0.2954731583595276,
      "learning_rate": 0.0004741148369963127,
      "loss": 2.0869,
      "step": 7950
    },
    {
      "epoch": 30.972762645914397,
      "grad_norm": 0.3332134783267975,
      "learning_rate": 0.00047404640016637713,
      "loss": 2.1016,
      "step": 7960
    },
    {
      "epoch": 31.0,
      "eval_loss": 1.0897901058197021,
      "eval_runtime": 6.185,
      "eval_samples_per_second": 3615.711,
      "eval_steps_per_second": 14.228,
      "step": 7967
    },
    {
      "epoch": 31.011673151750973,
      "grad_norm": 0.2826870381832123,
      "learning_rate": 0.0004739778779397443,
      "loss": 2.0949,
      "step": 7970
    },
    {
      "epoch": 31.05058365758755,
      "grad_norm": 0.35251086950302124,
      "learning_rate": 0.00047390927034253184,
      "loss": 2.076,
      "step": 7980
    },
    {
      "epoch": 31.089494163424124,
      "grad_norm": 0.32421693205833435,
      "learning_rate": 0.0004738405774008899,
      "loss": 2.0968,
      "step": 7990
    },
    {
      "epoch": 31.1284046692607,
      "grad_norm": 0.34960466623306274,
      "learning_rate": 0.0004737717991410014,
      "loss": 2.0957,
      "step": 8000
    },
    {
      "epoch": 31.167315175097276,
      "grad_norm": 0.33993828296661377,
      "learning_rate": 0.0004737029355890815,
      "loss": 2.08,
      "step": 8010
    },
    {
      "epoch": 31.20622568093385,
      "grad_norm": 0.3593460023403168,
      "learning_rate": 0.000473633986771378,
      "loss": 2.0853,
      "step": 8020
    },
    {
      "epoch": 31.245136186770427,
      "grad_norm": 0.349301278591156,
      "learning_rate": 0.0004735649527141711,
      "loss": 2.0945,
      "step": 8030
    },
    {
      "epoch": 31.284046692607003,
      "grad_norm": 0.3090720474720001,
      "learning_rate": 0.0004734958334437737,
      "loss": 2.0769,
      "step": 8040
    },
    {
      "epoch": 31.32295719844358,
      "grad_norm": 0.335137277841568,
      "learning_rate": 0.000473426628986531,
      "loss": 2.0763,
      "step": 8050
    },
    {
      "epoch": 31.361867704280154,
      "grad_norm": 0.3215181529521942,
      "learning_rate": 0.00047335733936882063,
      "loss": 2.0962,
      "step": 8060
    },
    {
      "epoch": 31.40077821011673,
      "grad_norm": 0.3088392913341522,
      "learning_rate": 0.0004732879646170528,
      "loss": 2.0774,
      "step": 8070
    },
    {
      "epoch": 31.439688715953306,
      "grad_norm": 0.3314628005027771,
      "learning_rate": 0.00047321850475767025,
      "loss": 2.0837,
      "step": 8080
    },
    {
      "epoch": 31.47859922178988,
      "grad_norm": 0.3249994218349457,
      "learning_rate": 0.0004731489598171479,
      "loss": 2.0838,
      "step": 8090
    },
    {
      "epoch": 31.51750972762646,
      "grad_norm": 0.3334130048751831,
      "learning_rate": 0.0004730793298219933,
      "loss": 2.098,
      "step": 8100
    },
    {
      "epoch": 31.556420233463037,
      "grad_norm": 0.3030069172382355,
      "learning_rate": 0.0004730096147987464,
      "loss": 2.0925,
      "step": 8110
    },
    {
      "epoch": 31.595330739299612,
      "grad_norm": 0.3548138737678528,
      "learning_rate": 0.0004729398147739794,
      "loss": 2.0995,
      "step": 8120
    },
    {
      "epoch": 31.634241245136188,
      "grad_norm": 0.3095841109752655,
      "learning_rate": 0.0004728699297742972,
      "loss": 2.0839,
      "step": 8130
    },
    {
      "epoch": 31.673151750972764,
      "grad_norm": 0.34161850810050964,
      "learning_rate": 0.0004727999598263367,
      "loss": 2.0796,
      "step": 8140
    },
    {
      "epoch": 31.71206225680934,
      "grad_norm": 0.30658265948295593,
      "learning_rate": 0.0004727299049567676,
      "loss": 2.0855,
      "step": 8150
    },
    {
      "epoch": 31.750972762645915,
      "grad_norm": 0.2722902297973633,
      "learning_rate": 0.0004726597651922916,
      "loss": 2.0983,
      "step": 8160
    },
    {
      "epoch": 31.78988326848249,
      "grad_norm": 0.3127340078353882,
      "learning_rate": 0.000472589540559643,
      "loss": 2.0791,
      "step": 8170
    },
    {
      "epoch": 31.828793774319067,
      "grad_norm": 0.3278551697731018,
      "learning_rate": 0.00047251923108558824,
      "loss": 2.0827,
      "step": 8180
    },
    {
      "epoch": 31.867704280155642,
      "grad_norm": 0.3477020263671875,
      "learning_rate": 0.00047244883679692633,
      "loss": 2.0993,
      "step": 8190
    },
    {
      "epoch": 31.90661478599222,
      "grad_norm": 0.3097165524959564,
      "learning_rate": 0.0004723783577204885,
      "loss": 2.0801,
      "step": 8200
    },
    {
      "epoch": 31.945525291828794,
      "grad_norm": 0.32586467266082764,
      "learning_rate": 0.00047230779388313825,
      "loss": 2.0978,
      "step": 8210
    },
    {
      "epoch": 31.98443579766537,
      "grad_norm": 0.28478899598121643,
      "learning_rate": 0.00047223714531177143,
      "loss": 2.0946,
      "step": 8220
    },
    {
      "epoch": 32.0,
      "eval_loss": 1.0917067527770996,
      "eval_runtime": 6.1838,
      "eval_samples_per_second": 3616.375,
      "eval_steps_per_second": 14.231,
      "step": 8224
    },
    {
      "epoch": 32.023346303501945,
      "grad_norm": 0.3453754186630249,
      "learning_rate": 0.0004721664120333162,
      "loss": 2.0771,
      "step": 8230
    },
    {
      "epoch": 32.06225680933852,
      "grad_norm": 0.2936173677444458,
      "learning_rate": 0.000472095594074733,
      "loss": 2.0881,
      "step": 8240
    },
    {
      "epoch": 32.1011673151751,
      "grad_norm": 0.30448541045188904,
      "learning_rate": 0.00047202469146301454,
      "loss": 2.0954,
      "step": 8250
    },
    {
      "epoch": 32.14007782101167,
      "grad_norm": 0.29691994190216064,
      "learning_rate": 0.0004719537042251858,
      "loss": 2.0875,
      "step": 8260
    },
    {
      "epoch": 32.17898832684825,
      "grad_norm": 0.30210229754447937,
      "learning_rate": 0.00047188263238830396,
      "loss": 2.0837,
      "step": 8270
    },
    {
      "epoch": 32.217898832684824,
      "grad_norm": 0.3222753703594208,
      "learning_rate": 0.00047181147597945863,
      "loss": 2.0828,
      "step": 8280
    },
    {
      "epoch": 32.2568093385214,
      "grad_norm": 0.3136647343635559,
      "learning_rate": 0.0004717402350257715,
      "loss": 2.0764,
      "step": 8290
    },
    {
      "epoch": 32.295719844357976,
      "grad_norm": 0.3446131646633148,
      "learning_rate": 0.0004716689095543963,
      "loss": 2.0744,
      "step": 8300
    },
    {
      "epoch": 32.33463035019455,
      "grad_norm": 0.3164076805114746,
      "learning_rate": 0.00047159749959251935,
      "loss": 2.0869,
      "step": 8310
    },
    {
      "epoch": 32.37354085603113,
      "grad_norm": 0.3193851411342621,
      "learning_rate": 0.00047152600516735905,
      "loss": 2.0924,
      "step": 8320
    },
    {
      "epoch": 32.4124513618677,
      "grad_norm": 0.31758272647857666,
      "learning_rate": 0.0004714544263061659,
      "loss": 2.0901,
      "step": 8330
    },
    {
      "epoch": 32.45136186770428,
      "grad_norm": 0.29760780930519104,
      "learning_rate": 0.00047138276303622254,
      "loss": 2.0836,
      "step": 8340
    },
    {
      "epoch": 32.490272373540854,
      "grad_norm": 0.3239668607711792,
      "learning_rate": 0.000471311015384844,
      "loss": 2.0752,
      "step": 8350
    },
    {
      "epoch": 32.52918287937743,
      "grad_norm": 0.3007654547691345,
      "learning_rate": 0.0004712391833793773,
      "loss": 2.087,
      "step": 8360
    },
    {
      "epoch": 32.568093385214006,
      "grad_norm": 0.328887403011322,
      "learning_rate": 0.0004711672670472017,
      "loss": 2.0864,
      "step": 8370
    },
    {
      "epoch": 32.60700389105058,
      "grad_norm": 0.31831228733062744,
      "learning_rate": 0.00047109526641572855,
      "loss": 2.0968,
      "step": 8380
    },
    {
      "epoch": 32.64591439688716,
      "grad_norm": 0.28551751375198364,
      "learning_rate": 0.0004710231815124013,
      "loss": 2.0881,
      "step": 8390
    },
    {
      "epoch": 32.68482490272373,
      "grad_norm": 0.3128146529197693,
      "learning_rate": 0.00047095101236469564,
      "loss": 2.0904,
      "step": 8400
    },
    {
      "epoch": 32.72373540856031,
      "grad_norm": 0.2982674837112427,
      "learning_rate": 0.00047087875900011914,
      "loss": 2.0819,
      "step": 8410
    },
    {
      "epoch": 32.762645914396884,
      "grad_norm": 0.30564382672309875,
      "learning_rate": 0.0004708064214462118,
      "loss": 2.084,
      "step": 8420
    },
    {
      "epoch": 32.80155642023346,
      "grad_norm": 0.30514466762542725,
      "learning_rate": 0.0004707339997305455,
      "loss": 2.088,
      "step": 8430
    },
    {
      "epoch": 32.840466926070036,
      "grad_norm": 0.2797330915927887,
      "learning_rate": 0.00047066149388072417,
      "loss": 2.0798,
      "step": 8440
    },
    {
      "epoch": 32.87937743190661,
      "grad_norm": 0.3211042284965515,
      "learning_rate": 0.00047058890392438394,
      "loss": 2.0883,
      "step": 8450
    },
    {
      "epoch": 32.91828793774319,
      "grad_norm": 0.2830042839050293,
      "learning_rate": 0.00047051622988919284,
      "loss": 2.0854,
      "step": 8460
    },
    {
      "epoch": 32.95719844357976,
      "grad_norm": 0.29492297768592834,
      "learning_rate": 0.0004704434718028511,
      "loss": 2.0704,
      "step": 8470
    },
    {
      "epoch": 32.99610894941634,
      "grad_norm": 0.2734339237213135,
      "learning_rate": 0.0004703706296930909,
      "loss": 2.0886,
      "step": 8480
    },
    {
      "epoch": 33.0,
      "eval_loss": 1.0928620100021362,
      "eval_runtime": 6.1941,
      "eval_samples_per_second": 3610.376,
      "eval_steps_per_second": 14.207,
      "step": 8481
    },
    {
      "epoch": 33.03501945525292,
      "grad_norm": 0.32572871446609497,
      "learning_rate": 0.00047029770358767656,
      "loss": 2.0781,
      "step": 8490
    },
    {
      "epoch": 33.0739299610895,
      "grad_norm": 0.3036741018295288,
      "learning_rate": 0.0004702246935144041,
      "loss": 2.0813,
      "step": 8500
    },
    {
      "epoch": 33.11284046692607,
      "grad_norm": 0.35761764645576477,
      "learning_rate": 0.0004701515995011021,
      "loss": 2.0622,
      "step": 8510
    },
    {
      "epoch": 33.15175097276265,
      "grad_norm": 0.283351868391037,
      "learning_rate": 0.00047007842157563055,
      "loss": 2.0787,
      "step": 8520
    },
    {
      "epoch": 33.190661478599225,
      "grad_norm": 0.301846981048584,
      "learning_rate": 0.00047000515976588163,
      "loss": 2.0726,
      "step": 8530
    },
    {
      "epoch": 33.2295719844358,
      "grad_norm": 0.3164525628089905,
      "learning_rate": 0.0004699318140997798,
      "loss": 2.0906,
      "step": 8540
    },
    {
      "epoch": 33.268482490272376,
      "grad_norm": 0.3506430387496948,
      "learning_rate": 0.000469858384605281,
      "loss": 2.077,
      "step": 8550
    },
    {
      "epoch": 33.30739299610895,
      "grad_norm": 0.34091266989707947,
      "learning_rate": 0.0004697848713103735,
      "loss": 2.0739,
      "step": 8560
    },
    {
      "epoch": 33.34630350194553,
      "grad_norm": 0.2949124872684479,
      "learning_rate": 0.00046971127424307724,
      "loss": 2.0742,
      "step": 8570
    },
    {
      "epoch": 33.3852140077821,
      "grad_norm": 0.30874934792518616,
      "learning_rate": 0.00046963759343144425,
      "loss": 2.0786,
      "step": 8580
    },
    {
      "epoch": 33.42412451361868,
      "grad_norm": 0.33211374282836914,
      "learning_rate": 0.0004695638289035584,
      "loss": 2.0846,
      "step": 8590
    },
    {
      "epoch": 33.463035019455255,
      "grad_norm": 0.3090302348136902,
      "learning_rate": 0.0004694899806875356,
      "loss": 2.0943,
      "step": 8600
    },
    {
      "epoch": 33.50194552529183,
      "grad_norm": 0.3170126676559448,
      "learning_rate": 0.00046941604881152346,
      "loss": 2.077,
      "step": 8610
    },
    {
      "epoch": 33.540856031128406,
      "grad_norm": 0.3183177411556244,
      "learning_rate": 0.00046934203330370163,
      "loss": 2.077,
      "step": 8620
    },
    {
      "epoch": 33.57976653696498,
      "grad_norm": 0.3211556375026703,
      "learning_rate": 0.0004692679341922816,
      "loss": 2.0768,
      "step": 8630
    },
    {
      "epoch": 33.61867704280156,
      "grad_norm": 0.3057798445224762,
      "learning_rate": 0.00046919375150550666,
      "loss": 2.0839,
      "step": 8640
    },
    {
      "epoch": 33.65758754863813,
      "grad_norm": 0.30066409707069397,
      "learning_rate": 0.00046911948527165206,
      "loss": 2.0994,
      "step": 8650
    },
    {
      "epoch": 33.69649805447471,
      "grad_norm": 0.2905505895614624,
      "learning_rate": 0.0004690451355190248,
      "loss": 2.0803,
      "step": 8660
    },
    {
      "epoch": 33.735408560311285,
      "grad_norm": 0.29997318983078003,
      "learning_rate": 0.00046897070227596376,
      "loss": 2.0868,
      "step": 8670
    },
    {
      "epoch": 33.77431906614786,
      "grad_norm": 0.31885915994644165,
      "learning_rate": 0.0004688961855708397,
      "loss": 2.0925,
      "step": 8680
    },
    {
      "epoch": 33.81322957198444,
      "grad_norm": 0.3434920310974121,
      "learning_rate": 0.0004688215854320551,
      "loss": 2.0769,
      "step": 8690
    },
    {
      "epoch": 33.85214007782101,
      "grad_norm": 0.30225643515586853,
      "learning_rate": 0.00046874690188804426,
      "loss": 2.0768,
      "step": 8700
    },
    {
      "epoch": 33.89105058365759,
      "grad_norm": 0.3259134888648987,
      "learning_rate": 0.00046867213496727325,
      "loss": 2.0832,
      "step": 8710
    },
    {
      "epoch": 33.929961089494164,
      "grad_norm": 0.3000031113624573,
      "learning_rate": 0.00046859728469824004,
      "loss": 2.0912,
      "step": 8720
    },
    {
      "epoch": 33.96887159533074,
      "grad_norm": 0.3217499256134033,
      "learning_rate": 0.00046852235110947415,
      "loss": 2.0844,
      "step": 8730
    },
    {
      "epoch": 34.0,
      "eval_loss": 1.0893309116363525,
      "eval_runtime": 6.1753,
      "eval_samples_per_second": 3621.374,
      "eval_steps_per_second": 14.25,
      "step": 8738
    },
    {
      "epoch": 34.007782101167315,
      "grad_norm": 0.3613435924053192,
      "learning_rate": 0.00046844733422953715,
      "loss": 2.067,
      "step": 8740
    },
    {
      "epoch": 34.04669260700389,
      "grad_norm": 0.317820280790329,
      "learning_rate": 0.0004683722340870221,
      "loss": 2.0725,
      "step": 8750
    },
    {
      "epoch": 34.08560311284047,
      "grad_norm": 0.30717819929122925,
      "learning_rate": 0.00046829705071055387,
      "loss": 2.0687,
      "step": 8760
    },
    {
      "epoch": 34.12451361867704,
      "grad_norm": 0.32200831174850464,
      "learning_rate": 0.00046822178412878925,
      "loss": 2.0646,
      "step": 8770
    },
    {
      "epoch": 34.16342412451362,
      "grad_norm": 0.3001982867717743,
      "learning_rate": 0.0004681464343704163,
      "loss": 2.0617,
      "step": 8780
    },
    {
      "epoch": 34.202334630350194,
      "grad_norm": 0.3406284749507904,
      "learning_rate": 0.00046807100146415527,
      "loss": 2.0843,
      "step": 8790
    },
    {
      "epoch": 34.24124513618677,
      "grad_norm": 0.3107107877731323,
      "learning_rate": 0.0004679954854387578,
      "loss": 2.071,
      "step": 8800
    },
    {
      "epoch": 34.280155642023345,
      "grad_norm": 0.2904866337776184,
      "learning_rate": 0.00046791988632300725,
      "loss": 2.0816,
      "step": 8810
    },
    {
      "epoch": 34.31906614785992,
      "grad_norm": 0.3433641195297241,
      "learning_rate": 0.0004678442041457188,
      "loss": 2.0643,
      "step": 8820
    },
    {
      "epoch": 34.3579766536965,
      "grad_norm": 0.3711656928062439,
      "learning_rate": 0.0004677684389357392,
      "loss": 2.0794,
      "step": 8830
    },
    {
      "epoch": 34.39688715953307,
      "grad_norm": 0.2898271679878235,
      "learning_rate": 0.0004676925907219467,
      "loss": 2.0667,
      "step": 8840
    },
    {
      "epoch": 34.43579766536965,
      "grad_norm": 0.3267742693424225,
      "learning_rate": 0.0004676166595332515,
      "loss": 2.0861,
      "step": 8850
    },
    {
      "epoch": 34.474708171206224,
      "grad_norm": 0.35224905610084534,
      "learning_rate": 0.0004675406453985951,
      "loss": 2.078,
      "step": 8860
    },
    {
      "epoch": 34.5136186770428,
      "grad_norm": 0.35016947984695435,
      "learning_rate": 0.00046746454834695086,
      "loss": 2.0906,
      "step": 8870
    },
    {
      "epoch": 34.552529182879375,
      "grad_norm": 0.32210439443588257,
      "learning_rate": 0.0004673883684073236,
      "loss": 2.074,
      "step": 8880
    },
    {
      "epoch": 34.59143968871595,
      "grad_norm": 0.3251269459724426,
      "learning_rate": 0.00046731210560874983,
      "loss": 2.0829,
      "step": 8890
    },
    {
      "epoch": 34.63035019455253,
      "grad_norm": 0.2980896532535553,
      "learning_rate": 0.00046723575998029753,
      "loss": 2.0908,
      "step": 8900
    },
    {
      "epoch": 34.6692607003891,
      "grad_norm": 0.31238457560539246,
      "learning_rate": 0.00046715933155106636,
      "loss": 2.0761,
      "step": 8910
    },
    {
      "epoch": 34.70817120622568,
      "grad_norm": 0.31028833985328674,
      "learning_rate": 0.0004670828203501876,
      "loss": 2.0631,
      "step": 8920
    },
    {
      "epoch": 34.747081712062254,
      "grad_norm": 0.27790185809135437,
      "learning_rate": 0.0004670062264068238,
      "loss": 2.0801,
      "step": 8930
    },
    {
      "epoch": 34.78599221789883,
      "grad_norm": 0.31316128373146057,
      "learning_rate": 0.00046692954975016926,
      "loss": 2.0789,
      "step": 8940
    },
    {
      "epoch": 34.824902723735406,
      "grad_norm": 0.3306715488433838,
      "learning_rate": 0.00046685279040944983,
      "loss": 2.076,
      "step": 8950
    },
    {
      "epoch": 34.86381322957198,
      "grad_norm": 0.2847522795200348,
      "learning_rate": 0.0004667759484139228,
      "loss": 2.0803,
      "step": 8960
    },
    {
      "epoch": 34.90272373540856,
      "grad_norm": 0.31590065360069275,
      "learning_rate": 0.000466699023792877,
      "loss": 2.0746,
      "step": 8970
    },
    {
      "epoch": 34.94163424124513,
      "grad_norm": 0.307476669549942,
      "learning_rate": 0.0004666220165756326,
      "loss": 2.0814,
      "step": 8980
    },
    {
      "epoch": 34.98054474708171,
      "grad_norm": 0.2829321026802063,
      "learning_rate": 0.0004665449267915416,
      "loss": 2.0991,
      "step": 8990
    },
    {
      "epoch": 35.0,
      "eval_loss": 1.0901159048080444,
      "eval_runtime": 6.1596,
      "eval_samples_per_second": 3630.573,
      "eval_steps_per_second": 14.287,
      "step": 8995
    },
    {
      "epoch": 35.01945525291829,
      "grad_norm": 0.3146551549434662,
      "learning_rate": 0.00046646775446998717,
      "loss": 2.0803,
      "step": 9000
    },
    {
      "epoch": 35.05836575875487,
      "grad_norm": 0.3203655481338501,
      "learning_rate": 0.000466390499640384,
      "loss": 2.0729,
      "step": 9010
    },
    {
      "epoch": 35.09727626459144,
      "grad_norm": 0.3050825595855713,
      "learning_rate": 0.00046631316233217824,
      "loss": 2.0628,
      "step": 9020
    },
    {
      "epoch": 35.13618677042802,
      "grad_norm": 0.3311644196510315,
      "learning_rate": 0.0004662357425748475,
      "loss": 2.0777,
      "step": 9030
    },
    {
      "epoch": 35.175097276264594,
      "grad_norm": 0.3129250705242157,
      "learning_rate": 0.00046615824039790085,
      "loss": 2.0544,
      "step": 9040
    },
    {
      "epoch": 35.21400778210117,
      "grad_norm": 0.31453225016593933,
      "learning_rate": 0.00046608065583087865,
      "loss": 2.0633,
      "step": 9050
    },
    {
      "epoch": 35.252918287937746,
      "grad_norm": 0.33196181058883667,
      "learning_rate": 0.00046600298890335284,
      "loss": 2.0519,
      "step": 9060
    },
    {
      "epoch": 35.29182879377432,
      "grad_norm": 0.32486212253570557,
      "learning_rate": 0.00046592523964492663,
      "loss": 2.0696,
      "step": 9070
    },
    {
      "epoch": 35.3307392996109,
      "grad_norm": 0.3180151879787445,
      "learning_rate": 0.00046584740808523463,
      "loss": 2.0598,
      "step": 9080
    },
    {
      "epoch": 35.36964980544747,
      "grad_norm": 0.3106776773929596,
      "learning_rate": 0.0004657694942539429,
      "loss": 2.0879,
      "step": 9090
    },
    {
      "epoch": 35.40856031128405,
      "grad_norm": 0.2951245605945587,
      "learning_rate": 0.0004656914981807486,
      "loss": 2.0897,
      "step": 9100
    },
    {
      "epoch": 35.447470817120625,
      "grad_norm": 0.2897966504096985,
      "learning_rate": 0.00046561341989538065,
      "loss": 2.0641,
      "step": 9110
    },
    {
      "epoch": 35.4863813229572,
      "grad_norm": 0.3240260183811188,
      "learning_rate": 0.00046553525942759886,
      "loss": 2.0754,
      "step": 9120
    },
    {
      "epoch": 35.525291828793776,
      "grad_norm": 0.3057774007320404,
      "learning_rate": 0.00046545701680719475,
      "loss": 2.0873,
      "step": 9130
    },
    {
      "epoch": 35.56420233463035,
      "grad_norm": 0.3174159824848175,
      "learning_rate": 0.000465378692063991,
      "loss": 2.0828,
      "step": 9140
    },
    {
      "epoch": 35.60311284046693,
      "grad_norm": 0.28341367840766907,
      "learning_rate": 0.0004653002852278414,
      "loss": 2.0772,
      "step": 9150
    },
    {
      "epoch": 35.6420233463035,
      "grad_norm": 0.33015573024749756,
      "learning_rate": 0.00046522179632863144,
      "loss": 2.0792,
      "step": 9160
    },
    {
      "epoch": 35.68093385214008,
      "grad_norm": 0.29368385672569275,
      "learning_rate": 0.0004651432253962775,
      "loss": 2.0908,
      "step": 9170
    },
    {
      "epoch": 35.719844357976655,
      "grad_norm": 0.3284702003002167,
      "learning_rate": 0.0004650645724607274,
      "loss": 2.0616,
      "step": 9180
    },
    {
      "epoch": 35.75875486381323,
      "grad_norm": 0.2880415618419647,
      "learning_rate": 0.00046498583755196036,
      "loss": 2.0923,
      "step": 9190
    },
    {
      "epoch": 35.797665369649806,
      "grad_norm": 0.31112149357795715,
      "learning_rate": 0.00046490702069998635,
      "loss": 2.0679,
      "step": 9200
    },
    {
      "epoch": 35.83657587548638,
      "grad_norm": 0.3071444630622864,
      "learning_rate": 0.00046482812193484723,
      "loss": 2.075,
      "step": 9210
    },
    {
      "epoch": 35.87548638132296,
      "grad_norm": 0.3372829258441925,
      "learning_rate": 0.00046474914128661574,
      "loss": 2.0708,
      "step": 9220
    },
    {
      "epoch": 35.91439688715953,
      "grad_norm": 0.3105931282043457,
      "learning_rate": 0.00046467007878539567,
      "loss": 2.0749,
      "step": 9230
    },
    {
      "epoch": 35.95330739299611,
      "grad_norm": 0.2886524796485901,
      "learning_rate": 0.00046459093446132225,
      "loss": 2.0699,
      "step": 9240
    },
    {
      "epoch": 35.992217898832685,
      "grad_norm": 0.32040461897850037,
      "learning_rate": 0.0004645117083445619,
      "loss": 2.0817,
      "step": 9250
    },
    {
      "epoch": 36.0,
      "eval_loss": 1.091446042060852,
      "eval_runtime": 6.2151,
      "eval_samples_per_second": 3598.197,
      "eval_steps_per_second": 14.159,
      "step": 9252
    },
    {
      "epoch": 36.03112840466926,
      "grad_norm": 0.3244767487049103,
      "learning_rate": 0.0004644324004653122,
      "loss": 2.0646,
      "step": 9260
    },
    {
      "epoch": 36.070038910505836,
      "grad_norm": 0.28791049122810364,
      "learning_rate": 0.00046435301085380167,
      "loss": 2.0788,
      "step": 9270
    },
    {
      "epoch": 36.10894941634241,
      "grad_norm": 0.3397088348865509,
      "learning_rate": 0.00046427353954029034,
      "loss": 2.0533,
      "step": 9280
    },
    {
      "epoch": 36.14785992217899,
      "grad_norm": 0.34834545850753784,
      "learning_rate": 0.00046419398655506903,
      "loss": 2.058,
      "step": 9290
    },
    {
      "epoch": 36.18677042801556,
      "grad_norm": 0.33416056632995605,
      "learning_rate": 0.00046411435192846007,
      "loss": 2.0717,
      "step": 9300
    },
    {
      "epoch": 36.22568093385214,
      "grad_norm": 0.3265443444252014,
      "learning_rate": 0.00046403463569081655,
      "loss": 2.0758,
      "step": 9310
    },
    {
      "epoch": 36.264591439688715,
      "grad_norm": 0.3154310882091522,
      "learning_rate": 0.00046395483787252287,
      "loss": 2.0742,
      "step": 9320
    },
    {
      "epoch": 36.30350194552529,
      "grad_norm": 0.31488433480262756,
      "learning_rate": 0.0004638749585039944,
      "loss": 2.0639,
      "step": 9330
    },
    {
      "epoch": 36.34241245136187,
      "grad_norm": 0.3066293001174927,
      "learning_rate": 0.0004637949976156778,
      "loss": 2.0586,
      "step": 9340
    },
    {
      "epoch": 36.38132295719844,
      "grad_norm": 0.3054104745388031,
      "learning_rate": 0.0004637149552380505,
      "loss": 2.0637,
      "step": 9350
    },
    {
      "epoch": 36.42023346303502,
      "grad_norm": 0.6327810883522034,
      "learning_rate": 0.00046363483140162125,
      "loss": 2.0628,
      "step": 9360
    },
    {
      "epoch": 36.459143968871594,
      "grad_norm": 0.32164984941482544,
      "learning_rate": 0.00046355462613692977,
      "loss": 2.0587,
      "step": 9370
    },
    {
      "epoch": 36.49805447470817,
      "grad_norm": 0.313841313123703,
      "learning_rate": 0.0004634743394745468,
      "loss": 2.0691,
      "step": 9380
    },
    {
      "epoch": 36.536964980544745,
      "grad_norm": 0.29446566104888916,
      "learning_rate": 0.00046339397144507405,
      "loss": 2.0799,
      "step": 9390
    },
    {
      "epoch": 36.57587548638132,
      "grad_norm": 0.30305445194244385,
      "learning_rate": 0.0004633135220791443,
      "loss": 2.0648,
      "step": 9400
    },
    {
      "epoch": 36.6147859922179,
      "grad_norm": 0.3344776928424835,
      "learning_rate": 0.0004632329914074215,
      "loss": 2.0623,
      "step": 9410
    },
    {
      "epoch": 36.65369649805447,
      "grad_norm": 0.3423689007759094,
      "learning_rate": 0.00046315237946060024,
      "loss": 2.0603,
      "step": 9420
    },
    {
      "epoch": 36.69260700389105,
      "grad_norm": 0.30806031823158264,
      "learning_rate": 0.00046307168626940633,
      "loss": 2.0689,
      "step": 9430
    },
    {
      "epoch": 36.731517509727624,
      "grad_norm": 0.29868581891059875,
      "learning_rate": 0.00046299091186459646,
      "loss": 2.0652,
      "step": 9440
    },
    {
      "epoch": 36.7704280155642,
      "grad_norm": 0.316938579082489,
      "learning_rate": 0.0004629100562769584,
      "loss": 2.0853,
      "step": 9450
    },
    {
      "epoch": 36.809338521400775,
      "grad_norm": 0.31598296761512756,
      "learning_rate": 0.00046282911953731055,
      "loss": 2.0628,
      "step": 9460
    },
    {
      "epoch": 36.84824902723735,
      "grad_norm": 0.31475430727005005,
      "learning_rate": 0.0004627481016765027,
      "loss": 2.07,
      "step": 9470
    },
    {
      "epoch": 36.88715953307393,
      "grad_norm": 0.2997882664203644,
      "learning_rate": 0.00046266700272541516,
      "loss": 2.0865,
      "step": 9480
    },
    {
      "epoch": 36.9260700389105,
      "grad_norm": 0.2855740785598755,
      "learning_rate": 0.0004625858227149594,
      "loss": 2.0785,
      "step": 9490
    },
    {
      "epoch": 36.96498054474708,
      "grad_norm": 0.2852614223957062,
      "learning_rate": 0.0004625045616760777,
      "loss": 2.0633,
      "step": 9500
    },
    {
      "epoch": 37.0,
      "eval_loss": 1.0910228490829468,
      "eval_runtime": 6.2094,
      "eval_samples_per_second": 3601.476,
      "eval_steps_per_second": 14.172,
      "step": 9509
    },
    {
      "epoch": 37.00389105058366,
      "grad_norm": 0.33056360483169556,
      "learning_rate": 0.0004624232196397431,
      "loss": 2.0854,
      "step": 9510
    },
    {
      "epoch": 37.04280155642024,
      "grad_norm": 0.31043583154678345,
      "learning_rate": 0.0004623417966369598,
      "loss": 2.0679,
      "step": 9520
    },
    {
      "epoch": 37.08171206225681,
      "grad_norm": 0.30938196182250977,
      "learning_rate": 0.00046226029269876256,
      "loss": 2.0651,
      "step": 9530
    },
    {
      "epoch": 37.12062256809339,
      "grad_norm": 0.29372143745422363,
      "learning_rate": 0.00046217870785621716,
      "loss": 2.0589,
      "step": 9540
    },
    {
      "epoch": 37.159533073929964,
      "grad_norm": 0.31576287746429443,
      "learning_rate": 0.00046209704214042013,
      "loss": 2.0592,
      "step": 9550
    },
    {
      "epoch": 37.19844357976654,
      "grad_norm": 0.35101497173309326,
      "learning_rate": 0.00046201529558249893,
      "loss": 2.0646,
      "step": 9560
    },
    {
      "epoch": 37.237354085603116,
      "grad_norm": 0.3299432396888733,
      "learning_rate": 0.0004619334682136118,
      "loss": 2.0688,
      "step": 9570
    },
    {
      "epoch": 37.27626459143969,
      "grad_norm": 0.32392776012420654,
      "learning_rate": 0.00046185156006494765,
      "loss": 2.0721,
      "step": 9580
    },
    {
      "epoch": 37.31517509727627,
      "grad_norm": 0.3115365207195282,
      "learning_rate": 0.00046176957116772645,
      "loss": 2.0696,
      "step": 9590
    },
    {
      "epoch": 37.35408560311284,
      "grad_norm": 0.292136013507843,
      "learning_rate": 0.0004616875015531986,
      "loss": 2.0676,
      "step": 9600
    },
    {
      "epoch": 37.39299610894942,
      "grad_norm": 0.2751252055168152,
      "learning_rate": 0.0004616053512526456,
      "loss": 2.0681,
      "step": 9610
    },
    {
      "epoch": 37.431906614785994,
      "grad_norm": 0.32247573137283325,
      "learning_rate": 0.00046152312029737946,
      "loss": 2.0784,
      "step": 9620
    },
    {
      "epoch": 37.47081712062257,
      "grad_norm": 0.32863810658454895,
      "learning_rate": 0.00046144080871874304,
      "loss": 2.0507,
      "step": 9630
    },
    {
      "epoch": 37.509727626459146,
      "grad_norm": 0.3196946084499359,
      "learning_rate": 0.00046135841654811006,
      "loss": 2.0693,
      "step": 9640
    },
    {
      "epoch": 37.54863813229572,
      "grad_norm": 0.30140209197998047,
      "learning_rate": 0.0004612759438168846,
      "loss": 2.0701,
      "step": 9650
    },
    {
      "epoch": 37.5875486381323,
      "grad_norm": 0.3156146705150604,
      "learning_rate": 0.0004611933905565018,
      "loss": 2.069,
      "step": 9660
    },
    {
      "epoch": 37.62645914396887,
      "grad_norm": 0.3092404007911682,
      "learning_rate": 0.00046111075679842724,
      "loss": 2.0507,
      "step": 9670
    },
    {
      "epoch": 37.66536964980545,
      "grad_norm": 0.3062949776649475,
      "learning_rate": 0.0004610280425741574,
      "loss": 2.0694,
      "step": 9680
    },
    {
      "epoch": 37.704280155642024,
      "grad_norm": 0.4129616916179657,
      "learning_rate": 0.0004609452479152193,
      "loss": 2.0492,
      "step": 9690
    },
    {
      "epoch": 37.7431906614786,
      "grad_norm": 0.3133569061756134,
      "learning_rate": 0.0004608623728531707,
      "loss": 2.0736,
      "step": 9700
    },
    {
      "epoch": 37.782101167315176,
      "grad_norm": 0.3027936816215515,
      "learning_rate": 0.00046077941741959984,
      "loss": 2.0673,
      "step": 9710
    },
    {
      "epoch": 37.82101167315175,
      "grad_norm": 0.3227345943450928,
      "learning_rate": 0.0004606963816461257,
      "loss": 2.0583,
      "step": 9720
    },
    {
      "epoch": 37.85992217898833,
      "grad_norm": 0.3017555773258209,
      "learning_rate": 0.00046061326556439807,
      "loss": 2.0717,
      "step": 9730
    },
    {
      "epoch": 37.8988326848249,
      "grad_norm": 0.27412959933280945,
      "learning_rate": 0.00046053006920609697,
      "loss": 2.0654,
      "step": 9740
    },
    {
      "epoch": 37.93774319066148,
      "grad_norm": 0.3245597183704376,
      "learning_rate": 0.0004604467926029333,
      "loss": 2.0628,
      "step": 9750
    },
    {
      "epoch": 37.976653696498055,
      "grad_norm": 0.33198174834251404,
      "learning_rate": 0.0004603634357866485,
      "loss": 2.0793,
      "step": 9760
    },
    {
      "epoch": 38.0,
      "eval_loss": 1.0914199352264404,
      "eval_runtime": 6.1755,
      "eval_samples_per_second": 3621.236,
      "eval_steps_per_second": 14.25,
      "step": 9766
    },
    {
      "epoch": 38.01556420233463,
      "grad_norm": 0.34185126423835754,
      "learning_rate": 0.0004602799987890145,
      "loss": 2.0692,
      "step": 9770
    },
    {
      "epoch": 38.054474708171206,
      "grad_norm": 0.2997875213623047,
      "learning_rate": 0.0004601964816418338,
      "loss": 2.0508,
      "step": 9780
    },
    {
      "epoch": 38.09338521400778,
      "grad_norm": 0.3028682768344879,
      "learning_rate": 0.00046011288437693956,
      "loss": 2.0579,
      "step": 9790
    },
    {
      "epoch": 38.13229571984436,
      "grad_norm": 0.31337496638298035,
      "learning_rate": 0.0004600292070261953,
      "loss": 2.0505,
      "step": 9800
    },
    {
      "epoch": 38.17120622568093,
      "grad_norm": 0.3199833333492279,
      "learning_rate": 0.0004599454496214953,
      "loss": 2.0682,
      "step": 9810
    },
    {
      "epoch": 38.21011673151751,
      "grad_norm": 0.3000016212463379,
      "learning_rate": 0.00045986161219476417,
      "loss": 2.0533,
      "step": 9820
    },
    {
      "epoch": 38.249027237354085,
      "grad_norm": 0.3048444092273712,
      "learning_rate": 0.00045977769477795704,
      "loss": 2.0551,
      "step": 9830
    },
    {
      "epoch": 38.28793774319066,
      "grad_norm": 0.3046560287475586,
      "learning_rate": 0.0004596936974030596,
      "loss": 2.0642,
      "step": 9840
    },
    {
      "epoch": 38.326848249027236,
      "grad_norm": 0.31229013204574585,
      "learning_rate": 0.00045960962010208793,
      "loss": 2.0779,
      "step": 9850
    },
    {
      "epoch": 38.36575875486381,
      "grad_norm": 0.2854377031326294,
      "learning_rate": 0.00045952546290708876,
      "loss": 2.0523,
      "step": 9860
    },
    {
      "epoch": 38.40466926070039,
      "grad_norm": 0.29395607113838196,
      "learning_rate": 0.000459441225850139,
      "loss": 2.0596,
      "step": 9870
    },
    {
      "epoch": 38.44357976653696,
      "grad_norm": 0.3306216597557068,
      "learning_rate": 0.0004593569089633461,
      "loss": 2.0768,
      "step": 9880
    },
    {
      "epoch": 38.48249027237354,
      "grad_norm": 0.29021766781806946,
      "learning_rate": 0.00045927251227884813,
      "loss": 2.0561,
      "step": 9890
    },
    {
      "epoch": 38.521400778210115,
      "grad_norm": 0.29887619614601135,
      "learning_rate": 0.0004591880358288133,
      "loss": 2.0656,
      "step": 9900
    },
    {
      "epoch": 38.56031128404669,
      "grad_norm": 0.313811331987381,
      "learning_rate": 0.0004591034796454403,
      "loss": 2.0638,
      "step": 9910
    },
    {
      "epoch": 38.599221789883266,
      "grad_norm": 0.32535240054130554,
      "learning_rate": 0.0004590188437609584,
      "loss": 2.0638,
      "step": 9920
    },
    {
      "epoch": 38.63813229571984,
      "grad_norm": 0.3098970353603363,
      "learning_rate": 0.00045893412820762706,
      "loss": 2.065,
      "step": 9930
    },
    {
      "epoch": 38.67704280155642,
      "grad_norm": 0.31863611936569214,
      "learning_rate": 0.000458849333017736,
      "loss": 2.0695,
      "step": 9940
    },
    {
      "epoch": 38.715953307392994,
      "grad_norm": 0.3087075650691986,
      "learning_rate": 0.00045876445822360567,
      "loss": 2.0695,
      "step": 9950
    },
    {
      "epoch": 38.75486381322957,
      "grad_norm": 0.3137573301792145,
      "learning_rate": 0.00045867950385758644,
      "loss": 2.0545,
      "step": 9960
    },
    {
      "epoch": 38.793774319066145,
      "grad_norm": 0.3018955588340759,
      "learning_rate": 0.00045859446995205936,
      "loss": 2.0593,
      "step": 9970
    },
    {
      "epoch": 38.83268482490272,
      "grad_norm": 0.31242671608924866,
      "learning_rate": 0.00045850935653943546,
      "loss": 2.0522,
      "step": 9980
    },
    {
      "epoch": 38.8715953307393,
      "grad_norm": 0.3049364984035492,
      "learning_rate": 0.00045842416365215647,
      "loss": 2.0694,
      "step": 9990
    },
    {
      "epoch": 38.91050583657587,
      "grad_norm": 0.30241820216178894,
      "learning_rate": 0.0004583388913226939,
      "loss": 2.06,
      "step": 10000
    },
    {
      "epoch": 38.94941634241245,
      "grad_norm": 0.3183806240558624,
      "learning_rate": 0.00045825353958355014,
      "loss": 2.0747,
      "step": 10010
    },
    {
      "epoch": 38.98832684824903,
      "grad_norm": 0.29451948404312134,
      "learning_rate": 0.00045816810846725743,
      "loss": 2.0667,
      "step": 10020
    },
    {
      "epoch": 39.0,
      "eval_loss": 1.0912781953811646,
      "eval_runtime": 6.1818,
      "eval_samples_per_second": 3617.557,
      "eval_steps_per_second": 14.235,
      "step": 10023
    },
    {
      "epoch": 39.02723735408561,
      "grad_norm": 0.3012981116771698,
      "learning_rate": 0.0004580825980063783,
      "loss": 2.0629,
      "step": 10030
    },
    {
      "epoch": 39.06614785992218,
      "grad_norm": 0.31863000988960266,
      "learning_rate": 0.0004579970082335057,
      "loss": 2.0333,
      "step": 10040
    },
    {
      "epoch": 39.10505836575876,
      "grad_norm": 0.3173699975013733,
      "learning_rate": 0.00045791133918126264,
      "loss": 2.0479,
      "step": 10050
    },
    {
      "epoch": 39.143968871595334,
      "grad_norm": 0.3290461599826813,
      "learning_rate": 0.0004578255908823025,
      "loss": 2.0563,
      "step": 10060
    },
    {
      "epoch": 39.18287937743191,
      "grad_norm": 0.31008464097976685,
      "learning_rate": 0.0004577397633693087,
      "loss": 2.0521,
      "step": 10070
    },
    {
      "epoch": 39.221789883268485,
      "grad_norm": 0.32003501057624817,
      "learning_rate": 0.000457653856674995,
      "loss": 2.0633,
      "step": 10080
    },
    {
      "epoch": 39.26070038910506,
      "grad_norm": 0.31132128834724426,
      "learning_rate": 0.0004575678708321053,
      "loss": 2.0562,
      "step": 10090
    },
    {
      "epoch": 39.29961089494164,
      "grad_norm": 0.31987062096595764,
      "learning_rate": 0.00045748180587341355,
      "loss": 2.0585,
      "step": 10100
    },
    {
      "epoch": 39.33852140077821,
      "grad_norm": 0.29487144947052,
      "learning_rate": 0.000457395661831724,
      "loss": 2.0598,
      "step": 10110
    },
    {
      "epoch": 39.37743190661479,
      "grad_norm": 0.31737542152404785,
      "learning_rate": 0.00045730943873987097,
      "loss": 2.0556,
      "step": 10120
    },
    {
      "epoch": 39.416342412451364,
      "grad_norm": 0.30238714814186096,
      "learning_rate": 0.00045722313663071904,
      "loss": 2.0535,
      "step": 10130
    },
    {
      "epoch": 39.45525291828794,
      "grad_norm": 0.3207437992095947,
      "learning_rate": 0.00045713675553716264,
      "loss": 2.064,
      "step": 10140
    },
    {
      "epoch": 39.494163424124515,
      "grad_norm": 0.29968148469924927,
      "learning_rate": 0.0004570502954921266,
      "loss": 2.0482,
      "step": 10150
    },
    {
      "epoch": 39.53307392996109,
      "grad_norm": 0.3348155915737152,
      "learning_rate": 0.0004569637565285657,
      "loss": 2.0543,
      "step": 10160
    },
    {
      "epoch": 39.57198443579767,
      "grad_norm": 0.3151359558105469,
      "learning_rate": 0.00045687713867946473,
      "loss": 2.0566,
      "step": 10170
    },
    {
      "epoch": 39.61089494163424,
      "grad_norm": 0.31107598543167114,
      "learning_rate": 0.00045679044197783865,
      "loss": 2.0689,
      "step": 10180
    },
    {
      "epoch": 39.64980544747082,
      "grad_norm": 0.31990063190460205,
      "learning_rate": 0.00045670366645673256,
      "loss": 2.0699,
      "step": 10190
    },
    {
      "epoch": 39.688715953307394,
      "grad_norm": 0.3054283559322357,
      "learning_rate": 0.0004566168121492214,
      "loss": 2.0535,
      "step": 10200
    },
    {
      "epoch": 39.72762645914397,
      "grad_norm": 0.3006927967071533,
      "learning_rate": 0.00045652987908841015,
      "loss": 2.0488,
      "step": 10210
    },
    {
      "epoch": 39.766536964980546,
      "grad_norm": 0.2985933721065521,
      "learning_rate": 0.00045644286730743403,
      "loss": 2.0717,
      "step": 10220
    },
    {
      "epoch": 39.80544747081712,
      "grad_norm": 0.2922404706478119,
      "learning_rate": 0.0004563557768394582,
      "loss": 2.0531,
      "step": 10230
    },
    {
      "epoch": 39.8443579766537,
      "grad_norm": 0.2852391004562378,
      "learning_rate": 0.0004562686077176775,
      "loss": 2.0743,
      "step": 10240
    },
    {
      "epoch": 39.88326848249027,
      "grad_norm": 0.3286898732185364,
      "learning_rate": 0.0004561813599753172,
      "loss": 2.0628,
      "step": 10250
    },
    {
      "epoch": 39.92217898832685,
      "grad_norm": 0.30615055561065674,
      "learning_rate": 0.00045609403364563217,
      "loss": 2.0472,
      "step": 10260
    },
    {
      "epoch": 39.961089494163424,
      "grad_norm": 0.3114861249923706,
      "learning_rate": 0.00045600662876190757,
      "loss": 2.0735,
      "step": 10270
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.4057786762714386,
      "learning_rate": 0.0004559191453574582,
      "loss": 2.0665,
      "step": 10280
    },
    {
      "epoch": 40.0,
      "eval_loss": 1.0905674695968628,
      "eval_runtime": 6.1964,
      "eval_samples_per_second": 3609.037,
      "eval_steps_per_second": 14.202,
      "step": 10280
    },
    {
      "epoch": 40.038910505836576,
      "grad_norm": 0.3006680905818939,
      "learning_rate": 0.0004558315834656289,
      "loss": 2.0538,
      "step": 10290
    },
    {
      "epoch": 40.07782101167315,
      "grad_norm": 0.29833462834358215,
      "learning_rate": 0.0004557439431197945,
      "loss": 2.0541,
      "step": 10300
    },
    {
      "epoch": 40.11673151750973,
      "grad_norm": 0.3415633738040924,
      "learning_rate": 0.0004556562243533597,
      "loss": 2.0596,
      "step": 10310
    },
    {
      "epoch": 40.1556420233463,
      "grad_norm": 0.31448855996131897,
      "learning_rate": 0.00045556842719975886,
      "loss": 2.044,
      "step": 10320
    },
    {
      "epoch": 40.19455252918288,
      "grad_norm": 0.3099713921546936,
      "learning_rate": 0.0004554805516924567,
      "loss": 2.0426,
      "step": 10330
    },
    {
      "epoch": 40.233463035019454,
      "grad_norm": 0.29661524295806885,
      "learning_rate": 0.0004553925978649474,
      "loss": 2.0545,
      "step": 10340
    },
    {
      "epoch": 40.27237354085603,
      "grad_norm": 0.31875544786453247,
      "learning_rate": 0.00045530456575075496,
      "loss": 2.0431,
      "step": 10350
    },
    {
      "epoch": 40.311284046692606,
      "grad_norm": 0.29688403010368347,
      "learning_rate": 0.0004552164553834336,
      "loss": 2.0526,
      "step": 10360
    },
    {
      "epoch": 40.35019455252918,
      "grad_norm": 0.321544349193573,
      "learning_rate": 0.00045512826679656705,
      "loss": 2.0379,
      "step": 10370
    },
    {
      "epoch": 40.38910505836576,
      "grad_norm": 0.2890607714653015,
      "learning_rate": 0.000455040000023769,
      "loss": 2.0389,
      "step": 10380
    },
    {
      "epoch": 40.42801556420233,
      "grad_norm": 0.29288607835769653,
      "learning_rate": 0.00045495165509868275,
      "loss": 2.0591,
      "step": 10390
    },
    {
      "epoch": 40.46692607003891,
      "grad_norm": 0.3032923638820648,
      "learning_rate": 0.00045486323205498163,
      "loss": 2.0588,
      "step": 10400
    },
    {
      "epoch": 40.505836575875485,
      "grad_norm": 0.3119908571243286,
      "learning_rate": 0.00045477473092636866,
      "loss": 2.0563,
      "step": 10410
    },
    {
      "epoch": 40.54474708171206,
      "grad_norm": 0.29368510842323303,
      "learning_rate": 0.00045468615174657656,
      "loss": 2.0428,
      "step": 10420
    },
    {
      "epoch": 40.583657587548636,
      "grad_norm": 0.3039624094963074,
      "learning_rate": 0.0004545974945493678,
      "loss": 2.0558,
      "step": 10430
    },
    {
      "epoch": 40.62256809338521,
      "grad_norm": 0.312734991312027,
      "learning_rate": 0.00045450875936853475,
      "loss": 2.0474,
      "step": 10440
    },
    {
      "epoch": 40.66147859922179,
      "grad_norm": 0.31886908411979675,
      "learning_rate": 0.0004544199462378993,
      "loss": 2.0538,
      "step": 10450
    },
    {
      "epoch": 40.70038910505836,
      "grad_norm": 0.3072415888309479,
      "learning_rate": 0.00045433105519131315,
      "loss": 2.0714,
      "step": 10460
    },
    {
      "epoch": 40.73929961089494,
      "grad_norm": 0.3203084468841553,
      "learning_rate": 0.00045424208626265765,
      "loss": 2.0461,
      "step": 10470
    },
    {
      "epoch": 40.778210116731515,
      "grad_norm": 0.3274776339530945,
      "learning_rate": 0.00045415303948584396,
      "loss": 2.0503,
      "step": 10480
    },
    {
      "epoch": 40.81712062256809,
      "grad_norm": 0.29062438011169434,
      "learning_rate": 0.0004540639148948127,
      "loss": 2.0587,
      "step": 10490
    },
    {
      "epoch": 40.856031128404666,
      "grad_norm": 0.3081248998641968,
      "learning_rate": 0.0004539747125235343,
      "loss": 2.0696,
      "step": 10500
    },
    {
      "epoch": 40.89494163424124,
      "grad_norm": 0.30920282006263733,
      "learning_rate": 0.0004538854324060089,
      "loss": 2.0613,
      "step": 10510
    },
    {
      "epoch": 40.93385214007782,
      "grad_norm": 0.30722200870513916,
      "learning_rate": 0.0004537960745762661,
      "loss": 2.0672,
      "step": 10520
    },
    {
      "epoch": 40.97276264591439,
      "grad_norm": 0.29452982544898987,
      "learning_rate": 0.0004537066390683652,
      "loss": 2.0566,
      "step": 10530
    },
    {
      "epoch": 41.0,
      "eval_loss": 1.090674638748169,
      "eval_runtime": 6.1833,
      "eval_samples_per_second": 3616.656,
      "eval_steps_per_second": 14.232,
      "step": 10537
    },
    {
      "epoch": 41.011673151750976,
      "grad_norm": 0.32264748215675354,
      "learning_rate": 0.00045361712591639517,
      "loss": 2.0621,
      "step": 10540
    },
    {
      "epoch": 41.05058365758755,
      "grad_norm": 0.3371550440788269,
      "learning_rate": 0.00045352753515447435,
      "loss": 2.0388,
      "step": 10550
    },
    {
      "epoch": 41.08949416342413,
      "grad_norm": 0.3188075125217438,
      "learning_rate": 0.00045343786681675103,
      "loss": 2.0456,
      "step": 10560
    },
    {
      "epoch": 41.1284046692607,
      "grad_norm": 0.34104713797569275,
      "learning_rate": 0.00045334812093740274,
      "loss": 2.0644,
      "step": 10570
    },
    {
      "epoch": 41.16731517509728,
      "grad_norm": 0.35248619318008423,
      "learning_rate": 0.00045325829755063675,
      "loss": 2.0347,
      "step": 10580
    },
    {
      "epoch": 41.206225680933855,
      "grad_norm": 0.3021869957447052,
      "learning_rate": 0.00045316839669068973,
      "loss": 2.0397,
      "step": 10590
    },
    {
      "epoch": 41.24513618677043,
      "grad_norm": 0.3078775703907013,
      "learning_rate": 0.00045307841839182795,
      "loss": 2.0499,
      "step": 10600
    },
    {
      "epoch": 41.284046692607006,
      "grad_norm": 0.32075726985931396,
      "learning_rate": 0.0004529883626883474,
      "loss": 2.0471,
      "step": 10610
    },
    {
      "epoch": 41.32295719844358,
      "grad_norm": 0.31393325328826904,
      "learning_rate": 0.0004528982296145731,
      "loss": 2.0361,
      "step": 10620
    },
    {
      "epoch": 41.36186770428016,
      "grad_norm": 0.320852130651474,
      "learning_rate": 0.00045280801920486005,
      "loss": 2.0609,
      "step": 10630
    },
    {
      "epoch": 41.400778210116734,
      "grad_norm": 0.2892123758792877,
      "learning_rate": 0.0004527177314935924,
      "loss": 2.0433,
      "step": 10640
    },
    {
      "epoch": 41.43968871595331,
      "grad_norm": 0.31496596336364746,
      "learning_rate": 0.00045262736651518397,
      "loss": 2.0495,
      "step": 10650
    },
    {
      "epoch": 41.478599221789885,
      "grad_norm": 0.30079081654548645,
      "learning_rate": 0.0004525369243040779,
      "loss": 2.0624,
      "step": 10660
    },
    {
      "epoch": 41.51750972762646,
      "grad_norm": 0.33952611684799194,
      "learning_rate": 0.0004524464048947468,
      "loss": 2.0473,
      "step": 10670
    },
    {
      "epoch": 41.55642023346304,
      "grad_norm": 0.317508339881897,
      "learning_rate": 0.0004523558083216927,
      "loss": 2.0632,
      "step": 10680
    },
    {
      "epoch": 41.59533073929961,
      "grad_norm": 0.31784722208976746,
      "learning_rate": 0.0004522651346194471,
      "loss": 2.0462,
      "step": 10690
    },
    {
      "epoch": 41.63424124513619,
      "grad_norm": 0.3047269880771637,
      "learning_rate": 0.0004521743838225708,
      "loss": 2.0581,
      "step": 10700
    },
    {
      "epoch": 41.673151750972764,
      "grad_norm": 0.29266536235809326,
      "learning_rate": 0.0004520835559656541,
      "loss": 2.0533,
      "step": 10710
    },
    {
      "epoch": 41.71206225680934,
      "grad_norm": 0.3442111015319824,
      "learning_rate": 0.0004519926510833165,
      "loss": 2.0411,
      "step": 10720
    },
    {
      "epoch": 41.750972762645915,
      "grad_norm": 0.29881951212882996,
      "learning_rate": 0.0004519016692102071,
      "loss": 2.0545,
      "step": 10730
    },
    {
      "epoch": 41.78988326848249,
      "grad_norm": 0.36294761300086975,
      "learning_rate": 0.0004518106103810041,
      "loss": 2.0451,
      "step": 10740
    },
    {
      "epoch": 41.82879377431907,
      "grad_norm": 0.32869836688041687,
      "learning_rate": 0.00045171947463041527,
      "loss": 2.0468,
      "step": 10750
    },
    {
      "epoch": 41.86770428015564,
      "grad_norm": 0.2802167534828186,
      "learning_rate": 0.00045162826199317746,
      "loss": 2.0536,
      "step": 10760
    },
    {
      "epoch": 41.90661478599222,
      "grad_norm": 0.30475664138793945,
      "learning_rate": 0.000451536972504057,
      "loss": 2.0633,
      "step": 10770
    },
    {
      "epoch": 41.945525291828794,
      "grad_norm": 0.29572153091430664,
      "learning_rate": 0.0004514456061978495,
      "loss": 2.055,
      "step": 10780
    },
    {
      "epoch": 41.98443579766537,
      "grad_norm": 0.2998575270175934,
      "learning_rate": 0.0004513541631093797,
      "loss": 2.0476,
      "step": 10790
    },
    {
      "epoch": 42.0,
      "eval_loss": 1.08894944190979,
      "eval_runtime": 6.19,
      "eval_samples_per_second": 3612.79,
      "eval_steps_per_second": 14.217,
      "step": 10794
    },
    {
      "epoch": 42.023346303501945,
      "grad_norm": 0.33052441477775574,
      "learning_rate": 0.00045126264327350176,
      "loss": 2.04,
      "step": 10800
    },
    {
      "epoch": 42.06225680933852,
      "grad_norm": 0.31349122524261475,
      "learning_rate": 0.000451171046725099,
      "loss": 2.0545,
      "step": 10810
    },
    {
      "epoch": 42.1011673151751,
      "grad_norm": 0.2989453077316284,
      "learning_rate": 0.0004510793734990841,
      "loss": 2.0446,
      "step": 10820
    },
    {
      "epoch": 42.14007782101167,
      "grad_norm": 0.35786768794059753,
      "learning_rate": 0.00045098762363039886,
      "loss": 2.0232,
      "step": 10830
    },
    {
      "epoch": 42.17898832684825,
      "grad_norm": 0.33550673723220825,
      "learning_rate": 0.0004508957971540143,
      "loss": 2.041,
      "step": 10840
    },
    {
      "epoch": 42.217898832684824,
      "grad_norm": 0.3106815218925476,
      "learning_rate": 0.0004508038941049306,
      "loss": 2.0523,
      "step": 10850
    },
    {
      "epoch": 42.2568093385214,
      "grad_norm": 0.351225346326828,
      "learning_rate": 0.0004507119145181774,
      "loss": 2.0578,
      "step": 10860
    },
    {
      "epoch": 42.295719844357976,
      "grad_norm": 0.312956303358078,
      "learning_rate": 0.00045061985842881304,
      "loss": 2.0365,
      "step": 10870
    },
    {
      "epoch": 42.33463035019455,
      "grad_norm": 0.30585670471191406,
      "learning_rate": 0.00045052772587192544,
      "loss": 2.0294,
      "step": 10880
    },
    {
      "epoch": 42.37354085603113,
      "grad_norm": 0.3380487263202667,
      "learning_rate": 0.00045043551688263143,
      "loss": 2.0428,
      "step": 10890
    },
    {
      "epoch": 42.4124513618677,
      "grad_norm": 0.31645217537879944,
      "learning_rate": 0.0004503432314960771,
      "loss": 2.0343,
      "step": 10900
    },
    {
      "epoch": 42.45136186770428,
      "grad_norm": 0.3458648920059204,
      "learning_rate": 0.00045025086974743756,
      "loss": 2.0501,
      "step": 10910
    },
    {
      "epoch": 42.490272373540854,
      "grad_norm": 0.3170071244239807,
      "learning_rate": 0.0004501584316719171,
      "loss": 2.0397,
      "step": 10920
    },
    {
      "epoch": 42.52918287937743,
      "grad_norm": 0.31451326608657837,
      "learning_rate": 0.0004500659173047491,
      "loss": 2.0311,
      "step": 10930
    },
    {
      "epoch": 42.568093385214006,
      "grad_norm": 0.31610554456710815,
      "learning_rate": 0.0004499733266811959,
      "loss": 2.0527,
      "step": 10940
    },
    {
      "epoch": 42.60700389105058,
      "grad_norm": 0.30208536982536316,
      "learning_rate": 0.0004498806598365491,
      "loss": 2.048,
      "step": 10950
    },
    {
      "epoch": 42.64591439688716,
      "grad_norm": 0.34252235293388367,
      "learning_rate": 0.0004497879168061292,
      "loss": 2.0471,
      "step": 10960
    },
    {
      "epoch": 42.68482490272373,
      "grad_norm": 0.3039706349372864,
      "learning_rate": 0.0004496950976252858,
      "loss": 2.0583,
      "step": 10970
    },
    {
      "epoch": 42.72373540856031,
      "grad_norm": 0.33565598726272583,
      "learning_rate": 0.0004496022023293976,
      "loss": 2.0598,
      "step": 10980
    },
    {
      "epoch": 42.762645914396884,
      "grad_norm": 0.29111114144325256,
      "learning_rate": 0.0004495092309538721,
      "loss": 2.0547,
      "step": 10990
    },
    {
      "epoch": 42.80155642023346,
      "grad_norm": 0.31038033962249756,
      "learning_rate": 0.00044941618353414595,
      "loss": 2.0625,
      "step": 11000
    },
    {
      "epoch": 42.840466926070036,
      "grad_norm": 0.2843107581138611,
      "learning_rate": 0.0004493230601056848,
      "loss": 2.0602,
      "step": 11010
    },
    {
      "epoch": 42.87937743190661,
      "grad_norm": 0.3149590492248535,
      "learning_rate": 0.0004492298607039832,
      "loss": 2.0566,
      "step": 11020
    },
    {
      "epoch": 42.91828793774319,
      "grad_norm": 0.3300229012966156,
      "learning_rate": 0.0004491365853645647,
      "loss": 2.0474,
      "step": 11030
    },
    {
      "epoch": 42.95719844357976,
      "grad_norm": 0.3036278486251831,
      "learning_rate": 0.0004490432341229819,
      "loss": 2.0591,
      "step": 11040
    },
    {
      "epoch": 42.99610894941634,
      "grad_norm": 0.3058825135231018,
      "learning_rate": 0.00044894980701481595,
      "loss": 2.0414,
      "step": 11050
    },
    {
      "epoch": 43.0,
      "eval_loss": 1.0893795490264893,
      "eval_runtime": 6.2038,
      "eval_samples_per_second": 3604.745,
      "eval_steps_per_second": 14.185,
      "step": 11051
    },
    {
      "epoch": 43.03501945525292,
      "grad_norm": 0.3119773268699646,
      "learning_rate": 0.0004488563040756774,
      "loss": 2.0384,
      "step": 11060
    },
    {
      "epoch": 43.0739299610895,
      "grad_norm": 0.2976170778274536,
      "learning_rate": 0.00044876272534120546,
      "loss": 2.0341,
      "step": 11070
    },
    {
      "epoch": 43.11284046692607,
      "grad_norm": 0.32536038756370544,
      "learning_rate": 0.0004486690708470681,
      "loss": 2.038,
      "step": 11080
    },
    {
      "epoch": 43.15175097276265,
      "grad_norm": 0.318956583738327,
      "learning_rate": 0.00044857534062896253,
      "loss": 2.0419,
      "step": 11090
    },
    {
      "epoch": 43.190661478599225,
      "grad_norm": 0.3129836916923523,
      "learning_rate": 0.0004484815347226144,
      "loss": 2.0376,
      "step": 11100
    },
    {
      "epoch": 43.2295719844358,
      "grad_norm": 0.3127322494983673,
      "learning_rate": 0.0004483876531637787,
      "loss": 2.0423,
      "step": 11110
    },
    {
      "epoch": 43.268482490272376,
      "grad_norm": 0.308358758687973,
      "learning_rate": 0.0004482936959882388,
      "loss": 2.0394,
      "step": 11120
    },
    {
      "epoch": 43.30739299610895,
      "grad_norm": 0.31442272663116455,
      "learning_rate": 0.00044819966323180697,
      "loss": 2.0499,
      "step": 11130
    },
    {
      "epoch": 43.34630350194553,
      "grad_norm": 0.333359032869339,
      "learning_rate": 0.0004481055549303246,
      "loss": 2.0501,
      "step": 11140
    },
    {
      "epoch": 43.3852140077821,
      "grad_norm": 0.30845293402671814,
      "learning_rate": 0.0004480113711196615,
      "loss": 2.0437,
      "step": 11150
    },
    {
      "epoch": 43.42412451361868,
      "grad_norm": 0.35027632117271423,
      "learning_rate": 0.0004479171118357165,
      "loss": 2.0475,
      "step": 11160
    },
    {
      "epoch": 43.463035019455255,
      "grad_norm": 0.33604246377944946,
      "learning_rate": 0.0004478227771144171,
      "loss": 2.04,
      "step": 11170
    },
    {
      "epoch": 43.50194552529183,
      "grad_norm": 0.3322187662124634,
      "learning_rate": 0.0004477283669917196,
      "loss": 2.0594,
      "step": 11180
    },
    {
      "epoch": 43.540856031128406,
      "grad_norm": 0.32777389883995056,
      "learning_rate": 0.00044763388150360905,
      "loss": 2.0462,
      "step": 11190
    },
    {
      "epoch": 43.57976653696498,
      "grad_norm": 0.3048346936702728,
      "learning_rate": 0.00044753932068609904,
      "loss": 2.0501,
      "step": 11200
    },
    {
      "epoch": 43.61867704280156,
      "grad_norm": 0.2990005314350128,
      "learning_rate": 0.00044744468457523224,
      "loss": 2.0303,
      "step": 11210
    },
    {
      "epoch": 43.65758754863813,
      "grad_norm": 0.3226405382156372,
      "learning_rate": 0.00044734997320707953,
      "loss": 2.0476,
      "step": 11220
    },
    {
      "epoch": 43.69649805447471,
      "grad_norm": 0.3140929639339447,
      "learning_rate": 0.000447255186617741,
      "loss": 2.0482,
      "step": 11230
    },
    {
      "epoch": 43.735408560311285,
      "grad_norm": 0.29611340165138245,
      "learning_rate": 0.00044716032484334503,
      "loss": 2.0606,
      "step": 11240
    },
    {
      "epoch": 43.77431906614786,
      "grad_norm": 0.3340625762939453,
      "learning_rate": 0.00044706538792004875,
      "loss": 2.0408,
      "step": 11250
    },
    {
      "epoch": 43.81322957198444,
      "grad_norm": 0.32214978337287903,
      "learning_rate": 0.00044697037588403807,
      "loss": 2.0361,
      "step": 11260
    },
    {
      "epoch": 43.85214007782101,
      "grad_norm": 0.3131049573421478,
      "learning_rate": 0.0004468752887715273,
      "loss": 2.0581,
      "step": 11270
    },
    {
      "epoch": 43.89105058365759,
      "grad_norm": 0.31759560108184814,
      "learning_rate": 0.00044678012661875967,
      "loss": 2.0406,
      "step": 11280
    },
    {
      "epoch": 43.929961089494164,
      "grad_norm": 0.33321619033813477,
      "learning_rate": 0.00044668488946200663,
      "loss": 2.0419,
      "step": 11290
    },
    {
      "epoch": 43.96887159533074,
      "grad_norm": 0.2787695527076721,
      "learning_rate": 0.00044658957733756854,
      "loss": 2.0433,
      "step": 11300
    },
    {
      "epoch": 44.0,
      "eval_loss": 1.0895109176635742,
      "eval_runtime": 6.4337,
      "eval_samples_per_second": 3475.902,
      "eval_steps_per_second": 13.678,
      "step": 11308
    },
    {
      "epoch": 44.007782101167315,
      "grad_norm": 0.31584620475769043,
      "learning_rate": 0.0004464941902817743,
      "loss": 2.0431,
      "step": 11310
    },
    {
      "epoch": 44.04669260700389,
      "grad_norm": 0.29372987151145935,
      "learning_rate": 0.00044639872833098106,
      "loss": 2.0347,
      "step": 11320
    },
    {
      "epoch": 44.08560311284047,
      "grad_norm": 0.28752169013023376,
      "learning_rate": 0.00044630319152157497,
      "loss": 2.0275,
      "step": 11330
    },
    {
      "epoch": 44.12451361867704,
      "grad_norm": 0.3330048620700836,
      "learning_rate": 0.0004462075798899703,
      "loss": 2.0332,
      "step": 11340
    },
    {
      "epoch": 44.16342412451362,
      "grad_norm": 0.31612372398376465,
      "learning_rate": 0.00044611189347261015,
      "loss": 2.0388,
      "step": 11350
    },
    {
      "epoch": 44.202334630350194,
      "grad_norm": 0.3212594985961914,
      "learning_rate": 0.0004460161323059659,
      "loss": 2.0382,
      "step": 11360
    },
    {
      "epoch": 44.24124513618677,
      "grad_norm": 0.2908320426940918,
      "learning_rate": 0.00044592029642653776,
      "loss": 2.0528,
      "step": 11370
    },
    {
      "epoch": 44.280155642023345,
      "grad_norm": 0.34099775552749634,
      "learning_rate": 0.0004458243858708538,
      "loss": 2.0397,
      "step": 11380
    },
    {
      "epoch": 44.31906614785992,
      "grad_norm": 0.2969682514667511,
      "learning_rate": 0.00044572840067547126,
      "loss": 2.0324,
      "step": 11390
    },
    {
      "epoch": 44.3579766536965,
      "grad_norm": 0.32119956612586975,
      "learning_rate": 0.00044563234087697536,
      "loss": 2.0328,
      "step": 11400
    },
    {
      "epoch": 44.39688715953307,
      "grad_norm": 0.33553749322891235,
      "learning_rate": 0.0004455362065119799,
      "loss": 2.0391,
      "step": 11410
    },
    {
      "epoch": 44.43579766536965,
      "grad_norm": 0.3175380825996399,
      "learning_rate": 0.00044543999761712715,
      "loss": 2.0478,
      "step": 11420
    },
    {
      "epoch": 44.474708171206224,
      "grad_norm": 0.30831199884414673,
      "learning_rate": 0.0004453437142290877,
      "loss": 2.0446,
      "step": 11430
    },
    {
      "epoch": 44.5136186770428,
      "grad_norm": 0.3092600107192993,
      "learning_rate": 0.0004452473563845606,
      "loss": 2.0447,
      "step": 11440
    },
    {
      "epoch": 44.552529182879375,
      "grad_norm": 0.32570111751556396,
      "learning_rate": 0.00044515092412027315,
      "loss": 2.0355,
      "step": 11450
    },
    {
      "epoch": 44.59143968871595,
      "grad_norm": 0.3134258985519409,
      "learning_rate": 0.0004450544174729812,
      "loss": 2.0413,
      "step": 11460
    },
    {
      "epoch": 44.63035019455253,
      "grad_norm": 0.37021690607070923,
      "learning_rate": 0.00044495783647946886,
      "loss": 2.0309,
      "step": 11470
    },
    {
      "epoch": 44.6692607003891,
      "grad_norm": 0.3274710476398468,
      "learning_rate": 0.0004448611811765486,
      "loss": 2.055,
      "step": 11480
    },
    {
      "epoch": 44.70817120622568,
      "grad_norm": 0.3026125133037567,
      "learning_rate": 0.0004447644516010612,
      "loss": 2.0387,
      "step": 11490
    },
    {
      "epoch": 44.747081712062254,
      "grad_norm": 0.3019598722457886,
      "learning_rate": 0.00044466764778987566,
      "loss": 2.0252,
      "step": 11500
    },
    {
      "epoch": 44.78599221789883,
      "grad_norm": 0.3107631802558899,
      "learning_rate": 0.00044457076977988955,
      "loss": 2.0257,
      "step": 11510
    },
    {
      "epoch": 44.824902723735406,
      "grad_norm": 0.29643166065216064,
      "learning_rate": 0.00044447381760802824,
      "loss": 2.0476,
      "step": 11520
    },
    {
      "epoch": 44.86381322957198,
      "grad_norm": 0.31180205941200256,
      "learning_rate": 0.000444376791311246,
      "loss": 2.0532,
      "step": 11530
    },
    {
      "epoch": 44.90272373540856,
      "grad_norm": 0.29472288489341736,
      "learning_rate": 0.0004442796909265247,
      "loss": 2.05,
      "step": 11540
    },
    {
      "epoch": 44.94163424124513,
      "grad_norm": 0.3114880621433258,
      "learning_rate": 0.0004441825164908749,
      "loss": 2.052,
      "step": 11550
    },
    {
      "epoch": 44.98054474708171,
      "grad_norm": 0.2634914219379425,
      "learning_rate": 0.0004440852680413354,
      "loss": 2.0277,
      "step": 11560
    },
    {
      "epoch": 45.0,
      "eval_loss": 1.0927577018737793,
      "eval_runtime": 6.2056,
      "eval_samples_per_second": 3603.697,
      "eval_steps_per_second": 14.181,
      "step": 11565
    },
    {
      "epoch": 45.01945525291829,
      "grad_norm": 0.30697768926620483,
      "learning_rate": 0.00044398794561497284,
      "loss": 2.0315,
      "step": 11570
    },
    {
      "epoch": 45.05836575875487,
      "grad_norm": 0.31534141302108765,
      "learning_rate": 0.0004438905492488824,
      "loss": 2.0133,
      "step": 11580
    },
    {
      "epoch": 45.09727626459144,
      "grad_norm": 0.31005704402923584,
      "learning_rate": 0.00044379307898018724,
      "loss": 2.0208,
      "step": 11590
    },
    {
      "epoch": 45.13618677042802,
      "grad_norm": 0.3121958076953888,
      "learning_rate": 0.00044369553484603874,
      "loss": 2.0359,
      "step": 11600
    },
    {
      "epoch": 45.175097276264594,
      "grad_norm": 0.30824315547943115,
      "learning_rate": 0.0004435979168836166,
      "loss": 2.0418,
      "step": 11610
    },
    {
      "epoch": 45.21400778210117,
      "grad_norm": 0.3375977575778961,
      "learning_rate": 0.00044350022513012845,
      "loss": 2.0325,
      "step": 11620
    },
    {
      "epoch": 45.252918287937746,
      "grad_norm": 0.3160305619239807,
      "learning_rate": 0.0004434024596228101,
      "loss": 2.0198,
      "step": 11630
    },
    {
      "epoch": 45.29182879377432,
      "grad_norm": 0.3356253504753113,
      "learning_rate": 0.0004433046203989254,
      "loss": 2.0468,
      "step": 11640
    },
    {
      "epoch": 45.3307392996109,
      "grad_norm": 0.32421740889549255,
      "learning_rate": 0.00044320670749576664,
      "loss": 2.0437,
      "step": 11650
    },
    {
      "epoch": 45.36964980544747,
      "grad_norm": 0.29911476373672485,
      "learning_rate": 0.00044310872095065367,
      "loss": 2.0372,
      "step": 11660
    },
    {
      "epoch": 45.40856031128405,
      "grad_norm": 0.3034361004829407,
      "learning_rate": 0.0004430106608009349,
      "loss": 2.0327,
      "step": 11670
    },
    {
      "epoch": 45.447470817120625,
      "grad_norm": 0.3187747597694397,
      "learning_rate": 0.0004429125270839864,
      "loss": 2.0436,
      "step": 11680
    },
    {
      "epoch": 45.4863813229572,
      "grad_norm": 0.3230014145374298,
      "learning_rate": 0.0004428143198372125,
      "loss": 2.0312,
      "step": 11690
    },
    {
      "epoch": 45.525291828793776,
      "grad_norm": 0.3370862603187561,
      "learning_rate": 0.0004427160390980456,
      "loss": 2.0418,
      "step": 11700
    },
    {
      "epoch": 45.56420233463035,
      "grad_norm": 0.3137849271297455,
      "learning_rate": 0.0004426176849039459,
      "loss": 2.0354,
      "step": 11710
    },
    {
      "epoch": 45.60311284046693,
      "grad_norm": 0.3023824989795685,
      "learning_rate": 0.00044251925729240184,
      "loss": 2.0288,
      "step": 11720
    },
    {
      "epoch": 45.6420233463035,
      "grad_norm": 0.3455071449279785,
      "learning_rate": 0.00044242075630092966,
      "loss": 2.032,
      "step": 11730
    },
    {
      "epoch": 45.68093385214008,
      "grad_norm": 0.2902064621448517,
      "learning_rate": 0.00044232218196707355,
      "loss": 2.0399,
      "step": 11740
    },
    {
      "epoch": 45.719844357976655,
      "grad_norm": 0.300149142742157,
      "learning_rate": 0.00044222353432840595,
      "loss": 2.0212,
      "step": 11750
    },
    {
      "epoch": 45.75875486381323,
      "grad_norm": 0.307233601808548,
      "learning_rate": 0.0004421248134225269,
      "loss": 2.0526,
      "step": 11760
    },
    {
      "epoch": 45.797665369649806,
      "grad_norm": 0.30086764693260193,
      "learning_rate": 0.0004420260192870644,
      "loss": 2.0423,
      "step": 11770
    },
    {
      "epoch": 45.83657587548638,
      "grad_norm": 0.3136545419692993,
      "learning_rate": 0.0004419271519596746,
      "loss": 2.0253,
      "step": 11780
    },
    {
      "epoch": 45.87548638132296,
      "grad_norm": 0.2858101725578308,
      "learning_rate": 0.0004418282114780413,
      "loss": 2.0435,
      "step": 11790
    },
    {
      "epoch": 45.91439688715953,
      "grad_norm": 0.3046242296695709,
      "learning_rate": 0.00044172919787987646,
      "loss": 2.0514,
      "step": 11800
    },
    {
      "epoch": 45.95330739299611,
      "grad_norm": 0.335970014333725,
      "learning_rate": 0.0004416301112029196,
      "loss": 2.0276,
      "step": 11810
    },
    {
      "epoch": 45.992217898832685,
      "grad_norm": 0.32477307319641113,
      "learning_rate": 0.00044153095148493824,
      "loss": 2.0441,
      "step": 11820
    },
    {
      "epoch": 46.0,
      "eval_loss": 1.0928534269332886,
      "eval_runtime": 6.1792,
      "eval_samples_per_second": 3619.073,
      "eval_steps_per_second": 14.241,
      "step": 11822
    },
    {
      "epoch": 46.03112840466926,
      "grad_norm": 0.2792415916919708,
      "learning_rate": 0.00044143171876372773,
      "loss": 2.022,
      "step": 11830
    },
    {
      "epoch": 46.070038910505836,
      "grad_norm": 0.33301034569740295,
      "learning_rate": 0.0004413324130771113,
      "loss": 2.0183,
      "step": 11840
    },
    {
      "epoch": 46.10894941634241,
      "grad_norm": 0.32302793860435486,
      "learning_rate": 0.00044123303446293996,
      "loss": 2.0322,
      "step": 11850
    },
    {
      "epoch": 46.14785992217899,
      "grad_norm": 0.3143600523471832,
      "learning_rate": 0.0004411335829590923,
      "loss": 2.0319,
      "step": 11860
    },
    {
      "epoch": 46.18677042801556,
      "grad_norm": 0.32257506251335144,
      "learning_rate": 0.00044103405860347513,
      "loss": 2.0254,
      "step": 11870
    },
    {
      "epoch": 46.22568093385214,
      "grad_norm": 0.3080582022666931,
      "learning_rate": 0.00044093446143402264,
      "loss": 2.03,
      "step": 11880
    },
    {
      "epoch": 46.264591439688715,
      "grad_norm": 0.3266943693161011,
      "learning_rate": 0.000440834791488697,
      "loss": 2.0287,
      "step": 11890
    },
    {
      "epoch": 46.30350194552529,
      "grad_norm": 0.34409481287002563,
      "learning_rate": 0.00044073504880548796,
      "loss": 2.0257,
      "step": 11900
    },
    {
      "epoch": 46.34241245136187,
      "grad_norm": 0.32994309067726135,
      "learning_rate": 0.0004406352334224131,
      "loss": 2.0163,
      "step": 11910
    },
    {
      "epoch": 46.38132295719844,
      "grad_norm": 0.29794085025787354,
      "learning_rate": 0.00044053534537751775,
      "loss": 2.0322,
      "step": 11920
    },
    {
      "epoch": 46.42023346303502,
      "grad_norm": 0.30016106367111206,
      "learning_rate": 0.00044043538470887476,
      "loss": 2.0303,
      "step": 11930
    },
    {
      "epoch": 46.459143968871594,
      "grad_norm": 0.3291005492210388,
      "learning_rate": 0.0004403353514545849,
      "loss": 2.0269,
      "step": 11940
    },
    {
      "epoch": 46.49805447470817,
      "grad_norm": 0.30632221698760986,
      "learning_rate": 0.00044023524565277636,
      "loss": 2.029,
      "step": 11950
    },
    {
      "epoch": 46.536964980544745,
      "grad_norm": 0.31113743782043457,
      "learning_rate": 0.00044013506734160514,
      "loss": 2.0339,
      "step": 11960
    },
    {
      "epoch": 46.57587548638132,
      "grad_norm": 0.306467741727829,
      "learning_rate": 0.0004400348165592548,
      "loss": 2.0302,
      "step": 11970
    },
    {
      "epoch": 46.6147859922179,
      "grad_norm": 0.3270135521888733,
      "learning_rate": 0.0004399344933439365,
      "loss": 2.0466,
      "step": 11980
    },
    {
      "epoch": 46.65369649805447,
      "grad_norm": 0.3089309334754944,
      "learning_rate": 0.00043983409773388934,
      "loss": 2.0421,
      "step": 11990
    },
    {
      "epoch": 46.69260700389105,
      "grad_norm": 0.2932821810245514,
      "learning_rate": 0.0004397336297673794,
      "loss": 2.0328,
      "step": 12000
    },
    {
      "epoch": 46.731517509727624,
      "grad_norm": 0.2832854390144348,
      "learning_rate": 0.0004396330894827009,
      "loss": 2.0409,
      "step": 12010
    },
    {
      "epoch": 46.7704280155642,
      "grad_norm": 0.31675341725349426,
      "learning_rate": 0.0004395324769181753,
      "loss": 2.0241,
      "step": 12020
    },
    {
      "epoch": 46.809338521400775,
      "grad_norm": 0.32251259684562683,
      "learning_rate": 0.0004394317921121518,
      "loss": 2.0357,
      "step": 12030
    },
    {
      "epoch": 46.84824902723735,
      "grad_norm": 0.31699812412261963,
      "learning_rate": 0.000439331035103007,
      "loss": 2.0335,
      "step": 12040
    },
    {
      "epoch": 46.88715953307393,
      "grad_norm": 0.3035803735256195,
      "learning_rate": 0.000439230205929145,
      "loss": 2.0392,
      "step": 12050
    },
    {
      "epoch": 46.9260700389105,
      "grad_norm": 0.32494649291038513,
      "learning_rate": 0.00043912930462899755,
      "loss": 2.0461,
      "step": 12060
    },
    {
      "epoch": 46.96498054474708,
      "grad_norm": 0.3082851469516754,
      "learning_rate": 0.0004390283312410238,
      "loss": 2.0443,
      "step": 12070
    },
    {
      "epoch": 47.0,
      "eval_loss": 1.0890164375305176,
      "eval_runtime": 6.1914,
      "eval_samples_per_second": 3611.966,
      "eval_steps_per_second": 14.213,
      "step": 12079
    },
    {
      "epoch": 47.00389105058366,
      "grad_norm": 0.3227735757827759,
      "learning_rate": 0.0004389272858037104,
      "loss": 2.0412,
      "step": 12080
    },
    {
      "epoch": 47.04280155642024,
      "grad_norm": 0.33993974328041077,
      "learning_rate": 0.0004388261683555714,
      "loss": 2.0283,
      "step": 12090
    },
    {
      "epoch": 47.08171206225681,
      "grad_norm": 0.3023635447025299,
      "learning_rate": 0.00043872497893514853,
      "loss": 2.0326,
      "step": 12100
    },
    {
      "epoch": 47.12062256809339,
      "grad_norm": 0.3396088480949402,
      "learning_rate": 0.0004386237175810106,
      "loss": 2.0273,
      "step": 12110
    },
    {
      "epoch": 47.159533073929964,
      "grad_norm": 0.33137038350105286,
      "learning_rate": 0.0004385223843317541,
      "loss": 2.0198,
      "step": 12120
    },
    {
      "epoch": 47.19844357976654,
      "grad_norm": 0.3350865840911865,
      "learning_rate": 0.00043842097922600266,
      "loss": 2.0183,
      "step": 12130
    },
    {
      "epoch": 47.237354085603116,
      "grad_norm": 0.33864232897758484,
      "learning_rate": 0.0004383195023024077,
      "loss": 2.021,
      "step": 12140
    },
    {
      "epoch": 47.27626459143969,
      "grad_norm": 0.2971106767654419,
      "learning_rate": 0.00043821795359964773,
      "loss": 2.0393,
      "step": 12150
    },
    {
      "epoch": 47.31517509727627,
      "grad_norm": 0.35389161109924316,
      "learning_rate": 0.0004381163331564286,
      "loss": 2.0057,
      "step": 12160
    },
    {
      "epoch": 47.35408560311284,
      "grad_norm": 0.3112521767616272,
      "learning_rate": 0.0004380146410114837,
      "loss": 2.0405,
      "step": 12170
    },
    {
      "epoch": 47.39299610894942,
      "grad_norm": 0.2991251051425934,
      "learning_rate": 0.00043791287720357355,
      "loss": 2.0378,
      "step": 12180
    },
    {
      "epoch": 47.431906614785994,
      "grad_norm": 0.3090401887893677,
      "learning_rate": 0.000437811041771486,
      "loss": 2.0136,
      "step": 12190
    },
    {
      "epoch": 47.47081712062257,
      "grad_norm": 0.3279394209384918,
      "learning_rate": 0.0004377091347540364,
      "loss": 2.0286,
      "step": 12200
    },
    {
      "epoch": 47.509727626459146,
      "grad_norm": 0.33274954557418823,
      "learning_rate": 0.00043760715619006724,
      "loss": 2.0288,
      "step": 12210
    },
    {
      "epoch": 47.54863813229572,
      "grad_norm": 0.31205835938453674,
      "learning_rate": 0.00043750510611844826,
      "loss": 2.0217,
      "step": 12220
    },
    {
      "epoch": 47.5875486381323,
      "grad_norm": 0.3184252083301544,
      "learning_rate": 0.00043740298457807644,
      "loss": 2.0374,
      "step": 12230
    },
    {
      "epoch": 47.62645914396887,
      "grad_norm": 0.3106967508792877,
      "learning_rate": 0.00043730079160787604,
      "loss": 2.0342,
      "step": 12240
    },
    {
      "epoch": 47.66536964980545,
      "grad_norm": 0.30374565720558167,
      "learning_rate": 0.0004371985272467987,
      "loss": 2.0368,
      "step": 12250
    },
    {
      "epoch": 47.704280155642024,
      "grad_norm": 0.31424158811569214,
      "learning_rate": 0.00043709619153382297,
      "loss": 2.0239,
      "step": 12260
    },
    {
      "epoch": 47.7431906614786,
      "grad_norm": 0.319485604763031,
      "learning_rate": 0.0004369937845079549,
      "loss": 2.0521,
      "step": 12270
    },
    {
      "epoch": 47.782101167315176,
      "grad_norm": 0.32350561022758484,
      "learning_rate": 0.00043689130620822736,
      "loss": 2.038,
      "step": 12280
    },
    {
      "epoch": 47.82101167315175,
      "grad_norm": 0.3045317530632019,
      "learning_rate": 0.0004367887566737008,
      "loss": 2.0314,
      "step": 12290
    },
    {
      "epoch": 47.85992217898833,
      "grad_norm": 0.3089299499988556,
      "learning_rate": 0.00043668613594346253,
      "loss": 2.0202,
      "step": 12300
    },
    {
      "epoch": 47.8988326848249,
      "grad_norm": 0.3036395013332367,
      "learning_rate": 0.00043658344405662707,
      "loss": 2.0398,
      "step": 12310
    },
    {
      "epoch": 47.93774319066148,
      "grad_norm": 0.3133207857608795,
      "learning_rate": 0.00043648068105233616,
      "loss": 2.0259,
      "step": 12320
    },
    {
      "epoch": 47.976653696498055,
      "grad_norm": 0.3234978914260864,
      "learning_rate": 0.0004363778469697586,
      "loss": 2.0399,
      "step": 12330
    },
    {
      "epoch": 48.0,
      "eval_loss": 1.0901553630828857,
      "eval_runtime": 6.174,
      "eval_samples_per_second": 3622.12,
      "eval_steps_per_second": 14.253,
      "step": 12336
    },
    {
      "epoch": 48.01556420233463,
      "grad_norm": 0.3200002610683441,
      "learning_rate": 0.00043627494184809003,
      "loss": 2.007,
      "step": 12340
    },
    {
      "epoch": 48.054474708171206,
      "grad_norm": 0.2920818328857422,
      "learning_rate": 0.0004361719657265536,
      "loss": 2.0415,
      "step": 12350
    },
    {
      "epoch": 48.09338521400778,
      "grad_norm": 0.331035852432251,
      "learning_rate": 0.00043606891864439917,
      "loss": 2.0061,
      "step": 12360
    },
    {
      "epoch": 48.13229571984436,
      "grad_norm": 0.312898188829422,
      "learning_rate": 0.0004359658006409039,
      "loss": 2.0174,
      "step": 12370
    },
    {
      "epoch": 48.17120622568093,
      "grad_norm": 0.3257216811180115,
      "learning_rate": 0.0004358626117553718,
      "loss": 2.0201,
      "step": 12380
    },
    {
      "epoch": 48.21011673151751,
      "grad_norm": 0.3206202983856201,
      "learning_rate": 0.00043575935202713403,
      "loss": 2.0084,
      "step": 12390
    },
    {
      "epoch": 48.249027237354085,
      "grad_norm": 0.30907920002937317,
      "learning_rate": 0.00043565602149554854,
      "loss": 2.0216,
      "step": 12400
    },
    {
      "epoch": 48.28793774319066,
      "grad_norm": 0.3224622309207916,
      "learning_rate": 0.0004355526202000006,
      "loss": 2.0234,
      "step": 12410
    },
    {
      "epoch": 48.326848249027236,
      "grad_norm": 0.36620527505874634,
      "learning_rate": 0.00043544914817990213,
      "loss": 2.0183,
      "step": 12420
    },
    {
      "epoch": 48.36575875486381,
      "grad_norm": 0.331648588180542,
      "learning_rate": 0.00043534560547469215,
      "loss": 2.0196,
      "step": 12430
    },
    {
      "epoch": 48.40466926070039,
      "grad_norm": 0.31601932644844055,
      "learning_rate": 0.0004352419921238367,
      "loss": 2.0124,
      "step": 12440
    },
    {
      "epoch": 48.44357976653696,
      "grad_norm": 0.30751749873161316,
      "learning_rate": 0.00043513830816682854,
      "loss": 2.0324,
      "step": 12450
    },
    {
      "epoch": 48.48249027237354,
      "grad_norm": 0.31675004959106445,
      "learning_rate": 0.00043503455364318766,
      "loss": 2.0074,
      "step": 12460
    },
    {
      "epoch": 48.521400778210115,
      "grad_norm": 0.2987514138221741,
      "learning_rate": 0.00043493072859246055,
      "loss": 2.038,
      "step": 12470
    },
    {
      "epoch": 48.56031128404669,
      "grad_norm": 0.30839449167251587,
      "learning_rate": 0.00043482683305422085,
      "loss": 2.0297,
      "step": 12480
    },
    {
      "epoch": 48.599221789883266,
      "grad_norm": 0.29021552205085754,
      "learning_rate": 0.000434722867068069,
      "loss": 2.0188,
      "step": 12490
    },
    {
      "epoch": 48.63813229571984,
      "grad_norm": 0.31369397044181824,
      "learning_rate": 0.0004346188306736323,
      "loss": 2.0298,
      "step": 12500
    },
    {
      "epoch": 48.67704280155642,
      "grad_norm": 0.3060145378112793,
      "learning_rate": 0.00043451472391056495,
      "loss": 2.0251,
      "step": 12510
    },
    {
      "epoch": 48.715953307392994,
      "grad_norm": 0.28794217109680176,
      "learning_rate": 0.00043441054681854773,
      "loss": 2.0343,
      "step": 12520
    },
    {
      "epoch": 48.75486381322957,
      "grad_norm": 0.31135332584381104,
      "learning_rate": 0.0004343062994372886,
      "loss": 2.0279,
      "step": 12530
    },
    {
      "epoch": 48.793774319066145,
      "grad_norm": 0.30791664123535156,
      "learning_rate": 0.0004342019818065219,
      "loss": 2.0313,
      "step": 12540
    },
    {
      "epoch": 48.83268482490272,
      "grad_norm": 0.29257598519325256,
      "learning_rate": 0.00043409759396600907,
      "loss": 2.0392,
      "step": 12550
    },
    {
      "epoch": 48.8715953307393,
      "grad_norm": 0.31238889694213867,
      "learning_rate": 0.00043399313595553815,
      "loss": 2.0249,
      "step": 12560
    },
    {
      "epoch": 48.91050583657587,
      "grad_norm": 0.29181504249572754,
      "learning_rate": 0.000433888607814924,
      "loss": 2.0273,
      "step": 12570
    },
    {
      "epoch": 48.94941634241245,
      "grad_norm": 0.3076750636100769,
      "learning_rate": 0.0004337840095840082,
      "loss": 2.0278,
      "step": 12580
    },
    {
      "epoch": 48.98832684824903,
      "grad_norm": 0.3303597569465637,
      "learning_rate": 0.000433679341302659,
      "loss": 2.0173,
      "step": 12590
    },
    {
      "epoch": 49.0,
      "eval_loss": 1.090036153793335,
      "eval_runtime": 6.2057,
      "eval_samples_per_second": 3603.595,
      "eval_steps_per_second": 14.18,
      "step": 12593
    },
    {
      "epoch": 49.02723735408561,
      "grad_norm": 0.31627970933914185,
      "learning_rate": 0.00043357460301077135,
      "loss": 2.0127,
      "step": 12600
    },
    {
      "epoch": 49.06614785992218,
      "grad_norm": 0.30781808495521545,
      "learning_rate": 0.000433469794748267,
      "loss": 2.0082,
      "step": 12610
    },
    {
      "epoch": 49.10505836575876,
      "grad_norm": 0.3230297863483429,
      "learning_rate": 0.0004333649165550941,
      "loss": 2.0068,
      "step": 12620
    },
    {
      "epoch": 49.143968871595334,
      "grad_norm": 0.3303582966327667,
      "learning_rate": 0.00043325996847122777,
      "loss": 2.0191,
      "step": 12630
    },
    {
      "epoch": 49.18287937743191,
      "grad_norm": 0.302624374628067,
      "learning_rate": 0.00043315495053666966,
      "loss": 2.0072,
      "step": 12640
    },
    {
      "epoch": 49.221789883268485,
      "grad_norm": 0.3517746925354004,
      "learning_rate": 0.00043304986279144785,
      "loss": 2.0192,
      "step": 12650
    },
    {
      "epoch": 49.26070038910506,
      "grad_norm": 0.3204719126224518,
      "learning_rate": 0.00043294470527561747,
      "loss": 2.0203,
      "step": 12660
    },
    {
      "epoch": 49.29961089494164,
      "grad_norm": 0.3145825266838074,
      "learning_rate": 0.0004328394780292597,
      "loss": 2.0058,
      "step": 12670
    },
    {
      "epoch": 49.33852140077821,
      "grad_norm": 0.31819382309913635,
      "learning_rate": 0.0004327341810924827,
      "loss": 2.0152,
      "step": 12680
    },
    {
      "epoch": 49.37743190661479,
      "grad_norm": 0.31109681725502014,
      "learning_rate": 0.000432628814505421,
      "loss": 2.0256,
      "step": 12690
    },
    {
      "epoch": 49.416342412451364,
      "grad_norm": 0.31411033868789673,
      "learning_rate": 0.00043252337830823584,
      "loss": 2.026,
      "step": 12700
    },
    {
      "epoch": 49.45525291828794,
      "grad_norm": 0.3471013903617859,
      "learning_rate": 0.00043241787254111487,
      "loss": 2.0169,
      "step": 12710
    },
    {
      "epoch": 49.494163424124515,
      "grad_norm": 0.2983771562576294,
      "learning_rate": 0.00043231229724427213,
      "loss": 2.0205,
      "step": 12720
    },
    {
      "epoch": 49.53307392996109,
      "grad_norm": 0.3105795383453369,
      "learning_rate": 0.00043220665245794854,
      "loss": 2.0342,
      "step": 12730
    },
    {
      "epoch": 49.57198443579767,
      "grad_norm": 0.31590569019317627,
      "learning_rate": 0.00043210093822241104,
      "loss": 2.0282,
      "step": 12740
    },
    {
      "epoch": 49.61089494163424,
      "grad_norm": 0.29914721846580505,
      "learning_rate": 0.0004319951545779535,
      "loss": 2.017,
      "step": 12750
    },
    {
      "epoch": 49.64980544747082,
      "grad_norm": 0.32967182993888855,
      "learning_rate": 0.0004318893015648958,
      "loss": 2.0199,
      "step": 12760
    },
    {
      "epoch": 49.688715953307394,
      "grad_norm": 0.32441702485084534,
      "learning_rate": 0.0004317833792235847,
      "loss": 2.0096,
      "step": 12770
    },
    {
      "epoch": 49.72762645914397,
      "grad_norm": 0.3446827828884125,
      "learning_rate": 0.000431677387594393,
      "loss": 2.0224,
      "step": 12780
    },
    {
      "epoch": 49.766536964980546,
      "grad_norm": 0.33598893880844116,
      "learning_rate": 0.00043157132671772016,
      "loss": 2.033,
      "step": 12790
    },
    {
      "epoch": 49.80544747081712,
      "grad_norm": 0.29179903864860535,
      "learning_rate": 0.0004314651966339919,
      "loss": 2.0256,
      "step": 12800
    },
    {
      "epoch": 49.8443579766537,
      "grad_norm": 0.3258580267429352,
      "learning_rate": 0.00043135899738366043,
      "loss": 2.0161,
      "step": 12810
    },
    {
      "epoch": 49.88326848249027,
      "grad_norm": 0.32917699217796326,
      "learning_rate": 0.00043125272900720424,
      "loss": 2.027,
      "step": 12820
    },
    {
      "epoch": 49.92217898832685,
      "grad_norm": 0.3249325454235077,
      "learning_rate": 0.0004311463915451281,
      "loss": 2.0188,
      "step": 12830
    },
    {
      "epoch": 49.961089494163424,
      "grad_norm": 0.36339855194091797,
      "learning_rate": 0.00043103998503796345,
      "loss": 2.0256,
      "step": 12840
    },
    {
      "epoch": 50.0,
      "grad_norm": 0.38861343264579773,
      "learning_rate": 0.0004309335095262675,
      "loss": 2.0279,
      "step": 12850
    },
    {
      "epoch": 50.0,
      "eval_loss": 1.0915288925170898,
      "eval_runtime": 6.1962,
      "eval_samples_per_second": 3609.175,
      "eval_steps_per_second": 14.202,
      "step": 12850
    },
    {
      "epoch": 50.038910505836576,
      "grad_norm": 0.3095199167728424,
      "learning_rate": 0.00043082696505062436,
      "loss": 2.0196,
      "step": 12860
    },
    {
      "epoch": 50.07782101167315,
      "grad_norm": 0.34631088376045227,
      "learning_rate": 0.0004307203516516438,
      "loss": 2.004,
      "step": 12870
    },
    {
      "epoch": 50.11673151750973,
      "grad_norm": 0.30860984325408936,
      "learning_rate": 0.0004306136693699625,
      "loss": 2.0106,
      "step": 12880
    },
    {
      "epoch": 50.1556420233463,
      "grad_norm": 0.3448909819126129,
      "learning_rate": 0.00043050691824624286,
      "loss": 2.0193,
      "step": 12890
    },
    {
      "epoch": 50.19455252918288,
      "grad_norm": 0.318220317363739,
      "learning_rate": 0.0004304000983211739,
      "loss": 2.015,
      "step": 12900
    },
    {
      "epoch": 50.233463035019454,
      "grad_norm": 0.31641507148742676,
      "learning_rate": 0.0004302932096354706,
      "loss": 2.0093,
      "step": 12910
    },
    {
      "epoch": 50.27237354085603,
      "grad_norm": 0.3208959400653839,
      "learning_rate": 0.0004301862522298743,
      "loss": 2.0149,
      "step": 12920
    },
    {
      "epoch": 50.311284046692606,
      "grad_norm": 0.3315902054309845,
      "learning_rate": 0.0004300792261451525,
      "loss": 2.0235,
      "step": 12930
    },
    {
      "epoch": 50.35019455252918,
      "grad_norm": 0.3127399981021881,
      "learning_rate": 0.00042997213142209877,
      "loss": 2.0215,
      "step": 12940
    },
    {
      "epoch": 50.38910505836576,
      "grad_norm": 0.3310001790523529,
      "learning_rate": 0.0004298649681015331,
      "loss": 2.0226,
      "step": 12950
    },
    {
      "epoch": 50.42801556420233,
      "grad_norm": 0.35224565863609314,
      "learning_rate": 0.00042975773622430137,
      "loss": 2.0159,
      "step": 12960
    },
    {
      "epoch": 50.46692607003891,
      "grad_norm": 0.34967464208602905,
      "learning_rate": 0.00042965043583127565,
      "loss": 2.0071,
      "step": 12970
    },
    {
      "epoch": 50.505836575875485,
      "grad_norm": 0.3442648947238922,
      "learning_rate": 0.00042954306696335424,
      "loss": 2.0109,
      "step": 12980
    },
    {
      "epoch": 50.54474708171206,
      "grad_norm": 0.3075568377971649,
      "learning_rate": 0.0004294356296614614,
      "loss": 2.0173,
      "step": 12990
    },
    {
      "epoch": 50.583657587548636,
      "grad_norm": 0.3209024965763092,
      "learning_rate": 0.0004293281239665476,
      "loss": 2.0184,
      "step": 13000
    },
    {
      "epoch": 50.62256809338521,
      "grad_norm": 0.3199281096458435,
      "learning_rate": 0.00042922054991958937,
      "loss": 2.0184,
      "step": 13010
    },
    {
      "epoch": 50.66147859922179,
      "grad_norm": 0.29778698086738586,
      "learning_rate": 0.00042911290756158897,
      "loss": 2.0162,
      "step": 13020
    },
    {
      "epoch": 50.70038910505836,
      "grad_norm": 0.3259638249874115,
      "learning_rate": 0.0004290051969335753,
      "loss": 2.0207,
      "step": 13030
    },
    {
      "epoch": 50.73929961089494,
      "grad_norm": 0.29006147384643555,
      "learning_rate": 0.00042889741807660266,
      "loss": 2.0237,
      "step": 13040
    },
    {
      "epoch": 50.778210116731515,
      "grad_norm": 0.34003543853759766,
      "learning_rate": 0.0004287895710317518,
      "loss": 2.0039,
      "step": 13050
    },
    {
      "epoch": 50.81712062256809,
      "grad_norm": 0.29790276288986206,
      "learning_rate": 0.0004286816558401292,
      "loss": 2.0064,
      "step": 13060
    },
    {
      "epoch": 50.856031128404666,
      "grad_norm": 0.29448044300079346,
      "learning_rate": 0.0004285736725428676,
      "loss": 2.012,
      "step": 13070
    },
    {
      "epoch": 50.89494163424124,
      "grad_norm": 0.33295246958732605,
      "learning_rate": 0.0004284656211811253,
      "loss": 2.0279,
      "step": 13080
    },
    {
      "epoch": 50.93385214007782,
      "grad_norm": 0.315643846988678,
      "learning_rate": 0.0004283575017960869,
      "loss": 2.0211,
      "step": 13090
    },
    {
      "epoch": 50.97276264591439,
      "grad_norm": 0.31199911236763,
      "learning_rate": 0.0004282493144289627,
      "loss": 2.0244,
      "step": 13100
    },
    {
      "epoch": 51.0,
      "eval_loss": 1.090213418006897,
      "eval_runtime": 6.1743,
      "eval_samples_per_second": 3621.951,
      "eval_steps_per_second": 14.253,
      "step": 13107
    },
    {
      "epoch": 51.011673151750976,
      "grad_norm": 0.3106148838996887,
      "learning_rate": 0.0004281410591209891,
      "loss": 2.0187,
      "step": 13110
    },
    {
      "epoch": 51.05058365758755,
      "grad_norm": 0.32751786708831787,
      "learning_rate": 0.00042803273591342813,
      "loss": 1.9958,
      "step": 13120
    },
    {
      "epoch": 51.08949416342413,
      "grad_norm": 0.32255974411964417,
      "learning_rate": 0.00042792434484756797,
      "loss": 2.0135,
      "step": 13130
    },
    {
      "epoch": 51.1284046692607,
      "grad_norm": 0.339773029088974,
      "learning_rate": 0.00042781588596472255,
      "loss": 2.0145,
      "step": 13140
    },
    {
      "epoch": 51.16731517509728,
      "grad_norm": 0.36201128363609314,
      "learning_rate": 0.00042770735930623173,
      "loss": 1.9996,
      "step": 13150
    },
    {
      "epoch": 51.206225680933855,
      "grad_norm": 0.32638421654701233,
      "learning_rate": 0.0004275987649134609,
      "loss": 2.0197,
      "step": 13160
    },
    {
      "epoch": 51.24513618677043,
      "grad_norm": 0.3225242793560028,
      "learning_rate": 0.0004274901028278018,
      "loss": 2.0101,
      "step": 13170
    },
    {
      "epoch": 51.284046692607006,
      "grad_norm": 0.3400285243988037,
      "learning_rate": 0.0004273813730906715,
      "loss": 2.0041,
      "step": 13180
    },
    {
      "epoch": 51.32295719844358,
      "grad_norm": 0.317643940448761,
      "learning_rate": 0.00042727257574351295,
      "loss": 2.0132,
      "step": 13190
    },
    {
      "epoch": 51.36186770428016,
      "grad_norm": 0.3081303536891937,
      "learning_rate": 0.0004271637108277951,
      "loss": 2.0133,
      "step": 13200
    },
    {
      "epoch": 51.400778210116734,
      "grad_norm": 0.3120729327201843,
      "learning_rate": 0.00042705477838501243,
      "loss": 2.0214,
      "step": 13210
    },
    {
      "epoch": 51.43968871595331,
      "grad_norm": 0.3336254060268402,
      "learning_rate": 0.00042694577845668526,
      "loss": 2.0022,
      "step": 13220
    },
    {
      "epoch": 51.478599221789885,
      "grad_norm": 0.32077714800834656,
      "learning_rate": 0.0004268367110843595,
      "loss": 2.0141,
      "step": 13230
    },
    {
      "epoch": 51.51750972762646,
      "grad_norm": 0.30129507184028625,
      "learning_rate": 0.00042672757630960703,
      "loss": 2.0054,
      "step": 13240
    },
    {
      "epoch": 51.55642023346304,
      "grad_norm": 0.32386940717697144,
      "learning_rate": 0.00042661837417402507,
      "loss": 2.0169,
      "step": 13250
    },
    {
      "epoch": 51.59533073929961,
      "grad_norm": 0.3246464133262634,
      "learning_rate": 0.0004265091047192368,
      "loss": 2.0085,
      "step": 13260
    },
    {
      "epoch": 51.63424124513619,
      "grad_norm": 0.3014020621776581,
      "learning_rate": 0.00042639976798689104,
      "loss": 2.0084,
      "step": 13270
    },
    {
      "epoch": 51.673151750972764,
      "grad_norm": 0.31502002477645874,
      "learning_rate": 0.000426290364018662,
      "loss": 2.0113,
      "step": 13280
    },
    {
      "epoch": 51.71206225680934,
      "grad_norm": 0.2944468855857849,
      "learning_rate": 0.00042618089285624983,
      "loss": 2.025,
      "step": 13290
    },
    {
      "epoch": 51.750972762645915,
      "grad_norm": 0.3525596261024475,
      "learning_rate": 0.0004260713545413801,
      "loss": 2.0044,
      "step": 13300
    },
    {
      "epoch": 51.78988326848249,
      "grad_norm": 0.3244192600250244,
      "learning_rate": 0.0004259617491158041,
      "loss": 2.0058,
      "step": 13310
    },
    {
      "epoch": 51.82879377431907,
      "grad_norm": 0.3050752878189087,
      "learning_rate": 0.0004258520766212985,
      "loss": 2.0268,
      "step": 13320
    },
    {
      "epoch": 51.86770428015564,
      "grad_norm": 0.3075445592403412,
      "learning_rate": 0.00042574233709966573,
      "loss": 2.0153,
      "step": 13330
    },
    {
      "epoch": 51.90661478599222,
      "grad_norm": 0.2990921139717102,
      "learning_rate": 0.00042563253059273376,
      "loss": 2.0194,
      "step": 13340
    },
    {
      "epoch": 51.945525291828794,
      "grad_norm": 0.31474393606185913,
      "learning_rate": 0.0004255226571423559,
      "loss": 2.0159,
      "step": 13350
    },
    {
      "epoch": 51.98443579766537,
      "grad_norm": 0.33104512095451355,
      "learning_rate": 0.00042541271679041116,
      "loss": 2.0029,
      "step": 13360
    },
    {
      "epoch": 52.0,
      "eval_loss": 1.0916383266448975,
      "eval_runtime": 6.1889,
      "eval_samples_per_second": 3613.406,
      "eval_steps_per_second": 14.219,
      "step": 13364
    },
    {
      "epoch": 52.023346303501945,
      "grad_norm": 0.3304380774497986,
      "learning_rate": 0.00042530270957880415,
      "loss": 2.0013,
      "step": 13370
    },
    {
      "epoch": 52.06225680933852,
      "grad_norm": 0.33526477217674255,
      "learning_rate": 0.00042519263554946453,
      "loss": 1.9863,
      "step": 13380
    },
    {
      "epoch": 52.1011673151751,
      "grad_norm": 0.35601815581321716,
      "learning_rate": 0.0004250824947443479,
      "loss": 2.0023,
      "step": 13390
    },
    {
      "epoch": 52.14007782101167,
      "grad_norm": 0.3115394711494446,
      "learning_rate": 0.0004249722872054351,
      "loss": 2.0069,
      "step": 13400
    },
    {
      "epoch": 52.17898832684825,
      "grad_norm": 0.3399975299835205,
      "learning_rate": 0.00042486201297473237,
      "loss": 1.9987,
      "step": 13410
    },
    {
      "epoch": 52.217898832684824,
      "grad_norm": 0.3202144503593445,
      "learning_rate": 0.0004247516720942716,
      "loss": 2.0111,
      "step": 13420
    },
    {
      "epoch": 52.2568093385214,
      "grad_norm": 0.32186809182167053,
      "learning_rate": 0.0004246412646061096,
      "loss": 2.0033,
      "step": 13430
    },
    {
      "epoch": 52.295719844357976,
      "grad_norm": 0.33401134610176086,
      "learning_rate": 0.0004245307905523291,
      "loss": 2.0147,
      "step": 13440
    },
    {
      "epoch": 52.33463035019455,
      "grad_norm": 0.3864923119544983,
      "learning_rate": 0.000424420249975038,
      "loss": 2.0159,
      "step": 13450
    },
    {
      "epoch": 52.37354085603113,
      "grad_norm": 0.3217819631099701,
      "learning_rate": 0.00042430964291636944,
      "loss": 2.0191,
      "step": 13460
    },
    {
      "epoch": 52.4124513618677,
      "grad_norm": 0.32092002034187317,
      "learning_rate": 0.00042419896941848205,
      "loss": 2.0034,
      "step": 13470
    },
    {
      "epoch": 52.45136186770428,
      "grad_norm": 0.3217824399471283,
      "learning_rate": 0.00042408822952355975,
      "loss": 1.9956,
      "step": 13480
    },
    {
      "epoch": 52.490272373540854,
      "grad_norm": 0.34762436151504517,
      "learning_rate": 0.0004239774232738117,
      "loss": 2.015,
      "step": 13490
    },
    {
      "epoch": 52.52918287937743,
      "grad_norm": 0.3291080594062805,
      "learning_rate": 0.00042386655071147237,
      "loss": 2.0047,
      "step": 13500
    },
    {
      "epoch": 52.568093385214006,
      "grad_norm": 0.32365885376930237,
      "learning_rate": 0.00042375561187880164,
      "loss": 1.9979,
      "step": 13510
    },
    {
      "epoch": 52.60700389105058,
      "grad_norm": 0.3267225921154022,
      "learning_rate": 0.0004236446068180844,
      "loss": 2.0225,
      "step": 13520
    },
    {
      "epoch": 52.64591439688716,
      "grad_norm": 0.3320358991622925,
      "learning_rate": 0.0004235335355716311,
      "loss": 2.0043,
      "step": 13530
    },
    {
      "epoch": 52.68482490272373,
      "grad_norm": 0.3124086260795593,
      "learning_rate": 0.00042342239818177706,
      "loss": 1.9989,
      "step": 13540
    },
    {
      "epoch": 52.72373540856031,
      "grad_norm": 0.32424867153167725,
      "learning_rate": 0.0004233111946908832,
      "loss": 2.0067,
      "step": 13550
    },
    {
      "epoch": 52.762645914396884,
      "grad_norm": 0.3105458915233612,
      "learning_rate": 0.0004231999251413353,
      "loss": 2.0153,
      "step": 13560
    },
    {
      "epoch": 52.80155642023346,
      "grad_norm": 0.30794665217399597,
      "learning_rate": 0.00042308858957554443,
      "loss": 2.0294,
      "step": 13570
    },
    {
      "epoch": 52.840466926070036,
      "grad_norm": 0.32498592138290405,
      "learning_rate": 0.00042297718803594695,
      "loss": 1.9955,
      "step": 13580
    },
    {
      "epoch": 52.87937743190661,
      "grad_norm": 0.32202187180519104,
      "learning_rate": 0.0004228657205650042,
      "loss": 2.0094,
      "step": 13590
    },
    {
      "epoch": 52.91828793774319,
      "grad_norm": 0.3267354965209961,
      "learning_rate": 0.00042275418720520263,
      "loss": 2.0073,
      "step": 13600
    },
    {
      "epoch": 52.95719844357976,
      "grad_norm": 0.29421669244766235,
      "learning_rate": 0.0004226425879990541,
      "loss": 2.0057,
      "step": 13610
    },
    {
      "epoch": 52.99610894941634,
      "grad_norm": 0.30895012617111206,
      "learning_rate": 0.00042253092298909505,
      "loss": 2.0307,
      "step": 13620
    },
    {
      "epoch": 53.0,
      "eval_loss": 1.0935269594192505,
      "eval_runtime": 6.4075,
      "eval_samples_per_second": 3490.142,
      "eval_steps_per_second": 13.734,
      "step": 13621
    },
    {
      "epoch": 53.03501945525292,
      "grad_norm": 0.3855891525745392,
      "learning_rate": 0.00042241919221788754,
      "loss": 2.0025,
      "step": 13630
    },
    {
      "epoch": 53.0739299610895,
      "grad_norm": 0.33424532413482666,
      "learning_rate": 0.0004223073957280184,
      "loss": 1.9907,
      "step": 13640
    },
    {
      "epoch": 53.11284046692607,
      "grad_norm": 0.3525198996067047,
      "learning_rate": 0.0004221955335620995,
      "loss": 1.9938,
      "step": 13650
    },
    {
      "epoch": 53.15175097276265,
      "grad_norm": 0.3411216139793396,
      "learning_rate": 0.0004220836057627679,
      "loss": 1.9853,
      "step": 13660
    },
    {
      "epoch": 53.190661478599225,
      "grad_norm": 0.3071519136428833,
      "learning_rate": 0.00042197161237268554,
      "loss": 1.9987,
      "step": 13670
    },
    {
      "epoch": 53.2295719844358,
      "grad_norm": 0.3349839448928833,
      "learning_rate": 0.0004218595534345394,
      "loss": 1.995,
      "step": 13680
    },
    {
      "epoch": 53.268482490272376,
      "grad_norm": 0.3366830348968506,
      "learning_rate": 0.00042174742899104146,
      "loss": 2.0113,
      "step": 13690
    },
    {
      "epoch": 53.30739299610895,
      "grad_norm": 0.33652934432029724,
      "learning_rate": 0.0004216352390849287,
      "loss": 1.9866,
      "step": 13700
    },
    {
      "epoch": 53.34630350194553,
      "grad_norm": 0.3155497610569,
      "learning_rate": 0.00042152298375896293,
      "loss": 2.012,
      "step": 13710
    },
    {
      "epoch": 53.3852140077821,
      "grad_norm": 0.32453155517578125,
      "learning_rate": 0.000421410663055931,
      "loss": 2.0081,
      "step": 13720
    },
    {
      "epoch": 53.42412451361868,
      "grad_norm": 0.3347337245941162,
      "learning_rate": 0.0004212982770186447,
      "loss": 1.9985,
      "step": 13730
    },
    {
      "epoch": 53.463035019455255,
      "grad_norm": 0.3449009656906128,
      "learning_rate": 0.00042118582568994055,
      "loss": 1.9971,
      "step": 13740
    },
    {
      "epoch": 53.50194552529183,
      "grad_norm": 0.3083443343639374,
      "learning_rate": 0.00042107330911268033,
      "loss": 1.9924,
      "step": 13750
    },
    {
      "epoch": 53.540856031128406,
      "grad_norm": 0.34027528762817383,
      "learning_rate": 0.0004209607273297502,
      "loss": 2.0134,
      "step": 13760
    },
    {
      "epoch": 53.57976653696498,
      "grad_norm": 0.33118322491645813,
      "learning_rate": 0.00042084808038406153,
      "loss": 2.0034,
      "step": 13770
    },
    {
      "epoch": 53.61867704280156,
      "grad_norm": 0.3281143605709076,
      "learning_rate": 0.0004207353683185503,
      "loss": 1.9953,
      "step": 13780
    },
    {
      "epoch": 53.65758754863813,
      "grad_norm": 0.34226754307746887,
      "learning_rate": 0.0004206225911761776,
      "loss": 2.0084,
      "step": 13790
    },
    {
      "epoch": 53.69649805447471,
      "grad_norm": 0.3217301666736603,
      "learning_rate": 0.0004205097489999291,
      "loss": 2.014,
      "step": 13800
    },
    {
      "epoch": 53.735408560311285,
      "grad_norm": 0.3194466233253479,
      "learning_rate": 0.00042039684183281517,
      "loss": 2.0089,
      "step": 13810
    },
    {
      "epoch": 53.77431906614786,
      "grad_norm": 0.3102269172668457,
      "learning_rate": 0.00042028386971787126,
      "loss": 2.0177,
      "step": 13820
    },
    {
      "epoch": 53.81322957198444,
      "grad_norm": 0.33544158935546875,
      "learning_rate": 0.00042017083269815726,
      "loss": 1.999,
      "step": 13830
    },
    {
      "epoch": 53.85214007782101,
      "grad_norm": 0.3152502179145813,
      "learning_rate": 0.00042005773081675807,
      "loss": 2.0077,
      "step": 13840
    },
    {
      "epoch": 53.89105058365759,
      "grad_norm": 0.3032667934894562,
      "learning_rate": 0.0004199445641167831,
      "loss": 2.0133,
      "step": 13850
    },
    {
      "epoch": 53.929961089494164,
      "grad_norm": 0.3438262641429901,
      "learning_rate": 0.00041983133264136656,
      "loss": 2.0013,
      "step": 13860
    },
    {
      "epoch": 53.96887159533074,
      "grad_norm": 0.34481722116470337,
      "learning_rate": 0.0004197180364336674,
      "loss": 1.9995,
      "step": 13870
    },
    {
      "epoch": 54.0,
      "eval_loss": 1.091193675994873,
      "eval_runtime": 6.4321,
      "eval_samples_per_second": 3476.767,
      "eval_steps_per_second": 13.681,
      "step": 13878
    },
    {
      "epoch": 54.007782101167315,
      "grad_norm": 0.3132913112640381,
      "learning_rate": 0.0004196046755368691,
      "loss": 1.9993,
      "step": 13880
    },
    {
      "epoch": 54.04669260700389,
      "grad_norm": 0.3471924662590027,
      "learning_rate": 0.00041949124999418,
      "loss": 1.9786,
      "step": 13890
    },
    {
      "epoch": 54.08560311284047,
      "grad_norm": 0.3383030295372009,
      "learning_rate": 0.00041937775984883275,
      "loss": 1.9897,
      "step": 13900
    },
    {
      "epoch": 54.12451361867704,
      "grad_norm": 0.31599581241607666,
      "learning_rate": 0.000419264205144085,
      "loss": 1.989,
      "step": 13910
    },
    {
      "epoch": 54.16342412451362,
      "grad_norm": 0.3402884900569916,
      "learning_rate": 0.0004191505859232189,
      "loss": 1.9968,
      "step": 13920
    },
    {
      "epoch": 54.202334630350194,
      "grad_norm": 0.32218942046165466,
      "learning_rate": 0.00041903690222954093,
      "loss": 1.9919,
      "step": 13930
    },
    {
      "epoch": 54.24124513618677,
      "grad_norm": 0.33173421025276184,
      "learning_rate": 0.0004189231541063825,
      "loss": 2.0037,
      "step": 13940
    },
    {
      "epoch": 54.280155642023345,
      "grad_norm": 0.349578857421875,
      "learning_rate": 0.0004188093415970994,
      "loss": 1.9765,
      "step": 13950
    },
    {
      "epoch": 54.31906614785992,
      "grad_norm": 0.32865065336227417,
      "learning_rate": 0.000418695464745072,
      "loss": 2.0075,
      "step": 13960
    },
    {
      "epoch": 54.3579766536965,
      "grad_norm": 0.30865541100502014,
      "learning_rate": 0.000418581523593705,
      "loss": 1.9998,
      "step": 13970
    },
    {
      "epoch": 54.39688715953307,
      "grad_norm": 0.3242884576320648,
      "learning_rate": 0.0004184675181864281,
      "loss": 2.0047,
      "step": 13980
    },
    {
      "epoch": 54.43579766536965,
      "grad_norm": 0.3178751468658447,
      "learning_rate": 0.00041835344856669496,
      "loss": 1.9983,
      "step": 13990
    },
    {
      "epoch": 54.474708171206224,
      "grad_norm": 0.32609450817108154,
      "learning_rate": 0.00041823931477798394,
      "loss": 1.9993,
      "step": 14000
    },
    {
      "epoch": 54.5136186770428,
      "grad_norm": 0.3337531089782715,
      "learning_rate": 0.0004181251168637979,
      "loss": 1.9984,
      "step": 14010
    },
    {
      "epoch": 54.552529182879375,
      "grad_norm": 0.30532974004745483,
      "learning_rate": 0.0004180108548676641,
      "loss": 2.0036,
      "step": 14020
    },
    {
      "epoch": 54.59143968871595,
      "grad_norm": 0.3107231557369232,
      "learning_rate": 0.00041789652883313425,
      "loss": 2.0035,
      "step": 14030
    },
    {
      "epoch": 54.63035019455253,
      "grad_norm": 0.34390324354171753,
      "learning_rate": 0.00041778213880378434,
      "loss": 1.9993,
      "step": 14040
    },
    {
      "epoch": 54.6692607003891,
      "grad_norm": 0.31804797053337097,
      "learning_rate": 0.00041766768482321494,
      "loss": 1.9976,
      "step": 14050
    },
    {
      "epoch": 54.70817120622568,
      "grad_norm": 0.32485273480415344,
      "learning_rate": 0.00041755316693505094,
      "loss": 2.0085,
      "step": 14060
    },
    {
      "epoch": 54.747081712062254,
      "grad_norm": 0.3183836340904236,
      "learning_rate": 0.00041743858518294145,
      "loss": 2.003,
      "step": 14070
    },
    {
      "epoch": 54.78599221789883,
      "grad_norm": 0.31077539920806885,
      "learning_rate": 0.00041732393961056003,
      "loss": 2.0024,
      "step": 14080
    },
    {
      "epoch": 54.824902723735406,
      "grad_norm": 0.30888107419013977,
      "learning_rate": 0.00041720923026160463,
      "loss": 1.9962,
      "step": 14090
    },
    {
      "epoch": 54.86381322957198,
      "grad_norm": 0.34855541586875916,
      "learning_rate": 0.0004170944571797974,
      "loss": 2.0103,
      "step": 14100
    },
    {
      "epoch": 54.90272373540856,
      "grad_norm": 0.30650559067726135,
      "learning_rate": 0.0004169796204088848,
      "loss": 1.9972,
      "step": 14110
    },
    {
      "epoch": 54.94163424124513,
      "grad_norm": 0.3355562388896942,
      "learning_rate": 0.00041686471999263775,
      "loss": 1.9967,
      "step": 14120
    },
    {
      "epoch": 54.98054474708171,
      "grad_norm": 0.30467548966407776,
      "learning_rate": 0.000416749755974851,
      "loss": 2.0076,
      "step": 14130
    },
    {
      "epoch": 55.0,
      "eval_loss": 1.0905132293701172,
      "eval_runtime": 6.1845,
      "eval_samples_per_second": 3615.981,
      "eval_steps_per_second": 14.229,
      "step": 14135
    },
    {
      "epoch": 55.01945525291829,
      "grad_norm": 0.3339459002017975,
      "learning_rate": 0.000416634728399344,
      "loss": 2.0063,
      "step": 14140
    },
    {
      "epoch": 55.05836575875487,
      "grad_norm": 0.3288155496120453,
      "learning_rate": 0.00041651963730996025,
      "loss": 1.9955,
      "step": 14150
    },
    {
      "epoch": 55.09727626459144,
      "grad_norm": 0.3526614010334015,
      "learning_rate": 0.0004164044827505673,
      "loss": 1.9883,
      "step": 14160
    },
    {
      "epoch": 55.13618677042802,
      "grad_norm": 0.35771697759628296,
      "learning_rate": 0.0004162892647650572,
      "loss": 1.9859,
      "step": 14170
    },
    {
      "epoch": 55.175097276264594,
      "grad_norm": 0.3445306420326233,
      "learning_rate": 0.0004161739833973459,
      "loss": 1.9867,
      "step": 14180
    },
    {
      "epoch": 55.21400778210117,
      "grad_norm": 0.3455585837364197,
      "learning_rate": 0.0004160586386913736,
      "loss": 1.9853,
      "step": 14190
    },
    {
      "epoch": 55.252918287937746,
      "grad_norm": 0.3439536690711975,
      "learning_rate": 0.0004159432306911047,
      "loss": 1.9945,
      "step": 14200
    },
    {
      "epoch": 55.29182879377432,
      "grad_norm": 0.3321695625782013,
      "learning_rate": 0.0004158277594405278,
      "loss": 1.9867,
      "step": 14210
    },
    {
      "epoch": 55.3307392996109,
      "grad_norm": 0.3356001377105713,
      "learning_rate": 0.00041571222498365534,
      "loss": 1.9909,
      "step": 14220
    },
    {
      "epoch": 55.36964980544747,
      "grad_norm": 0.33037129044532776,
      "learning_rate": 0.000415596627364524,
      "loss": 1.9921,
      "step": 14230
    },
    {
      "epoch": 55.40856031128405,
      "grad_norm": 0.32955989241600037,
      "learning_rate": 0.0004154809666271947,
      "loss": 1.9979,
      "step": 14240
    },
    {
      "epoch": 55.447470817120625,
      "grad_norm": 0.3456609547138214,
      "learning_rate": 0.00041536524281575216,
      "loss": 1.9908,
      "step": 14250
    },
    {
      "epoch": 55.4863813229572,
      "grad_norm": 0.3016788065433502,
      "learning_rate": 0.00041524945597430516,
      "loss": 2.0059,
      "step": 14260
    },
    {
      "epoch": 55.525291828793776,
      "grad_norm": 0.35727831721305847,
      "learning_rate": 0.0004151336061469867,
      "loss": 1.9888,
      "step": 14270
    },
    {
      "epoch": 55.56420233463035,
      "grad_norm": 0.3407820761203766,
      "learning_rate": 0.0004150176933779536,
      "loss": 1.999,
      "step": 14280
    },
    {
      "epoch": 55.60311284046693,
      "grad_norm": 0.3160528540611267,
      "learning_rate": 0.0004149017177113868,
      "loss": 1.9965,
      "step": 14290
    },
    {
      "epoch": 55.6420233463035,
      "grad_norm": 0.3335738182067871,
      "learning_rate": 0.0004147856791914911,
      "loss": 2.0112,
      "step": 14300
    },
    {
      "epoch": 55.68093385214008,
      "grad_norm": 0.35641154646873474,
      "learning_rate": 0.0004146695778624954,
      "loss": 1.9969,
      "step": 14310
    },
    {
      "epoch": 55.719844357976655,
      "grad_norm": 0.3137699365615845,
      "learning_rate": 0.00041455341376865233,
      "loss": 2.0085,
      "step": 14320
    },
    {
      "epoch": 55.75875486381323,
      "grad_norm": 0.3175005614757538,
      "learning_rate": 0.0004144371869542387,
      "loss": 1.9975,
      "step": 14330
    },
    {
      "epoch": 55.797665369649806,
      "grad_norm": 0.32030820846557617,
      "learning_rate": 0.00041432089746355505,
      "loss": 1.9846,
      "step": 14340
    },
    {
      "epoch": 55.83657587548638,
      "grad_norm": 0.3341958224773407,
      "learning_rate": 0.0004142045453409258,
      "loss": 1.9969,
      "step": 14350
    },
    {
      "epoch": 55.87548638132296,
      "grad_norm": 0.317169189453125,
      "learning_rate": 0.0004140881306306993,
      "loss": 1.9878,
      "step": 14360
    },
    {
      "epoch": 55.91439688715953,
      "grad_norm": 0.3246932625770569,
      "learning_rate": 0.0004139716533772478,
      "loss": 1.9863,
      "step": 14370
    },
    {
      "epoch": 55.95330739299611,
      "grad_norm": 0.3198506236076355,
      "learning_rate": 0.0004138551136249673,
      "loss": 1.9956,
      "step": 14380
    },
    {
      "epoch": 55.992217898832685,
      "grad_norm": 0.3307664394378662,
      "learning_rate": 0.00041373851141827766,
      "loss": 1.9914,
      "step": 14390
    },
    {
      "epoch": 56.0,
      "eval_loss": 1.0909571647644043,
      "eval_runtime": 6.1845,
      "eval_samples_per_second": 3616.001,
      "eval_steps_per_second": 14.229,
      "step": 14392
    },
    {
      "epoch": 56.03112840466926,
      "grad_norm": 0.36922886967658997,
      "learning_rate": 0.00041362184680162256,
      "loss": 1.9778,
      "step": 14400
    },
    {
      "epoch": 56.070038910505836,
      "grad_norm": 0.32852885127067566,
      "learning_rate": 0.00041350511981946955,
      "loss": 1.9835,
      "step": 14410
    },
    {
      "epoch": 56.10894941634241,
      "grad_norm": 0.3438836634159088,
      "learning_rate": 0.0004133883305163096,
      "loss": 1.9851,
      "step": 14420
    },
    {
      "epoch": 56.14785992217899,
      "grad_norm": 0.33293262124061584,
      "learning_rate": 0.00041327147893665796,
      "loss": 1.9857,
      "step": 14430
    },
    {
      "epoch": 56.18677042801556,
      "grad_norm": 0.3263188898563385,
      "learning_rate": 0.00041315456512505325,
      "loss": 1.9803,
      "step": 14440
    },
    {
      "epoch": 56.22568093385214,
      "grad_norm": 0.339077889919281,
      "learning_rate": 0.0004130375891260579,
      "loss": 1.9974,
      "step": 14450
    },
    {
      "epoch": 56.264591439688715,
      "grad_norm": 0.34494197368621826,
      "learning_rate": 0.00041292055098425794,
      "loss": 1.9903,
      "step": 14460
    },
    {
      "epoch": 56.30350194552529,
      "grad_norm": 0.33265823125839233,
      "learning_rate": 0.00041280345074426336,
      "loss": 1.9813,
      "step": 14470
    },
    {
      "epoch": 56.34241245136187,
      "grad_norm": 0.36211201548576355,
      "learning_rate": 0.0004126862884507076,
      "loss": 1.9935,
      "step": 14480
    },
    {
      "epoch": 56.38132295719844,
      "grad_norm": 0.3347731828689575,
      "learning_rate": 0.00041256906414824775,
      "loss": 1.9835,
      "step": 14490
    },
    {
      "epoch": 56.42023346303502,
      "grad_norm": 0.32308194041252136,
      "learning_rate": 0.00041245177788156465,
      "loss": 1.9846,
      "step": 14500
    },
    {
      "epoch": 56.459143968871594,
      "grad_norm": 0.33480337262153625,
      "learning_rate": 0.0004123344296953627,
      "loss": 1.9941,
      "step": 14510
    },
    {
      "epoch": 56.49805447470817,
      "grad_norm": 0.3007620573043823,
      "learning_rate": 0.00041221701963436996,
      "loss": 2.0014,
      "step": 14520
    },
    {
      "epoch": 56.536964980544745,
      "grad_norm": 0.33581459522247314,
      "learning_rate": 0.0004120995477433378,
      "loss": 1.9886,
      "step": 14530
    },
    {
      "epoch": 56.57587548638132,
      "grad_norm": 0.3332037925720215,
      "learning_rate": 0.0004119820140670416,
      "loss": 1.9805,
      "step": 14540
    },
    {
      "epoch": 56.6147859922179,
      "grad_norm": 0.341138631105423,
      "learning_rate": 0.00041186441865028,
      "loss": 1.9975,
      "step": 14550
    },
    {
      "epoch": 56.65369649805447,
      "grad_norm": 0.3132660984992981,
      "learning_rate": 0.0004117467615378752,
      "loss": 1.995,
      "step": 14560
    },
    {
      "epoch": 56.69260700389105,
      "grad_norm": 0.3441495895385742,
      "learning_rate": 0.0004116290427746729,
      "loss": 1.9974,
      "step": 14570
    },
    {
      "epoch": 56.731517509727624,
      "grad_norm": 0.32222700119018555,
      "learning_rate": 0.0004115112624055424,
      "loss": 1.988,
      "step": 14580
    },
    {
      "epoch": 56.7704280155642,
      "grad_norm": 0.35525375604629517,
      "learning_rate": 0.00041139342047537655,
      "loss": 1.9962,
      "step": 14590
    },
    {
      "epoch": 56.809338521400775,
      "grad_norm": 0.3205007314682007,
      "learning_rate": 0.0004112755170290913,
      "loss": 1.9861,
      "step": 14600
    },
    {
      "epoch": 56.84824902723735,
      "grad_norm": 0.35635316371917725,
      "learning_rate": 0.00041115755211162654,
      "loss": 1.9949,
      "step": 14610
    },
    {
      "epoch": 56.88715953307393,
      "grad_norm": 0.33014214038848877,
      "learning_rate": 0.0004110395257679451,
      "loss": 1.9926,
      "step": 14620
    },
    {
      "epoch": 56.9260700389105,
      "grad_norm": 0.3486309349536896,
      "learning_rate": 0.00041092143804303367,
      "loss": 2.0129,
      "step": 14630
    },
    {
      "epoch": 56.96498054474708,
      "grad_norm": 0.3318396806716919,
      "learning_rate": 0.0004108032889819021,
      "loss": 1.9772,
      "step": 14640
    },
    {
      "epoch": 57.0,
      "eval_loss": 1.0936909914016724,
      "eval_runtime": 6.1858,
      "eval_samples_per_second": 3615.219,
      "eval_steps_per_second": 14.226,
      "step": 14649
    },
    {
      "epoch": 57.00389105058366,
      "grad_norm": 0.30410048365592957,
      "learning_rate": 0.00041068507862958346,
      "loss": 1.9903,
      "step": 14650
    },
    {
      "epoch": 57.04280155642024,
      "grad_norm": 0.34343570470809937,
      "learning_rate": 0.00041056680703113464,
      "loss": 1.9624,
      "step": 14660
    },
    {
      "epoch": 57.08171206225681,
      "grad_norm": 0.3413046598434448,
      "learning_rate": 0.00041044847423163546,
      "loss": 1.9627,
      "step": 14670
    },
    {
      "epoch": 57.12062256809339,
      "grad_norm": 0.3482057452201843,
      "learning_rate": 0.00041033008027618916,
      "loss": 1.9948,
      "step": 14680
    },
    {
      "epoch": 57.159533073929964,
      "grad_norm": 0.34841063618659973,
      "learning_rate": 0.0004102116252099225,
      "loss": 1.9655,
      "step": 14690
    },
    {
      "epoch": 57.19844357976654,
      "grad_norm": 0.32697802782058716,
      "learning_rate": 0.00041009310907798513,
      "loss": 1.9822,
      "step": 14700
    },
    {
      "epoch": 57.237354085603116,
      "grad_norm": 0.3540736138820648,
      "learning_rate": 0.00040997453192555055,
      "loss": 1.9811,
      "step": 14710
    },
    {
      "epoch": 57.27626459143969,
      "grad_norm": 0.3441285192966461,
      "learning_rate": 0.00040985589379781493,
      "loss": 1.9676,
      "step": 14720
    },
    {
      "epoch": 57.31517509727627,
      "grad_norm": 0.338266521692276,
      "learning_rate": 0.000409737194739998,
      "loss": 1.9789,
      "step": 14730
    },
    {
      "epoch": 57.35408560311284,
      "grad_norm": 0.34090492129325867,
      "learning_rate": 0.0004096184347973427,
      "loss": 1.9869,
      "step": 14740
    },
    {
      "epoch": 57.39299610894942,
      "grad_norm": 0.32676899433135986,
      "learning_rate": 0.0004094996140151152,
      "loss": 1.9803,
      "step": 14750
    },
    {
      "epoch": 57.431906614785994,
      "grad_norm": 0.32821840047836304,
      "learning_rate": 0.00040938073243860465,
      "loss": 1.9933,
      "step": 14760
    },
    {
      "epoch": 57.47081712062257,
      "grad_norm": 0.32353460788726807,
      "learning_rate": 0.0004092617901131235,
      "loss": 1.9903,
      "step": 14770
    },
    {
      "epoch": 57.509727626459146,
      "grad_norm": 0.32556039094924927,
      "learning_rate": 0.00040914278708400743,
      "loss": 1.986,
      "step": 14780
    },
    {
      "epoch": 57.54863813229572,
      "grad_norm": 0.3277422785758972,
      "learning_rate": 0.0004090237233966153,
      "loss": 1.9945,
      "step": 14790
    },
    {
      "epoch": 57.5875486381323,
      "grad_norm": 0.32840022444725037,
      "learning_rate": 0.0004089045990963288,
      "loss": 1.9876,
      "step": 14800
    },
    {
      "epoch": 57.62645914396887,
      "grad_norm": 0.3495638966560364,
      "learning_rate": 0.000408785414228553,
      "loss": 1.996,
      "step": 14810
    },
    {
      "epoch": 57.66536964980545,
      "grad_norm": 0.35195642709732056,
      "learning_rate": 0.00040866616883871587,
      "loss": 1.9838,
      "step": 14820
    },
    {
      "epoch": 57.704280155642024,
      "grad_norm": 0.3408986032009125,
      "learning_rate": 0.0004085468629722687,
      "loss": 1.9954,
      "step": 14830
    },
    {
      "epoch": 57.7431906614786,
      "grad_norm": 0.326568603515625,
      "learning_rate": 0.0004084274966746856,
      "loss": 1.9864,
      "step": 14840
    },
    {
      "epoch": 57.782101167315176,
      "grad_norm": 0.3300798833370209,
      "learning_rate": 0.00040830806999146376,
      "loss": 1.9878,
      "step": 14850
    },
    {
      "epoch": 57.82101167315175,
      "grad_norm": 0.32122647762298584,
      "learning_rate": 0.0004081885829681234,
      "loss": 1.9971,
      "step": 14860
    },
    {
      "epoch": 57.85992217898833,
      "grad_norm": 0.31379637122154236,
      "learning_rate": 0.00040806903565020783,
      "loss": 1.991,
      "step": 14870
    },
    {
      "epoch": 57.8988326848249,
      "grad_norm": 0.3229861855506897,
      "learning_rate": 0.0004079494280832832,
      "loss": 1.9715,
      "step": 14880
    },
    {
      "epoch": 57.93774319066148,
      "grad_norm": 0.3335511386394501,
      "learning_rate": 0.0004078297603129387,
      "loss": 2.0004,
      "step": 14890
    },
    {
      "epoch": 57.976653696498055,
      "grad_norm": 0.32879897952079773,
      "learning_rate": 0.00040771003238478646,
      "loss": 1.9895,
      "step": 14900
    },
    {
      "epoch": 58.0,
      "eval_loss": 1.093029260635376,
      "eval_runtime": 6.2065,
      "eval_samples_per_second": 3603.146,
      "eval_steps_per_second": 14.179,
      "step": 14906
    },
    {
      "epoch": 58.01556420233463,
      "grad_norm": 0.3325325846672058,
      "learning_rate": 0.0004075902443444616,
      "loss": 1.9756,
      "step": 14910
    },
    {
      "epoch": 58.054474708171206,
      "grad_norm": 0.334438681602478,
      "learning_rate": 0.0004074703962376219,
      "loss": 1.9966,
      "step": 14920
    },
    {
      "epoch": 58.09338521400778,
      "grad_norm": 0.3384786546230316,
      "learning_rate": 0.00040735048810994846,
      "loss": 1.9727,
      "step": 14930
    },
    {
      "epoch": 58.13229571984436,
      "grad_norm": 0.3435515761375427,
      "learning_rate": 0.0004072305200071448,
      "loss": 1.9658,
      "step": 14940
    },
    {
      "epoch": 58.17120622568093,
      "grad_norm": 0.3266909122467041,
      "learning_rate": 0.00040711049197493765,
      "loss": 1.9833,
      "step": 14950
    },
    {
      "epoch": 58.21011673151751,
      "grad_norm": 0.3469046950340271,
      "learning_rate": 0.0004069904040590765,
      "loss": 1.9747,
      "step": 14960
    },
    {
      "epoch": 58.249027237354085,
      "grad_norm": 0.34635552763938904,
      "learning_rate": 0.00040687025630533344,
      "loss": 1.9789,
      "step": 14970
    },
    {
      "epoch": 58.28793774319066,
      "grad_norm": 0.336751252412796,
      "learning_rate": 0.00040675004875950364,
      "loss": 1.9868,
      "step": 14980
    },
    {
      "epoch": 58.326848249027236,
      "grad_norm": 0.35433489084243774,
      "learning_rate": 0.00040662978146740504,
      "loss": 1.9678,
      "step": 14990
    },
    {
      "epoch": 58.36575875486381,
      "grad_norm": 0.320480614900589,
      "learning_rate": 0.00040650945447487813,
      "loss": 1.9792,
      "step": 15000
    },
    {
      "epoch": 58.40466926070039,
      "grad_norm": 0.33705681562423706,
      "learning_rate": 0.0004063890678277864,
      "loss": 1.9804,
      "step": 15010
    },
    {
      "epoch": 58.44357976653696,
      "grad_norm": 0.34515783190727234,
      "learning_rate": 0.00040626862157201596,
      "loss": 1.9717,
      "step": 15020
    },
    {
      "epoch": 58.48249027237354,
      "grad_norm": 0.3211304843425751,
      "learning_rate": 0.00040614811575347565,
      "loss": 1.9869,
      "step": 15030
    },
    {
      "epoch": 58.521400778210115,
      "grad_norm": 0.3322824537754059,
      "learning_rate": 0.00040602755041809695,
      "loss": 1.9852,
      "step": 15040
    },
    {
      "epoch": 58.56031128404669,
      "grad_norm": 0.3275177478790283,
      "learning_rate": 0.0004059069256118343,
      "loss": 1.9888,
      "step": 15050
    },
    {
      "epoch": 58.599221789883266,
      "grad_norm": 0.3408678472042084,
      "learning_rate": 0.00040578624138066437,
      "loss": 1.98,
      "step": 15060
    },
    {
      "epoch": 58.63813229571984,
      "grad_norm": 0.33113276958465576,
      "learning_rate": 0.00040566549777058683,
      "loss": 1.9845,
      "step": 15070
    },
    {
      "epoch": 58.67704280155642,
      "grad_norm": 0.37104931473731995,
      "learning_rate": 0.0004055446948276239,
      "loss": 1.9792,
      "step": 15080
    },
    {
      "epoch": 58.715953307392994,
      "grad_norm": 0.3184885084629059,
      "learning_rate": 0.0004054238325978203,
      "loss": 1.9806,
      "step": 15090
    },
    {
      "epoch": 58.75486381322957,
      "grad_norm": 0.3336796462535858,
      "learning_rate": 0.0004053029111272435,
      "loss": 1.9891,
      "step": 15100
    },
    {
      "epoch": 58.793774319066145,
      "grad_norm": 0.35357582569122314,
      "learning_rate": 0.0004051819304619834,
      "loss": 1.9953,
      "step": 15110
    },
    {
      "epoch": 58.83268482490272,
      "grad_norm": 0.3435822129249573,
      "learning_rate": 0.00040506089064815267,
      "loss": 1.9624,
      "step": 15120
    },
    {
      "epoch": 58.8715953307393,
      "grad_norm": 0.33041658997535706,
      "learning_rate": 0.00040493979173188626,
      "loss": 1.9946,
      "step": 15130
    },
    {
      "epoch": 58.91050583657587,
      "grad_norm": 0.3349760174751282,
      "learning_rate": 0.0004048186337593419,
      "loss": 1.9758,
      "step": 15140
    },
    {
      "epoch": 58.94941634241245,
      "grad_norm": 0.3554861545562744,
      "learning_rate": 0.0004046974167766996,
      "loss": 1.9831,
      "step": 15150
    },
    {
      "epoch": 58.98832684824903,
      "grad_norm": 0.32860690355300903,
      "learning_rate": 0.00040457614083016206,
      "loss": 1.9785,
      "step": 15160
    },
    {
      "epoch": 59.0,
      "eval_loss": 1.0960625410079956,
      "eval_runtime": 6.4272,
      "eval_samples_per_second": 3479.449,
      "eval_steps_per_second": 13.692,
      "step": 15163
    },
    {
      "epoch": 59.02723735408561,
      "grad_norm": 0.33936357498168945,
      "learning_rate": 0.0004044548059659544,
      "loss": 1.9713,
      "step": 15170
    },
    {
      "epoch": 59.06614785992218,
      "grad_norm": 0.3259747326374054,
      "learning_rate": 0.00040433341223032403,
      "loss": 1.9753,
      "step": 15180
    },
    {
      "epoch": 59.10505836575876,
      "grad_norm": 0.3315367102622986,
      "learning_rate": 0.0004042119596695411,
      "loss": 1.9708,
      "step": 15190
    },
    {
      "epoch": 59.143968871595334,
      "grad_norm": 0.3477250337600708,
      "learning_rate": 0.00040409044832989796,
      "loss": 1.9652,
      "step": 15200
    },
    {
      "epoch": 59.18287937743191,
      "grad_norm": 0.33922258019447327,
      "learning_rate": 0.00040396887825770933,
      "loss": 1.9775,
      "step": 15210
    },
    {
      "epoch": 59.221789883268485,
      "grad_norm": 0.3407350778579712,
      "learning_rate": 0.0004038472494993125,
      "loss": 1.9683,
      "step": 15220
    },
    {
      "epoch": 59.26070038910506,
      "grad_norm": 0.3365086019039154,
      "learning_rate": 0.00040372556210106704,
      "loss": 1.9675,
      "step": 15230
    },
    {
      "epoch": 59.29961089494164,
      "grad_norm": 0.34944096207618713,
      "learning_rate": 0.0004036038161093549,
      "loss": 1.9753,
      "step": 15240
    },
    {
      "epoch": 59.33852140077821,
      "grad_norm": 0.35056474804878235,
      "learning_rate": 0.00040348201157058025,
      "loss": 1.9882,
      "step": 15250
    },
    {
      "epoch": 59.37743190661479,
      "grad_norm": 0.3487928807735443,
      "learning_rate": 0.00040336014853116964,
      "loss": 1.9758,
      "step": 15260
    },
    {
      "epoch": 59.416342412451364,
      "grad_norm": 0.3400762379169464,
      "learning_rate": 0.00040323822703757206,
      "loss": 1.9565,
      "step": 15270
    },
    {
      "epoch": 59.45525291828794,
      "grad_norm": 0.3411162495613098,
      "learning_rate": 0.0004031162471362585,
      "loss": 1.9699,
      "step": 15280
    },
    {
      "epoch": 59.494163424124515,
      "grad_norm": 0.32325536012649536,
      "learning_rate": 0.00040299420887372257,
      "loss": 1.9727,
      "step": 15290
    },
    {
      "epoch": 59.53307392996109,
      "grad_norm": 0.33193695545196533,
      "learning_rate": 0.0004028721122964797,
      "loss": 1.9757,
      "step": 15300
    },
    {
      "epoch": 59.57198443579767,
      "grad_norm": 0.3954381048679352,
      "learning_rate": 0.0004027499574510679,
      "loss": 1.9886,
      "step": 15310
    },
    {
      "epoch": 59.61089494163424,
      "grad_norm": 0.34745684266090393,
      "learning_rate": 0.00040262774438404726,
      "loss": 1.9751,
      "step": 15320
    },
    {
      "epoch": 59.64980544747082,
      "grad_norm": 0.3453022241592407,
      "learning_rate": 0.000402505473142,
      "loss": 1.965,
      "step": 15330
    },
    {
      "epoch": 59.688715953307394,
      "grad_norm": 0.3282604515552521,
      "learning_rate": 0.0004023831437715306,
      "loss": 1.9807,
      "step": 15340
    },
    {
      "epoch": 59.72762645914397,
      "grad_norm": 0.32229506969451904,
      "learning_rate": 0.0004022607563192657,
      "loss": 1.9723,
      "step": 15350
    },
    {
      "epoch": 59.766536964980546,
      "grad_norm": 0.3504968583583832,
      "learning_rate": 0.00040213831083185403,
      "loss": 1.9842,
      "step": 15360
    },
    {
      "epoch": 59.80544747081712,
      "grad_norm": 0.34663456678390503,
      "learning_rate": 0.00040201580735596657,
      "loss": 1.9887,
      "step": 15370
    },
    {
      "epoch": 59.8443579766537,
      "grad_norm": 0.34715521335601807,
      "learning_rate": 0.000401893245938296,
      "loss": 1.9823,
      "step": 15380
    },
    {
      "epoch": 59.88326848249027,
      "grad_norm": 0.3434317708015442,
      "learning_rate": 0.0004017706266255576,
      "loss": 1.9798,
      "step": 15390
    },
    {
      "epoch": 59.92217898832685,
      "grad_norm": 0.32992836833000183,
      "learning_rate": 0.00040164794946448846,
      "loss": 1.9797,
      "step": 15400
    },
    {
      "epoch": 59.961089494163424,
      "grad_norm": 0.34142136573791504,
      "learning_rate": 0.0004015252145018478,
      "loss": 1.9823,
      "step": 15410
    },
    {
      "epoch": 60.0,
      "grad_norm": 0.4823756217956543,
      "learning_rate": 0.00040140242178441667,
      "loss": 1.9862,
      "step": 15420
    },
    {
      "epoch": 60.0,
      "eval_loss": 1.095213532447815,
      "eval_runtime": 6.2279,
      "eval_samples_per_second": 3590.772,
      "eval_steps_per_second": 14.13,
      "step": 15420
    },
    {
      "epoch": 60.038910505836576,
      "grad_norm": 0.3337678909301758,
      "learning_rate": 0.0004012795713589984,
      "loss": 1.958,
      "step": 15430
    },
    {
      "epoch": 60.07782101167315,
      "grad_norm": 0.36739790439605713,
      "learning_rate": 0.0004011566632724183,
      "loss": 1.9683,
      "step": 15440
    },
    {
      "epoch": 60.11673151750973,
      "grad_norm": 0.3328346312046051,
      "learning_rate": 0.0004010336975715233,
      "loss": 1.9574,
      "step": 15450
    },
    {
      "epoch": 60.1556420233463,
      "grad_norm": 0.38494250178337097,
      "learning_rate": 0.00040091067430318277,
      "loss": 1.9762,
      "step": 15460
    },
    {
      "epoch": 60.19455252918288,
      "grad_norm": 0.32056888937950134,
      "learning_rate": 0.00040078759351428773,
      "loss": 1.9598,
      "step": 15470
    },
    {
      "epoch": 60.233463035019454,
      "grad_norm": 0.36446040868759155,
      "learning_rate": 0.00040066445525175124,
      "loss": 1.9534,
      "step": 15480
    },
    {
      "epoch": 60.27237354085603,
      "grad_norm": 0.3575746417045593,
      "learning_rate": 0.00040054125956250807,
      "loss": 1.9645,
      "step": 15490
    },
    {
      "epoch": 60.311284046692606,
      "grad_norm": 0.3485151529312134,
      "learning_rate": 0.0004004180064935153,
      "loss": 1.9614,
      "step": 15500
    },
    {
      "epoch": 60.35019455252918,
      "grad_norm": 0.3806590139865875,
      "learning_rate": 0.0004002946960917514,
      "loss": 1.9642,
      "step": 15510
    },
    {
      "epoch": 60.38910505836576,
      "grad_norm": 0.3655312657356262,
      "learning_rate": 0.000400171328404217,
      "loss": 1.9719,
      "step": 15520
    },
    {
      "epoch": 60.42801556420233,
      "grad_norm": 0.3228084146976471,
      "learning_rate": 0.0004000479034779344,
      "loss": 1.9716,
      "step": 15530
    },
    {
      "epoch": 60.46692607003891,
      "grad_norm": 0.3366323411464691,
      "learning_rate": 0.0003999244213599478,
      "loss": 1.9747,
      "step": 15540
    },
    {
      "epoch": 60.505836575875485,
      "grad_norm": 0.3305634558200836,
      "learning_rate": 0.00039980088209732326,
      "loss": 1.9698,
      "step": 15550
    },
    {
      "epoch": 60.54474708171206,
      "grad_norm": 0.3168752193450928,
      "learning_rate": 0.00039967728573714854,
      "loss": 1.9748,
      "step": 15560
    },
    {
      "epoch": 60.583657587548636,
      "grad_norm": 0.3975794017314911,
      "learning_rate": 0.0003995536323265331,
      "loss": 1.9773,
      "step": 15570
    },
    {
      "epoch": 60.62256809338521,
      "grad_norm": 0.3444485068321228,
      "learning_rate": 0.0003994299219126083,
      "loss": 1.9721,
      "step": 15580
    },
    {
      "epoch": 60.66147859922179,
      "grad_norm": 0.33864322304725647,
      "learning_rate": 0.00039930615454252704,
      "loss": 1.965,
      "step": 15590
    },
    {
      "epoch": 60.70038910505836,
      "grad_norm": 0.3511909544467926,
      "learning_rate": 0.0003991823302634642,
      "loss": 1.9676,
      "step": 15600
    },
    {
      "epoch": 60.73929961089494,
      "grad_norm": 0.3508691191673279,
      "learning_rate": 0.00039905844912261593,
      "loss": 1.9778,
      "step": 15610
    },
    {
      "epoch": 60.778210116731515,
      "grad_norm": 0.32243233919143677,
      "learning_rate": 0.0003989345111672005,
      "loss": 1.9865,
      "step": 15620
    },
    {
      "epoch": 60.81712062256809,
      "grad_norm": 0.33453288674354553,
      "learning_rate": 0.00039881051644445766,
      "loss": 1.9735,
      "step": 15630
    },
    {
      "epoch": 60.856031128404666,
      "grad_norm": 0.32002493739128113,
      "learning_rate": 0.00039868646500164866,
      "loss": 1.9759,
      "step": 15640
    },
    {
      "epoch": 60.89494163424124,
      "grad_norm": 0.34945231676101685,
      "learning_rate": 0.00039856235688605655,
      "loss": 1.9693,
      "step": 15650
    },
    {
      "epoch": 60.93385214007782,
      "grad_norm": 0.32486698031425476,
      "learning_rate": 0.00039843819214498594,
      "loss": 1.9859,
      "step": 15660
    },
    {
      "epoch": 60.97276264591439,
      "grad_norm": 0.3163999617099762,
      "learning_rate": 0.000398313970825763,
      "loss": 1.971,
      "step": 15670
    },
    {
      "epoch": 61.0,
      "eval_loss": 1.0941812992095947,
      "eval_runtime": 6.1959,
      "eval_samples_per_second": 3609.342,
      "eval_steps_per_second": 14.203,
      "step": 15677
    },
    {
      "epoch": 61.011673151750976,
      "grad_norm": 0.3236508369445801,
      "learning_rate": 0.0003981896929757354,
      "loss": 1.9719,
      "step": 15680
    },
    {
      "epoch": 61.05058365758755,
      "grad_norm": 0.38029834628105164,
      "learning_rate": 0.0003980653586422726,
      "loss": 1.946,
      "step": 15690
    },
    {
      "epoch": 61.08949416342413,
      "grad_norm": 0.3523813784122467,
      "learning_rate": 0.0003979409678727651,
      "loss": 1.9586,
      "step": 15700
    },
    {
      "epoch": 61.1284046692607,
      "grad_norm": 0.3680781126022339,
      "learning_rate": 0.00039781652071462555,
      "loss": 1.9575,
      "step": 15710
    },
    {
      "epoch": 61.16731517509728,
      "grad_norm": 0.376334011554718,
      "learning_rate": 0.00039769201721528757,
      "loss": 1.9463,
      "step": 15720
    },
    {
      "epoch": 61.206225680933855,
      "grad_norm": 0.35875004529953003,
      "learning_rate": 0.0003975674574222065,
      "loss": 1.9482,
      "step": 15730
    },
    {
      "epoch": 61.24513618677043,
      "grad_norm": 0.3473888337612152,
      "learning_rate": 0.00039744284138285913,
      "loss": 1.9611,
      "step": 15740
    },
    {
      "epoch": 61.284046692607006,
      "grad_norm": 0.3567071557044983,
      "learning_rate": 0.00039731816914474375,
      "loss": 1.9605,
      "step": 15750
    },
    {
      "epoch": 61.32295719844358,
      "grad_norm": 0.36354976892471313,
      "learning_rate": 0.0003971934407553797,
      "loss": 1.9607,
      "step": 15760
    },
    {
      "epoch": 61.36186770428016,
      "grad_norm": 0.366940975189209,
      "learning_rate": 0.00039706865626230816,
      "loss": 1.9699,
      "step": 15770
    },
    {
      "epoch": 61.400778210116734,
      "grad_norm": 0.3507235050201416,
      "learning_rate": 0.00039694381571309144,
      "loss": 1.9752,
      "step": 15780
    },
    {
      "epoch": 61.43968871595331,
      "grad_norm": 0.38246291875839233,
      "learning_rate": 0.00039681891915531356,
      "loss": 1.9748,
      "step": 15790
    },
    {
      "epoch": 61.478599221789885,
      "grad_norm": 0.35677894949913025,
      "learning_rate": 0.0003966939666365792,
      "loss": 1.9664,
      "step": 15800
    },
    {
      "epoch": 61.51750972762646,
      "grad_norm": 0.3559500575065613,
      "learning_rate": 0.0003965689582045152,
      "loss": 1.9612,
      "step": 15810
    },
    {
      "epoch": 61.55642023346304,
      "grad_norm": 0.32924556732177734,
      "learning_rate": 0.00039644389390676904,
      "loss": 1.9711,
      "step": 15820
    },
    {
      "epoch": 61.59533073929961,
      "grad_norm": 0.3400479555130005,
      "learning_rate": 0.00039631877379101,
      "loss": 1.9645,
      "step": 15830
    },
    {
      "epoch": 61.63424124513619,
      "grad_norm": 0.3389228880405426,
      "learning_rate": 0.00039619359790492813,
      "loss": 1.9747,
      "step": 15840
    },
    {
      "epoch": 61.673151750972764,
      "grad_norm": 0.36572667956352234,
      "learning_rate": 0.0003960683662962352,
      "loss": 1.9631,
      "step": 15850
    },
    {
      "epoch": 61.71206225680934,
      "grad_norm": 0.3354033827781677,
      "learning_rate": 0.00039594307901266403,
      "loss": 1.9728,
      "step": 15860
    },
    {
      "epoch": 61.750972762645915,
      "grad_norm": 0.34906038641929626,
      "learning_rate": 0.00039581773610196857,
      "loss": 1.9812,
      "step": 15870
    },
    {
      "epoch": 61.78988326848249,
      "grad_norm": 0.33606088161468506,
      "learning_rate": 0.0003956923376119241,
      "loss": 1.9794,
      "step": 15880
    },
    {
      "epoch": 61.82879377431907,
      "grad_norm": 0.3236403167247772,
      "learning_rate": 0.000395566883590327,
      "loss": 1.9777,
      "step": 15890
    },
    {
      "epoch": 61.86770428015564,
      "grad_norm": 0.33608242869377136,
      "learning_rate": 0.0003954413740849949,
      "loss": 1.9649,
      "step": 15900
    },
    {
      "epoch": 61.90661478599222,
      "grad_norm": 0.3451845347881317,
      "learning_rate": 0.0003953158091437666,
      "loss": 1.9847,
      "step": 15910
    },
    {
      "epoch": 61.945525291828794,
      "grad_norm": 0.32433733344078064,
      "learning_rate": 0.0003951901888145019,
      "loss": 1.9707,
      "step": 15920
    },
    {
      "epoch": 61.98443579766537,
      "grad_norm": 0.3534550964832306,
      "learning_rate": 0.00039506451314508175,
      "loss": 1.9664,
      "step": 15930
    },
    {
      "epoch": 62.0,
      "eval_loss": 1.0978717803955078,
      "eval_runtime": 6.2324,
      "eval_samples_per_second": 3588.202,
      "eval_steps_per_second": 14.12,
      "step": 15934
    },
    {
      "epoch": 62.0,
      "step": 15934,
      "total_flos": 2.2017388820955136e+16,
      "train_loss": 2.282557662703154,
      "train_runtime": 4206.7224,
      "train_samples_per_second": 6247.762,
      "train_steps_per_second": 12.219
    }
  ],
  "logging_steps": 10,
  "max_steps": 51400,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 200,
  "save_steps": 1000,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 20,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 20
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.2017388820955136e+16,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
