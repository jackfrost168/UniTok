{
  "best_metric": 1.1354084014892578,
  "best_model_checkpoint": "./ckpt/Toys_and_Games/checkpoint-9630",
  "epoch": 65.0,
  "eval_steps": 1000,
  "global_step": 13910,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04672897196261682,
      "grad_norm": 12.911788940429688,
      "learning_rate": 1.1682242990654205e-05,
      "loss": 21.4837,
      "step": 10
    },
    {
      "epoch": 0.09345794392523364,
      "grad_norm": 8.98236083984375,
      "learning_rate": 2.336448598130841e-05,
      "loss": 20.1135,
      "step": 20
    },
    {
      "epoch": 0.14018691588785046,
      "grad_norm": 5.230043888092041,
      "learning_rate": 3.504672897196262e-05,
      "loss": 18.1923,
      "step": 30
    },
    {
      "epoch": 0.18691588785046728,
      "grad_norm": 3.2932496070861816,
      "learning_rate": 4.672897196261682e-05,
      "loss": 16.5796,
      "step": 40
    },
    {
      "epoch": 0.2336448598130841,
      "grad_norm": 3.561553955078125,
      "learning_rate": 5.841121495327103e-05,
      "loss": 15.2539,
      "step": 50
    },
    {
      "epoch": 0.2803738317757009,
      "grad_norm": 3.0345239639282227,
      "learning_rate": 7.009345794392523e-05,
      "loss": 13.5516,
      "step": 60
    },
    {
      "epoch": 0.32710280373831774,
      "grad_norm": 2.58293080329895,
      "learning_rate": 8.177570093457943e-05,
      "loss": 11.7857,
      "step": 70
    },
    {
      "epoch": 0.37383177570093457,
      "grad_norm": 2.2588934898376465,
      "learning_rate": 9.345794392523364e-05,
      "loss": 10.1756,
      "step": 80
    },
    {
      "epoch": 0.4205607476635514,
      "grad_norm": 1.8342736959457397,
      "learning_rate": 0.00010514018691588785,
      "loss": 9.0043,
      "step": 90
    },
    {
      "epoch": 0.4672897196261682,
      "grad_norm": 1.509599208831787,
      "learning_rate": 0.00011682242990654206,
      "loss": 7.9836,
      "step": 100
    },
    {
      "epoch": 0.514018691588785,
      "grad_norm": 1.40744948387146,
      "learning_rate": 0.00012850467289719626,
      "loss": 7.5412,
      "step": 110
    },
    {
      "epoch": 0.5607476635514018,
      "grad_norm": 1.2720379829406738,
      "learning_rate": 0.00014018691588785047,
      "loss": 7.2332,
      "step": 120
    },
    {
      "epoch": 0.6074766355140186,
      "grad_norm": 1.256248116493225,
      "learning_rate": 0.00015186915887850468,
      "loss": 6.9699,
      "step": 130
    },
    {
      "epoch": 0.6542056074766355,
      "grad_norm": 1.1561496257781982,
      "learning_rate": 0.00016355140186915886,
      "loss": 6.7056,
      "step": 140
    },
    {
      "epoch": 0.7009345794392523,
      "grad_norm": 1.1118226051330566,
      "learning_rate": 0.00017523364485981307,
      "loss": 6.5161,
      "step": 150
    },
    {
      "epoch": 0.7476635514018691,
      "grad_norm": 1.1718448400497437,
      "learning_rate": 0.00018691588785046728,
      "loss": 6.4282,
      "step": 160
    },
    {
      "epoch": 0.794392523364486,
      "grad_norm": 1.0469359159469604,
      "learning_rate": 0.0001985981308411215,
      "loss": 6.3141,
      "step": 170
    },
    {
      "epoch": 0.8411214953271028,
      "grad_norm": 1.1878700256347656,
      "learning_rate": 0.0002102803738317757,
      "loss": 6.1318,
      "step": 180
    },
    {
      "epoch": 0.8878504672897196,
      "grad_norm": 1.0159204006195068,
      "learning_rate": 0.0002219626168224299,
      "loss": 6.009,
      "step": 190
    },
    {
      "epoch": 0.9345794392523364,
      "grad_norm": 0.973763644695282,
      "learning_rate": 0.00023364485981308412,
      "loss": 5.9548,
      "step": 200
    },
    {
      "epoch": 0.9813084112149533,
      "grad_norm": 0.9459819197654724,
      "learning_rate": 0.00024532710280373833,
      "loss": 5.8199,
      "step": 210
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.7402050495147705,
      "eval_runtime": 5.4589,
      "eval_samples_per_second": 3556.014,
      "eval_steps_per_second": 13.922,
      "step": 214
    },
    {
      "epoch": 1.02803738317757,
      "grad_norm": 1.009809970855713,
      "learning_rate": 0.0002570093457943925,
      "loss": 5.7452,
      "step": 220
    },
    {
      "epoch": 1.074766355140187,
      "grad_norm": 1.0185295343399048,
      "learning_rate": 0.00026869158878504675,
      "loss": 5.6572,
      "step": 230
    },
    {
      "epoch": 1.1214953271028036,
      "grad_norm": 0.8551406860351562,
      "learning_rate": 0.00028037383177570094,
      "loss": 5.5699,
      "step": 240
    },
    {
      "epoch": 1.1682242990654206,
      "grad_norm": 0.8116162419319153,
      "learning_rate": 0.00029205607476635517,
      "loss": 5.5219,
      "step": 250
    },
    {
      "epoch": 1.2149532710280373,
      "grad_norm": 0.795955240726471,
      "learning_rate": 0.00030373831775700936,
      "loss": 5.4003,
      "step": 260
    },
    {
      "epoch": 1.2616822429906542,
      "grad_norm": 0.760670006275177,
      "learning_rate": 0.00031542056074766354,
      "loss": 5.3055,
      "step": 270
    },
    {
      "epoch": 1.308411214953271,
      "grad_norm": 0.7343938946723938,
      "learning_rate": 0.0003271028037383177,
      "loss": 5.2066,
      "step": 280
    },
    {
      "epoch": 1.355140186915888,
      "grad_norm": 0.75275057554245,
      "learning_rate": 0.00033878504672897196,
      "loss": 5.1219,
      "step": 290
    },
    {
      "epoch": 1.4018691588785046,
      "grad_norm": 0.7245367169380188,
      "learning_rate": 0.00035046728971962614,
      "loss": 5.0688,
      "step": 300
    },
    {
      "epoch": 1.4485981308411215,
      "grad_norm": 0.65972501039505,
      "learning_rate": 0.0003621495327102804,
      "loss": 5.0003,
      "step": 310
    },
    {
      "epoch": 1.4953271028037383,
      "grad_norm": 0.7033731937408447,
      "learning_rate": 0.00037383177570093456,
      "loss": 4.9236,
      "step": 320
    },
    {
      "epoch": 1.542056074766355,
      "grad_norm": 0.663781464099884,
      "learning_rate": 0.0003855140186915888,
      "loss": 4.8052,
      "step": 330
    },
    {
      "epoch": 1.588785046728972,
      "grad_norm": 0.8042008280754089,
      "learning_rate": 0.000397196261682243,
      "loss": 4.761,
      "step": 340
    },
    {
      "epoch": 1.6355140186915889,
      "grad_norm": 0.6144437193870544,
      "learning_rate": 0.0004088785046728972,
      "loss": 4.7083,
      "step": 350
    },
    {
      "epoch": 1.6822429906542056,
      "grad_norm": 0.6497392058372498,
      "learning_rate": 0.0004205607476635514,
      "loss": 4.6149,
      "step": 360
    },
    {
      "epoch": 1.7289719626168223,
      "grad_norm": 0.6036389470100403,
      "learning_rate": 0.00043224299065420564,
      "loss": 4.5371,
      "step": 370
    },
    {
      "epoch": 1.7757009345794392,
      "grad_norm": 0.7538769245147705,
      "learning_rate": 0.0004439252336448598,
      "loss": 4.4692,
      "step": 380
    },
    {
      "epoch": 1.8224299065420562,
      "grad_norm": 0.6257584691047668,
      "learning_rate": 0.00045560747663551406,
      "loss": 4.3817,
      "step": 390
    },
    {
      "epoch": 1.8691588785046729,
      "grad_norm": 0.5747361779212952,
      "learning_rate": 0.00046728971962616824,
      "loss": 4.3404,
      "step": 400
    },
    {
      "epoch": 1.9158878504672896,
      "grad_norm": 0.6200488209724426,
      "learning_rate": 0.0004789719626168225,
      "loss": 4.2537,
      "step": 410
    },
    {
      "epoch": 1.9626168224299065,
      "grad_norm": 0.5087181925773621,
      "learning_rate": 0.0004906542056074767,
      "loss": 4.1774,
      "step": 420
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.9757990837097168,
      "eval_runtime": 5.4643,
      "eval_samples_per_second": 3552.534,
      "eval_steps_per_second": 13.909,
      "step": 428
    },
    {
      "epoch": 2.0093457943925235,
      "grad_norm": 0.6202853918075562,
      "learning_rate": 0.0004999999972513982,
      "loss": 4.1301,
      "step": 430
    },
    {
      "epoch": 2.05607476635514,
      "grad_norm": 0.49240946769714355,
      "learning_rate": 0.0004999999010503426,
      "loss": 4.0305,
      "step": 440
    },
    {
      "epoch": 2.102803738317757,
      "grad_norm": 0.5269511938095093,
      "learning_rate": 0.0004999996674192591,
      "loss": 3.95,
      "step": 450
    },
    {
      "epoch": 2.149532710280374,
      "grad_norm": 2.1738996505737305,
      "learning_rate": 0.0004999992963582759,
      "loss": 3.9229,
      "step": 460
    },
    {
      "epoch": 2.196261682242991,
      "grad_norm": 0.4396865963935852,
      "learning_rate": 0.0004999987878675971,
      "loss": 3.8439,
      "step": 470
    },
    {
      "epoch": 2.2429906542056073,
      "grad_norm": 0.42258796095848083,
      "learning_rate": 0.0004999981419475021,
      "loss": 3.802,
      "step": 480
    },
    {
      "epoch": 2.289719626168224,
      "grad_norm": 0.5974486470222473,
      "learning_rate": 0.0004999973585983463,
      "loss": 3.6924,
      "step": 490
    },
    {
      "epoch": 2.336448598130841,
      "grad_norm": 0.4851449728012085,
      "learning_rate": 0.00049999643782056,
      "loss": 3.7253,
      "step": 500
    },
    {
      "epoch": 2.383177570093458,
      "grad_norm": 0.4934317171573639,
      "learning_rate": 0.0004999953796146495,
      "loss": 3.6354,
      "step": 510
    },
    {
      "epoch": 2.4299065420560746,
      "grad_norm": 0.3472864329814911,
      "learning_rate": 0.0004999941839811965,
      "loss": 3.5538,
      "step": 520
    },
    {
      "epoch": 2.4766355140186915,
      "grad_norm": 0.3464597761631012,
      "learning_rate": 0.0004999928509208583,
      "loss": 3.4804,
      "step": 530
    },
    {
      "epoch": 2.5233644859813085,
      "grad_norm": 0.3518422245979309,
      "learning_rate": 0.0004999913804343677,
      "loss": 3.4787,
      "step": 540
    },
    {
      "epoch": 2.5700934579439254,
      "grad_norm": 0.3571282923221588,
      "learning_rate": 0.000499989772522533,
      "loss": 3.4081,
      "step": 550
    },
    {
      "epoch": 2.616822429906542,
      "grad_norm": 0.40099993348121643,
      "learning_rate": 0.000499988027186238,
      "loss": 3.3818,
      "step": 560
    },
    {
      "epoch": 2.663551401869159,
      "grad_norm": 0.39399927854537964,
      "learning_rate": 0.0004999861444264425,
      "loss": 3.3383,
      "step": 570
    },
    {
      "epoch": 2.710280373831776,
      "grad_norm": 0.2988314926624298,
      "learning_rate": 0.0004999841242441811,
      "loss": 3.2854,
      "step": 580
    },
    {
      "epoch": 2.7570093457943923,
      "grad_norm": 0.3317462205886841,
      "learning_rate": 0.0004999819666405646,
      "loss": 3.2636,
      "step": 590
    },
    {
      "epoch": 2.803738317757009,
      "grad_norm": 0.30589720606803894,
      "learning_rate": 0.000499979671616779,
      "loss": 3.251,
      "step": 600
    },
    {
      "epoch": 2.850467289719626,
      "grad_norm": 0.28504478931427,
      "learning_rate": 0.0004999772391740859,
      "loss": 3.2006,
      "step": 610
    },
    {
      "epoch": 2.897196261682243,
      "grad_norm": 0.3559640645980835,
      "learning_rate": 0.0004999746693138224,
      "loss": 3.1548,
      "step": 620
    },
    {
      "epoch": 2.94392523364486,
      "grad_norm": 0.30033233761787415,
      "learning_rate": 0.0004999719620374013,
      "loss": 3.1463,
      "step": 630
    },
    {
      "epoch": 2.9906542056074765,
      "grad_norm": 0.31885695457458496,
      "learning_rate": 0.0004999691173463109,
      "loss": 3.1172,
      "step": 640
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.5082108974456787,
      "eval_runtime": 5.4679,
      "eval_samples_per_second": 3550.198,
      "eval_steps_per_second": 13.899,
      "step": 642
    },
    {
      "epoch": 3.0373831775700935,
      "grad_norm": 0.34187158942222595,
      "learning_rate": 0.0004999661352421148,
      "loss": 3.0763,
      "step": 650
    },
    {
      "epoch": 3.0841121495327104,
      "grad_norm": 0.2700548768043518,
      "learning_rate": 0.0004999630157264526,
      "loss": 3.0688,
      "step": 660
    },
    {
      "epoch": 3.130841121495327,
      "grad_norm": 0.24236632883548737,
      "learning_rate": 0.0004999597588010388,
      "loss": 3.0331,
      "step": 670
    },
    {
      "epoch": 3.177570093457944,
      "grad_norm": 0.34467625617980957,
      "learning_rate": 0.000499956364467664,
      "loss": 3.0207,
      "step": 680
    },
    {
      "epoch": 3.2242990654205608,
      "grad_norm": 0.2996760904788971,
      "learning_rate": 0.0004999528327281942,
      "loss": 2.9634,
      "step": 690
    },
    {
      "epoch": 3.2710280373831777,
      "grad_norm": 0.24481132626533508,
      "learning_rate": 0.0004999491635845708,
      "loss": 2.9666,
      "step": 700
    },
    {
      "epoch": 3.317757009345794,
      "grad_norm": 0.2937810719013214,
      "learning_rate": 0.0004999453570388107,
      "loss": 2.9482,
      "step": 710
    },
    {
      "epoch": 3.364485981308411,
      "grad_norm": 0.32218679785728455,
      "learning_rate": 0.0004999414130930067,
      "loss": 2.9332,
      "step": 720
    },
    {
      "epoch": 3.411214953271028,
      "grad_norm": 0.26001521944999695,
      "learning_rate": 0.0004999373317493266,
      "loss": 2.9354,
      "step": 730
    },
    {
      "epoch": 3.457943925233645,
      "grad_norm": 0.2767893970012665,
      "learning_rate": 0.000499933113010014,
      "loss": 2.8816,
      "step": 740
    },
    {
      "epoch": 3.5046728971962615,
      "grad_norm": 0.23730887472629547,
      "learning_rate": 0.0004999287568773883,
      "loss": 2.8604,
      "step": 750
    },
    {
      "epoch": 3.5514018691588785,
      "grad_norm": 0.4859538674354553,
      "learning_rate": 0.0004999242633538438,
      "loss": 2.8246,
      "step": 760
    },
    {
      "epoch": 3.5981308411214954,
      "grad_norm": 0.21389514207839966,
      "learning_rate": 0.000499919632441851,
      "loss": 2.8377,
      "step": 770
    },
    {
      "epoch": 3.6448598130841123,
      "grad_norm": 0.31629055738449097,
      "learning_rate": 0.0004999148641439554,
      "loss": 2.8299,
      "step": 780
    },
    {
      "epoch": 3.691588785046729,
      "grad_norm": 0.2526956796646118,
      "learning_rate": 0.0004999099584627783,
      "loss": 2.807,
      "step": 790
    },
    {
      "epoch": 3.7383177570093458,
      "grad_norm": 0.35439926385879517,
      "learning_rate": 0.0004999049154010164,
      "loss": 2.8247,
      "step": 800
    },
    {
      "epoch": 3.7850467289719627,
      "grad_norm": 0.2984602153301239,
      "learning_rate": 0.0004998997349614421,
      "loss": 2.787,
      "step": 810
    },
    {
      "epoch": 3.831775700934579,
      "grad_norm": 0.21075373888015747,
      "learning_rate": 0.000499894417146903,
      "loss": 2.7659,
      "step": 820
    },
    {
      "epoch": 3.878504672897196,
      "grad_norm": 0.25479814410209656,
      "learning_rate": 0.0004998889619603226,
      "loss": 2.7697,
      "step": 830
    },
    {
      "epoch": 3.925233644859813,
      "grad_norm": 0.33988872170448303,
      "learning_rate": 0.0004998833694046997,
      "loss": 2.7671,
      "step": 840
    },
    {
      "epoch": 3.97196261682243,
      "grad_norm": 0.2275369018316269,
      "learning_rate": 0.0004998776394831085,
      "loss": 2.769,
      "step": 850
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.3413876295089722,
      "eval_runtime": 5.5633,
      "eval_samples_per_second": 3489.308,
      "eval_steps_per_second": 13.661,
      "step": 856
    },
    {
      "epoch": 4.018691588785047,
      "grad_norm": 0.21495915949344635,
      "learning_rate": 0.000499871772198699,
      "loss": 2.7234,
      "step": 860
    },
    {
      "epoch": 4.065420560747664,
      "grad_norm": 0.2222709059715271,
      "learning_rate": 0.0004998657675546965,
      "loss": 2.7531,
      "step": 870
    },
    {
      "epoch": 4.11214953271028,
      "grad_norm": 1.3277904987335205,
      "learning_rate": 0.0004998596255544019,
      "loss": 2.7078,
      "step": 880
    },
    {
      "epoch": 4.158878504672897,
      "grad_norm": 0.219929039478302,
      "learning_rate": 0.0004998533462011916,
      "loss": 2.7377,
      "step": 890
    },
    {
      "epoch": 4.205607476635514,
      "grad_norm": 0.21870893239974976,
      "learning_rate": 0.0004998469294985174,
      "loss": 2.6996,
      "step": 900
    },
    {
      "epoch": 4.252336448598131,
      "grad_norm": 0.2385089099407196,
      "learning_rate": 0.0004998403754499067,
      "loss": 2.7087,
      "step": 910
    },
    {
      "epoch": 4.299065420560748,
      "grad_norm": 0.21594089269638062,
      "learning_rate": 0.0004998336840589626,
      "loss": 2.6776,
      "step": 920
    },
    {
      "epoch": 4.345794392523365,
      "grad_norm": 0.2659348249435425,
      "learning_rate": 0.0004998268553293632,
      "loss": 2.6825,
      "step": 930
    },
    {
      "epoch": 4.392523364485982,
      "grad_norm": 0.2061716914176941,
      "learning_rate": 0.0004998198892648626,
      "loss": 2.6716,
      "step": 940
    },
    {
      "epoch": 4.4392523364485985,
      "grad_norm": 0.218571737408638,
      "learning_rate": 0.00049981278586929,
      "loss": 2.6468,
      "step": 950
    },
    {
      "epoch": 4.485981308411215,
      "grad_norm": 0.23069268465042114,
      "learning_rate": 0.0004998055451465505,
      "loss": 2.661,
      "step": 960
    },
    {
      "epoch": 4.5327102803738315,
      "grad_norm": 0.2314687967300415,
      "learning_rate": 0.0004997981671006243,
      "loss": 2.6507,
      "step": 970
    },
    {
      "epoch": 4.579439252336448,
      "grad_norm": 0.1976572722196579,
      "learning_rate": 0.0004997906517355674,
      "loss": 2.6477,
      "step": 980
    },
    {
      "epoch": 4.626168224299065,
      "grad_norm": 0.22989127039909363,
      "learning_rate": 0.0004997829990555111,
      "loss": 2.6474,
      "step": 990
    },
    {
      "epoch": 4.672897196261682,
      "grad_norm": 0.23764806985855103,
      "learning_rate": 0.0004997752090646621,
      "loss": 2.634,
      "step": 1000
    },
    {
      "epoch": 4.719626168224299,
      "grad_norm": 0.2329656183719635,
      "learning_rate": 0.000499767281767303,
      "loss": 2.6356,
      "step": 1010
    },
    {
      "epoch": 4.766355140186916,
      "grad_norm": 0.20089603960514069,
      "learning_rate": 0.0004997592171677912,
      "loss": 2.6107,
      "step": 1020
    },
    {
      "epoch": 4.813084112149532,
      "grad_norm": 0.2623112201690674,
      "learning_rate": 0.0004997510152705604,
      "loss": 2.6075,
      "step": 1030
    },
    {
      "epoch": 4.859813084112149,
      "grad_norm": 0.4119821786880493,
      "learning_rate": 0.000499742676080119,
      "loss": 2.63,
      "step": 1040
    },
    {
      "epoch": 4.906542056074766,
      "grad_norm": 0.19275330007076263,
      "learning_rate": 0.0004997341996010516,
      "loss": 2.5986,
      "step": 1050
    },
    {
      "epoch": 4.953271028037383,
      "grad_norm": 0.22230149805545807,
      "learning_rate": 0.0004997255858380174,
      "loss": 2.6,
      "step": 1060
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.31725868582725525,
      "learning_rate": 0.000499716834795752,
      "loss": 2.5978,
      "step": 1070
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.2751412391662598,
      "eval_runtime": 5.495,
      "eval_samples_per_second": 3532.672,
      "eval_steps_per_second": 13.831,
      "step": 1070
    },
    {
      "epoch": 5.046728971962617,
      "grad_norm": 0.23973296582698822,
      "learning_rate": 0.0004997079464790659,
      "loss": 2.5808,
      "step": 1080
    },
    {
      "epoch": 5.093457943925234,
      "grad_norm": 0.22175851464271545,
      "learning_rate": 0.000499698920892845,
      "loss": 2.5738,
      "step": 1090
    },
    {
      "epoch": 5.140186915887851,
      "grad_norm": 0.24757999181747437,
      "learning_rate": 0.000499689758042051,
      "loss": 2.5871,
      "step": 1100
    },
    {
      "epoch": 5.186915887850467,
      "grad_norm": 0.2004144787788391,
      "learning_rate": 0.0004996804579317209,
      "loss": 2.5798,
      "step": 1110
    },
    {
      "epoch": 5.233644859813084,
      "grad_norm": 0.2219940572977066,
      "learning_rate": 0.0004996710205669671,
      "loss": 2.5843,
      "step": 1120
    },
    {
      "epoch": 5.280373831775701,
      "grad_norm": 0.1889733225107193,
      "learning_rate": 0.0004996614459529777,
      "loss": 2.585,
      "step": 1130
    },
    {
      "epoch": 5.327102803738318,
      "grad_norm": 0.20711714029312134,
      "learning_rate": 0.0004996517340950158,
      "loss": 2.578,
      "step": 1140
    },
    {
      "epoch": 5.373831775700935,
      "grad_norm": 0.30178168416023254,
      "learning_rate": 0.0004996418849984205,
      "loss": 2.563,
      "step": 1150
    },
    {
      "epoch": 5.420560747663552,
      "grad_norm": 0.19051869213581085,
      "learning_rate": 0.0004996318986686057,
      "loss": 2.5694,
      "step": 1160
    },
    {
      "epoch": 5.4672897196261685,
      "grad_norm": 0.25937938690185547,
      "learning_rate": 0.0004996217751110613,
      "loss": 2.565,
      "step": 1170
    },
    {
      "epoch": 5.5140186915887845,
      "grad_norm": 0.20427733659744263,
      "learning_rate": 0.0004996115143313525,
      "loss": 2.5576,
      "step": 1180
    },
    {
      "epoch": 5.5607476635514015,
      "grad_norm": 0.22215396165847778,
      "learning_rate": 0.0004996011163351197,
      "loss": 2.5598,
      "step": 1190
    },
    {
      "epoch": 5.607476635514018,
      "grad_norm": 0.2076454609632492,
      "learning_rate": 0.0004995905811280789,
      "loss": 2.5489,
      "step": 1200
    },
    {
      "epoch": 5.654205607476635,
      "grad_norm": 0.20737475156784058,
      "learning_rate": 0.0004995799087160216,
      "loss": 2.5791,
      "step": 1210
    },
    {
      "epoch": 5.700934579439252,
      "grad_norm": 0.2506759464740753,
      "learning_rate": 0.0004995690991048146,
      "loss": 2.5483,
      "step": 1220
    },
    {
      "epoch": 5.747663551401869,
      "grad_norm": 0.25382015109062195,
      "learning_rate": 0.0004995581523004001,
      "loss": 2.5504,
      "step": 1230
    },
    {
      "epoch": 5.794392523364486,
      "grad_norm": 0.2017277628183365,
      "learning_rate": 0.0004995470683087959,
      "loss": 2.5373,
      "step": 1240
    },
    {
      "epoch": 5.841121495327103,
      "grad_norm": 0.19920630753040314,
      "learning_rate": 0.0004995358471360952,
      "loss": 2.5292,
      "step": 1250
    },
    {
      "epoch": 5.88785046728972,
      "grad_norm": 0.2349066138267517,
      "learning_rate": 0.0004995244887884661,
      "loss": 2.5282,
      "step": 1260
    },
    {
      "epoch": 5.934579439252336,
      "grad_norm": 0.23726460337638855,
      "learning_rate": 0.0004995129932721528,
      "loss": 2.5285,
      "step": 1270
    },
    {
      "epoch": 5.981308411214953,
      "grad_norm": 0.21439237892627716,
      "learning_rate": 0.0004995013605934746,
      "loss": 2.5306,
      "step": 1280
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.242438793182373,
      "eval_runtime": 5.516,
      "eval_samples_per_second": 3519.185,
      "eval_steps_per_second": 13.778,
      "step": 1284
    },
    {
      "epoch": 6.02803738317757,
      "grad_norm": 0.18333078920841217,
      "learning_rate": 0.0004994895907588263,
      "loss": 2.5289,
      "step": 1290
    },
    {
      "epoch": 6.074766355140187,
      "grad_norm": 0.22680073976516724,
      "learning_rate": 0.0004994776837746778,
      "loss": 2.5231,
      "step": 1300
    },
    {
      "epoch": 6.121495327102804,
      "grad_norm": 0.2540360689163208,
      "learning_rate": 0.0004994656396475749,
      "loss": 2.5359,
      "step": 1310
    },
    {
      "epoch": 6.168224299065421,
      "grad_norm": 0.19988124072551727,
      "learning_rate": 0.0004994534583841381,
      "loss": 2.5197,
      "step": 1320
    },
    {
      "epoch": 6.214953271028038,
      "grad_norm": 0.23920810222625732,
      "learning_rate": 0.0004994411399910641,
      "loss": 2.5081,
      "step": 1330
    },
    {
      "epoch": 6.261682242990654,
      "grad_norm": 0.23216010630130768,
      "learning_rate": 0.0004994286844751244,
      "loss": 2.4966,
      "step": 1340
    },
    {
      "epoch": 6.308411214953271,
      "grad_norm": 0.2448776662349701,
      "learning_rate": 0.0004994160918431659,
      "loss": 2.5131,
      "step": 1350
    },
    {
      "epoch": 6.355140186915888,
      "grad_norm": 0.2352929711341858,
      "learning_rate": 0.0004994033621021113,
      "loss": 2.5141,
      "step": 1360
    },
    {
      "epoch": 6.401869158878505,
      "grad_norm": 0.22722779214382172,
      "learning_rate": 0.0004993904952589581,
      "loss": 2.5068,
      "step": 1370
    },
    {
      "epoch": 6.4485981308411215,
      "grad_norm": 0.23429250717163086,
      "learning_rate": 0.0004993774913207798,
      "loss": 2.4997,
      "step": 1380
    },
    {
      "epoch": 6.4953271028037385,
      "grad_norm": 0.23650601506233215,
      "learning_rate": 0.0004993643502947246,
      "loss": 2.5025,
      "step": 1390
    },
    {
      "epoch": 6.542056074766355,
      "grad_norm": 0.2677355110645294,
      "learning_rate": 0.0004993510721880167,
      "loss": 2.4977,
      "step": 1400
    },
    {
      "epoch": 6.588785046728972,
      "grad_norm": 0.22338759899139404,
      "learning_rate": 0.0004993376570079552,
      "loss": 2.5017,
      "step": 1410
    },
    {
      "epoch": 6.635514018691588,
      "grad_norm": 0.19646808505058289,
      "learning_rate": 0.0004993241047619146,
      "loss": 2.4921,
      "step": 1420
    },
    {
      "epoch": 6.682242990654205,
      "grad_norm": 0.2458503395318985,
      "learning_rate": 0.000499310415457345,
      "loss": 2.4917,
      "step": 1430
    },
    {
      "epoch": 6.728971962616822,
      "grad_norm": 0.4509492516517639,
      "learning_rate": 0.0004992965891017715,
      "loss": 2.4976,
      "step": 1440
    },
    {
      "epoch": 6.775700934579439,
      "grad_norm": 0.2029295712709427,
      "learning_rate": 0.0004992826257027949,
      "loss": 2.4905,
      "step": 1450
    },
    {
      "epoch": 6.822429906542056,
      "grad_norm": 0.22342848777770996,
      "learning_rate": 0.0004992685252680912,
      "loss": 2.4743,
      "step": 1460
    },
    {
      "epoch": 6.869158878504673,
      "grad_norm": 0.23423832654953003,
      "learning_rate": 0.0004992542878054115,
      "loss": 2.4861,
      "step": 1470
    },
    {
      "epoch": 6.91588785046729,
      "grad_norm": 0.23909613490104675,
      "learning_rate": 0.0004992399133225827,
      "loss": 2.5109,
      "step": 1480
    },
    {
      "epoch": 6.962616822429906,
      "grad_norm": 0.22622528672218323,
      "learning_rate": 0.0004992254018275064,
      "loss": 2.488,
      "step": 1490
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.2219821214675903,
      "eval_runtime": 5.5125,
      "eval_samples_per_second": 3521.451,
      "eval_steps_per_second": 13.787,
      "step": 1498
    },
    {
      "epoch": 7.009345794392523,
      "grad_norm": 0.2733405530452728,
      "learning_rate": 0.0004992107533281602,
      "loss": 2.4796,
      "step": 1500
    },
    {
      "epoch": 7.05607476635514,
      "grad_norm": 0.21458950638771057,
      "learning_rate": 0.0004991959678325964,
      "loss": 2.4735,
      "step": 1510
    },
    {
      "epoch": 7.102803738317757,
      "grad_norm": 0.21583765745162964,
      "learning_rate": 0.0004991810453489432,
      "loss": 2.4791,
      "step": 1520
    },
    {
      "epoch": 7.149532710280374,
      "grad_norm": 0.23435115814208984,
      "learning_rate": 0.0004991659858854034,
      "loss": 2.4829,
      "step": 1530
    },
    {
      "epoch": 7.196261682242991,
      "grad_norm": 0.24289147555828094,
      "learning_rate": 0.0004991507894502557,
      "loss": 2.465,
      "step": 1540
    },
    {
      "epoch": 7.242990654205608,
      "grad_norm": 0.2375035285949707,
      "learning_rate": 0.000499135456051854,
      "loss": 2.4865,
      "step": 1550
    },
    {
      "epoch": 7.289719626168225,
      "grad_norm": 0.19284431636333466,
      "learning_rate": 0.0004991199856986272,
      "loss": 2.4699,
      "step": 1560
    },
    {
      "epoch": 7.336448598130841,
      "grad_norm": 0.22043336927890778,
      "learning_rate": 0.0004991043783990798,
      "loss": 2.4838,
      "step": 1570
    },
    {
      "epoch": 7.383177570093458,
      "grad_norm": 0.4636644721031189,
      "learning_rate": 0.0004990886341617913,
      "loss": 2.4618,
      "step": 1580
    },
    {
      "epoch": 7.429906542056075,
      "grad_norm": 0.22105590999126434,
      "learning_rate": 0.0004990727529954168,
      "loss": 2.4585,
      "step": 1590
    },
    {
      "epoch": 7.4766355140186915,
      "grad_norm": 0.21695208549499512,
      "learning_rate": 0.0004990567349086863,
      "loss": 2.455,
      "step": 1600
    },
    {
      "epoch": 7.5233644859813085,
      "grad_norm": 0.21992433071136475,
      "learning_rate": 0.0004990405799104054,
      "loss": 2.4766,
      "step": 1610
    },
    {
      "epoch": 7.570093457943925,
      "grad_norm": 0.2188297063112259,
      "learning_rate": 0.0004990242880094549,
      "loss": 2.4672,
      "step": 1620
    },
    {
      "epoch": 7.616822429906542,
      "grad_norm": 0.23063208162784576,
      "learning_rate": 0.0004990078592147907,
      "loss": 2.453,
      "step": 1630
    },
    {
      "epoch": 7.663551401869158,
      "grad_norm": 0.22762326896190643,
      "learning_rate": 0.000498991293535444,
      "loss": 2.4538,
      "step": 1640
    },
    {
      "epoch": 7.710280373831775,
      "grad_norm": 0.2271927446126938,
      "learning_rate": 0.0004989745909805213,
      "loss": 2.4643,
      "step": 1650
    },
    {
      "epoch": 7.757009345794392,
      "grad_norm": 0.23467856645584106,
      "learning_rate": 0.0004989577515592044,
      "loss": 2.4803,
      "step": 1660
    },
    {
      "epoch": 7.803738317757009,
      "grad_norm": 0.2002689093351364,
      "learning_rate": 0.0004989407752807502,
      "loss": 2.4523,
      "step": 1670
    },
    {
      "epoch": 7.850467289719626,
      "grad_norm": 0.22377482056617737,
      "learning_rate": 0.0004989236621544909,
      "loss": 2.468,
      "step": 1680
    },
    {
      "epoch": 7.897196261682243,
      "grad_norm": 0.20638617873191833,
      "learning_rate": 0.0004989064121898342,
      "loss": 2.4573,
      "step": 1690
    },
    {
      "epoch": 7.94392523364486,
      "grad_norm": 0.2047625184059143,
      "learning_rate": 0.0004988890253962623,
      "loss": 2.4415,
      "step": 1700
    },
    {
      "epoch": 7.990654205607477,
      "grad_norm": 0.22981038689613342,
      "learning_rate": 0.0004988715017833334,
      "loss": 2.4498,
      "step": 1710
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.208255410194397,
      "eval_runtime": 5.5041,
      "eval_samples_per_second": 3526.834,
      "eval_steps_per_second": 13.808,
      "step": 1712
    },
    {
      "epoch": 8.037383177570094,
      "grad_norm": 0.24078862369060516,
      "learning_rate": 0.0004988538413606805,
      "loss": 2.4419,
      "step": 1720
    },
    {
      "epoch": 8.08411214953271,
      "grad_norm": 0.22768080234527588,
      "learning_rate": 0.0004988360441380118,
      "loss": 2.4523,
      "step": 1730
    },
    {
      "epoch": 8.130841121495328,
      "grad_norm": 0.2248253971338272,
      "learning_rate": 0.000498818110125111,
      "loss": 2.4499,
      "step": 1740
    },
    {
      "epoch": 8.177570093457945,
      "grad_norm": 0.2092253565788269,
      "learning_rate": 0.0004988000393318367,
      "loss": 2.4344,
      "step": 1750
    },
    {
      "epoch": 8.22429906542056,
      "grad_norm": 0.23518823087215424,
      "learning_rate": 0.0004987818317681226,
      "loss": 2.4265,
      "step": 1760
    },
    {
      "epoch": 8.271028037383177,
      "grad_norm": 0.23162053525447845,
      "learning_rate": 0.0004987634874439781,
      "loss": 2.4465,
      "step": 1770
    },
    {
      "epoch": 8.317757009345794,
      "grad_norm": 0.24348217248916626,
      "learning_rate": 0.0004987450063694872,
      "loss": 2.4449,
      "step": 1780
    },
    {
      "epoch": 8.36448598130841,
      "grad_norm": 0.3816847503185272,
      "learning_rate": 0.0004987263885548093,
      "loss": 2.4451,
      "step": 1790
    },
    {
      "epoch": 8.411214953271028,
      "grad_norm": 0.7256289720535278,
      "learning_rate": 0.0004987076340101792,
      "loss": 2.4414,
      "step": 1800
    },
    {
      "epoch": 8.457943925233645,
      "grad_norm": 0.23199188709259033,
      "learning_rate": 0.0004986887427459065,
      "loss": 2.4471,
      "step": 1810
    },
    {
      "epoch": 8.504672897196262,
      "grad_norm": 0.23380155861377716,
      "learning_rate": 0.0004986697147723762,
      "loss": 2.4486,
      "step": 1820
    },
    {
      "epoch": 8.551401869158878,
      "grad_norm": 0.2602226138114929,
      "learning_rate": 0.0004986505501000483,
      "loss": 2.4371,
      "step": 1830
    },
    {
      "epoch": 8.598130841121495,
      "grad_norm": 0.21672366559505463,
      "learning_rate": 0.000498631248739458,
      "loss": 2.4259,
      "step": 1840
    },
    {
      "epoch": 8.644859813084112,
      "grad_norm": 0.23465462028980255,
      "learning_rate": 0.0004986118107012156,
      "loss": 2.4355,
      "step": 1850
    },
    {
      "epoch": 8.69158878504673,
      "grad_norm": 0.2172676920890808,
      "learning_rate": 0.0004985922359960069,
      "loss": 2.4388,
      "step": 1860
    },
    {
      "epoch": 8.738317757009346,
      "grad_norm": 0.2323274314403534,
      "learning_rate": 0.000498572524634592,
      "loss": 2.4258,
      "step": 1870
    },
    {
      "epoch": 8.785046728971963,
      "grad_norm": 0.2203647792339325,
      "learning_rate": 0.0004985526766278071,
      "loss": 2.4394,
      "step": 1880
    },
    {
      "epoch": 8.83177570093458,
      "grad_norm": 0.20171132683753967,
      "learning_rate": 0.0004985326919865628,
      "loss": 2.4324,
      "step": 1890
    },
    {
      "epoch": 8.878504672897197,
      "grad_norm": 0.21951980888843536,
      "learning_rate": 0.0004985125707218451,
      "loss": 2.4277,
      "step": 1900
    },
    {
      "epoch": 8.925233644859812,
      "grad_norm": 0.21343180537223816,
      "learning_rate": 0.0004984923128447151,
      "loss": 2.4338,
      "step": 1910
    },
    {
      "epoch": 8.97196261682243,
      "grad_norm": 0.23567445576190948,
      "learning_rate": 0.000498471918366309,
      "loss": 2.4147,
      "step": 1920
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.1990795135498047,
      "eval_runtime": 5.5007,
      "eval_samples_per_second": 3529.006,
      "eval_steps_per_second": 13.816,
      "step": 1926
    },
    {
      "epoch": 9.018691588785046,
      "grad_norm": 0.22512388229370117,
      "learning_rate": 0.000498451387297838,
      "loss": 2.4254,
      "step": 1930
    },
    {
      "epoch": 9.065420560747663,
      "grad_norm": 0.21246878802776337,
      "learning_rate": 0.0004984307196505885,
      "loss": 2.4408,
      "step": 1940
    },
    {
      "epoch": 9.11214953271028,
      "grad_norm": 0.21501480042934418,
      "learning_rate": 0.0004984099154359218,
      "loss": 2.4071,
      "step": 1950
    },
    {
      "epoch": 9.158878504672897,
      "grad_norm": 0.23555923998355865,
      "learning_rate": 0.0004983889746652746,
      "loss": 2.4352,
      "step": 1960
    },
    {
      "epoch": 9.205607476635514,
      "grad_norm": 0.22832058370113373,
      "learning_rate": 0.0004983678973501583,
      "loss": 2.4289,
      "step": 1970
    },
    {
      "epoch": 9.25233644859813,
      "grad_norm": 0.21479856967926025,
      "learning_rate": 0.0004983466835021596,
      "loss": 2.4117,
      "step": 1980
    },
    {
      "epoch": 9.299065420560748,
      "grad_norm": 0.238040030002594,
      "learning_rate": 0.0004983253331329402,
      "loss": 2.433,
      "step": 1990
    },
    {
      "epoch": 9.345794392523365,
      "grad_norm": 0.23257701098918915,
      "learning_rate": 0.0004983038462542368,
      "loss": 2.4174,
      "step": 2000
    },
    {
      "epoch": 9.392523364485982,
      "grad_norm": 0.2566848695278168,
      "learning_rate": 0.0004982822228778612,
      "loss": 2.4258,
      "step": 2010
    },
    {
      "epoch": 9.439252336448599,
      "grad_norm": 0.20344842970371246,
      "learning_rate": 0.0004982604630157002,
      "loss": 2.4313,
      "step": 2020
    },
    {
      "epoch": 9.485981308411215,
      "grad_norm": 0.22267979383468628,
      "learning_rate": 0.0004982385666797155,
      "loss": 2.4122,
      "step": 2030
    },
    {
      "epoch": 9.532710280373832,
      "grad_norm": 0.22744035720825195,
      "learning_rate": 0.0004982165338819442,
      "loss": 2.4107,
      "step": 2040
    },
    {
      "epoch": 9.57943925233645,
      "grad_norm": 0.21149294078350067,
      "learning_rate": 0.000498194364634498,
      "loss": 2.4089,
      "step": 2050
    },
    {
      "epoch": 9.626168224299064,
      "grad_norm": 0.21657533943653107,
      "learning_rate": 0.0004981720589495639,
      "loss": 2.4318,
      "step": 2060
    },
    {
      "epoch": 9.672897196261681,
      "grad_norm": 0.21874509751796722,
      "learning_rate": 0.0004981496168394037,
      "loss": 2.4073,
      "step": 2070
    },
    {
      "epoch": 9.719626168224298,
      "grad_norm": 0.2073247879743576,
      "learning_rate": 0.0004981270383163544,
      "loss": 2.4106,
      "step": 2080
    },
    {
      "epoch": 9.766355140186915,
      "grad_norm": 0.20193125307559967,
      "learning_rate": 0.0004981043233928278,
      "loss": 2.4045,
      "step": 2090
    },
    {
      "epoch": 9.813084112149532,
      "grad_norm": 0.21326741576194763,
      "learning_rate": 0.0004980814720813106,
      "loss": 2.4048,
      "step": 2100
    },
    {
      "epoch": 9.85981308411215,
      "grad_norm": 0.307872474193573,
      "learning_rate": 0.0004980584843943649,
      "loss": 2.4166,
      "step": 2110
    },
    {
      "epoch": 9.906542056074766,
      "grad_norm": 0.19088326394557953,
      "learning_rate": 0.0004980353603446274,
      "loss": 2.4092,
      "step": 2120
    },
    {
      "epoch": 9.953271028037383,
      "grad_norm": 0.2804618179798126,
      "learning_rate": 0.0004980120999448097,
      "loss": 2.4167,
      "step": 2130
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.5368602275848389,
      "learning_rate": 0.0004979887032076989,
      "loss": 2.4074,
      "step": 2140
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.1889911890029907,
      "eval_runtime": 5.5176,
      "eval_samples_per_second": 3518.211,
      "eval_steps_per_second": 13.774,
      "step": 2140
    },
    {
      "epoch": 10.046728971962617,
      "grad_norm": 0.21671973168849945,
      "learning_rate": 0.0004979651701461562,
      "loss": 2.3968,
      "step": 2150
    },
    {
      "epoch": 10.093457943925234,
      "grad_norm": 0.2101743519306183,
      "learning_rate": 0.0004979415007731185,
      "loss": 2.3996,
      "step": 2160
    },
    {
      "epoch": 10.14018691588785,
      "grad_norm": 0.2016562819480896,
      "learning_rate": 0.0004979176951015972,
      "loss": 2.3897,
      "step": 2170
    },
    {
      "epoch": 10.186915887850468,
      "grad_norm": 0.25134557485580444,
      "learning_rate": 0.0004978937531446789,
      "loss": 2.394,
      "step": 2180
    },
    {
      "epoch": 10.233644859813085,
      "grad_norm": 0.2491856962442398,
      "learning_rate": 0.0004978696749155249,
      "loss": 2.4022,
      "step": 2190
    },
    {
      "epoch": 10.280373831775702,
      "grad_norm": 0.21161775290966034,
      "learning_rate": 0.0004978454604273715,
      "loss": 2.4087,
      "step": 2200
    },
    {
      "epoch": 10.327102803738319,
      "grad_norm": 0.22179944813251495,
      "learning_rate": 0.0004978211096935298,
      "loss": 2.4127,
      "step": 2210
    },
    {
      "epoch": 10.373831775700934,
      "grad_norm": 0.2513800859451294,
      "learning_rate": 0.000497796622727386,
      "loss": 2.398,
      "step": 2220
    },
    {
      "epoch": 10.42056074766355,
      "grad_norm": 0.19472119212150574,
      "learning_rate": 0.0004977719995424011,
      "loss": 2.3936,
      "step": 2230
    },
    {
      "epoch": 10.467289719626168,
      "grad_norm": 0.2517758011817932,
      "learning_rate": 0.000497747240152111,
      "loss": 2.4028,
      "step": 2240
    },
    {
      "epoch": 10.514018691588785,
      "grad_norm": 0.22601187229156494,
      "learning_rate": 0.0004977223445701263,
      "loss": 2.3945,
      "step": 2250
    },
    {
      "epoch": 10.560747663551401,
      "grad_norm": 0.24616111814975739,
      "learning_rate": 0.0004976973128101327,
      "loss": 2.3861,
      "step": 2260
    },
    {
      "epoch": 10.607476635514018,
      "grad_norm": 0.21643950045108795,
      "learning_rate": 0.0004976721448858905,
      "loss": 2.402,
      "step": 2270
    },
    {
      "epoch": 10.654205607476635,
      "grad_norm": 0.2004477083683014,
      "learning_rate": 0.0004976468408112353,
      "loss": 2.3968,
      "step": 2280
    },
    {
      "epoch": 10.700934579439252,
      "grad_norm": 0.21101629734039307,
      "learning_rate": 0.000497621400600077,
      "loss": 2.3977,
      "step": 2290
    },
    {
      "epoch": 10.74766355140187,
      "grad_norm": 0.236237570643425,
      "learning_rate": 0.0004975958242664009,
      "loss": 2.4097,
      "step": 2300
    },
    {
      "epoch": 10.794392523364486,
      "grad_norm": 0.2281179279088974,
      "learning_rate": 0.0004975701118242667,
      "loss": 2.4048,
      "step": 2310
    },
    {
      "epoch": 10.841121495327103,
      "grad_norm": 0.19782131910324097,
      "learning_rate": 0.0004975442632878089,
      "loss": 2.3953,
      "step": 2320
    },
    {
      "epoch": 10.88785046728972,
      "grad_norm": 0.20178551971912384,
      "learning_rate": 0.000497518278671237,
      "loss": 2.39,
      "step": 2330
    },
    {
      "epoch": 10.934579439252337,
      "grad_norm": 0.2240155190229416,
      "learning_rate": 0.0004974921579888354,
      "loss": 2.3978,
      "step": 2340
    },
    {
      "epoch": 10.981308411214954,
      "grad_norm": 0.2369598150253296,
      "learning_rate": 0.0004974659012549632,
      "loss": 2.3815,
      "step": 2350
    },
    {
      "epoch": 11.0,
      "eval_loss": 1.1822363138198853,
      "eval_runtime": 5.5251,
      "eval_samples_per_second": 3513.428,
      "eval_steps_per_second": 13.755,
      "step": 2354
    },
    {
      "epoch": 11.02803738317757,
      "grad_norm": 0.207997664809227,
      "learning_rate": 0.0004974395084840541,
      "loss": 2.3918,
      "step": 2360
    },
    {
      "epoch": 11.074766355140186,
      "grad_norm": 0.27343466877937317,
      "learning_rate": 0.0004974129796906169,
      "loss": 2.3841,
      "step": 2370
    },
    {
      "epoch": 11.121495327102803,
      "grad_norm": 0.24878919124603271,
      "learning_rate": 0.000497386314889235,
      "loss": 2.3772,
      "step": 2380
    },
    {
      "epoch": 11.16822429906542,
      "grad_norm": 0.2166314274072647,
      "learning_rate": 0.0004973595140945663,
      "loss": 2.3631,
      "step": 2390
    },
    {
      "epoch": 11.214953271028037,
      "grad_norm": 0.2371222972869873,
      "learning_rate": 0.0004973325773213441,
      "loss": 2.3866,
      "step": 2400
    },
    {
      "epoch": 11.261682242990654,
      "grad_norm": 0.22849200665950775,
      "learning_rate": 0.000497305504584376,
      "loss": 2.385,
      "step": 2410
    },
    {
      "epoch": 11.30841121495327,
      "grad_norm": 0.2249206006526947,
      "learning_rate": 0.0004972782958985443,
      "loss": 2.3936,
      "step": 2420
    },
    {
      "epoch": 11.355140186915888,
      "grad_norm": 0.22873689234256744,
      "learning_rate": 0.0004972509512788062,
      "loss": 2.3812,
      "step": 2430
    },
    {
      "epoch": 11.401869158878505,
      "grad_norm": 0.24513083696365356,
      "learning_rate": 0.0004972234707401938,
      "loss": 2.3903,
      "step": 2440
    },
    {
      "epoch": 11.448598130841122,
      "grad_norm": 0.21578291058540344,
      "learning_rate": 0.0004971958542978135,
      "loss": 2.396,
      "step": 2450
    },
    {
      "epoch": 11.495327102803738,
      "grad_norm": 0.49007266759872437,
      "learning_rate": 0.0004971681019668467,
      "loss": 2.3907,
      "step": 2460
    },
    {
      "epoch": 11.542056074766355,
      "grad_norm": 0.22829023003578186,
      "learning_rate": 0.0004971402137625494,
      "loss": 2.3835,
      "step": 2470
    },
    {
      "epoch": 11.588785046728972,
      "grad_norm": 0.2443944662809372,
      "learning_rate": 0.0004971121897002523,
      "loss": 2.3936,
      "step": 2480
    },
    {
      "epoch": 11.63551401869159,
      "grad_norm": 0.3769768476486206,
      "learning_rate": 0.0004970840297953608,
      "loss": 2.3898,
      "step": 2490
    },
    {
      "epoch": 11.682242990654206,
      "grad_norm": 0.24231143295764923,
      "learning_rate": 0.000497055734063355,
      "loss": 2.3851,
      "step": 2500
    },
    {
      "epoch": 11.728971962616823,
      "grad_norm": 0.22333836555480957,
      "learning_rate": 0.0004970273025197896,
      "loss": 2.3913,
      "step": 2510
    },
    {
      "epoch": 11.77570093457944,
      "grad_norm": 0.21648040413856506,
      "learning_rate": 0.000496998735180294,
      "loss": 2.3733,
      "step": 2520
    },
    {
      "epoch": 11.822429906542055,
      "grad_norm": 0.28950950503349304,
      "learning_rate": 0.0004969700320605723,
      "loss": 2.3829,
      "step": 2530
    },
    {
      "epoch": 11.869158878504672,
      "grad_norm": 0.2795458436012268,
      "learning_rate": 0.0004969411931764032,
      "loss": 2.3842,
      "step": 2540
    },
    {
      "epoch": 11.91588785046729,
      "grad_norm": 0.21055062115192413,
      "learning_rate": 0.00049691221854364,
      "loss": 2.3674,
      "step": 2550
    },
    {
      "epoch": 11.962616822429906,
      "grad_norm": 0.3937389552593231,
      "learning_rate": 0.0004968831081782106,
      "loss": 2.38,
      "step": 2560
    },
    {
      "epoch": 12.0,
      "eval_loss": 1.176760196685791,
      "eval_runtime": 5.4936,
      "eval_samples_per_second": 3533.559,
      "eval_steps_per_second": 13.834,
      "step": 2568
    },
    {
      "epoch": 12.009345794392523,
      "grad_norm": 0.2345358282327652,
      "learning_rate": 0.0004968538620961175,
      "loss": 2.3762,
      "step": 2570
    },
    {
      "epoch": 12.05607476635514,
      "grad_norm": 0.23014488816261292,
      "learning_rate": 0.000496824480313438,
      "loss": 2.3773,
      "step": 2580
    },
    {
      "epoch": 12.102803738317757,
      "grad_norm": 0.2462136298418045,
      "learning_rate": 0.0004967949628463239,
      "loss": 2.3549,
      "step": 2590
    },
    {
      "epoch": 12.149532710280374,
      "grad_norm": 0.21238631010055542,
      "learning_rate": 0.0004967653097110013,
      "loss": 2.364,
      "step": 2600
    },
    {
      "epoch": 12.19626168224299,
      "grad_norm": 0.2622698247432709,
      "learning_rate": 0.0004967355209237713,
      "loss": 2.3732,
      "step": 2610
    },
    {
      "epoch": 12.242990654205608,
      "grad_norm": 0.2370268702507019,
      "learning_rate": 0.0004967055965010096,
      "loss": 2.3779,
      "step": 2620
    },
    {
      "epoch": 12.289719626168225,
      "grad_norm": 0.21956709027290344,
      "learning_rate": 0.000496675536459166,
      "loss": 2.3534,
      "step": 2630
    },
    {
      "epoch": 12.336448598130842,
      "grad_norm": 0.22452287375926971,
      "learning_rate": 0.000496645340814765,
      "loss": 2.3716,
      "step": 2640
    },
    {
      "epoch": 12.383177570093459,
      "grad_norm": 0.22636185586452484,
      "learning_rate": 0.0004966150095844061,
      "loss": 2.3696,
      "step": 2650
    },
    {
      "epoch": 12.429906542056075,
      "grad_norm": 0.28398552536964417,
      "learning_rate": 0.0004965845427847628,
      "loss": 2.366,
      "step": 2660
    },
    {
      "epoch": 12.476635514018692,
      "grad_norm": 0.2418077439069748,
      "learning_rate": 0.0004965539404325833,
      "loss": 2.3829,
      "step": 2670
    },
    {
      "epoch": 12.523364485981308,
      "grad_norm": 0.24718277156352997,
      "learning_rate": 0.0004965232025446903,
      "loss": 2.3752,
      "step": 2680
    },
    {
      "epoch": 12.570093457943925,
      "grad_norm": 0.3157610297203064,
      "learning_rate": 0.0004964923291379813,
      "loss": 2.3797,
      "step": 2690
    },
    {
      "epoch": 12.616822429906541,
      "grad_norm": 0.24411028623580933,
      "learning_rate": 0.0004964613202294278,
      "loss": 2.3698,
      "step": 2700
    },
    {
      "epoch": 12.663551401869158,
      "grad_norm": 0.22311300039291382,
      "learning_rate": 0.0004964301758360761,
      "loss": 2.3613,
      "step": 2710
    },
    {
      "epoch": 12.710280373831775,
      "grad_norm": 0.26223886013031006,
      "learning_rate": 0.0004963988959750469,
      "loss": 2.3794,
      "step": 2720
    },
    {
      "epoch": 12.757009345794392,
      "grad_norm": 0.2398604303598404,
      "learning_rate": 0.0004963674806635353,
      "loss": 2.3842,
      "step": 2730
    },
    {
      "epoch": 12.80373831775701,
      "grad_norm": 0.20653018355369568,
      "learning_rate": 0.0004963359299188111,
      "loss": 2.3828,
      "step": 2740
    },
    {
      "epoch": 12.850467289719626,
      "grad_norm": 0.2278430312871933,
      "learning_rate": 0.0004963042437582183,
      "loss": 2.3723,
      "step": 2750
    },
    {
      "epoch": 12.897196261682243,
      "grad_norm": 0.20427067577838898,
      "learning_rate": 0.0004962724221991753,
      "loss": 2.3687,
      "step": 2760
    },
    {
      "epoch": 12.94392523364486,
      "grad_norm": 0.22941865026950836,
      "learning_rate": 0.0004962404652591754,
      "loss": 2.3789,
      "step": 2770
    },
    {
      "epoch": 12.990654205607477,
      "grad_norm": 0.22020365297794342,
      "learning_rate": 0.0004962083729557855,
      "loss": 2.3788,
      "step": 2780
    },
    {
      "epoch": 13.0,
      "eval_loss": 1.171857237815857,
      "eval_runtime": 5.4728,
      "eval_samples_per_second": 3546.973,
      "eval_steps_per_second": 13.887,
      "step": 2782
    },
    {
      "epoch": 13.037383177570094,
      "grad_norm": 0.2393530309200287,
      "learning_rate": 0.0004961761453066479,
      "loss": 2.3609,
      "step": 2790
    },
    {
      "epoch": 13.08411214953271,
      "grad_norm": 0.2530321180820465,
      "learning_rate": 0.0004961437823294784,
      "loss": 2.3687,
      "step": 2800
    },
    {
      "epoch": 13.130841121495328,
      "grad_norm": 0.2245333194732666,
      "learning_rate": 0.0004961112840420678,
      "loss": 2.3606,
      "step": 2810
    },
    {
      "epoch": 13.177570093457945,
      "grad_norm": 0.22254584729671478,
      "learning_rate": 0.000496078650462281,
      "loss": 2.3437,
      "step": 2820
    },
    {
      "epoch": 13.22429906542056,
      "grad_norm": 0.257712721824646,
      "learning_rate": 0.0004960458816080571,
      "loss": 2.3718,
      "step": 2830
    },
    {
      "epoch": 13.271028037383177,
      "grad_norm": 0.22127753496170044,
      "learning_rate": 0.0004960129774974104,
      "loss": 2.3475,
      "step": 2840
    },
    {
      "epoch": 13.317757009345794,
      "grad_norm": 0.23650188744068146,
      "learning_rate": 0.0004959799381484284,
      "loss": 2.3626,
      "step": 2850
    },
    {
      "epoch": 13.36448598130841,
      "grad_norm": 0.27005624771118164,
      "learning_rate": 0.0004959467635792739,
      "loss": 2.368,
      "step": 2860
    },
    {
      "epoch": 13.411214953271028,
      "grad_norm": 0.2465919852256775,
      "learning_rate": 0.0004959134538081832,
      "loss": 2.3627,
      "step": 2870
    },
    {
      "epoch": 13.457943925233645,
      "grad_norm": 0.21302001178264618,
      "learning_rate": 0.0004958800088534677,
      "loss": 2.3611,
      "step": 2880
    },
    {
      "epoch": 13.504672897196262,
      "grad_norm": 0.2214624434709549,
      "learning_rate": 0.0004958464287335128,
      "loss": 2.3548,
      "step": 2890
    },
    {
      "epoch": 13.551401869158878,
      "grad_norm": 0.22916513681411743,
      "learning_rate": 0.0004958127134667778,
      "loss": 2.3592,
      "step": 2900
    },
    {
      "epoch": 13.598130841121495,
      "grad_norm": 0.22517333924770355,
      "learning_rate": 0.0004957788630717971,
      "loss": 2.3735,
      "step": 2910
    },
    {
      "epoch": 13.644859813084112,
      "grad_norm": 0.22795844078063965,
      "learning_rate": 0.0004957448775671788,
      "loss": 2.381,
      "step": 2920
    },
    {
      "epoch": 13.69158878504673,
      "grad_norm": 0.2282734513282776,
      "learning_rate": 0.0004957107569716053,
      "loss": 2.3657,
      "step": 2930
    },
    {
      "epoch": 13.738317757009346,
      "grad_norm": 0.21207047998905182,
      "learning_rate": 0.0004956765013038334,
      "loss": 2.3694,
      "step": 2940
    },
    {
      "epoch": 13.785046728971963,
      "grad_norm": 0.22846311330795288,
      "learning_rate": 0.0004956421105826944,
      "loss": 2.3652,
      "step": 2950
    },
    {
      "epoch": 13.83177570093458,
      "grad_norm": 0.28713706135749817,
      "learning_rate": 0.0004956075848270932,
      "loss": 2.3438,
      "step": 2960
    },
    {
      "epoch": 13.878504672897197,
      "grad_norm": 0.2352837324142456,
      "learning_rate": 0.0004955729240560097,
      "loss": 2.3679,
      "step": 2970
    },
    {
      "epoch": 13.925233644859812,
      "grad_norm": 0.21526014804840088,
      "learning_rate": 0.0004955381282884972,
      "loss": 2.3426,
      "step": 2980
    },
    {
      "epoch": 13.97196261682243,
      "grad_norm": 0.22265301644802094,
      "learning_rate": 0.000495503197543684,
      "loss": 2.3551,
      "step": 2990
    },
    {
      "epoch": 14.0,
      "eval_loss": 1.1673566102981567,
      "eval_runtime": 5.4962,
      "eval_samples_per_second": 3531.867,
      "eval_steps_per_second": 13.828,
      "step": 2996
    },
    {
      "epoch": 14.018691588785046,
      "grad_norm": 0.21720275282859802,
      "learning_rate": 0.0004954681318407721,
      "loss": 2.3491,
      "step": 3000
    },
    {
      "epoch": 14.065420560747663,
      "grad_norm": 0.24110646545886993,
      "learning_rate": 0.0004954329311990379,
      "loss": 2.3527,
      "step": 3010
    },
    {
      "epoch": 14.11214953271028,
      "grad_norm": 0.23954607546329498,
      "learning_rate": 0.0004953975956378317,
      "loss": 2.3678,
      "step": 3020
    },
    {
      "epoch": 14.158878504672897,
      "grad_norm": 0.22825703024864197,
      "learning_rate": 0.0004953621251765784,
      "loss": 2.3623,
      "step": 3030
    },
    {
      "epoch": 14.205607476635514,
      "grad_norm": 0.27561163902282715,
      "learning_rate": 0.0004953265198347768,
      "loss": 2.3416,
      "step": 3040
    },
    {
      "epoch": 14.25233644859813,
      "grad_norm": 0.24777752161026,
      "learning_rate": 0.0004952907796319999,
      "loss": 2.3619,
      "step": 3050
    },
    {
      "epoch": 14.299065420560748,
      "grad_norm": 0.2914876639842987,
      "learning_rate": 0.0004952549045878946,
      "loss": 2.3535,
      "step": 3060
    },
    {
      "epoch": 14.345794392523365,
      "grad_norm": 0.24390922486782074,
      "learning_rate": 0.0004952188947221824,
      "loss": 2.352,
      "step": 3070
    },
    {
      "epoch": 14.392523364485982,
      "grad_norm": 0.2152176946401596,
      "learning_rate": 0.0004951827500546585,
      "loss": 2.3525,
      "step": 3080
    },
    {
      "epoch": 14.439252336448599,
      "grad_norm": 0.2776676416397095,
      "learning_rate": 0.0004951464706051924,
      "loss": 2.3473,
      "step": 3090
    },
    {
      "epoch": 14.485981308411215,
      "grad_norm": 0.31299158930778503,
      "learning_rate": 0.0004951100563937278,
      "loss": 2.3573,
      "step": 3100
    },
    {
      "epoch": 14.532710280373832,
      "grad_norm": 0.25162410736083984,
      "learning_rate": 0.000495073507440282,
      "loss": 2.3401,
      "step": 3110
    },
    {
      "epoch": 14.57943925233645,
      "grad_norm": 0.2230226695537567,
      "learning_rate": 0.000495036823764947,
      "loss": 2.3621,
      "step": 3120
    },
    {
      "epoch": 14.626168224299064,
      "grad_norm": 0.3334400951862335,
      "learning_rate": 0.0004950000053878884,
      "loss": 2.3383,
      "step": 3130
    },
    {
      "epoch": 14.672897196261681,
      "grad_norm": 0.26016533374786377,
      "learning_rate": 0.0004949630523293461,
      "loss": 2.3563,
      "step": 3140
    },
    {
      "epoch": 14.719626168224298,
      "grad_norm": 0.23268543183803558,
      "learning_rate": 0.0004949259646096339,
      "loss": 2.3528,
      "step": 3150
    },
    {
      "epoch": 14.766355140186915,
      "grad_norm": 0.22981557250022888,
      "learning_rate": 0.0004948887422491397,
      "loss": 2.3525,
      "step": 3160
    },
    {
      "epoch": 14.813084112149532,
      "grad_norm": 0.23152756690979004,
      "learning_rate": 0.0004948513852683255,
      "loss": 2.3453,
      "step": 3170
    },
    {
      "epoch": 14.85981308411215,
      "grad_norm": 0.2181462198495865,
      "learning_rate": 0.000494813893687727,
      "loss": 2.3587,
      "step": 3180
    },
    {
      "epoch": 14.906542056074766,
      "grad_norm": 0.2545097768306732,
      "learning_rate": 0.000494776267527954,
      "loss": 2.3677,
      "step": 3190
    },
    {
      "epoch": 14.953271028037383,
      "grad_norm": 0.2719486951828003,
      "learning_rate": 0.0004947385068096907,
      "loss": 2.346,
      "step": 3200
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.32521766424179077,
      "learning_rate": 0.0004947006115536948,
      "loss": 2.3377,
      "step": 3210
    },
    {
      "epoch": 15.0,
      "eval_loss": 1.1665972471237183,
      "eval_runtime": 5.5067,
      "eval_samples_per_second": 3525.136,
      "eval_steps_per_second": 13.801,
      "step": 3210
    },
    {
      "epoch": 15.046728971962617,
      "grad_norm": 0.24553464353084564,
      "learning_rate": 0.0004946625817807978,
      "loss": 2.3478,
      "step": 3220
    },
    {
      "epoch": 15.093457943925234,
      "grad_norm": 0.239844411611557,
      "learning_rate": 0.0004946244175119058,
      "loss": 2.3393,
      "step": 3230
    },
    {
      "epoch": 15.14018691588785,
      "grad_norm": 0.2570011019706726,
      "learning_rate": 0.0004945861187679985,
      "loss": 2.3373,
      "step": 3240
    },
    {
      "epoch": 15.186915887850468,
      "grad_norm": 0.3715876042842865,
      "learning_rate": 0.0004945476855701292,
      "loss": 2.3429,
      "step": 3250
    },
    {
      "epoch": 15.233644859813085,
      "grad_norm": 0.21324607729911804,
      "learning_rate": 0.0004945091179394256,
      "loss": 2.3368,
      "step": 3260
    },
    {
      "epoch": 15.280373831775702,
      "grad_norm": 0.24027003347873688,
      "learning_rate": 0.0004944704158970891,
      "loss": 2.3607,
      "step": 3270
    },
    {
      "epoch": 15.327102803738319,
      "grad_norm": 0.24695546925067902,
      "learning_rate": 0.000494431579464395,
      "loss": 2.3496,
      "step": 3280
    },
    {
      "epoch": 15.373831775700934,
      "grad_norm": 0.2667216658592224,
      "learning_rate": 0.0004943926086626924,
      "loss": 2.3431,
      "step": 3290
    },
    {
      "epoch": 15.42056074766355,
      "grad_norm": 0.23954088985919952,
      "learning_rate": 0.0004943535035134044,
      "loss": 2.362,
      "step": 3300
    },
    {
      "epoch": 15.467289719626168,
      "grad_norm": 0.5346038937568665,
      "learning_rate": 0.0004943142640380279,
      "loss": 2.3363,
      "step": 3310
    },
    {
      "epoch": 15.514018691588785,
      "grad_norm": 0.23483526706695557,
      "learning_rate": 0.0004942748902581337,
      "loss": 2.3296,
      "step": 3320
    },
    {
      "epoch": 15.560747663551401,
      "grad_norm": 0.2448139786720276,
      "learning_rate": 0.0004942353821953663,
      "loss": 2.3384,
      "step": 3330
    },
    {
      "epoch": 15.607476635514018,
      "grad_norm": 0.2625763416290283,
      "learning_rate": 0.000494195739871444,
      "loss": 2.3583,
      "step": 3340
    },
    {
      "epoch": 15.654205607476635,
      "grad_norm": 0.2313903570175171,
      "learning_rate": 0.0004941559633081591,
      "loss": 2.3504,
      "step": 3350
    },
    {
      "epoch": 15.700934579439252,
      "grad_norm": 0.25663670897483826,
      "learning_rate": 0.0004941160525273775,
      "loss": 2.3444,
      "step": 3360
    },
    {
      "epoch": 15.74766355140187,
      "grad_norm": 0.22622033953666687,
      "learning_rate": 0.0004940760075510391,
      "loss": 2.3343,
      "step": 3370
    },
    {
      "epoch": 15.794392523364486,
      "grad_norm": 0.233212411403656,
      "learning_rate": 0.0004940358284011573,
      "loss": 2.3583,
      "step": 3380
    },
    {
      "epoch": 15.841121495327103,
      "grad_norm": 0.22583962976932526,
      "learning_rate": 0.0004939955150998196,
      "loss": 2.3411,
      "step": 3390
    },
    {
      "epoch": 15.88785046728972,
      "grad_norm": 0.23746001720428467,
      "learning_rate": 0.0004939550676691868,
      "loss": 2.3379,
      "step": 3400
    },
    {
      "epoch": 15.934579439252337,
      "grad_norm": 0.25225600600242615,
      "learning_rate": 0.0004939144861314937,
      "loss": 2.3508,
      "step": 3410
    },
    {
      "epoch": 15.981308411214954,
      "grad_norm": 0.27999627590179443,
      "learning_rate": 0.0004938737705090491,
      "loss": 2.3428,
      "step": 3420
    },
    {
      "epoch": 16.0,
      "eval_loss": 1.162082552909851,
      "eval_runtime": 5.4409,
      "eval_samples_per_second": 3567.809,
      "eval_steps_per_second": 13.968,
      "step": 3424
    },
    {
      "epoch": 16.02803738317757,
      "grad_norm": 0.2572297155857086,
      "learning_rate": 0.0004938329208242347,
      "loss": 2.3344,
      "step": 3430
    },
    {
      "epoch": 16.074766355140188,
      "grad_norm": 0.24141067266464233,
      "learning_rate": 0.0004937919370995069,
      "loss": 2.3512,
      "step": 3440
    },
    {
      "epoch": 16.121495327102803,
      "grad_norm": 0.2183905839920044,
      "learning_rate": 0.0004937508193573949,
      "loss": 2.338,
      "step": 3450
    },
    {
      "epoch": 16.16822429906542,
      "grad_norm": 0.2285512238740921,
      "learning_rate": 0.0004937095676205023,
      "loss": 2.3335,
      "step": 3460
    },
    {
      "epoch": 16.214953271028037,
      "grad_norm": 0.2435920685529709,
      "learning_rate": 0.0004936681819115058,
      "loss": 2.3114,
      "step": 3470
    },
    {
      "epoch": 16.261682242990656,
      "grad_norm": 0.25719186663627625,
      "learning_rate": 0.0004936266622531559,
      "loss": 2.3262,
      "step": 3480
    },
    {
      "epoch": 16.30841121495327,
      "grad_norm": 0.26923730969429016,
      "learning_rate": 0.000493585008668277,
      "loss": 2.329,
      "step": 3490
    },
    {
      "epoch": 16.35514018691589,
      "grad_norm": 0.2608914375305176,
      "learning_rate": 0.0004935432211797668,
      "loss": 2.3453,
      "step": 3500
    },
    {
      "epoch": 16.401869158878505,
      "grad_norm": 0.22254915535449982,
      "learning_rate": 0.0004935012998105967,
      "loss": 2.3469,
      "step": 3510
    },
    {
      "epoch": 16.44859813084112,
      "grad_norm": 0.2385406494140625,
      "learning_rate": 0.0004934592445838119,
      "loss": 2.3475,
      "step": 3520
    },
    {
      "epoch": 16.49532710280374,
      "grad_norm": 0.22378304600715637,
      "learning_rate": 0.0004934170555225309,
      "loss": 2.3361,
      "step": 3530
    },
    {
      "epoch": 16.542056074766354,
      "grad_norm": 0.2711157500743866,
      "learning_rate": 0.0004933747326499459,
      "loss": 2.3368,
      "step": 3540
    },
    {
      "epoch": 16.588785046728972,
      "grad_norm": 0.24053843319416046,
      "learning_rate": 0.0004933322759893225,
      "loss": 2.3428,
      "step": 3550
    },
    {
      "epoch": 16.635514018691588,
      "grad_norm": 0.23073358833789825,
      "learning_rate": 0.0004932896855640003,
      "loss": 2.3487,
      "step": 3560
    },
    {
      "epoch": 16.682242990654206,
      "grad_norm": 0.25362107157707214,
      "learning_rate": 0.0004932469613973918,
      "loss": 2.3291,
      "step": 3570
    },
    {
      "epoch": 16.72897196261682,
      "grad_norm": 0.23722298443317413,
      "learning_rate": 0.0004932041035129836,
      "loss": 2.3403,
      "step": 3580
    },
    {
      "epoch": 16.77570093457944,
      "grad_norm": 0.3134593069553375,
      "learning_rate": 0.0004931611119343355,
      "loss": 2.3388,
      "step": 3590
    },
    {
      "epoch": 16.822429906542055,
      "grad_norm": 0.24031051993370056,
      "learning_rate": 0.0004931179866850806,
      "loss": 2.343,
      "step": 3600
    },
    {
      "epoch": 16.869158878504674,
      "grad_norm": 0.23450128734111786,
      "learning_rate": 0.0004930747277889259,
      "loss": 2.3376,
      "step": 3610
    },
    {
      "epoch": 16.91588785046729,
      "grad_norm": 0.24835532903671265,
      "learning_rate": 0.0004930313352696519,
      "loss": 2.3241,
      "step": 3620
    },
    {
      "epoch": 16.962616822429908,
      "grad_norm": 0.2348850667476654,
      "learning_rate": 0.0004929878091511121,
      "loss": 2.3361,
      "step": 3630
    },
    {
      "epoch": 17.0,
      "eval_loss": 1.1597243547439575,
      "eval_runtime": 5.4164,
      "eval_samples_per_second": 3583.91,
      "eval_steps_per_second": 14.031,
      "step": 3638
    },
    {
      "epoch": 17.009345794392523,
      "grad_norm": 0.24651923775672913,
      "learning_rate": 0.0004929441494572336,
      "loss": 2.3312,
      "step": 3640
    },
    {
      "epoch": 17.05607476635514,
      "grad_norm": 0.23419643938541412,
      "learning_rate": 0.0004929003562120173,
      "loss": 2.3336,
      "step": 3650
    },
    {
      "epoch": 17.102803738317757,
      "grad_norm": 0.26511234045028687,
      "learning_rate": 0.0004928564294395372,
      "loss": 2.3358,
      "step": 3660
    },
    {
      "epoch": 17.149532710280372,
      "grad_norm": 0.4312407672405243,
      "learning_rate": 0.0004928123691639404,
      "loss": 2.314,
      "step": 3670
    },
    {
      "epoch": 17.19626168224299,
      "grad_norm": 0.22661729156970978,
      "learning_rate": 0.0004927681754094481,
      "loss": 2.321,
      "step": 3680
    },
    {
      "epoch": 17.242990654205606,
      "grad_norm": 0.258731484413147,
      "learning_rate": 0.0004927238482003544,
      "loss": 2.3253,
      "step": 3690
    },
    {
      "epoch": 17.289719626168225,
      "grad_norm": 0.23511677980422974,
      "learning_rate": 0.0004926793875610268,
      "loss": 2.343,
      "step": 3700
    },
    {
      "epoch": 17.33644859813084,
      "grad_norm": 0.24161265790462494,
      "learning_rate": 0.0004926347935159063,
      "loss": 2.3311,
      "step": 3710
    },
    {
      "epoch": 17.38317757009346,
      "grad_norm": 0.3012140095233917,
      "learning_rate": 0.0004925900660895071,
      "loss": 2.3327,
      "step": 3720
    },
    {
      "epoch": 17.429906542056074,
      "grad_norm": 0.2299470752477646,
      "learning_rate": 0.0004925452053064169,
      "loss": 2.3335,
      "step": 3730
    },
    {
      "epoch": 17.476635514018692,
      "grad_norm": 0.25436481833457947,
      "learning_rate": 0.0004925002111912963,
      "loss": 2.3431,
      "step": 3740
    },
    {
      "epoch": 17.523364485981308,
      "grad_norm": 0.28905484080314636,
      "learning_rate": 0.0004924550837688798,
      "loss": 2.3187,
      "step": 3750
    },
    {
      "epoch": 17.570093457943926,
      "grad_norm": 0.26710787415504456,
      "learning_rate": 0.0004924098230639747,
      "loss": 2.3294,
      "step": 3760
    },
    {
      "epoch": 17.61682242990654,
      "grad_norm": 0.2446238100528717,
      "learning_rate": 0.0004923644291014616,
      "loss": 2.3286,
      "step": 3770
    },
    {
      "epoch": 17.66355140186916,
      "grad_norm": 0.24076464772224426,
      "learning_rate": 0.0004923189019062948,
      "loss": 2.3315,
      "step": 3780
    },
    {
      "epoch": 17.710280373831775,
      "grad_norm": 0.2669808566570282,
      "learning_rate": 0.0004922732415035013,
      "loss": 2.3444,
      "step": 3790
    },
    {
      "epoch": 17.757009345794394,
      "grad_norm": 0.24281707406044006,
      "learning_rate": 0.0004922274479181816,
      "loss": 2.3223,
      "step": 3800
    },
    {
      "epoch": 17.80373831775701,
      "grad_norm": 0.2660326361656189,
      "learning_rate": 0.0004921815211755095,
      "loss": 2.3278,
      "step": 3810
    },
    {
      "epoch": 17.850467289719624,
      "grad_norm": 0.29833778738975525,
      "learning_rate": 0.0004921354613007317,
      "loss": 2.3165,
      "step": 3820
    },
    {
      "epoch": 17.897196261682243,
      "grad_norm": 0.2835446000099182,
      "learning_rate": 0.0004920892683191681,
      "loss": 2.3194,
      "step": 3830
    },
    {
      "epoch": 17.94392523364486,
      "grad_norm": 0.26517024636268616,
      "learning_rate": 0.0004920429422562122,
      "loss": 2.3305,
      "step": 3840
    },
    {
      "epoch": 17.990654205607477,
      "grad_norm": 0.24550582468509674,
      "learning_rate": 0.0004919964831373304,
      "loss": 2.335,
      "step": 3850
    },
    {
      "epoch": 18.0,
      "eval_loss": 1.1570277214050293,
      "eval_runtime": 5.4349,
      "eval_samples_per_second": 3571.722,
      "eval_steps_per_second": 13.984,
      "step": 3852
    },
    {
      "epoch": 18.037383177570092,
      "grad_norm": 0.23586507141590118,
      "learning_rate": 0.0004919498909880621,
      "loss": 2.3201,
      "step": 3860
    },
    {
      "epoch": 18.08411214953271,
      "grad_norm": 0.2692047953605652,
      "learning_rate": 0.0004919031658340198,
      "loss": 2.3197,
      "step": 3870
    },
    {
      "epoch": 18.130841121495326,
      "grad_norm": 0.26166409254074097,
      "learning_rate": 0.0004918563077008895,
      "loss": 2.3324,
      "step": 3880
    },
    {
      "epoch": 18.177570093457945,
      "grad_norm": 0.24239975214004517,
      "learning_rate": 0.00049180931661443,
      "loss": 2.322,
      "step": 3890
    },
    {
      "epoch": 18.22429906542056,
      "grad_norm": 0.24218124151229858,
      "learning_rate": 0.0004917621926004734,
      "loss": 2.3319,
      "step": 3900
    },
    {
      "epoch": 18.27102803738318,
      "grad_norm": 0.24780899286270142,
      "learning_rate": 0.0004917149356849244,
      "loss": 2.3173,
      "step": 3910
    },
    {
      "epoch": 18.317757009345794,
      "grad_norm": 0.2631339430809021,
      "learning_rate": 0.0004916675458937614,
      "loss": 2.3189,
      "step": 3920
    },
    {
      "epoch": 18.364485981308412,
      "grad_norm": 0.26076740026474,
      "learning_rate": 0.0004916200232530353,
      "loss": 2.321,
      "step": 3930
    },
    {
      "epoch": 18.411214953271028,
      "grad_norm": 0.5216046571731567,
      "learning_rate": 0.0004915723677888703,
      "loss": 2.3262,
      "step": 3940
    },
    {
      "epoch": 18.457943925233646,
      "grad_norm": 0.278453528881073,
      "learning_rate": 0.0004915245795274638,
      "loss": 2.3145,
      "step": 3950
    },
    {
      "epoch": 18.50467289719626,
      "grad_norm": 0.27652743458747864,
      "learning_rate": 0.0004914766584950857,
      "loss": 2.3223,
      "step": 3960
    },
    {
      "epoch": 18.55140186915888,
      "grad_norm": 0.6240624785423279,
      "learning_rate": 0.0004914286047180793,
      "loss": 2.3283,
      "step": 3970
    },
    {
      "epoch": 18.598130841121495,
      "grad_norm": 0.255123496055603,
      "learning_rate": 0.0004913804182228609,
      "loss": 2.3137,
      "step": 3980
    },
    {
      "epoch": 18.64485981308411,
      "grad_norm": 0.2935715913772583,
      "learning_rate": 0.0004913320990359193,
      "loss": 2.3396,
      "step": 3990
    },
    {
      "epoch": 18.69158878504673,
      "grad_norm": 0.24625061452388763,
      "learning_rate": 0.0004912836471838165,
      "loss": 2.324,
      "step": 4000
    },
    {
      "epoch": 18.738317757009344,
      "grad_norm": 0.3073173761367798,
      "learning_rate": 0.0004912350626931879,
      "loss": 2.3245,
      "step": 4010
    },
    {
      "epoch": 18.785046728971963,
      "grad_norm": 0.30796268582344055,
      "learning_rate": 0.0004911863455907409,
      "loss": 2.3224,
      "step": 4020
    },
    {
      "epoch": 18.83177570093458,
      "grad_norm": 0.2743653655052185,
      "learning_rate": 0.0004911374959032566,
      "loss": 2.3297,
      "step": 4030
    },
    {
      "epoch": 18.878504672897197,
      "grad_norm": 0.28742945194244385,
      "learning_rate": 0.0004910885136575886,
      "loss": 2.324,
      "step": 4040
    },
    {
      "epoch": 18.925233644859812,
      "grad_norm": 0.26395323872566223,
      "learning_rate": 0.0004910393988806633,
      "loss": 2.3286,
      "step": 4050
    },
    {
      "epoch": 18.97196261682243,
      "grad_norm": 0.2365982085466385,
      "learning_rate": 0.0004909901515994801,
      "loss": 2.3237,
      "step": 4060
    },
    {
      "epoch": 19.0,
      "eval_loss": 1.154789924621582,
      "eval_runtime": 5.4124,
      "eval_samples_per_second": 3586.601,
      "eval_steps_per_second": 14.042,
      "step": 4066
    },
    {
      "epoch": 19.018691588785046,
      "grad_norm": 0.2501848638057709,
      "learning_rate": 0.0004909407718411115,
      "loss": 2.321,
      "step": 4070
    },
    {
      "epoch": 19.065420560747665,
      "grad_norm": 0.26366040110588074,
      "learning_rate": 0.0004908912596327022,
      "loss": 2.3114,
      "step": 4080
    },
    {
      "epoch": 19.11214953271028,
      "grad_norm": 0.2832949161529541,
      "learning_rate": 0.0004908416150014703,
      "loss": 2.3182,
      "step": 4090
    },
    {
      "epoch": 19.1588785046729,
      "grad_norm": 0.27094003558158875,
      "learning_rate": 0.0004907918379747065,
      "loss": 2.3222,
      "step": 4100
    },
    {
      "epoch": 19.205607476635514,
      "grad_norm": 0.27401265501976013,
      "learning_rate": 0.0004907419285797741,
      "loss": 2.3233,
      "step": 4110
    },
    {
      "epoch": 19.252336448598133,
      "grad_norm": 0.2527003288269043,
      "learning_rate": 0.0004906918868441092,
      "loss": 2.3331,
      "step": 4120
    },
    {
      "epoch": 19.299065420560748,
      "grad_norm": 0.3421112596988678,
      "learning_rate": 0.0004906417127952212,
      "loss": 2.309,
      "step": 4130
    },
    {
      "epoch": 19.345794392523363,
      "grad_norm": 0.2716771960258484,
      "learning_rate": 0.0004905914064606912,
      "loss": 2.3135,
      "step": 4140
    },
    {
      "epoch": 19.39252336448598,
      "grad_norm": 0.2618480622768402,
      "learning_rate": 0.0004905409678681742,
      "loss": 2.3146,
      "step": 4150
    },
    {
      "epoch": 19.439252336448597,
      "grad_norm": 0.2767588794231415,
      "learning_rate": 0.0004904903970453969,
      "loss": 2.3137,
      "step": 4160
    },
    {
      "epoch": 19.485981308411215,
      "grad_norm": 0.2583732604980469,
      "learning_rate": 0.0004904396940201593,
      "loss": 2.3252,
      "step": 4170
    },
    {
      "epoch": 19.53271028037383,
      "grad_norm": 0.27639028429985046,
      "learning_rate": 0.0004903888588203338,
      "loss": 2.3252,
      "step": 4180
    },
    {
      "epoch": 19.57943925233645,
      "grad_norm": 0.27189481258392334,
      "learning_rate": 0.0004903378914738656,
      "loss": 2.3266,
      "step": 4190
    },
    {
      "epoch": 19.626168224299064,
      "grad_norm": 0.25856852531433105,
      "learning_rate": 0.0004902867920087725,
      "loss": 2.321,
      "step": 4200
    },
    {
      "epoch": 19.672897196261683,
      "grad_norm": 0.27075737714767456,
      "learning_rate": 0.0004902355604531447,
      "loss": 2.3162,
      "step": 4210
    },
    {
      "epoch": 19.7196261682243,
      "grad_norm": 0.26264363527297974,
      "learning_rate": 0.0004901841968351457,
      "loss": 2.3219,
      "step": 4220
    },
    {
      "epoch": 19.766355140186917,
      "grad_norm": 0.25003781914711,
      "learning_rate": 0.0004901327011830106,
      "loss": 2.337,
      "step": 4230
    },
    {
      "epoch": 19.813084112149532,
      "grad_norm": 0.2818920612335205,
      "learning_rate": 0.000490081073525048,
      "loss": 2.3091,
      "step": 4240
    },
    {
      "epoch": 19.85981308411215,
      "grad_norm": 0.26639848947525024,
      "learning_rate": 0.0004900293138896385,
      "loss": 2.3278,
      "step": 4250
    },
    {
      "epoch": 19.906542056074766,
      "grad_norm": 0.24894843995571136,
      "learning_rate": 0.0004899774223052353,
      "loss": 2.3098,
      "step": 4260
    },
    {
      "epoch": 19.953271028037385,
      "grad_norm": 0.24128934741020203,
      "learning_rate": 0.0004899253988003645,
      "loss": 2.3139,
      "step": 4270
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.4483646750450134,
      "learning_rate": 0.0004898732434036243,
      "loss": 2.3065,
      "step": 4280
    },
    {
      "epoch": 20.0,
      "eval_loss": 1.1529836654663086,
      "eval_runtime": 5.4389,
      "eval_samples_per_second": 3569.113,
      "eval_steps_per_second": 13.973,
      "step": 4280
    },
    {
      "epoch": 20.046728971962615,
      "grad_norm": 0.32313036918640137,
      "learning_rate": 0.0004898209561436858,
      "loss": 2.3187,
      "step": 4290
    },
    {
      "epoch": 20.093457943925234,
      "grad_norm": 0.2791363000869751,
      "learning_rate": 0.0004897685370492921,
      "loss": 2.3207,
      "step": 4300
    },
    {
      "epoch": 20.14018691588785,
      "grad_norm": 0.28729891777038574,
      "learning_rate": 0.0004897159861492592,
      "loss": 2.3165,
      "step": 4310
    },
    {
      "epoch": 20.186915887850468,
      "grad_norm": 0.3061676025390625,
      "learning_rate": 0.0004896633034724754,
      "loss": 2.3111,
      "step": 4320
    },
    {
      "epoch": 20.233644859813083,
      "grad_norm": 0.25903892517089844,
      "learning_rate": 0.0004896104890479014,
      "loss": 2.3206,
      "step": 4330
    },
    {
      "epoch": 20.2803738317757,
      "grad_norm": 0.2682279944419861,
      "learning_rate": 0.0004895575429045703,
      "loss": 2.3113,
      "step": 4340
    },
    {
      "epoch": 20.327102803738317,
      "grad_norm": 0.27895960211753845,
      "learning_rate": 0.0004895044650715879,
      "loss": 2.3103,
      "step": 4350
    },
    {
      "epoch": 20.373831775700936,
      "grad_norm": 0.3086280822753906,
      "learning_rate": 0.0004894512555781319,
      "loss": 2.3153,
      "step": 4360
    },
    {
      "epoch": 20.42056074766355,
      "grad_norm": 0.28203409910202026,
      "learning_rate": 0.0004893979144534527,
      "loss": 2.3308,
      "step": 4370
    },
    {
      "epoch": 20.46728971962617,
      "grad_norm": 0.2685681879520416,
      "learning_rate": 0.0004893444417268731,
      "loss": 2.3123,
      "step": 4380
    },
    {
      "epoch": 20.514018691588785,
      "grad_norm": 0.2883701026439667,
      "learning_rate": 0.000489290837427788,
      "loss": 2.31,
      "step": 4390
    },
    {
      "epoch": 20.560747663551403,
      "grad_norm": 0.3107623755931854,
      "learning_rate": 0.0004892371015856649,
      "loss": 2.3175,
      "step": 4400
    },
    {
      "epoch": 20.60747663551402,
      "grad_norm": 0.2743625342845917,
      "learning_rate": 0.0004891832342300435,
      "loss": 2.315,
      "step": 4410
    },
    {
      "epoch": 20.654205607476637,
      "grad_norm": 0.2865143418312073,
      "learning_rate": 0.0004891292353905358,
      "loss": 2.3111,
      "step": 4420
    },
    {
      "epoch": 20.700934579439252,
      "grad_norm": 0.33790162205696106,
      "learning_rate": 0.0004890751050968258,
      "loss": 2.2957,
      "step": 4430
    },
    {
      "epoch": 20.747663551401867,
      "grad_norm": 0.25785908102989197,
      "learning_rate": 0.0004890208433786703,
      "loss": 2.3179,
      "step": 4440
    },
    {
      "epoch": 20.794392523364486,
      "grad_norm": 0.26777443289756775,
      "learning_rate": 0.000488966450265898,
      "loss": 2.3147,
      "step": 4450
    },
    {
      "epoch": 20.8411214953271,
      "grad_norm": 0.24800196290016174,
      "learning_rate": 0.0004889119257884099,
      "loss": 2.3228,
      "step": 4460
    },
    {
      "epoch": 20.88785046728972,
      "grad_norm": 0.2643049359321594,
      "learning_rate": 0.0004888572699761792,
      "loss": 2.31,
      "step": 4470
    },
    {
      "epoch": 20.934579439252335,
      "grad_norm": 0.26010987162590027,
      "learning_rate": 0.0004888024828592513,
      "loss": 2.3012,
      "step": 4480
    },
    {
      "epoch": 20.981308411214954,
      "grad_norm": 0.26039573550224304,
      "learning_rate": 0.0004887475644677437,
      "loss": 2.3185,
      "step": 4490
    },
    {
      "epoch": 21.0,
      "eval_loss": 1.1516081094741821,
      "eval_runtime": 5.4751,
      "eval_samples_per_second": 3545.531,
      "eval_steps_per_second": 13.881,
      "step": 4494
    },
    {
      "epoch": 21.02803738317757,
      "grad_norm": 0.2638402283191681,
      "learning_rate": 0.0004886925148318463,
      "loss": 2.3079,
      "step": 4500
    },
    {
      "epoch": 21.074766355140188,
      "grad_norm": 0.2752481997013092,
      "learning_rate": 0.0004886373339818209,
      "loss": 2.3068,
      "step": 4510
    },
    {
      "epoch": 21.121495327102803,
      "grad_norm": 0.2568960189819336,
      "learning_rate": 0.0004885820219480018,
      "loss": 2.3088,
      "step": 4520
    },
    {
      "epoch": 21.16822429906542,
      "grad_norm": 0.31342262029647827,
      "learning_rate": 0.0004885265787607948,
      "loss": 2.3065,
      "step": 4530
    },
    {
      "epoch": 21.214953271028037,
      "grad_norm": 0.2976863980293274,
      "learning_rate": 0.0004884710044506783,
      "loss": 2.3131,
      "step": 4540
    },
    {
      "epoch": 21.261682242990656,
      "grad_norm": 0.3158322274684906,
      "learning_rate": 0.0004884152990482026,
      "loss": 2.3219,
      "step": 4550
    },
    {
      "epoch": 21.30841121495327,
      "grad_norm": 0.29308685660362244,
      "learning_rate": 0.0004883594625839902,
      "loss": 2.3021,
      "step": 4560
    },
    {
      "epoch": 21.35514018691589,
      "grad_norm": 0.27597445249557495,
      "learning_rate": 0.0004883034950887352,
      "loss": 2.3028,
      "step": 4570
    },
    {
      "epoch": 21.401869158878505,
      "grad_norm": 0.25267601013183594,
      "learning_rate": 0.00048824739659320454,
      "loss": 2.3095,
      "step": 4580
    },
    {
      "epoch": 21.44859813084112,
      "grad_norm": 0.3023955821990967,
      "learning_rate": 0.0004881911671282364,
      "loss": 2.3111,
      "step": 4590
    },
    {
      "epoch": 21.49532710280374,
      "grad_norm": 0.27391067147254944,
      "learning_rate": 0.0004881348067247414,
      "loss": 2.3184,
      "step": 4600
    },
    {
      "epoch": 21.542056074766354,
      "grad_norm": 0.2914612889289856,
      "learning_rate": 0.00048807831541370196,
      "loss": 2.315,
      "step": 4610
    },
    {
      "epoch": 21.588785046728972,
      "grad_norm": 0.2685193419456482,
      "learning_rate": 0.0004880216932261724,
      "loss": 2.3144,
      "step": 4620
    },
    {
      "epoch": 21.635514018691588,
      "grad_norm": 0.277788907289505,
      "learning_rate": 0.0004879649401932792,
      "loss": 2.3139,
      "step": 4630
    },
    {
      "epoch": 21.682242990654206,
      "grad_norm": 0.3369967043399811,
      "learning_rate": 0.00048790805634622066,
      "loss": 2.3077,
      "step": 4640
    },
    {
      "epoch": 21.72897196261682,
      "grad_norm": 0.26921337842941284,
      "learning_rate": 0.0004878510417162669,
      "loss": 2.302,
      "step": 4650
    },
    {
      "epoch": 21.77570093457944,
      "grad_norm": 0.269178569316864,
      "learning_rate": 0.00048779389633476014,
      "loss": 2.3083,
      "step": 4660
    },
    {
      "epoch": 21.822429906542055,
      "grad_norm": 0.2927505373954773,
      "learning_rate": 0.0004877366202331143,
      "loss": 2.3066,
      "step": 4670
    },
    {
      "epoch": 21.869158878504674,
      "grad_norm": 0.26355302333831787,
      "learning_rate": 0.0004876792134428151,
      "loss": 2.3028,
      "step": 4680
    },
    {
      "epoch": 21.91588785046729,
      "grad_norm": 0.2816755175590515,
      "learning_rate": 0.0004876216759954204,
      "loss": 2.3157,
      "step": 4690
    },
    {
      "epoch": 21.962616822429908,
      "grad_norm": 0.3182477056980133,
      "learning_rate": 0.00048756400792255964,
      "loss": 2.3144,
      "step": 4700
    },
    {
      "epoch": 22.0,
      "eval_loss": 1.1510714292526245,
      "eval_runtime": 5.4807,
      "eval_samples_per_second": 3541.882,
      "eval_steps_per_second": 13.867,
      "step": 4708
    },
    {
      "epoch": 22.009345794392523,
      "grad_norm": 0.26157721877098083,
      "learning_rate": 0.00048750620925593416,
      "loss": 2.3065,
      "step": 4710
    },
    {
      "epoch": 22.05607476635514,
      "grad_norm": 0.31419724225997925,
      "learning_rate": 0.000487448280027317,
      "loss": 2.304,
      "step": 4720
    },
    {
      "epoch": 22.102803738317757,
      "grad_norm": 0.30907610058784485,
      "learning_rate": 0.00048739022026855305,
      "loss": 2.2934,
      "step": 4730
    },
    {
      "epoch": 22.149532710280372,
      "grad_norm": 0.26620009541511536,
      "learning_rate": 0.000487332030011559,
      "loss": 2.2939,
      "step": 4740
    },
    {
      "epoch": 22.19626168224299,
      "grad_norm": 0.2971680462360382,
      "learning_rate": 0.00048727370928832304,
      "loss": 2.2999,
      "step": 4750
    },
    {
      "epoch": 22.242990654205606,
      "grad_norm": 0.3073981702327728,
      "learning_rate": 0.00048721525813090553,
      "loss": 2.2802,
      "step": 4760
    },
    {
      "epoch": 22.289719626168225,
      "grad_norm": 0.297149658203125,
      "learning_rate": 0.000487156676571438,
      "loss": 2.3087,
      "step": 4770
    },
    {
      "epoch": 22.33644859813084,
      "grad_norm": 0.2957926094532013,
      "learning_rate": 0.0004870979646421242,
      "loss": 2.3131,
      "step": 4780
    },
    {
      "epoch": 22.38317757009346,
      "grad_norm": 0.2998073995113373,
      "learning_rate": 0.00048703912237523894,
      "loss": 2.3191,
      "step": 4790
    },
    {
      "epoch": 22.429906542056074,
      "grad_norm": 0.29880577325820923,
      "learning_rate": 0.00048698014980312935,
      "loss": 2.3031,
      "step": 4800
    },
    {
      "epoch": 22.476635514018692,
      "grad_norm": 0.26241403818130493,
      "learning_rate": 0.0004869210469582136,
      "loss": 2.3191,
      "step": 4810
    },
    {
      "epoch": 22.523364485981308,
      "grad_norm": 0.3804592788219452,
      "learning_rate": 0.00048686181387298176,
      "loss": 2.3209,
      "step": 4820
    },
    {
      "epoch": 22.570093457943926,
      "grad_norm": 0.2807258069515228,
      "learning_rate": 0.0004868024505799956,
      "loss": 2.3006,
      "step": 4830
    },
    {
      "epoch": 22.61682242990654,
      "grad_norm": 0.2670397162437439,
      "learning_rate": 0.0004867429571118882,
      "loss": 2.308,
      "step": 4840
    },
    {
      "epoch": 22.66355140186916,
      "grad_norm": 0.2814469039440155,
      "learning_rate": 0.0004866833335013644,
      "loss": 2.3171,
      "step": 4850
    },
    {
      "epoch": 22.710280373831775,
      "grad_norm": 0.2639461159706116,
      "learning_rate": 0.0004866235797812004,
      "loss": 2.3059,
      "step": 4860
    },
    {
      "epoch": 22.757009345794394,
      "grad_norm": 0.2815417945384979,
      "learning_rate": 0.0004865636959842442,
      "loss": 2.2938,
      "step": 4870
    },
    {
      "epoch": 22.80373831775701,
      "grad_norm": 0.29904302954673767,
      "learning_rate": 0.000486503682143415,
      "loss": 2.2976,
      "step": 4880
    },
    {
      "epoch": 22.850467289719624,
      "grad_norm": 0.3249499499797821,
      "learning_rate": 0.0004864435382917037,
      "loss": 2.3189,
      "step": 4890
    },
    {
      "epoch": 22.897196261682243,
      "grad_norm": 0.27459532022476196,
      "learning_rate": 0.0004863832644621726,
      "loss": 2.303,
      "step": 4900
    },
    {
      "epoch": 22.94392523364486,
      "grad_norm": 0.24281951785087585,
      "learning_rate": 0.0004863228606879554,
      "loss": 2.3058,
      "step": 4910
    },
    {
      "epoch": 22.990654205607477,
      "grad_norm": 0.2909460961818695,
      "learning_rate": 0.00048626232700225736,
      "loss": 2.3019,
      "step": 4920
    },
    {
      "epoch": 23.0,
      "eval_loss": 1.149932622909546,
      "eval_runtime": 5.4368,
      "eval_samples_per_second": 3570.514,
      "eval_steps_per_second": 13.979,
      "step": 4922
    },
    {
      "epoch": 23.037383177570092,
      "grad_norm": 0.3771245777606964,
      "learning_rate": 0.00048620166343835505,
      "loss": 2.3069,
      "step": 4930
    },
    {
      "epoch": 23.08411214953271,
      "grad_norm": 0.3086494207382202,
      "learning_rate": 0.0004861408700295964,
      "loss": 2.3054,
      "step": 4940
    },
    {
      "epoch": 23.130841121495326,
      "grad_norm": 0.296268492937088,
      "learning_rate": 0.00048607994680940084,
      "loss": 2.3043,
      "step": 4950
    },
    {
      "epoch": 23.177570093457945,
      "grad_norm": 0.35626110434532166,
      "learning_rate": 0.00048601889381125906,
      "loss": 2.304,
      "step": 4960
    },
    {
      "epoch": 23.22429906542056,
      "grad_norm": 0.3183821737766266,
      "learning_rate": 0.0004859577110687332,
      "loss": 2.2979,
      "step": 4970
    },
    {
      "epoch": 23.27102803738318,
      "grad_norm": 0.380669504404068,
      "learning_rate": 0.0004858963986154566,
      "loss": 2.3055,
      "step": 4980
    },
    {
      "epoch": 23.317757009345794,
      "grad_norm": 0.2944808006286621,
      "learning_rate": 0.00048583495648513397,
      "loss": 2.2976,
      "step": 4990
    },
    {
      "epoch": 23.364485981308412,
      "grad_norm": 0.28834325075149536,
      "learning_rate": 0.0004857733847115414,
      "loss": 2.2947,
      "step": 5000
    },
    {
      "epoch": 23.411214953271028,
      "grad_norm": 0.3655080199241638,
      "learning_rate": 0.000485711683328526,
      "loss": 2.2992,
      "step": 5010
    },
    {
      "epoch": 23.457943925233646,
      "grad_norm": 0.3247704803943634,
      "learning_rate": 0.0004856498523700063,
      "loss": 2.2923,
      "step": 5020
    },
    {
      "epoch": 23.50467289719626,
      "grad_norm": 0.26264238357543945,
      "learning_rate": 0.0004855878918699721,
      "loss": 2.2909,
      "step": 5030
    },
    {
      "epoch": 23.55140186915888,
      "grad_norm": 0.3246597945690155,
      "learning_rate": 0.00048552580186248434,
      "loss": 2.2967,
      "step": 5040
    },
    {
      "epoch": 23.598130841121495,
      "grad_norm": 0.27849581837654114,
      "learning_rate": 0.0004854635823816751,
      "loss": 2.3028,
      "step": 5050
    },
    {
      "epoch": 23.64485981308411,
      "grad_norm": 0.26168662309646606,
      "learning_rate": 0.00048540123346174776,
      "loss": 2.3011,
      "step": 5060
    },
    {
      "epoch": 23.69158878504673,
      "grad_norm": 0.2527901828289032,
      "learning_rate": 0.00048533875513697675,
      "loss": 2.2866,
      "step": 5070
    },
    {
      "epoch": 23.738317757009344,
      "grad_norm": 0.268587589263916,
      "learning_rate": 0.0004852761474417077,
      "loss": 2.3001,
      "step": 5080
    },
    {
      "epoch": 23.785046728971963,
      "grad_norm": 0.30234476923942566,
      "learning_rate": 0.00048521341041035725,
      "loss": 2.3179,
      "step": 5090
    },
    {
      "epoch": 23.83177570093458,
      "grad_norm": 0.29491686820983887,
      "learning_rate": 0.00048515054407741333,
      "loss": 2.2932,
      "step": 5100
    },
    {
      "epoch": 23.878504672897197,
      "grad_norm": 0.3398180902004242,
      "learning_rate": 0.00048508754847743473,
      "loss": 2.31,
      "step": 5110
    },
    {
      "epoch": 23.925233644859812,
      "grad_norm": 0.2841954529285431,
      "learning_rate": 0.0004850244236450516,
      "loss": 2.2973,
      "step": 5120
    },
    {
      "epoch": 23.97196261682243,
      "grad_norm": 0.27961331605911255,
      "learning_rate": 0.0004849611696149647,
      "loss": 2.2902,
      "step": 5130
    },
    {
      "epoch": 24.0,
      "eval_loss": 1.1476200819015503,
      "eval_runtime": 5.4643,
      "eval_samples_per_second": 3552.509,
      "eval_steps_per_second": 13.908,
      "step": 5136
    },
    {
      "epoch": 24.018691588785046,
      "grad_norm": 0.3259110450744629,
      "learning_rate": 0.00048489778642194626,
      "loss": 2.3023,
      "step": 5140
    },
    {
      "epoch": 24.065420560747665,
      "grad_norm": 0.27636316418647766,
      "learning_rate": 0.00048483427410083926,
      "loss": 2.2827,
      "step": 5150
    },
    {
      "epoch": 24.11214953271028,
      "grad_norm": 0.3121357858181,
      "learning_rate": 0.00048477063268655764,
      "loss": 2.294,
      "step": 5160
    },
    {
      "epoch": 24.1588785046729,
      "grad_norm": 0.3648361563682556,
      "learning_rate": 0.00048470686221408643,
      "loss": 2.2937,
      "step": 5170
    },
    {
      "epoch": 24.205607476635514,
      "grad_norm": 0.27079328894615173,
      "learning_rate": 0.0004846429627184815,
      "loss": 2.2955,
      "step": 5180
    },
    {
      "epoch": 24.252336448598133,
      "grad_norm": 0.27956894040107727,
      "learning_rate": 0.00048457893423486974,
      "loss": 2.3036,
      "step": 5190
    },
    {
      "epoch": 24.299065420560748,
      "grad_norm": 0.24771004915237427,
      "learning_rate": 0.00048451477679844904,
      "loss": 2.3015,
      "step": 5200
    },
    {
      "epoch": 24.345794392523363,
      "grad_norm": 0.2806188464164734,
      "learning_rate": 0.00048445049044448785,
      "loss": 2.2858,
      "step": 5210
    },
    {
      "epoch": 24.39252336448598,
      "grad_norm": 0.28170880675315857,
      "learning_rate": 0.0004843860752083258,
      "loss": 2.2946,
      "step": 5220
    },
    {
      "epoch": 24.439252336448597,
      "grad_norm": 0.35106414556503296,
      "learning_rate": 0.00048432153112537313,
      "loss": 2.3097,
      "step": 5230
    },
    {
      "epoch": 24.485981308411215,
      "grad_norm": 0.25890642404556274,
      "learning_rate": 0.0004842568582311112,
      "loss": 2.2855,
      "step": 5240
    },
    {
      "epoch": 24.53271028037383,
      "grad_norm": 0.2915726900100708,
      "learning_rate": 0.0004841920565610919,
      "loss": 2.2926,
      "step": 5250
    },
    {
      "epoch": 24.57943925233645,
      "grad_norm": 0.27467793226242065,
      "learning_rate": 0.00048412712615093805,
      "loss": 2.2944,
      "step": 5260
    },
    {
      "epoch": 24.626168224299064,
      "grad_norm": 0.28157392144203186,
      "learning_rate": 0.0004840620670363433,
      "loss": 2.299,
      "step": 5270
    },
    {
      "epoch": 24.672897196261683,
      "grad_norm": 0.26712921261787415,
      "learning_rate": 0.00048399687925307176,
      "loss": 2.2972,
      "step": 5280
    },
    {
      "epoch": 24.7196261682243,
      "grad_norm": 0.2612397372722626,
      "learning_rate": 0.00048393156283695873,
      "loss": 2.3002,
      "step": 5290
    },
    {
      "epoch": 24.766355140186917,
      "grad_norm": 0.30069971084594727,
      "learning_rate": 0.0004838661178239098,
      "loss": 2.288,
      "step": 5300
    },
    {
      "epoch": 24.813084112149532,
      "grad_norm": 0.2662784457206726,
      "learning_rate": 0.0004838005442499015,
      "loss": 2.2986,
      "step": 5310
    },
    {
      "epoch": 24.85981308411215,
      "grad_norm": 0.27265995740890503,
      "learning_rate": 0.00048373484215098094,
      "loss": 2.2963,
      "step": 5320
    },
    {
      "epoch": 24.906542056074766,
      "grad_norm": 0.28065481781959534,
      "learning_rate": 0.0004836690115632659,
      "loss": 2.2981,
      "step": 5330
    },
    {
      "epoch": 24.953271028037385,
      "grad_norm": 0.29862910509109497,
      "learning_rate": 0.00048360305252294485,
      "loss": 2.3053,
      "step": 5340
    },
    {
      "epoch": 25.0,
      "grad_norm": 0.40051040053367615,
      "learning_rate": 0.0004835369650662767,
      "loss": 2.2941,
      "step": 5350
    },
    {
      "epoch": 25.0,
      "eval_loss": 1.1471126079559326,
      "eval_runtime": 5.4611,
      "eval_samples_per_second": 3554.599,
      "eval_steps_per_second": 13.917,
      "step": 5350
    },
    {
      "epoch": 25.046728971962615,
      "grad_norm": 0.29869794845581055,
      "learning_rate": 0.00048347074922959113,
      "loss": 2.2929,
      "step": 5360
    },
    {
      "epoch": 25.093457943925234,
      "grad_norm": 0.277759850025177,
      "learning_rate": 0.00048340440504928827,
      "loss": 2.2909,
      "step": 5370
    },
    {
      "epoch": 25.14018691588785,
      "grad_norm": 0.3346215486526489,
      "learning_rate": 0.000483337932561839,
      "loss": 2.2931,
      "step": 5380
    },
    {
      "epoch": 25.186915887850468,
      "grad_norm": 0.2888808846473694,
      "learning_rate": 0.00048327133180378444,
      "loss": 2.3042,
      "step": 5390
    },
    {
      "epoch": 25.233644859813083,
      "grad_norm": 0.25623029470443726,
      "learning_rate": 0.00048320460281173655,
      "loss": 2.2979,
      "step": 5400
    },
    {
      "epoch": 25.2803738317757,
      "grad_norm": 0.283871054649353,
      "learning_rate": 0.00048313774562237745,
      "loss": 2.286,
      "step": 5410
    },
    {
      "epoch": 25.327102803738317,
      "grad_norm": 0.27695077657699585,
      "learning_rate": 0.00048307076027246,
      "loss": 2.2948,
      "step": 5420
    },
    {
      "epoch": 25.373831775700936,
      "grad_norm": 0.2927607297897339,
      "learning_rate": 0.00048300364679880735,
      "loss": 2.2756,
      "step": 5430
    },
    {
      "epoch": 25.42056074766355,
      "grad_norm": 0.2777692377567291,
      "learning_rate": 0.00048293640523831323,
      "loss": 2.2924,
      "step": 5440
    },
    {
      "epoch": 25.46728971962617,
      "grad_norm": 0.3082900643348694,
      "learning_rate": 0.0004828690356279416,
      "loss": 2.2901,
      "step": 5450
    },
    {
      "epoch": 25.514018691588785,
      "grad_norm": 0.3016658127307892,
      "learning_rate": 0.0004828015380047269,
      "loss": 2.3043,
      "step": 5460
    },
    {
      "epoch": 25.560747663551403,
      "grad_norm": 0.2904738187789917,
      "learning_rate": 0.00048273391240577404,
      "loss": 2.2834,
      "step": 5470
    },
    {
      "epoch": 25.60747663551402,
      "grad_norm": 0.28519293665885925,
      "learning_rate": 0.00048266615886825804,
      "loss": 2.2885,
      "step": 5480
    },
    {
      "epoch": 25.654205607476637,
      "grad_norm": 0.3071095943450928,
      "learning_rate": 0.00048259827742942453,
      "loss": 2.2996,
      "step": 5490
    },
    {
      "epoch": 25.700934579439252,
      "grad_norm": 0.2746465802192688,
      "learning_rate": 0.0004825302681265893,
      "loss": 2.286,
      "step": 5500
    },
    {
      "epoch": 25.747663551401867,
      "grad_norm": 0.3242386281490326,
      "learning_rate": 0.00048246213099713845,
      "loss": 2.2947,
      "step": 5510
    },
    {
      "epoch": 25.794392523364486,
      "grad_norm": 0.24788178503513336,
      "learning_rate": 0.0004823938660785282,
      "loss": 2.2873,
      "step": 5520
    },
    {
      "epoch": 25.8411214953271,
      "grad_norm": 0.319338321685791,
      "learning_rate": 0.00048232547340828537,
      "loss": 2.2846,
      "step": 5530
    },
    {
      "epoch": 25.88785046728972,
      "grad_norm": 0.27631282806396484,
      "learning_rate": 0.00048225695302400663,
      "loss": 2.2866,
      "step": 5540
    },
    {
      "epoch": 25.934579439252335,
      "grad_norm": 0.2806839942932129,
      "learning_rate": 0.00048218830496335913,
      "loss": 2.2795,
      "step": 5550
    },
    {
      "epoch": 25.981308411214954,
      "grad_norm": 0.2787807583808899,
      "learning_rate": 0.0004821195292640801,
      "loss": 2.3085,
      "step": 5560
    },
    {
      "epoch": 26.0,
      "eval_loss": 1.145565390586853,
      "eval_runtime": 5.4704,
      "eval_samples_per_second": 3548.538,
      "eval_steps_per_second": 13.893,
      "step": 5564
    },
    {
      "epoch": 26.02803738317757,
      "grad_norm": 0.2970828413963318,
      "learning_rate": 0.0004820506259639769,
      "loss": 2.2919,
      "step": 5570
    },
    {
      "epoch": 26.074766355140188,
      "grad_norm": 0.27010902762413025,
      "learning_rate": 0.0004819815951009272,
      "loss": 2.2967,
      "step": 5580
    },
    {
      "epoch": 26.121495327102803,
      "grad_norm": 0.2882218658924103,
      "learning_rate": 0.00048191243671287846,
      "loss": 2.2778,
      "step": 5590
    },
    {
      "epoch": 26.16822429906542,
      "grad_norm": 0.25505635142326355,
      "learning_rate": 0.00048184315083784853,
      "loss": 2.2915,
      "step": 5600
    },
    {
      "epoch": 26.214953271028037,
      "grad_norm": 0.3229948580265045,
      "learning_rate": 0.00048177373751392527,
      "loss": 2.2865,
      "step": 5610
    },
    {
      "epoch": 26.261682242990656,
      "grad_norm": 0.2909294068813324,
      "learning_rate": 0.00048170419677926666,
      "loss": 2.2806,
      "step": 5620
    },
    {
      "epoch": 26.30841121495327,
      "grad_norm": 0.27915194630622864,
      "learning_rate": 0.00048163452867210066,
      "loss": 2.2851,
      "step": 5630
    },
    {
      "epoch": 26.35514018691589,
      "grad_norm": 0.29650717973709106,
      "learning_rate": 0.0004815647332307252,
      "loss": 2.2732,
      "step": 5640
    },
    {
      "epoch": 26.401869158878505,
      "grad_norm": 0.3178403973579407,
      "learning_rate": 0.0004814948104935082,
      "loss": 2.2924,
      "step": 5650
    },
    {
      "epoch": 26.44859813084112,
      "grad_norm": 0.2715993821620941,
      "learning_rate": 0.00048142476049888765,
      "loss": 2.2848,
      "step": 5660
    },
    {
      "epoch": 26.49532710280374,
      "grad_norm": 0.3027403950691223,
      "learning_rate": 0.0004813545832853715,
      "loss": 2.2806,
      "step": 5670
    },
    {
      "epoch": 26.542056074766354,
      "grad_norm": 0.26931700110435486,
      "learning_rate": 0.0004812842788915376,
      "loss": 2.2905,
      "step": 5680
    },
    {
      "epoch": 26.588785046728972,
      "grad_norm": 0.2771444022655487,
      "learning_rate": 0.00048121384735603357,
      "loss": 2.286,
      "step": 5690
    },
    {
      "epoch": 26.635514018691588,
      "grad_norm": 0.26763397455215454,
      "learning_rate": 0.0004811432887175772,
      "loss": 2.2821,
      "step": 5700
    },
    {
      "epoch": 26.682242990654206,
      "grad_norm": 0.2836827337741852,
      "learning_rate": 0.0004810726030149559,
      "loss": 2.2798,
      "step": 5710
    },
    {
      "epoch": 26.72897196261682,
      "grad_norm": 0.31054461002349854,
      "learning_rate": 0.0004810017902870271,
      "loss": 2.2801,
      "step": 5720
    },
    {
      "epoch": 26.77570093457944,
      "grad_norm": 0.28394925594329834,
      "learning_rate": 0.000480930850572718,
      "loss": 2.2894,
      "step": 5730
    },
    {
      "epoch": 26.822429906542055,
      "grad_norm": 0.3152174651622772,
      "learning_rate": 0.00048085978391102565,
      "loss": 2.2877,
      "step": 5740
    },
    {
      "epoch": 26.869158878504674,
      "grad_norm": 0.26474931836128235,
      "learning_rate": 0.00048078859034101674,
      "loss": 2.2955,
      "step": 5750
    },
    {
      "epoch": 26.91588785046729,
      "grad_norm": 0.3318651020526886,
      "learning_rate": 0.00048071726990182786,
      "loss": 2.2937,
      "step": 5760
    },
    {
      "epoch": 26.962616822429908,
      "grad_norm": 0.302377313375473,
      "learning_rate": 0.0004806458226326653,
      "loss": 2.2959,
      "step": 5770
    },
    {
      "epoch": 27.0,
      "eval_loss": 1.145350694656372,
      "eval_runtime": 5.468,
      "eval_samples_per_second": 3550.125,
      "eval_steps_per_second": 13.899,
      "step": 5778
    },
    {
      "epoch": 27.009345794392523,
      "grad_norm": 0.3051127791404724,
      "learning_rate": 0.0004805742485728051,
      "loss": 2.2992,
      "step": 5780
    },
    {
      "epoch": 27.05607476635514,
      "grad_norm": 0.29105159640312195,
      "learning_rate": 0.000480502547761593,
      "loss": 2.2851,
      "step": 5790
    },
    {
      "epoch": 27.102803738317757,
      "grad_norm": 0.407721608877182,
      "learning_rate": 0.00048043072023844425,
      "loss": 2.283,
      "step": 5800
    },
    {
      "epoch": 27.149532710280372,
      "grad_norm": 0.26182568073272705,
      "learning_rate": 0.00048035876604284413,
      "loss": 2.2897,
      "step": 5810
    },
    {
      "epoch": 27.19626168224299,
      "grad_norm": 0.3493399918079376,
      "learning_rate": 0.0004802866852143471,
      "loss": 2.2848,
      "step": 5820
    },
    {
      "epoch": 27.242990654205606,
      "grad_norm": 0.3186880052089691,
      "learning_rate": 0.0004802144777925776,
      "loss": 2.2845,
      "step": 5830
    },
    {
      "epoch": 27.289719626168225,
      "grad_norm": 0.2990100383758545,
      "learning_rate": 0.0004801421438172294,
      "loss": 2.2857,
      "step": 5840
    },
    {
      "epoch": 27.33644859813084,
      "grad_norm": 0.4042055606842041,
      "learning_rate": 0.00048006968332806613,
      "loss": 2.2912,
      "step": 5850
    },
    {
      "epoch": 27.38317757009346,
      "grad_norm": 0.33783090114593506,
      "learning_rate": 0.0004799970963649207,
      "loss": 2.2861,
      "step": 5860
    },
    {
      "epoch": 27.429906542056074,
      "grad_norm": 0.2771359086036682,
      "learning_rate": 0.0004799243829676956,
      "loss": 2.2744,
      "step": 5870
    },
    {
      "epoch": 27.476635514018692,
      "grad_norm": 0.29227307438850403,
      "learning_rate": 0.0004798515431763628,
      "loss": 2.2861,
      "step": 5880
    },
    {
      "epoch": 27.523364485981308,
      "grad_norm": 0.30241551995277405,
      "learning_rate": 0.00047977857703096407,
      "loss": 2.2764,
      "step": 5890
    },
    {
      "epoch": 27.570093457943926,
      "grad_norm": 0.3424077033996582,
      "learning_rate": 0.00047970548457161013,
      "loss": 2.2897,
      "step": 5900
    },
    {
      "epoch": 27.61682242990654,
      "grad_norm": 0.2700273096561432,
      "learning_rate": 0.0004796322658384815,
      "loss": 2.286,
      "step": 5910
    },
    {
      "epoch": 27.66355140186916,
      "grad_norm": 0.28635305166244507,
      "learning_rate": 0.000479558920871828,
      "loss": 2.2964,
      "step": 5920
    },
    {
      "epoch": 27.710280373831775,
      "grad_norm": 0.33276936411857605,
      "learning_rate": 0.0004794854497119688,
      "loss": 2.2708,
      "step": 5930
    },
    {
      "epoch": 27.757009345794394,
      "grad_norm": 0.2776978015899658,
      "learning_rate": 0.00047941185239929265,
      "loss": 2.28,
      "step": 5940
    },
    {
      "epoch": 27.80373831775701,
      "grad_norm": 0.33247441053390503,
      "learning_rate": 0.0004793381289742572,
      "loss": 2.2757,
      "step": 5950
    },
    {
      "epoch": 27.850467289719624,
      "grad_norm": 0.28200140595436096,
      "learning_rate": 0.00047926427947739004,
      "loss": 2.2773,
      "step": 5960
    },
    {
      "epoch": 27.897196261682243,
      "grad_norm": 0.3805188834667206,
      "learning_rate": 0.00047919030394928756,
      "loss": 2.2964,
      "step": 5970
    },
    {
      "epoch": 27.94392523364486,
      "grad_norm": 0.2958950400352478,
      "learning_rate": 0.00047911620243061554,
      "loss": 2.2901,
      "step": 5980
    },
    {
      "epoch": 27.990654205607477,
      "grad_norm": 0.3018803596496582,
      "learning_rate": 0.00047904197496210924,
      "loss": 2.2872,
      "step": 5990
    },
    {
      "epoch": 28.0,
      "eval_loss": 1.145490050315857,
      "eval_runtime": 5.4616,
      "eval_samples_per_second": 3554.247,
      "eval_steps_per_second": 13.915,
      "step": 5992
    },
    {
      "epoch": 28.037383177570092,
      "grad_norm": 0.3006521165370941,
      "learning_rate": 0.00047896762158457294,
      "loss": 2.2701,
      "step": 6000
    },
    {
      "epoch": 28.08411214953271,
      "grad_norm": 0.2917233407497406,
      "learning_rate": 0.00047889314233888025,
      "loss": 2.2778,
      "step": 6010
    },
    {
      "epoch": 28.130841121495326,
      "grad_norm": 0.36335617303848267,
      "learning_rate": 0.00047881853726597384,
      "loss": 2.2689,
      "step": 6020
    },
    {
      "epoch": 28.177570093457945,
      "grad_norm": 0.36996641755104065,
      "learning_rate": 0.00047874380640686577,
      "loss": 2.2686,
      "step": 6030
    },
    {
      "epoch": 28.22429906542056,
      "grad_norm": 0.32293859124183655,
      "learning_rate": 0.000478668949802637,
      "loss": 2.278,
      "step": 6040
    },
    {
      "epoch": 28.27102803738318,
      "grad_norm": 0.37832900881767273,
      "learning_rate": 0.00047859396749443773,
      "loss": 2.2794,
      "step": 6050
    },
    {
      "epoch": 28.317757009345794,
      "grad_norm": 0.29426923394203186,
      "learning_rate": 0.00047851885952348726,
      "loss": 2.2835,
      "step": 6060
    },
    {
      "epoch": 28.364485981308412,
      "grad_norm": 0.30193769931793213,
      "learning_rate": 0.00047844362593107406,
      "loss": 2.2859,
      "step": 6070
    },
    {
      "epoch": 28.411214953271028,
      "grad_norm": 0.3080075979232788,
      "learning_rate": 0.00047836826675855547,
      "loss": 2.273,
      "step": 6080
    },
    {
      "epoch": 28.457943925233646,
      "grad_norm": 0.2918514311313629,
      "learning_rate": 0.00047829278204735803,
      "loss": 2.2869,
      "step": 6090
    },
    {
      "epoch": 28.50467289719626,
      "grad_norm": 0.39059996604919434,
      "learning_rate": 0.00047821717183897715,
      "loss": 2.283,
      "step": 6100
    },
    {
      "epoch": 28.55140186915888,
      "grad_norm": 0.2650158405303955,
      "learning_rate": 0.0004781414361749774,
      "loss": 2.2931,
      "step": 6110
    },
    {
      "epoch": 28.598130841121495,
      "grad_norm": 0.31009641289711,
      "learning_rate": 0.00047806557509699207,
      "loss": 2.2712,
      "step": 6120
    },
    {
      "epoch": 28.64485981308411,
      "grad_norm": 0.2991909384727478,
      "learning_rate": 0.0004779895886467236,
      "loss": 2.2842,
      "step": 6130
    },
    {
      "epoch": 28.69158878504673,
      "grad_norm": 0.272763729095459,
      "learning_rate": 0.00047791347686594333,
      "loss": 2.284,
      "step": 6140
    },
    {
      "epoch": 28.738317757009344,
      "grad_norm": 0.30277037620544434,
      "learning_rate": 0.0004778372397964914,
      "loss": 2.2847,
      "step": 6150
    },
    {
      "epoch": 28.785046728971963,
      "grad_norm": 0.26680606603622437,
      "learning_rate": 0.00047776087748027695,
      "loss": 2.274,
      "step": 6160
    },
    {
      "epoch": 28.83177570093458,
      "grad_norm": 0.2931482493877411,
      "learning_rate": 0.0004776843899592778,
      "loss": 2.2945,
      "step": 6170
    },
    {
      "epoch": 28.878504672897197,
      "grad_norm": 0.25129324197769165,
      "learning_rate": 0.0004776077772755407,
      "loss": 2.2764,
      "step": 6180
    },
    {
      "epoch": 28.925233644859812,
      "grad_norm": 0.3008967638015747,
      "learning_rate": 0.0004775310394711813,
      "loss": 2.2936,
      "step": 6190
    },
    {
      "epoch": 28.97196261682243,
      "grad_norm": 0.27105486392974854,
      "learning_rate": 0.0004774541765883839,
      "loss": 2.2733,
      "step": 6200
    },
    {
      "epoch": 29.0,
      "eval_loss": 1.1429823637008667,
      "eval_runtime": 5.523,
      "eval_samples_per_second": 3514.767,
      "eval_steps_per_second": 13.761,
      "step": 6206
    },
    {
      "epoch": 29.018691588785046,
      "grad_norm": 0.28115418553352356,
      "learning_rate": 0.0004773771886694015,
      "loss": 2.2759,
      "step": 6210
    },
    {
      "epoch": 29.065420560747665,
      "grad_norm": 0.3295072913169861,
      "learning_rate": 0.000477300075756556,
      "loss": 2.2824,
      "step": 6220
    },
    {
      "epoch": 29.11214953271028,
      "grad_norm": 0.27066344022750854,
      "learning_rate": 0.000477222837892238,
      "loss": 2.2685,
      "step": 6230
    },
    {
      "epoch": 29.1588785046729,
      "grad_norm": 0.2815554440021515,
      "learning_rate": 0.00047714547511890657,
      "loss": 2.2607,
      "step": 6240
    },
    {
      "epoch": 29.205607476635514,
      "grad_norm": 0.2755579948425293,
      "learning_rate": 0.0004770679874790896,
      "loss": 2.2727,
      "step": 6250
    },
    {
      "epoch": 29.252336448598133,
      "grad_norm": 0.26468297839164734,
      "learning_rate": 0.00047699037501538376,
      "loss": 2.271,
      "step": 6260
    },
    {
      "epoch": 29.299065420560748,
      "grad_norm": 0.28784939646720886,
      "learning_rate": 0.00047691263777045425,
      "loss": 2.2767,
      "step": 6270
    },
    {
      "epoch": 29.345794392523363,
      "grad_norm": 0.2716969847679138,
      "learning_rate": 0.0004768347757870346,
      "loss": 2.2846,
      "step": 6280
    },
    {
      "epoch": 29.39252336448598,
      "grad_norm": 0.2933449447154999,
      "learning_rate": 0.00047675678910792717,
      "loss": 2.2846,
      "step": 6290
    },
    {
      "epoch": 29.439252336448597,
      "grad_norm": 0.32170388102531433,
      "learning_rate": 0.00047667867777600293,
      "loss": 2.2543,
      "step": 6300
    },
    {
      "epoch": 29.485981308411215,
      "grad_norm": 0.3173339068889618,
      "learning_rate": 0.00047660044183420126,
      "loss": 2.2807,
      "step": 6310
    },
    {
      "epoch": 29.53271028037383,
      "grad_norm": 0.2673798203468323,
      "learning_rate": 0.0004765220813255299,
      "loss": 2.2694,
      "step": 6320
    },
    {
      "epoch": 29.57943925233645,
      "grad_norm": 0.3043995201587677,
      "learning_rate": 0.00047644359629306544,
      "loss": 2.2616,
      "step": 6330
    },
    {
      "epoch": 29.626168224299064,
      "grad_norm": 0.31707409024238586,
      "learning_rate": 0.00047636498677995246,
      "loss": 2.2931,
      "step": 6340
    },
    {
      "epoch": 29.672897196261683,
      "grad_norm": 0.3451476991176605,
      "learning_rate": 0.0004762862528294044,
      "loss": 2.2808,
      "step": 6350
    },
    {
      "epoch": 29.7196261682243,
      "grad_norm": 0.3738710284233093,
      "learning_rate": 0.0004762073944847028,
      "loss": 2.2911,
      "step": 6360
    },
    {
      "epoch": 29.766355140186917,
      "grad_norm": 0.26680800318717957,
      "learning_rate": 0.00047612841178919777,
      "loss": 2.2643,
      "step": 6370
    },
    {
      "epoch": 29.813084112149532,
      "grad_norm": 0.31803834438323975,
      "learning_rate": 0.0004760493047863076,
      "loss": 2.2701,
      "step": 6380
    },
    {
      "epoch": 29.85981308411215,
      "grad_norm": 0.29490458965301514,
      "learning_rate": 0.0004759700735195191,
      "loss": 2.2863,
      "step": 6390
    },
    {
      "epoch": 29.906542056074766,
      "grad_norm": 0.27340665459632874,
      "learning_rate": 0.00047589071803238726,
      "loss": 2.2864,
      "step": 6400
    },
    {
      "epoch": 29.953271028037385,
      "grad_norm": 0.31819891929626465,
      "learning_rate": 0.0004758112383685355,
      "loss": 2.28,
      "step": 6410
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.6874978542327881,
      "learning_rate": 0.0004757316345716554,
      "loss": 2.2679,
      "step": 6420
    },
    {
      "epoch": 30.0,
      "eval_loss": 1.1418828964233398,
      "eval_runtime": 5.4514,
      "eval_samples_per_second": 3560.912,
      "eval_steps_per_second": 13.941,
      "step": 6420
    },
    {
      "epoch": 30.046728971962615,
      "grad_norm": 0.2985500693321228,
      "learning_rate": 0.00047565190668550657,
      "loss": 2.2743,
      "step": 6430
    },
    {
      "epoch": 30.093457943925234,
      "grad_norm": 0.3088383078575134,
      "learning_rate": 0.0004755720547539173,
      "loss": 2.2728,
      "step": 6440
    },
    {
      "epoch": 30.14018691588785,
      "grad_norm": 0.28676149249076843,
      "learning_rate": 0.00047549207882078366,
      "loss": 2.2667,
      "step": 6450
    },
    {
      "epoch": 30.186915887850468,
      "grad_norm": 0.2764797508716583,
      "learning_rate": 0.00047541197893007016,
      "loss": 2.2699,
      "step": 6460
    },
    {
      "epoch": 30.233644859813083,
      "grad_norm": 0.27036282420158386,
      "learning_rate": 0.0004753317551258093,
      "loss": 2.269,
      "step": 6470
    },
    {
      "epoch": 30.2803738317757,
      "grad_norm": 0.2978605031967163,
      "learning_rate": 0.00047525140745210173,
      "loss": 2.2883,
      "step": 6480
    },
    {
      "epoch": 30.327102803738317,
      "grad_norm": 0.3054541051387787,
      "learning_rate": 0.0004751709359531162,
      "loss": 2.2726,
      "step": 6490
    },
    {
      "epoch": 30.373831775700936,
      "grad_norm": 0.30650991201400757,
      "learning_rate": 0.0004750903406730894,
      "loss": 2.2624,
      "step": 6500
    },
    {
      "epoch": 30.42056074766355,
      "grad_norm": 0.3185901641845703,
      "learning_rate": 0.0004750096216563265,
      "loss": 2.2697,
      "step": 6510
    },
    {
      "epoch": 30.46728971962617,
      "grad_norm": 0.2951219379901886,
      "learning_rate": 0.0004749287789472001,
      "loss": 2.2888,
      "step": 6520
    },
    {
      "epoch": 30.514018691588785,
      "grad_norm": 0.25941991806030273,
      "learning_rate": 0.0004748478125901512,
      "loss": 2.2687,
      "step": 6530
    },
    {
      "epoch": 30.560747663551403,
      "grad_norm": 0.2810411751270294,
      "learning_rate": 0.0004747667226296887,
      "loss": 2.2791,
      "step": 6540
    },
    {
      "epoch": 30.60747663551402,
      "grad_norm": 0.3046315610408783,
      "learning_rate": 0.0004746855091103893,
      "loss": 2.279,
      "step": 6550
    },
    {
      "epoch": 30.654205607476637,
      "grad_norm": 0.3565270006656647,
      "learning_rate": 0.00047460417207689776,
      "loss": 2.2687,
      "step": 6560
    },
    {
      "epoch": 30.700934579439252,
      "grad_norm": 0.3183743953704834,
      "learning_rate": 0.0004745227115739267,
      "loss": 2.2735,
      "step": 6570
    },
    {
      "epoch": 30.747663551401867,
      "grad_norm": 0.30627939105033875,
      "learning_rate": 0.00047444112764625655,
      "loss": 2.2722,
      "step": 6580
    },
    {
      "epoch": 30.794392523364486,
      "grad_norm": 0.3110082447528839,
      "learning_rate": 0.0004743594203387358,
      "loss": 2.2685,
      "step": 6590
    },
    {
      "epoch": 30.8411214953271,
      "grad_norm": 0.29472675919532776,
      "learning_rate": 0.0004742775896962805,
      "loss": 2.2764,
      "step": 6600
    },
    {
      "epoch": 30.88785046728972,
      "grad_norm": 0.30993127822875977,
      "learning_rate": 0.0004741956357638747,
      "loss": 2.2784,
      "step": 6610
    },
    {
      "epoch": 30.934579439252335,
      "grad_norm": 0.3952578604221344,
      "learning_rate": 0.00047411355858657003,
      "loss": 2.275,
      "step": 6620
    },
    {
      "epoch": 30.981308411214954,
      "grad_norm": 0.3009045720100403,
      "learning_rate": 0.0004740313582094861,
      "loss": 2.2665,
      "step": 6630
    },
    {
      "epoch": 31.0,
      "eval_loss": 1.1413722038269043,
      "eval_runtime": 5.4432,
      "eval_samples_per_second": 3566.29,
      "eval_steps_per_second": 13.962,
      "step": 6634
    },
    {
      "epoch": 31.02803738317757,
      "grad_norm": 0.30603328347206116,
      "learning_rate": 0.00047394903467781003,
      "loss": 2.2609,
      "step": 6640
    },
    {
      "epoch": 31.074766355140188,
      "grad_norm": 0.3230022192001343,
      "learning_rate": 0.0004738665880367968,
      "loss": 2.2532,
      "step": 6650
    },
    {
      "epoch": 31.121495327102803,
      "grad_norm": 0.32750681042671204,
      "learning_rate": 0.0004737840183317691,
      "loss": 2.2661,
      "step": 6660
    },
    {
      "epoch": 31.16822429906542,
      "grad_norm": 0.31209152936935425,
      "learning_rate": 0.00047370132560811695,
      "loss": 2.2649,
      "step": 6670
    },
    {
      "epoch": 31.214953271028037,
      "grad_norm": 0.3225160539150238,
      "learning_rate": 0.0004736185099112984,
      "loss": 2.2687,
      "step": 6680
    },
    {
      "epoch": 31.261682242990656,
      "grad_norm": 0.3057814836502075,
      "learning_rate": 0.0004735355712868388,
      "loss": 2.2786,
      "step": 6690
    },
    {
      "epoch": 31.30841121495327,
      "grad_norm": 0.330136239528656,
      "learning_rate": 0.00047345250978033125,
      "loss": 2.2623,
      "step": 6700
    },
    {
      "epoch": 31.35514018691589,
      "grad_norm": 0.3203296661376953,
      "learning_rate": 0.0004733693254374365,
      "loss": 2.2592,
      "step": 6710
    },
    {
      "epoch": 31.401869158878505,
      "grad_norm": 0.3527294993400574,
      "learning_rate": 0.0004732860183038824,
      "loss": 2.2786,
      "step": 6720
    },
    {
      "epoch": 31.44859813084112,
      "grad_norm": 0.2752276659011841,
      "learning_rate": 0.0004732025884254647,
      "loss": 2.2569,
      "step": 6730
    },
    {
      "epoch": 31.49532710280374,
      "grad_norm": 0.3427309989929199,
      "learning_rate": 0.0004731190358480466,
      "loss": 2.2878,
      "step": 6740
    },
    {
      "epoch": 31.542056074766354,
      "grad_norm": 0.2574062645435333,
      "learning_rate": 0.00047303536061755845,
      "loss": 2.2644,
      "step": 6750
    },
    {
      "epoch": 31.588785046728972,
      "grad_norm": 0.29567503929138184,
      "learning_rate": 0.0004729515627799984,
      "loss": 2.2862,
      "step": 6760
    },
    {
      "epoch": 31.635514018691588,
      "grad_norm": 0.2973855435848236,
      "learning_rate": 0.00047286764238143176,
      "loss": 2.264,
      "step": 6770
    },
    {
      "epoch": 31.682242990654206,
      "grad_norm": 0.27156880497932434,
      "learning_rate": 0.0004727835994679913,
      "loss": 2.2732,
      "step": 6780
    },
    {
      "epoch": 31.72897196261682,
      "grad_norm": 0.30234625935554504,
      "learning_rate": 0.00047269943408587703,
      "loss": 2.273,
      "step": 6790
    },
    {
      "epoch": 31.77570093457944,
      "grad_norm": 0.3606035113334656,
      "learning_rate": 0.0004726151462813565,
      "loss": 2.2831,
      "step": 6800
    },
    {
      "epoch": 31.822429906542055,
      "grad_norm": 0.2660788893699646,
      "learning_rate": 0.00047253073610076436,
      "loss": 2.2671,
      "step": 6810
    },
    {
      "epoch": 31.869158878504674,
      "grad_norm": 0.3201174736022949,
      "learning_rate": 0.00047244620359050254,
      "loss": 2.2723,
      "step": 6820
    },
    {
      "epoch": 31.91588785046729,
      "grad_norm": 0.2612808048725128,
      "learning_rate": 0.0004723615487970404,
      "loss": 2.2704,
      "step": 6830
    },
    {
      "epoch": 31.962616822429908,
      "grad_norm": 0.2799781262874603,
      "learning_rate": 0.00047227677176691436,
      "loss": 2.2629,
      "step": 6840
    },
    {
      "epoch": 32.0,
      "eval_loss": 1.141749620437622,
      "eval_runtime": 5.6673,
      "eval_samples_per_second": 3425.245,
      "eval_steps_per_second": 13.41,
      "step": 6848
    },
    {
      "epoch": 32.00934579439252,
      "grad_norm": 0.2896476089954376,
      "learning_rate": 0.000472191872546728,
      "loss": 2.2722,
      "step": 6850
    },
    {
      "epoch": 32.05607476635514,
      "grad_norm": 0.27299806475639343,
      "learning_rate": 0.0004721068511831523,
      "loss": 2.2606,
      "step": 6860
    },
    {
      "epoch": 32.10280373831776,
      "grad_norm": 0.2783915400505066,
      "learning_rate": 0.00047202170772292506,
      "loss": 2.2616,
      "step": 6870
    },
    {
      "epoch": 32.149532710280376,
      "grad_norm": 0.28347793221473694,
      "learning_rate": 0.0004719364422128515,
      "loss": 2.2704,
      "step": 6880
    },
    {
      "epoch": 32.19626168224299,
      "grad_norm": 0.5119174122810364,
      "learning_rate": 0.00047185105469980384,
      "loss": 2.2592,
      "step": 6890
    },
    {
      "epoch": 32.242990654205606,
      "grad_norm": 0.27620241045951843,
      "learning_rate": 0.0004717655452307211,
      "loss": 2.2623,
      "step": 6900
    },
    {
      "epoch": 32.28971962616822,
      "grad_norm": 0.31473201513290405,
      "learning_rate": 0.00047167991385260987,
      "loss": 2.2568,
      "step": 6910
    },
    {
      "epoch": 32.33644859813084,
      "grad_norm": 0.2829333245754242,
      "learning_rate": 0.0004715941606125432,
      "loss": 2.2645,
      "step": 6920
    },
    {
      "epoch": 32.38317757009346,
      "grad_norm": 0.2964363694190979,
      "learning_rate": 0.00047150828555766154,
      "loss": 2.2601,
      "step": 6930
    },
    {
      "epoch": 32.429906542056074,
      "grad_norm": 0.2766575813293457,
      "learning_rate": 0.00047142228873517215,
      "loss": 2.2695,
      "step": 6940
    },
    {
      "epoch": 32.47663551401869,
      "grad_norm": 0.2909126579761505,
      "learning_rate": 0.0004713361701923492,
      "loss": 2.2844,
      "step": 6950
    },
    {
      "epoch": 32.52336448598131,
      "grad_norm": 0.28615859150886536,
      "learning_rate": 0.0004712499299765338,
      "loss": 2.2756,
      "step": 6960
    },
    {
      "epoch": 32.570093457943926,
      "grad_norm": 0.29931026697158813,
      "learning_rate": 0.00047116356813513396,
      "loss": 2.2812,
      "step": 6970
    },
    {
      "epoch": 32.61682242990654,
      "grad_norm": 0.25853630900382996,
      "learning_rate": 0.0004710770847156245,
      "loss": 2.2613,
      "step": 6980
    },
    {
      "epoch": 32.66355140186916,
      "grad_norm": 0.32357388734817505,
      "learning_rate": 0.0004709904797655472,
      "loss": 2.267,
      "step": 6990
    },
    {
      "epoch": 32.71028037383178,
      "grad_norm": 0.3039780855178833,
      "learning_rate": 0.00047090375333251047,
      "loss": 2.2764,
      "step": 7000
    },
    {
      "epoch": 32.757009345794394,
      "grad_norm": 0.2965052127838135,
      "learning_rate": 0.00047081690546418967,
      "loss": 2.2625,
      "step": 7010
    },
    {
      "epoch": 32.80373831775701,
      "grad_norm": 0.2870313823223114,
      "learning_rate": 0.0004707299362083267,
      "loss": 2.2577,
      "step": 7020
    },
    {
      "epoch": 32.850467289719624,
      "grad_norm": 0.2807151675224304,
      "learning_rate": 0.0004706428456127305,
      "loss": 2.271,
      "step": 7030
    },
    {
      "epoch": 32.89719626168224,
      "grad_norm": 0.32697078585624695,
      "learning_rate": 0.00047055563372527657,
      "loss": 2.2711,
      "step": 7040
    },
    {
      "epoch": 32.94392523364486,
      "grad_norm": 0.28847187757492065,
      "learning_rate": 0.0004704683005939068,
      "loss": 2.2701,
      "step": 7050
    },
    {
      "epoch": 32.99065420560748,
      "grad_norm": 0.2753031551837921,
      "learning_rate": 0.0004703808462666302,
      "loss": 2.2802,
      "step": 7060
    },
    {
      "epoch": 33.0,
      "eval_loss": 1.1396512985229492,
      "eval_runtime": 5.4676,
      "eval_samples_per_second": 3550.4,
      "eval_steps_per_second": 13.9,
      "step": 7062
    },
    {
      "epoch": 33.03738317757009,
      "grad_norm": 0.2605065405368805,
      "learning_rate": 0.00047029327079152217,
      "loss": 2.2689,
      "step": 7070
    },
    {
      "epoch": 33.08411214953271,
      "grad_norm": 0.2982354760169983,
      "learning_rate": 0.0004702055742167246,
      "loss": 2.2639,
      "step": 7080
    },
    {
      "epoch": 33.13084112149533,
      "grad_norm": 0.3135046362876892,
      "learning_rate": 0.0004701177565904463,
      "loss": 2.2488,
      "step": 7090
    },
    {
      "epoch": 33.177570093457945,
      "grad_norm": 0.2814585566520691,
      "learning_rate": 0.0004700298179609622,
      "loss": 2.2814,
      "step": 7100
    },
    {
      "epoch": 33.22429906542056,
      "grad_norm": 0.3031691312789917,
      "learning_rate": 0.0004699417583766141,
      "loss": 2.2578,
      "step": 7110
    },
    {
      "epoch": 33.271028037383175,
      "grad_norm": 0.2905323803424835,
      "learning_rate": 0.00046985357788581,
      "loss": 2.2775,
      "step": 7120
    },
    {
      "epoch": 33.3177570093458,
      "grad_norm": 0.3621674180030823,
      "learning_rate": 0.0004697652765370246,
      "loss": 2.2562,
      "step": 7130
    },
    {
      "epoch": 33.36448598130841,
      "grad_norm": 0.371895968914032,
      "learning_rate": 0.00046967685437879897,
      "loss": 2.2575,
      "step": 7140
    },
    {
      "epoch": 33.41121495327103,
      "grad_norm": 0.27308303117752075,
      "learning_rate": 0.00046958831145974054,
      "loss": 2.2701,
      "step": 7150
    },
    {
      "epoch": 33.45794392523364,
      "grad_norm": 0.3154461085796356,
      "learning_rate": 0.0004694996478285231,
      "loss": 2.2536,
      "step": 7160
    },
    {
      "epoch": 33.504672897196265,
      "grad_norm": 0.32168957591056824,
      "learning_rate": 0.00046941086353388694,
      "loss": 2.2787,
      "step": 7170
    },
    {
      "epoch": 33.55140186915888,
      "grad_norm": 0.2902012765407562,
      "learning_rate": 0.0004693219586246385,
      "loss": 2.2592,
      "step": 7180
    },
    {
      "epoch": 33.598130841121495,
      "grad_norm": 0.27270305156707764,
      "learning_rate": 0.00046923293314965063,
      "loss": 2.2354,
      "step": 7190
    },
    {
      "epoch": 33.64485981308411,
      "grad_norm": 0.2720828354358673,
      "learning_rate": 0.00046914378715786254,
      "loss": 2.2599,
      "step": 7200
    },
    {
      "epoch": 33.691588785046726,
      "grad_norm": 0.30813416838645935,
      "learning_rate": 0.0004690545206982795,
      "loss": 2.2783,
      "step": 7210
    },
    {
      "epoch": 33.73831775700935,
      "grad_norm": 0.2851213812828064,
      "learning_rate": 0.0004689651338199732,
      "loss": 2.2496,
      "step": 7220
    },
    {
      "epoch": 33.78504672897196,
      "grad_norm": 0.2975739538669586,
      "learning_rate": 0.0004688756265720813,
      "loss": 2.2718,
      "step": 7230
    },
    {
      "epoch": 33.83177570093458,
      "grad_norm": 0.3466629385948181,
      "learning_rate": 0.00046878599900380773,
      "loss": 2.2649,
      "step": 7240
    },
    {
      "epoch": 33.87850467289719,
      "grad_norm": 0.2976154685020447,
      "learning_rate": 0.0004686962511644227,
      "loss": 2.2649,
      "step": 7250
    },
    {
      "epoch": 33.925233644859816,
      "grad_norm": 0.33156225085258484,
      "learning_rate": 0.00046860638310326243,
      "loss": 2.2683,
      "step": 7260
    },
    {
      "epoch": 33.97196261682243,
      "grad_norm": 0.27235329151153564,
      "learning_rate": 0.0004685163948697292,
      "loss": 2.2791,
      "step": 7270
    },
    {
      "epoch": 34.0,
      "eval_loss": 1.1394450664520264,
      "eval_runtime": 5.4606,
      "eval_samples_per_second": 3554.892,
      "eval_steps_per_second": 13.918,
      "step": 7276
    },
    {
      "epoch": 34.018691588785046,
      "grad_norm": 0.27165141701698303,
      "learning_rate": 0.0004684262865132912,
      "loss": 2.2671,
      "step": 7280
    },
    {
      "epoch": 34.06542056074766,
      "grad_norm": 0.2931520640850067,
      "learning_rate": 0.00046833605808348314,
      "loss": 2.2469,
      "step": 7290
    },
    {
      "epoch": 34.11214953271028,
      "grad_norm": 0.2861177325248718,
      "learning_rate": 0.00046824570962990513,
      "loss": 2.2462,
      "step": 7300
    },
    {
      "epoch": 34.1588785046729,
      "grad_norm": 0.34103915095329285,
      "learning_rate": 0.00046815524120222377,
      "loss": 2.2664,
      "step": 7310
    },
    {
      "epoch": 34.205607476635514,
      "grad_norm": 0.3035736680030823,
      "learning_rate": 0.0004680646528501712,
      "loss": 2.2629,
      "step": 7320
    },
    {
      "epoch": 34.25233644859813,
      "grad_norm": 0.28909391164779663,
      "learning_rate": 0.00046797394462354583,
      "loss": 2.2574,
      "step": 7330
    },
    {
      "epoch": 34.299065420560744,
      "grad_norm": 0.31114375591278076,
      "learning_rate": 0.00046788311657221173,
      "loss": 2.2668,
      "step": 7340
    },
    {
      "epoch": 34.345794392523366,
      "grad_norm": 0.3168494701385498,
      "learning_rate": 0.000467792168746099,
      "loss": 2.2692,
      "step": 7350
    },
    {
      "epoch": 34.39252336448598,
      "grad_norm": 0.2823934555053711,
      "learning_rate": 0.0004677011011952034,
      "loss": 2.2633,
      "step": 7360
    },
    {
      "epoch": 34.4392523364486,
      "grad_norm": 0.35063666105270386,
      "learning_rate": 0.00046760991396958677,
      "loss": 2.2632,
      "step": 7370
    },
    {
      "epoch": 34.48598130841121,
      "grad_norm": 0.31500330567359924,
      "learning_rate": 0.0004675186071193764,
      "loss": 2.2569,
      "step": 7380
    },
    {
      "epoch": 34.532710280373834,
      "grad_norm": 0.360871821641922,
      "learning_rate": 0.00046742718069476576,
      "loss": 2.261,
      "step": 7390
    },
    {
      "epoch": 34.57943925233645,
      "grad_norm": 0.3153783977031708,
      "learning_rate": 0.00046733563474601355,
      "loss": 2.2615,
      "step": 7400
    },
    {
      "epoch": 34.626168224299064,
      "grad_norm": 0.27910441160202026,
      "learning_rate": 0.0004672439693234446,
      "loss": 2.2681,
      "step": 7410
    },
    {
      "epoch": 34.67289719626168,
      "grad_norm": 0.29487624764442444,
      "learning_rate": 0.0004671521844774492,
      "loss": 2.2645,
      "step": 7420
    },
    {
      "epoch": 34.7196261682243,
      "grad_norm": 0.2833365797996521,
      "learning_rate": 0.00046706028025848335,
      "loss": 2.257,
      "step": 7430
    },
    {
      "epoch": 34.76635514018692,
      "grad_norm": 0.3725721538066864,
      "learning_rate": 0.00046696825671706867,
      "loss": 2.2569,
      "step": 7440
    },
    {
      "epoch": 34.81308411214953,
      "grad_norm": 0.28940683603286743,
      "learning_rate": 0.0004668761139037924,
      "loss": 2.2637,
      "step": 7450
    },
    {
      "epoch": 34.85981308411215,
      "grad_norm": 0.2981834411621094,
      "learning_rate": 0.00046678385186930727,
      "loss": 2.2695,
      "step": 7460
    },
    {
      "epoch": 34.90654205607477,
      "grad_norm": 0.27148574590682983,
      "learning_rate": 0.0004666914706643317,
      "loss": 2.2632,
      "step": 7470
    },
    {
      "epoch": 34.953271028037385,
      "grad_norm": 0.3100584149360657,
      "learning_rate": 0.0004665989703396494,
      "loss": 2.2659,
      "step": 7480
    },
    {
      "epoch": 35.0,
      "grad_norm": 0.43018239736557007,
      "learning_rate": 0.00046650635094610973,
      "loss": 2.2578,
      "step": 7490
    },
    {
      "epoch": 35.0,
      "eval_loss": 1.1404918432235718,
      "eval_runtime": 5.4736,
      "eval_samples_per_second": 3546.454,
      "eval_steps_per_second": 13.885,
      "step": 7490
    },
    {
      "epoch": 35.046728971962615,
      "grad_norm": 0.3140999376773834,
      "learning_rate": 0.0004664136125346274,
      "loss": 2.2501,
      "step": 7500
    },
    {
      "epoch": 35.09345794392523,
      "grad_norm": 0.3271084427833557,
      "learning_rate": 0.00046632075515618264,
      "loss": 2.2473,
      "step": 7510
    },
    {
      "epoch": 35.14018691588785,
      "grad_norm": 0.33678513765335083,
      "learning_rate": 0.00046622777886182106,
      "loss": 2.2676,
      "step": 7520
    },
    {
      "epoch": 35.18691588785047,
      "grad_norm": 0.31435221433639526,
      "learning_rate": 0.0004661346837026536,
      "loss": 2.2571,
      "step": 7530
    },
    {
      "epoch": 35.23364485981308,
      "grad_norm": 0.3117122948169708,
      "learning_rate": 0.00046604146972985657,
      "loss": 2.2486,
      "step": 7540
    },
    {
      "epoch": 35.2803738317757,
      "grad_norm": 0.326957643032074,
      "learning_rate": 0.0004659481369946715,
      "loss": 2.2474,
      "step": 7550
    },
    {
      "epoch": 35.32710280373832,
      "grad_norm": 0.3102516829967499,
      "learning_rate": 0.0004658546855484055,
      "loss": 2.249,
      "step": 7560
    },
    {
      "epoch": 35.373831775700936,
      "grad_norm": 0.2999348044395447,
      "learning_rate": 0.00046576111544243055,
      "loss": 2.2591,
      "step": 7570
    },
    {
      "epoch": 35.42056074766355,
      "grad_norm": 0.2969255745410919,
      "learning_rate": 0.00046566742672818405,
      "loss": 2.2727,
      "step": 7580
    },
    {
      "epoch": 35.467289719626166,
      "grad_norm": 0.3277705907821655,
      "learning_rate": 0.0004655736194571687,
      "loss": 2.2572,
      "step": 7590
    },
    {
      "epoch": 35.51401869158879,
      "grad_norm": 0.281930536031723,
      "learning_rate": 0.0004654796936809522,
      "loss": 2.2429,
      "step": 7600
    },
    {
      "epoch": 35.5607476635514,
      "grad_norm": 0.2905573546886444,
      "learning_rate": 0.00046538564945116734,
      "loss": 2.2643,
      "step": 7610
    },
    {
      "epoch": 35.60747663551402,
      "grad_norm": 0.3684113323688507,
      "learning_rate": 0.0004652914868195124,
      "loss": 2.2528,
      "step": 7620
    },
    {
      "epoch": 35.654205607476634,
      "grad_norm": 0.2730604112148285,
      "learning_rate": 0.0004651972058377502,
      "loss": 2.2607,
      "step": 7630
    },
    {
      "epoch": 35.70093457943925,
      "grad_norm": 0.326978474855423,
      "learning_rate": 0.0004651028065577092,
      "loss": 2.2499,
      "step": 7640
    },
    {
      "epoch": 35.74766355140187,
      "grad_norm": 0.29947593808174133,
      "learning_rate": 0.0004650082890312824,
      "loss": 2.2668,
      "step": 7650
    },
    {
      "epoch": 35.794392523364486,
      "grad_norm": 0.3060457706451416,
      "learning_rate": 0.00046491365331042807,
      "loss": 2.2625,
      "step": 7660
    },
    {
      "epoch": 35.8411214953271,
      "grad_norm": 0.30803751945495605,
      "learning_rate": 0.0004648188994471694,
      "loss": 2.2528,
      "step": 7670
    },
    {
      "epoch": 35.88785046728972,
      "grad_norm": 0.29472172260284424,
      "learning_rate": 0.0004647240274935945,
      "loss": 2.2711,
      "step": 7680
    },
    {
      "epoch": 35.93457943925234,
      "grad_norm": 0.2902335822582245,
      "learning_rate": 0.0004646290375018564,
      "loss": 2.2655,
      "step": 7690
    },
    {
      "epoch": 35.981308411214954,
      "grad_norm": 0.3045864403247833,
      "learning_rate": 0.0004645339295241731,
      "loss": 2.249,
      "step": 7700
    },
    {
      "epoch": 36.0,
      "eval_loss": 1.1392276287078857,
      "eval_runtime": 5.4696,
      "eval_samples_per_second": 3549.092,
      "eval_steps_per_second": 13.895,
      "step": 7704
    },
    {
      "epoch": 36.02803738317757,
      "grad_norm": 0.4158405661582947,
      "learning_rate": 0.0004644387036128273,
      "loss": 2.2596,
      "step": 7710
    },
    {
      "epoch": 36.074766355140184,
      "grad_norm": 0.2840115427970886,
      "learning_rate": 0.0004643433598201667,
      "loss": 2.2634,
      "step": 7720
    },
    {
      "epoch": 36.12149532710281,
      "grad_norm": 0.28130143880844116,
      "learning_rate": 0.0004642478981986036,
      "loss": 2.2482,
      "step": 7730
    },
    {
      "epoch": 36.16822429906542,
      "grad_norm": 0.2935379147529602,
      "learning_rate": 0.00046415231880061537,
      "loss": 2.2495,
      "step": 7740
    },
    {
      "epoch": 36.21495327102804,
      "grad_norm": 0.311491996049881,
      "learning_rate": 0.00046405662167874377,
      "loss": 2.2633,
      "step": 7750
    },
    {
      "epoch": 36.26168224299065,
      "grad_norm": 0.2939258813858032,
      "learning_rate": 0.0004639608068855956,
      "loss": 2.241,
      "step": 7760
    },
    {
      "epoch": 36.308411214953274,
      "grad_norm": 0.32196855545043945,
      "learning_rate": 0.00046386487447384206,
      "loss": 2.2552,
      "step": 7770
    },
    {
      "epoch": 36.35514018691589,
      "grad_norm": 0.3281853497028351,
      "learning_rate": 0.00046376882449621927,
      "loss": 2.2625,
      "step": 7780
    },
    {
      "epoch": 36.401869158878505,
      "grad_norm": 0.3096464276313782,
      "learning_rate": 0.0004636726570055277,
      "loss": 2.2559,
      "step": 7790
    },
    {
      "epoch": 36.44859813084112,
      "grad_norm": 0.30589205026626587,
      "learning_rate": 0.0004635763720546328,
      "loss": 2.2423,
      "step": 7800
    },
    {
      "epoch": 36.495327102803735,
      "grad_norm": 0.35303691029548645,
      "learning_rate": 0.0004634799696964642,
      "loss": 2.2497,
      "step": 7810
    },
    {
      "epoch": 36.54205607476636,
      "grad_norm": 0.33752530813217163,
      "learning_rate": 0.00046338344998401635,
      "loss": 2.2495,
      "step": 7820
    },
    {
      "epoch": 36.58878504672897,
      "grad_norm": 0.30061855912208557,
      "learning_rate": 0.0004632868129703479,
      "loss": 2.2689,
      "step": 7830
    },
    {
      "epoch": 36.63551401869159,
      "grad_norm": 0.30612003803253174,
      "learning_rate": 0.0004631900587085824,
      "loss": 2.2535,
      "step": 7840
    },
    {
      "epoch": 36.6822429906542,
      "grad_norm": 0.27603521943092346,
      "learning_rate": 0.00046309318725190754,
      "loss": 2.2627,
      "step": 7850
    },
    {
      "epoch": 36.728971962616825,
      "grad_norm": 0.3177516460418701,
      "learning_rate": 0.0004629961986535755,
      "loss": 2.2678,
      "step": 7860
    },
    {
      "epoch": 36.77570093457944,
      "grad_norm": 0.4771476089954376,
      "learning_rate": 0.00046289909296690296,
      "loss": 2.2576,
      "step": 7870
    },
    {
      "epoch": 36.822429906542055,
      "grad_norm": 0.2837037444114685,
      "learning_rate": 0.0004628018702452708,
      "loss": 2.2427,
      "step": 7880
    },
    {
      "epoch": 36.86915887850467,
      "grad_norm": 0.37880709767341614,
      "learning_rate": 0.0004627045305421244,
      "loss": 2.2538,
      "step": 7890
    },
    {
      "epoch": 36.91588785046729,
      "grad_norm": 0.30056408047676086,
      "learning_rate": 0.00046260707391097334,
      "loss": 2.2484,
      "step": 7900
    },
    {
      "epoch": 36.96261682242991,
      "grad_norm": 0.2878059446811676,
      "learning_rate": 0.00046250950040539155,
      "loss": 2.2522,
      "step": 7910
    },
    {
      "epoch": 37.0,
      "eval_loss": 1.1398929357528687,
      "eval_runtime": 5.4401,
      "eval_samples_per_second": 3568.348,
      "eval_steps_per_second": 13.97,
      "step": 7918
    },
    {
      "epoch": 37.00934579439252,
      "grad_norm": 0.35241809487342834,
      "learning_rate": 0.00046241181007901713,
      "loss": 2.2625,
      "step": 7920
    },
    {
      "epoch": 37.05607476635514,
      "grad_norm": 0.36652258038520813,
      "learning_rate": 0.00046231400298555236,
      "loss": 2.2427,
      "step": 7930
    },
    {
      "epoch": 37.10280373831776,
      "grad_norm": 0.2972365915775299,
      "learning_rate": 0.00046221607917876396,
      "loss": 2.2411,
      "step": 7940
    },
    {
      "epoch": 37.149532710280376,
      "grad_norm": 0.3275974988937378,
      "learning_rate": 0.00046211803871248257,
      "loss": 2.2345,
      "step": 7950
    },
    {
      "epoch": 37.19626168224299,
      "grad_norm": 0.3219527006149292,
      "learning_rate": 0.00046201988164060295,
      "loss": 2.2575,
      "step": 7960
    },
    {
      "epoch": 37.242990654205606,
      "grad_norm": 0.3396497070789337,
      "learning_rate": 0.0004619216080170842,
      "loss": 2.2475,
      "step": 7970
    },
    {
      "epoch": 37.28971962616822,
      "grad_norm": 0.36350730061531067,
      "learning_rate": 0.0004618232178959491,
      "loss": 2.2509,
      "step": 7980
    },
    {
      "epoch": 37.33644859813084,
      "grad_norm": 0.326698899269104,
      "learning_rate": 0.0004617247113312849,
      "loss": 2.2465,
      "step": 7990
    },
    {
      "epoch": 37.38317757009346,
      "grad_norm": 0.37622833251953125,
      "learning_rate": 0.0004616260883772425,
      "loss": 2.2561,
      "step": 8000
    },
    {
      "epoch": 37.429906542056074,
      "grad_norm": 0.3152376115322113,
      "learning_rate": 0.00046152734908803716,
      "loss": 2.2444,
      "step": 8010
    },
    {
      "epoch": 37.47663551401869,
      "grad_norm": 0.34461623430252075,
      "learning_rate": 0.0004614284935179477,
      "loss": 2.2422,
      "step": 8020
    },
    {
      "epoch": 37.52336448598131,
      "grad_norm": 0.3831768333911896,
      "learning_rate": 0.00046132952172131704,
      "loss": 2.2619,
      "step": 8030
    },
    {
      "epoch": 37.570093457943926,
      "grad_norm": 0.3330596387386322,
      "learning_rate": 0.000461230433752552,
      "loss": 2.2666,
      "step": 8040
    },
    {
      "epoch": 37.61682242990654,
      "grad_norm": 0.2907164394855499,
      "learning_rate": 0.0004611312296661234,
      "loss": 2.2472,
      "step": 8050
    },
    {
      "epoch": 37.66355140186916,
      "grad_norm": 0.30546408891677856,
      "learning_rate": 0.0004610319095165656,
      "loss": 2.2555,
      "step": 8060
    },
    {
      "epoch": 37.71028037383178,
      "grad_norm": 0.3183620572090149,
      "learning_rate": 0.00046093247335847687,
      "loss": 2.2536,
      "step": 8070
    },
    {
      "epoch": 37.757009345794394,
      "grad_norm": 0.3124530613422394,
      "learning_rate": 0.0004608329212465194,
      "loss": 2.2465,
      "step": 8080
    },
    {
      "epoch": 37.80373831775701,
      "grad_norm": 0.2877570390701294,
      "learning_rate": 0.0004607332532354189,
      "loss": 2.2592,
      "step": 8090
    },
    {
      "epoch": 37.850467289719624,
      "grad_norm": 0.3360767960548401,
      "learning_rate": 0.00046063346937996497,
      "loss": 2.2622,
      "step": 8100
    },
    {
      "epoch": 37.89719626168224,
      "grad_norm": 0.310613751411438,
      "learning_rate": 0.0004605335697350108,
      "loss": 2.24,
      "step": 8110
    },
    {
      "epoch": 37.94392523364486,
      "grad_norm": 0.3115041255950928,
      "learning_rate": 0.00046043355435547336,
      "loss": 2.2517,
      "step": 8120
    },
    {
      "epoch": 37.99065420560748,
      "grad_norm": 0.39176568388938904,
      "learning_rate": 0.000460333423296333,
      "loss": 2.2455,
      "step": 8130
    },
    {
      "epoch": 38.0,
      "eval_loss": 1.1403342485427856,
      "eval_runtime": 5.6482,
      "eval_samples_per_second": 3436.847,
      "eval_steps_per_second": 13.456,
      "step": 8132
    },
    {
      "epoch": 38.03738317757009,
      "grad_norm": 0.35639312863349915,
      "learning_rate": 0.0004602331766126338,
      "loss": 2.2458,
      "step": 8140
    },
    {
      "epoch": 38.08411214953271,
      "grad_norm": 0.33952462673187256,
      "learning_rate": 0.0004601328143594835,
      "loss": 2.2472,
      "step": 8150
    },
    {
      "epoch": 38.13084112149533,
      "grad_norm": 0.32317861914634705,
      "learning_rate": 0.00046003233659205314,
      "loss": 2.2312,
      "step": 8160
    },
    {
      "epoch": 38.177570093457945,
      "grad_norm": 0.30445337295532227,
      "learning_rate": 0.00045993174336557755,
      "loss": 2.2505,
      "step": 8170
    },
    {
      "epoch": 38.22429906542056,
      "grad_norm": 0.33555835485458374,
      "learning_rate": 0.00045983103473535474,
      "loss": 2.2416,
      "step": 8180
    },
    {
      "epoch": 38.271028037383175,
      "grad_norm": 0.34641867876052856,
      "learning_rate": 0.00045973021075674636,
      "loss": 2.2506,
      "step": 8190
    },
    {
      "epoch": 38.3177570093458,
      "grad_norm": 0.4113573133945465,
      "learning_rate": 0.0004596292714851774,
      "loss": 2.2501,
      "step": 8200
    },
    {
      "epoch": 38.36448598130841,
      "grad_norm": 0.33734801411628723,
      "learning_rate": 0.0004595282169761362,
      "loss": 2.2539,
      "step": 8210
    },
    {
      "epoch": 38.41121495327103,
      "grad_norm": 0.2999035716056824,
      "learning_rate": 0.00045942704728517446,
      "loss": 2.2528,
      "step": 8220
    },
    {
      "epoch": 38.45794392523364,
      "grad_norm": 0.32748711109161377,
      "learning_rate": 0.00045932576246790724,
      "loss": 2.2465,
      "step": 8230
    },
    {
      "epoch": 38.504672897196265,
      "grad_norm": 0.5173051953315735,
      "learning_rate": 0.0004592243625800129,
      "loss": 2.2486,
      "step": 8240
    },
    {
      "epoch": 38.55140186915888,
      "grad_norm": 0.3123626410961151,
      "learning_rate": 0.000459122847677233,
      "loss": 2.2443,
      "step": 8250
    },
    {
      "epoch": 38.598130841121495,
      "grad_norm": 0.2962929606437683,
      "learning_rate": 0.00045902121781537234,
      "loss": 2.2502,
      "step": 8260
    },
    {
      "epoch": 38.64485981308411,
      "grad_norm": 0.34406694769859314,
      "learning_rate": 0.00045891947305029887,
      "loss": 2.2493,
      "step": 8270
    },
    {
      "epoch": 38.691588785046726,
      "grad_norm": 0.2934674322605133,
      "learning_rate": 0.0004588176134379438,
      "loss": 2.2509,
      "step": 8280
    },
    {
      "epoch": 38.73831775700935,
      "grad_norm": 0.3394661843776703,
      "learning_rate": 0.00045871563903430144,
      "loss": 2.2513,
      "step": 8290
    },
    {
      "epoch": 38.78504672897196,
      "grad_norm": 0.32194092869758606,
      "learning_rate": 0.0004586135498954292,
      "loss": 2.2584,
      "step": 8300
    },
    {
      "epoch": 38.83177570093458,
      "grad_norm": 0.2726542353630066,
      "learning_rate": 0.0004585113460774475,
      "loss": 2.2427,
      "step": 8310
    },
    {
      "epoch": 38.87850467289719,
      "grad_norm": 0.35519030690193176,
      "learning_rate": 0.00045840902763653993,
      "loss": 2.2532,
      "step": 8320
    },
    {
      "epoch": 38.925233644859816,
      "grad_norm": 0.3338718116283417,
      "learning_rate": 0.00045830659462895297,
      "loss": 2.2551,
      "step": 8330
    },
    {
      "epoch": 38.97196261682243,
      "grad_norm": 0.32271116971969604,
      "learning_rate": 0.0004582040471109962,
      "loss": 2.2532,
      "step": 8340
    },
    {
      "epoch": 39.0,
      "eval_loss": 1.139711618423462,
      "eval_runtime": 5.6185,
      "eval_samples_per_second": 3455.025,
      "eval_steps_per_second": 13.527,
      "step": 8346
    },
    {
      "epoch": 39.018691588785046,
      "grad_norm": 0.3398556113243103,
      "learning_rate": 0.00045810138513904195,
      "loss": 2.2385,
      "step": 8350
    },
    {
      "epoch": 39.06542056074766,
      "grad_norm": 0.3617827892303467,
      "learning_rate": 0.0004579986087695256,
      "loss": 2.2411,
      "step": 8360
    },
    {
      "epoch": 39.11214953271028,
      "grad_norm": 0.41261354088783264,
      "learning_rate": 0.0004578957180589456,
      "loss": 2.2321,
      "step": 8370
    },
    {
      "epoch": 39.1588785046729,
      "grad_norm": 0.3367686867713928,
      "learning_rate": 0.00045779271306386284,
      "loss": 2.2479,
      "step": 8380
    },
    {
      "epoch": 39.205607476635514,
      "grad_norm": 0.3394985795021057,
      "learning_rate": 0.00045768959384090137,
      "loss": 2.241,
      "step": 8390
    },
    {
      "epoch": 39.25233644859813,
      "grad_norm": 0.33499011397361755,
      "learning_rate": 0.0004575863604467479,
      "loss": 2.2402,
      "step": 8400
    },
    {
      "epoch": 39.299065420560744,
      "grad_norm": 0.3267599642276764,
      "learning_rate": 0.0004574830129381519,
      "loss": 2.2438,
      "step": 8410
    },
    {
      "epoch": 39.345794392523366,
      "grad_norm": 0.3131817579269409,
      "learning_rate": 0.00045737955137192566,
      "loss": 2.2546,
      "step": 8420
    },
    {
      "epoch": 39.39252336448598,
      "grad_norm": 0.3498212993144989,
      "learning_rate": 0.0004572759758049441,
      "loss": 2.2428,
      "step": 8430
    },
    {
      "epoch": 39.4392523364486,
      "grad_norm": 0.30555081367492676,
      "learning_rate": 0.00045717228629414474,
      "loss": 2.2649,
      "step": 8440
    },
    {
      "epoch": 39.48598130841121,
      "grad_norm": 0.33730125427246094,
      "learning_rate": 0.0004570684828965279,
      "loss": 2.2495,
      "step": 8450
    },
    {
      "epoch": 39.532710280373834,
      "grad_norm": 0.3276432454586029,
      "learning_rate": 0.0004569645656691564,
      "loss": 2.2438,
      "step": 8460
    },
    {
      "epoch": 39.57943925233645,
      "grad_norm": 0.3325137495994568,
      "learning_rate": 0.00045686053466915553,
      "loss": 2.2601,
      "step": 8470
    },
    {
      "epoch": 39.626168224299064,
      "grad_norm": 0.2977874279022217,
      "learning_rate": 0.0004567563899537135,
      "loss": 2.2393,
      "step": 8480
    },
    {
      "epoch": 39.67289719626168,
      "grad_norm": 0.30085277557373047,
      "learning_rate": 0.00045665213158008054,
      "loss": 2.2414,
      "step": 8490
    },
    {
      "epoch": 39.7196261682243,
      "grad_norm": 0.2724922001361847,
      "learning_rate": 0.00045654775960556965,
      "loss": 2.2439,
      "step": 8500
    },
    {
      "epoch": 39.76635514018692,
      "grad_norm": 0.28827300667762756,
      "learning_rate": 0.00045644327408755626,
      "loss": 2.244,
      "step": 8510
    },
    {
      "epoch": 39.81308411214953,
      "grad_norm": 0.33124271035194397,
      "learning_rate": 0.00045633867508347825,
      "loss": 2.2414,
      "step": 8520
    },
    {
      "epoch": 39.85981308411215,
      "grad_norm": 0.3823183476924896,
      "learning_rate": 0.00045623396265083573,
      "loss": 2.2453,
      "step": 8530
    },
    {
      "epoch": 39.90654205607477,
      "grad_norm": 0.3715711534023285,
      "learning_rate": 0.0004561291368471912,
      "loss": 2.24,
      "step": 8540
    },
    {
      "epoch": 39.953271028037385,
      "grad_norm": 0.3202360272407532,
      "learning_rate": 0.00045602419773016966,
      "loss": 2.2493,
      "step": 8550
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.5040966868400574,
      "learning_rate": 0.0004559191453574582,
      "loss": 2.2541,
      "step": 8560
    },
    {
      "epoch": 40.0,
      "eval_loss": 1.1382006406784058,
      "eval_runtime": 5.44,
      "eval_samples_per_second": 3568.399,
      "eval_steps_per_second": 13.971,
      "step": 8560
    },
    {
      "epoch": 40.046728971962615,
      "grad_norm": 0.3301813304424286,
      "learning_rate": 0.0004558139797868063,
      "loss": 2.2306,
      "step": 8570
    },
    {
      "epoch": 40.09345794392523,
      "grad_norm": 0.351301908493042,
      "learning_rate": 0.00045570870107602556,
      "loss": 2.2343,
      "step": 8580
    },
    {
      "epoch": 40.14018691588785,
      "grad_norm": 0.3233008086681366,
      "learning_rate": 0.00045560330928298985,
      "loss": 2.2475,
      "step": 8590
    },
    {
      "epoch": 40.18691588785047,
      "grad_norm": 0.3465366065502167,
      "learning_rate": 0.00045549780446563513,
      "loss": 2.2291,
      "step": 8600
    },
    {
      "epoch": 40.23364485981308,
      "grad_norm": 0.3315548598766327,
      "learning_rate": 0.0004553921866819597,
      "loss": 2.2352,
      "step": 8610
    },
    {
      "epoch": 40.2803738317757,
      "grad_norm": 0.3487364649772644,
      "learning_rate": 0.00045528645599002363,
      "loss": 2.253,
      "step": 8620
    },
    {
      "epoch": 40.32710280373832,
      "grad_norm": 0.35674208402633667,
      "learning_rate": 0.00045518061244794936,
      "loss": 2.252,
      "step": 8630
    },
    {
      "epoch": 40.373831775700936,
      "grad_norm": 0.29849687218666077,
      "learning_rate": 0.0004550746561139211,
      "loss": 2.2584,
      "step": 8640
    },
    {
      "epoch": 40.42056074766355,
      "grad_norm": 0.3088304400444031,
      "learning_rate": 0.00045496858704618525,
      "loss": 2.2411,
      "step": 8650
    },
    {
      "epoch": 40.467289719626166,
      "grad_norm": 0.33347049355506897,
      "learning_rate": 0.00045486240530305023,
      "loss": 2.2242,
      "step": 8660
    },
    {
      "epoch": 40.51401869158879,
      "grad_norm": 0.3656063675880432,
      "learning_rate": 0.00045475611094288623,
      "loss": 2.2347,
      "step": 8670
    },
    {
      "epoch": 40.5607476635514,
      "grad_norm": 0.33976680040359497,
      "learning_rate": 0.0004546497040241254,
      "loss": 2.2533,
      "step": 8680
    },
    {
      "epoch": 40.60747663551402,
      "grad_norm": 0.37034469842910767,
      "learning_rate": 0.0004545431846052618,
      "loss": 2.2317,
      "step": 8690
    },
    {
      "epoch": 40.654205607476634,
      "grad_norm": 0.3826640844345093,
      "learning_rate": 0.0004544365527448513,
      "loss": 2.2446,
      "step": 8700
    },
    {
      "epoch": 40.70093457943925,
      "grad_norm": 0.33360323309898376,
      "learning_rate": 0.00045432980850151173,
      "loss": 2.2373,
      "step": 8710
    },
    {
      "epoch": 40.74766355140187,
      "grad_norm": 0.3172132074832916,
      "learning_rate": 0.00045422295193392237,
      "loss": 2.2602,
      "step": 8720
    },
    {
      "epoch": 40.794392523364486,
      "grad_norm": 0.3214589059352875,
      "learning_rate": 0.0004541159831008246,
      "loss": 2.2374,
      "step": 8730
    },
    {
      "epoch": 40.8411214953271,
      "grad_norm": 0.32131683826446533,
      "learning_rate": 0.00045400890206102125,
      "loss": 2.2478,
      "step": 8740
    },
    {
      "epoch": 40.88785046728972,
      "grad_norm": 0.35027068853378296,
      "learning_rate": 0.000453901708873377,
      "loss": 2.2499,
      "step": 8750
    },
    {
      "epoch": 40.93457943925234,
      "grad_norm": 0.33101192116737366,
      "learning_rate": 0.0004537944035968182,
      "loss": 2.258,
      "step": 8760
    },
    {
      "epoch": 40.981308411214954,
      "grad_norm": 0.35286617279052734,
      "learning_rate": 0.0004536869862903327,
      "loss": 2.2501,
      "step": 8770
    },
    {
      "epoch": 41.0,
      "eval_loss": 1.1372690200805664,
      "eval_runtime": 5.463,
      "eval_samples_per_second": 3553.333,
      "eval_steps_per_second": 13.912,
      "step": 8774
    },
    {
      "epoch": 41.02803738317757,
      "grad_norm": 0.33160600066185,
      "learning_rate": 0.0004535794570129698,
      "loss": 2.2392,
      "step": 8780
    },
    {
      "epoch": 41.074766355140184,
      "grad_norm": 0.320441871881485,
      "learning_rate": 0.00045347181582384077,
      "loss": 2.2349,
      "step": 8790
    },
    {
      "epoch": 41.12149532710281,
      "grad_norm": 0.3494120240211487,
      "learning_rate": 0.00045336406278211804,
      "loss": 2.2253,
      "step": 8800
    },
    {
      "epoch": 41.16822429906542,
      "grad_norm": 0.33036893606185913,
      "learning_rate": 0.00045325619794703574,
      "loss": 2.2274,
      "step": 8810
    },
    {
      "epoch": 41.21495327102804,
      "grad_norm": 0.32513317465782166,
      "learning_rate": 0.0004531482213778892,
      "loss": 2.2524,
      "step": 8820
    },
    {
      "epoch": 41.26168224299065,
      "grad_norm": 0.36167943477630615,
      "learning_rate": 0.00045304013313403547,
      "loss": 2.2391,
      "step": 8830
    },
    {
      "epoch": 41.308411214953274,
      "grad_norm": 0.3756123185157776,
      "learning_rate": 0.0004529319332748929,
      "loss": 2.249,
      "step": 8840
    },
    {
      "epoch": 41.35514018691589,
      "grad_norm": 0.29886651039123535,
      "learning_rate": 0.00045282362185994097,
      "loss": 2.2468,
      "step": 8850
    },
    {
      "epoch": 41.401869158878505,
      "grad_norm": 0.32570090889930725,
      "learning_rate": 0.0004527151989487208,
      "loss": 2.2264,
      "step": 8860
    },
    {
      "epoch": 41.44859813084112,
      "grad_norm": 0.35352426767349243,
      "learning_rate": 0.0004526066646008346,
      "loss": 2.2228,
      "step": 8870
    },
    {
      "epoch": 41.495327102803735,
      "grad_norm": 0.3136260211467743,
      "learning_rate": 0.000452498018875946,
      "loss": 2.2467,
      "step": 8880
    },
    {
      "epoch": 41.54205607476636,
      "grad_norm": 0.3313511312007904,
      "learning_rate": 0.0004523892618337797,
      "loss": 2.2422,
      "step": 8890
    },
    {
      "epoch": 41.58878504672897,
      "grad_norm": 0.3215492367744446,
      "learning_rate": 0.00045228039353412163,
      "loss": 2.2344,
      "step": 8900
    },
    {
      "epoch": 41.63551401869159,
      "grad_norm": 0.3221052289009094,
      "learning_rate": 0.00045217141403681895,
      "loss": 2.2537,
      "step": 8910
    },
    {
      "epoch": 41.6822429906542,
      "grad_norm": 0.29550790786743164,
      "learning_rate": 0.0004520623234017799,
      "loss": 2.2508,
      "step": 8920
    },
    {
      "epoch": 41.728971962616825,
      "grad_norm": 0.3553783595561981,
      "learning_rate": 0.0004519531216889738,
      "loss": 2.2472,
      "step": 8930
    },
    {
      "epoch": 41.77570093457944,
      "grad_norm": 0.3108334243297577,
      "learning_rate": 0.000451843808958431,
      "loss": 2.2405,
      "step": 8940
    },
    {
      "epoch": 41.822429906542055,
      "grad_norm": 0.3388879597187042,
      "learning_rate": 0.00045173438527024314,
      "loss": 2.24,
      "step": 8950
    },
    {
      "epoch": 41.86915887850467,
      "grad_norm": 0.3370998501777649,
      "learning_rate": 0.0004516248506845625,
      "loss": 2.2586,
      "step": 8960
    },
    {
      "epoch": 41.91588785046729,
      "grad_norm": 0.3285679221153259,
      "learning_rate": 0.0004515152052616024,
      "loss": 2.2426,
      "step": 8970
    },
    {
      "epoch": 41.96261682242991,
      "grad_norm": 0.45535945892333984,
      "learning_rate": 0.0004514054490616372,
      "loss": 2.2432,
      "step": 8980
    },
    {
      "epoch": 42.0,
      "eval_loss": 1.1392813920974731,
      "eval_runtime": 5.5134,
      "eval_samples_per_second": 3520.875,
      "eval_steps_per_second": 13.785,
      "step": 8988
    },
    {
      "epoch": 42.00934579439252,
      "grad_norm": 0.3103522062301636,
      "learning_rate": 0.00045129558214500223,
      "loss": 2.246,
      "step": 8990
    },
    {
      "epoch": 42.05607476635514,
      "grad_norm": 0.3547903597354889,
      "learning_rate": 0.00045118560457209345,
      "loss": 2.2257,
      "step": 9000
    },
    {
      "epoch": 42.10280373831776,
      "grad_norm": 0.35805585980415344,
      "learning_rate": 0.00045107551640336777,
      "loss": 2.2411,
      "step": 9010
    },
    {
      "epoch": 42.149532710280376,
      "grad_norm": 0.3482261002063751,
      "learning_rate": 0.0004509653176993429,
      "loss": 2.2327,
      "step": 9020
    },
    {
      "epoch": 42.19626168224299,
      "grad_norm": 0.31121519207954407,
      "learning_rate": 0.00045085500852059743,
      "loss": 2.2391,
      "step": 9030
    },
    {
      "epoch": 42.242990654205606,
      "grad_norm": 0.29928678274154663,
      "learning_rate": 0.00045074458892777037,
      "loss": 2.2454,
      "step": 9040
    },
    {
      "epoch": 42.28971962616822,
      "grad_norm": 0.3421775698661804,
      "learning_rate": 0.0004506340589815617,
      "loss": 2.2371,
      "step": 9050
    },
    {
      "epoch": 42.33644859813084,
      "grad_norm": 0.31356748938560486,
      "learning_rate": 0.00045052341874273204,
      "loss": 2.2244,
      "step": 9060
    },
    {
      "epoch": 42.38317757009346,
      "grad_norm": 0.3217674195766449,
      "learning_rate": 0.0004504126682721026,
      "loss": 2.2387,
      "step": 9070
    },
    {
      "epoch": 42.429906542056074,
      "grad_norm": 0.38839003443717957,
      "learning_rate": 0.00045030180763055495,
      "loss": 2.2464,
      "step": 9080
    },
    {
      "epoch": 42.47663551401869,
      "grad_norm": 0.32492151856422424,
      "learning_rate": 0.0004501908368790316,
      "loss": 2.2423,
      "step": 9090
    },
    {
      "epoch": 42.52336448598131,
      "grad_norm": 0.3422938287258148,
      "learning_rate": 0.0004500797560785355,
      "loss": 2.2347,
      "step": 9100
    },
    {
      "epoch": 42.570093457943926,
      "grad_norm": 0.34565791487693787,
      "learning_rate": 0.00044996856529012984,
      "loss": 2.2455,
      "step": 9110
    },
    {
      "epoch": 42.61682242990654,
      "grad_norm": 0.3308328092098236,
      "learning_rate": 0.0004498572645749386,
      "loss": 2.234,
      "step": 9120
    },
    {
      "epoch": 42.66355140186916,
      "grad_norm": 0.32428479194641113,
      "learning_rate": 0.0004497458539941459,
      "loss": 2.2244,
      "step": 9130
    },
    {
      "epoch": 42.71028037383178,
      "grad_norm": 0.31249555945396423,
      "learning_rate": 0.0004496343336089965,
      "loss": 2.2312,
      "step": 9140
    },
    {
      "epoch": 42.757009345794394,
      "grad_norm": 0.342843234539032,
      "learning_rate": 0.0004495227034807955,
      "loss": 2.2221,
      "step": 9150
    },
    {
      "epoch": 42.80373831775701,
      "grad_norm": 0.31050390005111694,
      "learning_rate": 0.0004494109636709082,
      "loss": 2.2338,
      "step": 9160
    },
    {
      "epoch": 42.850467289719624,
      "grad_norm": 0.31184569001197815,
      "learning_rate": 0.0004492991142407601,
      "loss": 2.2475,
      "step": 9170
    },
    {
      "epoch": 42.89719626168224,
      "grad_norm": 0.3225122094154358,
      "learning_rate": 0.00044918715525183725,
      "loss": 2.2478,
      "step": 9180
    },
    {
      "epoch": 42.94392523364486,
      "grad_norm": 0.3526621162891388,
      "learning_rate": 0.00044907508676568573,
      "loss": 2.2297,
      "step": 9190
    },
    {
      "epoch": 42.99065420560748,
      "grad_norm": 0.34783175587654114,
      "learning_rate": 0.0004489629088439119,
      "loss": 2.2368,
      "step": 9200
    },
    {
      "epoch": 43.0,
      "eval_loss": 1.1381869316101074,
      "eval_runtime": 5.4496,
      "eval_samples_per_second": 3562.073,
      "eval_steps_per_second": 13.946,
      "step": 9202
    },
    {
      "epoch": 43.03738317757009,
      "grad_norm": 0.3330365717411041,
      "learning_rate": 0.0004488506215481822,
      "loss": 2.2316,
      "step": 9210
    },
    {
      "epoch": 43.08411214953271,
      "grad_norm": 0.3043118417263031,
      "learning_rate": 0.0004487382249402233,
      "loss": 2.2271,
      "step": 9220
    },
    {
      "epoch": 43.13084112149533,
      "grad_norm": 0.3364969789981842,
      "learning_rate": 0.00044862571908182194,
      "loss": 2.2303,
      "step": 9230
    },
    {
      "epoch": 43.177570093457945,
      "grad_norm": 0.3403140604496002,
      "learning_rate": 0.0004485131040348247,
      "loss": 2.2352,
      "step": 9240
    },
    {
      "epoch": 43.22429906542056,
      "grad_norm": 0.38647884130477905,
      "learning_rate": 0.0004484003798611385,
      "loss": 2.2268,
      "step": 9250
    },
    {
      "epoch": 43.271028037383175,
      "grad_norm": 0.34334835410118103,
      "learning_rate": 0.00044828754662273006,
      "loss": 2.2282,
      "step": 9260
    },
    {
      "epoch": 43.3177570093458,
      "grad_norm": 0.39360469579696655,
      "learning_rate": 0.00044817460438162615,
      "loss": 2.2417,
      "step": 9270
    },
    {
      "epoch": 43.36448598130841,
      "grad_norm": 0.32384663820266724,
      "learning_rate": 0.0004480615531999134,
      "loss": 2.2211,
      "step": 9280
    },
    {
      "epoch": 43.41121495327103,
      "grad_norm": 0.3265049457550049,
      "learning_rate": 0.00044794839313973836,
      "loss": 2.2415,
      "step": 9290
    },
    {
      "epoch": 43.45794392523364,
      "grad_norm": 0.3086414635181427,
      "learning_rate": 0.00044783512426330727,
      "loss": 2.2332,
      "step": 9300
    },
    {
      "epoch": 43.504672897196265,
      "grad_norm": 0.2982354164123535,
      "learning_rate": 0.00044772174663288653,
      "loss": 2.2288,
      "step": 9310
    },
    {
      "epoch": 43.55140186915888,
      "grad_norm": 0.3195591866970062,
      "learning_rate": 0.00044760826031080205,
      "loss": 2.2286,
      "step": 9320
    },
    {
      "epoch": 43.598130841121495,
      "grad_norm": 0.32853710651397705,
      "learning_rate": 0.0004474946653594395,
      "loss": 2.2293,
      "step": 9330
    },
    {
      "epoch": 43.64485981308411,
      "grad_norm": 0.2955547273159027,
      "learning_rate": 0.00044738096184124444,
      "loss": 2.2347,
      "step": 9340
    },
    {
      "epoch": 43.691588785046726,
      "grad_norm": 0.3107830286026001,
      "learning_rate": 0.000447267149818722,
      "loss": 2.2393,
      "step": 9350
    },
    {
      "epoch": 43.73831775700935,
      "grad_norm": 0.3421638607978821,
      "learning_rate": 0.0004471532293544369,
      "loss": 2.2448,
      "step": 9360
    },
    {
      "epoch": 43.78504672897196,
      "grad_norm": 0.3231862187385559,
      "learning_rate": 0.00044703920051101354,
      "loss": 2.2401,
      "step": 9370
    },
    {
      "epoch": 43.83177570093458,
      "grad_norm": 0.3353627324104309,
      "learning_rate": 0.00044692506335113595,
      "loss": 2.2236,
      "step": 9380
    },
    {
      "epoch": 43.87850467289719,
      "grad_norm": 0.3400309383869171,
      "learning_rate": 0.0004468108179375476,
      "loss": 2.2502,
      "step": 9390
    },
    {
      "epoch": 43.925233644859816,
      "grad_norm": 0.32150664925575256,
      "learning_rate": 0.00044669646433305156,
      "loss": 2.2351,
      "step": 9400
    },
    {
      "epoch": 43.97196261682243,
      "grad_norm": 0.31601566076278687,
      "learning_rate": 0.0004465820026005103,
      "loss": 2.2398,
      "step": 9410
    },
    {
      "epoch": 44.0,
      "eval_loss": 1.1359115839004517,
      "eval_runtime": 5.4824,
      "eval_samples_per_second": 3540.802,
      "eval_steps_per_second": 13.863,
      "step": 9416
    },
    {
      "epoch": 44.018691588785046,
      "grad_norm": 0.3223811686038971,
      "learning_rate": 0.00044646743280284573,
      "loss": 2.2281,
      "step": 9420
    },
    {
      "epoch": 44.06542056074766,
      "grad_norm": 0.3138440251350403,
      "learning_rate": 0.00044635275500303927,
      "loss": 2.231,
      "step": 9430
    },
    {
      "epoch": 44.11214953271028,
      "grad_norm": 0.3124805688858032,
      "learning_rate": 0.00044623796926413157,
      "loss": 2.2206,
      "step": 9440
    },
    {
      "epoch": 44.1588785046729,
      "grad_norm": 0.3349592387676239,
      "learning_rate": 0.0004461230756492227,
      "loss": 2.2263,
      "step": 9450
    },
    {
      "epoch": 44.205607476635514,
      "grad_norm": 0.30500558018684387,
      "learning_rate": 0.00044600807422147203,
      "loss": 2.2299,
      "step": 9460
    },
    {
      "epoch": 44.25233644859813,
      "grad_norm": 0.30244043469429016,
      "learning_rate": 0.0004458929650440982,
      "loss": 2.2311,
      "step": 9470
    },
    {
      "epoch": 44.299065420560744,
      "grad_norm": 0.32082173228263855,
      "learning_rate": 0.0004457777481803791,
      "loss": 2.2204,
      "step": 9480
    },
    {
      "epoch": 44.345794392523366,
      "grad_norm": 0.3321036100387573,
      "learning_rate": 0.0004456624236936516,
      "loss": 2.2214,
      "step": 9490
    },
    {
      "epoch": 44.39252336448598,
      "grad_norm": 0.3022514283657074,
      "learning_rate": 0.0004455469916473122,
      "loss": 2.2346,
      "step": 9500
    },
    {
      "epoch": 44.4392523364486,
      "grad_norm": 0.3791826665401459,
      "learning_rate": 0.00044543145210481597,
      "loss": 2.2288,
      "step": 9510
    },
    {
      "epoch": 44.48598130841121,
      "grad_norm": 0.33729273080825806,
      "learning_rate": 0.0004453158051296775,
      "loss": 2.243,
      "step": 9520
    },
    {
      "epoch": 44.532710280373834,
      "grad_norm": 0.32026734948158264,
      "learning_rate": 0.0004452000507854702,
      "loss": 2.2157,
      "step": 9530
    },
    {
      "epoch": 44.57943925233645,
      "grad_norm": 0.3176819682121277,
      "learning_rate": 0.00044508418913582673,
      "loss": 2.2233,
      "step": 9540
    },
    {
      "epoch": 44.626168224299064,
      "grad_norm": 0.32712092995643616,
      "learning_rate": 0.00044496822024443837,
      "loss": 2.2412,
      "step": 9550
    },
    {
      "epoch": 44.67289719626168,
      "grad_norm": 0.37173038721084595,
      "learning_rate": 0.00044485214417505577,
      "loss": 2.2386,
      "step": 9560
    },
    {
      "epoch": 44.7196261682243,
      "grad_norm": 0.42961767315864563,
      "learning_rate": 0.00044473596099148824,
      "loss": 2.2399,
      "step": 9570
    },
    {
      "epoch": 44.76635514018692,
      "grad_norm": 0.2998000979423523,
      "learning_rate": 0.000444619670757604,
      "loss": 2.2218,
      "step": 9580
    },
    {
      "epoch": 44.81308411214953,
      "grad_norm": 0.33175429701805115,
      "learning_rate": 0.0004445032735373302,
      "loss": 2.2387,
      "step": 9590
    },
    {
      "epoch": 44.85981308411215,
      "grad_norm": 0.3235989809036255,
      "learning_rate": 0.00044438676939465276,
      "loss": 2.2318,
      "step": 9600
    },
    {
      "epoch": 44.90654205607477,
      "grad_norm": 0.3606274127960205,
      "learning_rate": 0.0004442701583936164,
      "loss": 2.2383,
      "step": 9610
    },
    {
      "epoch": 44.953271028037385,
      "grad_norm": 0.31828707456588745,
      "learning_rate": 0.0004441534405983245,
      "loss": 2.2349,
      "step": 9620
    },
    {
      "epoch": 45.0,
      "grad_norm": 0.4529382586479187,
      "learning_rate": 0.0004440366160729392,
      "loss": 2.2281,
      "step": 9630
    },
    {
      "epoch": 45.0,
      "eval_loss": 1.1354084014892578,
      "eval_runtime": 5.4353,
      "eval_samples_per_second": 3571.488,
      "eval_steps_per_second": 13.983,
      "step": 9630
    },
    {
      "epoch": 45.046728971962615,
      "grad_norm": 0.3345908522605896,
      "learning_rate": 0.0004439196848816814,
      "loss": 2.2172,
      "step": 9640
    },
    {
      "epoch": 45.09345794392523,
      "grad_norm": 0.3272932767868042,
      "learning_rate": 0.00044380264708883047,
      "loss": 2.221,
      "step": 9650
    },
    {
      "epoch": 45.14018691588785,
      "grad_norm": 0.3184978663921356,
      "learning_rate": 0.00044368550275872444,
      "loss": 2.218,
      "step": 9660
    },
    {
      "epoch": 45.18691588785047,
      "grad_norm": 0.3215187191963196,
      "learning_rate": 0.00044356825195576,
      "loss": 2.2251,
      "step": 9670
    },
    {
      "epoch": 45.23364485981308,
      "grad_norm": 0.34485146403312683,
      "learning_rate": 0.00044345089474439236,
      "loss": 2.2224,
      "step": 9680
    },
    {
      "epoch": 45.2803738317757,
      "grad_norm": 0.47901737689971924,
      "learning_rate": 0.00044333343118913503,
      "loss": 2.2291,
      "step": 9690
    },
    {
      "epoch": 45.32710280373832,
      "grad_norm": 0.3195666968822479,
      "learning_rate": 0.00044321586135456016,
      "loss": 2.2181,
      "step": 9700
    },
    {
      "epoch": 45.373831775700936,
      "grad_norm": 0.3640119731426239,
      "learning_rate": 0.00044309818530529835,
      "loss": 2.2366,
      "step": 9710
    },
    {
      "epoch": 45.42056074766355,
      "grad_norm": 0.3337879478931427,
      "learning_rate": 0.0004429804031060384,
      "loss": 2.2314,
      "step": 9720
    },
    {
      "epoch": 45.467289719626166,
      "grad_norm": 0.35819002985954285,
      "learning_rate": 0.0004428625148215276,
      "loss": 2.2269,
      "step": 9730
    },
    {
      "epoch": 45.51401869158879,
      "grad_norm": 0.3483784794807434,
      "learning_rate": 0.00044274452051657165,
      "loss": 2.2256,
      "step": 9740
    },
    {
      "epoch": 45.5607476635514,
      "grad_norm": 0.3429171144962311,
      "learning_rate": 0.0004426264202560343,
      "loss": 2.2208,
      "step": 9750
    },
    {
      "epoch": 45.60747663551402,
      "grad_norm": 0.35952746868133545,
      "learning_rate": 0.00044250821410483774,
      "loss": 2.2247,
      "step": 9760
    },
    {
      "epoch": 45.654205607476634,
      "grad_norm": 0.32111117243766785,
      "learning_rate": 0.00044238990212796213,
      "loss": 2.2261,
      "step": 9770
    },
    {
      "epoch": 45.70093457943925,
      "grad_norm": 0.29660704731941223,
      "learning_rate": 0.0004422714843904463,
      "loss": 2.2277,
      "step": 9780
    },
    {
      "epoch": 45.74766355140187,
      "grad_norm": 0.3737069070339203,
      "learning_rate": 0.00044215296095738654,
      "loss": 2.2386,
      "step": 9790
    },
    {
      "epoch": 45.794392523364486,
      "grad_norm": 0.29507535696029663,
      "learning_rate": 0.0004420343318939378,
      "loss": 2.2315,
      "step": 9800
    },
    {
      "epoch": 45.8411214953271,
      "grad_norm": 0.380903035402298,
      "learning_rate": 0.00044191559726531276,
      "loss": 2.2315,
      "step": 9810
    },
    {
      "epoch": 45.88785046728972,
      "grad_norm": 0.3069706857204437,
      "learning_rate": 0.00044179675713678236,
      "loss": 2.2314,
      "step": 9820
    },
    {
      "epoch": 45.93457943925234,
      "grad_norm": 0.30013734102249146,
      "learning_rate": 0.00044167781157367536,
      "loss": 2.2282,
      "step": 9830
    },
    {
      "epoch": 45.981308411214954,
      "grad_norm": 0.28417351841926575,
      "learning_rate": 0.0004415587606413787,
      "loss": 2.2389,
      "step": 9840
    },
    {
      "epoch": 46.0,
      "eval_loss": 1.1359055042266846,
      "eval_runtime": 5.4471,
      "eval_samples_per_second": 3563.723,
      "eval_steps_per_second": 13.952,
      "step": 9844
    },
    {
      "epoch": 46.02803738317757,
      "grad_norm": 0.3110971450805664,
      "learning_rate": 0.00044143960440533694,
      "loss": 2.2308,
      "step": 9850
    },
    {
      "epoch": 46.074766355140184,
      "grad_norm": 0.343207448720932,
      "learning_rate": 0.00044132034293105273,
      "loss": 2.231,
      "step": 9860
    },
    {
      "epoch": 46.12149532710281,
      "grad_norm": 0.3946349322795868,
      "learning_rate": 0.00044120097628408644,
      "loss": 2.2068,
      "step": 9870
    },
    {
      "epoch": 46.16822429906542,
      "grad_norm": 0.3834485709667206,
      "learning_rate": 0.00044108150453005653,
      "loss": 2.2269,
      "step": 9880
    },
    {
      "epoch": 46.21495327102804,
      "grad_norm": 0.34137457609176636,
      "learning_rate": 0.00044096192773463897,
      "loss": 2.2224,
      "step": 9890
    },
    {
      "epoch": 46.26168224299065,
      "grad_norm": 0.341283917427063,
      "learning_rate": 0.0004408422459635675,
      "loss": 2.2192,
      "step": 9900
    },
    {
      "epoch": 46.308411214953274,
      "grad_norm": 0.3700546324253082,
      "learning_rate": 0.0004407224592826337,
      "loss": 2.2085,
      "step": 9910
    },
    {
      "epoch": 46.35514018691589,
      "grad_norm": 0.3258854150772095,
      "learning_rate": 0.0004406025677576866,
      "loss": 2.2366,
      "step": 9920
    },
    {
      "epoch": 46.401869158878505,
      "grad_norm": 0.3395386040210724,
      "learning_rate": 0.0004404825714546332,
      "loss": 2.2366,
      "step": 9930
    },
    {
      "epoch": 46.44859813084112,
      "grad_norm": 0.4083261489868164,
      "learning_rate": 0.00044036247043943775,
      "loss": 2.2315,
      "step": 9940
    },
    {
      "epoch": 46.495327102803735,
      "grad_norm": 0.3562439978122711,
      "learning_rate": 0.0004402422647781225,
      "loss": 2.2269,
      "step": 9950
    },
    {
      "epoch": 46.54205607476636,
      "grad_norm": 0.3343833088874817,
      "learning_rate": 0.0004401219545367665,
      "loss": 2.2273,
      "step": 9960
    },
    {
      "epoch": 46.58878504672897,
      "grad_norm": 0.3092317283153534,
      "learning_rate": 0.0004400015397815071,
      "loss": 2.2266,
      "step": 9970
    },
    {
      "epoch": 46.63551401869159,
      "grad_norm": 0.30529966950416565,
      "learning_rate": 0.00043988102057853864,
      "loss": 2.2265,
      "step": 9980
    },
    {
      "epoch": 46.6822429906542,
      "grad_norm": 0.31931573152542114,
      "learning_rate": 0.00043976039699411285,
      "loss": 2.2163,
      "step": 9990
    },
    {
      "epoch": 46.728971962616825,
      "grad_norm": 0.33519312739372253,
      "learning_rate": 0.00043963966909453913,
      "loss": 2.2292,
      "step": 10000
    },
    {
      "epoch": 46.77570093457944,
      "grad_norm": 0.3457014858722687,
      "learning_rate": 0.000439518836946184,
      "loss": 2.2335,
      "step": 10010
    },
    {
      "epoch": 46.822429906542055,
      "grad_norm": 0.30571454763412476,
      "learning_rate": 0.0004393979006154713,
      "loss": 2.2241,
      "step": 10020
    },
    {
      "epoch": 46.86915887850467,
      "grad_norm": 0.3685053884983063,
      "learning_rate": 0.00043927686016888225,
      "loss": 2.2131,
      "step": 10030
    },
    {
      "epoch": 46.91588785046729,
      "grad_norm": 0.3084897994995117,
      "learning_rate": 0.00043915571567295524,
      "loss": 2.2158,
      "step": 10040
    },
    {
      "epoch": 46.96261682242991,
      "grad_norm": 0.36691123247146606,
      "learning_rate": 0.00043903446719428585,
      "loss": 2.2466,
      "step": 10050
    },
    {
      "epoch": 47.0,
      "eval_loss": 1.1372073888778687,
      "eval_runtime": 5.5022,
      "eval_samples_per_second": 3528.017,
      "eval_steps_per_second": 13.813,
      "step": 10058
    },
    {
      "epoch": 47.00934579439252,
      "grad_norm": 0.2922113239765167,
      "learning_rate": 0.0004389131147995269,
      "loss": 2.2136,
      "step": 10060
    },
    {
      "epoch": 47.05607476635514,
      "grad_norm": 0.34315451979637146,
      "learning_rate": 0.0004387916585553881,
      "loss": 2.2156,
      "step": 10070
    },
    {
      "epoch": 47.10280373831776,
      "grad_norm": 0.35131365060806274,
      "learning_rate": 0.0004386700985286366,
      "loss": 2.2083,
      "step": 10080
    },
    {
      "epoch": 47.149532710280376,
      "grad_norm": 0.3714347779750824,
      "learning_rate": 0.0004385484347860963,
      "loss": 2.2208,
      "step": 10090
    },
    {
      "epoch": 47.19626168224299,
      "grad_norm": 0.32131657004356384,
      "learning_rate": 0.0004384266673946482,
      "loss": 2.2087,
      "step": 10100
    },
    {
      "epoch": 47.242990654205606,
      "grad_norm": 0.34774839878082275,
      "learning_rate": 0.0004383047964212305,
      "loss": 2.2169,
      "step": 10110
    },
    {
      "epoch": 47.28971962616822,
      "grad_norm": 0.3094159662723541,
      "learning_rate": 0.000438182821932838,
      "loss": 2.2307,
      "step": 10120
    },
    {
      "epoch": 47.33644859813084,
      "grad_norm": 0.3303214907646179,
      "learning_rate": 0.00043806074399652253,
      "loss": 2.2169,
      "step": 10130
    },
    {
      "epoch": 47.38317757009346,
      "grad_norm": 0.3170797526836395,
      "learning_rate": 0.0004379385626793929,
      "loss": 2.229,
      "step": 10140
    },
    {
      "epoch": 47.429906542056074,
      "grad_norm": 0.3075812757015228,
      "learning_rate": 0.0004378162780486147,
      "loss": 2.2063,
      "step": 10150
    },
    {
      "epoch": 47.47663551401869,
      "grad_norm": 0.4649501144886017,
      "learning_rate": 0.0004376938901714101,
      "loss": 2.219,
      "step": 10160
    },
    {
      "epoch": 47.52336448598131,
      "grad_norm": 0.3733213543891907,
      "learning_rate": 0.00043757139911505843,
      "loss": 2.219,
      "step": 10170
    },
    {
      "epoch": 47.570093457943926,
      "grad_norm": 0.3065469563007355,
      "learning_rate": 0.0004374488049468954,
      "loss": 2.2154,
      "step": 10180
    },
    {
      "epoch": 47.61682242990654,
      "grad_norm": 0.33687835931777954,
      "learning_rate": 0.0004373261077343135,
      "loss": 2.2325,
      "step": 10190
    },
    {
      "epoch": 47.66355140186916,
      "grad_norm": 0.3594226837158203,
      "learning_rate": 0.0004372033075447618,
      "loss": 2.2253,
      "step": 10200
    },
    {
      "epoch": 47.71028037383178,
      "grad_norm": 0.3166021406650543,
      "learning_rate": 0.00043708040444574627,
      "loss": 2.2211,
      "step": 10210
    },
    {
      "epoch": 47.757009345794394,
      "grad_norm": 0.3273668885231018,
      "learning_rate": 0.0004369573985048291,
      "loss": 2.2233,
      "step": 10220
    },
    {
      "epoch": 47.80373831775701,
      "grad_norm": 0.3048207759857178,
      "learning_rate": 0.00043683428978962913,
      "loss": 2.2303,
      "step": 10230
    },
    {
      "epoch": 47.850467289719624,
      "grad_norm": 0.3053796589374542,
      "learning_rate": 0.0004367110783678219,
      "loss": 2.2227,
      "step": 10240
    },
    {
      "epoch": 47.89719626168224,
      "grad_norm": 0.32380393147468567,
      "learning_rate": 0.0004365877643071391,
      "loss": 2.2249,
      "step": 10250
    },
    {
      "epoch": 47.94392523364486,
      "grad_norm": 0.3315986394882202,
      "learning_rate": 0.0004364643476753689,
      "loss": 2.224,
      "step": 10260
    },
    {
      "epoch": 47.99065420560748,
      "grad_norm": 0.3654508888721466,
      "learning_rate": 0.0004363408285403561,
      "loss": 2.2278,
      "step": 10270
    },
    {
      "epoch": 48.0,
      "eval_loss": 1.1367738246917725,
      "eval_runtime": 5.4721,
      "eval_samples_per_second": 3547.48,
      "eval_steps_per_second": 13.889,
      "step": 10272
    },
    {
      "epoch": 48.03738317757009,
      "grad_norm": 0.2982788383960724,
      "learning_rate": 0.00043621720697000155,
      "loss": 2.2086,
      "step": 10280
    },
    {
      "epoch": 48.08411214953271,
      "grad_norm": 0.29431185126304626,
      "learning_rate": 0.0004360934830322626,
      "loss": 2.2115,
      "step": 10290
    },
    {
      "epoch": 48.13084112149533,
      "grad_norm": 0.30826330184936523,
      "learning_rate": 0.0004359696567951529,
      "loss": 2.2309,
      "step": 10300
    },
    {
      "epoch": 48.177570093457945,
      "grad_norm": 0.3106282651424408,
      "learning_rate": 0.0004358457283267421,
      "loss": 2.2151,
      "step": 10310
    },
    {
      "epoch": 48.22429906542056,
      "grad_norm": 0.3308432698249817,
      "learning_rate": 0.00043572169769515623,
      "loss": 2.212,
      "step": 10320
    },
    {
      "epoch": 48.271028037383175,
      "grad_norm": 0.5286840200424194,
      "learning_rate": 0.0004355975649685775,
      "loss": 2.2186,
      "step": 10330
    },
    {
      "epoch": 48.3177570093458,
      "grad_norm": 0.3601107597351074,
      "learning_rate": 0.00043547333021524417,
      "loss": 2.2218,
      "step": 10340
    },
    {
      "epoch": 48.36448598130841,
      "grad_norm": 0.33316096663475037,
      "learning_rate": 0.0004353489935034506,
      "loss": 2.2268,
      "step": 10350
    },
    {
      "epoch": 48.41121495327103,
      "grad_norm": 0.3575665056705475,
      "learning_rate": 0.00043522455490154724,
      "loss": 2.2189,
      "step": 10360
    },
    {
      "epoch": 48.45794392523364,
      "grad_norm": 0.29465946555137634,
      "learning_rate": 0.00043510001447794044,
      "loss": 2.2115,
      "step": 10370
    },
    {
      "epoch": 48.504672897196265,
      "grad_norm": 0.34145447611808777,
      "learning_rate": 0.00043497537230109267,
      "loss": 2.2152,
      "step": 10380
    },
    {
      "epoch": 48.55140186915888,
      "grad_norm": 0.3435525894165039,
      "learning_rate": 0.0004348506284395223,
      "loss": 2.2203,
      "step": 10390
    },
    {
      "epoch": 48.598130841121495,
      "grad_norm": 0.35968834161758423,
      "learning_rate": 0.00043472578296180353,
      "loss": 2.222,
      "step": 10400
    },
    {
      "epoch": 48.64485981308411,
      "grad_norm": 0.2865586578845978,
      "learning_rate": 0.00043460083593656643,
      "loss": 2.2122,
      "step": 10410
    },
    {
      "epoch": 48.691588785046726,
      "grad_norm": 0.3210587501525879,
      "learning_rate": 0.00043447578743249695,
      "loss": 2.2078,
      "step": 10420
    },
    {
      "epoch": 48.73831775700935,
      "grad_norm": 0.3164716958999634,
      "learning_rate": 0.00043435063751833675,
      "loss": 2.2231,
      "step": 10430
    },
    {
      "epoch": 48.78504672897196,
      "grad_norm": 0.34770965576171875,
      "learning_rate": 0.00043422538626288333,
      "loss": 2.2146,
      "step": 10440
    },
    {
      "epoch": 48.83177570093458,
      "grad_norm": 0.300205796957016,
      "learning_rate": 0.0004341000337349898,
      "loss": 2.2095,
      "step": 10450
    },
    {
      "epoch": 48.87850467289719,
      "grad_norm": 0.3265537619590759,
      "learning_rate": 0.00043397458000356514,
      "loss": 2.2274,
      "step": 10460
    },
    {
      "epoch": 48.925233644859816,
      "grad_norm": 0.3382234275341034,
      "learning_rate": 0.00043384902513757376,
      "loss": 2.2358,
      "step": 10470
    },
    {
      "epoch": 48.97196261682243,
      "grad_norm": 0.3309827148914337,
      "learning_rate": 0.0004337233692060355,
      "loss": 2.2251,
      "step": 10480
    },
    {
      "epoch": 49.0,
      "eval_loss": 1.1364532709121704,
      "eval_runtime": 5.4366,
      "eval_samples_per_second": 3570.635,
      "eval_steps_per_second": 13.979,
      "step": 10486
    },
    {
      "epoch": 49.018691588785046,
      "grad_norm": 0.3426154851913452,
      "learning_rate": 0.00043359761227802627,
      "loss": 2.2106,
      "step": 10490
    },
    {
      "epoch": 49.06542056074766,
      "grad_norm": 0.3453778922557831,
      "learning_rate": 0.000433471754422677,
      "loss": 2.2082,
      "step": 10500
    },
    {
      "epoch": 49.11214953271028,
      "grad_norm": 0.4501333236694336,
      "learning_rate": 0.0004333457957091744,
      "loss": 2.2064,
      "step": 10510
    },
    {
      "epoch": 49.1588785046729,
      "grad_norm": 0.3532041013240814,
      "learning_rate": 0.0004332197362067607,
      "loss": 2.2133,
      "step": 10520
    },
    {
      "epoch": 49.205607476635514,
      "grad_norm": 0.36739620566368103,
      "learning_rate": 0.0004330935759847331,
      "loss": 2.1993,
      "step": 10530
    },
    {
      "epoch": 49.25233644859813,
      "grad_norm": 0.35837361216545105,
      "learning_rate": 0.0004329673151124445,
      "loss": 2.2187,
      "step": 10540
    },
    {
      "epoch": 49.299065420560744,
      "grad_norm": 0.34596025943756104,
      "learning_rate": 0.0004328409536593032,
      "loss": 2.1993,
      "step": 10550
    },
    {
      "epoch": 49.345794392523366,
      "grad_norm": 0.41743797063827515,
      "learning_rate": 0.0004327144916947725,
      "loss": 2.2141,
      "step": 10560
    },
    {
      "epoch": 49.39252336448598,
      "grad_norm": 0.3153827488422394,
      "learning_rate": 0.00043258792928837125,
      "loss": 2.223,
      "step": 10570
    },
    {
      "epoch": 49.4392523364486,
      "grad_norm": 0.31000086665153503,
      "learning_rate": 0.0004324612665096733,
      "loss": 2.2213,
      "step": 10580
    },
    {
      "epoch": 49.48598130841121,
      "grad_norm": 0.36041370034217834,
      "learning_rate": 0.0004323345034283078,
      "loss": 2.2202,
      "step": 10590
    },
    {
      "epoch": 49.532710280373834,
      "grad_norm": 0.36901259422302246,
      "learning_rate": 0.00043220764011395895,
      "loss": 2.2272,
      "step": 10600
    },
    {
      "epoch": 49.57943925233645,
      "grad_norm": 0.3491816222667694,
      "learning_rate": 0.0004320806766363661,
      "loss": 2.2106,
      "step": 10610
    },
    {
      "epoch": 49.626168224299064,
      "grad_norm": 0.4984137713909149,
      "learning_rate": 0.00043195361306532366,
      "loss": 2.2099,
      "step": 10620
    },
    {
      "epoch": 49.67289719626168,
      "grad_norm": 0.3254970610141754,
      "learning_rate": 0.00043182644947068106,
      "loss": 2.2197,
      "step": 10630
    },
    {
      "epoch": 49.7196261682243,
      "grad_norm": 0.3588390052318573,
      "learning_rate": 0.0004316991859223427,
      "loss": 2.2345,
      "step": 10640
    },
    {
      "epoch": 49.76635514018692,
      "grad_norm": 0.3259676694869995,
      "learning_rate": 0.00043157182249026796,
      "loss": 2.2292,
      "step": 10650
    },
    {
      "epoch": 49.81308411214953,
      "grad_norm": 0.3401186168193817,
      "learning_rate": 0.0004314443592444711,
      "loss": 2.2163,
      "step": 10660
    },
    {
      "epoch": 49.85981308411215,
      "grad_norm": 0.3597690165042877,
      "learning_rate": 0.0004313167962550213,
      "loss": 2.2091,
      "step": 10670
    },
    {
      "epoch": 49.90654205607477,
      "grad_norm": 0.3505052328109741,
      "learning_rate": 0.0004311891335920425,
      "loss": 2.2279,
      "step": 10680
    },
    {
      "epoch": 49.953271028037385,
      "grad_norm": 0.3315810263156891,
      "learning_rate": 0.0004310613713257134,
      "loss": 2.2179,
      "step": 10690
    },
    {
      "epoch": 50.0,
      "grad_norm": 0.7102012634277344,
      "learning_rate": 0.0004309335095262675,
      "loss": 2.2143,
      "step": 10700
    },
    {
      "epoch": 50.0,
      "eval_loss": 1.1372092962265015,
      "eval_runtime": 5.4688,
      "eval_samples_per_second": 3549.593,
      "eval_steps_per_second": 13.897,
      "step": 10700
    },
    {
      "epoch": 50.046728971962615,
      "grad_norm": 0.3542405962944031,
      "learning_rate": 0.0004308055482639932,
      "loss": 2.207,
      "step": 10710
    },
    {
      "epoch": 50.09345794392523,
      "grad_norm": 0.33717799186706543,
      "learning_rate": 0.0004306774876092333,
      "loss": 2.2186,
      "step": 10720
    },
    {
      "epoch": 50.14018691588785,
      "grad_norm": 0.3552630841732025,
      "learning_rate": 0.0004305493276323853,
      "loss": 2.2055,
      "step": 10730
    },
    {
      "epoch": 50.18691588785047,
      "grad_norm": 0.31152841448783875,
      "learning_rate": 0.0004304210684039014,
      "loss": 2.2146,
      "step": 10740
    },
    {
      "epoch": 50.23364485981308,
      "grad_norm": 0.38132351636886597,
      "learning_rate": 0.0004302927099942884,
      "loss": 2.2059,
      "step": 10750
    },
    {
      "epoch": 50.2803738317757,
      "grad_norm": 0.35489559173583984,
      "learning_rate": 0.0004301642524741073,
      "loss": 2.221,
      "step": 10760
    },
    {
      "epoch": 50.32710280373832,
      "grad_norm": 0.3607267439365387,
      "learning_rate": 0.00043003569591397396,
      "loss": 2.208,
      "step": 10770
    },
    {
      "epoch": 50.373831775700936,
      "grad_norm": 0.3854008615016937,
      "learning_rate": 0.00042990704038455853,
      "loss": 2.2036,
      "step": 10780
    },
    {
      "epoch": 50.42056074766355,
      "grad_norm": 0.3576991856098175,
      "learning_rate": 0.0004297782859565855,
      "loss": 2.2075,
      "step": 10790
    },
    {
      "epoch": 50.467289719626166,
      "grad_norm": 0.3419131934642792,
      "learning_rate": 0.0004296494327008339,
      "loss": 2.2112,
      "step": 10800
    },
    {
      "epoch": 50.51401869158879,
      "grad_norm": 0.3461242616176605,
      "learning_rate": 0.00042952048068813694,
      "loss": 2.2091,
      "step": 10810
    },
    {
      "epoch": 50.5607476635514,
      "grad_norm": 0.34985578060150146,
      "learning_rate": 0.0004293914299893821,
      "loss": 2.2148,
      "step": 10820
    },
    {
      "epoch": 50.60747663551402,
      "grad_norm": 0.3692241907119751,
      "learning_rate": 0.00042926228067551134,
      "loss": 2.2204,
      "step": 10830
    },
    {
      "epoch": 50.654205607476634,
      "grad_norm": 0.3141746520996094,
      "learning_rate": 0.0004291330328175204,
      "loss": 2.2254,
      "step": 10840
    },
    {
      "epoch": 50.70093457943925,
      "grad_norm": 0.4090614318847656,
      "learning_rate": 0.0004290036864864597,
      "loss": 2.2198,
      "step": 10850
    },
    {
      "epoch": 50.74766355140187,
      "grad_norm": 0.33641210198402405,
      "learning_rate": 0.0004288742417534334,
      "loss": 2.1987,
      "step": 10860
    },
    {
      "epoch": 50.794392523364486,
      "grad_norm": 0.3424046039581299,
      "learning_rate": 0.0004287446986896,
      "loss": 2.2172,
      "step": 10870
    },
    {
      "epoch": 50.8411214953271,
      "grad_norm": 0.3760378956794739,
      "learning_rate": 0.0004286150573661719,
      "loss": 2.2144,
      "step": 10880
    },
    {
      "epoch": 50.88785046728972,
      "grad_norm": 0.362077534198761,
      "learning_rate": 0.0004284853178544156,
      "loss": 2.2041,
      "step": 10890
    },
    {
      "epoch": 50.93457943925234,
      "grad_norm": 0.34612858295440674,
      "learning_rate": 0.00042835548022565145,
      "loss": 2.2179,
      "step": 10900
    },
    {
      "epoch": 50.981308411214954,
      "grad_norm": 0.3597710132598877,
      "learning_rate": 0.00042822554455125393,
      "loss": 2.2216,
      "step": 10910
    },
    {
      "epoch": 51.0,
      "eval_loss": 1.1369316577911377,
      "eval_runtime": 5.459,
      "eval_samples_per_second": 3555.957,
      "eval_steps_per_second": 13.922,
      "step": 10914
    },
    {
      "epoch": 51.02803738317757,
      "grad_norm": 0.3132410943508148,
      "learning_rate": 0.0004280955109026514,
      "loss": 2.2032,
      "step": 10920
    },
    {
      "epoch": 51.074766355140184,
      "grad_norm": 0.3261583149433136,
      "learning_rate": 0.0004279653793513258,
      "loss": 2.2059,
      "step": 10930
    },
    {
      "epoch": 51.12149532710281,
      "grad_norm": 0.3240729868412018,
      "learning_rate": 0.00042783514996881325,
      "loss": 2.2101,
      "step": 10940
    },
    {
      "epoch": 51.16822429906542,
      "grad_norm": 0.3813355565071106,
      "learning_rate": 0.0004277048228267034,
      "loss": 2.2044,
      "step": 10950
    },
    {
      "epoch": 51.21495327102804,
      "grad_norm": 0.37837424874305725,
      "learning_rate": 0.0004275743979966398,
      "loss": 2.1883,
      "step": 10960
    },
    {
      "epoch": 51.26168224299065,
      "grad_norm": 0.33585458993911743,
      "learning_rate": 0.0004274438755503195,
      "loss": 2.202,
      "step": 10970
    },
    {
      "epoch": 51.308411214953274,
      "grad_norm": 0.37441912293434143,
      "learning_rate": 0.0004273132555594935,
      "loss": 2.2124,
      "step": 10980
    },
    {
      "epoch": 51.35514018691589,
      "grad_norm": 0.3418252468109131,
      "learning_rate": 0.0004271825380959662,
      "loss": 2.2064,
      "step": 10990
    },
    {
      "epoch": 51.401869158878505,
      "grad_norm": 0.3394518196582794,
      "learning_rate": 0.00042705172323159567,
      "loss": 2.2088,
      "step": 11000
    },
    {
      "epoch": 51.44859813084112,
      "grad_norm": 0.3291361629962921,
      "learning_rate": 0.0004269208110382935,
      "loss": 2.2008,
      "step": 11010
    },
    {
      "epoch": 51.495327102803735,
      "grad_norm": 0.3065755367279053,
      "learning_rate": 0.00042678980158802464,
      "loss": 2.2144,
      "step": 11020
    },
    {
      "epoch": 51.54205607476636,
      "grad_norm": 0.3087327778339386,
      "learning_rate": 0.00042665869495280787,
      "loss": 2.2158,
      "step": 11030
    },
    {
      "epoch": 51.58878504672897,
      "grad_norm": 0.34364214539527893,
      "learning_rate": 0.0004265274912047151,
      "loss": 2.2255,
      "step": 11040
    },
    {
      "epoch": 51.63551401869159,
      "grad_norm": 0.33238109946250916,
      "learning_rate": 0.0004263961904158716,
      "loss": 2.2022,
      "step": 11050
    },
    {
      "epoch": 51.6822429906542,
      "grad_norm": 0.34823453426361084,
      "learning_rate": 0.0004262647926584561,
      "loss": 2.2175,
      "step": 11060
    },
    {
      "epoch": 51.728971962616825,
      "grad_norm": 0.33388563990592957,
      "learning_rate": 0.0004261332980047008,
      "loss": 2.2076,
      "step": 11070
    },
    {
      "epoch": 51.77570093457944,
      "grad_norm": 0.3130554258823395,
      "learning_rate": 0.0004260017065268908,
      "loss": 2.2165,
      "step": 11080
    },
    {
      "epoch": 51.822429906542055,
      "grad_norm": 0.35896065831184387,
      "learning_rate": 0.0004258700182973646,
      "loss": 2.2097,
      "step": 11090
    },
    {
      "epoch": 51.86915887850467,
      "grad_norm": 0.361197292804718,
      "learning_rate": 0.0004257382333885141,
      "loss": 2.2144,
      "step": 11100
    },
    {
      "epoch": 51.91588785046729,
      "grad_norm": 0.36605140566825867,
      "learning_rate": 0.00042560635187278387,
      "loss": 2.2128,
      "step": 11110
    },
    {
      "epoch": 51.96261682242991,
      "grad_norm": 0.3290224075317383,
      "learning_rate": 0.00042547437382267205,
      "loss": 2.1963,
      "step": 11120
    },
    {
      "epoch": 52.0,
      "eval_loss": 1.1368358135223389,
      "eval_runtime": 5.4837,
      "eval_samples_per_second": 3539.928,
      "eval_steps_per_second": 13.859,
      "step": 11128
    },
    {
      "epoch": 52.00934579439252,
      "grad_norm": 0.3390038311481476,
      "learning_rate": 0.0004253422993107297,
      "loss": 2.2094,
      "step": 11130
    },
    {
      "epoch": 52.05607476635514,
      "grad_norm": 0.338428795337677,
      "learning_rate": 0.0004252101284095606,
      "loss": 2.2032,
      "step": 11140
    },
    {
      "epoch": 52.10280373831776,
      "grad_norm": 0.35044512152671814,
      "learning_rate": 0.000425077861191822,
      "loss": 2.1996,
      "step": 11150
    },
    {
      "epoch": 52.149532710280376,
      "grad_norm": 0.3397638201713562,
      "learning_rate": 0.0004249454977302238,
      "loss": 2.2036,
      "step": 11160
    },
    {
      "epoch": 52.19626168224299,
      "grad_norm": 0.3813759386539459,
      "learning_rate": 0.00042481303809752905,
      "loss": 2.202,
      "step": 11170
    },
    {
      "epoch": 52.242990654205606,
      "grad_norm": 0.34647831320762634,
      "learning_rate": 0.00042468048236655326,
      "loss": 2.194,
      "step": 11180
    },
    {
      "epoch": 52.28971962616822,
      "grad_norm": 0.33599939942359924,
      "learning_rate": 0.0004245478306101652,
      "loss": 2.2137,
      "step": 11190
    },
    {
      "epoch": 52.33644859813084,
      "grad_norm": 0.3238208293914795,
      "learning_rate": 0.0004244150829012861,
      "loss": 2.198,
      "step": 11200
    },
    {
      "epoch": 52.38317757009346,
      "grad_norm": 0.3227531611919403,
      "learning_rate": 0.00042428223931289014,
      "loss": 2.2073,
      "step": 11210
    },
    {
      "epoch": 52.429906542056074,
      "grad_norm": 0.3756462037563324,
      "learning_rate": 0.000424149299918004,
      "loss": 2.2141,
      "step": 11220
    },
    {
      "epoch": 52.47663551401869,
      "grad_norm": 0.3458636403083801,
      "learning_rate": 0.00042401626478970745,
      "loss": 2.1972,
      "step": 11230
    },
    {
      "epoch": 52.52336448598131,
      "grad_norm": 0.40982311964035034,
      "learning_rate": 0.0004238831340011324,
      "loss": 2.201,
      "step": 11240
    },
    {
      "epoch": 52.570093457943926,
      "grad_norm": 0.36693817377090454,
      "learning_rate": 0.0004237499076254636,
      "loss": 2.2037,
      "step": 11250
    },
    {
      "epoch": 52.61682242990654,
      "grad_norm": 0.3368532657623291,
      "learning_rate": 0.0004236165857359383,
      "loss": 2.2077,
      "step": 11260
    },
    {
      "epoch": 52.66355140186916,
      "grad_norm": 0.3497203290462494,
      "learning_rate": 0.00042348316840584634,
      "loss": 2.2097,
      "step": 11270
    },
    {
      "epoch": 52.71028037383178,
      "grad_norm": 0.3315648138523102,
      "learning_rate": 0.00042334965570852974,
      "loss": 2.2062,
      "step": 11280
    },
    {
      "epoch": 52.757009345794394,
      "grad_norm": 0.3370130956172943,
      "learning_rate": 0.0004232160477173833,
      "loss": 2.2036,
      "step": 11290
    },
    {
      "epoch": 52.80373831775701,
      "grad_norm": 0.31375011801719666,
      "learning_rate": 0.000423082344505854,
      "loss": 2.2063,
      "step": 11300
    },
    {
      "epoch": 52.850467289719624,
      "grad_norm": 0.3255711793899536,
      "learning_rate": 0.0004229485461474412,
      "loss": 2.2145,
      "step": 11310
    },
    {
      "epoch": 52.89719626168224,
      "grad_norm": 0.3226207494735718,
      "learning_rate": 0.00042281465271569663,
      "loss": 2.2144,
      "step": 11320
    },
    {
      "epoch": 52.94392523364486,
      "grad_norm": 0.32272881269454956,
      "learning_rate": 0.00042268066428422413,
      "loss": 2.2111,
      "step": 11330
    },
    {
      "epoch": 52.99065420560748,
      "grad_norm": 0.3438210189342499,
      "learning_rate": 0.00042254658092668,
      "loss": 2.2154,
      "step": 11340
    },
    {
      "epoch": 53.0,
      "eval_loss": 1.1360068321228027,
      "eval_runtime": 5.4387,
      "eval_samples_per_second": 3569.262,
      "eval_steps_per_second": 13.974,
      "step": 11342
    },
    {
      "epoch": 53.03738317757009,
      "grad_norm": 0.3262684643268585,
      "learning_rate": 0.0004224124027167725,
      "loss": 2.1999,
      "step": 11350
    },
    {
      "epoch": 53.08411214953271,
      "grad_norm": 0.35236018896102905,
      "learning_rate": 0.0004222781297282622,
      "loss": 2.2012,
      "step": 11360
    },
    {
      "epoch": 53.13084112149533,
      "grad_norm": 0.34636256098747253,
      "learning_rate": 0.0004221437620349616,
      "loss": 2.1961,
      "step": 11370
    },
    {
      "epoch": 53.177570093457945,
      "grad_norm": 0.3495355546474457,
      "learning_rate": 0.00042200929971073533,
      "loss": 2.1962,
      "step": 11380
    },
    {
      "epoch": 53.22429906542056,
      "grad_norm": 0.34459447860717773,
      "learning_rate": 0.0004218747428295001,
      "loss": 2.2019,
      "step": 11390
    },
    {
      "epoch": 53.271028037383175,
      "grad_norm": 0.344494104385376,
      "learning_rate": 0.00042174009146522465,
      "loss": 2.2001,
      "step": 11400
    },
    {
      "epoch": 53.3177570093458,
      "grad_norm": 0.413901150226593,
      "learning_rate": 0.0004216053456919295,
      "loss": 2.1998,
      "step": 11410
    },
    {
      "epoch": 53.36448598130841,
      "grad_norm": 0.3418126702308655,
      "learning_rate": 0.0004214705055836871,
      "loss": 2.1986,
      "step": 11420
    },
    {
      "epoch": 53.41121495327103,
      "grad_norm": 0.3728121221065521,
      "learning_rate": 0.00042133557121462183,
      "loss": 2.1969,
      "step": 11430
    },
    {
      "epoch": 53.45794392523364,
      "grad_norm": 0.37986987829208374,
      "learning_rate": 0.00042120054265890993,
      "loss": 2.2171,
      "step": 11440
    },
    {
      "epoch": 53.504672897196265,
      "grad_norm": 0.36469072103500366,
      "learning_rate": 0.0004210654199907792,
      "loss": 2.2105,
      "step": 11450
    },
    {
      "epoch": 53.55140186915888,
      "grad_norm": 0.3202647566795349,
      "learning_rate": 0.0004209302032845095,
      "loss": 2.2187,
      "step": 11460
    },
    {
      "epoch": 53.598130841121495,
      "grad_norm": 0.34992754459381104,
      "learning_rate": 0.00042079489261443207,
      "loss": 2.1881,
      "step": 11470
    },
    {
      "epoch": 53.64485981308411,
      "grad_norm": 0.36006608605384827,
      "learning_rate": 0.00042065948805492995,
      "loss": 2.2045,
      "step": 11480
    },
    {
      "epoch": 53.691588785046726,
      "grad_norm": 0.35707956552505493,
      "learning_rate": 0.0004205239896804377,
      "loss": 2.2048,
      "step": 11490
    },
    {
      "epoch": 53.73831775700935,
      "grad_norm": 0.3601641356945038,
      "learning_rate": 0.0004203883975654418,
      "loss": 2.1956,
      "step": 11500
    },
    {
      "epoch": 53.78504672897196,
      "grad_norm": 0.357291579246521,
      "learning_rate": 0.00042025271178447964,
      "loss": 2.2119,
      "step": 11510
    },
    {
      "epoch": 53.83177570093458,
      "grad_norm": 0.36376112699508667,
      "learning_rate": 0.00042011693241214077,
      "loss": 2.1944,
      "step": 11520
    },
    {
      "epoch": 53.87850467289719,
      "grad_norm": 0.30719029903411865,
      "learning_rate": 0.00041998105952306566,
      "loss": 2.194,
      "step": 11530
    },
    {
      "epoch": 53.925233644859816,
      "grad_norm": 0.33939430117607117,
      "learning_rate": 0.0004198450931919465,
      "loss": 2.2087,
      "step": 11540
    },
    {
      "epoch": 53.97196261682243,
      "grad_norm": 0.31696680188179016,
      "learning_rate": 0.00041970903349352673,
      "loss": 2.2083,
      "step": 11550
    },
    {
      "epoch": 54.0,
      "eval_loss": 1.1366997957229614,
      "eval_runtime": 5.4354,
      "eval_samples_per_second": 3571.399,
      "eval_steps_per_second": 13.982,
      "step": 11556
    },
    {
      "epoch": 54.018691588785046,
      "grad_norm": 0.337300181388855,
      "learning_rate": 0.0004195728805026011,
      "loss": 2.2003,
      "step": 11560
    },
    {
      "epoch": 54.06542056074766,
      "grad_norm": 0.3388617932796478,
      "learning_rate": 0.00041943663429401567,
      "loss": 2.1968,
      "step": 11570
    },
    {
      "epoch": 54.11214953271028,
      "grad_norm": 0.3717207610607147,
      "learning_rate": 0.00041930029494266784,
      "loss": 2.1917,
      "step": 11580
    },
    {
      "epoch": 54.1588785046729,
      "grad_norm": 0.33408239483833313,
      "learning_rate": 0.000419163862523506,
      "loss": 2.207,
      "step": 11590
    },
    {
      "epoch": 54.205607476635514,
      "grad_norm": 0.3480214774608612,
      "learning_rate": 0.00041902733711153,
      "loss": 2.197,
      "step": 11600
    },
    {
      "epoch": 54.25233644859813,
      "grad_norm": 0.35860565304756165,
      "learning_rate": 0.00041889071878179043,
      "loss": 2.2024,
      "step": 11610
    },
    {
      "epoch": 54.299065420560744,
      "grad_norm": 0.3316735625267029,
      "learning_rate": 0.0004187540076093892,
      "loss": 2.2112,
      "step": 11620
    },
    {
      "epoch": 54.345794392523366,
      "grad_norm": 0.3588561415672302,
      "learning_rate": 0.0004186172036694794,
      "loss": 2.2124,
      "step": 11630
    },
    {
      "epoch": 54.39252336448598,
      "grad_norm": 0.3908441364765167,
      "learning_rate": 0.0004184803070372647,
      "loss": 2.1993,
      "step": 11640
    },
    {
      "epoch": 54.4392523364486,
      "grad_norm": 0.3052978217601776,
      "learning_rate": 0.00041834331778800013,
      "loss": 2.1933,
      "step": 11650
    },
    {
      "epoch": 54.48598130841121,
      "grad_norm": 0.3233652710914612,
      "learning_rate": 0.0004182062359969914,
      "loss": 2.1889,
      "step": 11660
    },
    {
      "epoch": 54.532710280373834,
      "grad_norm": 0.3378896117210388,
      "learning_rate": 0.0004180690617395951,
      "loss": 2.1948,
      "step": 11670
    },
    {
      "epoch": 54.57943925233645,
      "grad_norm": 0.3255598843097687,
      "learning_rate": 0.0004179317950912189,
      "loss": 2.2058,
      "step": 11680
    },
    {
      "epoch": 54.626168224299064,
      "grad_norm": 0.34470033645629883,
      "learning_rate": 0.0004177944361273208,
      "loss": 2.1989,
      "step": 11690
    },
    {
      "epoch": 54.67289719626168,
      "grad_norm": 0.344025194644928,
      "learning_rate": 0.0004176569849234101,
      "loss": 2.2037,
      "step": 11700
    },
    {
      "epoch": 54.7196261682243,
      "grad_norm": 0.31435200572013855,
      "learning_rate": 0.0004175194415550463,
      "loss": 2.1899,
      "step": 11710
    },
    {
      "epoch": 54.76635514018692,
      "grad_norm": 0.32383498549461365,
      "learning_rate": 0.0004173818060978399,
      "loss": 2.2058,
      "step": 11720
    },
    {
      "epoch": 54.81308411214953,
      "grad_norm": 0.335729718208313,
      "learning_rate": 0.00041724407862745176,
      "loss": 2.1927,
      "step": 11730
    },
    {
      "epoch": 54.85981308411215,
      "grad_norm": 0.35843074321746826,
      "learning_rate": 0.00041710625921959364,
      "loss": 2.2036,
      "step": 11740
    },
    {
      "epoch": 54.90654205607477,
      "grad_norm": 0.3635815382003784,
      "learning_rate": 0.0004169683479500277,
      "loss": 2.1977,
      "step": 11750
    },
    {
      "epoch": 54.953271028037385,
      "grad_norm": 0.3670791983604431,
      "learning_rate": 0.0004168303448945664,
      "loss": 2.1865,
      "step": 11760
    },
    {
      "epoch": 55.0,
      "grad_norm": 0.5791473388671875,
      "learning_rate": 0.0004166922501290729,
      "loss": 2.1948,
      "step": 11770
    },
    {
      "epoch": 55.0,
      "eval_loss": 1.1368680000305176,
      "eval_runtime": 5.4576,
      "eval_samples_per_second": 3556.877,
      "eval_steps_per_second": 13.926,
      "step": 11770
    },
    {
      "epoch": 55.046728971962615,
      "grad_norm": 0.4064651131629944,
      "learning_rate": 0.0004165540637294608,
      "loss": 2.1855,
      "step": 11780
    },
    {
      "epoch": 55.09345794392523,
      "grad_norm": 0.32014715671539307,
      "learning_rate": 0.00041641578577169376,
      "loss": 2.1987,
      "step": 11790
    },
    {
      "epoch": 55.14018691588785,
      "grad_norm": 0.4055517613887787,
      "learning_rate": 0.00041627741633178616,
      "loss": 2.1982,
      "step": 11800
    },
    {
      "epoch": 55.18691588785047,
      "grad_norm": 0.31567683815956116,
      "learning_rate": 0.0004161389554858024,
      "loss": 2.1828,
      "step": 11810
    },
    {
      "epoch": 55.23364485981308,
      "grad_norm": 0.3504120111465454,
      "learning_rate": 0.0004160004033098572,
      "loss": 2.1897,
      "step": 11820
    },
    {
      "epoch": 55.2803738317757,
      "grad_norm": 0.35644736886024475,
      "learning_rate": 0.00041586175988011576,
      "loss": 2.2055,
      "step": 11830
    },
    {
      "epoch": 55.32710280373832,
      "grad_norm": 0.3135136663913727,
      "learning_rate": 0.0004157230252727928,
      "loss": 2.1957,
      "step": 11840
    },
    {
      "epoch": 55.373831775700936,
      "grad_norm": 0.3469143211841583,
      "learning_rate": 0.0004155841995641539,
      "loss": 2.186,
      "step": 11850
    },
    {
      "epoch": 55.42056074766355,
      "grad_norm": 0.3358757197856903,
      "learning_rate": 0.0004154452828305142,
      "loss": 2.1995,
      "step": 11860
    },
    {
      "epoch": 55.467289719626166,
      "grad_norm": 0.34082093834877014,
      "learning_rate": 0.00041530627514823904,
      "loss": 2.197,
      "step": 11870
    },
    {
      "epoch": 55.51401869158879,
      "grad_norm": 0.3290681540966034,
      "learning_rate": 0.00041516717659374384,
      "loss": 2.1762,
      "step": 11880
    },
    {
      "epoch": 55.5607476635514,
      "grad_norm": 0.34355026483535767,
      "learning_rate": 0.0004150279872434938,
      "loss": 2.1859,
      "step": 11890
    },
    {
      "epoch": 55.60747663551402,
      "grad_norm": 0.33859983086586,
      "learning_rate": 0.0004148887071740043,
      "loss": 2.2046,
      "step": 11900
    },
    {
      "epoch": 55.654205607476634,
      "grad_norm": 0.3693384826183319,
      "learning_rate": 0.00041474933646184033,
      "loss": 2.1971,
      "step": 11910
    },
    {
      "epoch": 55.70093457943925,
      "grad_norm": 0.37364909052848816,
      "learning_rate": 0.0004146098751836167,
      "loss": 2.2092,
      "step": 11920
    },
    {
      "epoch": 55.74766355140187,
      "grad_norm": 0.3519187867641449,
      "learning_rate": 0.0004144703234159983,
      "loss": 2.1971,
      "step": 11930
    },
    {
      "epoch": 55.794392523364486,
      "grad_norm": 0.3103635907173157,
      "learning_rate": 0.0004143306812356995,
      "loss": 2.1874,
      "step": 11940
    },
    {
      "epoch": 55.8411214953271,
      "grad_norm": 0.3648460805416107,
      "learning_rate": 0.0004141909487194844,
      "loss": 2.2028,
      "step": 11950
    },
    {
      "epoch": 55.88785046728972,
      "grad_norm": 0.3161962628364563,
      "learning_rate": 0.0004140511259441669,
      "loss": 2.2014,
      "step": 11960
    },
    {
      "epoch": 55.93457943925234,
      "grad_norm": 0.31622201204299927,
      "learning_rate": 0.00041391121298661027,
      "loss": 2.2127,
      "step": 11970
    },
    {
      "epoch": 55.981308411214954,
      "grad_norm": 0.3499284088611603,
      "learning_rate": 0.00041377120992372766,
      "loss": 2.202,
      "step": 11980
    },
    {
      "epoch": 56.0,
      "eval_loss": 1.1382960081100464,
      "eval_runtime": 5.451,
      "eval_samples_per_second": 3561.159,
      "eval_steps_per_second": 13.942,
      "step": 11984
    },
    {
      "epoch": 56.02803738317757,
      "grad_norm": 0.3196955621242523,
      "learning_rate": 0.00041363111683248154,
      "loss": 2.1993,
      "step": 11990
    },
    {
      "epoch": 56.074766355140184,
      "grad_norm": 0.36129093170166016,
      "learning_rate": 0.0004134909337898839,
      "loss": 2.1838,
      "step": 12000
    },
    {
      "epoch": 56.12149532710281,
      "grad_norm": 0.343750923871994,
      "learning_rate": 0.00041335066087299635,
      "loss": 2.1846,
      "step": 12010
    },
    {
      "epoch": 56.16822429906542,
      "grad_norm": 0.3689565062522888,
      "learning_rate": 0.0004132102981589295,
      "loss": 2.1854,
      "step": 12020
    },
    {
      "epoch": 56.21495327102804,
      "grad_norm": 0.34870028495788574,
      "learning_rate": 0.00041306984572484385,
      "loss": 2.192,
      "step": 12030
    },
    {
      "epoch": 56.26168224299065,
      "grad_norm": 0.346640020608902,
      "learning_rate": 0.0004129293036479488,
      "loss": 2.1742,
      "step": 12040
    },
    {
      "epoch": 56.308411214953274,
      "grad_norm": 0.3570249378681183,
      "learning_rate": 0.00041278867200550325,
      "loss": 2.2031,
      "step": 12050
    },
    {
      "epoch": 56.35514018691589,
      "grad_norm": 0.32561248540878296,
      "learning_rate": 0.00041264795087481523,
      "loss": 2.2007,
      "step": 12060
    },
    {
      "epoch": 56.401869158878505,
      "grad_norm": 0.3363415002822876,
      "learning_rate": 0.00041250714033324204,
      "loss": 2.1985,
      "step": 12070
    },
    {
      "epoch": 56.44859813084112,
      "grad_norm": 0.3345460593700409,
      "learning_rate": 0.0004123662404581901,
      "loss": 2.2066,
      "step": 12080
    },
    {
      "epoch": 56.495327102803735,
      "grad_norm": 0.36265140771865845,
      "learning_rate": 0.000412225251327115,
      "loss": 2.1918,
      "step": 12090
    },
    {
      "epoch": 56.54205607476636,
      "grad_norm": 0.3511081337928772,
      "learning_rate": 0.0004120841730175211,
      "loss": 2.1905,
      "step": 12100
    },
    {
      "epoch": 56.58878504672897,
      "grad_norm": 0.36001431941986084,
      "learning_rate": 0.0004119430056069623,
      "loss": 2.1834,
      "step": 12110
    },
    {
      "epoch": 56.63551401869159,
      "grad_norm": 0.3462922275066376,
      "learning_rate": 0.00041180174917304104,
      "loss": 2.193,
      "step": 12120
    },
    {
      "epoch": 56.6822429906542,
      "grad_norm": 0.37305793166160583,
      "learning_rate": 0.0004116604037934089,
      "loss": 2.1874,
      "step": 12130
    },
    {
      "epoch": 56.728971962616825,
      "grad_norm": 0.33375850319862366,
      "learning_rate": 0.0004115189695457663,
      "loss": 2.1962,
      "step": 12140
    },
    {
      "epoch": 56.77570093457944,
      "grad_norm": 0.3798513412475586,
      "learning_rate": 0.00041137744650786246,
      "loss": 2.1933,
      "step": 12150
    },
    {
      "epoch": 56.822429906542055,
      "grad_norm": 0.3302529752254486,
      "learning_rate": 0.0004112358347574955,
      "loss": 2.194,
      "step": 12160
    },
    {
      "epoch": 56.86915887850467,
      "grad_norm": 0.36836180090904236,
      "learning_rate": 0.00041109413437251244,
      "loss": 2.1953,
      "step": 12170
    },
    {
      "epoch": 56.91588785046729,
      "grad_norm": 0.3554365932941437,
      "learning_rate": 0.0004109523454308086,
      "loss": 2.1957,
      "step": 12180
    },
    {
      "epoch": 56.96261682242991,
      "grad_norm": 0.34392210841178894,
      "learning_rate": 0.0004108104680103284,
      "loss": 2.1932,
      "step": 12190
    },
    {
      "epoch": 57.0,
      "eval_loss": 1.136492133140564,
      "eval_runtime": 5.4876,
      "eval_samples_per_second": 3537.457,
      "eval_steps_per_second": 13.85,
      "step": 12198
    },
    {
      "epoch": 57.00934579439252,
      "grad_norm": 0.3289449214935303,
      "learning_rate": 0.0004106685021890647,
      "loss": 2.1929,
      "step": 12200
    },
    {
      "epoch": 57.05607476635514,
      "grad_norm": 0.3770798146724701,
      "learning_rate": 0.000410526448045059,
      "loss": 2.177,
      "step": 12210
    },
    {
      "epoch": 57.10280373831776,
      "grad_norm": 0.3726472854614258,
      "learning_rate": 0.00041038430565640147,
      "loss": 2.1756,
      "step": 12220
    },
    {
      "epoch": 57.149532710280376,
      "grad_norm": 0.35137423872947693,
      "learning_rate": 0.00041024207510123047,
      "loss": 2.1793,
      "step": 12230
    },
    {
      "epoch": 57.19626168224299,
      "grad_norm": 0.3413963317871094,
      "learning_rate": 0.00041009975645773313,
      "loss": 2.1892,
      "step": 12240
    },
    {
      "epoch": 57.242990654205606,
      "grad_norm": 0.35001710057258606,
      "learning_rate": 0.00040995734980414487,
      "loss": 2.1855,
      "step": 12250
    },
    {
      "epoch": 57.28971962616822,
      "grad_norm": 0.35872581601142883,
      "learning_rate": 0.0004098148552187496,
      "loss": 2.1813,
      "step": 12260
    },
    {
      "epoch": 57.33644859813084,
      "grad_norm": 0.3498048186302185,
      "learning_rate": 0.0004096722727798794,
      "loss": 2.188,
      "step": 12270
    },
    {
      "epoch": 57.38317757009346,
      "grad_norm": 0.33586129546165466,
      "learning_rate": 0.00040952960256591476,
      "loss": 2.1934,
      "step": 12280
    },
    {
      "epoch": 57.429906542056074,
      "grad_norm": 0.3534131348133087,
      "learning_rate": 0.0004093868446552844,
      "loss": 2.2004,
      "step": 12290
    },
    {
      "epoch": 57.47663551401869,
      "grad_norm": 0.32343634963035583,
      "learning_rate": 0.00040924399912646526,
      "loss": 2.1824,
      "step": 12300
    },
    {
      "epoch": 57.52336448598131,
      "grad_norm": 0.3330478072166443,
      "learning_rate": 0.00040910106605798237,
      "loss": 2.1853,
      "step": 12310
    },
    {
      "epoch": 57.570093457943926,
      "grad_norm": 0.35581740736961365,
      "learning_rate": 0.00040895804552840907,
      "loss": 2.1999,
      "step": 12320
    },
    {
      "epoch": 57.61682242990654,
      "grad_norm": 0.3570280373096466,
      "learning_rate": 0.00040881493761636657,
      "loss": 2.189,
      "step": 12330
    },
    {
      "epoch": 57.66355140186916,
      "grad_norm": 0.3281659483909607,
      "learning_rate": 0.0004086717424005242,
      "loss": 2.1978,
      "step": 12340
    },
    {
      "epoch": 57.71028037383178,
      "grad_norm": 0.38190338015556335,
      "learning_rate": 0.00040852845995959923,
      "loss": 2.1926,
      "step": 12350
    },
    {
      "epoch": 57.757009345794394,
      "grad_norm": 0.3479519784450531,
      "learning_rate": 0.0004083850903723571,
      "loss": 2.2103,
      "step": 12360
    },
    {
      "epoch": 57.80373831775701,
      "grad_norm": 0.3787253499031067,
      "learning_rate": 0.00040824163371761083,
      "loss": 2.1999,
      "step": 12370
    },
    {
      "epoch": 57.850467289719624,
      "grad_norm": 0.3424779176712036,
      "learning_rate": 0.0004080980900742215,
      "loss": 2.181,
      "step": 12380
    },
    {
      "epoch": 57.89719626168224,
      "grad_norm": 0.34377408027648926,
      "learning_rate": 0.0004079544595210979,
      "loss": 2.1984,
      "step": 12390
    },
    {
      "epoch": 57.94392523364486,
      "grad_norm": 0.32989469170570374,
      "learning_rate": 0.00040781074213719684,
      "loss": 2.1825,
      "step": 12400
    },
    {
      "epoch": 57.99065420560748,
      "grad_norm": 0.34061941504478455,
      "learning_rate": 0.00040766693800152253,
      "loss": 2.1972,
      "step": 12410
    },
    {
      "epoch": 58.0,
      "eval_loss": 1.1371654272079468,
      "eval_runtime": 5.4475,
      "eval_samples_per_second": 3563.437,
      "eval_steps_per_second": 13.951,
      "step": 12412
    },
    {
      "epoch": 58.03738317757009,
      "grad_norm": 0.3749999701976776,
      "learning_rate": 0.0004075230471931271,
      "loss": 2.174,
      "step": 12420
    },
    {
      "epoch": 58.08411214953271,
      "grad_norm": 0.3292592465877533,
      "learning_rate": 0.00040737906979111026,
      "loss": 2.173,
      "step": 12430
    },
    {
      "epoch": 58.13084112149533,
      "grad_norm": 0.33945322036743164,
      "learning_rate": 0.00040723500587461925,
      "loss": 2.1786,
      "step": 12440
    },
    {
      "epoch": 58.177570093457945,
      "grad_norm": 0.38593795895576477,
      "learning_rate": 0.00040709085552284905,
      "loss": 2.1813,
      "step": 12450
    },
    {
      "epoch": 58.22429906542056,
      "grad_norm": 0.37863433361053467,
      "learning_rate": 0.0004069466188150419,
      "loss": 2.1833,
      "step": 12460
    },
    {
      "epoch": 58.271028037383175,
      "grad_norm": 0.3701658248901367,
      "learning_rate": 0.0004068022958304877,
      "loss": 2.1856,
      "step": 12470
    },
    {
      "epoch": 58.3177570093458,
      "grad_norm": 0.3407420217990875,
      "learning_rate": 0.00040665788664852375,
      "loss": 2.1853,
      "step": 12480
    },
    {
      "epoch": 58.36448598130841,
      "grad_norm": 0.3837825357913971,
      "learning_rate": 0.00040651339134853474,
      "loss": 2.191,
      "step": 12490
    },
    {
      "epoch": 58.41121495327103,
      "grad_norm": 0.34621134400367737,
      "learning_rate": 0.0004063688100099526,
      "loss": 2.1845,
      "step": 12500
    },
    {
      "epoch": 58.45794392523364,
      "grad_norm": 0.3169669508934021,
      "learning_rate": 0.00040622414271225673,
      "loss": 2.1946,
      "step": 12510
    },
    {
      "epoch": 58.504672897196265,
      "grad_norm": 0.33663809299468994,
      "learning_rate": 0.0004060793895349736,
      "loss": 2.1858,
      "step": 12520
    },
    {
      "epoch": 58.55140186915888,
      "grad_norm": 0.3448336720466614,
      "learning_rate": 0.000405934550557677,
      "loss": 2.1797,
      "step": 12530
    },
    {
      "epoch": 58.598130841121495,
      "grad_norm": 0.3514650762081146,
      "learning_rate": 0.0004057896258599878,
      "loss": 2.1832,
      "step": 12540
    },
    {
      "epoch": 58.64485981308411,
      "grad_norm": 0.33504995703697205,
      "learning_rate": 0.00040564461552157423,
      "loss": 2.1812,
      "step": 12550
    },
    {
      "epoch": 58.691588785046726,
      "grad_norm": 0.35764825344085693,
      "learning_rate": 0.00040549951962215127,
      "loss": 2.1895,
      "step": 12560
    },
    {
      "epoch": 58.73831775700935,
      "grad_norm": 0.33892297744750977,
      "learning_rate": 0.00040535433824148107,
      "loss": 2.1813,
      "step": 12570
    },
    {
      "epoch": 58.78504672897196,
      "grad_norm": 0.37874728441238403,
      "learning_rate": 0.00040520907145937283,
      "loss": 2.1901,
      "step": 12580
    },
    {
      "epoch": 58.83177570093458,
      "grad_norm": 0.33467307686805725,
      "learning_rate": 0.00040506371935568276,
      "loss": 2.1849,
      "step": 12590
    },
    {
      "epoch": 58.87850467289719,
      "grad_norm": 0.35101285576820374,
      "learning_rate": 0.0004049182820103137,
      "loss": 2.1828,
      "step": 12600
    },
    {
      "epoch": 58.925233644859816,
      "grad_norm": 0.31534188985824585,
      "learning_rate": 0.00040477275950321555,
      "loss": 2.2071,
      "step": 12610
    },
    {
      "epoch": 58.97196261682243,
      "grad_norm": 0.3427104651927948,
      "learning_rate": 0.00040462715191438506,
      "loss": 2.1997,
      "step": 12620
    },
    {
      "epoch": 59.0,
      "eval_loss": 1.1385810375213623,
      "eval_runtime": 5.4464,
      "eval_samples_per_second": 3564.207,
      "eval_steps_per_second": 13.954,
      "step": 12626
    },
    {
      "epoch": 59.018691588785046,
      "grad_norm": 0.3341100513935089,
      "learning_rate": 0.0004044814593238656,
      "loss": 2.1825,
      "step": 12630
    },
    {
      "epoch": 59.06542056074766,
      "grad_norm": 0.31783902645111084,
      "learning_rate": 0.0004043356818117474,
      "loss": 2.1721,
      "step": 12640
    },
    {
      "epoch": 59.11214953271028,
      "grad_norm": 0.37653878331184387,
      "learning_rate": 0.00040418981945816734,
      "loss": 2.1709,
      "step": 12650
    },
    {
      "epoch": 59.1588785046729,
      "grad_norm": 0.36866071820259094,
      "learning_rate": 0.0004040438723433089,
      "loss": 2.1806,
      "step": 12660
    },
    {
      "epoch": 59.205607476635514,
      "grad_norm": 0.33560630679130554,
      "learning_rate": 0.0004038978405474022,
      "loss": 2.1829,
      "step": 12670
    },
    {
      "epoch": 59.25233644859813,
      "grad_norm": 0.37220001220703125,
      "learning_rate": 0.0004037517241507238,
      "loss": 2.168,
      "step": 12680
    },
    {
      "epoch": 59.299065420560744,
      "grad_norm": 0.38030052185058594,
      "learning_rate": 0.00040360552323359693,
      "loss": 2.1909,
      "step": 12690
    },
    {
      "epoch": 59.345794392523366,
      "grad_norm": 0.33881044387817383,
      "learning_rate": 0.0004034592378763912,
      "loss": 2.1861,
      "step": 12700
    },
    {
      "epoch": 59.39252336448598,
      "grad_norm": 0.3640865087509155,
      "learning_rate": 0.0004033128681595227,
      "loss": 2.188,
      "step": 12710
    },
    {
      "epoch": 59.4392523364486,
      "grad_norm": 0.33782830834388733,
      "learning_rate": 0.0004031664141634537,
      "loss": 2.1854,
      "step": 12720
    },
    {
      "epoch": 59.48598130841121,
      "grad_norm": 0.43451663851737976,
      "learning_rate": 0.000403019875968693,
      "loss": 2.1778,
      "step": 12730
    },
    {
      "epoch": 59.532710280373834,
      "grad_norm": 0.3472479581832886,
      "learning_rate": 0.00040287325365579563,
      "loss": 2.1655,
      "step": 12740
    },
    {
      "epoch": 59.57943925233645,
      "grad_norm": 0.31195294857025146,
      "learning_rate": 0.0004027265473053629,
      "loss": 2.1749,
      "step": 12750
    },
    {
      "epoch": 59.626168224299064,
      "grad_norm": 0.34751108288764954,
      "learning_rate": 0.0004025797569980422,
      "loss": 2.1833,
      "step": 12760
    },
    {
      "epoch": 59.67289719626168,
      "grad_norm": 0.3487350046634674,
      "learning_rate": 0.00040243288281452725,
      "loss": 2.1783,
      "step": 12770
    },
    {
      "epoch": 59.7196261682243,
      "grad_norm": 0.3260658383369446,
      "learning_rate": 0.0004022859248355576,
      "loss": 2.1803,
      "step": 12780
    },
    {
      "epoch": 59.76635514018692,
      "grad_norm": 0.35130080580711365,
      "learning_rate": 0.00040213888314191926,
      "loss": 2.1885,
      "step": 12790
    },
    {
      "epoch": 59.81308411214953,
      "grad_norm": 0.3896926939487457,
      "learning_rate": 0.0004019917578144439,
      "loss": 2.1912,
      "step": 12800
    },
    {
      "epoch": 59.85981308411215,
      "grad_norm": 0.333520770072937,
      "learning_rate": 0.00040184454893400925,
      "loss": 2.1923,
      "step": 12810
    },
    {
      "epoch": 59.90654205607477,
      "grad_norm": 0.3274613320827484,
      "learning_rate": 0.0004016972565815391,
      "loss": 2.1927,
      "step": 12820
    },
    {
      "epoch": 59.953271028037385,
      "grad_norm": 0.32234153151512146,
      "learning_rate": 0.00040154988083800314,
      "loss": 2.1848,
      "step": 12830
    },
    {
      "epoch": 60.0,
      "grad_norm": 0.6622810959815979,
      "learning_rate": 0.00040140242178441667,
      "loss": 2.1988,
      "step": 12840
    },
    {
      "epoch": 60.0,
      "eval_loss": 1.137873649597168,
      "eval_runtime": 5.4801,
      "eval_samples_per_second": 3542.269,
      "eval_steps_per_second": 13.868,
      "step": 12840
    },
    {
      "epoch": 60.046728971962615,
      "grad_norm": 0.3600875735282898,
      "learning_rate": 0.000401254879501841,
      "loss": 2.1666,
      "step": 12850
    },
    {
      "epoch": 60.09345794392523,
      "grad_norm": 0.34812721610069275,
      "learning_rate": 0.0004011072540713832,
      "loss": 2.1715,
      "step": 12860
    },
    {
      "epoch": 60.14018691588785,
      "grad_norm": 0.3322165608406067,
      "learning_rate": 0.0004009595455741957,
      "loss": 2.1794,
      "step": 12870
    },
    {
      "epoch": 60.18691588785047,
      "grad_norm": 0.4572766423225403,
      "learning_rate": 0.00040081175409147714,
      "loss": 2.1784,
      "step": 12880
    },
    {
      "epoch": 60.23364485981308,
      "grad_norm": 0.41693517565727234,
      "learning_rate": 0.0004006638797044714,
      "loss": 2.1748,
      "step": 12890
    },
    {
      "epoch": 60.2803738317757,
      "grad_norm": 0.36619219183921814,
      "learning_rate": 0.000400515922494468,
      "loss": 2.1789,
      "step": 12900
    },
    {
      "epoch": 60.32710280373832,
      "grad_norm": 0.35561224818229675,
      "learning_rate": 0.0004003678825428021,
      "loss": 2.1869,
      "step": 12910
    },
    {
      "epoch": 60.373831775700936,
      "grad_norm": 0.3480245769023895,
      "learning_rate": 0.00040021975993085424,
      "loss": 2.175,
      "step": 12920
    },
    {
      "epoch": 60.42056074766355,
      "grad_norm": 0.34395238757133484,
      "learning_rate": 0.00040007155474005034,
      "loss": 2.1713,
      "step": 12930
    },
    {
      "epoch": 60.467289719626166,
      "grad_norm": 0.37800896167755127,
      "learning_rate": 0.000399923267051862,
      "loss": 2.1747,
      "step": 12940
    },
    {
      "epoch": 60.51401869158879,
      "grad_norm": 0.42791876196861267,
      "learning_rate": 0.0003997748969478059,
      "loss": 2.1953,
      "step": 12950
    },
    {
      "epoch": 60.5607476635514,
      "grad_norm": 0.4518051743507385,
      "learning_rate": 0.00039962644450944394,
      "loss": 2.1746,
      "step": 12960
    },
    {
      "epoch": 60.60747663551402,
      "grad_norm": 0.3204897940158844,
      "learning_rate": 0.0003994779098183837,
      "loss": 2.1809,
      "step": 12970
    },
    {
      "epoch": 60.654205607476634,
      "grad_norm": 0.3371317982673645,
      "learning_rate": 0.00039932929295627753,
      "loss": 2.1702,
      "step": 12980
    },
    {
      "epoch": 60.70093457943925,
      "grad_norm": 0.3261183798313141,
      "learning_rate": 0.0003991805940048232,
      "loss": 2.1862,
      "step": 12990
    },
    {
      "epoch": 60.74766355140187,
      "grad_norm": 0.3426361382007599,
      "learning_rate": 0.00039903181304576363,
      "loss": 2.1726,
      "step": 13000
    },
    {
      "epoch": 60.794392523364486,
      "grad_norm": 0.34261947870254517,
      "learning_rate": 0.00039888295016088653,
      "loss": 2.1935,
      "step": 13010
    },
    {
      "epoch": 60.8411214953271,
      "grad_norm": 0.3422120213508606,
      "learning_rate": 0.0003987340054320251,
      "loss": 2.1839,
      "step": 13020
    },
    {
      "epoch": 60.88785046728972,
      "grad_norm": 0.3157326281070709,
      "learning_rate": 0.0003985849789410572,
      "loss": 2.1935,
      "step": 13030
    },
    {
      "epoch": 60.93457943925234,
      "grad_norm": 0.3383270800113678,
      "learning_rate": 0.0003984358707699056,
      "loss": 2.1858,
      "step": 13040
    },
    {
      "epoch": 60.981308411214954,
      "grad_norm": 0.3697813153266907,
      "learning_rate": 0.0003982866810005382,
      "loss": 2.1816,
      "step": 13050
    },
    {
      "epoch": 61.0,
      "eval_loss": 1.136031150817871,
      "eval_runtime": 5.4415,
      "eval_samples_per_second": 3567.392,
      "eval_steps_per_second": 13.967,
      "step": 13054
    },
    {
      "epoch": 61.02803738317757,
      "grad_norm": 0.33278951048851013,
      "learning_rate": 0.00039813740971496764,
      "loss": 2.163,
      "step": 13060
    },
    {
      "epoch": 61.074766355140184,
      "grad_norm": 0.3713251054286957,
      "learning_rate": 0.00039798805699525134,
      "loss": 2.1582,
      "step": 13070
    },
    {
      "epoch": 61.12149532710281,
      "grad_norm": 0.33818739652633667,
      "learning_rate": 0.0003978386229234917,
      "loss": 2.1536,
      "step": 13080
    },
    {
      "epoch": 61.16822429906542,
      "grad_norm": 0.35006657242774963,
      "learning_rate": 0.00039768910758183543,
      "loss": 2.1602,
      "step": 13090
    },
    {
      "epoch": 61.21495327102804,
      "grad_norm": 0.34133344888687134,
      "learning_rate": 0.0003975395110524742,
      "loss": 2.1796,
      "step": 13100
    },
    {
      "epoch": 61.26168224299065,
      "grad_norm": 0.3480820953845978,
      "learning_rate": 0.00039738983341764436,
      "loss": 2.1752,
      "step": 13110
    },
    {
      "epoch": 61.308411214953274,
      "grad_norm": 0.3486025631427765,
      "learning_rate": 0.00039724007475962675,
      "loss": 2.1877,
      "step": 13120
    },
    {
      "epoch": 61.35514018691589,
      "grad_norm": 0.34120041131973267,
      "learning_rate": 0.0003970902351607466,
      "loss": 2.1628,
      "step": 13130
    },
    {
      "epoch": 61.401869158878505,
      "grad_norm": 0.40527647733688354,
      "learning_rate": 0.000396940314703374,
      "loss": 2.1648,
      "step": 13140
    },
    {
      "epoch": 61.44859813084112,
      "grad_norm": 0.3561726212501526,
      "learning_rate": 0.0003967903134699231,
      "loss": 2.1766,
      "step": 13150
    },
    {
      "epoch": 61.495327102803735,
      "grad_norm": 0.3729025423526764,
      "learning_rate": 0.00039664023154285273,
      "loss": 2.1905,
      "step": 13160
    },
    {
      "epoch": 61.54205607476636,
      "grad_norm": 0.36460962891578674,
      "learning_rate": 0.0003964900690046659,
      "loss": 2.1816,
      "step": 13170
    },
    {
      "epoch": 61.58878504672897,
      "grad_norm": 0.35404250025749207,
      "learning_rate": 0.00039633982593791,
      "loss": 2.1742,
      "step": 13180
    },
    {
      "epoch": 61.63551401869159,
      "grad_norm": 0.3481828272342682,
      "learning_rate": 0.0003961895024251768,
      "loss": 2.1795,
      "step": 13190
    },
    {
      "epoch": 61.6822429906542,
      "grad_norm": 0.33165550231933594,
      "learning_rate": 0.00039603909854910214,
      "loss": 2.175,
      "step": 13200
    },
    {
      "epoch": 61.728971962616825,
      "grad_norm": 0.3598918616771698,
      "learning_rate": 0.00039588861439236603,
      "loss": 2.1586,
      "step": 13210
    },
    {
      "epoch": 61.77570093457944,
      "grad_norm": 0.36932024359703064,
      "learning_rate": 0.00039573805003769276,
      "loss": 2.1787,
      "step": 13220
    },
    {
      "epoch": 61.822429906542055,
      "grad_norm": 0.34138572216033936,
      "learning_rate": 0.00039558740556785055,
      "loss": 2.1866,
      "step": 13230
    },
    {
      "epoch": 61.86915887850467,
      "grad_norm": 0.3765456974506378,
      "learning_rate": 0.0003954366810656518,
      "loss": 2.176,
      "step": 13240
    },
    {
      "epoch": 61.91588785046729,
      "grad_norm": 0.3224269449710846,
      "learning_rate": 0.00039528587661395275,
      "loss": 2.1895,
      "step": 13250
    },
    {
      "epoch": 61.96261682242991,
      "grad_norm": 0.3203040361404419,
      "learning_rate": 0.00039513499229565374,
      "loss": 2.1722,
      "step": 13260
    },
    {
      "epoch": 62.0,
      "eval_loss": 1.1375054121017456,
      "eval_runtime": 5.4659,
      "eval_samples_per_second": 3551.479,
      "eval_steps_per_second": 13.904,
      "step": 13268
    },
    {
      "epoch": 62.00934579439252,
      "grad_norm": 0.3369012176990509,
      "learning_rate": 0.0003949840281936989,
      "loss": 2.1772,
      "step": 13270
    },
    {
      "epoch": 62.05607476635514,
      "grad_norm": 0.35430046916007996,
      "learning_rate": 0.00039483298439107627,
      "loss": 2.1721,
      "step": 13280
    },
    {
      "epoch": 62.10280373831776,
      "grad_norm": 0.356946736574173,
      "learning_rate": 0.00039468186097081783,
      "loss": 2.1708,
      "step": 13290
    },
    {
      "epoch": 62.149532710280376,
      "grad_norm": 0.3733263909816742,
      "learning_rate": 0.0003945306580159989,
      "loss": 2.1714,
      "step": 13300
    },
    {
      "epoch": 62.19626168224299,
      "grad_norm": 0.3494679629802704,
      "learning_rate": 0.00039437937560973915,
      "loss": 2.1619,
      "step": 13310
    },
    {
      "epoch": 62.242990654205606,
      "grad_norm": 0.40148958563804626,
      "learning_rate": 0.00039422801383520137,
      "loss": 2.1834,
      "step": 13320
    },
    {
      "epoch": 62.28971962616822,
      "grad_norm": 0.36309927701950073,
      "learning_rate": 0.0003940765727755923,
      "loss": 2.1781,
      "step": 13330
    },
    {
      "epoch": 62.33644859813084,
      "grad_norm": 0.34692060947418213,
      "learning_rate": 0.00039392505251416207,
      "loss": 2.1726,
      "step": 13340
    },
    {
      "epoch": 62.38317757009346,
      "grad_norm": 0.3664485812187195,
      "learning_rate": 0.00039377345313420457,
      "loss": 2.1722,
      "step": 13350
    },
    {
      "epoch": 62.429906542056074,
      "grad_norm": 0.45534592866897583,
      "learning_rate": 0.000393621774719057,
      "loss": 2.1727,
      "step": 13360
    },
    {
      "epoch": 62.47663551401869,
      "grad_norm": 0.3688468635082245,
      "learning_rate": 0.00039347001735210016,
      "loss": 2.1593,
      "step": 13370
    },
    {
      "epoch": 62.52336448598131,
      "grad_norm": 0.3898508548736572,
      "learning_rate": 0.000393318181116758,
      "loss": 2.175,
      "step": 13380
    },
    {
      "epoch": 62.570093457943926,
      "grad_norm": 0.34888577461242676,
      "learning_rate": 0.00039316626609649816,
      "loss": 2.1724,
      "step": 13390
    },
    {
      "epoch": 62.61682242990654,
      "grad_norm": 0.3535788059234619,
      "learning_rate": 0.0003930142723748312,
      "loss": 2.1677,
      "step": 13400
    },
    {
      "epoch": 62.66355140186916,
      "grad_norm": 0.35192498564720154,
      "learning_rate": 0.00039286220003531135,
      "loss": 2.169,
      "step": 13410
    },
    {
      "epoch": 62.71028037383178,
      "grad_norm": 0.36232760548591614,
      "learning_rate": 0.00039271004916153584,
      "loss": 2.1591,
      "step": 13420
    },
    {
      "epoch": 62.757009345794394,
      "grad_norm": 0.3691021800041199,
      "learning_rate": 0.000392557819837145,
      "loss": 2.1835,
      "step": 13430
    },
    {
      "epoch": 62.80373831775701,
      "grad_norm": 0.37907689809799194,
      "learning_rate": 0.0003924055121458224,
      "loss": 2.1713,
      "step": 13440
    },
    {
      "epoch": 62.850467289719624,
      "grad_norm": 0.3626268208026886,
      "learning_rate": 0.00039225312617129483,
      "loss": 2.1832,
      "step": 13450
    },
    {
      "epoch": 62.89719626168224,
      "grad_norm": 0.3761035203933716,
      "learning_rate": 0.0003921006619973318,
      "loss": 2.1661,
      "step": 13460
    },
    {
      "epoch": 62.94392523364486,
      "grad_norm": 0.36577609181404114,
      "learning_rate": 0.00039194811970774603,
      "loss": 2.1753,
      "step": 13470
    },
    {
      "epoch": 62.99065420560748,
      "grad_norm": 0.36439868807792664,
      "learning_rate": 0.00039179549938639304,
      "loss": 2.1803,
      "step": 13480
    },
    {
      "epoch": 63.0,
      "eval_loss": 1.1376467943191528,
      "eval_runtime": 5.4549,
      "eval_samples_per_second": 3558.653,
      "eval_steps_per_second": 13.932,
      "step": 13482
    },
    {
      "epoch": 63.03738317757009,
      "grad_norm": 0.37699395418167114,
      "learning_rate": 0.00039164280111717145,
      "loss": 2.158,
      "step": 13490
    },
    {
      "epoch": 63.08411214953271,
      "grad_norm": 0.3977215886116028,
      "learning_rate": 0.0003914900249840224,
      "loss": 2.157,
      "step": 13500
    },
    {
      "epoch": 63.13084112149533,
      "grad_norm": 0.380647212266922,
      "learning_rate": 0.00039133717107093033,
      "loss": 2.1532,
      "step": 13510
    },
    {
      "epoch": 63.177570093457945,
      "grad_norm": 0.4008066952228546,
      "learning_rate": 0.00039118423946192196,
      "loss": 2.1685,
      "step": 13520
    },
    {
      "epoch": 63.22429906542056,
      "grad_norm": 0.4014066457748413,
      "learning_rate": 0.0003910312302410668,
      "loss": 2.1722,
      "step": 13530
    },
    {
      "epoch": 63.271028037383175,
      "grad_norm": 0.3658851981163025,
      "learning_rate": 0.0003908781434924774,
      "loss": 2.1813,
      "step": 13540
    },
    {
      "epoch": 63.3177570093458,
      "grad_norm": 0.37645697593688965,
      "learning_rate": 0.00039072497930030844,
      "loss": 2.1667,
      "step": 13550
    },
    {
      "epoch": 63.36448598130841,
      "grad_norm": 0.38575613498687744,
      "learning_rate": 0.0003905717377487575,
      "loss": 2.1764,
      "step": 13560
    },
    {
      "epoch": 63.41121495327103,
      "grad_norm": 0.36620721220970154,
      "learning_rate": 0.00039041841892206453,
      "loss": 2.1637,
      "step": 13570
    },
    {
      "epoch": 63.45794392523364,
      "grad_norm": 0.36230581998825073,
      "learning_rate": 0.00039026502290451205,
      "loss": 2.1731,
      "step": 13580
    },
    {
      "epoch": 63.504672897196265,
      "grad_norm": 0.38195082545280457,
      "learning_rate": 0.00039011154978042486,
      "loss": 2.1703,
      "step": 13590
    },
    {
      "epoch": 63.55140186915888,
      "grad_norm": 0.37471482157707214,
      "learning_rate": 0.00038995799963417044,
      "loss": 2.1648,
      "step": 13600
    },
    {
      "epoch": 63.598130841121495,
      "grad_norm": 0.36657214164733887,
      "learning_rate": 0.0003898043725501582,
      "loss": 2.1727,
      "step": 13610
    },
    {
      "epoch": 63.64485981308411,
      "grad_norm": 0.35531342029571533,
      "learning_rate": 0.0003896506686128403,
      "loss": 2.1766,
      "step": 13620
    },
    {
      "epoch": 63.691588785046726,
      "grad_norm": 0.39151641726493835,
      "learning_rate": 0.0003894968879067108,
      "loss": 2.1514,
      "step": 13630
    },
    {
      "epoch": 63.73831775700935,
      "grad_norm": 0.35295993089675903,
      "learning_rate": 0.00038934303051630606,
      "loss": 2.1651,
      "step": 13640
    },
    {
      "epoch": 63.78504672897196,
      "grad_norm": 0.40212276577949524,
      "learning_rate": 0.0003891890965262046,
      "loss": 2.1634,
      "step": 13650
    },
    {
      "epoch": 63.83177570093458,
      "grad_norm": 0.38230979442596436,
      "learning_rate": 0.00038903508602102714,
      "loss": 2.1815,
      "step": 13660
    },
    {
      "epoch": 63.87850467289719,
      "grad_norm": 0.34279340505599976,
      "learning_rate": 0.0003888809990854364,
      "loss": 2.1731,
      "step": 13670
    },
    {
      "epoch": 63.925233644859816,
      "grad_norm": 0.3872416615486145,
      "learning_rate": 0.00038872683580413705,
      "loss": 2.1677,
      "step": 13680
    },
    {
      "epoch": 63.97196261682243,
      "grad_norm": 0.352154016494751,
      "learning_rate": 0.00038857259626187576,
      "loss": 2.1806,
      "step": 13690
    },
    {
      "epoch": 64.0,
      "eval_loss": 1.1367781162261963,
      "eval_runtime": 5.4882,
      "eval_samples_per_second": 3537.024,
      "eval_steps_per_second": 13.848,
      "step": 13696
    },
    {
      "epoch": 64.01869158878505,
      "grad_norm": 0.3658446967601776,
      "learning_rate": 0.0003884182805434412,
      "loss": 2.1655,
      "step": 13700
    },
    {
      "epoch": 64.06542056074767,
      "grad_norm": 0.370023638010025,
      "learning_rate": 0.00038826388873366383,
      "loss": 2.1551,
      "step": 13710
    },
    {
      "epoch": 64.11214953271028,
      "grad_norm": 0.3416748046875,
      "learning_rate": 0.0003881094209174159,
      "loss": 2.1512,
      "step": 13720
    },
    {
      "epoch": 64.1588785046729,
      "grad_norm": 0.37650322914123535,
      "learning_rate": 0.00038795487717961164,
      "loss": 2.1675,
      "step": 13730
    },
    {
      "epoch": 64.20560747663552,
      "grad_norm": 0.35769662261009216,
      "learning_rate": 0.00038780025760520675,
      "loss": 2.1574,
      "step": 13740
    },
    {
      "epoch": 64.25233644859813,
      "grad_norm": 0.3552079200744629,
      "learning_rate": 0.0003876455622791989,
      "loss": 2.1486,
      "step": 13750
    },
    {
      "epoch": 64.29906542056075,
      "grad_norm": 0.3787502944469452,
      "learning_rate": 0.00038749079128662714,
      "loss": 2.1685,
      "step": 13760
    },
    {
      "epoch": 64.34579439252336,
      "grad_norm": 0.37631261348724365,
      "learning_rate": 0.00038733594471257227,
      "loss": 2.1575,
      "step": 13770
    },
    {
      "epoch": 64.39252336448598,
      "grad_norm": 0.3771452307701111,
      "learning_rate": 0.0003871810226421566,
      "loss": 2.1535,
      "step": 13780
    },
    {
      "epoch": 64.4392523364486,
      "grad_norm": 0.3713497221469879,
      "learning_rate": 0.00038702602516054385,
      "loss": 2.1737,
      "step": 13790
    },
    {
      "epoch": 64.48598130841121,
      "grad_norm": 0.40906381607055664,
      "learning_rate": 0.00038687095235293955,
      "loss": 2.1749,
      "step": 13800
    },
    {
      "epoch": 64.53271028037383,
      "grad_norm": 0.3595314621925354,
      "learning_rate": 0.0003867158043045901,
      "loss": 2.17,
      "step": 13810
    },
    {
      "epoch": 64.57943925233644,
      "grad_norm": 0.3405967056751251,
      "learning_rate": 0.00038656058110078363,
      "loss": 2.1676,
      "step": 13820
    },
    {
      "epoch": 64.62616822429906,
      "grad_norm": 0.3518694043159485,
      "learning_rate": 0.0003864052828268495,
      "loss": 2.1644,
      "step": 13830
    },
    {
      "epoch": 64.67289719626169,
      "grad_norm": 0.3519951105117798,
      "learning_rate": 0.00038624990956815833,
      "loss": 2.1603,
      "step": 13840
    },
    {
      "epoch": 64.7196261682243,
      "grad_norm": 0.3608461916446686,
      "learning_rate": 0.00038609446141012194,
      "loss": 2.1607,
      "step": 13850
    },
    {
      "epoch": 64.76635514018692,
      "grad_norm": 0.31969472765922546,
      "learning_rate": 0.00038593893843819337,
      "loss": 2.1616,
      "step": 13860
    },
    {
      "epoch": 64.81308411214954,
      "grad_norm": 0.31424686312675476,
      "learning_rate": 0.0003857833407378668,
      "loss": 2.1601,
      "step": 13870
    },
    {
      "epoch": 64.85981308411215,
      "grad_norm": 0.3475174903869629,
      "learning_rate": 0.0003856276683946773,
      "loss": 2.1846,
      "step": 13880
    },
    {
      "epoch": 64.90654205607477,
      "grad_norm": 0.3453793227672577,
      "learning_rate": 0.0003854719214942013,
      "loss": 2.1705,
      "step": 13890
    },
    {
      "epoch": 64.95327102803738,
      "grad_norm": 0.3374801576137543,
      "learning_rate": 0.0003853161001220559,
      "loss": 2.1758,
      "step": 13900
    },
    {
      "epoch": 65.0,
      "grad_norm": 0.5578538775444031,
      "learning_rate": 0.0003851602043638994,
      "loss": 2.1777,
      "step": 13910
    },
    {
      "epoch": 65.0,
      "eval_loss": 1.1406446695327759,
      "eval_runtime": 5.5179,
      "eval_samples_per_second": 3517.99,
      "eval_steps_per_second": 13.773,
      "step": 13910
    },
    {
      "epoch": 65.0,
      "step": 13910,
      "total_flos": 1.9209303677730816e+16,
      "train_loss": 2.4721874834906705,
      "train_runtime": 3957.8506,
      "train_samples_per_second": 5526.282,
      "train_steps_per_second": 10.814
    }
  ],
  "logging_steps": 10,
  "max_steps": 42800,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 200,
  "save_steps": 1000,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 20,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 20
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.9209303677730816e+16,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
