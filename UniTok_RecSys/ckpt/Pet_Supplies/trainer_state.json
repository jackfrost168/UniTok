{
  "best_metric": 1.0782898664474487,
  "best_model_checkpoint": "./ckpt/Pet_Supplies/checkpoint-10560",
  "epoch": 75.0,
  "eval_steps": 1000,
  "global_step": 14400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.052083333333333336,
      "grad_norm": 11.756708145141602,
      "learning_rate": 1.3020833333333334e-05,
      "loss": 21.5624,
      "step": 10
    },
    {
      "epoch": 0.10416666666666667,
      "grad_norm": 7.755390167236328,
      "learning_rate": 2.604166666666667e-05,
      "loss": 20.1177,
      "step": 20
    },
    {
      "epoch": 0.15625,
      "grad_norm": 4.436103343963623,
      "learning_rate": 3.90625e-05,
      "loss": 18.272,
      "step": 30
    },
    {
      "epoch": 0.20833333333333334,
      "grad_norm": 3.975264549255371,
      "learning_rate": 5.208333333333334e-05,
      "loss": 16.7876,
      "step": 40
    },
    {
      "epoch": 0.2604166666666667,
      "grad_norm": 3.811800479888916,
      "learning_rate": 6.510416666666668e-05,
      "loss": 15.1392,
      "step": 50
    },
    {
      "epoch": 0.3125,
      "grad_norm": 3.2901203632354736,
      "learning_rate": 7.8125e-05,
      "loss": 13.1456,
      "step": 60
    },
    {
      "epoch": 0.3645833333333333,
      "grad_norm": 2.5465104579925537,
      "learning_rate": 9.114583333333332e-05,
      "loss": 11.1404,
      "step": 70
    },
    {
      "epoch": 0.4166666666666667,
      "grad_norm": 1.988466739654541,
      "learning_rate": 0.00010416666666666667,
      "loss": 9.3979,
      "step": 80
    },
    {
      "epoch": 0.46875,
      "grad_norm": 1.6544533967971802,
      "learning_rate": 0.0001171875,
      "loss": 8.2911,
      "step": 90
    },
    {
      "epoch": 0.5208333333333334,
      "grad_norm": 1.4983010292053223,
      "learning_rate": 0.00013020833333333336,
      "loss": 7.4664,
      "step": 100
    },
    {
      "epoch": 0.5729166666666666,
      "grad_norm": 1.3232109546661377,
      "learning_rate": 0.00014322916666666667,
      "loss": 6.9551,
      "step": 110
    },
    {
      "epoch": 0.625,
      "grad_norm": 1.230577826499939,
      "learning_rate": 0.00015625,
      "loss": 6.5025,
      "step": 120
    },
    {
      "epoch": 0.6770833333333334,
      "grad_norm": 1.081268548965454,
      "learning_rate": 0.00016927083333333334,
      "loss": 6.1605,
      "step": 130
    },
    {
      "epoch": 0.7291666666666666,
      "grad_norm": 1.0110411643981934,
      "learning_rate": 0.00018229166666666665,
      "loss": 5.9838,
      "step": 140
    },
    {
      "epoch": 0.78125,
      "grad_norm": 0.9438450336456299,
      "learning_rate": 0.0001953125,
      "loss": 5.8294,
      "step": 150
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 0.8706321716308594,
      "learning_rate": 0.00020833333333333335,
      "loss": 5.6765,
      "step": 160
    },
    {
      "epoch": 0.8854166666666666,
      "grad_norm": 0.8066859841346741,
      "learning_rate": 0.00022135416666666666,
      "loss": 5.5933,
      "step": 170
    },
    {
      "epoch": 0.9375,
      "grad_norm": 0.8059171438217163,
      "learning_rate": 0.000234375,
      "loss": 5.5012,
      "step": 180
    },
    {
      "epoch": 0.9895833333333334,
      "grad_norm": 0.7667565941810608,
      "learning_rate": 0.00024739583333333335,
      "loss": 5.3908,
      "step": 190
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.5400452613830566,
      "eval_runtime": 5.673,
      "eval_samples_per_second": 3500.099,
      "eval_steps_per_second": 13.749,
      "step": 192
    },
    {
      "epoch": 1.0416666666666667,
      "grad_norm": 0.7188822627067566,
      "learning_rate": 0.0002604166666666667,
      "loss": 5.3764,
      "step": 200
    },
    {
      "epoch": 1.09375,
      "grad_norm": 0.7649931311607361,
      "learning_rate": 0.0002734375,
      "loss": 5.2701,
      "step": 210
    },
    {
      "epoch": 1.1458333333333333,
      "grad_norm": 0.7197499871253967,
      "learning_rate": 0.00028645833333333333,
      "loss": 5.1428,
      "step": 220
    },
    {
      "epoch": 1.1979166666666667,
      "grad_norm": 0.8631341457366943,
      "learning_rate": 0.0002994791666666667,
      "loss": 5.1008,
      "step": 230
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.6888325214385986,
      "learning_rate": 0.0003125,
      "loss": 5.0231,
      "step": 240
    },
    {
      "epoch": 1.3020833333333333,
      "grad_norm": 0.6495670080184937,
      "learning_rate": 0.0003255208333333333,
      "loss": 4.9495,
      "step": 250
    },
    {
      "epoch": 1.3541666666666667,
      "grad_norm": 0.5919005274772644,
      "learning_rate": 0.0003385416666666667,
      "loss": 4.8705,
      "step": 260
    },
    {
      "epoch": 1.40625,
      "grad_norm": 0.6787846684455872,
      "learning_rate": 0.0003515625,
      "loss": 4.8154,
      "step": 270
    },
    {
      "epoch": 1.4583333333333333,
      "grad_norm": 0.9442359805107117,
      "learning_rate": 0.0003645833333333333,
      "loss": 4.7137,
      "step": 280
    },
    {
      "epoch": 1.5104166666666665,
      "grad_norm": 0.6184521913528442,
      "learning_rate": 0.0003776041666666667,
      "loss": 4.6401,
      "step": 290
    },
    {
      "epoch": 1.5625,
      "grad_norm": 0.564786434173584,
      "learning_rate": 0.000390625,
      "loss": 4.586,
      "step": 300
    },
    {
      "epoch": 1.6145833333333335,
      "grad_norm": 0.5786031484603882,
      "learning_rate": 0.00040364583333333333,
      "loss": 4.52,
      "step": 310
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.5193225741386414,
      "learning_rate": 0.0004166666666666667,
      "loss": 4.4577,
      "step": 320
    },
    {
      "epoch": 1.71875,
      "grad_norm": 0.5196457505226135,
      "learning_rate": 0.0004296875,
      "loss": 4.4041,
      "step": 330
    },
    {
      "epoch": 1.7708333333333335,
      "grad_norm": 0.5683116316795349,
      "learning_rate": 0.0004427083333333333,
      "loss": 4.3505,
      "step": 340
    },
    {
      "epoch": 1.8229166666666665,
      "grad_norm": 0.5754044651985168,
      "learning_rate": 0.0004557291666666667,
      "loss": 4.2863,
      "step": 350
    },
    {
      "epoch": 1.875,
      "grad_norm": 0.4418111741542816,
      "learning_rate": 0.00046875,
      "loss": 4.2064,
      "step": 360
    },
    {
      "epoch": 1.9270833333333335,
      "grad_norm": 0.5373986959457397,
      "learning_rate": 0.00048177083333333335,
      "loss": 4.1143,
      "step": 370
    },
    {
      "epoch": 1.9791666666666665,
      "grad_norm": 0.45409759879112244,
      "learning_rate": 0.0004947916666666667,
      "loss": 4.0384,
      "step": 380
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.9260244369506836,
      "eval_runtime": 5.4314,
      "eval_samples_per_second": 3655.767,
      "eval_steps_per_second": 14.361,
      "step": 384
    },
    {
      "epoch": 2.03125,
      "grad_norm": 0.7219817638397217,
      "learning_rate": 0.0004999999692688076,
      "loss": 3.9678,
      "step": 390
    },
    {
      "epoch": 2.0833333333333335,
      "grad_norm": 0.4865483045578003,
      "learning_rate": 0.0004999997814671033,
      "loss": 3.9148,
      "step": 400
    },
    {
      "epoch": 2.1354166666666665,
      "grad_norm": 0.41601434350013733,
      "learning_rate": 0.0004999994229367076,
      "loss": 3.8575,
      "step": 410
    },
    {
      "epoch": 2.1875,
      "grad_norm": 0.41478464007377625,
      "learning_rate": 0.0004999988936778651,
      "loss": 3.7677,
      "step": 420
    },
    {
      "epoch": 2.2395833333333335,
      "grad_norm": 0.40850362181663513,
      "learning_rate": 0.0004999981936909375,
      "loss": 3.692,
      "step": 430
    },
    {
      "epoch": 2.2916666666666665,
      "grad_norm": 0.390592485666275,
      "learning_rate": 0.0004999973229764027,
      "loss": 3.6564,
      "step": 440
    },
    {
      "epoch": 2.34375,
      "grad_norm": 0.44786766171455383,
      "learning_rate": 0.0004999962815348555,
      "loss": 3.5847,
      "step": 450
    },
    {
      "epoch": 2.3958333333333335,
      "grad_norm": 0.47964367270469666,
      "learning_rate": 0.0004999950693670068,
      "loss": 3.5295,
      "step": 460
    },
    {
      "epoch": 2.4479166666666665,
      "grad_norm": 0.3720339238643646,
      "learning_rate": 0.0004999936864736845,
      "loss": 3.4675,
      "step": 470
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.3508007228374481,
      "learning_rate": 0.0004999921328558333,
      "loss": 3.4294,
      "step": 480
    },
    {
      "epoch": 2.5520833333333335,
      "grad_norm": 0.30781102180480957,
      "learning_rate": 0.0004999904085145138,
      "loss": 3.3683,
      "step": 490
    },
    {
      "epoch": 2.6041666666666665,
      "grad_norm": 0.35316869616508484,
      "learning_rate": 0.0004999885134509039,
      "loss": 3.3067,
      "step": 500
    },
    {
      "epoch": 2.65625,
      "grad_norm": 0.5973392724990845,
      "learning_rate": 0.0004999864476662975,
      "loss": 3.2579,
      "step": 510
    },
    {
      "epoch": 2.7083333333333335,
      "grad_norm": 0.4298304319381714,
      "learning_rate": 0.0004999842111621056,
      "loss": 3.216,
      "step": 520
    },
    {
      "epoch": 2.7604166666666665,
      "grad_norm": 0.31092512607574463,
      "learning_rate": 0.0004999818039398553,
      "loss": 3.1652,
      "step": 530
    },
    {
      "epoch": 2.8125,
      "grad_norm": 0.28827086091041565,
      "learning_rate": 0.0004999792260011906,
      "loss": 3.1352,
      "step": 540
    },
    {
      "epoch": 2.8645833333333335,
      "grad_norm": 0.4357509911060333,
      "learning_rate": 0.0004999764773478721,
      "loss": 3.1075,
      "step": 550
    },
    {
      "epoch": 2.9166666666666665,
      "grad_norm": 0.3513086140155792,
      "learning_rate": 0.0004999735579817769,
      "loss": 3.0621,
      "step": 560
    },
    {
      "epoch": 2.96875,
      "grad_norm": 0.49859631061553955,
      "learning_rate": 0.0004999704679048986,
      "loss": 3.0107,
      "step": 570
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.4458972215652466,
      "eval_runtime": 5.4554,
      "eval_samples_per_second": 3639.718,
      "eval_steps_per_second": 14.298,
      "step": 576
    },
    {
      "epoch": 3.0208333333333335,
      "grad_norm": 0.27876055240631104,
      "learning_rate": 0.0004999672071193475,
      "loss": 2.9758,
      "step": 580
    },
    {
      "epoch": 3.0729166666666665,
      "grad_norm": 0.29217728972435,
      "learning_rate": 0.0004999637756273504,
      "loss": 2.962,
      "step": 590
    },
    {
      "epoch": 3.125,
      "grad_norm": 0.3389708399772644,
      "learning_rate": 0.0004999601734312508,
      "loss": 2.9354,
      "step": 600
    },
    {
      "epoch": 3.1770833333333335,
      "grad_norm": 0.49389660358428955,
      "learning_rate": 0.0004999564005335087,
      "loss": 2.9233,
      "step": 610
    },
    {
      "epoch": 3.2291666666666665,
      "grad_norm": 0.2765278220176697,
      "learning_rate": 0.0004999524569367005,
      "loss": 2.8673,
      "step": 620
    },
    {
      "epoch": 3.28125,
      "grad_norm": 0.2599188983440399,
      "learning_rate": 0.0004999483426435195,
      "loss": 2.8436,
      "step": 630
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.27141454815864563,
      "learning_rate": 0.0004999440576567755,
      "loss": 2.8032,
      "step": 640
    },
    {
      "epoch": 3.3854166666666665,
      "grad_norm": 0.24165360629558563,
      "learning_rate": 0.0004999396019793945,
      "loss": 2.816,
      "step": 650
    },
    {
      "epoch": 3.4375,
      "grad_norm": 2.25315523147583,
      "learning_rate": 0.0004999349756144196,
      "loss": 2.7714,
      "step": 660
    },
    {
      "epoch": 3.4895833333333335,
      "grad_norm": 0.22886554896831512,
      "learning_rate": 0.0004999301785650101,
      "loss": 2.775,
      "step": 670
    },
    {
      "epoch": 3.5416666666666665,
      "grad_norm": 0.35446128249168396,
      "learning_rate": 0.0004999252108344419,
      "loss": 2.7315,
      "step": 680
    },
    {
      "epoch": 3.59375,
      "grad_norm": 0.21564549207687378,
      "learning_rate": 0.0004999200724261078,
      "loss": 2.7278,
      "step": 690
    },
    {
      "epoch": 3.6458333333333335,
      "grad_norm": 0.2151627540588379,
      "learning_rate": 0.0004999147633435167,
      "loss": 2.6865,
      "step": 700
    },
    {
      "epoch": 3.6979166666666665,
      "grad_norm": 0.2409241944551468,
      "learning_rate": 0.0004999092835902944,
      "loss": 2.6603,
      "step": 710
    },
    {
      "epoch": 3.75,
      "grad_norm": 0.20945896208286285,
      "learning_rate": 0.0004999036331701828,
      "loss": 2.6423,
      "step": 720
    },
    {
      "epoch": 3.8020833333333335,
      "grad_norm": 0.24547377228736877,
      "learning_rate": 0.000499897812087041,
      "loss": 2.64,
      "step": 730
    },
    {
      "epoch": 3.8541666666666665,
      "grad_norm": 1.5399298667907715,
      "learning_rate": 0.0004998918203448441,
      "loss": 2.6381,
      "step": 740
    },
    {
      "epoch": 3.90625,
      "grad_norm": 0.28990864753723145,
      "learning_rate": 0.000499885657947684,
      "loss": 2.6137,
      "step": 750
    },
    {
      "epoch": 3.9583333333333335,
      "grad_norm": 0.4029792547225952,
      "learning_rate": 0.0004998793248997691,
      "loss": 2.6041,
      "step": 760
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.262170433998108,
      "eval_runtime": 5.434,
      "eval_samples_per_second": 3653.998,
      "eval_steps_per_second": 14.354,
      "step": 768
    },
    {
      "epoch": 4.010416666666667,
      "grad_norm": 0.2444324791431427,
      "learning_rate": 0.0004998728212054245,
      "loss": 2.6076,
      "step": 770
    },
    {
      "epoch": 4.0625,
      "grad_norm": 0.22174569964408875,
      "learning_rate": 0.0004998661468690914,
      "loss": 2.5785,
      "step": 780
    },
    {
      "epoch": 4.114583333333333,
      "grad_norm": 0.2565564811229706,
      "learning_rate": 0.000499859301895328,
      "loss": 2.5954,
      "step": 790
    },
    {
      "epoch": 4.166666666666667,
      "grad_norm": 0.23577046394348145,
      "learning_rate": 0.0004998522862888087,
      "loss": 2.5751,
      "step": 800
    },
    {
      "epoch": 4.21875,
      "grad_norm": 0.21368370950222015,
      "learning_rate": 0.0004998451000543247,
      "loss": 2.5648,
      "step": 810
    },
    {
      "epoch": 4.270833333333333,
      "grad_norm": 0.19819726049900055,
      "learning_rate": 0.0004998377431967836,
      "loss": 2.5445,
      "step": 820
    },
    {
      "epoch": 4.322916666666667,
      "grad_norm": 0.18334579467773438,
      "learning_rate": 0.0004998302157212093,
      "loss": 2.5318,
      "step": 830
    },
    {
      "epoch": 4.375,
      "grad_norm": 0.31320494413375854,
      "learning_rate": 0.0004998225176327426,
      "loss": 2.5365,
      "step": 840
    },
    {
      "epoch": 4.427083333333333,
      "grad_norm": 0.18447761237621307,
      "learning_rate": 0.0004998146489366407,
      "loss": 2.5202,
      "step": 850
    },
    {
      "epoch": 4.479166666666667,
      "grad_norm": 0.24259868264198303,
      "learning_rate": 0.0004998066096382769,
      "loss": 2.5115,
      "step": 860
    },
    {
      "epoch": 4.53125,
      "grad_norm": 0.23465371131896973,
      "learning_rate": 0.0004997983997431419,
      "loss": 2.5016,
      "step": 870
    },
    {
      "epoch": 4.583333333333333,
      "grad_norm": 0.21610687673091888,
      "learning_rate": 0.000499790019256842,
      "loss": 2.4862,
      "step": 880
    },
    {
      "epoch": 4.635416666666667,
      "grad_norm": 0.21213401854038239,
      "learning_rate": 0.0004997814681851004,
      "loss": 2.4831,
      "step": 890
    },
    {
      "epoch": 4.6875,
      "grad_norm": 0.2216418981552124,
      "learning_rate": 0.0004997727465337569,
      "loss": 2.474,
      "step": 900
    },
    {
      "epoch": 4.739583333333333,
      "grad_norm": 0.19304518401622772,
      "learning_rate": 0.0004997638543087675,
      "loss": 2.4616,
      "step": 910
    },
    {
      "epoch": 4.791666666666667,
      "grad_norm": 0.3340674042701721,
      "learning_rate": 0.0004997547915162049,
      "loss": 2.462,
      "step": 920
    },
    {
      "epoch": 4.84375,
      "grad_norm": 0.21662698686122894,
      "learning_rate": 0.0004997455581622582,
      "loss": 2.4808,
      "step": 930
    },
    {
      "epoch": 4.895833333333333,
      "grad_norm": 0.2630714476108551,
      "learning_rate": 0.000499736154253233,
      "loss": 2.4328,
      "step": 940
    },
    {
      "epoch": 4.947916666666667,
      "grad_norm": 0.2844213843345642,
      "learning_rate": 0.0004997265797955514,
      "loss": 2.4548,
      "step": 950
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.18814119696617126,
      "learning_rate": 0.000499716834795752,
      "loss": 2.4593,
      "step": 960
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.193497896194458,
      "eval_runtime": 5.439,
      "eval_samples_per_second": 3650.647,
      "eval_steps_per_second": 14.341,
      "step": 960
    },
    {
      "epoch": 5.052083333333333,
      "grad_norm": 0.17625291645526886,
      "learning_rate": 0.0004997069192604897,
      "loss": 2.4357,
      "step": 970
    },
    {
      "epoch": 5.104166666666667,
      "grad_norm": 0.20696493983268738,
      "learning_rate": 0.0004996968331965361,
      "loss": 2.4372,
      "step": 980
    },
    {
      "epoch": 5.15625,
      "grad_norm": 0.2513856291770935,
      "learning_rate": 0.0004996865766107789,
      "loss": 2.4226,
      "step": 990
    },
    {
      "epoch": 5.208333333333333,
      "grad_norm": 0.28749847412109375,
      "learning_rate": 0.0004996761495102226,
      "loss": 2.4428,
      "step": 1000
    },
    {
      "epoch": 5.260416666666667,
      "grad_norm": 5.706593990325928,
      "learning_rate": 0.0004996655519019881,
      "loss": 2.4092,
      "step": 1010
    },
    {
      "epoch": 5.3125,
      "grad_norm": 0.19517183303833008,
      "learning_rate": 0.0004996547837933127,
      "loss": 2.4287,
      "step": 1020
    },
    {
      "epoch": 5.364583333333333,
      "grad_norm": 0.23538774251937866,
      "learning_rate": 0.0004996438451915499,
      "loss": 2.4398,
      "step": 1030
    },
    {
      "epoch": 5.416666666666667,
      "grad_norm": 0.4671749174594879,
      "learning_rate": 0.00049963273610417,
      "loss": 2.4165,
      "step": 1040
    },
    {
      "epoch": 5.46875,
      "grad_norm": 0.20086105167865753,
      "learning_rate": 0.0004996214565387596,
      "loss": 2.4174,
      "step": 1050
    },
    {
      "epoch": 5.520833333333333,
      "grad_norm": 0.22121712565422058,
      "learning_rate": 0.0004996100065030216,
      "loss": 2.4143,
      "step": 1060
    },
    {
      "epoch": 5.572916666666667,
      "grad_norm": 0.2882012724876404,
      "learning_rate": 0.0004995983860047753,
      "loss": 2.4127,
      "step": 1070
    },
    {
      "epoch": 5.625,
      "grad_norm": 0.19816818833351135,
      "learning_rate": 0.0004995865950519568,
      "loss": 2.4228,
      "step": 1080
    },
    {
      "epoch": 5.677083333333333,
      "grad_norm": 0.22145786881446838,
      "learning_rate": 0.0004995746336526181,
      "loss": 2.3826,
      "step": 1090
    },
    {
      "epoch": 5.729166666666667,
      "grad_norm": 0.20899580419063568,
      "learning_rate": 0.0004995625018149279,
      "loss": 2.3943,
      "step": 1100
    },
    {
      "epoch": 5.78125,
      "grad_norm": 0.21722203493118286,
      "learning_rate": 0.0004995501995471712,
      "loss": 2.3962,
      "step": 1110
    },
    {
      "epoch": 5.833333333333333,
      "grad_norm": 0.3973139822483063,
      "learning_rate": 0.0004995377268577494,
      "loss": 2.3823,
      "step": 1120
    },
    {
      "epoch": 5.885416666666667,
      "grad_norm": 0.16045236587524414,
      "learning_rate": 0.0004995250837551803,
      "loss": 2.373,
      "step": 1130
    },
    {
      "epoch": 5.9375,
      "grad_norm": 0.20176604390144348,
      "learning_rate": 0.0004995122702480981,
      "loss": 2.3749,
      "step": 1140
    },
    {
      "epoch": 5.989583333333333,
      "grad_norm": 0.25678014755249023,
      "learning_rate": 0.0004994992863452533,
      "loss": 2.395,
      "step": 1150
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.161879539489746,
      "eval_runtime": 5.4544,
      "eval_samples_per_second": 3640.342,
      "eval_steps_per_second": 14.3,
      "step": 1152
    },
    {
      "epoch": 6.041666666666667,
      "grad_norm": 0.17612338066101074,
      "learning_rate": 0.0004994861320555128,
      "loss": 2.3772,
      "step": 1160
    },
    {
      "epoch": 6.09375,
      "grad_norm": 0.17500221729278564,
      "learning_rate": 0.00049947280738786,
      "loss": 2.3625,
      "step": 1170
    },
    {
      "epoch": 6.145833333333333,
      "grad_norm": 0.20850834250450134,
      "learning_rate": 0.0004994593123513943,
      "loss": 2.3628,
      "step": 1180
    },
    {
      "epoch": 6.197916666666667,
      "grad_norm": 0.20630496740341187,
      "learning_rate": 0.0004994456469553318,
      "loss": 2.3926,
      "step": 1190
    },
    {
      "epoch": 6.25,
      "grad_norm": 0.16450463235378265,
      "learning_rate": 0.0004994318112090048,
      "loss": 2.3628,
      "step": 1200
    },
    {
      "epoch": 6.302083333333333,
      "grad_norm": 0.15957579016685486,
      "learning_rate": 0.0004994178051218618,
      "loss": 2.372,
      "step": 1210
    },
    {
      "epoch": 6.354166666666667,
      "grad_norm": 0.2319481521844864,
      "learning_rate": 0.0004994036287034681,
      "loss": 2.3595,
      "step": 1220
    },
    {
      "epoch": 6.40625,
      "grad_norm": 0.2178075611591339,
      "learning_rate": 0.0004993892819635047,
      "loss": 2.3597,
      "step": 1230
    },
    {
      "epoch": 6.458333333333333,
      "grad_norm": 0.20105822384357452,
      "learning_rate": 0.0004993747649117694,
      "loss": 2.3702,
      "step": 1240
    },
    {
      "epoch": 6.510416666666667,
      "grad_norm": 0.20039017498493195,
      "learning_rate": 0.0004993600775581758,
      "loss": 2.3561,
      "step": 1250
    },
    {
      "epoch": 6.5625,
      "grad_norm": 0.17993131279945374,
      "learning_rate": 0.0004993452199127545,
      "loss": 2.3664,
      "step": 1260
    },
    {
      "epoch": 6.614583333333333,
      "grad_norm": 0.3275992274284363,
      "learning_rate": 0.0004993301919856519,
      "loss": 2.3728,
      "step": 1270
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 0.24616971611976624,
      "learning_rate": 0.0004993149937871307,
      "loss": 2.3471,
      "step": 1280
    },
    {
      "epoch": 6.71875,
      "grad_norm": 0.166299507021904,
      "learning_rate": 0.0004992996253275699,
      "loss": 2.3357,
      "step": 1290
    },
    {
      "epoch": 6.770833333333333,
      "grad_norm": 0.18914851546287537,
      "learning_rate": 0.0004992840866174652,
      "loss": 2.3271,
      "step": 1300
    },
    {
      "epoch": 6.822916666666667,
      "grad_norm": 0.1729961782693863,
      "learning_rate": 0.0004992683776674279,
      "loss": 2.3421,
      "step": 1310
    },
    {
      "epoch": 6.875,
      "grad_norm": 0.19176381826400757,
      "learning_rate": 0.000499252498488186,
      "loss": 2.3359,
      "step": 1320
    },
    {
      "epoch": 6.927083333333333,
      "grad_norm": 0.17196813225746155,
      "learning_rate": 0.0004992364490905837,
      "loss": 2.3469,
      "step": 1330
    },
    {
      "epoch": 6.979166666666667,
      "grad_norm": 0.16629621386528015,
      "learning_rate": 0.0004992202294855813,
      "loss": 2.3385,
      "step": 1340
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.144755482673645,
      "eval_runtime": 5.4471,
      "eval_samples_per_second": 3645.269,
      "eval_steps_per_second": 14.32,
      "step": 1344
    },
    {
      "epoch": 7.03125,
      "grad_norm": 0.15774782001972198,
      "learning_rate": 0.0004992038396842554,
      "loss": 2.337,
      "step": 1350
    },
    {
      "epoch": 7.083333333333333,
      "grad_norm": 0.18064014613628387,
      "learning_rate": 0.000499187279697799,
      "loss": 2.3383,
      "step": 1360
    },
    {
      "epoch": 7.135416666666667,
      "grad_norm": 0.15523239970207214,
      "learning_rate": 0.0004991705495375209,
      "loss": 2.339,
      "step": 1370
    },
    {
      "epoch": 7.1875,
      "grad_norm": 0.18521134555339813,
      "learning_rate": 0.0004991536492148467,
      "loss": 2.336,
      "step": 1380
    },
    {
      "epoch": 7.239583333333333,
      "grad_norm": 0.19308766722679138,
      "learning_rate": 0.0004991365787413176,
      "loss": 2.34,
      "step": 1390
    },
    {
      "epoch": 7.291666666666667,
      "grad_norm": 0.22126831114292145,
      "learning_rate": 0.0004991193381285915,
      "loss": 2.3238,
      "step": 1400
    },
    {
      "epoch": 7.34375,
      "grad_norm": 0.3171199560165405,
      "learning_rate": 0.0004991019273884421,
      "loss": 2.3348,
      "step": 1410
    },
    {
      "epoch": 7.395833333333333,
      "grad_norm": 0.20096325874328613,
      "learning_rate": 0.0004990843465327597,
      "loss": 2.336,
      "step": 1420
    },
    {
      "epoch": 7.447916666666667,
      "grad_norm": 0.19521790742874146,
      "learning_rate": 0.0004990665955735503,
      "loss": 2.3448,
      "step": 1430
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.1741323471069336,
      "learning_rate": 0.0004990486745229364,
      "loss": 2.3286,
      "step": 1440
    },
    {
      "epoch": 7.552083333333333,
      "grad_norm": 0.19602282345294952,
      "learning_rate": 0.0004990305833931565,
      "loss": 2.3149,
      "step": 1450
    },
    {
      "epoch": 7.604166666666667,
      "grad_norm": 0.2410760223865509,
      "learning_rate": 0.0004990123221965655,
      "loss": 2.3274,
      "step": 1460
    },
    {
      "epoch": 7.65625,
      "grad_norm": 0.17470261454582214,
      "learning_rate": 0.0004989938909456341,
      "loss": 2.3156,
      "step": 1470
    },
    {
      "epoch": 7.708333333333333,
      "grad_norm": 0.1940057873725891,
      "learning_rate": 0.0004989752896529492,
      "loss": 2.3208,
      "step": 1480
    },
    {
      "epoch": 7.760416666666667,
      "grad_norm": 0.17802749574184418,
      "learning_rate": 0.000498956518331214,
      "loss": 2.3116,
      "step": 1490
    },
    {
      "epoch": 7.8125,
      "grad_norm": 0.2272276133298874,
      "learning_rate": 0.0004989375769932479,
      "loss": 2.3221,
      "step": 1500
    },
    {
      "epoch": 7.864583333333333,
      "grad_norm": 0.21353667974472046,
      "learning_rate": 0.0004989184656519859,
      "loss": 2.3176,
      "step": 1510
    },
    {
      "epoch": 7.916666666666667,
      "grad_norm": 0.1905418336391449,
      "learning_rate": 0.0004988991843204797,
      "loss": 2.3105,
      "step": 1520
    },
    {
      "epoch": 7.96875,
      "grad_norm": 0.20450207591056824,
      "learning_rate": 0.0004988797330118967,
      "loss": 2.3064,
      "step": 1530
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.1358840465545654,
      "eval_runtime": 5.4256,
      "eval_samples_per_second": 3659.671,
      "eval_steps_per_second": 14.376,
      "step": 1536
    },
    {
      "epoch": 8.020833333333334,
      "grad_norm": 0.20364569127559662,
      "learning_rate": 0.0004988601117395205,
      "loss": 2.3092,
      "step": 1540
    },
    {
      "epoch": 8.072916666666666,
      "grad_norm": 0.19144746661186218,
      "learning_rate": 0.0004988403205167508,
      "loss": 2.3203,
      "step": 1550
    },
    {
      "epoch": 8.125,
      "grad_norm": 0.2580832242965698,
      "learning_rate": 0.0004988203593571033,
      "loss": 2.3136,
      "step": 1560
    },
    {
      "epoch": 8.177083333333334,
      "grad_norm": 0.18294759094715118,
      "learning_rate": 0.0004988002282742096,
      "loss": 2.2993,
      "step": 1570
    },
    {
      "epoch": 8.229166666666666,
      "grad_norm": 0.15878576040267944,
      "learning_rate": 0.0004987799272818179,
      "loss": 2.2993,
      "step": 1580
    },
    {
      "epoch": 8.28125,
      "grad_norm": 0.1927795261144638,
      "learning_rate": 0.000498759456393792,
      "loss": 2.3179,
      "step": 1590
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 0.19717808067798615,
      "learning_rate": 0.0004987388156241115,
      "loss": 2.3119,
      "step": 1600
    },
    {
      "epoch": 8.385416666666666,
      "grad_norm": 0.19151654839515686,
      "learning_rate": 0.0004987180049868725,
      "loss": 2.298,
      "step": 1610
    },
    {
      "epoch": 8.4375,
      "grad_norm": 0.21251636743545532,
      "learning_rate": 0.0004986970244962868,
      "loss": 2.2957,
      "step": 1620
    },
    {
      "epoch": 8.489583333333334,
      "grad_norm": 0.194216787815094,
      "learning_rate": 0.0004986758741666825,
      "loss": 2.3208,
      "step": 1630
    },
    {
      "epoch": 8.541666666666666,
      "grad_norm": 0.17995160818099976,
      "learning_rate": 0.0004986545540125032,
      "loss": 2.2807,
      "step": 1640
    },
    {
      "epoch": 8.59375,
      "grad_norm": 0.19437174499034882,
      "learning_rate": 0.0004986330640483089,
      "loss": 2.3039,
      "step": 1650
    },
    {
      "epoch": 8.645833333333334,
      "grad_norm": 0.18119028210639954,
      "learning_rate": 0.0004986114042887756,
      "loss": 2.3058,
      "step": 1660
    },
    {
      "epoch": 8.697916666666666,
      "grad_norm": 0.2014491707086563,
      "learning_rate": 0.0004985895747486947,
      "loss": 2.2934,
      "step": 1670
    },
    {
      "epoch": 8.75,
      "grad_norm": 0.16764988005161285,
      "learning_rate": 0.0004985675754429744,
      "loss": 2.2855,
      "step": 1680
    },
    {
      "epoch": 8.802083333333334,
      "grad_norm": 0.19833001494407654,
      "learning_rate": 0.000498545406386638,
      "loss": 2.2969,
      "step": 1690
    },
    {
      "epoch": 8.854166666666666,
      "grad_norm": 0.18640202283859253,
      "learning_rate": 0.0004985230675948251,
      "loss": 2.2914,
      "step": 1700
    },
    {
      "epoch": 8.90625,
      "grad_norm": 0.17975665628910065,
      "learning_rate": 0.0004985005590827914,
      "loss": 2.294,
      "step": 1710
    },
    {
      "epoch": 8.958333333333334,
      "grad_norm": 0.22109930217266083,
      "learning_rate": 0.0004984778808659082,
      "loss": 2.274,
      "step": 1720
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.1255487203598022,
      "eval_runtime": 5.4241,
      "eval_samples_per_second": 3660.668,
      "eval_steps_per_second": 14.38,
      "step": 1728
    },
    {
      "epoch": 9.010416666666666,
      "grad_norm": 0.18127526342868805,
      "learning_rate": 0.0004984550329596627,
      "loss": 2.2967,
      "step": 1730
    },
    {
      "epoch": 9.0625,
      "grad_norm": 0.20159049332141876,
      "learning_rate": 0.0004984320153796584,
      "loss": 2.2976,
      "step": 1740
    },
    {
      "epoch": 9.114583333333334,
      "grad_norm": 0.21613110601902008,
      "learning_rate": 0.0004984088281416141,
      "loss": 2.2995,
      "step": 1750
    },
    {
      "epoch": 9.166666666666666,
      "grad_norm": 0.19129915535449982,
      "learning_rate": 0.0004983854712613647,
      "loss": 2.2883,
      "step": 1760
    },
    {
      "epoch": 9.21875,
      "grad_norm": 0.19695012271404266,
      "learning_rate": 0.000498361944754861,
      "loss": 2.2883,
      "step": 1770
    },
    {
      "epoch": 9.270833333333334,
      "grad_norm": 0.18446902930736542,
      "learning_rate": 0.0004983382486381699,
      "loss": 2.2763,
      "step": 1780
    },
    {
      "epoch": 9.322916666666666,
      "grad_norm": 0.17563655972480774,
      "learning_rate": 0.0004983143829274734,
      "loss": 2.2796,
      "step": 1790
    },
    {
      "epoch": 9.375,
      "grad_norm": 0.21299579739570618,
      "learning_rate": 0.0004982903476390701,
      "loss": 2.2678,
      "step": 1800
    },
    {
      "epoch": 9.427083333333334,
      "grad_norm": 0.1876586377620697,
      "learning_rate": 0.0004982661427893739,
      "loss": 2.2997,
      "step": 1810
    },
    {
      "epoch": 9.479166666666666,
      "grad_norm": 0.2256416231393814,
      "learning_rate": 0.0004982417683949146,
      "loss": 2.2757,
      "step": 1820
    },
    {
      "epoch": 9.53125,
      "grad_norm": 0.17776058614253998,
      "learning_rate": 0.0004982172244723381,
      "loss": 2.2883,
      "step": 1830
    },
    {
      "epoch": 9.583333333333334,
      "grad_norm": 0.19339042901992798,
      "learning_rate": 0.0004981925110384056,
      "loss": 2.2918,
      "step": 1840
    },
    {
      "epoch": 9.635416666666666,
      "grad_norm": 0.19217999279499054,
      "learning_rate": 0.0004981676281099943,
      "loss": 2.2779,
      "step": 1850
    },
    {
      "epoch": 9.6875,
      "grad_norm": 0.1775275021791458,
      "learning_rate": 0.0004981425757040973,
      "loss": 2.2923,
      "step": 1860
    },
    {
      "epoch": 9.739583333333334,
      "grad_norm": 0.19035375118255615,
      "learning_rate": 0.000498117353837823,
      "loss": 2.2827,
      "step": 1870
    },
    {
      "epoch": 9.791666666666666,
      "grad_norm": 0.16991116106510162,
      "learning_rate": 0.0004980919625283962,
      "loss": 2.279,
      "step": 1880
    },
    {
      "epoch": 9.84375,
      "grad_norm": 0.1689639389514923,
      "learning_rate": 0.0004980664017931566,
      "loss": 2.2835,
      "step": 1890
    },
    {
      "epoch": 9.895833333333334,
      "grad_norm": 0.173748180270195,
      "learning_rate": 0.0004980406716495602,
      "loss": 2.268,
      "step": 1900
    },
    {
      "epoch": 9.947916666666666,
      "grad_norm": 0.20474904775619507,
      "learning_rate": 0.0004980147721151786,
      "loss": 2.2775,
      "step": 1910
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.20122410356998444,
      "learning_rate": 0.0004979887032076989,
      "loss": 2.267,
      "step": 1920
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.1191397905349731,
      "eval_runtime": 5.4166,
      "eval_samples_per_second": 3665.742,
      "eval_steps_per_second": 14.4,
      "step": 1920
    },
    {
      "epoch": 10.052083333333334,
      "grad_norm": 0.2561852037906647,
      "learning_rate": 0.0004979624649449238,
      "loss": 2.2582,
      "step": 1930
    },
    {
      "epoch": 10.104166666666666,
      "grad_norm": 0.18498453497886658,
      "learning_rate": 0.0004979360573447721,
      "loss": 2.2705,
      "step": 1940
    },
    {
      "epoch": 10.15625,
      "grad_norm": 0.22482895851135254,
      "learning_rate": 0.0004979094804252777,
      "loss": 2.2647,
      "step": 1950
    },
    {
      "epoch": 10.208333333333334,
      "grad_norm": 0.18845823407173157,
      "learning_rate": 0.0004978827342045906,
      "loss": 2.2836,
      "step": 1960
    },
    {
      "epoch": 10.260416666666666,
      "grad_norm": 0.18767257034778595,
      "learning_rate": 0.0004978558187009762,
      "loss": 2.2773,
      "step": 1970
    },
    {
      "epoch": 10.3125,
      "grad_norm": 0.19943611323833466,
      "learning_rate": 0.0004978287339328152,
      "loss": 2.2842,
      "step": 1980
    },
    {
      "epoch": 10.364583333333334,
      "grad_norm": 0.2598455548286438,
      "learning_rate": 0.0004978014799186046,
      "loss": 2.2713,
      "step": 1990
    },
    {
      "epoch": 10.416666666666666,
      "grad_norm": 0.20519928634166718,
      "learning_rate": 0.0004977740566769564,
      "loss": 2.2754,
      "step": 2000
    },
    {
      "epoch": 10.46875,
      "grad_norm": 0.2589176595211029,
      "learning_rate": 0.0004977464642265983,
      "loss": 2.2779,
      "step": 2010
    },
    {
      "epoch": 10.520833333333334,
      "grad_norm": 0.21119937300682068,
      "learning_rate": 0.0004977187025863737,
      "loss": 2.2544,
      "step": 2020
    },
    {
      "epoch": 10.572916666666666,
      "grad_norm": 0.25233161449432373,
      "learning_rate": 0.0004976907717752414,
      "loss": 2.2792,
      "step": 2030
    },
    {
      "epoch": 10.625,
      "grad_norm": 0.21095801889896393,
      "learning_rate": 0.0004976626718122759,
      "loss": 2.271,
      "step": 2040
    },
    {
      "epoch": 10.677083333333334,
      "grad_norm": 0.2069525420665741,
      "learning_rate": 0.0004976344027166669,
      "loss": 2.2472,
      "step": 2050
    },
    {
      "epoch": 10.729166666666666,
      "grad_norm": 0.1854572892189026,
      "learning_rate": 0.00049760596450772,
      "loss": 2.2702,
      "step": 2060
    },
    {
      "epoch": 10.78125,
      "grad_norm": 0.20062273740768433,
      "learning_rate": 0.0004975773572048559,
      "loss": 2.2573,
      "step": 2070
    },
    {
      "epoch": 10.833333333333334,
      "grad_norm": 0.1974780410528183,
      "learning_rate": 0.000497548580827611,
      "loss": 2.2507,
      "step": 2080
    },
    {
      "epoch": 10.885416666666666,
      "grad_norm": 0.2067400962114334,
      "learning_rate": 0.0004975196353956373,
      "loss": 2.2681,
      "step": 2090
    },
    {
      "epoch": 10.9375,
      "grad_norm": 0.19017083942890167,
      "learning_rate": 0.0004974905209287019,
      "loss": 2.2552,
      "step": 2100
    },
    {
      "epoch": 10.989583333333334,
      "grad_norm": 0.20330847799777985,
      "learning_rate": 0.0004974612374466877,
      "loss": 2.2862,
      "step": 2110
    },
    {
      "epoch": 11.0,
      "eval_loss": 1.1128121614456177,
      "eval_runtime": 5.4466,
      "eval_samples_per_second": 3645.551,
      "eval_steps_per_second": 14.321,
      "step": 2112
    },
    {
      "epoch": 11.041666666666666,
      "grad_norm": 0.1740473359823227,
      "learning_rate": 0.0004974317849695926,
      "loss": 2.267,
      "step": 2120
    },
    {
      "epoch": 11.09375,
      "grad_norm": 0.21484555304050446,
      "learning_rate": 0.0004974021635175304,
      "loss": 2.2471,
      "step": 2130
    },
    {
      "epoch": 11.145833333333334,
      "grad_norm": 0.2592523396015167,
      "learning_rate": 0.0004973723731107298,
      "loss": 2.271,
      "step": 2140
    },
    {
      "epoch": 11.197916666666666,
      "grad_norm": 0.18657879531383514,
      "learning_rate": 0.0004973424137695354,
      "loss": 2.2587,
      "step": 2150
    },
    {
      "epoch": 11.25,
      "grad_norm": 0.22095291316509247,
      "learning_rate": 0.0004973122855144066,
      "loss": 2.2497,
      "step": 2160
    },
    {
      "epoch": 11.302083333333334,
      "grad_norm": 0.20478445291519165,
      "learning_rate": 0.0004972819883659185,
      "loss": 2.2662,
      "step": 2170
    },
    {
      "epoch": 11.354166666666666,
      "grad_norm": 0.18753913044929504,
      "learning_rate": 0.0004972515223447617,
      "loss": 2.2464,
      "step": 2180
    },
    {
      "epoch": 11.40625,
      "grad_norm": 0.2208254635334015,
      "learning_rate": 0.0004972208874717419,
      "loss": 2.2482,
      "step": 2190
    },
    {
      "epoch": 11.458333333333334,
      "grad_norm": 0.18484710156917572,
      "learning_rate": 0.0004971900837677798,
      "loss": 2.2703,
      "step": 2200
    },
    {
      "epoch": 11.510416666666666,
      "grad_norm": 0.21453766524791718,
      "learning_rate": 0.0004971591112539121,
      "loss": 2.2382,
      "step": 2210
    },
    {
      "epoch": 11.5625,
      "grad_norm": 0.19749760627746582,
      "learning_rate": 0.0004971279699512901,
      "loss": 2.2519,
      "step": 2220
    },
    {
      "epoch": 11.614583333333334,
      "grad_norm": 0.1933760643005371,
      "learning_rate": 0.0004970966598811809,
      "loss": 2.2581,
      "step": 2230
    },
    {
      "epoch": 11.666666666666666,
      "grad_norm": 0.21684104204177856,
      "learning_rate": 0.0004970651810649666,
      "loss": 2.2558,
      "step": 2240
    },
    {
      "epoch": 11.71875,
      "grad_norm": 0.26733633875846863,
      "learning_rate": 0.0004970335335241444,
      "loss": 2.2667,
      "step": 2250
    },
    {
      "epoch": 11.770833333333334,
      "grad_norm": 0.2229175716638565,
      "learning_rate": 0.0004970017172803271,
      "loss": 2.2531,
      "step": 2260
    },
    {
      "epoch": 11.822916666666666,
      "grad_norm": 0.21103793382644653,
      "learning_rate": 0.0004969697323552423,
      "loss": 2.2507,
      "step": 2270
    },
    {
      "epoch": 11.875,
      "grad_norm": 0.19820493459701538,
      "learning_rate": 0.0004969375787707332,
      "loss": 2.2586,
      "step": 2280
    },
    {
      "epoch": 11.927083333333334,
      "grad_norm": 0.20872563123703003,
      "learning_rate": 0.0004969052565487578,
      "loss": 2.2515,
      "step": 2290
    },
    {
      "epoch": 11.979166666666666,
      "grad_norm": 0.2766086757183075,
      "learning_rate": 0.0004968727657113895,
      "loss": 2.2669,
      "step": 2300
    },
    {
      "epoch": 12.0,
      "eval_loss": 1.1117794513702393,
      "eval_runtime": 5.4282,
      "eval_samples_per_second": 3657.943,
      "eval_steps_per_second": 14.369,
      "step": 2304
    },
    {
      "epoch": 12.03125,
      "grad_norm": 0.23547758162021637,
      "learning_rate": 0.0004968401062808168,
      "loss": 2.2373,
      "step": 2310
    },
    {
      "epoch": 12.083333333333334,
      "grad_norm": 0.1911631077528,
      "learning_rate": 0.0004968072782793435,
      "loss": 2.2504,
      "step": 2320
    },
    {
      "epoch": 12.135416666666666,
      "grad_norm": 0.18195298314094543,
      "learning_rate": 0.0004967742817293881,
      "loss": 2.2325,
      "step": 2330
    },
    {
      "epoch": 12.1875,
      "grad_norm": 0.19277453422546387,
      "learning_rate": 0.0004967411166534845,
      "loss": 2.237,
      "step": 2340
    },
    {
      "epoch": 12.239583333333334,
      "grad_norm": 0.2692094147205353,
      "learning_rate": 0.0004967077830742817,
      "loss": 2.26,
      "step": 2350
    },
    {
      "epoch": 12.291666666666666,
      "grad_norm": 0.19753526151180267,
      "learning_rate": 0.0004966742810145438,
      "loss": 2.2418,
      "step": 2360
    },
    {
      "epoch": 12.34375,
      "grad_norm": 0.2652440667152405,
      "learning_rate": 0.0004966406104971496,
      "loss": 2.2301,
      "step": 2370
    },
    {
      "epoch": 12.395833333333334,
      "grad_norm": 0.2103116810321808,
      "learning_rate": 0.0004966067715450935,
      "loss": 2.2568,
      "step": 2380
    },
    {
      "epoch": 12.447916666666666,
      "grad_norm": 0.23044593632221222,
      "learning_rate": 0.0004965727641814844,
      "loss": 2.2512,
      "step": 2390
    },
    {
      "epoch": 12.5,
      "grad_norm": 0.24945053458213806,
      "learning_rate": 0.0004965385884295467,
      "loss": 2.256,
      "step": 2400
    },
    {
      "epoch": 12.552083333333334,
      "grad_norm": 0.280198872089386,
      "learning_rate": 0.0004965042443126193,
      "loss": 2.2438,
      "step": 2410
    },
    {
      "epoch": 12.604166666666666,
      "grad_norm": 0.19797778129577637,
      "learning_rate": 0.0004964697318541564,
      "loss": 2.233,
      "step": 2420
    },
    {
      "epoch": 12.65625,
      "grad_norm": 0.18953156471252441,
      "learning_rate": 0.0004964350510777273,
      "loss": 2.2515,
      "step": 2430
    },
    {
      "epoch": 12.708333333333334,
      "grad_norm": 0.19416941702365875,
      "learning_rate": 0.0004964002020070157,
      "loss": 2.2604,
      "step": 2440
    },
    {
      "epoch": 12.760416666666666,
      "grad_norm": 0.20446524024009705,
      "learning_rate": 0.0004963651846658209,
      "loss": 2.254,
      "step": 2450
    },
    {
      "epoch": 12.8125,
      "grad_norm": 0.24649761617183685,
      "learning_rate": 0.0004963299990780564,
      "loss": 2.2418,
      "step": 2460
    },
    {
      "epoch": 12.864583333333334,
      "grad_norm": 0.2032751888036728,
      "learning_rate": 0.0004962946452677512,
      "loss": 2.2461,
      "step": 2470
    },
    {
      "epoch": 12.916666666666666,
      "grad_norm": 0.21027632057666779,
      "learning_rate": 0.0004962591232590491,
      "loss": 2.2469,
      "step": 2480
    },
    {
      "epoch": 12.96875,
      "grad_norm": 0.20446434617042542,
      "learning_rate": 0.0004962234330762084,
      "loss": 2.249,
      "step": 2490
    },
    {
      "epoch": 13.0,
      "eval_loss": 1.1065057516098022,
      "eval_runtime": 5.4583,
      "eval_samples_per_second": 3637.789,
      "eval_steps_per_second": 14.29,
      "step": 2496
    },
    {
      "epoch": 13.020833333333334,
      "grad_norm": 0.2262507975101471,
      "learning_rate": 0.0004961875747436026,
      "loss": 2.2591,
      "step": 2500
    },
    {
      "epoch": 13.072916666666666,
      "grad_norm": 0.21505646407604218,
      "learning_rate": 0.0004961515482857197,
      "loss": 2.2188,
      "step": 2510
    },
    {
      "epoch": 13.125,
      "grad_norm": 0.25121936202049255,
      "learning_rate": 0.000496115353727163,
      "loss": 2.2458,
      "step": 2520
    },
    {
      "epoch": 13.177083333333334,
      "grad_norm": 0.1989094316959381,
      "learning_rate": 0.0004960789910926502,
      "loss": 2.2313,
      "step": 2530
    },
    {
      "epoch": 13.229166666666666,
      "grad_norm": 0.22959329187870026,
      "learning_rate": 0.0004960424604070139,
      "loss": 2.2293,
      "step": 2540
    },
    {
      "epoch": 13.28125,
      "grad_norm": 0.2721049189567566,
      "learning_rate": 0.0004960057616952013,
      "loss": 2.2453,
      "step": 2550
    },
    {
      "epoch": 13.333333333333334,
      "grad_norm": 0.2157449871301651,
      "learning_rate": 0.0004959688949822749,
      "loss": 2.2326,
      "step": 2560
    },
    {
      "epoch": 13.385416666666666,
      "grad_norm": 0.20242923498153687,
      "learning_rate": 0.0004959318602934111,
      "loss": 2.2399,
      "step": 2570
    },
    {
      "epoch": 13.4375,
      "grad_norm": 0.21004439890384674,
      "learning_rate": 0.0004958946576539018,
      "loss": 2.2258,
      "step": 2580
    },
    {
      "epoch": 13.489583333333334,
      "grad_norm": 0.22366583347320557,
      "learning_rate": 0.0004958572870891532,
      "loss": 2.2268,
      "step": 2590
    },
    {
      "epoch": 13.541666666666666,
      "grad_norm": 0.23186157643795013,
      "learning_rate": 0.000495819748624686,
      "loss": 2.2359,
      "step": 2600
    },
    {
      "epoch": 13.59375,
      "grad_norm": 0.20001938939094543,
      "learning_rate": 0.000495782042286136,
      "loss": 2.2434,
      "step": 2610
    },
    {
      "epoch": 13.645833333333334,
      "grad_norm": 0.19695915281772614,
      "learning_rate": 0.0004957441680992535,
      "loss": 2.2358,
      "step": 2620
    },
    {
      "epoch": 13.697916666666666,
      "grad_norm": 0.1961490511894226,
      "learning_rate": 0.0004957061260899032,
      "loss": 2.25,
      "step": 2630
    },
    {
      "epoch": 13.75,
      "grad_norm": 0.2251022309064865,
      "learning_rate": 0.0004956679162840646,
      "loss": 2.2366,
      "step": 2640
    },
    {
      "epoch": 13.802083333333334,
      "grad_norm": 0.2133328914642334,
      "learning_rate": 0.0004956295387078319,
      "loss": 2.2236,
      "step": 2650
    },
    {
      "epoch": 13.854166666666666,
      "grad_norm": 0.26947274804115295,
      "learning_rate": 0.0004955909933874135,
      "loss": 2.2308,
      "step": 2660
    },
    {
      "epoch": 13.90625,
      "grad_norm": 0.29742011427879333,
      "learning_rate": 0.0004955522803491328,
      "loss": 2.2427,
      "step": 2670
    },
    {
      "epoch": 13.958333333333334,
      "grad_norm": 0.20745961368083954,
      "learning_rate": 0.0004955133996194274,
      "loss": 2.2435,
      "step": 2680
    },
    {
      "epoch": 14.0,
      "eval_loss": 1.1034868955612183,
      "eval_runtime": 5.4499,
      "eval_samples_per_second": 3643.39,
      "eval_steps_per_second": 14.312,
      "step": 2688
    },
    {
      "epoch": 14.010416666666666,
      "grad_norm": 0.2096010148525238,
      "learning_rate": 0.0004954743512248496,
      "loss": 2.2359,
      "step": 2690
    },
    {
      "epoch": 14.0625,
      "grad_norm": 0.22002089023590088,
      "learning_rate": 0.0004954351351920663,
      "loss": 2.2063,
      "step": 2700
    },
    {
      "epoch": 14.114583333333334,
      "grad_norm": 0.2047884464263916,
      "learning_rate": 0.0004953957515478584,
      "loss": 2.2532,
      "step": 2710
    },
    {
      "epoch": 14.166666666666666,
      "grad_norm": 0.2630546987056732,
      "learning_rate": 0.0004953562003191219,
      "loss": 2.2321,
      "step": 2720
    },
    {
      "epoch": 14.21875,
      "grad_norm": 0.23803304135799408,
      "learning_rate": 0.0004953164815328668,
      "loss": 2.2292,
      "step": 2730
    },
    {
      "epoch": 14.270833333333334,
      "grad_norm": 0.23974506556987762,
      "learning_rate": 0.0004952765952162177,
      "loss": 2.2363,
      "step": 2740
    },
    {
      "epoch": 14.322916666666666,
      "grad_norm": 0.22407354414463043,
      "learning_rate": 0.0004952365413964135,
      "loss": 2.2328,
      "step": 2750
    },
    {
      "epoch": 14.375,
      "grad_norm": 0.2589082419872284,
      "learning_rate": 0.0004951963201008077,
      "loss": 2.2378,
      "step": 2760
    },
    {
      "epoch": 14.427083333333334,
      "grad_norm": 0.25629445910453796,
      "learning_rate": 0.0004951559313568679,
      "loss": 2.2209,
      "step": 2770
    },
    {
      "epoch": 14.479166666666666,
      "grad_norm": 0.23685376346111298,
      "learning_rate": 0.0004951153751921762,
      "loss": 2.2301,
      "step": 2780
    },
    {
      "epoch": 14.53125,
      "grad_norm": 0.20017527043819427,
      "learning_rate": 0.0004950746516344292,
      "loss": 2.2247,
      "step": 2790
    },
    {
      "epoch": 14.583333333333334,
      "grad_norm": 0.2624261975288391,
      "learning_rate": 0.0004950337607114376,
      "loss": 2.232,
      "step": 2800
    },
    {
      "epoch": 14.635416666666666,
      "grad_norm": 0.32667067646980286,
      "learning_rate": 0.0004949927024511263,
      "loss": 2.229,
      "step": 2810
    },
    {
      "epoch": 14.6875,
      "grad_norm": 0.2373901754617691,
      "learning_rate": 0.0004949514768815348,
      "loss": 2.2271,
      "step": 2820
    },
    {
      "epoch": 14.739583333333334,
      "grad_norm": 0.3144720196723938,
      "learning_rate": 0.0004949100840308164,
      "loss": 2.2261,
      "step": 2830
    },
    {
      "epoch": 14.791666666666666,
      "grad_norm": 0.21635715663433075,
      "learning_rate": 0.0004948685239272391,
      "loss": 2.2424,
      "step": 2840
    },
    {
      "epoch": 14.84375,
      "grad_norm": 0.2074689269065857,
      "learning_rate": 0.000494826796599185,
      "loss": 2.2358,
      "step": 2850
    },
    {
      "epoch": 14.895833333333334,
      "grad_norm": 0.22776682674884796,
      "learning_rate": 0.0004947849020751503,
      "loss": 2.2243,
      "step": 2860
    },
    {
      "epoch": 14.947916666666666,
      "grad_norm": 0.29884782433509827,
      "learning_rate": 0.0004947428403837453,
      "loss": 2.2339,
      "step": 2870
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.25484350323677063,
      "learning_rate": 0.0004947006115536948,
      "loss": 2.2313,
      "step": 2880
    },
    {
      "epoch": 15.0,
      "eval_loss": 1.1009721755981445,
      "eval_runtime": 5.4421,
      "eval_samples_per_second": 3648.558,
      "eval_steps_per_second": 14.333,
      "step": 2880
    },
    {
      "epoch": 15.052083333333334,
      "grad_norm": 0.21695002913475037,
      "learning_rate": 0.0004946582156138371,
      "loss": 2.2358,
      "step": 2890
    },
    {
      "epoch": 15.104166666666666,
      "grad_norm": 0.24883632361888885,
      "learning_rate": 0.0004946156525931254,
      "loss": 2.2218,
      "step": 2900
    },
    {
      "epoch": 15.15625,
      "grad_norm": 0.24074797332286835,
      "learning_rate": 0.0004945729225206266,
      "loss": 2.2218,
      "step": 2910
    },
    {
      "epoch": 15.208333333333334,
      "grad_norm": 0.21293380856513977,
      "learning_rate": 0.0004945300254255216,
      "loss": 2.2253,
      "step": 2920
    },
    {
      "epoch": 15.260416666666666,
      "grad_norm": 0.23403963446617126,
      "learning_rate": 0.0004944869613371054,
      "loss": 2.2156,
      "step": 2930
    },
    {
      "epoch": 15.3125,
      "grad_norm": 0.22848717868328094,
      "learning_rate": 0.0004944437302847875,
      "loss": 2.2176,
      "step": 2940
    },
    {
      "epoch": 15.364583333333334,
      "grad_norm": 0.23786288499832153,
      "learning_rate": 0.0004944003322980908,
      "loss": 2.2249,
      "step": 2950
    },
    {
      "epoch": 15.416666666666666,
      "grad_norm": 0.23557548224925995,
      "learning_rate": 0.0004943567674066524,
      "loss": 2.2061,
      "step": 2960
    },
    {
      "epoch": 15.46875,
      "grad_norm": 0.2113240510225296,
      "learning_rate": 0.0004943130356402235,
      "loss": 2.2161,
      "step": 2970
    },
    {
      "epoch": 15.520833333333334,
      "grad_norm": 0.2556476294994354,
      "learning_rate": 0.0004942691370286693,
      "loss": 2.2223,
      "step": 2980
    },
    {
      "epoch": 15.572916666666666,
      "grad_norm": 0.23343095183372498,
      "learning_rate": 0.0004942250716019686,
      "loss": 2.2422,
      "step": 2990
    },
    {
      "epoch": 15.625,
      "grad_norm": 0.22992245852947235,
      "learning_rate": 0.0004941808393902146,
      "loss": 2.2335,
      "step": 3000
    },
    {
      "epoch": 15.677083333333334,
      "grad_norm": 0.22743342816829681,
      "learning_rate": 0.000494136440423614,
      "loss": 2.2388,
      "step": 3010
    },
    {
      "epoch": 15.729166666666666,
      "grad_norm": 0.2095693051815033,
      "learning_rate": 0.0004940918747324876,
      "loss": 2.2272,
      "step": 3020
    },
    {
      "epoch": 15.78125,
      "grad_norm": 0.2566658854484558,
      "learning_rate": 0.00049404714234727,
      "loss": 2.2233,
      "step": 3030
    },
    {
      "epoch": 15.833333333333334,
      "grad_norm": 0.23452456295490265,
      "learning_rate": 0.0004940022432985096,
      "loss": 2.2393,
      "step": 3040
    },
    {
      "epoch": 15.885416666666666,
      "grad_norm": 0.20508979260921478,
      "learning_rate": 0.0004939571776168688,
      "loss": 2.2223,
      "step": 3050
    },
    {
      "epoch": 15.9375,
      "grad_norm": 0.23535075783729553,
      "learning_rate": 0.0004939119453331233,
      "loss": 2.2066,
      "step": 3060
    },
    {
      "epoch": 15.989583333333334,
      "grad_norm": 0.2190217524766922,
      "learning_rate": 0.0004938665464781632,
      "loss": 2.2319,
      "step": 3070
    },
    {
      "epoch": 16.0,
      "eval_loss": 1.0986487865447998,
      "eval_runtime": 5.4165,
      "eval_samples_per_second": 3665.839,
      "eval_steps_per_second": 14.4,
      "step": 3072
    },
    {
      "epoch": 16.041666666666668,
      "grad_norm": 0.24801196157932281,
      "learning_rate": 0.0004938209810829921,
      "loss": 2.2108,
      "step": 3080
    },
    {
      "epoch": 16.09375,
      "grad_norm": 0.2447916865348816,
      "learning_rate": 0.0004937752491787271,
      "loss": 2.2174,
      "step": 3090
    },
    {
      "epoch": 16.145833333333332,
      "grad_norm": 0.2569996416568756,
      "learning_rate": 0.0004937293507965994,
      "loss": 2.2048,
      "step": 3100
    },
    {
      "epoch": 16.197916666666668,
      "grad_norm": 0.20713666081428528,
      "learning_rate": 0.0004936832859679537,
      "loss": 2.2289,
      "step": 3110
    },
    {
      "epoch": 16.25,
      "grad_norm": 0.23371809720993042,
      "learning_rate": 0.0004936370547242482,
      "loss": 2.2097,
      "step": 3120
    },
    {
      "epoch": 16.302083333333332,
      "grad_norm": 0.22778810560703278,
      "learning_rate": 0.0004935906570970552,
      "loss": 2.2102,
      "step": 3130
    },
    {
      "epoch": 16.354166666666668,
      "grad_norm": 0.21142315864562988,
      "learning_rate": 0.0004935440931180602,
      "loss": 2.213,
      "step": 3140
    },
    {
      "epoch": 16.40625,
      "grad_norm": 0.23154494166374207,
      "learning_rate": 0.0004934973628190624,
      "loss": 2.2218,
      "step": 3150
    },
    {
      "epoch": 16.458333333333332,
      "grad_norm": 0.2599083483219147,
      "learning_rate": 0.0004934504662319747,
      "loss": 2.2093,
      "step": 3160
    },
    {
      "epoch": 16.510416666666668,
      "grad_norm": 0.22559237480163574,
      "learning_rate": 0.0004934034033888235,
      "loss": 2.2094,
      "step": 3170
    },
    {
      "epoch": 16.5625,
      "grad_norm": 0.26766520738601685,
      "learning_rate": 0.0004933561743217488,
      "loss": 2.2237,
      "step": 3180
    },
    {
      "epoch": 16.614583333333332,
      "grad_norm": 0.2240174412727356,
      "learning_rate": 0.000493308779063004,
      "loss": 2.2183,
      "step": 3190
    },
    {
      "epoch": 16.666666666666668,
      "grad_norm": 0.24677005410194397,
      "learning_rate": 0.0004932612176449559,
      "loss": 2.215,
      "step": 3200
    },
    {
      "epoch": 16.71875,
      "grad_norm": 0.2298608273267746,
      "learning_rate": 0.0004932134901000852,
      "loss": 2.2106,
      "step": 3210
    },
    {
      "epoch": 16.770833333333332,
      "grad_norm": 0.22385942935943604,
      "learning_rate": 0.0004931655964609857,
      "loss": 2.2159,
      "step": 3220
    },
    {
      "epoch": 16.822916666666668,
      "grad_norm": 0.23769187927246094,
      "learning_rate": 0.0004931175367603645,
      "loss": 2.2211,
      "step": 3230
    },
    {
      "epoch": 16.875,
      "grad_norm": 0.2837609648704529,
      "learning_rate": 0.0004930693110310426,
      "loss": 2.2177,
      "step": 3240
    },
    {
      "epoch": 16.927083333333332,
      "grad_norm": 0.22614803910255432,
      "learning_rate": 0.0004930209193059538,
      "loss": 2.2153,
      "step": 3250
    },
    {
      "epoch": 16.979166666666668,
      "grad_norm": 0.25733789801597595,
      "learning_rate": 0.0004929723616181459,
      "loss": 2.2203,
      "step": 3260
    },
    {
      "epoch": 17.0,
      "eval_loss": 1.0963977575302124,
      "eval_runtime": 5.4332,
      "eval_samples_per_second": 3654.564,
      "eval_steps_per_second": 14.356,
      "step": 3264
    },
    {
      "epoch": 17.03125,
      "grad_norm": 0.20476548373699188,
      "learning_rate": 0.0004929236380007793,
      "loss": 2.2134,
      "step": 3270
    },
    {
      "epoch": 17.083333333333332,
      "grad_norm": 0.2391727715730667,
      "learning_rate": 0.0004928747484871284,
      "loss": 2.2164,
      "step": 3280
    },
    {
      "epoch": 17.135416666666668,
      "grad_norm": 0.21239517629146576,
      "learning_rate": 0.0004928256931105804,
      "loss": 2.2048,
      "step": 3290
    },
    {
      "epoch": 17.1875,
      "grad_norm": 0.24181261658668518,
      "learning_rate": 0.0004927764719046361,
      "loss": 2.2173,
      "step": 3300
    },
    {
      "epoch": 17.239583333333332,
      "grad_norm": 0.3017377555370331,
      "learning_rate": 0.0004927270849029095,
      "loss": 2.2282,
      "step": 3310
    },
    {
      "epoch": 17.291666666666668,
      "grad_norm": 0.2340705394744873,
      "learning_rate": 0.0004926775321391274,
      "loss": 2.2007,
      "step": 3320
    },
    {
      "epoch": 17.34375,
      "grad_norm": 0.24104894697666168,
      "learning_rate": 0.0004926278136471306,
      "loss": 2.2153,
      "step": 3330
    },
    {
      "epoch": 17.395833333333332,
      "grad_norm": 0.3746702969074249,
      "learning_rate": 0.0004925779294608723,
      "loss": 2.2265,
      "step": 3340
    },
    {
      "epoch": 17.447916666666668,
      "grad_norm": 0.23711815476417542,
      "learning_rate": 0.0004925278796144193,
      "loss": 2.2028,
      "step": 3350
    },
    {
      "epoch": 17.5,
      "grad_norm": 0.28824254870414734,
      "learning_rate": 0.0004924776641419512,
      "loss": 2.2148,
      "step": 3360
    },
    {
      "epoch": 17.552083333333332,
      "grad_norm": 0.23196180164813995,
      "learning_rate": 0.0004924272830777614,
      "loss": 2.223,
      "step": 3370
    },
    {
      "epoch": 17.604166666666668,
      "grad_norm": 0.219869926571846,
      "learning_rate": 0.0004923767364562555,
      "loss": 2.1988,
      "step": 3380
    },
    {
      "epoch": 17.65625,
      "grad_norm": 0.2141842544078827,
      "learning_rate": 0.0004923260243119525,
      "loss": 2.2047,
      "step": 3390
    },
    {
      "epoch": 17.708333333333332,
      "grad_norm": 0.21761475503444672,
      "learning_rate": 0.0004922751466794848,
      "loss": 2.1942,
      "step": 3400
    },
    {
      "epoch": 17.760416666666668,
      "grad_norm": 0.19711945950984955,
      "learning_rate": 0.0004922241035935973,
      "loss": 2.214,
      "step": 3410
    },
    {
      "epoch": 17.8125,
      "grad_norm": 0.24978302419185638,
      "learning_rate": 0.0004921728950891483,
      "loss": 2.2109,
      "step": 3420
    },
    {
      "epoch": 17.864583333333332,
      "grad_norm": 0.23711995780467987,
      "learning_rate": 0.0004921215212011087,
      "loss": 2.2094,
      "step": 3430
    },
    {
      "epoch": 17.916666666666668,
      "grad_norm": 0.2188136875629425,
      "learning_rate": 0.0004920699819645626,
      "loss": 2.2071,
      "step": 3440
    },
    {
      "epoch": 17.96875,
      "grad_norm": 0.2696889340877533,
      "learning_rate": 0.0004920182774147069,
      "loss": 2.2071,
      "step": 3450
    },
    {
      "epoch": 18.0,
      "eval_loss": 1.094240665435791,
      "eval_runtime": 5.4564,
      "eval_samples_per_second": 3639.008,
      "eval_steps_per_second": 14.295,
      "step": 3456
    },
    {
      "epoch": 18.020833333333332,
      "grad_norm": 0.34354159235954285,
      "learning_rate": 0.0004919664075868515,
      "loss": 2.2052,
      "step": 3460
    },
    {
      "epoch": 18.072916666666668,
      "grad_norm": 0.26286181807518005,
      "learning_rate": 0.000491914372516419,
      "loss": 2.1942,
      "step": 3470
    },
    {
      "epoch": 18.125,
      "grad_norm": 0.3216232359409332,
      "learning_rate": 0.0004918621722389449,
      "loss": 2.212,
      "step": 3480
    },
    {
      "epoch": 18.177083333333332,
      "grad_norm": 0.24050648510456085,
      "learning_rate": 0.0004918098067900778,
      "loss": 2.2178,
      "step": 3490
    },
    {
      "epoch": 18.229166666666668,
      "grad_norm": 0.23617495596408844,
      "learning_rate": 0.0004917572762055788,
      "loss": 2.2048,
      "step": 3500
    },
    {
      "epoch": 18.28125,
      "grad_norm": 0.244900643825531,
      "learning_rate": 0.0004917045805213217,
      "loss": 2.2118,
      "step": 3510
    },
    {
      "epoch": 18.333333333333332,
      "grad_norm": 0.2479710727930069,
      "learning_rate": 0.0004916517197732933,
      "loss": 2.2159,
      "step": 3520
    },
    {
      "epoch": 18.385416666666668,
      "grad_norm": 0.2760242819786072,
      "learning_rate": 0.000491598693997593,
      "loss": 2.2026,
      "step": 3530
    },
    {
      "epoch": 18.4375,
      "grad_norm": 0.2229117751121521,
      "learning_rate": 0.0004915455032304329,
      "loss": 2.2084,
      "step": 3540
    },
    {
      "epoch": 18.489583333333332,
      "grad_norm": 0.26953932642936707,
      "learning_rate": 0.0004914921475081377,
      "loss": 2.211,
      "step": 3550
    },
    {
      "epoch": 18.541666666666668,
      "grad_norm": 0.23742856085300446,
      "learning_rate": 0.0004914386268671452,
      "loss": 2.2008,
      "step": 3560
    },
    {
      "epoch": 18.59375,
      "grad_norm": 0.25635039806365967,
      "learning_rate": 0.000491384941344005,
      "loss": 2.209,
      "step": 3570
    },
    {
      "epoch": 18.645833333333332,
      "grad_norm": 0.3139067590236664,
      "learning_rate": 0.00049133109097538,
      "loss": 2.201,
      "step": 3580
    },
    {
      "epoch": 18.697916666666668,
      "grad_norm": 0.22584855556488037,
      "learning_rate": 0.0004912770757980455,
      "loss": 2.2111,
      "step": 3590
    },
    {
      "epoch": 18.75,
      "grad_norm": 0.34735527634620667,
      "learning_rate": 0.0004912228958488892,
      "loss": 2.2045,
      "step": 3600
    },
    {
      "epoch": 18.802083333333332,
      "grad_norm": 0.20965251326560974,
      "learning_rate": 0.0004911685511649114,
      "loss": 2.2152,
      "step": 3610
    },
    {
      "epoch": 18.854166666666668,
      "grad_norm": 0.2251918762922287,
      "learning_rate": 0.0004911140417832251,
      "loss": 2.202,
      "step": 3620
    },
    {
      "epoch": 18.90625,
      "grad_norm": 0.36474859714508057,
      "learning_rate": 0.0004910593677410553,
      "loss": 2.2123,
      "step": 3630
    },
    {
      "epoch": 18.958333333333332,
      "grad_norm": 0.243262380361557,
      "learning_rate": 0.0004910045290757399,
      "loss": 2.1929,
      "step": 3640
    },
    {
      "epoch": 19.0,
      "eval_loss": 1.092529535293579,
      "eval_runtime": 5.4396,
      "eval_samples_per_second": 3650.268,
      "eval_steps_per_second": 14.339,
      "step": 3648
    },
    {
      "epoch": 19.010416666666668,
      "grad_norm": 0.22466999292373657,
      "learning_rate": 0.0004909495258247291,
      "loss": 2.1969,
      "step": 3650
    },
    {
      "epoch": 19.0625,
      "grad_norm": 0.26139771938323975,
      "learning_rate": 0.0004908943580255855,
      "loss": 2.2171,
      "step": 3660
    },
    {
      "epoch": 19.114583333333332,
      "grad_norm": 0.2267082780599594,
      "learning_rate": 0.0004908390257159839,
      "loss": 2.1897,
      "step": 3670
    },
    {
      "epoch": 19.166666666666668,
      "grad_norm": 0.24856816232204437,
      "learning_rate": 0.0004907835289337116,
      "loss": 2.1998,
      "step": 3680
    },
    {
      "epoch": 19.21875,
      "grad_norm": 0.24610865116119385,
      "learning_rate": 0.0004907278677166683,
      "loss": 2.1927,
      "step": 3690
    },
    {
      "epoch": 19.270833333333332,
      "grad_norm": 0.2526984214782715,
      "learning_rate": 0.0004906720421028658,
      "loss": 2.2041,
      "step": 3700
    },
    {
      "epoch": 19.322916666666668,
      "grad_norm": 0.27132248878479004,
      "learning_rate": 0.0004906160521304285,
      "loss": 2.2132,
      "step": 3710
    },
    {
      "epoch": 19.375,
      "grad_norm": 0.2886433005332947,
      "learning_rate": 0.0004905598978375926,
      "loss": 2.206,
      "step": 3720
    },
    {
      "epoch": 19.427083333333332,
      "grad_norm": 0.24821671843528748,
      "learning_rate": 0.0004905035792627066,
      "loss": 2.1998,
      "step": 3730
    },
    {
      "epoch": 19.479166666666668,
      "grad_norm": 0.2603980302810669,
      "learning_rate": 0.0004904470964442316,
      "loss": 2.1896,
      "step": 3740
    },
    {
      "epoch": 19.53125,
      "grad_norm": 0.245404452085495,
      "learning_rate": 0.0004903904494207405,
      "loss": 2.2233,
      "step": 3750
    },
    {
      "epoch": 19.583333333333332,
      "grad_norm": 0.32721731066703796,
      "learning_rate": 0.0004903336382309183,
      "loss": 2.2176,
      "step": 3760
    },
    {
      "epoch": 19.635416666666668,
      "grad_norm": 0.2612970173358917,
      "learning_rate": 0.0004902766629135625,
      "loss": 2.198,
      "step": 3770
    },
    {
      "epoch": 19.6875,
      "grad_norm": 0.22384272515773773,
      "learning_rate": 0.0004902195235075821,
      "loss": 2.2077,
      "step": 3780
    },
    {
      "epoch": 19.739583333333332,
      "grad_norm": 0.29638904333114624,
      "learning_rate": 0.0004901622200519986,
      "loss": 2.2016,
      "step": 3790
    },
    {
      "epoch": 19.791666666666668,
      "grad_norm": 0.24928104877471924,
      "learning_rate": 0.0004901047525859456,
      "loss": 2.193,
      "step": 3800
    },
    {
      "epoch": 19.84375,
      "grad_norm": 0.23204027116298676,
      "learning_rate": 0.0004900471211486682,
      "loss": 2.2008,
      "step": 3810
    },
    {
      "epoch": 19.895833333333332,
      "grad_norm": 0.2657718062400818,
      "learning_rate": 0.000489989325779524,
      "loss": 2.1999,
      "step": 3820
    },
    {
      "epoch": 19.947916666666668,
      "grad_norm": 0.2001722753047943,
      "learning_rate": 0.0004899313665179823,
      "loss": 2.1888,
      "step": 3830
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.22826549410820007,
      "learning_rate": 0.0004898732434036243,
      "loss": 2.1997,
      "step": 3840
    },
    {
      "epoch": 20.0,
      "eval_loss": 1.092218041419983,
      "eval_runtime": 5.6117,
      "eval_samples_per_second": 3538.296,
      "eval_steps_per_second": 13.899,
      "step": 3840
    },
    {
      "epoch": 20.052083333333332,
      "grad_norm": 0.2141696661710739,
      "learning_rate": 0.0004898149564761434,
      "loss": 2.2002,
      "step": 3850
    },
    {
      "epoch": 20.104166666666668,
      "grad_norm": 0.2666621506214142,
      "learning_rate": 0.0004897565057753443,
      "loss": 2.2011,
      "step": 3860
    },
    {
      "epoch": 20.15625,
      "grad_norm": 0.2289241999387741,
      "learning_rate": 0.0004896978913411441,
      "loss": 2.1979,
      "step": 3870
    },
    {
      "epoch": 20.208333333333332,
      "grad_norm": 0.2646303176879883,
      "learning_rate": 0.0004896391132135715,
      "loss": 2.191,
      "step": 3880
    },
    {
      "epoch": 20.260416666666668,
      "grad_norm": 0.2709728181362152,
      "learning_rate": 0.0004895801714327668,
      "loss": 2.1914,
      "step": 3890
    },
    {
      "epoch": 20.3125,
      "grad_norm": 0.24759991466999054,
      "learning_rate": 0.0004895210660389825,
      "loss": 2.192,
      "step": 3900
    },
    {
      "epoch": 20.364583333333332,
      "grad_norm": 0.2501601576805115,
      "learning_rate": 0.0004894617970725825,
      "loss": 2.2028,
      "step": 3910
    },
    {
      "epoch": 20.416666666666668,
      "grad_norm": 0.3107547461986542,
      "learning_rate": 0.0004894023645740423,
      "loss": 2.1988,
      "step": 3920
    },
    {
      "epoch": 20.46875,
      "grad_norm": 0.28573912382125854,
      "learning_rate": 0.0004893427685839496,
      "loss": 2.1932,
      "step": 3930
    },
    {
      "epoch": 20.520833333333332,
      "grad_norm": 0.2575124204158783,
      "learning_rate": 0.0004892830091430031,
      "loss": 2.2027,
      "step": 3940
    },
    {
      "epoch": 20.572916666666668,
      "grad_norm": 0.24788130819797516,
      "learning_rate": 0.0004892230862920135,
      "loss": 2.1945,
      "step": 3950
    },
    {
      "epoch": 20.625,
      "grad_norm": 0.6880726218223572,
      "learning_rate": 0.0004891630000719032,
      "loss": 2.1959,
      "step": 3960
    },
    {
      "epoch": 20.677083333333332,
      "grad_norm": 0.29334431886672974,
      "learning_rate": 0.0004891027505237061,
      "loss": 2.2021,
      "step": 3970
    },
    {
      "epoch": 20.729166666666668,
      "grad_norm": 0.2652110159397125,
      "learning_rate": 0.0004890423376885671,
      "loss": 2.2002,
      "step": 3980
    },
    {
      "epoch": 20.78125,
      "grad_norm": 0.24139687418937683,
      "learning_rate": 0.0004889817616077433,
      "loss": 2.2082,
      "step": 3990
    },
    {
      "epoch": 20.833333333333332,
      "grad_norm": 0.3138728141784668,
      "learning_rate": 0.0004889210223226032,
      "loss": 2.2142,
      "step": 4000
    },
    {
      "epoch": 20.885416666666668,
      "grad_norm": 0.2713223099708557,
      "learning_rate": 0.0004888601198746263,
      "loss": 2.194,
      "step": 4010
    },
    {
      "epoch": 20.9375,
      "grad_norm": 0.23193372786045074,
      "learning_rate": 0.0004887990543054041,
      "loss": 2.2011,
      "step": 4020
    },
    {
      "epoch": 20.989583333333332,
      "grad_norm": 0.24236120283603668,
      "learning_rate": 0.0004887378256566389,
      "loss": 2.1967,
      "step": 4030
    },
    {
      "epoch": 21.0,
      "eval_loss": 1.0911433696746826,
      "eval_runtime": 5.4471,
      "eval_samples_per_second": 3645.264,
      "eval_steps_per_second": 14.32,
      "step": 4032
    },
    {
      "epoch": 21.041666666666668,
      "grad_norm": 0.2599871754646301,
      "learning_rate": 0.000488676433970145,
      "loss": 2.2026,
      "step": 4040
    },
    {
      "epoch": 21.09375,
      "grad_norm": 0.26126784086227417,
      "learning_rate": 0.0004886148792878476,
      "loss": 2.2067,
      "step": 4050
    },
    {
      "epoch": 21.145833333333332,
      "grad_norm": 0.24858835339546204,
      "learning_rate": 0.0004885531616517832,
      "loss": 2.1814,
      "step": 4060
    },
    {
      "epoch": 21.197916666666668,
      "grad_norm": 0.2603242099285126,
      "learning_rate": 0.0004884912811040998,
      "loss": 2.1955,
      "step": 4070
    },
    {
      "epoch": 21.25,
      "grad_norm": 0.27523601055145264,
      "learning_rate": 0.0004884292376870567,
      "loss": 2.1843,
      "step": 4080
    },
    {
      "epoch": 21.302083333333332,
      "grad_norm": 0.45048147439956665,
      "learning_rate": 0.0004883670314430243,
      "loss": 2.1844,
      "step": 4090
    },
    {
      "epoch": 21.354166666666668,
      "grad_norm": 0.2677202522754669,
      "learning_rate": 0.000488304662414484,
      "loss": 2.2024,
      "step": 4100
    },
    {
      "epoch": 21.40625,
      "grad_norm": 0.2941351532936096,
      "learning_rate": 0.0004882421306440287,
      "loss": 2.1961,
      "step": 4110
    },
    {
      "epoch": 21.458333333333332,
      "grad_norm": 0.2572305500507355,
      "learning_rate": 0.0004881794361743623,
      "loss": 2.1875,
      "step": 4120
    },
    {
      "epoch": 21.510416666666668,
      "grad_norm": 0.28323453664779663,
      "learning_rate": 0.0004881165790482998,
      "loss": 2.1953,
      "step": 4130
    },
    {
      "epoch": 21.5625,
      "grad_norm": 0.2984142005443573,
      "learning_rate": 0.00048805355930876733,
      "loss": 2.1997,
      "step": 4140
    },
    {
      "epoch": 21.614583333333332,
      "grad_norm": 0.2722153663635254,
      "learning_rate": 0.000487990376998802,
      "loss": 2.2023,
      "step": 4150
    },
    {
      "epoch": 21.666666666666668,
      "grad_norm": 0.4372085928916931,
      "learning_rate": 0.000487927032161552,
      "loss": 2.1938,
      "step": 4160
    },
    {
      "epoch": 21.71875,
      "grad_norm": 0.25354093313217163,
      "learning_rate": 0.0004878635248402765,
      "loss": 2.2067,
      "step": 4170
    },
    {
      "epoch": 21.770833333333332,
      "grad_norm": 0.33385512232780457,
      "learning_rate": 0.00048779985507834556,
      "loss": 2.1951,
      "step": 4180
    },
    {
      "epoch": 21.822916666666668,
      "grad_norm": 0.45686787366867065,
      "learning_rate": 0.00048773602291924035,
      "loss": 2.1981,
      "step": 4190
    },
    {
      "epoch": 21.875,
      "grad_norm": 0.2954925298690796,
      "learning_rate": 0.0004876720284065528,
      "loss": 2.1859,
      "step": 4200
    },
    {
      "epoch": 21.927083333333332,
      "grad_norm": 0.26002761721611023,
      "learning_rate": 0.00048760787158398563,
      "loss": 2.1963,
      "step": 4210
    },
    {
      "epoch": 21.979166666666668,
      "grad_norm": 0.29125919938087463,
      "learning_rate": 0.00048754355249535264,
      "loss": 2.2012,
      "step": 4220
    },
    {
      "epoch": 22.0,
      "eval_loss": 1.0902093648910522,
      "eval_runtime": 5.4326,
      "eval_samples_per_second": 3654.946,
      "eval_steps_per_second": 14.358,
      "step": 4224
    },
    {
      "epoch": 22.03125,
      "grad_norm": 0.2980376183986664,
      "learning_rate": 0.0004874790711845783,
      "loss": 2.1906,
      "step": 4230
    },
    {
      "epoch": 22.083333333333332,
      "grad_norm": 0.28186219930648804,
      "learning_rate": 0.0004874144276956979,
      "loss": 2.1945,
      "step": 4240
    },
    {
      "epoch": 22.135416666666668,
      "grad_norm": 0.2963946759700775,
      "learning_rate": 0.0004873496220728574,
      "loss": 2.1981,
      "step": 4250
    },
    {
      "epoch": 22.1875,
      "grad_norm": 0.29266980290412903,
      "learning_rate": 0.00048728465436031365,
      "loss": 2.2023,
      "step": 4260
    },
    {
      "epoch": 22.239583333333332,
      "grad_norm": 0.2655448913574219,
      "learning_rate": 0.00048721952460243403,
      "loss": 2.193,
      "step": 4270
    },
    {
      "epoch": 22.291666666666668,
      "grad_norm": 0.40092048048973083,
      "learning_rate": 0.00048715423284369664,
      "loss": 2.1867,
      "step": 4280
    },
    {
      "epoch": 22.34375,
      "grad_norm": 0.24049454927444458,
      "learning_rate": 0.0004870887791286903,
      "loss": 2.1944,
      "step": 4290
    },
    {
      "epoch": 22.395833333333332,
      "grad_norm": 0.2753801643848419,
      "learning_rate": 0.0004870231635021144,
      "loss": 2.1841,
      "step": 4300
    },
    {
      "epoch": 22.447916666666668,
      "grad_norm": 0.27999910712242126,
      "learning_rate": 0.0004869573860087787,
      "loss": 2.196,
      "step": 4310
    },
    {
      "epoch": 22.5,
      "grad_norm": 0.44961535930633545,
      "learning_rate": 0.00048689144669360375,
      "loss": 2.1848,
      "step": 4320
    },
    {
      "epoch": 22.552083333333332,
      "grad_norm": 0.24246419966220856,
      "learning_rate": 0.0004868253456016205,
      "loss": 2.1938,
      "step": 4330
    },
    {
      "epoch": 22.604166666666668,
      "grad_norm": 0.2590618431568146,
      "learning_rate": 0.0004867590827779704,
      "loss": 2.1978,
      "step": 4340
    },
    {
      "epoch": 22.65625,
      "grad_norm": 0.23709246516227722,
      "learning_rate": 0.00048669265826790546,
      "loss": 2.2058,
      "step": 4350
    },
    {
      "epoch": 22.708333333333332,
      "grad_norm": 0.2629351317882538,
      "learning_rate": 0.00048662607211678784,
      "loss": 2.1894,
      "step": 4360
    },
    {
      "epoch": 22.760416666666668,
      "grad_norm": 0.25325116515159607,
      "learning_rate": 0.0004865593243700903,
      "loss": 2.2024,
      "step": 4370
    },
    {
      "epoch": 22.8125,
      "grad_norm": 0.2990657091140747,
      "learning_rate": 0.00048649241507339595,
      "loss": 2.1824,
      "step": 4380
    },
    {
      "epoch": 22.864583333333332,
      "grad_norm": 0.2696399688720703,
      "learning_rate": 0.00048642534427239804,
      "loss": 2.1965,
      "step": 4390
    },
    {
      "epoch": 22.916666666666668,
      "grad_norm": 0.2896154820919037,
      "learning_rate": 0.0004863581120129004,
      "loss": 2.188,
      "step": 4400
    },
    {
      "epoch": 22.96875,
      "grad_norm": 0.27282094955444336,
      "learning_rate": 0.00048629071834081696,
      "loss": 2.1733,
      "step": 4410
    },
    {
      "epoch": 23.0,
      "eval_loss": 1.0881074666976929,
      "eval_runtime": 5.431,
      "eval_samples_per_second": 3656.036,
      "eval_steps_per_second": 14.362,
      "step": 4416
    },
    {
      "epoch": 23.020833333333332,
      "grad_norm": 0.24608147144317627,
      "learning_rate": 0.0004862231633021718,
      "loss": 2.1808,
      "step": 4420
    },
    {
      "epoch": 23.072916666666668,
      "grad_norm": 0.34443458914756775,
      "learning_rate": 0.0004861554469430994,
      "loss": 2.1875,
      "step": 4430
    },
    {
      "epoch": 23.125,
      "grad_norm": 0.29031965136528015,
      "learning_rate": 0.00048608756930984423,
      "loss": 2.1947,
      "step": 4440
    },
    {
      "epoch": 23.177083333333332,
      "grad_norm": 0.28987497091293335,
      "learning_rate": 0.0004860195304487609,
      "loss": 2.1841,
      "step": 4450
    },
    {
      "epoch": 23.229166666666668,
      "grad_norm": 0.2612026035785675,
      "learning_rate": 0.0004859513304063144,
      "loss": 2.1738,
      "step": 4460
    },
    {
      "epoch": 23.28125,
      "grad_norm": 0.25099262595176697,
      "learning_rate": 0.00048588296922907935,
      "loss": 2.1749,
      "step": 4470
    },
    {
      "epoch": 23.333333333333332,
      "grad_norm": 0.2692762017250061,
      "learning_rate": 0.00048581444696374086,
      "loss": 2.1826,
      "step": 4480
    },
    {
      "epoch": 23.385416666666668,
      "grad_norm": 0.4586580693721771,
      "learning_rate": 0.00048574576365709377,
      "loss": 2.1943,
      "step": 4490
    },
    {
      "epoch": 23.4375,
      "grad_norm": 0.25332239270210266,
      "learning_rate": 0.00048567691935604284,
      "loss": 2.1924,
      "step": 4500
    },
    {
      "epoch": 23.489583333333332,
      "grad_norm": 0.2902185618877411,
      "learning_rate": 0.0004856079141076031,
      "loss": 2.1761,
      "step": 4510
    },
    {
      "epoch": 23.541666666666668,
      "grad_norm": 0.2958855926990509,
      "learning_rate": 0.0004855387479588991,
      "loss": 2.1918,
      "step": 4520
    },
    {
      "epoch": 23.59375,
      "grad_norm": 0.25177091360092163,
      "learning_rate": 0.0004854694209571656,
      "loss": 2.1866,
      "step": 4530
    },
    {
      "epoch": 23.645833333333332,
      "grad_norm": 0.26156944036483765,
      "learning_rate": 0.00048539993314974705,
      "loss": 2.197,
      "step": 4540
    },
    {
      "epoch": 23.697916666666668,
      "grad_norm": 0.26690566539764404,
      "learning_rate": 0.0004853302845840978,
      "loss": 2.1903,
      "step": 4550
    },
    {
      "epoch": 23.75,
      "grad_norm": 0.28024032711982727,
      "learning_rate": 0.00048526047530778174,
      "loss": 2.1883,
      "step": 4560
    },
    {
      "epoch": 23.802083333333332,
      "grad_norm": 0.27390798926353455,
      "learning_rate": 0.0004851905053684728,
      "loss": 2.1908,
      "step": 4570
    },
    {
      "epoch": 23.854166666666668,
      "grad_norm": 0.2621907889842987,
      "learning_rate": 0.0004851203748139545,
      "loss": 2.1983,
      "step": 4580
    },
    {
      "epoch": 23.90625,
      "grad_norm": 0.25340551137924194,
      "learning_rate": 0.00048505008369212024,
      "loss": 2.1918,
      "step": 4590
    },
    {
      "epoch": 23.958333333333332,
      "grad_norm": 0.2835940420627594,
      "learning_rate": 0.0004849796320509727,
      "loss": 2.1847,
      "step": 4600
    },
    {
      "epoch": 24.0,
      "eval_loss": 1.088287353515625,
      "eval_runtime": 5.4229,
      "eval_samples_per_second": 3661.505,
      "eval_steps_per_second": 14.383,
      "step": 4608
    },
    {
      "epoch": 24.010416666666668,
      "grad_norm": 0.23769637942314148,
      "learning_rate": 0.0004849090199386245,
      "loss": 2.178,
      "step": 4610
    },
    {
      "epoch": 24.0625,
      "grad_norm": 0.23617865145206451,
      "learning_rate": 0.00048483824740329763,
      "loss": 2.1842,
      "step": 4620
    },
    {
      "epoch": 24.114583333333332,
      "grad_norm": 0.25828662514686584,
      "learning_rate": 0.0004847673144933239,
      "loss": 2.1783,
      "step": 4630
    },
    {
      "epoch": 24.166666666666668,
      "grad_norm": 0.22963988780975342,
      "learning_rate": 0.0004846962212571443,
      "loss": 2.1848,
      "step": 4640
    },
    {
      "epoch": 24.21875,
      "grad_norm": 0.2966330051422119,
      "learning_rate": 0.00048462496774330966,
      "loss": 2.1841,
      "step": 4650
    },
    {
      "epoch": 24.270833333333332,
      "grad_norm": 0.25928428769111633,
      "learning_rate": 0.00048455355400048,
      "loss": 2.1791,
      "step": 4660
    },
    {
      "epoch": 24.322916666666668,
      "grad_norm": 0.4762410521507263,
      "learning_rate": 0.0004844819800774249,
      "loss": 2.1869,
      "step": 4670
    },
    {
      "epoch": 24.375,
      "grad_norm": 0.3816896975040436,
      "learning_rate": 0.0004844102460230233,
      "loss": 2.1923,
      "step": 4680
    },
    {
      "epoch": 24.427083333333332,
      "grad_norm": 0.3851388692855835,
      "learning_rate": 0.0004843383518862634,
      "loss": 2.1905,
      "step": 4690
    },
    {
      "epoch": 24.479166666666668,
      "grad_norm": 0.26969069242477417,
      "learning_rate": 0.00048426629771624295,
      "loss": 2.1862,
      "step": 4700
    },
    {
      "epoch": 24.53125,
      "grad_norm": 0.3036588132381439,
      "learning_rate": 0.00048419408356216876,
      "loss": 2.1792,
      "step": 4710
    },
    {
      "epoch": 24.583333333333332,
      "grad_norm": 0.2625867426395416,
      "learning_rate": 0.00048412170947335697,
      "loss": 2.1934,
      "step": 4720
    },
    {
      "epoch": 24.635416666666668,
      "grad_norm": 0.26636451482772827,
      "learning_rate": 0.000484049175499233,
      "loss": 2.1817,
      "step": 4730
    },
    {
      "epoch": 24.6875,
      "grad_norm": 0.29999539256095886,
      "learning_rate": 0.00048397648168933144,
      "loss": 2.1921,
      "step": 4740
    },
    {
      "epoch": 24.739583333333332,
      "grad_norm": 0.31731757521629333,
      "learning_rate": 0.00048390362809329595,
      "loss": 2.1855,
      "step": 4750
    },
    {
      "epoch": 24.791666666666668,
      "grad_norm": 0.2681881785392761,
      "learning_rate": 0.0004838306147608794,
      "loss": 2.1807,
      "step": 4760
    },
    {
      "epoch": 24.84375,
      "grad_norm": 0.3555835485458374,
      "learning_rate": 0.00048375744174194367,
      "loss": 2.193,
      "step": 4770
    },
    {
      "epoch": 24.895833333333332,
      "grad_norm": 0.3053831458091736,
      "learning_rate": 0.0004836841090864599,
      "loss": 2.169,
      "step": 4780
    },
    {
      "epoch": 24.947916666666668,
      "grad_norm": 0.253949910402298,
      "learning_rate": 0.0004836106168445079,
      "loss": 2.1947,
      "step": 4790
    },
    {
      "epoch": 25.0,
      "grad_norm": 0.3013908863067627,
      "learning_rate": 0.0004835369650662767,
      "loss": 2.1696,
      "step": 4800
    },
    {
      "epoch": 25.0,
      "eval_loss": 1.0854438543319702,
      "eval_runtime": 5.4302,
      "eval_samples_per_second": 3656.576,
      "eval_steps_per_second": 14.364,
      "step": 4800
    },
    {
      "epoch": 25.052083333333332,
      "grad_norm": 0.3357531428337097,
      "learning_rate": 0.0004834631538020643,
      "loss": 2.163,
      "step": 4810
    },
    {
      "epoch": 25.104166666666668,
      "grad_norm": 0.3369262218475342,
      "learning_rate": 0.0004833891831022774,
      "loss": 2.1805,
      "step": 4820
    },
    {
      "epoch": 25.15625,
      "grad_norm": 0.32946154475212097,
      "learning_rate": 0.0004833150530174319,
      "loss": 2.177,
      "step": 4830
    },
    {
      "epoch": 25.208333333333332,
      "grad_norm": 0.28030744194984436,
      "learning_rate": 0.0004832407635981523,
      "loss": 2.1758,
      "step": 4840
    },
    {
      "epoch": 25.260416666666668,
      "grad_norm": 0.2647608518600464,
      "learning_rate": 0.00048316631489517194,
      "loss": 2.1695,
      "step": 4850
    },
    {
      "epoch": 25.3125,
      "grad_norm": 0.3398423492908478,
      "learning_rate": 0.0004830917069593331,
      "loss": 2.1686,
      "step": 4860
    },
    {
      "epoch": 25.364583333333332,
      "grad_norm": 0.34708648920059204,
      "learning_rate": 0.00048301693984158657,
      "loss": 2.1918,
      "step": 4870
    },
    {
      "epoch": 25.416666666666668,
      "grad_norm": 0.283122718334198,
      "learning_rate": 0.00048294201359299195,
      "loss": 2.1893,
      "step": 4880
    },
    {
      "epoch": 25.46875,
      "grad_norm": 0.2927153408527374,
      "learning_rate": 0.0004828669282647177,
      "loss": 2.1823,
      "step": 4890
    },
    {
      "epoch": 25.520833333333332,
      "grad_norm": 0.2871679365634918,
      "learning_rate": 0.0004827916839080405,
      "loss": 2.1808,
      "step": 4900
    },
    {
      "epoch": 25.572916666666668,
      "grad_norm": 0.25413092970848083,
      "learning_rate": 0.00048271628057434604,
      "loss": 2.1864,
      "step": 4910
    },
    {
      "epoch": 25.625,
      "grad_norm": 0.27477407455444336,
      "learning_rate": 0.0004826407183151284,
      "loss": 2.1716,
      "step": 4920
    },
    {
      "epoch": 25.677083333333332,
      "grad_norm": 0.2523881793022156,
      "learning_rate": 0.0004825649971819902,
      "loss": 2.2005,
      "step": 4930
    },
    {
      "epoch": 25.729166666666668,
      "grad_norm": 0.271980345249176,
      "learning_rate": 0.0004824891172266425,
      "loss": 2.1881,
      "step": 4940
    },
    {
      "epoch": 25.78125,
      "grad_norm": 0.27739766240119934,
      "learning_rate": 0.000482413078500905,
      "loss": 2.1895,
      "step": 4950
    },
    {
      "epoch": 25.833333333333332,
      "grad_norm": 0.24616311490535736,
      "learning_rate": 0.0004823368810567056,
      "loss": 2.1837,
      "step": 4960
    },
    {
      "epoch": 25.885416666666668,
      "grad_norm": 0.2662138342857361,
      "learning_rate": 0.0004822605249460808,
      "loss": 2.1859,
      "step": 4970
    },
    {
      "epoch": 25.9375,
      "grad_norm": 0.3562179505825043,
      "learning_rate": 0.0004821840102211753,
      "loss": 2.1858,
      "step": 4980
    },
    {
      "epoch": 25.989583333333332,
      "grad_norm": 0.38053712248802185,
      "learning_rate": 0.0004821073369342422,
      "loss": 2.1747,
      "step": 4990
    },
    {
      "epoch": 26.0,
      "eval_loss": 1.0875524282455444,
      "eval_runtime": 5.4357,
      "eval_samples_per_second": 3652.889,
      "eval_steps_per_second": 14.35,
      "step": 4992
    },
    {
      "epoch": 26.041666666666668,
      "grad_norm": 0.29041990637779236,
      "learning_rate": 0.0004820305051376429,
      "loss": 2.1811,
      "step": 5000
    },
    {
      "epoch": 26.09375,
      "grad_norm": 0.29228031635284424,
      "learning_rate": 0.00048195351488384685,
      "loss": 2.1746,
      "step": 5010
    },
    {
      "epoch": 26.145833333333332,
      "grad_norm": 0.2897540330886841,
      "learning_rate": 0.0004818763662254322,
      "loss": 2.1664,
      "step": 5020
    },
    {
      "epoch": 26.197916666666668,
      "grad_norm": 0.2789416015148163,
      "learning_rate": 0.0004817990592150846,
      "loss": 2.1696,
      "step": 5030
    },
    {
      "epoch": 26.25,
      "grad_norm": 0.2687371075153351,
      "learning_rate": 0.0004817215939055984,
      "loss": 2.1772,
      "step": 5040
    },
    {
      "epoch": 26.302083333333332,
      "grad_norm": 0.272823691368103,
      "learning_rate": 0.00048164397034987583,
      "loss": 2.1716,
      "step": 5050
    },
    {
      "epoch": 26.354166666666668,
      "grad_norm": 0.32159000635147095,
      "learning_rate": 0.00048156618860092714,
      "loss": 2.1796,
      "step": 5060
    },
    {
      "epoch": 26.40625,
      "grad_norm": 0.29560044407844543,
      "learning_rate": 0.0004814882487118708,
      "loss": 2.1815,
      "step": 5070
    },
    {
      "epoch": 26.458333333333332,
      "grad_norm": 0.31218501925468445,
      "learning_rate": 0.0004814101507359331,
      "loss": 2.196,
      "step": 5080
    },
    {
      "epoch": 26.510416666666668,
      "grad_norm": 0.2704387903213501,
      "learning_rate": 0.00048133189472644825,
      "loss": 2.1739,
      "step": 5090
    },
    {
      "epoch": 26.5625,
      "grad_norm": 0.29532453417778015,
      "learning_rate": 0.00048125348073685853,
      "loss": 2.175,
      "step": 5100
    },
    {
      "epoch": 26.614583333333332,
      "grad_norm": 0.2913585603237152,
      "learning_rate": 0.0004811749088207141,
      "loss": 2.1669,
      "step": 5110
    },
    {
      "epoch": 26.666666666666668,
      "grad_norm": 0.2895503044128418,
      "learning_rate": 0.00048109617903167303,
      "loss": 2.1859,
      "step": 5120
    },
    {
      "epoch": 26.71875,
      "grad_norm": 0.3223091661930084,
      "learning_rate": 0.0004810172914235009,
      "loss": 2.1754,
      "step": 5130
    },
    {
      "epoch": 26.770833333333332,
      "grad_norm": 0.26642173528671265,
      "learning_rate": 0.0004809382460500714,
      "loss": 2.187,
      "step": 5140
    },
    {
      "epoch": 26.822916666666668,
      "grad_norm": 0.3151063323020935,
      "learning_rate": 0.00048085904296536573,
      "loss": 2.195,
      "step": 5150
    },
    {
      "epoch": 26.875,
      "grad_norm": 0.7059401869773865,
      "learning_rate": 0.000480779682223473,
      "loss": 2.1823,
      "step": 5160
    },
    {
      "epoch": 26.927083333333332,
      "grad_norm": 0.316890686750412,
      "learning_rate": 0.0004807001638785898,
      "loss": 2.1702,
      "step": 5170
    },
    {
      "epoch": 26.979166666666668,
      "grad_norm": 0.2994679808616638,
      "learning_rate": 0.00048062048798502057,
      "loss": 2.1877,
      "step": 5180
    },
    {
      "epoch": 27.0,
      "eval_loss": 1.0863182544708252,
      "eval_runtime": 5.429,
      "eval_samples_per_second": 3657.404,
      "eval_steps_per_second": 14.367,
      "step": 5184
    },
    {
      "epoch": 27.03125,
      "grad_norm": 0.2703229784965515,
      "learning_rate": 0.000480540654597177,
      "loss": 2.1814,
      "step": 5190
    },
    {
      "epoch": 27.083333333333332,
      "grad_norm": 0.2666497528553009,
      "learning_rate": 0.0004804606637695786,
      "loss": 2.1839,
      "step": 5200
    },
    {
      "epoch": 27.135416666666668,
      "grad_norm": 0.29249775409698486,
      "learning_rate": 0.00048038051555685245,
      "loss": 2.1761,
      "step": 5210
    },
    {
      "epoch": 27.1875,
      "grad_norm": 0.28288623690605164,
      "learning_rate": 0.00048030021001373293,
      "loss": 2.1858,
      "step": 5220
    },
    {
      "epoch": 27.239583333333332,
      "grad_norm": 0.36533433198928833,
      "learning_rate": 0.0004802197471950618,
      "loss": 2.1654,
      "step": 5230
    },
    {
      "epoch": 27.291666666666668,
      "grad_norm": 0.2653939425945282,
      "learning_rate": 0.00048013912715578854,
      "loss": 2.179,
      "step": 5240
    },
    {
      "epoch": 27.34375,
      "grad_norm": 0.3049033284187317,
      "learning_rate": 0.00048005834995096974,
      "loss": 2.1789,
      "step": 5250
    },
    {
      "epoch": 27.395833333333332,
      "grad_norm": 0.25756680965423584,
      "learning_rate": 0.0004799774156357694,
      "loss": 2.1797,
      "step": 5260
    },
    {
      "epoch": 27.447916666666668,
      "grad_norm": 0.47131893038749695,
      "learning_rate": 0.0004798963242654588,
      "loss": 2.16,
      "step": 5270
    },
    {
      "epoch": 27.5,
      "grad_norm": 0.2697443664073944,
      "learning_rate": 0.0004798150758954164,
      "loss": 2.1669,
      "step": 5280
    },
    {
      "epoch": 27.552083333333332,
      "grad_norm": 0.2646316587924957,
      "learning_rate": 0.00047973367058112815,
      "loss": 2.1957,
      "step": 5290
    },
    {
      "epoch": 27.604166666666668,
      "grad_norm": 0.2767805755138397,
      "learning_rate": 0.00047965210837818686,
      "loss": 2.1856,
      "step": 5300
    },
    {
      "epoch": 27.65625,
      "grad_norm": 0.30087682604789734,
      "learning_rate": 0.0004795703893422926,
      "loss": 2.183,
      "step": 5310
    },
    {
      "epoch": 27.708333333333332,
      "grad_norm": 0.28507745265960693,
      "learning_rate": 0.0004794885135292526,
      "loss": 2.1681,
      "step": 5320
    },
    {
      "epoch": 27.760416666666668,
      "grad_norm": 0.2779822051525116,
      "learning_rate": 0.0004794064809949811,
      "loss": 2.1675,
      "step": 5330
    },
    {
      "epoch": 27.8125,
      "grad_norm": 0.2538621723651886,
      "learning_rate": 0.0004793242917954994,
      "loss": 2.1642,
      "step": 5340
    },
    {
      "epoch": 27.864583333333332,
      "grad_norm": 0.5058121681213379,
      "learning_rate": 0.0004792419459869357,
      "loss": 2.1822,
      "step": 5350
    },
    {
      "epoch": 27.916666666666668,
      "grad_norm": 0.26179394125938416,
      "learning_rate": 0.0004791594436255253,
      "loss": 2.17,
      "step": 5360
    },
    {
      "epoch": 27.96875,
      "grad_norm": 0.2672344148159027,
      "learning_rate": 0.0004790767847676103,
      "loss": 2.1692,
      "step": 5370
    },
    {
      "epoch": 28.0,
      "eval_loss": 1.0842564105987549,
      "eval_runtime": 5.4635,
      "eval_samples_per_second": 3634.267,
      "eval_steps_per_second": 14.276,
      "step": 5376
    },
    {
      "epoch": 28.020833333333332,
      "grad_norm": 0.2588791251182556,
      "learning_rate": 0.0004789939694696397,
      "loss": 2.1804,
      "step": 5380
    },
    {
      "epoch": 28.072916666666668,
      "grad_norm": 0.31863999366760254,
      "learning_rate": 0.0004789109977881693,
      "loss": 2.1711,
      "step": 5390
    },
    {
      "epoch": 28.125,
      "grad_norm": 0.2746058702468872,
      "learning_rate": 0.0004788278697798618,
      "loss": 2.1706,
      "step": 5400
    },
    {
      "epoch": 28.177083333333332,
      "grad_norm": 0.2832642197608948,
      "learning_rate": 0.00047874458550148656,
      "loss": 2.1663,
      "step": 5410
    },
    {
      "epoch": 28.229166666666668,
      "grad_norm": 0.27632877230644226,
      "learning_rate": 0.00047866114500991967,
      "loss": 2.1826,
      "step": 5420
    },
    {
      "epoch": 28.28125,
      "grad_norm": 0.26707664132118225,
      "learning_rate": 0.000478577548362144,
      "loss": 2.1588,
      "step": 5430
    },
    {
      "epoch": 28.333333333333332,
      "grad_norm": 0.29071131348609924,
      "learning_rate": 0.00047849379561524895,
      "loss": 2.1681,
      "step": 5440
    },
    {
      "epoch": 28.385416666666668,
      "grad_norm": 0.2840331494808197,
      "learning_rate": 0.0004784098868264305,
      "loss": 2.1759,
      "step": 5450
    },
    {
      "epoch": 28.4375,
      "grad_norm": 0.24191223084926605,
      "learning_rate": 0.00047832582205299136,
      "loss": 2.1694,
      "step": 5460
    },
    {
      "epoch": 28.489583333333332,
      "grad_norm": 0.2761693298816681,
      "learning_rate": 0.0004782416013523405,
      "loss": 2.1767,
      "step": 5470
    },
    {
      "epoch": 28.541666666666668,
      "grad_norm": 0.26683560013771057,
      "learning_rate": 0.0004781572247819937,
      "loss": 2.1892,
      "step": 5480
    },
    {
      "epoch": 28.59375,
      "grad_norm": 0.27802178263664246,
      "learning_rate": 0.0004780726923995729,
      "loss": 2.1736,
      "step": 5490
    },
    {
      "epoch": 28.645833333333332,
      "grad_norm": 0.27296170592308044,
      "learning_rate": 0.0004779880042628066,
      "loss": 2.1928,
      "step": 5500
    },
    {
      "epoch": 28.697916666666668,
      "grad_norm": 0.44282233715057373,
      "learning_rate": 0.00047790316042952964,
      "loss": 2.1762,
      "step": 5510
    },
    {
      "epoch": 28.75,
      "grad_norm": 0.31741127371788025,
      "learning_rate": 0.00047781816095768313,
      "loss": 2.1666,
      "step": 5520
    },
    {
      "epoch": 28.802083333333332,
      "grad_norm": 0.3566749691963196,
      "learning_rate": 0.00047773300590531464,
      "loss": 2.1844,
      "step": 5530
    },
    {
      "epoch": 28.854166666666668,
      "grad_norm": 0.26356029510498047,
      "learning_rate": 0.0004776476953305777,
      "loss": 2.1717,
      "step": 5540
    },
    {
      "epoch": 28.90625,
      "grad_norm": 0.28023189306259155,
      "learning_rate": 0.00047756222929173236,
      "loss": 2.1682,
      "step": 5550
    },
    {
      "epoch": 28.958333333333332,
      "grad_norm": 0.6399245858192444,
      "learning_rate": 0.00047747660784714464,
      "loss": 2.169,
      "step": 5560
    },
    {
      "epoch": 29.0,
      "eval_loss": 1.085985541343689,
      "eval_runtime": 5.4536,
      "eval_samples_per_second": 3640.894,
      "eval_steps_per_second": 14.302,
      "step": 5568
    },
    {
      "epoch": 29.010416666666668,
      "grad_norm": 0.4029904007911682,
      "learning_rate": 0.0004773908310552866,
      "loss": 2.1594,
      "step": 5570
    },
    {
      "epoch": 29.0625,
      "grad_norm": 0.37907713651657104,
      "learning_rate": 0.00047730489897473673,
      "loss": 2.1647,
      "step": 5580
    },
    {
      "epoch": 29.114583333333332,
      "grad_norm": 0.3128792345523834,
      "learning_rate": 0.00047721881166417924,
      "loss": 2.1729,
      "step": 5590
    },
    {
      "epoch": 29.166666666666668,
      "grad_norm": 0.345440149307251,
      "learning_rate": 0.00047713256918240456,
      "loss": 2.1741,
      "step": 5600
    },
    {
      "epoch": 29.21875,
      "grad_norm": 0.287828654050827,
      "learning_rate": 0.000477046171588309,
      "loss": 2.17,
      "step": 5610
    },
    {
      "epoch": 29.270833333333332,
      "grad_norm": 0.36724939942359924,
      "learning_rate": 0.0004769596189408947,
      "loss": 2.1768,
      "step": 5620
    },
    {
      "epoch": 29.322916666666668,
      "grad_norm": 0.3338257968425751,
      "learning_rate": 0.0004768729112992699,
      "loss": 2.1707,
      "step": 5630
    },
    {
      "epoch": 29.375,
      "grad_norm": 0.2842925786972046,
      "learning_rate": 0.00047678604872264857,
      "loss": 2.1758,
      "step": 5640
    },
    {
      "epoch": 29.427083333333332,
      "grad_norm": 0.3516516089439392,
      "learning_rate": 0.00047669903127035043,
      "loss": 2.1742,
      "step": 5650
    },
    {
      "epoch": 29.479166666666668,
      "grad_norm": 0.30287253856658936,
      "learning_rate": 0.00047661185900180116,
      "loss": 2.1753,
      "step": 5660
    },
    {
      "epoch": 29.53125,
      "grad_norm": 0.2785395383834839,
      "learning_rate": 0.00047652453197653187,
      "loss": 2.1723,
      "step": 5670
    },
    {
      "epoch": 29.583333333333332,
      "grad_norm": 0.3298577070236206,
      "learning_rate": 0.00047643705025417963,
      "loss": 2.1741,
      "step": 5680
    },
    {
      "epoch": 29.635416666666668,
      "grad_norm": 0.2985081076622009,
      "learning_rate": 0.00047634941389448703,
      "loss": 2.1762,
      "step": 5690
    },
    {
      "epoch": 29.6875,
      "grad_norm": 0.33714598417282104,
      "learning_rate": 0.00047626162295730235,
      "loss": 2.1692,
      "step": 5700
    },
    {
      "epoch": 29.739583333333332,
      "grad_norm": 0.31139180064201355,
      "learning_rate": 0.00047617367750257936,
      "loss": 2.1661,
      "step": 5710
    },
    {
      "epoch": 29.791666666666668,
      "grad_norm": 0.36803269386291504,
      "learning_rate": 0.00047608557759037717,
      "loss": 2.1655,
      "step": 5720
    },
    {
      "epoch": 29.84375,
      "grad_norm": 0.36144620180130005,
      "learning_rate": 0.0004759973232808609,
      "loss": 2.182,
      "step": 5730
    },
    {
      "epoch": 29.895833333333332,
      "grad_norm": 0.6957780122756958,
      "learning_rate": 0.0004759089146343004,
      "loss": 2.1793,
      "step": 5740
    },
    {
      "epoch": 29.947916666666668,
      "grad_norm": 0.3266785740852356,
      "learning_rate": 0.0004758203517110716,
      "loss": 2.1721,
      "step": 5750
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.31719252467155457,
      "learning_rate": 0.0004757316345716554,
      "loss": 2.1722,
      "step": 5760
    },
    {
      "epoch": 30.0,
      "eval_loss": 1.0844106674194336,
      "eval_runtime": 5.4458,
      "eval_samples_per_second": 3646.143,
      "eval_steps_per_second": 14.323,
      "step": 5760
    },
    {
      "epoch": 30.052083333333332,
      "grad_norm": 0.2816460132598877,
      "learning_rate": 0.00047564276327663794,
      "loss": 2.1742,
      "step": 5770
    },
    {
      "epoch": 30.104166666666668,
      "grad_norm": 0.3008667826652527,
      "learning_rate": 0.0004755537378867109,
      "loss": 2.1686,
      "step": 5780
    },
    {
      "epoch": 30.15625,
      "grad_norm": 0.28804150223731995,
      "learning_rate": 0.00047546455846267117,
      "loss": 2.17,
      "step": 5790
    },
    {
      "epoch": 30.208333333333332,
      "grad_norm": 0.3415672481060028,
      "learning_rate": 0.0004753752250654206,
      "loss": 2.1658,
      "step": 5800
    },
    {
      "epoch": 30.260416666666668,
      "grad_norm": 0.2770758867263794,
      "learning_rate": 0.0004752857377559665,
      "loss": 2.1766,
      "step": 5810
    },
    {
      "epoch": 30.3125,
      "grad_norm": 0.29082319140434265,
      "learning_rate": 0.000475196096595421,
      "loss": 2.1506,
      "step": 5820
    },
    {
      "epoch": 30.364583333333332,
      "grad_norm": 0.31163373589515686,
      "learning_rate": 0.00047510630164500145,
      "loss": 2.1623,
      "step": 5830
    },
    {
      "epoch": 30.416666666666668,
      "grad_norm": 0.2752930819988251,
      "learning_rate": 0.0004750163529660303,
      "loss": 2.1787,
      "step": 5840
    },
    {
      "epoch": 30.46875,
      "grad_norm": 0.2892860174179077,
      "learning_rate": 0.00047492625061993477,
      "loss": 2.1605,
      "step": 5850
    },
    {
      "epoch": 30.520833333333332,
      "grad_norm": 0.27265626192092896,
      "learning_rate": 0.00047483599466824713,
      "loss": 2.164,
      "step": 5860
    },
    {
      "epoch": 30.572916666666668,
      "grad_norm": 0.33392322063446045,
      "learning_rate": 0.00047474558517260465,
      "loss": 2.1616,
      "step": 5870
    },
    {
      "epoch": 30.625,
      "grad_norm": 0.30138206481933594,
      "learning_rate": 0.0004746550221947493,
      "loss": 2.1678,
      "step": 5880
    },
    {
      "epoch": 30.677083333333332,
      "grad_norm": 0.28201940655708313,
      "learning_rate": 0.0004745643057965279,
      "loss": 2.1716,
      "step": 5890
    },
    {
      "epoch": 30.729166666666668,
      "grad_norm": 0.2545698285102844,
      "learning_rate": 0.0004744734360398921,
      "loss": 2.166,
      "step": 5900
    },
    {
      "epoch": 30.78125,
      "grad_norm": 0.32167771458625793,
      "learning_rate": 0.00047438241298689834,
      "loss": 2.1659,
      "step": 5910
    },
    {
      "epoch": 30.833333333333332,
      "grad_norm": 0.327653169631958,
      "learning_rate": 0.0004742912366997075,
      "loss": 2.1671,
      "step": 5920
    },
    {
      "epoch": 30.885416666666668,
      "grad_norm": 0.2758433520793915,
      "learning_rate": 0.0004741999072405854,
      "loss": 2.17,
      "step": 5930
    },
    {
      "epoch": 30.9375,
      "grad_norm": 0.3446809649467468,
      "learning_rate": 0.0004741084246719023,
      "loss": 2.177,
      "step": 5940
    },
    {
      "epoch": 30.989583333333332,
      "grad_norm": 0.3496168851852417,
      "learning_rate": 0.000474016789056133,
      "loss": 2.1702,
      "step": 5950
    },
    {
      "epoch": 31.0,
      "eval_loss": 1.083472490310669,
      "eval_runtime": 5.4511,
      "eval_samples_per_second": 3642.559,
      "eval_steps_per_second": 14.309,
      "step": 5952
    },
    {
      "epoch": 31.041666666666668,
      "grad_norm": 0.2994450330734253,
      "learning_rate": 0.00047392500045585696,
      "loss": 2.1649,
      "step": 5960
    },
    {
      "epoch": 31.09375,
      "grad_norm": 0.33295682072639465,
      "learning_rate": 0.00047383305893375794,
      "loss": 2.1691,
      "step": 5970
    },
    {
      "epoch": 31.145833333333332,
      "grad_norm": 0.27704721689224243,
      "learning_rate": 0.00047374096455262424,
      "loss": 2.1659,
      "step": 5980
    },
    {
      "epoch": 31.197916666666668,
      "grad_norm": 0.3758634030818939,
      "learning_rate": 0.00047364871737534854,
      "loss": 2.1771,
      "step": 5990
    },
    {
      "epoch": 31.25,
      "grad_norm": 0.35742807388305664,
      "learning_rate": 0.00047355631746492786,
      "loss": 2.1644,
      "step": 6000
    },
    {
      "epoch": 31.302083333333332,
      "grad_norm": 0.32487234473228455,
      "learning_rate": 0.00047346376488446347,
      "loss": 2.1626,
      "step": 6010
    },
    {
      "epoch": 31.354166666666668,
      "grad_norm": 0.2931367754936218,
      "learning_rate": 0.000473371059697161,
      "loss": 2.168,
      "step": 6020
    },
    {
      "epoch": 31.40625,
      "grad_norm": 0.324940949678421,
      "learning_rate": 0.00047327820196633026,
      "loss": 2.1727,
      "step": 6030
    },
    {
      "epoch": 31.458333333333332,
      "grad_norm": 0.28533193469047546,
      "learning_rate": 0.0004731851917553852,
      "loss": 2.1629,
      "step": 6040
    },
    {
      "epoch": 31.510416666666668,
      "grad_norm": 0.3279074728488922,
      "learning_rate": 0.0004730920291278439,
      "loss": 2.1608,
      "step": 6050
    },
    {
      "epoch": 31.5625,
      "grad_norm": 0.2839222848415375,
      "learning_rate": 0.00047299871414732854,
      "loss": 2.1551,
      "step": 6060
    },
    {
      "epoch": 31.614583333333332,
      "grad_norm": 0.359934002161026,
      "learning_rate": 0.0004729052468775654,
      "loss": 2.1677,
      "step": 6070
    },
    {
      "epoch": 31.666666666666668,
      "grad_norm": 0.3517129719257355,
      "learning_rate": 0.0004728116273823847,
      "loss": 2.1715,
      "step": 6080
    },
    {
      "epoch": 31.71875,
      "grad_norm": 0.32209789752960205,
      "learning_rate": 0.0004727178557257207,
      "loss": 2.167,
      "step": 6090
    },
    {
      "epoch": 31.770833333333332,
      "grad_norm": 0.38447144627571106,
      "learning_rate": 0.00047262393197161135,
      "loss": 2.166,
      "step": 6100
    },
    {
      "epoch": 31.822916666666668,
      "grad_norm": 0.31369075179100037,
      "learning_rate": 0.0004725298561841987,
      "loss": 2.1599,
      "step": 6110
    },
    {
      "epoch": 31.875,
      "grad_norm": 0.3507799804210663,
      "learning_rate": 0.0004724356284277286,
      "loss": 2.1657,
      "step": 6120
    },
    {
      "epoch": 31.927083333333332,
      "grad_norm": 0.3442170321941376,
      "learning_rate": 0.00047234124876655053,
      "loss": 2.185,
      "step": 6130
    },
    {
      "epoch": 31.979166666666668,
      "grad_norm": 0.4511096477508545,
      "learning_rate": 0.0004722467172651179,
      "loss": 2.165,
      "step": 6140
    },
    {
      "epoch": 32.0,
      "eval_loss": 1.0825814008712769,
      "eval_runtime": 5.4414,
      "eval_samples_per_second": 3649.078,
      "eval_steps_per_second": 14.335,
      "step": 6144
    },
    {
      "epoch": 32.03125,
      "grad_norm": 0.3224971890449524,
      "learning_rate": 0.0004721520339879877,
      "loss": 2.1644,
      "step": 6150
    },
    {
      "epoch": 32.083333333333336,
      "grad_norm": 0.326408326625824,
      "learning_rate": 0.0004720571989998206,
      "loss": 2.166,
      "step": 6160
    },
    {
      "epoch": 32.135416666666664,
      "grad_norm": 0.3563058376312256,
      "learning_rate": 0.00047196221236538085,
      "loss": 2.1589,
      "step": 6170
    },
    {
      "epoch": 32.1875,
      "grad_norm": 0.39698365330696106,
      "learning_rate": 0.00047186707414953634,
      "loss": 2.1716,
      "step": 6180
    },
    {
      "epoch": 32.239583333333336,
      "grad_norm": 0.2839450538158417,
      "learning_rate": 0.0004717717844172583,
      "loss": 2.1813,
      "step": 6190
    },
    {
      "epoch": 32.291666666666664,
      "grad_norm": 0.37926092743873596,
      "learning_rate": 0.0004716763432336216,
      "loss": 2.1626,
      "step": 6200
    },
    {
      "epoch": 32.34375,
      "grad_norm": 0.45172426104545593,
      "learning_rate": 0.0004715807506638046,
      "loss": 2.1669,
      "step": 6210
    },
    {
      "epoch": 32.395833333333336,
      "grad_norm": 0.2703556716442108,
      "learning_rate": 0.0004714850067730888,
      "loss": 2.1656,
      "step": 6220
    },
    {
      "epoch": 32.447916666666664,
      "grad_norm": 0.2595929503440857,
      "learning_rate": 0.0004713891116268592,
      "loss": 2.1624,
      "step": 6230
    },
    {
      "epoch": 32.5,
      "grad_norm": 0.38798707723617554,
      "learning_rate": 0.0004712930652906041,
      "loss": 2.1663,
      "step": 6240
    },
    {
      "epoch": 32.552083333333336,
      "grad_norm": 0.3526016175746918,
      "learning_rate": 0.0004711968678299151,
      "loss": 2.1768,
      "step": 6250
    },
    {
      "epoch": 32.604166666666664,
      "grad_norm": 0.36194321513175964,
      "learning_rate": 0.0004711005193104867,
      "loss": 2.1561,
      "step": 6260
    },
    {
      "epoch": 32.65625,
      "grad_norm": 0.32385000586509705,
      "learning_rate": 0.00047100401979811705,
      "loss": 2.1562,
      "step": 6270
    },
    {
      "epoch": 32.708333333333336,
      "grad_norm": 0.2991131842136383,
      "learning_rate": 0.00047090736935870693,
      "loss": 2.1665,
      "step": 6280
    },
    {
      "epoch": 32.760416666666664,
      "grad_norm": 0.28652840852737427,
      "learning_rate": 0.0004708105680582605,
      "loss": 2.1636,
      "step": 6290
    },
    {
      "epoch": 32.8125,
      "grad_norm": 0.3334459662437439,
      "learning_rate": 0.00047071361596288486,
      "loss": 2.1532,
      "step": 6300
    },
    {
      "epoch": 32.864583333333336,
      "grad_norm": 0.2600846588611603,
      "learning_rate": 0.00047061651313879007,
      "loss": 2.1676,
      "step": 6310
    },
    {
      "epoch": 32.916666666666664,
      "grad_norm": 0.34001773595809937,
      "learning_rate": 0.00047051925965228917,
      "loss": 2.1724,
      "step": 6320
    },
    {
      "epoch": 32.96875,
      "grad_norm": 0.2803203761577606,
      "learning_rate": 0.000470421855569798,
      "loss": 2.1615,
      "step": 6330
    },
    {
      "epoch": 33.0,
      "eval_loss": 1.0820319652557373,
      "eval_runtime": 5.4307,
      "eval_samples_per_second": 3656.237,
      "eval_steps_per_second": 14.363,
      "step": 6336
    },
    {
      "epoch": 33.020833333333336,
      "grad_norm": 0.31568601727485657,
      "learning_rate": 0.00047032430095783536,
      "loss": 2.1526,
      "step": 6340
    },
    {
      "epoch": 33.072916666666664,
      "grad_norm": 0.3739814758300781,
      "learning_rate": 0.00047022659588302274,
      "loss": 2.1529,
      "step": 6350
    },
    {
      "epoch": 33.125,
      "grad_norm": 0.34613969922065735,
      "learning_rate": 0.00047012874041208456,
      "loss": 2.1611,
      "step": 6360
    },
    {
      "epoch": 33.177083333333336,
      "grad_norm": 0.31300973892211914,
      "learning_rate": 0.00047003073461184767,
      "loss": 2.168,
      "step": 6370
    },
    {
      "epoch": 33.229166666666664,
      "grad_norm": 0.35956519842147827,
      "learning_rate": 0.0004699325785492418,
      "loss": 2.1579,
      "step": 6380
    },
    {
      "epoch": 33.28125,
      "grad_norm": 0.29012611508369446,
      "learning_rate": 0.0004698342722912993,
      "loss": 2.1639,
      "step": 6390
    },
    {
      "epoch": 33.333333333333336,
      "grad_norm": 0.33401453495025635,
      "learning_rate": 0.0004697358159051549,
      "loss": 2.1785,
      "step": 6400
    },
    {
      "epoch": 33.385416666666664,
      "grad_norm": 0.3617711067199707,
      "learning_rate": 0.000469637209458046,
      "loss": 2.1689,
      "step": 6410
    },
    {
      "epoch": 33.4375,
      "grad_norm": 0.2754324972629547,
      "learning_rate": 0.00046953845301731255,
      "loss": 2.1632,
      "step": 6420
    },
    {
      "epoch": 33.489583333333336,
      "grad_norm": 0.30944857001304626,
      "learning_rate": 0.0004694395466503968,
      "loss": 2.1658,
      "step": 6430
    },
    {
      "epoch": 33.541666666666664,
      "grad_norm": 0.3256116807460785,
      "learning_rate": 0.00046934049042484337,
      "loss": 2.1665,
      "step": 6440
    },
    {
      "epoch": 33.59375,
      "grad_norm": 0.34127476811408997,
      "learning_rate": 0.0004692412844082994,
      "loss": 2.161,
      "step": 6450
    },
    {
      "epoch": 33.645833333333336,
      "grad_norm": 0.28164470195770264,
      "learning_rate": 0.00046914192866851406,
      "loss": 2.1563,
      "step": 6460
    },
    {
      "epoch": 33.697916666666664,
      "grad_norm": 0.31219977140426636,
      "learning_rate": 0.00046904242327333904,
      "loss": 2.1528,
      "step": 6470
    },
    {
      "epoch": 33.75,
      "grad_norm": 0.2870440185070038,
      "learning_rate": 0.0004689427682907279,
      "loss": 2.1538,
      "step": 6480
    },
    {
      "epoch": 33.802083333333336,
      "grad_norm": 0.30631086230278015,
      "learning_rate": 0.00046884296378873683,
      "loss": 2.1563,
      "step": 6490
    },
    {
      "epoch": 33.854166666666664,
      "grad_norm": 0.2774803042411804,
      "learning_rate": 0.00046874300983552365,
      "loss": 2.1706,
      "step": 6500
    },
    {
      "epoch": 33.90625,
      "grad_norm": 0.29375240206718445,
      "learning_rate": 0.0004686429064993486,
      "loss": 2.1684,
      "step": 6510
    },
    {
      "epoch": 33.958333333333336,
      "grad_norm": 0.33199864625930786,
      "learning_rate": 0.00046854265384857366,
      "loss": 2.1563,
      "step": 6520
    },
    {
      "epoch": 34.0,
      "eval_loss": 1.082838773727417,
      "eval_runtime": 5.4347,
      "eval_samples_per_second": 3653.583,
      "eval_steps_per_second": 14.352,
      "step": 6528
    },
    {
      "epoch": 34.010416666666664,
      "grad_norm": 0.2952080965042114,
      "learning_rate": 0.00046844225195166294,
      "loss": 2.15,
      "step": 6530
    },
    {
      "epoch": 34.0625,
      "grad_norm": 0.299116849899292,
      "learning_rate": 0.0004683417008771825,
      "loss": 2.1578,
      "step": 6540
    },
    {
      "epoch": 34.114583333333336,
      "grad_norm": 0.30137720704078674,
      "learning_rate": 0.00046824100069380015,
      "loss": 2.1652,
      "step": 6550
    },
    {
      "epoch": 34.166666666666664,
      "grad_norm": 0.33926600217819214,
      "learning_rate": 0.0004681401514702856,
      "loss": 2.1632,
      "step": 6560
    },
    {
      "epoch": 34.21875,
      "grad_norm": 0.4212357997894287,
      "learning_rate": 0.0004680391532755104,
      "loss": 2.1493,
      "step": 6570
    },
    {
      "epoch": 34.270833333333336,
      "grad_norm": 0.3487124443054199,
      "learning_rate": 0.0004679380061784476,
      "loss": 2.1542,
      "step": 6580
    },
    {
      "epoch": 34.322916666666664,
      "grad_norm": 0.34499403834342957,
      "learning_rate": 0.0004678367102481723,
      "loss": 2.1582,
      "step": 6590
    },
    {
      "epoch": 34.375,
      "grad_norm": 0.42661556601524353,
      "learning_rate": 0.0004677352655538609,
      "loss": 2.1694,
      "step": 6600
    },
    {
      "epoch": 34.427083333333336,
      "grad_norm": 0.34124332666397095,
      "learning_rate": 0.00046763367216479167,
      "loss": 2.1699,
      "step": 6610
    },
    {
      "epoch": 34.479166666666664,
      "grad_norm": 0.3424346446990967,
      "learning_rate": 0.0004675319301503442,
      "loss": 2.1574,
      "step": 6620
    },
    {
      "epoch": 34.53125,
      "grad_norm": 0.3135429918766022,
      "learning_rate": 0.0004674300395799998,
      "loss": 2.1616,
      "step": 6630
    },
    {
      "epoch": 34.583333333333336,
      "grad_norm": 0.345426470041275,
      "learning_rate": 0.00046732800052334096,
      "loss": 2.1592,
      "step": 6640
    },
    {
      "epoch": 34.635416666666664,
      "grad_norm": 0.5290221571922302,
      "learning_rate": 0.00046722581305005175,
      "loss": 2.1467,
      "step": 6650
    },
    {
      "epoch": 34.6875,
      "grad_norm": 0.3201567530632019,
      "learning_rate": 0.00046712347722991754,
      "loss": 2.1861,
      "step": 6660
    },
    {
      "epoch": 34.739583333333336,
      "grad_norm": 0.368490606546402,
      "learning_rate": 0.0004670209931328252,
      "loss": 2.1475,
      "step": 6670
    },
    {
      "epoch": 34.791666666666664,
      "grad_norm": 0.3439813256263733,
      "learning_rate": 0.00046691836082876246,
      "loss": 2.1592,
      "step": 6680
    },
    {
      "epoch": 34.84375,
      "grad_norm": 0.37944844365119934,
      "learning_rate": 0.0004668155803878187,
      "loss": 2.1651,
      "step": 6690
    },
    {
      "epoch": 34.895833333333336,
      "grad_norm": 0.3901328146457672,
      "learning_rate": 0.0004667126518801842,
      "loss": 2.1544,
      "step": 6700
    },
    {
      "epoch": 34.947916666666664,
      "grad_norm": 0.36948904395103455,
      "learning_rate": 0.00046660957537615036,
      "loss": 2.16,
      "step": 6710
    },
    {
      "epoch": 35.0,
      "grad_norm": 0.34939461946487427,
      "learning_rate": 0.00046650635094610973,
      "loss": 2.1747,
      "step": 6720
    },
    {
      "epoch": 35.0,
      "eval_loss": 1.0815829038619995,
      "eval_runtime": 5.4274,
      "eval_samples_per_second": 3658.487,
      "eval_steps_per_second": 14.372,
      "step": 6720
    },
    {
      "epoch": 35.052083333333336,
      "grad_norm": 0.332675963640213,
      "learning_rate": 0.0004664029786605558,
      "loss": 2.1548,
      "step": 6730
    },
    {
      "epoch": 35.104166666666664,
      "grad_norm": 0.39668238162994385,
      "learning_rate": 0.00046629945859008327,
      "loss": 2.144,
      "step": 6740
    },
    {
      "epoch": 35.15625,
      "grad_norm": 0.36814743280410767,
      "learning_rate": 0.0004661957908053874,
      "loss": 2.1594,
      "step": 6750
    },
    {
      "epoch": 35.208333333333336,
      "grad_norm": 0.3623543977737427,
      "learning_rate": 0.00046609197537726465,
      "loss": 2.1585,
      "step": 6760
    },
    {
      "epoch": 35.260416666666664,
      "grad_norm": 0.3646552562713623,
      "learning_rate": 0.00046598801237661213,
      "loss": 2.1516,
      "step": 6770
    },
    {
      "epoch": 35.3125,
      "grad_norm": 0.4202120006084442,
      "learning_rate": 0.0004658839018744277,
      "loss": 2.158,
      "step": 6780
    },
    {
      "epoch": 35.364583333333336,
      "grad_norm": 0.3522779047489166,
      "learning_rate": 0.0004657796439418101,
      "loss": 2.166,
      "step": 6790
    },
    {
      "epoch": 35.416666666666664,
      "grad_norm": 0.29824772477149963,
      "learning_rate": 0.00046567523864995866,
      "loss": 2.1625,
      "step": 6800
    },
    {
      "epoch": 35.46875,
      "grad_norm": 0.31842151284217834,
      "learning_rate": 0.00046557068607017333,
      "loss": 2.1731,
      "step": 6810
    },
    {
      "epoch": 35.520833333333336,
      "grad_norm": 0.3583514392375946,
      "learning_rate": 0.0004654659862738547,
      "loss": 2.1842,
      "step": 6820
    },
    {
      "epoch": 35.572916666666664,
      "grad_norm": 0.32031336426734924,
      "learning_rate": 0.0004653611393325039,
      "loss": 2.162,
      "step": 6830
    },
    {
      "epoch": 35.625,
      "grad_norm": 0.35752347111701965,
      "learning_rate": 0.0004652561453177224,
      "loss": 2.1658,
      "step": 6840
    },
    {
      "epoch": 35.677083333333336,
      "grad_norm": 0.38441744446754456,
      "learning_rate": 0.0004651510043012124,
      "loss": 2.1562,
      "step": 6850
    },
    {
      "epoch": 35.729166666666664,
      "grad_norm": 0.33557549118995667,
      "learning_rate": 0.0004650457163547761,
      "loss": 2.1502,
      "step": 6860
    },
    {
      "epoch": 35.78125,
      "grad_norm": 0.34959420561790466,
      "learning_rate": 0.00046494028155031643,
      "loss": 2.1506,
      "step": 6870
    },
    {
      "epoch": 35.833333333333336,
      "grad_norm": 0.4348512589931488,
      "learning_rate": 0.0004648346999598364,
      "loss": 2.1583,
      "step": 6880
    },
    {
      "epoch": 35.885416666666664,
      "grad_norm": 0.3616977632045746,
      "learning_rate": 0.00046472897165543924,
      "loss": 2.1469,
      "step": 6890
    },
    {
      "epoch": 35.9375,
      "grad_norm": 0.33206525444984436,
      "learning_rate": 0.0004646230967093286,
      "loss": 2.1614,
      "step": 6900
    },
    {
      "epoch": 35.989583333333336,
      "grad_norm": 0.3805752098560333,
      "learning_rate": 0.0004645170751938078,
      "loss": 2.1709,
      "step": 6910
    },
    {
      "epoch": 36.0,
      "eval_loss": 1.0809448957443237,
      "eval_runtime": 5.4433,
      "eval_samples_per_second": 3647.785,
      "eval_steps_per_second": 14.33,
      "step": 6912
    },
    {
      "epoch": 36.041666666666664,
      "grad_norm": 0.316935658454895,
      "learning_rate": 0.0004644109071812809,
      "loss": 2.1652,
      "step": 6920
    },
    {
      "epoch": 36.09375,
      "grad_norm": 0.3110620677471161,
      "learning_rate": 0.00046430459274425143,
      "loss": 2.1456,
      "step": 6930
    },
    {
      "epoch": 36.145833333333336,
      "grad_norm": 0.3204956650733948,
      "learning_rate": 0.0004641981319553232,
      "loss": 2.1401,
      "step": 6940
    },
    {
      "epoch": 36.197916666666664,
      "grad_norm": 0.3302816152572632,
      "learning_rate": 0.0004640915248872001,
      "loss": 2.1558,
      "step": 6950
    },
    {
      "epoch": 36.25,
      "grad_norm": 0.3720759451389313,
      "learning_rate": 0.00046398477161268544,
      "loss": 2.1607,
      "step": 6960
    },
    {
      "epoch": 36.302083333333336,
      "grad_norm": 0.35636934638023376,
      "learning_rate": 0.00046387787220468284,
      "loss": 2.1609,
      "step": 6970
    },
    {
      "epoch": 36.354166666666664,
      "grad_norm": 0.3052334785461426,
      "learning_rate": 0.0004637708267361956,
      "loss": 2.1652,
      "step": 6980
    },
    {
      "epoch": 36.40625,
      "grad_norm": 0.32424789667129517,
      "learning_rate": 0.00046366363528032656,
      "loss": 2.1611,
      "step": 6990
    },
    {
      "epoch": 36.458333333333336,
      "grad_norm": 0.326194703578949,
      "learning_rate": 0.00046355629791027854,
      "loss": 2.1621,
      "step": 7000
    },
    {
      "epoch": 36.510416666666664,
      "grad_norm": 0.3039962947368622,
      "learning_rate": 0.00046344881469935386,
      "loss": 2.1545,
      "step": 7010
    },
    {
      "epoch": 36.5625,
      "grad_norm": 0.31102752685546875,
      "learning_rate": 0.00046334118572095433,
      "loss": 2.1582,
      "step": 7020
    },
    {
      "epoch": 36.614583333333336,
      "grad_norm": 0.2953221797943115,
      "learning_rate": 0.00046323341104858163,
      "loss": 2.161,
      "step": 7030
    },
    {
      "epoch": 36.666666666666664,
      "grad_norm": 0.3184928894042969,
      "learning_rate": 0.0004631254907558365,
      "loss": 2.1533,
      "step": 7040
    },
    {
      "epoch": 36.71875,
      "grad_norm": 0.31265005469322205,
      "learning_rate": 0.0004630174249164197,
      "loss": 2.1689,
      "step": 7050
    },
    {
      "epoch": 36.770833333333336,
      "grad_norm": 0.30172640085220337,
      "learning_rate": 0.00046290921360413076,
      "loss": 2.1583,
      "step": 7060
    },
    {
      "epoch": 36.822916666666664,
      "grad_norm": 0.2753000259399414,
      "learning_rate": 0.0004628008568928689,
      "loss": 2.1636,
      "step": 7070
    },
    {
      "epoch": 36.875,
      "grad_norm": 0.2989618480205536,
      "learning_rate": 0.00046269235485663275,
      "loss": 2.1542,
      "step": 7080
    },
    {
      "epoch": 36.927083333333336,
      "grad_norm": 0.3353830575942993,
      "learning_rate": 0.00046258370756951977,
      "loss": 2.1674,
      "step": 7090
    },
    {
      "epoch": 36.979166666666664,
      "grad_norm": 0.3400632441043854,
      "learning_rate": 0.000462474915105727,
      "loss": 2.147,
      "step": 7100
    },
    {
      "epoch": 37.0,
      "eval_loss": 1.0829298496246338,
      "eval_runtime": 5.4286,
      "eval_samples_per_second": 3657.697,
      "eval_steps_per_second": 14.368,
      "step": 7104
    },
    {
      "epoch": 37.03125,
      "grad_norm": 0.36147886514663696,
      "learning_rate": 0.00046236597753955056,
      "loss": 2.1554,
      "step": 7110
    },
    {
      "epoch": 37.083333333333336,
      "grad_norm": 0.46957504749298096,
      "learning_rate": 0.00046225689494538546,
      "loss": 2.1438,
      "step": 7120
    },
    {
      "epoch": 37.135416666666664,
      "grad_norm": 0.3473050892353058,
      "learning_rate": 0.00046214766739772594,
      "loss": 2.1508,
      "step": 7130
    },
    {
      "epoch": 37.1875,
      "grad_norm": 0.45874303579330444,
      "learning_rate": 0.0004620382949711651,
      "loss": 2.1531,
      "step": 7140
    },
    {
      "epoch": 37.239583333333336,
      "grad_norm": 0.3657788038253784,
      "learning_rate": 0.0004619287777403951,
      "loss": 2.1577,
      "step": 7150
    },
    {
      "epoch": 37.291666666666664,
      "grad_norm": 0.28743278980255127,
      "learning_rate": 0.00046181911578020696,
      "loss": 2.1616,
      "step": 7160
    },
    {
      "epoch": 37.34375,
      "grad_norm": 0.3794746696949005,
      "learning_rate": 0.00046170930916549055,
      "loss": 2.1554,
      "step": 7170
    },
    {
      "epoch": 37.395833333333336,
      "grad_norm": 0.3187148869037628,
      "learning_rate": 0.00046159935797123434,
      "loss": 2.166,
      "step": 7180
    },
    {
      "epoch": 37.447916666666664,
      "grad_norm": 0.37447068095207214,
      "learning_rate": 0.00046148926227252584,
      "loss": 2.158,
      "step": 7190
    },
    {
      "epoch": 37.5,
      "grad_norm": 0.42700615525245667,
      "learning_rate": 0.0004613790221445511,
      "loss": 2.1623,
      "step": 7200
    },
    {
      "epoch": 37.552083333333336,
      "grad_norm": 0.41868653893470764,
      "learning_rate": 0.00046126863766259463,
      "loss": 2.1603,
      "step": 7210
    },
    {
      "epoch": 37.604166666666664,
      "grad_norm": 0.3874484896659851,
      "learning_rate": 0.0004611581089020399,
      "loss": 2.1476,
      "step": 7220
    },
    {
      "epoch": 37.65625,
      "grad_norm": 0.3146236836910248,
      "learning_rate": 0.00046104743593836854,
      "loss": 2.1582,
      "step": 7230
    },
    {
      "epoch": 37.708333333333336,
      "grad_norm": 0.3603883981704712,
      "learning_rate": 0.0004609366188471609,
      "loss": 2.1596,
      "step": 7240
    },
    {
      "epoch": 37.760416666666664,
      "grad_norm": 0.3438121974468231,
      "learning_rate": 0.00046082565770409566,
      "loss": 2.1548,
      "step": 7250
    },
    {
      "epoch": 37.8125,
      "grad_norm": 0.3894208073616028,
      "learning_rate": 0.0004607145525849499,
      "loss": 2.1671,
      "step": 7260
    },
    {
      "epoch": 37.864583333333336,
      "grad_norm": 0.3075060546398163,
      "learning_rate": 0.0004606033035655989,
      "loss": 2.1563,
      "step": 7270
    },
    {
      "epoch": 37.916666666666664,
      "grad_norm": 0.32109174132347107,
      "learning_rate": 0.00046049191072201646,
      "loss": 2.1628,
      "step": 7280
    },
    {
      "epoch": 37.96875,
      "grad_norm": 0.4309675097465515,
      "learning_rate": 0.00046038037413027443,
      "loss": 2.1679,
      "step": 7290
    },
    {
      "epoch": 38.0,
      "eval_loss": 1.0812643766403198,
      "eval_runtime": 5.4315,
      "eval_samples_per_second": 3655.738,
      "eval_steps_per_second": 14.361,
      "step": 7296
    },
    {
      "epoch": 38.020833333333336,
      "grad_norm": 0.3179072439670563,
      "learning_rate": 0.0004602686938665429,
      "loss": 2.1587,
      "step": 7300
    },
    {
      "epoch": 38.072916666666664,
      "grad_norm": 0.3748454451560974,
      "learning_rate": 0.00046015687000708995,
      "loss": 2.1625,
      "step": 7310
    },
    {
      "epoch": 38.125,
      "grad_norm": 0.3410901129245758,
      "learning_rate": 0.00046004490262828185,
      "loss": 2.1518,
      "step": 7320
    },
    {
      "epoch": 38.177083333333336,
      "grad_norm": 0.3518804609775543,
      "learning_rate": 0.0004599327918065829,
      "loss": 2.1585,
      "step": 7330
    },
    {
      "epoch": 38.229166666666664,
      "grad_norm": 0.3319990038871765,
      "learning_rate": 0.00045982053761855514,
      "loss": 2.1486,
      "step": 7340
    },
    {
      "epoch": 38.28125,
      "grad_norm": 0.4037131667137146,
      "learning_rate": 0.00045970814014085885,
      "loss": 2.1652,
      "step": 7350
    },
    {
      "epoch": 38.333333333333336,
      "grad_norm": 0.3391713798046112,
      "learning_rate": 0.00045959559945025184,
      "loss": 2.1565,
      "step": 7360
    },
    {
      "epoch": 38.385416666666664,
      "grad_norm": 0.387386679649353,
      "learning_rate": 0.0004594829156235901,
      "loss": 2.1577,
      "step": 7370
    },
    {
      "epoch": 38.4375,
      "grad_norm": 0.3674412667751312,
      "learning_rate": 0.000459370088737827,
      "loss": 2.1632,
      "step": 7380
    },
    {
      "epoch": 38.489583333333336,
      "grad_norm": 0.6026315689086914,
      "learning_rate": 0.00045925711887001374,
      "loss": 2.1518,
      "step": 7390
    },
    {
      "epoch": 38.541666666666664,
      "grad_norm": 0.3779471814632416,
      "learning_rate": 0.0004591440060972992,
      "loss": 2.1552,
      "step": 7400
    },
    {
      "epoch": 38.59375,
      "grad_norm": 0.5823208093643188,
      "learning_rate": 0.00045903075049692977,
      "loss": 2.1657,
      "step": 7410
    },
    {
      "epoch": 38.645833333333336,
      "grad_norm": 0.4701763689517975,
      "learning_rate": 0.00045891735214624964,
      "loss": 2.1461,
      "step": 7420
    },
    {
      "epoch": 38.697916666666664,
      "grad_norm": 0.3515580892562866,
      "learning_rate": 0.00045880381112270007,
      "loss": 2.1565,
      "step": 7430
    },
    {
      "epoch": 38.75,
      "grad_norm": 0.3033420145511627,
      "learning_rate": 0.00045869012750382004,
      "loss": 2.1519,
      "step": 7440
    },
    {
      "epoch": 38.802083333333336,
      "grad_norm": 0.46490517258644104,
      "learning_rate": 0.0004585763013672459,
      "loss": 2.1547,
      "step": 7450
    },
    {
      "epoch": 38.854166666666664,
      "grad_norm": 0.4006526470184326,
      "learning_rate": 0.0004584623327907112,
      "loss": 2.1402,
      "step": 7460
    },
    {
      "epoch": 38.90625,
      "grad_norm": 0.3646460175514221,
      "learning_rate": 0.00045834822185204685,
      "loss": 2.1583,
      "step": 7470
    },
    {
      "epoch": 38.958333333333336,
      "grad_norm": 0.296846479177475,
      "learning_rate": 0.000458233968629181,
      "loss": 2.153,
      "step": 7480
    },
    {
      "epoch": 39.0,
      "eval_loss": 1.0819836854934692,
      "eval_runtime": 5.4535,
      "eval_samples_per_second": 3640.949,
      "eval_steps_per_second": 14.303,
      "step": 7488
    },
    {
      "epoch": 39.010416666666664,
      "grad_norm": 0.3153447210788727,
      "learning_rate": 0.00045811957320013877,
      "loss": 2.1498,
      "step": 7490
    },
    {
      "epoch": 39.0625,
      "grad_norm": 0.3287924826145172,
      "learning_rate": 0.0004580050356430428,
      "loss": 2.1487,
      "step": 7500
    },
    {
      "epoch": 39.114583333333336,
      "grad_norm": 0.5480120778083801,
      "learning_rate": 0.0004578903560361124,
      "loss": 2.1494,
      "step": 7510
    },
    {
      "epoch": 39.166666666666664,
      "grad_norm": 0.36310669779777527,
      "learning_rate": 0.00045777553445766405,
      "loss": 2.1467,
      "step": 7520
    },
    {
      "epoch": 39.21875,
      "grad_norm": 0.37376630306243896,
      "learning_rate": 0.0004576605709861112,
      "loss": 2.1484,
      "step": 7530
    },
    {
      "epoch": 39.270833333333336,
      "grad_norm": 0.38286563754081726,
      "learning_rate": 0.0004575454656999641,
      "loss": 2.1464,
      "step": 7540
    },
    {
      "epoch": 39.322916666666664,
      "grad_norm": 0.3625435531139374,
      "learning_rate": 0.00045743021867783007,
      "loss": 2.1477,
      "step": 7550
    },
    {
      "epoch": 39.375,
      "grad_norm": 0.3685801327228546,
      "learning_rate": 0.0004573148299984129,
      "loss": 2.1487,
      "step": 7560
    },
    {
      "epoch": 39.427083333333336,
      "grad_norm": 0.5238218307495117,
      "learning_rate": 0.00045719929974051337,
      "loss": 2.1708,
      "step": 7570
    },
    {
      "epoch": 39.479166666666664,
      "grad_norm": 0.33304694294929504,
      "learning_rate": 0.00045708362798302886,
      "loss": 2.1713,
      "step": 7580
    },
    {
      "epoch": 39.53125,
      "grad_norm": 0.4168984591960907,
      "learning_rate": 0.0004569678148049534,
      "loss": 2.1549,
      "step": 7590
    },
    {
      "epoch": 39.583333333333336,
      "grad_norm": 0.32018613815307617,
      "learning_rate": 0.00045685186028537764,
      "loss": 2.1468,
      "step": 7600
    },
    {
      "epoch": 39.635416666666664,
      "grad_norm": 0.4188900291919708,
      "learning_rate": 0.0004567357645034886,
      "loss": 2.1545,
      "step": 7610
    },
    {
      "epoch": 39.6875,
      "grad_norm": 0.3786580562591553,
      "learning_rate": 0.00045661952753856997,
      "loss": 2.1592,
      "step": 7620
    },
    {
      "epoch": 39.739583333333336,
      "grad_norm": 0.454495370388031,
      "learning_rate": 0.0004565031494700016,
      "loss": 2.1458,
      "step": 7630
    },
    {
      "epoch": 39.791666666666664,
      "grad_norm": 0.32764947414398193,
      "learning_rate": 0.00045638663037726,
      "loss": 2.1554,
      "step": 7640
    },
    {
      "epoch": 39.84375,
      "grad_norm": 0.35143932700157166,
      "learning_rate": 0.00045626997033991793,
      "loss": 2.1591,
      "step": 7650
    },
    {
      "epoch": 39.895833333333336,
      "grad_norm": 0.3455003499984741,
      "learning_rate": 0.0004561531694376441,
      "loss": 2.1548,
      "step": 7660
    },
    {
      "epoch": 39.947916666666664,
      "grad_norm": 0.3034394681453705,
      "learning_rate": 0.0004560362277502038,
      "loss": 2.1496,
      "step": 7670
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.3536674976348877,
      "learning_rate": 0.0004559191453574582,
      "loss": 2.1556,
      "step": 7680
    },
    {
      "epoch": 40.0,
      "eval_loss": 1.0800005197525024,
      "eval_runtime": 5.4478,
      "eval_samples_per_second": 3644.756,
      "eval_steps_per_second": 14.318,
      "step": 7680
    },
    {
      "epoch": 40.052083333333336,
      "grad_norm": 0.3380817174911499,
      "learning_rate": 0.0004558019223393648,
      "loss": 2.1435,
      "step": 7690
    },
    {
      "epoch": 40.104166666666664,
      "grad_norm": 0.3976497948169708,
      "learning_rate": 0.0004556845587759768,
      "loss": 2.1363,
      "step": 7700
    },
    {
      "epoch": 40.15625,
      "grad_norm": 0.3674977421760559,
      "learning_rate": 0.00045556705474744376,
      "loss": 2.1667,
      "step": 7710
    },
    {
      "epoch": 40.208333333333336,
      "grad_norm": 0.3440277576446533,
      "learning_rate": 0.000455449410334011,
      "loss": 2.1429,
      "step": 7720
    },
    {
      "epoch": 40.260416666666664,
      "grad_norm": 0.35619205236434937,
      "learning_rate": 0.0004553316256160195,
      "loss": 2.1532,
      "step": 7730
    },
    {
      "epoch": 40.3125,
      "grad_norm": 0.37452903389930725,
      "learning_rate": 0.0004552137006739064,
      "loss": 2.1685,
      "step": 7740
    },
    {
      "epoch": 40.364583333333336,
      "grad_norm": 0.31552910804748535,
      "learning_rate": 0.00045509563558820455,
      "loss": 2.1619,
      "step": 7750
    },
    {
      "epoch": 40.416666666666664,
      "grad_norm": 0.40828800201416016,
      "learning_rate": 0.0004549774304395422,
      "loss": 2.1499,
      "step": 7760
    },
    {
      "epoch": 40.46875,
      "grad_norm": 0.3681296110153198,
      "learning_rate": 0.0004548590853086435,
      "loss": 2.1496,
      "step": 7770
    },
    {
      "epoch": 40.520833333333336,
      "grad_norm": 0.3385144770145416,
      "learning_rate": 0.00045474060027632835,
      "loss": 2.151,
      "step": 7780
    },
    {
      "epoch": 40.572916666666664,
      "grad_norm": 0.3683827519416809,
      "learning_rate": 0.00045462197542351176,
      "loss": 2.1528,
      "step": 7790
    },
    {
      "epoch": 40.625,
      "grad_norm": 0.29752328991889954,
      "learning_rate": 0.0004545032108312046,
      "loss": 2.1355,
      "step": 7800
    },
    {
      "epoch": 40.677083333333336,
      "grad_norm": 0.36556392908096313,
      "learning_rate": 0.000454384306580513,
      "loss": 2.1405,
      "step": 7810
    },
    {
      "epoch": 40.729166666666664,
      "grad_norm": 0.3475893437862396,
      "learning_rate": 0.00045426526275263847,
      "loss": 2.1631,
      "step": 7820
    },
    {
      "epoch": 40.78125,
      "grad_norm": 0.3932790458202362,
      "learning_rate": 0.0004541460794288779,
      "loss": 2.1564,
      "step": 7830
    },
    {
      "epoch": 40.833333333333336,
      "grad_norm": 0.3824841380119324,
      "learning_rate": 0.0004540267566906234,
      "loss": 2.1603,
      "step": 7840
    },
    {
      "epoch": 40.885416666666664,
      "grad_norm": 0.3663831055164337,
      "learning_rate": 0.0004539072946193624,
      "loss": 2.1509,
      "step": 7850
    },
    {
      "epoch": 40.9375,
      "grad_norm": 0.32963502407073975,
      "learning_rate": 0.0004537876932966772,
      "loss": 2.1394,
      "step": 7860
    },
    {
      "epoch": 40.989583333333336,
      "grad_norm": 0.33290785551071167,
      "learning_rate": 0.00045366795280424554,
      "loss": 2.1489,
      "step": 7870
    },
    {
      "epoch": 41.0,
      "eval_loss": 1.0795447826385498,
      "eval_runtime": 5.6095,
      "eval_samples_per_second": 3539.701,
      "eval_steps_per_second": 13.905,
      "step": 7872
    },
    {
      "epoch": 41.041666666666664,
      "grad_norm": 0.35979536175727844,
      "learning_rate": 0.00045354807322383993,
      "loss": 2.1703,
      "step": 7880
    },
    {
      "epoch": 41.09375,
      "grad_norm": 0.36516064405441284,
      "learning_rate": 0.00045342805463732805,
      "loss": 2.1398,
      "step": 7890
    },
    {
      "epoch": 41.145833333333336,
      "grad_norm": 0.36934784054756165,
      "learning_rate": 0.00045330789712667244,
      "loss": 2.1288,
      "step": 7900
    },
    {
      "epoch": 41.197916666666664,
      "grad_norm": 0.4062430262565613,
      "learning_rate": 0.00045318760077393046,
      "loss": 2.1459,
      "step": 7910
    },
    {
      "epoch": 41.25,
      "grad_norm": 0.3983069360256195,
      "learning_rate": 0.00045306716566125433,
      "loss": 2.1458,
      "step": 7920
    },
    {
      "epoch": 41.302083333333336,
      "grad_norm": 0.3776504695415497,
      "learning_rate": 0.0004529465918708911,
      "loss": 2.1512,
      "step": 7930
    },
    {
      "epoch": 41.354166666666664,
      "grad_norm": 0.32711318135261536,
      "learning_rate": 0.00045282587948518245,
      "loss": 2.1395,
      "step": 7940
    },
    {
      "epoch": 41.40625,
      "grad_norm": 0.3653206527233124,
      "learning_rate": 0.0004527050285865647,
      "loss": 2.1451,
      "step": 7950
    },
    {
      "epoch": 41.458333333333336,
      "grad_norm": 0.5421797633171082,
      "learning_rate": 0.00045258403925756873,
      "loss": 2.1539,
      "step": 7960
    },
    {
      "epoch": 41.510416666666664,
      "grad_norm": 0.3513281047344208,
      "learning_rate": 0.0004524629115808201,
      "loss": 2.1434,
      "step": 7970
    },
    {
      "epoch": 41.5625,
      "grad_norm": 0.3207338750362396,
      "learning_rate": 0.0004523416456390388,
      "loss": 2.1535,
      "step": 7980
    },
    {
      "epoch": 41.614583333333336,
      "grad_norm": 0.36270156502723694,
      "learning_rate": 0.00045222024151503906,
      "loss": 2.1496,
      "step": 7990
    },
    {
      "epoch": 41.666666666666664,
      "grad_norm": 0.39778244495391846,
      "learning_rate": 0.0004520986992917297,
      "loss": 2.1556,
      "step": 8000
    },
    {
      "epoch": 41.71875,
      "grad_norm": 0.3261365294456482,
      "learning_rate": 0.0004519770190521138,
      "loss": 2.1571,
      "step": 8010
    },
    {
      "epoch": 41.770833333333336,
      "grad_norm": 0.3231765329837799,
      "learning_rate": 0.00045185520087928866,
      "loss": 2.1439,
      "step": 8020
    },
    {
      "epoch": 41.822916666666664,
      "grad_norm": 0.5996594429016113,
      "learning_rate": 0.0004517332448564457,
      "loss": 2.1441,
      "step": 8030
    },
    {
      "epoch": 41.875,
      "grad_norm": 0.32371869683265686,
      "learning_rate": 0.0004516111510668707,
      "loss": 2.1615,
      "step": 8040
    },
    {
      "epoch": 41.927083333333336,
      "grad_norm": 0.407295823097229,
      "learning_rate": 0.0004514889195939432,
      "loss": 2.1582,
      "step": 8050
    },
    {
      "epoch": 41.979166666666664,
      "grad_norm": 0.4138381779193878,
      "learning_rate": 0.0004513665505211371,
      "loss": 2.1583,
      "step": 8060
    },
    {
      "epoch": 42.0,
      "eval_loss": 1.080856442451477,
      "eval_runtime": 5.6286,
      "eval_samples_per_second": 3527.716,
      "eval_steps_per_second": 13.858,
      "step": 8064
    },
    {
      "epoch": 42.03125,
      "grad_norm": 0.356770783662796,
      "learning_rate": 0.00045124404393202014,
      "loss": 2.1469,
      "step": 8070
    },
    {
      "epoch": 42.083333333333336,
      "grad_norm": 0.3975531756877899,
      "learning_rate": 0.0004511213999102538,
      "loss": 2.1452,
      "step": 8080
    },
    {
      "epoch": 42.135416666666664,
      "grad_norm": 0.6741907000541687,
      "learning_rate": 0.00045099861853959366,
      "loss": 2.1572,
      "step": 8090
    },
    {
      "epoch": 42.1875,
      "grad_norm": 0.3766154944896698,
      "learning_rate": 0.000450875699903889,
      "loss": 2.1684,
      "step": 8100
    },
    {
      "epoch": 42.239583333333336,
      "grad_norm": 0.3700176179409027,
      "learning_rate": 0.00045075264408708283,
      "loss": 2.1486,
      "step": 8110
    },
    {
      "epoch": 42.291666666666664,
      "grad_norm": 0.31120824813842773,
      "learning_rate": 0.00045062945117321193,
      "loss": 2.1472,
      "step": 8120
    },
    {
      "epoch": 42.34375,
      "grad_norm": 0.36373865604400635,
      "learning_rate": 0.00045050612124640656,
      "loss": 2.136,
      "step": 8130
    },
    {
      "epoch": 42.395833333333336,
      "grad_norm": 0.3028036952018738,
      "learning_rate": 0.00045038265439089053,
      "loss": 2.1529,
      "step": 8140
    },
    {
      "epoch": 42.447916666666664,
      "grad_norm": 0.3791414499282837,
      "learning_rate": 0.0004502590506909815,
      "loss": 2.1399,
      "step": 8150
    },
    {
      "epoch": 42.5,
      "grad_norm": 0.27396494150161743,
      "learning_rate": 0.0004501353102310901,
      "loss": 2.1462,
      "step": 8160
    },
    {
      "epoch": 42.552083333333336,
      "grad_norm": 0.3193090260028839,
      "learning_rate": 0.00045001143309572074,
      "loss": 2.1492,
      "step": 8170
    },
    {
      "epoch": 42.604166666666664,
      "grad_norm": 0.3576381504535675,
      "learning_rate": 0.0004498874193694709,
      "loss": 2.1391,
      "step": 8180
    },
    {
      "epoch": 42.65625,
      "grad_norm": 0.35045722126960754,
      "learning_rate": 0.00044976326913703156,
      "loss": 2.1441,
      "step": 8190
    },
    {
      "epoch": 42.708333333333336,
      "grad_norm": 0.34934693574905396,
      "learning_rate": 0.0004496389824831868,
      "loss": 2.1429,
      "step": 8200
    },
    {
      "epoch": 42.760416666666664,
      "grad_norm": 0.29740530252456665,
      "learning_rate": 0.0004495145594928138,
      "loss": 2.1461,
      "step": 8210
    },
    {
      "epoch": 42.8125,
      "grad_norm": 0.32359227538108826,
      "learning_rate": 0.00044939000025088306,
      "loss": 2.1467,
      "step": 8220
    },
    {
      "epoch": 42.864583333333336,
      "grad_norm": 0.3843902051448822,
      "learning_rate": 0.000449265304842458,
      "loss": 2.1431,
      "step": 8230
    },
    {
      "epoch": 42.916666666666664,
      "grad_norm": 0.3756227195262909,
      "learning_rate": 0.0004491404733526949,
      "loss": 2.1549,
      "step": 8240
    },
    {
      "epoch": 42.96875,
      "grad_norm": 0.3698834180831909,
      "learning_rate": 0.00044901550586684313,
      "loss": 2.146,
      "step": 8250
    },
    {
      "epoch": 43.0,
      "eval_loss": 1.0796022415161133,
      "eval_runtime": 5.5999,
      "eval_samples_per_second": 3545.796,
      "eval_steps_per_second": 13.929,
      "step": 8256
    },
    {
      "epoch": 43.020833333333336,
      "grad_norm": 0.38789546489715576,
      "learning_rate": 0.000448890402470245,
      "loss": 2.1548,
      "step": 8260
    },
    {
      "epoch": 43.072916666666664,
      "grad_norm": 0.3509189784526825,
      "learning_rate": 0.0004487651632483354,
      "loss": 2.1511,
      "step": 8270
    },
    {
      "epoch": 43.125,
      "grad_norm": 0.4341389238834381,
      "learning_rate": 0.0004486397882866423,
      "loss": 2.1523,
      "step": 8280
    },
    {
      "epoch": 43.177083333333336,
      "grad_norm": 0.40381354093551636,
      "learning_rate": 0.0004485142776707861,
      "loss": 2.1343,
      "step": 8290
    },
    {
      "epoch": 43.229166666666664,
      "grad_norm": 0.3637892007827759,
      "learning_rate": 0.0004483886314864799,
      "loss": 2.1282,
      "step": 8300
    },
    {
      "epoch": 43.28125,
      "grad_norm": 0.325835645198822,
      "learning_rate": 0.0004482628498195294,
      "loss": 2.1217,
      "step": 8310
    },
    {
      "epoch": 43.333333333333336,
      "grad_norm": 0.3370063900947571,
      "learning_rate": 0.0004481369327558329,
      "loss": 2.1563,
      "step": 8320
    },
    {
      "epoch": 43.385416666666664,
      "grad_norm": 0.3597683310508728,
      "learning_rate": 0.0004480108803813811,
      "loss": 2.1335,
      "step": 8330
    },
    {
      "epoch": 43.4375,
      "grad_norm": 0.3468571603298187,
      "learning_rate": 0.000447884692782257,
      "loss": 2.1395,
      "step": 8340
    },
    {
      "epoch": 43.489583333333336,
      "grad_norm": 0.39207082986831665,
      "learning_rate": 0.00044775837004463613,
      "loss": 2.1421,
      "step": 8350
    },
    {
      "epoch": 43.541666666666664,
      "grad_norm": 0.3706054985523224,
      "learning_rate": 0.0004476319122547863,
      "loss": 2.1468,
      "step": 8360
    },
    {
      "epoch": 43.59375,
      "grad_norm": 0.3309992849826813,
      "learning_rate": 0.00044750531949906724,
      "loss": 2.1487,
      "step": 8370
    },
    {
      "epoch": 43.645833333333336,
      "grad_norm": 0.3470328450202942,
      "learning_rate": 0.00044737859186393136,
      "loss": 2.1409,
      "step": 8380
    },
    {
      "epoch": 43.697916666666664,
      "grad_norm": 0.4102596044540405,
      "learning_rate": 0.00044725172943592276,
      "loss": 2.1525,
      "step": 8390
    },
    {
      "epoch": 43.75,
      "grad_norm": 0.46765297651290894,
      "learning_rate": 0.0004471247323016777,
      "loss": 2.1461,
      "step": 8400
    },
    {
      "epoch": 43.802083333333336,
      "grad_norm": 0.3466882109642029,
      "learning_rate": 0.0004469976005479246,
      "loss": 2.1511,
      "step": 8410
    },
    {
      "epoch": 43.854166666666664,
      "grad_norm": 0.3369576632976532,
      "learning_rate": 0.0004468703342614836,
      "loss": 2.1458,
      "step": 8420
    },
    {
      "epoch": 43.90625,
      "grad_norm": 0.35879775881767273,
      "learning_rate": 0.0004467429335292669,
      "loss": 2.1495,
      "step": 8430
    },
    {
      "epoch": 43.958333333333336,
      "grad_norm": 0.32896220684051514,
      "learning_rate": 0.0004466153984382782,
      "loss": 2.147,
      "step": 8440
    },
    {
      "epoch": 44.0,
      "eval_loss": 1.0795366764068604,
      "eval_runtime": 5.6272,
      "eval_samples_per_second": 3528.552,
      "eval_steps_per_second": 13.861,
      "step": 8448
    },
    {
      "epoch": 44.010416666666664,
      "grad_norm": 0.3440426290035248,
      "learning_rate": 0.00044648772907561354,
      "loss": 2.1512,
      "step": 8450
    },
    {
      "epoch": 44.0625,
      "grad_norm": 0.29678210616111755,
      "learning_rate": 0.00044635992552845993,
      "loss": 2.1459,
      "step": 8460
    },
    {
      "epoch": 44.114583333333336,
      "grad_norm": 0.3611341118812561,
      "learning_rate": 0.0004462319878840966,
      "loss": 2.1453,
      "step": 8470
    },
    {
      "epoch": 44.166666666666664,
      "grad_norm": 0.3150394558906555,
      "learning_rate": 0.0004461039162298939,
      "loss": 2.1425,
      "step": 8480
    },
    {
      "epoch": 44.21875,
      "grad_norm": 0.3551105558872223,
      "learning_rate": 0.00044597571065331423,
      "loss": 2.1412,
      "step": 8490
    },
    {
      "epoch": 44.270833333333336,
      "grad_norm": 0.3254960775375366,
      "learning_rate": 0.00044584737124191094,
      "loss": 2.1486,
      "step": 8500
    },
    {
      "epoch": 44.322916666666664,
      "grad_norm": 0.3275834619998932,
      "learning_rate": 0.00044571889808332906,
      "loss": 2.1396,
      "step": 8510
    },
    {
      "epoch": 44.375,
      "grad_norm": 0.3814272880554199,
      "learning_rate": 0.00044559029126530484,
      "loss": 2.1413,
      "step": 8520
    },
    {
      "epoch": 44.427083333333336,
      "grad_norm": 0.3760748505592346,
      "learning_rate": 0.0004454615508756659,
      "loss": 2.1419,
      "step": 8530
    },
    {
      "epoch": 44.479166666666664,
      "grad_norm": 0.3995763957500458,
      "learning_rate": 0.00044533267700233104,
      "loss": 2.1365,
      "step": 8540
    },
    {
      "epoch": 44.53125,
      "grad_norm": 0.3940584659576416,
      "learning_rate": 0.0004452036697333102,
      "loss": 2.1425,
      "step": 8550
    },
    {
      "epoch": 44.583333333333336,
      "grad_norm": 0.4473263621330261,
      "learning_rate": 0.00044507452915670424,
      "loss": 2.1387,
      "step": 8560
    },
    {
      "epoch": 44.635416666666664,
      "grad_norm": 0.4506869316101074,
      "learning_rate": 0.0004449452553607056,
      "loss": 2.1396,
      "step": 8570
    },
    {
      "epoch": 44.6875,
      "grad_norm": 0.41066959500312805,
      "learning_rate": 0.000444815848433597,
      "loss": 2.1483,
      "step": 8580
    },
    {
      "epoch": 44.739583333333336,
      "grad_norm": 0.2981026768684387,
      "learning_rate": 0.00044468630846375266,
      "loss": 2.1405,
      "step": 8590
    },
    {
      "epoch": 44.791666666666664,
      "grad_norm": 0.3570998013019562,
      "learning_rate": 0.00044455663553963733,
      "loss": 2.1446,
      "step": 8600
    },
    {
      "epoch": 44.84375,
      "grad_norm": 0.3599071800708771,
      "learning_rate": 0.00044442682974980656,
      "loss": 2.1498,
      "step": 8610
    },
    {
      "epoch": 44.895833333333336,
      "grad_norm": 0.3064291179180145,
      "learning_rate": 0.0004442968911829068,
      "loss": 2.135,
      "step": 8620
    },
    {
      "epoch": 44.947916666666664,
      "grad_norm": 0.4231247901916504,
      "learning_rate": 0.00044416681992767514,
      "loss": 2.1524,
      "step": 8630
    },
    {
      "epoch": 45.0,
      "grad_norm": 0.5407418608665466,
      "learning_rate": 0.0004440366160729392,
      "loss": 2.1453,
      "step": 8640
    },
    {
      "epoch": 45.0,
      "eval_loss": 1.0804178714752197,
      "eval_runtime": 5.6151,
      "eval_samples_per_second": 3536.163,
      "eval_steps_per_second": 13.891,
      "step": 8640
    },
    {
      "epoch": 45.052083333333336,
      "grad_norm": 0.3790662884712219,
      "learning_rate": 0.00044390627970761714,
      "loss": 2.1357,
      "step": 8650
    },
    {
      "epoch": 45.104166666666664,
      "grad_norm": 0.36981672048568726,
      "learning_rate": 0.0004437758109207177,
      "loss": 2.1304,
      "step": 8660
    },
    {
      "epoch": 45.15625,
      "grad_norm": 0.7338696122169495,
      "learning_rate": 0.00044364520980134004,
      "loss": 2.1349,
      "step": 8670
    },
    {
      "epoch": 45.208333333333336,
      "grad_norm": 0.4192894399166107,
      "learning_rate": 0.00044351447643867367,
      "loss": 2.1288,
      "step": 8680
    },
    {
      "epoch": 45.260416666666664,
      "grad_norm": 0.5204683542251587,
      "learning_rate": 0.0004433836109219984,
      "loss": 2.1395,
      "step": 8690
    },
    {
      "epoch": 45.3125,
      "grad_norm": 0.38729214668273926,
      "learning_rate": 0.0004432526133406842,
      "loss": 2.1377,
      "step": 8700
    },
    {
      "epoch": 45.364583333333336,
      "grad_norm": 0.37903907895088196,
      "learning_rate": 0.0004431214837841915,
      "loss": 2.139,
      "step": 8710
    },
    {
      "epoch": 45.416666666666664,
      "grad_norm": 0.36960214376449585,
      "learning_rate": 0.00044299022234207063,
      "loss": 2.1405,
      "step": 8720
    },
    {
      "epoch": 45.46875,
      "grad_norm": 0.38486242294311523,
      "learning_rate": 0.00044285882910396205,
      "loss": 2.1523,
      "step": 8730
    },
    {
      "epoch": 45.520833333333336,
      "grad_norm": 0.34486067295074463,
      "learning_rate": 0.0004427273041595962,
      "loss": 2.127,
      "step": 8740
    },
    {
      "epoch": 45.572916666666664,
      "grad_norm": 0.35686802864074707,
      "learning_rate": 0.00044259564759879344,
      "loss": 2.1364,
      "step": 8750
    },
    {
      "epoch": 45.625,
      "grad_norm": 0.3642236590385437,
      "learning_rate": 0.00044246385951146415,
      "loss": 2.1561,
      "step": 8760
    },
    {
      "epoch": 45.677083333333336,
      "grad_norm": 0.37573879957199097,
      "learning_rate": 0.00044233193998760833,
      "loss": 2.143,
      "step": 8770
    },
    {
      "epoch": 45.729166666666664,
      "grad_norm": 0.3432994484901428,
      "learning_rate": 0.000442199889117316,
      "loss": 2.1598,
      "step": 8780
    },
    {
      "epoch": 45.78125,
      "grad_norm": 0.36235925555229187,
      "learning_rate": 0.0004420677069907666,
      "loss": 2.1567,
      "step": 8790
    },
    {
      "epoch": 45.833333333333336,
      "grad_norm": 0.3299092650413513,
      "learning_rate": 0.0004419353936982293,
      "loss": 2.1433,
      "step": 8800
    },
    {
      "epoch": 45.885416666666664,
      "grad_norm": 0.5404343605041504,
      "learning_rate": 0.0004418029493300631,
      "loss": 2.1449,
      "step": 8810
    },
    {
      "epoch": 45.9375,
      "grad_norm": 0.4174965023994446,
      "learning_rate": 0.00044167037397671604,
      "loss": 2.1443,
      "step": 8820
    },
    {
      "epoch": 45.989583333333336,
      "grad_norm": 0.3038269877433777,
      "learning_rate": 0.0004415376677287261,
      "loss": 2.1582,
      "step": 8830
    },
    {
      "epoch": 46.0,
      "eval_loss": 1.0797010660171509,
      "eval_runtime": 5.6088,
      "eval_samples_per_second": 3540.167,
      "eval_steps_per_second": 13.907,
      "step": 8832
    },
    {
      "epoch": 46.041666666666664,
      "grad_norm": 0.41302111744880676,
      "learning_rate": 0.00044140483067672023,
      "loss": 2.1338,
      "step": 8840
    },
    {
      "epoch": 46.09375,
      "grad_norm": 0.4030633866786957,
      "learning_rate": 0.00044127186291141493,
      "loss": 2.1313,
      "step": 8850
    },
    {
      "epoch": 46.145833333333336,
      "grad_norm": 0.38623061776161194,
      "learning_rate": 0.00044113876452361595,
      "loss": 2.1395,
      "step": 8860
    },
    {
      "epoch": 46.197916666666664,
      "grad_norm": 0.35195252299308777,
      "learning_rate": 0.00044100553560421827,
      "loss": 2.1418,
      "step": 8870
    },
    {
      "epoch": 46.25,
      "grad_norm": 0.41124072670936584,
      "learning_rate": 0.0004408721762442059,
      "loss": 2.1289,
      "step": 8880
    },
    {
      "epoch": 46.302083333333336,
      "grad_norm": 0.36139121651649475,
      "learning_rate": 0.00044073868653465197,
      "loss": 2.1287,
      "step": 8890
    },
    {
      "epoch": 46.354166666666664,
      "grad_norm": 0.3748011291027069,
      "learning_rate": 0.0004406050665667188,
      "loss": 2.1271,
      "step": 8900
    },
    {
      "epoch": 46.40625,
      "grad_norm": 0.37736716866493225,
      "learning_rate": 0.0004404713164316574,
      "loss": 2.1379,
      "step": 8910
    },
    {
      "epoch": 46.458333333333336,
      "grad_norm": 0.3720107078552246,
      "learning_rate": 0.0004403374362208078,
      "loss": 2.1359,
      "step": 8920
    },
    {
      "epoch": 46.510416666666664,
      "grad_norm": 0.3702382445335388,
      "learning_rate": 0.0004402034260255989,
      "loss": 2.1534,
      "step": 8930
    },
    {
      "epoch": 46.5625,
      "grad_norm": 0.368762344121933,
      "learning_rate": 0.00044006928593754823,
      "loss": 2.1446,
      "step": 8940
    },
    {
      "epoch": 46.614583333333336,
      "grad_norm": 0.35385367274284363,
      "learning_rate": 0.00043993501604826224,
      "loss": 2.1518,
      "step": 8950
    },
    {
      "epoch": 46.666666666666664,
      "grad_norm": 0.3286602199077606,
      "learning_rate": 0.00043980061644943583,
      "loss": 2.1422,
      "step": 8960
    },
    {
      "epoch": 46.71875,
      "grad_norm": 0.6168622970581055,
      "learning_rate": 0.0004396660872328525,
      "loss": 2.148,
      "step": 8970
    },
    {
      "epoch": 46.770833333333336,
      "grad_norm": 0.3435720205307007,
      "learning_rate": 0.0004395314284903844,
      "loss": 2.1401,
      "step": 8980
    },
    {
      "epoch": 46.822916666666664,
      "grad_norm": 0.30798041820526123,
      "learning_rate": 0.0004393966403139921,
      "loss": 2.1522,
      "step": 8990
    },
    {
      "epoch": 46.875,
      "grad_norm": 0.3578747510910034,
      "learning_rate": 0.0004392617227957244,
      "loss": 2.1497,
      "step": 9000
    },
    {
      "epoch": 46.927083333333336,
      "grad_norm": 0.34788545966148376,
      "learning_rate": 0.00043912667602771853,
      "loss": 2.1428,
      "step": 9010
    },
    {
      "epoch": 46.979166666666664,
      "grad_norm": 1.9999310970306396,
      "learning_rate": 0.0004389915001022001,
      "loss": 2.1434,
      "step": 9020
    },
    {
      "epoch": 47.0,
      "eval_loss": 1.0807111263275146,
      "eval_runtime": 5.608,
      "eval_samples_per_second": 3540.645,
      "eval_steps_per_second": 13.909,
      "step": 9024
    },
    {
      "epoch": 47.03125,
      "grad_norm": 0.43544209003448486,
      "learning_rate": 0.0004388561951114829,
      "loss": 2.1374,
      "step": 9030
    },
    {
      "epoch": 47.083333333333336,
      "grad_norm": 0.4027309715747833,
      "learning_rate": 0.0004387207611479686,
      "loss": 2.1203,
      "step": 9040
    },
    {
      "epoch": 47.135416666666664,
      "grad_norm": 0.3303805887699127,
      "learning_rate": 0.00043858519830414715,
      "loss": 2.1394,
      "step": 9050
    },
    {
      "epoch": 47.1875,
      "grad_norm": 0.40577247738838196,
      "learning_rate": 0.00043844950667259666,
      "loss": 2.1386,
      "step": 9060
    },
    {
      "epoch": 47.239583333333336,
      "grad_norm": 0.32992494106292725,
      "learning_rate": 0.0004383136863459829,
      "loss": 2.127,
      "step": 9070
    },
    {
      "epoch": 47.291666666666664,
      "grad_norm": 0.44647017121315,
      "learning_rate": 0.0004381777374170597,
      "loss": 2.1418,
      "step": 9080
    },
    {
      "epoch": 47.34375,
      "grad_norm": 0.46331310272216797,
      "learning_rate": 0.00043804165997866863,
      "loss": 2.1357,
      "step": 9090
    },
    {
      "epoch": 47.395833333333336,
      "grad_norm": 0.4236786365509033,
      "learning_rate": 0.00043790545412373904,
      "loss": 2.1391,
      "step": 9100
    },
    {
      "epoch": 47.447916666666664,
      "grad_norm": 0.4424808919429779,
      "learning_rate": 0.0004377691199452881,
      "loss": 2.1448,
      "step": 9110
    },
    {
      "epoch": 47.5,
      "grad_norm": 0.4652564823627472,
      "learning_rate": 0.0004376326575364206,
      "loss": 2.1551,
      "step": 9120
    },
    {
      "epoch": 47.552083333333336,
      "grad_norm": 0.4045630395412445,
      "learning_rate": 0.0004374960669903285,
      "loss": 2.1402,
      "step": 9130
    },
    {
      "epoch": 47.604166666666664,
      "grad_norm": 0.4385922849178314,
      "learning_rate": 0.00043735934840029186,
      "loss": 2.142,
      "step": 9140
    },
    {
      "epoch": 47.65625,
      "grad_norm": 0.4333397150039673,
      "learning_rate": 0.0004372225018596778,
      "loss": 2.1475,
      "step": 9150
    },
    {
      "epoch": 47.708333333333336,
      "grad_norm": 0.5374109148979187,
      "learning_rate": 0.0004370855274619409,
      "loss": 2.1392,
      "step": 9160
    },
    {
      "epoch": 47.760416666666664,
      "grad_norm": 0.5193338394165039,
      "learning_rate": 0.00043694842530062316,
      "loss": 2.1478,
      "step": 9170
    },
    {
      "epoch": 47.8125,
      "grad_norm": 0.41514965891838074,
      "learning_rate": 0.00043681119546935376,
      "loss": 2.1435,
      "step": 9180
    },
    {
      "epoch": 47.864583333333336,
      "grad_norm": 0.4011400640010834,
      "learning_rate": 0.0004366738380618489,
      "loss": 2.1434,
      "step": 9190
    },
    {
      "epoch": 47.916666666666664,
      "grad_norm": 0.50398188829422,
      "learning_rate": 0.00043653635317191224,
      "loss": 2.1427,
      "step": 9200
    },
    {
      "epoch": 47.96875,
      "grad_norm": 0.3995131254196167,
      "learning_rate": 0.0004363987408934343,
      "loss": 2.1351,
      "step": 9210
    },
    {
      "epoch": 48.0,
      "eval_loss": 1.0791200399398804,
      "eval_runtime": 5.6297,
      "eval_samples_per_second": 3526.99,
      "eval_steps_per_second": 13.855,
      "step": 9216
    },
    {
      "epoch": 48.020833333333336,
      "grad_norm": 0.35253793001174927,
      "learning_rate": 0.0004362610013203925,
      "loss": 2.144,
      "step": 9220
    },
    {
      "epoch": 48.072916666666664,
      "grad_norm": 0.4701630473136902,
      "learning_rate": 0.0004361231345468514,
      "loss": 2.1385,
      "step": 9230
    },
    {
      "epoch": 48.125,
      "grad_norm": 0.41644763946533203,
      "learning_rate": 0.00043598514066696235,
      "loss": 2.1509,
      "step": 9240
    },
    {
      "epoch": 48.177083333333336,
      "grad_norm": 0.41105854511260986,
      "learning_rate": 0.0004358470197749635,
      "loss": 2.1448,
      "step": 9250
    },
    {
      "epoch": 48.229166666666664,
      "grad_norm": 0.3190569281578064,
      "learning_rate": 0.00043570877196517964,
      "loss": 2.1393,
      "step": 9260
    },
    {
      "epoch": 48.28125,
      "grad_norm": 0.3847584128379822,
      "learning_rate": 0.0004355703973320224,
      "loss": 2.1301,
      "step": 9270
    },
    {
      "epoch": 48.333333333333336,
      "grad_norm": 0.32823607325553894,
      "learning_rate": 0.0004354318959699899,
      "loss": 2.139,
      "step": 9280
    },
    {
      "epoch": 48.385416666666664,
      "grad_norm": 0.3450072407722473,
      "learning_rate": 0.00043529326797366686,
      "loss": 2.137,
      "step": 9290
    },
    {
      "epoch": 48.4375,
      "grad_norm": 0.3682173490524292,
      "learning_rate": 0.00043515451343772456,
      "loss": 2.1398,
      "step": 9300
    },
    {
      "epoch": 48.489583333333336,
      "grad_norm": 0.3779304623603821,
      "learning_rate": 0.00043501563245692046,
      "loss": 2.1312,
      "step": 9310
    },
    {
      "epoch": 48.541666666666664,
      "grad_norm": 0.3658752739429474,
      "learning_rate": 0.0004348766251260986,
      "loss": 2.133,
      "step": 9320
    },
    {
      "epoch": 48.59375,
      "grad_norm": 0.40117454528808594,
      "learning_rate": 0.0004347374915401892,
      "loss": 2.1337,
      "step": 9330
    },
    {
      "epoch": 48.645833333333336,
      "grad_norm": 0.39656922221183777,
      "learning_rate": 0.0004345982317942087,
      "loss": 2.1393,
      "step": 9340
    },
    {
      "epoch": 48.697916666666664,
      "grad_norm": 0.49081215262413025,
      "learning_rate": 0.00043445884598325966,
      "loss": 2.132,
      "step": 9350
    },
    {
      "epoch": 48.75,
      "grad_norm": 0.46983712911605835,
      "learning_rate": 0.000434319334202531,
      "loss": 2.1376,
      "step": 9360
    },
    {
      "epoch": 48.802083333333336,
      "grad_norm": 0.41088083386421204,
      "learning_rate": 0.00043417969654729736,
      "loss": 2.1211,
      "step": 9370
    },
    {
      "epoch": 48.854166666666664,
      "grad_norm": 0.4214170277118683,
      "learning_rate": 0.00043403993311291934,
      "loss": 2.1481,
      "step": 9380
    },
    {
      "epoch": 48.90625,
      "grad_norm": 0.38399913907051086,
      "learning_rate": 0.0004339000439948436,
      "loss": 2.1441,
      "step": 9390
    },
    {
      "epoch": 48.958333333333336,
      "grad_norm": 0.35220158100128174,
      "learning_rate": 0.00043376002928860257,
      "loss": 2.1407,
      "step": 9400
    },
    {
      "epoch": 49.0,
      "eval_loss": 1.0790756940841675,
      "eval_runtime": 5.6191,
      "eval_samples_per_second": 3533.642,
      "eval_steps_per_second": 13.881,
      "step": 9408
    },
    {
      "epoch": 49.010416666666664,
      "grad_norm": 0.32787907123565674,
      "learning_rate": 0.00043361988908981446,
      "loss": 2.1279,
      "step": 9410
    },
    {
      "epoch": 49.0625,
      "grad_norm": 0.4418776035308838,
      "learning_rate": 0.0004334796234941832,
      "loss": 2.1186,
      "step": 9420
    },
    {
      "epoch": 49.114583333333336,
      "grad_norm": 0.43348050117492676,
      "learning_rate": 0.0004333392325974983,
      "loss": 2.1243,
      "step": 9430
    },
    {
      "epoch": 49.166666666666664,
      "grad_norm": 0.3584471344947815,
      "learning_rate": 0.0004331987164956347,
      "loss": 2.1365,
      "step": 9440
    },
    {
      "epoch": 49.21875,
      "grad_norm": 0.39140602946281433,
      "learning_rate": 0.0004330580752845533,
      "loss": 2.1348,
      "step": 9450
    },
    {
      "epoch": 49.270833333333336,
      "grad_norm": 0.3450317680835724,
      "learning_rate": 0.0004329173090602999,
      "loss": 2.153,
      "step": 9460
    },
    {
      "epoch": 49.322916666666664,
      "grad_norm": 0.38031846284866333,
      "learning_rate": 0.000432776417919006,
      "loss": 2.1403,
      "step": 9470
    },
    {
      "epoch": 49.375,
      "grad_norm": 0.3710471987724304,
      "learning_rate": 0.00043263540195688835,
      "loss": 2.128,
      "step": 9480
    },
    {
      "epoch": 49.427083333333336,
      "grad_norm": 0.3730998635292053,
      "learning_rate": 0.0004324942612702488,
      "loss": 2.1403,
      "step": 9490
    },
    {
      "epoch": 49.479166666666664,
      "grad_norm": 0.3962605893611908,
      "learning_rate": 0.0004323529959554747,
      "loss": 2.1338,
      "step": 9500
    },
    {
      "epoch": 49.53125,
      "grad_norm": 0.3254006803035736,
      "learning_rate": 0.0004322116061090382,
      "loss": 2.1486,
      "step": 9510
    },
    {
      "epoch": 49.583333333333336,
      "grad_norm": 0.3679860234260559,
      "learning_rate": 0.00043207009182749656,
      "loss": 2.1303,
      "step": 9520
    },
    {
      "epoch": 49.635416666666664,
      "grad_norm": 0.33189287781715393,
      "learning_rate": 0.0004319284532074921,
      "loss": 2.1353,
      "step": 9530
    },
    {
      "epoch": 49.6875,
      "grad_norm": 0.3763493299484253,
      "learning_rate": 0.0004317866903457519,
      "loss": 2.1304,
      "step": 9540
    },
    {
      "epoch": 49.739583333333336,
      "grad_norm": 0.37297308444976807,
      "learning_rate": 0.0004316448033390882,
      "loss": 2.1344,
      "step": 9550
    },
    {
      "epoch": 49.791666666666664,
      "grad_norm": 0.43162834644317627,
      "learning_rate": 0.00043150279228439765,
      "loss": 2.1447,
      "step": 9560
    },
    {
      "epoch": 49.84375,
      "grad_norm": 0.40561941266059875,
      "learning_rate": 0.0004313606572786619,
      "loss": 2.1243,
      "step": 9570
    },
    {
      "epoch": 49.895833333333336,
      "grad_norm": 0.46156835556030273,
      "learning_rate": 0.000431218398418947,
      "loss": 2.146,
      "step": 9580
    },
    {
      "epoch": 49.947916666666664,
      "grad_norm": 0.5505310893058777,
      "learning_rate": 0.0004310760158024038,
      "loss": 2.1323,
      "step": 9590
    },
    {
      "epoch": 50.0,
      "grad_norm": 0.3681013286113739,
      "learning_rate": 0.0004309335095262675,
      "loss": 2.1387,
      "step": 9600
    },
    {
      "epoch": 50.0,
      "eval_loss": 1.0792691707611084,
      "eval_runtime": 5.5991,
      "eval_samples_per_second": 3546.279,
      "eval_steps_per_second": 13.931,
      "step": 9600
    },
    {
      "epoch": 50.052083333333336,
      "grad_norm": 0.49277463555336,
      "learning_rate": 0.000430790879687858,
      "loss": 2.1256,
      "step": 9610
    },
    {
      "epoch": 50.104166666666664,
      "grad_norm": 0.41395577788352966,
      "learning_rate": 0.00043064812638457924,
      "loss": 2.1194,
      "step": 9620
    },
    {
      "epoch": 50.15625,
      "grad_norm": 0.39765167236328125,
      "learning_rate": 0.0004305052497139197,
      "loss": 2.1356,
      "step": 9630
    },
    {
      "epoch": 50.208333333333336,
      "grad_norm": 0.4728224575519562,
      "learning_rate": 0.00043036224977345197,
      "loss": 2.1377,
      "step": 9640
    },
    {
      "epoch": 50.260416666666664,
      "grad_norm": 0.4430810809135437,
      "learning_rate": 0.00043021912666083305,
      "loss": 2.1353,
      "step": 9650
    },
    {
      "epoch": 50.3125,
      "grad_norm": 0.35005253553390503,
      "learning_rate": 0.00043007588047380387,
      "loss": 2.1392,
      "step": 9660
    },
    {
      "epoch": 50.364583333333336,
      "grad_norm": 0.49442461133003235,
      "learning_rate": 0.00042993251131018934,
      "loss": 2.1226,
      "step": 9670
    },
    {
      "epoch": 50.416666666666664,
      "grad_norm": 0.44876205921173096,
      "learning_rate": 0.0004297890192678986,
      "loss": 2.1329,
      "step": 9680
    },
    {
      "epoch": 50.46875,
      "grad_norm": 0.3458113968372345,
      "learning_rate": 0.00042964540444492453,
      "loss": 2.1369,
      "step": 9690
    },
    {
      "epoch": 50.520833333333336,
      "grad_norm": 0.4386262595653534,
      "learning_rate": 0.0004295016669393439,
      "loss": 2.1231,
      "step": 9700
    },
    {
      "epoch": 50.572916666666664,
      "grad_norm": 0.3808368146419525,
      "learning_rate": 0.0004293578068493172,
      "loss": 2.1346,
      "step": 9710
    },
    {
      "epoch": 50.625,
      "grad_norm": 0.35176655650138855,
      "learning_rate": 0.00042921382427308876,
      "loss": 2.1355,
      "step": 9720
    },
    {
      "epoch": 50.677083333333336,
      "grad_norm": 0.38544973731040955,
      "learning_rate": 0.00042906971930898653,
      "loss": 2.1158,
      "step": 9730
    },
    {
      "epoch": 50.729166666666664,
      "grad_norm": 0.33735713362693787,
      "learning_rate": 0.0004289254920554219,
      "loss": 2.1342,
      "step": 9740
    },
    {
      "epoch": 50.78125,
      "grad_norm": 0.2999182641506195,
      "learning_rate": 0.00042878114261089,
      "loss": 2.1448,
      "step": 9750
    },
    {
      "epoch": 50.833333333333336,
      "grad_norm": 0.35332179069519043,
      "learning_rate": 0.0004286366710739691,
      "loss": 2.1357,
      "step": 9760
    },
    {
      "epoch": 50.885416666666664,
      "grad_norm": 0.37298741936683655,
      "learning_rate": 0.0004284920775433212,
      "loss": 2.158,
      "step": 9770
    },
    {
      "epoch": 50.9375,
      "grad_norm": 0.399318665266037,
      "learning_rate": 0.0004283473621176914,
      "loss": 2.1366,
      "step": 9780
    },
    {
      "epoch": 50.989583333333336,
      "grad_norm": 0.44025760889053345,
      "learning_rate": 0.0004282025248959081,
      "loss": 2.1449,
      "step": 9790
    },
    {
      "epoch": 51.0,
      "eval_loss": 1.079543948173523,
      "eval_runtime": 5.6291,
      "eval_samples_per_second": 3527.407,
      "eval_steps_per_second": 13.857,
      "step": 9792
    },
    {
      "epoch": 51.041666666666664,
      "grad_norm": 0.36907339096069336,
      "learning_rate": 0.0004280575659768828,
      "loss": 2.1358,
      "step": 9800
    },
    {
      "epoch": 51.09375,
      "grad_norm": 0.44264790415763855,
      "learning_rate": 0.0004279124854596102,
      "loss": 2.125,
      "step": 9810
    },
    {
      "epoch": 51.145833333333336,
      "grad_norm": 0.4067240059375763,
      "learning_rate": 0.0004277672834431681,
      "loss": 2.1345,
      "step": 9820
    },
    {
      "epoch": 51.197916666666664,
      "grad_norm": 0.5542470812797546,
      "learning_rate": 0.00042762196002671697,
      "loss": 2.1293,
      "step": 9830
    },
    {
      "epoch": 51.25,
      "grad_norm": 0.3898525536060333,
      "learning_rate": 0.00042747651530950073,
      "loss": 2.1305,
      "step": 9840
    },
    {
      "epoch": 51.302083333333336,
      "grad_norm": 0.6631176471710205,
      "learning_rate": 0.00042733094939084547,
      "loss": 2.1242,
      "step": 9850
    },
    {
      "epoch": 51.354166666666664,
      "grad_norm": 0.38268977403640747,
      "learning_rate": 0.00042718526237016066,
      "loss": 2.1299,
      "step": 9860
    },
    {
      "epoch": 51.40625,
      "grad_norm": 1.053161859512329,
      "learning_rate": 0.00042703945434693804,
      "loss": 2.1368,
      "step": 9870
    },
    {
      "epoch": 51.458333333333336,
      "grad_norm": 0.445290744304657,
      "learning_rate": 0.0004268935254207523,
      "loss": 2.1305,
      "step": 9880
    },
    {
      "epoch": 51.510416666666664,
      "grad_norm": 0.38337159156799316,
      "learning_rate": 0.0004267474756912603,
      "loss": 2.1296,
      "step": 9890
    },
    {
      "epoch": 51.5625,
      "grad_norm": 0.3864056468009949,
      "learning_rate": 0.0004266013052582019,
      "loss": 2.1402,
      "step": 9900
    },
    {
      "epoch": 51.614583333333336,
      "grad_norm": 0.340917706489563,
      "learning_rate": 0.00042645501422139897,
      "loss": 2.135,
      "step": 9910
    },
    {
      "epoch": 51.666666666666664,
      "grad_norm": 0.4570600092411041,
      "learning_rate": 0.0004263086026807561,
      "loss": 2.1423,
      "step": 9920
    },
    {
      "epoch": 51.71875,
      "grad_norm": 0.39412593841552734,
      "learning_rate": 0.00042616207073625974,
      "loss": 2.1316,
      "step": 9930
    },
    {
      "epoch": 51.770833333333336,
      "grad_norm": 0.37255632877349854,
      "learning_rate": 0.00042601541848797894,
      "loss": 2.1369,
      "step": 9940
    },
    {
      "epoch": 51.822916666666664,
      "grad_norm": 0.6602497696876526,
      "learning_rate": 0.0004258686460360647,
      "loss": 2.1407,
      "step": 9950
    },
    {
      "epoch": 51.875,
      "grad_norm": 0.364469051361084,
      "learning_rate": 0.0004257217534807503,
      "loss": 2.1487,
      "step": 9960
    },
    {
      "epoch": 51.927083333333336,
      "grad_norm": 0.344513863325119,
      "learning_rate": 0.0004255747409223508,
      "loss": 2.1487,
      "step": 9970
    },
    {
      "epoch": 51.979166666666664,
      "grad_norm": 0.3529660105705261,
      "learning_rate": 0.0004254276084612634,
      "loss": 2.1246,
      "step": 9980
    },
    {
      "epoch": 52.0,
      "eval_loss": 1.079407811164856,
      "eval_runtime": 5.6073,
      "eval_samples_per_second": 3541.071,
      "eval_steps_per_second": 13.91,
      "step": 9984
    },
    {
      "epoch": 52.03125,
      "grad_norm": 0.34718939661979675,
      "learning_rate": 0.00042528035619796706,
      "loss": 2.1286,
      "step": 9990
    },
    {
      "epoch": 52.083333333333336,
      "grad_norm": 0.48761674761772156,
      "learning_rate": 0.0004251329842330227,
      "loss": 2.1304,
      "step": 10000
    },
    {
      "epoch": 52.135416666666664,
      "grad_norm": 0.4093593955039978,
      "learning_rate": 0.0004249854926670729,
      "loss": 2.1382,
      "step": 10010
    },
    {
      "epoch": 52.1875,
      "grad_norm": 0.4470835030078888,
      "learning_rate": 0.0004248378816008418,
      "loss": 2.1223,
      "step": 10020
    },
    {
      "epoch": 52.239583333333336,
      "grad_norm": 0.3611481189727783,
      "learning_rate": 0.00042469015113513536,
      "loss": 2.1326,
      "step": 10030
    },
    {
      "epoch": 52.291666666666664,
      "grad_norm": 0.44422978162765503,
      "learning_rate": 0.0004245423013708409,
      "loss": 2.1336,
      "step": 10040
    },
    {
      "epoch": 52.34375,
      "grad_norm": 0.6061463356018066,
      "learning_rate": 0.00042439433240892745,
      "loss": 2.1307,
      "step": 10050
    },
    {
      "epoch": 52.395833333333336,
      "grad_norm": 0.4319086968898773,
      "learning_rate": 0.00042424624435044524,
      "loss": 2.1231,
      "step": 10060
    },
    {
      "epoch": 52.447916666666664,
      "grad_norm": 0.4617640972137451,
      "learning_rate": 0.00042409803729652576,
      "loss": 2.131,
      "step": 10070
    },
    {
      "epoch": 52.5,
      "grad_norm": 0.3642273545265198,
      "learning_rate": 0.0004239497113483819,
      "loss": 2.1427,
      "step": 10080
    },
    {
      "epoch": 52.552083333333336,
      "grad_norm": 0.42367666959762573,
      "learning_rate": 0.00042380126660730786,
      "loss": 2.1371,
      "step": 10090
    },
    {
      "epoch": 52.604166666666664,
      "grad_norm": 0.44521379470825195,
      "learning_rate": 0.00042365270317467875,
      "loss": 2.1247,
      "step": 10100
    },
    {
      "epoch": 52.65625,
      "grad_norm": 0.5715442299842834,
      "learning_rate": 0.00042350402115195085,
      "loss": 2.1396,
      "step": 10110
    },
    {
      "epoch": 52.708333333333336,
      "grad_norm": 0.3594321310520172,
      "learning_rate": 0.00042335522064066133,
      "loss": 2.1378,
      "step": 10120
    },
    {
      "epoch": 52.760416666666664,
      "grad_norm": 0.3548186421394348,
      "learning_rate": 0.0004232063017424285,
      "loss": 2.1274,
      "step": 10130
    },
    {
      "epoch": 52.8125,
      "grad_norm": 0.3600231111049652,
      "learning_rate": 0.0004230572645589511,
      "loss": 2.1352,
      "step": 10140
    },
    {
      "epoch": 52.864583333333336,
      "grad_norm": 0.371077299118042,
      "learning_rate": 0.00042290810919200916,
      "loss": 2.143,
      "step": 10150
    },
    {
      "epoch": 52.916666666666664,
      "grad_norm": 0.7864533066749573,
      "learning_rate": 0.0004227588357434631,
      "loss": 2.1288,
      "step": 10160
    },
    {
      "epoch": 52.96875,
      "grad_norm": 0.4272826910018921,
      "learning_rate": 0.00042260944431525403,
      "loss": 2.1311,
      "step": 10170
    },
    {
      "epoch": 53.0,
      "eval_loss": 1.0789906978607178,
      "eval_runtime": 5.6197,
      "eval_samples_per_second": 3533.305,
      "eval_steps_per_second": 13.88,
      "step": 10176
    },
    {
      "epoch": 53.020833333333336,
      "grad_norm": 0.4375619888305664,
      "learning_rate": 0.0004224599350094036,
      "loss": 2.122,
      "step": 10180
    },
    {
      "epoch": 53.072916666666664,
      "grad_norm": 0.45200908184051514,
      "learning_rate": 0.00042231030792801416,
      "loss": 2.1247,
      "step": 10190
    },
    {
      "epoch": 53.125,
      "grad_norm": 0.33663398027420044,
      "learning_rate": 0.0004221605631732681,
      "loss": 2.1283,
      "step": 10200
    },
    {
      "epoch": 53.177083333333336,
      "grad_norm": 0.3749391436576843,
      "learning_rate": 0.00042201070084742876,
      "loss": 2.127,
      "step": 10210
    },
    {
      "epoch": 53.229166666666664,
      "grad_norm": 0.39534619450569153,
      "learning_rate": 0.00042186072105283905,
      "loss": 2.1325,
      "step": 10220
    },
    {
      "epoch": 53.28125,
      "grad_norm": 0.3440695106983185,
      "learning_rate": 0.00042171062389192277,
      "loss": 2.1309,
      "step": 10230
    },
    {
      "epoch": 53.333333333333336,
      "grad_norm": 0.5370349884033203,
      "learning_rate": 0.00042156040946718344,
      "loss": 2.1243,
      "step": 10240
    },
    {
      "epoch": 53.385416666666664,
      "grad_norm": 0.45651450753211975,
      "learning_rate": 0.0004214100778812048,
      "loss": 2.1323,
      "step": 10250
    },
    {
      "epoch": 53.4375,
      "grad_norm": 0.3896660804748535,
      "learning_rate": 0.0004212596292366506,
      "loss": 2.1239,
      "step": 10260
    },
    {
      "epoch": 53.489583333333336,
      "grad_norm": 0.39361950755119324,
      "learning_rate": 0.0004211090636362646,
      "loss": 2.1303,
      "step": 10270
    },
    {
      "epoch": 53.541666666666664,
      "grad_norm": 0.3611363172531128,
      "learning_rate": 0.00042095838118287024,
      "loss": 2.1213,
      "step": 10280
    },
    {
      "epoch": 53.59375,
      "grad_norm": 0.4417993724346161,
      "learning_rate": 0.000420807581979371,
      "loss": 2.1354,
      "step": 10290
    },
    {
      "epoch": 53.645833333333336,
      "grad_norm": 0.35556912422180176,
      "learning_rate": 0.00042065666612874986,
      "loss": 2.1308,
      "step": 10300
    },
    {
      "epoch": 53.697916666666664,
      "grad_norm": 0.38558581471443176,
      "learning_rate": 0.00042050563373406967,
      "loss": 2.1404,
      "step": 10310
    },
    {
      "epoch": 53.75,
      "grad_norm": 0.38126954436302185,
      "learning_rate": 0.00042035448489847284,
      "loss": 2.1226,
      "step": 10320
    },
    {
      "epoch": 53.802083333333336,
      "grad_norm": 0.3731514811515808,
      "learning_rate": 0.000420203219725181,
      "loss": 2.1503,
      "step": 10330
    },
    {
      "epoch": 53.854166666666664,
      "grad_norm": 0.3650517165660858,
      "learning_rate": 0.00042005183831749567,
      "loss": 2.1434,
      "step": 10340
    },
    {
      "epoch": 53.90625,
      "grad_norm": 0.3868899941444397,
      "learning_rate": 0.0004199003407787974,
      "loss": 2.1285,
      "step": 10350
    },
    {
      "epoch": 53.958333333333336,
      "grad_norm": 0.3470454216003418,
      "learning_rate": 0.0004197487272125463,
      "loss": 2.1304,
      "step": 10360
    },
    {
      "epoch": 54.0,
      "eval_loss": 1.0787378549575806,
      "eval_runtime": 5.6008,
      "eval_samples_per_second": 3545.234,
      "eval_steps_per_second": 13.927,
      "step": 10368
    },
    {
      "epoch": 54.010416666666664,
      "grad_norm": 0.3924606740474701,
      "learning_rate": 0.00041959699772228153,
      "loss": 2.1292,
      "step": 10370
    },
    {
      "epoch": 54.0625,
      "grad_norm": 0.35835233330726624,
      "learning_rate": 0.0004194451524116216,
      "loss": 2.1248,
      "step": 10380
    },
    {
      "epoch": 54.114583333333336,
      "grad_norm": 0.4634345769882202,
      "learning_rate": 0.0004192931913842638,
      "loss": 2.1164,
      "step": 10390
    },
    {
      "epoch": 54.166666666666664,
      "grad_norm": 0.729826033115387,
      "learning_rate": 0.00041914111474398487,
      "loss": 2.1336,
      "step": 10400
    },
    {
      "epoch": 54.21875,
      "grad_norm": 0.3806903064250946,
      "learning_rate": 0.00041898892259464003,
      "loss": 2.1149,
      "step": 10410
    },
    {
      "epoch": 54.270833333333336,
      "grad_norm": 0.4030263125896454,
      "learning_rate": 0.0004188366150401639,
      "loss": 2.126,
      "step": 10420
    },
    {
      "epoch": 54.322916666666664,
      "grad_norm": 0.5346605777740479,
      "learning_rate": 0.00041868419218456953,
      "loss": 2.1308,
      "step": 10430
    },
    {
      "epoch": 54.375,
      "grad_norm": 0.44662201404571533,
      "learning_rate": 0.00041853165413194884,
      "loss": 2.1351,
      "step": 10440
    },
    {
      "epoch": 54.427083333333336,
      "grad_norm": 0.5087890625,
      "learning_rate": 0.00041837900098647243,
      "loss": 2.1274,
      "step": 10450
    },
    {
      "epoch": 54.479166666666664,
      "grad_norm": 0.3428124487400055,
      "learning_rate": 0.00041822623285238945,
      "loss": 2.1301,
      "step": 10460
    },
    {
      "epoch": 54.53125,
      "grad_norm": 0.4278947114944458,
      "learning_rate": 0.00041807334983402756,
      "loss": 2.1251,
      "step": 10470
    },
    {
      "epoch": 54.583333333333336,
      "grad_norm": 0.3772788345813751,
      "learning_rate": 0.000417920352035793,
      "loss": 2.1273,
      "step": 10480
    },
    {
      "epoch": 54.635416666666664,
      "grad_norm": 0.3617441654205322,
      "learning_rate": 0.00041776723956217027,
      "loss": 2.1336,
      "step": 10490
    },
    {
      "epoch": 54.6875,
      "grad_norm": 0.3945523798465729,
      "learning_rate": 0.00041761401251772223,
      "loss": 2.1239,
      "step": 10500
    },
    {
      "epoch": 54.739583333333336,
      "grad_norm": 0.4447554647922516,
      "learning_rate": 0.00041746067100709004,
      "loss": 2.1249,
      "step": 10510
    },
    {
      "epoch": 54.791666666666664,
      "grad_norm": 0.508732795715332,
      "learning_rate": 0.00041730721513499305,
      "loss": 2.1346,
      "step": 10520
    },
    {
      "epoch": 54.84375,
      "grad_norm": 0.5141351222991943,
      "learning_rate": 0.00041715364500622836,
      "loss": 2.1265,
      "step": 10530
    },
    {
      "epoch": 54.895833333333336,
      "grad_norm": 0.3564893305301666,
      "learning_rate": 0.0004169999607256716,
      "loss": 2.1235,
      "step": 10540
    },
    {
      "epoch": 54.947916666666664,
      "grad_norm": 0.4477912485599518,
      "learning_rate": 0.000416846162398276,
      "loss": 2.1448,
      "step": 10550
    },
    {
      "epoch": 55.0,
      "grad_norm": 0.3347291946411133,
      "learning_rate": 0.0004166922501290729,
      "loss": 2.1333,
      "step": 10560
    },
    {
      "epoch": 55.0,
      "eval_loss": 1.0782898664474487,
      "eval_runtime": 5.6218,
      "eval_samples_per_second": 3531.996,
      "eval_steps_per_second": 13.875,
      "step": 10560
    },
    {
      "epoch": 55.052083333333336,
      "grad_norm": 0.38591283559799194,
      "learning_rate": 0.0004165382240231713,
      "loss": 2.1289,
      "step": 10570
    },
    {
      "epoch": 55.104166666666664,
      "grad_norm": 0.47511211037635803,
      "learning_rate": 0.00041638408418575803,
      "loss": 2.1266,
      "step": 10580
    },
    {
      "epoch": 55.15625,
      "grad_norm": 0.4054200351238251,
      "learning_rate": 0.0004162298307220975,
      "loss": 2.1221,
      "step": 10590
    },
    {
      "epoch": 55.208333333333336,
      "grad_norm": 0.41717055439949036,
      "learning_rate": 0.0004160754637375318,
      "loss": 2.1279,
      "step": 10600
    },
    {
      "epoch": 55.260416666666664,
      "grad_norm": 0.44061294198036194,
      "learning_rate": 0.0004159209833374805,
      "loss": 2.1291,
      "step": 10610
    },
    {
      "epoch": 55.3125,
      "grad_norm": 0.5045822262763977,
      "learning_rate": 0.00041576638962744075,
      "loss": 2.1345,
      "step": 10620
    },
    {
      "epoch": 55.364583333333336,
      "grad_norm": 0.4642210304737091,
      "learning_rate": 0.0004156116827129867,
      "loss": 2.1196,
      "step": 10630
    },
    {
      "epoch": 55.416666666666664,
      "grad_norm": 0.4097091257572174,
      "learning_rate": 0.0004154568626997703,
      "loss": 2.1298,
      "step": 10640
    },
    {
      "epoch": 55.46875,
      "grad_norm": 0.48701414465904236,
      "learning_rate": 0.00041530192969352055,
      "loss": 2.1287,
      "step": 10650
    },
    {
      "epoch": 55.520833333333336,
      "grad_norm": 0.4940546154975891,
      "learning_rate": 0.00041514688380004343,
      "loss": 2.1231,
      "step": 10660
    },
    {
      "epoch": 55.572916666666664,
      "grad_norm": 0.39887192845344543,
      "learning_rate": 0.00041499172512522226,
      "loss": 2.1282,
      "step": 10670
    },
    {
      "epoch": 55.625,
      "grad_norm": 0.3947461247444153,
      "learning_rate": 0.0004148364537750172,
      "loss": 2.114,
      "step": 10680
    },
    {
      "epoch": 55.677083333333336,
      "grad_norm": 0.4074471890926361,
      "learning_rate": 0.00041468106985546556,
      "loss": 2.1251,
      "step": 10690
    },
    {
      "epoch": 55.729166666666664,
      "grad_norm": 0.49991652369499207,
      "learning_rate": 0.0004145255734726813,
      "loss": 2.1359,
      "step": 10700
    },
    {
      "epoch": 55.78125,
      "grad_norm": 0.44726696610450745,
      "learning_rate": 0.00041436996473285533,
      "loss": 2.1326,
      "step": 10710
    },
    {
      "epoch": 55.833333333333336,
      "grad_norm": 0.43257224559783936,
      "learning_rate": 0.0004142142437422552,
      "loss": 2.1161,
      "step": 10720
    },
    {
      "epoch": 55.885416666666664,
      "grad_norm": 0.46771714091300964,
      "learning_rate": 0.0004140584106072253,
      "loss": 2.1272,
      "step": 10730
    },
    {
      "epoch": 55.9375,
      "grad_norm": 0.4056673049926758,
      "learning_rate": 0.0004139024654341863,
      "loss": 2.118,
      "step": 10740
    },
    {
      "epoch": 55.989583333333336,
      "grad_norm": 0.47745516896247864,
      "learning_rate": 0.00041374640832963567,
      "loss": 2.1367,
      "step": 10750
    },
    {
      "epoch": 56.0,
      "eval_loss": 1.0791312456130981,
      "eval_runtime": 5.6267,
      "eval_samples_per_second": 3528.875,
      "eval_steps_per_second": 13.862,
      "step": 10752
    },
    {
      "epoch": 56.041666666666664,
      "grad_norm": 0.6697044372558594,
      "learning_rate": 0.0004135902394001472,
      "loss": 2.1179,
      "step": 10760
    },
    {
      "epoch": 56.09375,
      "grad_norm": 0.41753432154655457,
      "learning_rate": 0.00041343395875237095,
      "loss": 2.1239,
      "step": 10770
    },
    {
      "epoch": 56.145833333333336,
      "grad_norm": 0.41977041959762573,
      "learning_rate": 0.0004132775664930335,
      "loss": 2.1106,
      "step": 10780
    },
    {
      "epoch": 56.197916666666664,
      "grad_norm": 0.4037427008152008,
      "learning_rate": 0.00041312106272893746,
      "loss": 2.1294,
      "step": 10790
    },
    {
      "epoch": 56.25,
      "grad_norm": 0.5204278230667114,
      "learning_rate": 0.0004129644475669616,
      "loss": 2.1378,
      "step": 10800
    },
    {
      "epoch": 56.302083333333336,
      "grad_norm": 0.529961347579956,
      "learning_rate": 0.00041280772111406094,
      "loss": 2.1305,
      "step": 10810
    },
    {
      "epoch": 56.354166666666664,
      "grad_norm": 0.405735045671463,
      "learning_rate": 0.0004126508834772664,
      "loss": 2.1217,
      "step": 10820
    },
    {
      "epoch": 56.40625,
      "grad_norm": 0.4804580509662628,
      "learning_rate": 0.00041249393476368475,
      "loss": 2.1211,
      "step": 10830
    },
    {
      "epoch": 56.458333333333336,
      "grad_norm": 0.4438551664352417,
      "learning_rate": 0.00041233687508049853,
      "loss": 2.1236,
      "step": 10840
    },
    {
      "epoch": 56.510416666666664,
      "grad_norm": 0.43255171179771423,
      "learning_rate": 0.0004121797045349665,
      "loss": 2.1305,
      "step": 10850
    },
    {
      "epoch": 56.5625,
      "grad_norm": 0.4833824336528778,
      "learning_rate": 0.0004120224232344226,
      "loss": 2.1274,
      "step": 10860
    },
    {
      "epoch": 56.614583333333336,
      "grad_norm": 0.43171456456184387,
      "learning_rate": 0.00041186503128627677,
      "loss": 2.1178,
      "step": 10870
    },
    {
      "epoch": 56.666666666666664,
      "grad_norm": 0.44595369696617126,
      "learning_rate": 0.00041170752879801436,
      "loss": 2.1193,
      "step": 10880
    },
    {
      "epoch": 56.71875,
      "grad_norm": 0.3767893612384796,
      "learning_rate": 0.0004115499158771963,
      "loss": 2.1314,
      "step": 10890
    },
    {
      "epoch": 56.770833333333336,
      "grad_norm": 0.38661450147628784,
      "learning_rate": 0.0004113921926314587,
      "loss": 2.1079,
      "step": 10900
    },
    {
      "epoch": 56.822916666666664,
      "grad_norm": 0.3980673849582672,
      "learning_rate": 0.00041123435916851336,
      "loss": 2.1376,
      "step": 10910
    },
    {
      "epoch": 56.875,
      "grad_norm": 0.4529125988483429,
      "learning_rate": 0.00041107641559614703,
      "loss": 2.1316,
      "step": 10920
    },
    {
      "epoch": 56.927083333333336,
      "grad_norm": 0.42006829380989075,
      "learning_rate": 0.000410918362022222,
      "loss": 2.1311,
      "step": 10930
    },
    {
      "epoch": 56.979166666666664,
      "grad_norm": 0.3395718038082123,
      "learning_rate": 0.00041076019855467534,
      "loss": 2.1383,
      "step": 10940
    },
    {
      "epoch": 57.0,
      "eval_loss": 1.0794157981872559,
      "eval_runtime": 5.6064,
      "eval_samples_per_second": 3541.639,
      "eval_steps_per_second": 13.913,
      "step": 10944
    },
    {
      "epoch": 57.03125,
      "grad_norm": 0.3699004352092743,
      "learning_rate": 0.0004106019253015193,
      "loss": 2.1224,
      "step": 10950
    },
    {
      "epoch": 57.083333333333336,
      "grad_norm": 0.4414326250553131,
      "learning_rate": 0.0004104435423708412,
      "loss": 2.1281,
      "step": 10960
    },
    {
      "epoch": 57.135416666666664,
      "grad_norm": 0.400829941034317,
      "learning_rate": 0.00041028504987080316,
      "loss": 2.1157,
      "step": 10970
    },
    {
      "epoch": 57.1875,
      "grad_norm": 0.4608452320098877,
      "learning_rate": 0.00041012644790964207,
      "loss": 2.1205,
      "step": 10980
    },
    {
      "epoch": 57.239583333333336,
      "grad_norm": 0.34991514682769775,
      "learning_rate": 0.0004099677365956697,
      "loss": 2.1281,
      "step": 10990
    },
    {
      "epoch": 57.291666666666664,
      "grad_norm": 0.38601186871528625,
      "learning_rate": 0.00040980891603727246,
      "loss": 2.1178,
      "step": 11000
    },
    {
      "epoch": 57.34375,
      "grad_norm": 0.3654645085334778,
      "learning_rate": 0.00040964998634291137,
      "loss": 2.1222,
      "step": 11010
    },
    {
      "epoch": 57.395833333333336,
      "grad_norm": 0.33781933784484863,
      "learning_rate": 0.0004094909476211218,
      "loss": 2.1283,
      "step": 11020
    },
    {
      "epoch": 57.447916666666664,
      "grad_norm": 0.3203481435775757,
      "learning_rate": 0.00040933179998051394,
      "loss": 2.1238,
      "step": 11030
    },
    {
      "epoch": 57.5,
      "grad_norm": 0.40136563777923584,
      "learning_rate": 0.00040917254352977204,
      "loss": 2.1102,
      "step": 11040
    },
    {
      "epoch": 57.552083333333336,
      "grad_norm": 0.44034862518310547,
      "learning_rate": 0.00040901317837765483,
      "loss": 2.1215,
      "step": 11050
    },
    {
      "epoch": 57.604166666666664,
      "grad_norm": 0.3722761571407318,
      "learning_rate": 0.0004088537046329952,
      "loss": 2.1246,
      "step": 11060
    },
    {
      "epoch": 57.65625,
      "grad_norm": 0.3301604092121124,
      "learning_rate": 0.0004086941224047003,
      "loss": 2.1255,
      "step": 11070
    },
    {
      "epoch": 57.708333333333336,
      "grad_norm": 0.34879693388938904,
      "learning_rate": 0.0004085344318017511,
      "loss": 2.1169,
      "step": 11080
    },
    {
      "epoch": 57.760416666666664,
      "grad_norm": 0.34857624769210815,
      "learning_rate": 0.0004083746329332029,
      "loss": 2.1265,
      "step": 11090
    },
    {
      "epoch": 57.8125,
      "grad_norm": 0.39987897872924805,
      "learning_rate": 0.00040821472590818475,
      "loss": 2.1419,
      "step": 11100
    },
    {
      "epoch": 57.864583333333336,
      "grad_norm": 0.3210756778717041,
      "learning_rate": 0.00040805471083589967,
      "loss": 2.1162,
      "step": 11110
    },
    {
      "epoch": 57.916666666666664,
      "grad_norm": 0.3638042211532593,
      "learning_rate": 0.0004078945878256244,
      "loss": 2.1228,
      "step": 11120
    },
    {
      "epoch": 57.96875,
      "grad_norm": 0.3636649250984192,
      "learning_rate": 0.00040773435698670933,
      "loss": 2.1365,
      "step": 11130
    },
    {
      "epoch": 58.0,
      "eval_loss": 1.0792323350906372,
      "eval_runtime": 5.6025,
      "eval_samples_per_second": 3544.153,
      "eval_steps_per_second": 13.922,
      "step": 11136
    },
    {
      "epoch": 58.020833333333336,
      "grad_norm": 0.41588738560676575,
      "learning_rate": 0.00040757401842857866,
      "loss": 2.1206,
      "step": 11140
    },
    {
      "epoch": 58.072916666666664,
      "grad_norm": 0.384807825088501,
      "learning_rate": 0.00040741357226073004,
      "loss": 2.1208,
      "step": 11150
    },
    {
      "epoch": 58.125,
      "grad_norm": 0.3486633598804474,
      "learning_rate": 0.00040725301859273456,
      "loss": 2.1185,
      "step": 11160
    },
    {
      "epoch": 58.177083333333336,
      "grad_norm": 0.373393714427948,
      "learning_rate": 0.00040709235753423677,
      "loss": 2.1177,
      "step": 11170
    },
    {
      "epoch": 58.229166666666664,
      "grad_norm": 0.3680203855037689,
      "learning_rate": 0.00040693158919495473,
      "loss": 2.1314,
      "step": 11180
    },
    {
      "epoch": 58.28125,
      "grad_norm": 0.399495393037796,
      "learning_rate": 0.0004067707136846794,
      "loss": 2.115,
      "step": 11190
    },
    {
      "epoch": 58.333333333333336,
      "grad_norm": 0.4843664765357971,
      "learning_rate": 0.00040660973111327533,
      "loss": 2.1117,
      "step": 11200
    },
    {
      "epoch": 58.385416666666664,
      "grad_norm": 0.3883942663669586,
      "learning_rate": 0.00040644864159067984,
      "loss": 2.1172,
      "step": 11210
    },
    {
      "epoch": 58.4375,
      "grad_norm": 0.4089794456958771,
      "learning_rate": 0.00040628744522690354,
      "loss": 2.1233,
      "step": 11220
    },
    {
      "epoch": 58.489583333333336,
      "grad_norm": 0.41780510544776917,
      "learning_rate": 0.0004061261421320298,
      "loss": 2.1053,
      "step": 11230
    },
    {
      "epoch": 58.541666666666664,
      "grad_norm": 0.40286773443222046,
      "learning_rate": 0.0004059647324162151,
      "loss": 2.1196,
      "step": 11240
    },
    {
      "epoch": 58.59375,
      "grad_norm": 0.3809427320957184,
      "learning_rate": 0.00040580321618968854,
      "loss": 2.1374,
      "step": 11250
    },
    {
      "epoch": 58.645833333333336,
      "grad_norm": 0.372022420167923,
      "learning_rate": 0.0004056415935627521,
      "loss": 2.1146,
      "step": 11260
    },
    {
      "epoch": 58.697916666666664,
      "grad_norm": 0.510584831237793,
      "learning_rate": 0.00040547986464578025,
      "loss": 2.1302,
      "step": 11270
    },
    {
      "epoch": 58.75,
      "grad_norm": 0.46359920501708984,
      "learning_rate": 0.0004053180295492203,
      "loss": 2.1206,
      "step": 11280
    },
    {
      "epoch": 58.802083333333336,
      "grad_norm": 0.41000592708587646,
      "learning_rate": 0.00040515608838359173,
      "loss": 2.1233,
      "step": 11290
    },
    {
      "epoch": 58.854166666666664,
      "grad_norm": 0.3874646723270416,
      "learning_rate": 0.0004049940412594868,
      "loss": 2.1156,
      "step": 11300
    },
    {
      "epoch": 58.90625,
      "grad_norm": 0.46897318959236145,
      "learning_rate": 0.0004048318882875699,
      "loss": 2.1288,
      "step": 11310
    },
    {
      "epoch": 58.958333333333336,
      "grad_norm": 0.4047962427139282,
      "learning_rate": 0.0004046696295785779,
      "loss": 2.1374,
      "step": 11320
    },
    {
      "epoch": 59.0,
      "eval_loss": 1.0785480737686157,
      "eval_runtime": 5.6299,
      "eval_samples_per_second": 3526.875,
      "eval_steps_per_second": 13.855,
      "step": 11328
    },
    {
      "epoch": 59.010416666666664,
      "grad_norm": 0.3914530277252197,
      "learning_rate": 0.0004045072652433196,
      "loss": 2.1223,
      "step": 11330
    },
    {
      "epoch": 59.0625,
      "grad_norm": 0.44832828640937805,
      "learning_rate": 0.00040434479539267626,
      "loss": 2.117,
      "step": 11340
    },
    {
      "epoch": 59.114583333333336,
      "grad_norm": 0.47384101152420044,
      "learning_rate": 0.0004041822201376009,
      "loss": 2.121,
      "step": 11350
    },
    {
      "epoch": 59.166666666666664,
      "grad_norm": 0.44923803210258484,
      "learning_rate": 0.00040401953958911876,
      "loss": 2.1233,
      "step": 11360
    },
    {
      "epoch": 59.21875,
      "grad_norm": 0.6166911721229553,
      "learning_rate": 0.00040385675385832685,
      "loss": 2.1087,
      "step": 11370
    },
    {
      "epoch": 59.270833333333336,
      "grad_norm": 0.5059581995010376,
      "learning_rate": 0.000403693863056394,
      "loss": 2.1156,
      "step": 11380
    },
    {
      "epoch": 59.322916666666664,
      "grad_norm": 0.507136881351471,
      "learning_rate": 0.0004035308672945609,
      "loss": 2.1109,
      "step": 11390
    },
    {
      "epoch": 59.375,
      "grad_norm": 0.4373128116130829,
      "learning_rate": 0.00040336776668413986,
      "loss": 2.1268,
      "step": 11400
    },
    {
      "epoch": 59.427083333333336,
      "grad_norm": 0.4665566086769104,
      "learning_rate": 0.0004032045613365148,
      "loss": 2.1237,
      "step": 11410
    },
    {
      "epoch": 59.479166666666664,
      "grad_norm": 0.3695276379585266,
      "learning_rate": 0.0004030412513631411,
      "loss": 2.1243,
      "step": 11420
    },
    {
      "epoch": 59.53125,
      "grad_norm": 0.3691675364971161,
      "learning_rate": 0.00040287783687554575,
      "loss": 2.1225,
      "step": 11430
    },
    {
      "epoch": 59.583333333333336,
      "grad_norm": 0.4447052776813507,
      "learning_rate": 0.00040271431798532685,
      "loss": 2.1299,
      "step": 11440
    },
    {
      "epoch": 59.635416666666664,
      "grad_norm": 0.43367302417755127,
      "learning_rate": 0.00040255069480415415,
      "loss": 2.1136,
      "step": 11450
    },
    {
      "epoch": 59.6875,
      "grad_norm": 0.4496828317642212,
      "learning_rate": 0.0004023869674437683,
      "loss": 2.1271,
      "step": 11460
    },
    {
      "epoch": 59.739583333333336,
      "grad_norm": 0.40449047088623047,
      "learning_rate": 0.00040222313601598125,
      "loss": 2.1222,
      "step": 11470
    },
    {
      "epoch": 59.791666666666664,
      "grad_norm": 0.47852498292922974,
      "learning_rate": 0.000402059200632676,
      "loss": 2.122,
      "step": 11480
    },
    {
      "epoch": 59.84375,
      "grad_norm": 0.40899497270584106,
      "learning_rate": 0.00040189516140580673,
      "loss": 2.1237,
      "step": 11490
    },
    {
      "epoch": 59.895833333333336,
      "grad_norm": 0.34043368697166443,
      "learning_rate": 0.0004017310184473981,
      "loss": 2.1208,
      "step": 11500
    },
    {
      "epoch": 59.947916666666664,
      "grad_norm": 0.40576720237731934,
      "learning_rate": 0.0004015667718695459,
      "loss": 2.1213,
      "step": 11510
    },
    {
      "epoch": 60.0,
      "grad_norm": 0.7881055474281311,
      "learning_rate": 0.00040140242178441667,
      "loss": 2.1148,
      "step": 11520
    },
    {
      "epoch": 60.0,
      "eval_loss": 1.080365538597107,
      "eval_runtime": 5.661,
      "eval_samples_per_second": 3507.478,
      "eval_steps_per_second": 13.778,
      "step": 11520
    },
    {
      "epoch": 60.052083333333336,
      "grad_norm": 0.3801347017288208,
      "learning_rate": 0.00040123796830424764,
      "loss": 2.1186,
      "step": 11530
    },
    {
      "epoch": 60.104166666666664,
      "grad_norm": 0.41448649764060974,
      "learning_rate": 0.00040107341154134663,
      "loss": 2.1134,
      "step": 11540
    },
    {
      "epoch": 60.15625,
      "grad_norm": 0.3559502959251404,
      "learning_rate": 0.0004009087516080919,
      "loss": 2.1121,
      "step": 11550
    },
    {
      "epoch": 60.208333333333336,
      "grad_norm": 0.4215220510959625,
      "learning_rate": 0.0004007439886169324,
      "loss": 2.1037,
      "step": 11560
    },
    {
      "epoch": 60.260416666666664,
      "grad_norm": 0.35332900285720825,
      "learning_rate": 0.0004005791226803872,
      "loss": 2.1242,
      "step": 11570
    },
    {
      "epoch": 60.3125,
      "grad_norm": 0.4643799960613251,
      "learning_rate": 0.00040041415391104567,
      "loss": 2.1253,
      "step": 11580
    },
    {
      "epoch": 60.364583333333336,
      "grad_norm": 0.3989628255367279,
      "learning_rate": 0.00040024908242156776,
      "loss": 2.1116,
      "step": 11590
    },
    {
      "epoch": 60.416666666666664,
      "grad_norm": 0.3933124542236328,
      "learning_rate": 0.0004000839083246831,
      "loss": 2.1148,
      "step": 11600
    },
    {
      "epoch": 60.46875,
      "grad_norm": 0.3578532338142395,
      "learning_rate": 0.0003999186317331918,
      "loss": 2.1163,
      "step": 11610
    },
    {
      "epoch": 60.520833333333336,
      "grad_norm": 0.4011812210083008,
      "learning_rate": 0.00039975325275996365,
      "loss": 2.1216,
      "step": 11620
    },
    {
      "epoch": 60.572916666666664,
      "grad_norm": 0.38736122846603394,
      "learning_rate": 0.0003995877715179386,
      "loss": 2.116,
      "step": 11630
    },
    {
      "epoch": 60.625,
      "grad_norm": 0.44915470480918884,
      "learning_rate": 0.0003994221881201262,
      "loss": 2.1256,
      "step": 11640
    },
    {
      "epoch": 60.677083333333336,
      "grad_norm": 0.4195011258125305,
      "learning_rate": 0.00039925650267960607,
      "loss": 2.1265,
      "step": 11650
    },
    {
      "epoch": 60.729166666666664,
      "grad_norm": 0.40277865529060364,
      "learning_rate": 0.00039909071530952716,
      "loss": 2.1196,
      "step": 11660
    },
    {
      "epoch": 60.78125,
      "grad_norm": 0.40573519468307495,
      "learning_rate": 0.0003989248261231084,
      "loss": 2.1074,
      "step": 11670
    },
    {
      "epoch": 60.833333333333336,
      "grad_norm": 0.3917233347892761,
      "learning_rate": 0.0003987588352336379,
      "loss": 2.1281,
      "step": 11680
    },
    {
      "epoch": 60.885416666666664,
      "grad_norm": 0.35737746953964233,
      "learning_rate": 0.0003985927427544734,
      "loss": 2.1232,
      "step": 11690
    },
    {
      "epoch": 60.9375,
      "grad_norm": 0.34731829166412354,
      "learning_rate": 0.00039842654879904214,
      "loss": 2.121,
      "step": 11700
    },
    {
      "epoch": 60.989583333333336,
      "grad_norm": 0.3873433768749237,
      "learning_rate": 0.0003982602534808404,
      "loss": 2.1162,
      "step": 11710
    },
    {
      "epoch": 61.0,
      "eval_loss": 1.0798282623291016,
      "eval_runtime": 5.6228,
      "eval_samples_per_second": 3531.34,
      "eval_steps_per_second": 13.872,
      "step": 11712
    },
    {
      "epoch": 61.041666666666664,
      "grad_norm": 0.48049086332321167,
      "learning_rate": 0.0003980938569134338,
      "loss": 2.1253,
      "step": 11720
    },
    {
      "epoch": 61.09375,
      "grad_norm": 0.4268791079521179,
      "learning_rate": 0.00039792735921045724,
      "loss": 2.1138,
      "step": 11730
    },
    {
      "epoch": 61.145833333333336,
      "grad_norm": 0.37482950091362,
      "learning_rate": 0.0003977607604856145,
      "loss": 2.1053,
      "step": 11740
    },
    {
      "epoch": 61.197916666666664,
      "grad_norm": 0.3902198374271393,
      "learning_rate": 0.00039759406085267834,
      "loss": 2.1266,
      "step": 11750
    },
    {
      "epoch": 61.25,
      "grad_norm": 0.4775443971157074,
      "learning_rate": 0.00039742726042549053,
      "loss": 2.1165,
      "step": 11760
    },
    {
      "epoch": 61.302083333333336,
      "grad_norm": 0.43937480449676514,
      "learning_rate": 0.0003972603593179617,
      "loss": 2.1186,
      "step": 11770
    },
    {
      "epoch": 61.354166666666664,
      "grad_norm": 0.40584707260131836,
      "learning_rate": 0.0003970933576440711,
      "loss": 2.1149,
      "step": 11780
    },
    {
      "epoch": 61.40625,
      "grad_norm": 0.4216688871383667,
      "learning_rate": 0.0003969262555178669,
      "loss": 2.1116,
      "step": 11790
    },
    {
      "epoch": 61.458333333333336,
      "grad_norm": 0.48857852816581726,
      "learning_rate": 0.0003967590530534655,
      "loss": 2.104,
      "step": 11800
    },
    {
      "epoch": 61.510416666666664,
      "grad_norm": 0.3457527160644531,
      "learning_rate": 0.0003965917503650521,
      "loss": 2.1296,
      "step": 11810
    },
    {
      "epoch": 61.5625,
      "grad_norm": 0.3798082172870636,
      "learning_rate": 0.00039642434756688037,
      "loss": 2.1081,
      "step": 11820
    },
    {
      "epoch": 61.614583333333336,
      "grad_norm": 0.3964930474758148,
      "learning_rate": 0.00039625684477327216,
      "loss": 2.1171,
      "step": 11830
    },
    {
      "epoch": 61.666666666666664,
      "grad_norm": 0.3557681739330292,
      "learning_rate": 0.00039608924209861776,
      "loss": 2.1246,
      "step": 11840
    },
    {
      "epoch": 61.71875,
      "grad_norm": 0.3508346676826477,
      "learning_rate": 0.00039592153965737546,
      "loss": 2.1217,
      "step": 11850
    },
    {
      "epoch": 61.770833333333336,
      "grad_norm": 0.37485459446907043,
      "learning_rate": 0.0003957537375640721,
      "loss": 2.1248,
      "step": 11860
    },
    {
      "epoch": 61.822916666666664,
      "grad_norm": 0.3835274577140808,
      "learning_rate": 0.00039558583593330207,
      "loss": 2.1248,
      "step": 11870
    },
    {
      "epoch": 61.875,
      "grad_norm": 0.40303078293800354,
      "learning_rate": 0.000395417834879728,
      "loss": 2.1163,
      "step": 11880
    },
    {
      "epoch": 61.927083333333336,
      "grad_norm": 0.3343469500541687,
      "learning_rate": 0.00039524973451808055,
      "loss": 2.1145,
      "step": 11890
    },
    {
      "epoch": 61.979166666666664,
      "grad_norm": 0.36257123947143555,
      "learning_rate": 0.0003950815349631579,
      "loss": 2.1076,
      "step": 11900
    },
    {
      "epoch": 62.0,
      "eval_loss": 1.0796159505844116,
      "eval_runtime": 5.6156,
      "eval_samples_per_second": 3535.849,
      "eval_steps_per_second": 13.89,
      "step": 11904
    },
    {
      "epoch": 62.03125,
      "grad_norm": 0.4355376660823822,
      "learning_rate": 0.0003949132363298262,
      "loss": 2.1087,
      "step": 11910
    },
    {
      "epoch": 62.083333333333336,
      "grad_norm": 0.3758419156074524,
      "learning_rate": 0.00039474483873301906,
      "loss": 2.119,
      "step": 11920
    },
    {
      "epoch": 62.135416666666664,
      "grad_norm": 0.49532070755958557,
      "learning_rate": 0.0003945763422877379,
      "loss": 2.1027,
      "step": 11930
    },
    {
      "epoch": 62.1875,
      "grad_norm": 0.36294472217559814,
      "learning_rate": 0.0003944077471090515,
      "loss": 2.1059,
      "step": 11940
    },
    {
      "epoch": 62.239583333333336,
      "grad_norm": 0.3927631080150604,
      "learning_rate": 0.00039423905331209595,
      "loss": 2.119,
      "step": 11950
    },
    {
      "epoch": 62.291666666666664,
      "grad_norm": 0.39740416407585144,
      "learning_rate": 0.0003940702610120751,
      "loss": 2.104,
      "step": 11960
    },
    {
      "epoch": 62.34375,
      "grad_norm": 0.4019978940486908,
      "learning_rate": 0.00039390137032425953,
      "loss": 2.1066,
      "step": 11970
    },
    {
      "epoch": 62.395833333333336,
      "grad_norm": 0.37557780742645264,
      "learning_rate": 0.0003937323813639875,
      "loss": 2.1168,
      "step": 11980
    },
    {
      "epoch": 62.447916666666664,
      "grad_norm": 0.3873199224472046,
      "learning_rate": 0.00039356329424666413,
      "loss": 2.1189,
      "step": 11990
    },
    {
      "epoch": 62.5,
      "grad_norm": 0.40377894043922424,
      "learning_rate": 0.00039339410908776154,
      "loss": 2.1144,
      "step": 12000
    },
    {
      "epoch": 62.552083333333336,
      "grad_norm": 0.4228155016899109,
      "learning_rate": 0.0003932248260028189,
      "loss": 2.1215,
      "step": 12010
    },
    {
      "epoch": 62.604166666666664,
      "grad_norm": 0.374555766582489,
      "learning_rate": 0.00039305544510744223,
      "loss": 2.1143,
      "step": 12020
    },
    {
      "epoch": 62.65625,
      "grad_norm": 0.3667863607406616,
      "learning_rate": 0.00039288596651730433,
      "loss": 2.1043,
      "step": 12030
    },
    {
      "epoch": 62.708333333333336,
      "grad_norm": 0.43577316403388977,
      "learning_rate": 0.00039271639034814474,
      "loss": 2.1207,
      "step": 12040
    },
    {
      "epoch": 62.760416666666664,
      "grad_norm": 0.39567670226097107,
      "learning_rate": 0.0003925467167157697,
      "loss": 2.1128,
      "step": 12050
    },
    {
      "epoch": 62.8125,
      "grad_norm": 0.3839327096939087,
      "learning_rate": 0.00039237694573605186,
      "loss": 2.1243,
      "step": 12060
    },
    {
      "epoch": 62.864583333333336,
      "grad_norm": 0.38133659958839417,
      "learning_rate": 0.0003922070775249305,
      "loss": 2.121,
      "step": 12070
    },
    {
      "epoch": 62.916666666666664,
      "grad_norm": 0.3820497691631317,
      "learning_rate": 0.00039203711219841107,
      "loss": 2.1234,
      "step": 12080
    },
    {
      "epoch": 62.96875,
      "grad_norm": 0.5442071557044983,
      "learning_rate": 0.0003918670498725657,
      "loss": 2.128,
      "step": 12090
    },
    {
      "epoch": 63.0,
      "eval_loss": 1.0790132284164429,
      "eval_runtime": 5.6173,
      "eval_samples_per_second": 3534.78,
      "eval_steps_per_second": 13.886,
      "step": 12096
    },
    {
      "epoch": 63.020833333333336,
      "grad_norm": 0.3562926650047302,
      "learning_rate": 0.0003916968906635325,
      "loss": 2.1165,
      "step": 12100
    },
    {
      "epoch": 63.072916666666664,
      "grad_norm": 0.38353005051612854,
      "learning_rate": 0.0003915266346875157,
      "loss": 2.105,
      "step": 12110
    },
    {
      "epoch": 63.125,
      "grad_norm": 0.4047989845275879,
      "learning_rate": 0.0003913562820607859,
      "loss": 2.1024,
      "step": 12120
    },
    {
      "epoch": 63.177083333333336,
      "grad_norm": 0.6980888843536377,
      "learning_rate": 0.00039118583289967935,
      "loss": 2.1046,
      "step": 12130
    },
    {
      "epoch": 63.229166666666664,
      "grad_norm": 0.41762834787368774,
      "learning_rate": 0.00039101528732059856,
      "loss": 2.1172,
      "step": 12140
    },
    {
      "epoch": 63.28125,
      "grad_norm": 0.39116141200065613,
      "learning_rate": 0.00039084464544001166,
      "loss": 2.1128,
      "step": 12150
    },
    {
      "epoch": 63.333333333333336,
      "grad_norm": 0.3664599657058716,
      "learning_rate": 0.00039067390737445256,
      "loss": 2.1275,
      "step": 12160
    },
    {
      "epoch": 63.385416666666664,
      "grad_norm": 0.35905948281288147,
      "learning_rate": 0.000390503073240521,
      "loss": 2.1303,
      "step": 12170
    },
    {
      "epoch": 63.4375,
      "grad_norm": 0.37822824716567993,
      "learning_rate": 0.0003903321431548821,
      "loss": 2.1203,
      "step": 12180
    },
    {
      "epoch": 63.489583333333336,
      "grad_norm": 0.37422266602516174,
      "learning_rate": 0.0003901611172342668,
      "loss": 2.1179,
      "step": 12190
    },
    {
      "epoch": 63.541666666666664,
      "grad_norm": 0.42569500207901,
      "learning_rate": 0.00038998999559547134,
      "loss": 2.112,
      "step": 12200
    },
    {
      "epoch": 63.59375,
      "grad_norm": 0.42068731784820557,
      "learning_rate": 0.00038981877835535706,
      "loss": 2.1114,
      "step": 12210
    },
    {
      "epoch": 63.645833333333336,
      "grad_norm": 0.39838600158691406,
      "learning_rate": 0.0003896474656308511,
      "loss": 2.1,
      "step": 12220
    },
    {
      "epoch": 63.697916666666664,
      "grad_norm": 0.4172300100326538,
      "learning_rate": 0.00038947605753894554,
      "loss": 2.1058,
      "step": 12230
    },
    {
      "epoch": 63.75,
      "grad_norm": 0.5797217488288879,
      "learning_rate": 0.00038930455419669747,
      "loss": 2.1108,
      "step": 12240
    },
    {
      "epoch": 63.802083333333336,
      "grad_norm": 0.457256019115448,
      "learning_rate": 0.0003891329557212292,
      "loss": 2.1014,
      "step": 12250
    },
    {
      "epoch": 63.854166666666664,
      "grad_norm": 0.43301886320114136,
      "learning_rate": 0.000388961262229728,
      "loss": 2.1092,
      "step": 12260
    },
    {
      "epoch": 63.90625,
      "grad_norm": 0.5057405829429626,
      "learning_rate": 0.000388789473839446,
      "loss": 2.1221,
      "step": 12270
    },
    {
      "epoch": 63.958333333333336,
      "grad_norm": 0.4152153432369232,
      "learning_rate": 0.00038861759066770004,
      "loss": 2.1183,
      "step": 12280
    },
    {
      "epoch": 64.0,
      "eval_loss": 1.0788655281066895,
      "eval_runtime": 5.6121,
      "eval_samples_per_second": 3538.078,
      "eval_steps_per_second": 13.899,
      "step": 12288
    },
    {
      "epoch": 64.01041666666667,
      "grad_norm": 0.42223063111305237,
      "learning_rate": 0.00038844561283187185,
      "loss": 2.1142,
      "step": 12290
    },
    {
      "epoch": 64.0625,
      "grad_norm": 0.4464396834373474,
      "learning_rate": 0.0003882735404494078,
      "loss": 2.1017,
      "step": 12300
    },
    {
      "epoch": 64.11458333333333,
      "grad_norm": 0.3673259913921356,
      "learning_rate": 0.0003881013736378186,
      "loss": 2.0952,
      "step": 12310
    },
    {
      "epoch": 64.16666666666667,
      "grad_norm": 0.4063870906829834,
      "learning_rate": 0.0003879291125146798,
      "loss": 2.1081,
      "step": 12320
    },
    {
      "epoch": 64.21875,
      "grad_norm": 0.4347632825374603,
      "learning_rate": 0.00038775675719763104,
      "loss": 2.12,
      "step": 12330
    },
    {
      "epoch": 64.27083333333333,
      "grad_norm": 0.36652880907058716,
      "learning_rate": 0.00038758430780437645,
      "loss": 2.1054,
      "step": 12340
    },
    {
      "epoch": 64.32291666666667,
      "grad_norm": 0.380972683429718,
      "learning_rate": 0.0003874117644526843,
      "loss": 2.1145,
      "step": 12350
    },
    {
      "epoch": 64.375,
      "grad_norm": 0.39069467782974243,
      "learning_rate": 0.00038723912726038723,
      "loss": 2.0963,
      "step": 12360
    },
    {
      "epoch": 64.42708333333333,
      "grad_norm": 0.42660608887672424,
      "learning_rate": 0.0003870663963453818,
      "loss": 2.1102,
      "step": 12370
    },
    {
      "epoch": 64.47916666666667,
      "grad_norm": 0.40182429552078247,
      "learning_rate": 0.00038689357182562843,
      "loss": 2.1176,
      "step": 12380
    },
    {
      "epoch": 64.53125,
      "grad_norm": 0.3840756416320801,
      "learning_rate": 0.0003867206538191519,
      "loss": 2.1198,
      "step": 12390
    },
    {
      "epoch": 64.58333333333333,
      "grad_norm": 0.49973365664482117,
      "learning_rate": 0.0003865476424440404,
      "loss": 2.1119,
      "step": 12400
    },
    {
      "epoch": 64.63541666666667,
      "grad_norm": 0.49153435230255127,
      "learning_rate": 0.0003863745378184461,
      "loss": 2.1112,
      "step": 12410
    },
    {
      "epoch": 64.6875,
      "grad_norm": 0.463356614112854,
      "learning_rate": 0.0003862013400605848,
      "loss": 2.0985,
      "step": 12420
    },
    {
      "epoch": 64.73958333333333,
      "grad_norm": 0.36593320965766907,
      "learning_rate": 0.00038602804928873603,
      "loss": 2.1119,
      "step": 12430
    },
    {
      "epoch": 64.79166666666667,
      "grad_norm": 0.48632100224494934,
      "learning_rate": 0.0003858546656212425,
      "loss": 2.1139,
      "step": 12440
    },
    {
      "epoch": 64.84375,
      "grad_norm": 0.5209692120552063,
      "learning_rate": 0.00038568118917651074,
      "loss": 2.1051,
      "step": 12450
    },
    {
      "epoch": 64.89583333333333,
      "grad_norm": 0.3929609954357147,
      "learning_rate": 0.00038550762007301046,
      "loss": 2.1305,
      "step": 12460
    },
    {
      "epoch": 64.94791666666667,
      "grad_norm": 0.4045150578022003,
      "learning_rate": 0.0003853339584292746,
      "loss": 2.1199,
      "step": 12470
    },
    {
      "epoch": 65.0,
      "grad_norm": 0.3764578402042389,
      "learning_rate": 0.0003851602043638994,
      "loss": 2.1187,
      "step": 12480
    },
    {
      "epoch": 65.0,
      "eval_loss": 1.0790208578109741,
      "eval_runtime": 5.6118,
      "eval_samples_per_second": 3538.25,
      "eval_steps_per_second": 13.899,
      "step": 12480
    },
    {
      "epoch": 65.05208333333333,
      "grad_norm": 0.5379012227058411,
      "learning_rate": 0.0003849863579955442,
      "loss": 2.1168,
      "step": 12490
    },
    {
      "epoch": 65.10416666666667,
      "grad_norm": 0.40812692046165466,
      "learning_rate": 0.00038481241944293134,
      "loss": 2.1082,
      "step": 12500
    },
    {
      "epoch": 65.15625,
      "grad_norm": 0.531255841255188,
      "learning_rate": 0.00038463838882484615,
      "loss": 2.1003,
      "step": 12510
    },
    {
      "epoch": 65.20833333333333,
      "grad_norm": 0.3469341993331909,
      "learning_rate": 0.00038446426626013677,
      "loss": 2.1003,
      "step": 12520
    },
    {
      "epoch": 65.26041666666667,
      "grad_norm": 0.3870964050292969,
      "learning_rate": 0.00038429005186771425,
      "loss": 2.1077,
      "step": 12530
    },
    {
      "epoch": 65.3125,
      "grad_norm": 0.3648773729801178,
      "learning_rate": 0.00038411574576655217,
      "loss": 2.0999,
      "step": 12540
    },
    {
      "epoch": 65.36458333333333,
      "grad_norm": 0.41197913885116577,
      "learning_rate": 0.00038394134807568693,
      "loss": 2.111,
      "step": 12550
    },
    {
      "epoch": 65.41666666666667,
      "grad_norm": 0.37635087966918945,
      "learning_rate": 0.0003837668589142174,
      "loss": 2.104,
      "step": 12560
    },
    {
      "epoch": 65.46875,
      "grad_norm": 0.4181191027164459,
      "learning_rate": 0.00038359227840130476,
      "loss": 2.1097,
      "step": 12570
    },
    {
      "epoch": 65.52083333333333,
      "grad_norm": 0.4152415096759796,
      "learning_rate": 0.0003834176066561729,
      "loss": 2.1255,
      "step": 12580
    },
    {
      "epoch": 65.57291666666667,
      "grad_norm": 0.37430429458618164,
      "learning_rate": 0.0003832428437981078,
      "loss": 2.0984,
      "step": 12590
    },
    {
      "epoch": 65.625,
      "grad_norm": 0.35702309012413025,
      "learning_rate": 0.0003830679899464576,
      "loss": 2.1118,
      "step": 12600
    },
    {
      "epoch": 65.67708333333333,
      "grad_norm": 0.3658403754234314,
      "learning_rate": 0.0003828930452206328,
      "loss": 2.1167,
      "step": 12610
    },
    {
      "epoch": 65.72916666666667,
      "grad_norm": 0.32160523533821106,
      "learning_rate": 0.0003827180097401058,
      "loss": 2.1083,
      "step": 12620
    },
    {
      "epoch": 65.78125,
      "grad_norm": 0.46676895022392273,
      "learning_rate": 0.00038254288362441093,
      "loss": 2.117,
      "step": 12630
    },
    {
      "epoch": 65.83333333333333,
      "grad_norm": 0.35364946722984314,
      "learning_rate": 0.00038236766699314474,
      "loss": 2.107,
      "step": 12640
    },
    {
      "epoch": 65.88541666666667,
      "grad_norm": 0.3945678770542145,
      "learning_rate": 0.00038219235996596513,
      "loss": 2.1033,
      "step": 12650
    },
    {
      "epoch": 65.9375,
      "grad_norm": 0.3918561041355133,
      "learning_rate": 0.000382016962662592,
      "loss": 2.1114,
      "step": 12660
    },
    {
      "epoch": 65.98958333333333,
      "grad_norm": 0.4030303955078125,
      "learning_rate": 0.0003818414752028069,
      "loss": 2.1111,
      "step": 12670
    },
    {
      "epoch": 66.0,
      "eval_loss": 1.0807979106903076,
      "eval_runtime": 5.6134,
      "eval_samples_per_second": 3537.241,
      "eval_steps_per_second": 13.895,
      "step": 12672
    },
    {
      "epoch": 66.04166666666667,
      "grad_norm": 0.36849167943000793,
      "learning_rate": 0.00038166589770645306,
      "loss": 2.0974,
      "step": 12680
    },
    {
      "epoch": 66.09375,
      "grad_norm": 0.4218178391456604,
      "learning_rate": 0.0003814902302934348,
      "loss": 2.113,
      "step": 12690
    },
    {
      "epoch": 66.14583333333333,
      "grad_norm": 0.399895578622818,
      "learning_rate": 0.00038131447308371814,
      "loss": 2.1001,
      "step": 12700
    },
    {
      "epoch": 66.19791666666667,
      "grad_norm": 0.4446599781513214,
      "learning_rate": 0.00038113862619733053,
      "loss": 2.1041,
      "step": 12710
    },
    {
      "epoch": 66.25,
      "grad_norm": 0.38838738203048706,
      "learning_rate": 0.00038096268975436044,
      "loss": 2.1102,
      "step": 12720
    },
    {
      "epoch": 66.30208333333333,
      "grad_norm": 0.4067925810813904,
      "learning_rate": 0.00038078666387495743,
      "loss": 2.1067,
      "step": 12730
    },
    {
      "epoch": 66.35416666666667,
      "grad_norm": 0.3734695017337799,
      "learning_rate": 0.0003806105486793325,
      "loss": 2.1005,
      "step": 12740
    },
    {
      "epoch": 66.40625,
      "grad_norm": 0.5314926505088806,
      "learning_rate": 0.0003804343442877573,
      "loss": 2.1085,
      "step": 12750
    },
    {
      "epoch": 66.45833333333333,
      "grad_norm": 0.40518587827682495,
      "learning_rate": 0.0003802580508205645,
      "loss": 2.1072,
      "step": 12760
    },
    {
      "epoch": 66.51041666666667,
      "grad_norm": 0.39994266629219055,
      "learning_rate": 0.00038008166839814775,
      "loss": 2.121,
      "step": 12770
    },
    {
      "epoch": 66.5625,
      "grad_norm": 0.5076383948326111,
      "learning_rate": 0.0003799051971409611,
      "loss": 2.1076,
      "step": 12780
    },
    {
      "epoch": 66.61458333333333,
      "grad_norm": 0.29453733563423157,
      "learning_rate": 0.00037972863716951964,
      "loss": 2.1105,
      "step": 12790
    },
    {
      "epoch": 66.66666666666667,
      "grad_norm": 0.35781484842300415,
      "learning_rate": 0.00037955198860439886,
      "loss": 2.1141,
      "step": 12800
    },
    {
      "epoch": 66.71875,
      "grad_norm": 0.4064728915691376,
      "learning_rate": 0.0003793752515662348,
      "loss": 2.1082,
      "step": 12810
    },
    {
      "epoch": 66.77083333333333,
      "grad_norm": 0.38816946744918823,
      "learning_rate": 0.0003791984261757238,
      "loss": 2.1195,
      "step": 12820
    },
    {
      "epoch": 66.82291666666667,
      "grad_norm": 0.36354243755340576,
      "learning_rate": 0.0003790215125536228,
      "loss": 2.1048,
      "step": 12830
    },
    {
      "epoch": 66.875,
      "grad_norm": 0.39467957615852356,
      "learning_rate": 0.00037884451082074864,
      "loss": 2.111,
      "step": 12840
    },
    {
      "epoch": 66.92708333333333,
      "grad_norm": 0.35738834738731384,
      "learning_rate": 0.00037866742109797866,
      "loss": 2.1111,
      "step": 12850
    },
    {
      "epoch": 66.97916666666667,
      "grad_norm": 0.4209544360637665,
      "learning_rate": 0.00037849024350625004,
      "loss": 2.1043,
      "step": 12860
    },
    {
      "epoch": 67.0,
      "eval_loss": 1.0797199010849,
      "eval_runtime": 5.4143,
      "eval_samples_per_second": 3667.306,
      "eval_steps_per_second": 14.406,
      "step": 12864
    },
    {
      "epoch": 67.03125,
      "grad_norm": 0.5632805824279785,
      "learning_rate": 0.0003783129781665602,
      "loss": 2.1036,
      "step": 12870
    },
    {
      "epoch": 67.08333333333333,
      "grad_norm": 0.3640053868293762,
      "learning_rate": 0.0003781356251999663,
      "loss": 2.0962,
      "step": 12880
    },
    {
      "epoch": 67.13541666666667,
      "grad_norm": 0.34368953108787537,
      "learning_rate": 0.0003779581847275854,
      "loss": 2.104,
      "step": 12890
    },
    {
      "epoch": 67.1875,
      "grad_norm": 0.3782036304473877,
      "learning_rate": 0.00037778065687059435,
      "loss": 2.104,
      "step": 12900
    },
    {
      "epoch": 67.23958333333333,
      "grad_norm": 0.3985460698604584,
      "learning_rate": 0.0003776030417502297,
      "loss": 2.1063,
      "step": 12910
    },
    {
      "epoch": 67.29166666666667,
      "grad_norm": 0.4107053875923157,
      "learning_rate": 0.00037742533948778746,
      "loss": 2.1013,
      "step": 12920
    },
    {
      "epoch": 67.34375,
      "grad_norm": 0.40494874119758606,
      "learning_rate": 0.0003772475502046232,
      "loss": 2.0979,
      "step": 12930
    },
    {
      "epoch": 67.39583333333333,
      "grad_norm": 0.40919986367225647,
      "learning_rate": 0.000377069674022152,
      "loss": 2.1137,
      "step": 12940
    },
    {
      "epoch": 67.44791666666667,
      "grad_norm": 0.5093868970870972,
      "learning_rate": 0.00037689171106184837,
      "loss": 2.0919,
      "step": 12950
    },
    {
      "epoch": 67.5,
      "grad_norm": 0.37182381749153137,
      "learning_rate": 0.0003767136614452458,
      "loss": 2.1095,
      "step": 12960
    },
    {
      "epoch": 67.55208333333333,
      "grad_norm": 0.4509218633174896,
      "learning_rate": 0.0003765355252939371,
      "loss": 2.0921,
      "step": 12970
    },
    {
      "epoch": 67.60416666666667,
      "grad_norm": 1.4458378553390503,
      "learning_rate": 0.00037635730272957417,
      "loss": 2.1128,
      "step": 12980
    },
    {
      "epoch": 67.65625,
      "grad_norm": 0.37944361567497253,
      "learning_rate": 0.000376178993873868,
      "loss": 2.1006,
      "step": 12990
    },
    {
      "epoch": 67.70833333333333,
      "grad_norm": 0.5558601021766663,
      "learning_rate": 0.0003760005988485885,
      "loss": 2.1147,
      "step": 13000
    },
    {
      "epoch": 67.76041666666667,
      "grad_norm": 0.45034268498420715,
      "learning_rate": 0.0003758221177755643,
      "loss": 2.0981,
      "step": 13010
    },
    {
      "epoch": 67.8125,
      "grad_norm": 0.4460924565792084,
      "learning_rate": 0.0003756435507766829,
      "loss": 2.115,
      "step": 13020
    },
    {
      "epoch": 67.86458333333333,
      "grad_norm": 0.5555424690246582,
      "learning_rate": 0.0003754648979738904,
      "loss": 2.1219,
      "step": 13030
    },
    {
      "epoch": 67.91666666666667,
      "grad_norm": 0.39606842398643494,
      "learning_rate": 0.00037528615948919156,
      "loss": 2.1003,
      "step": 13040
    },
    {
      "epoch": 67.96875,
      "grad_norm": 0.38683655858039856,
      "learning_rate": 0.00037510733544464966,
      "loss": 2.0982,
      "step": 13050
    },
    {
      "epoch": 68.0,
      "eval_loss": 1.0796914100646973,
      "eval_runtime": 5.4942,
      "eval_samples_per_second": 3614.018,
      "eval_steps_per_second": 14.197,
      "step": 13056
    },
    {
      "epoch": 68.02083333333333,
      "grad_norm": 0.38769587874412537,
      "learning_rate": 0.00037492842596238636,
      "loss": 2.1063,
      "step": 13060
    },
    {
      "epoch": 68.07291666666667,
      "grad_norm": 0.38822102546691895,
      "learning_rate": 0.0003747494311645817,
      "loss": 2.0881,
      "step": 13070
    },
    {
      "epoch": 68.125,
      "grad_norm": 0.365357369184494,
      "learning_rate": 0.000374570351173474,
      "loss": 2.0928,
      "step": 13080
    },
    {
      "epoch": 68.17708333333333,
      "grad_norm": 0.46697041392326355,
      "learning_rate": 0.0003743911861113597,
      "loss": 2.0915,
      "step": 13090
    },
    {
      "epoch": 68.22916666666667,
      "grad_norm": 0.46641629934310913,
      "learning_rate": 0.00037421193610059347,
      "loss": 2.0961,
      "step": 13100
    },
    {
      "epoch": 68.28125,
      "grad_norm": 0.3828639090061188,
      "learning_rate": 0.0003740326012635877,
      "loss": 2.0892,
      "step": 13110
    },
    {
      "epoch": 68.33333333333333,
      "grad_norm": 0.44596371054649353,
      "learning_rate": 0.0003738531817228131,
      "loss": 2.1196,
      "step": 13120
    },
    {
      "epoch": 68.38541666666667,
      "grad_norm": 0.44888198375701904,
      "learning_rate": 0.00037367367760079794,
      "loss": 2.105,
      "step": 13130
    },
    {
      "epoch": 68.4375,
      "grad_norm": 0.3400905430316925,
      "learning_rate": 0.0003734940890201284,
      "loss": 2.1092,
      "step": 13140
    },
    {
      "epoch": 68.48958333333333,
      "grad_norm": 0.5175862908363342,
      "learning_rate": 0.00037331441610344816,
      "loss": 2.104,
      "step": 13150
    },
    {
      "epoch": 68.54166666666667,
      "grad_norm": 0.3751545548439026,
      "learning_rate": 0.00037313465897345876,
      "loss": 2.0949,
      "step": 13160
    },
    {
      "epoch": 68.59375,
      "grad_norm": 0.5737741589546204,
      "learning_rate": 0.000372954817752919,
      "loss": 2.1167,
      "step": 13170
    },
    {
      "epoch": 68.64583333333333,
      "grad_norm": 0.3866190016269684,
      "learning_rate": 0.0003727748925646453,
      "loss": 2.1095,
      "step": 13180
    },
    {
      "epoch": 68.69791666666667,
      "grad_norm": 0.4209158420562744,
      "learning_rate": 0.0003725948835315112,
      "loss": 2.1178,
      "step": 13190
    },
    {
      "epoch": 68.75,
      "grad_norm": 0.36665835976600647,
      "learning_rate": 0.0003724147907764478,
      "loss": 2.113,
      "step": 13200
    },
    {
      "epoch": 68.80208333333333,
      "grad_norm": 0.479400098323822,
      "learning_rate": 0.00037223461442244314,
      "loss": 2.1195,
      "step": 13210
    },
    {
      "epoch": 68.85416666666667,
      "grad_norm": 0.6910444498062134,
      "learning_rate": 0.0003720543545925424,
      "loss": 2.1026,
      "step": 13220
    },
    {
      "epoch": 68.90625,
      "grad_norm": 0.4093942940235138,
      "learning_rate": 0.0003718740114098478,
      "loss": 2.1036,
      "step": 13230
    },
    {
      "epoch": 68.95833333333333,
      "grad_norm": 0.38235801458358765,
      "learning_rate": 0.00037169358499751845,
      "loss": 2.1069,
      "step": 13240
    },
    {
      "epoch": 69.0,
      "eval_loss": 1.0806206464767456,
      "eval_runtime": 5.4452,
      "eval_samples_per_second": 3646.521,
      "eval_steps_per_second": 14.325,
      "step": 13248
    },
    {
      "epoch": 69.01041666666667,
      "grad_norm": 0.36035239696502686,
      "learning_rate": 0.00037151307547877033,
      "loss": 2.1085,
      "step": 13250
    },
    {
      "epoch": 69.0625,
      "grad_norm": 0.44657018780708313,
      "learning_rate": 0.00037133248297687615,
      "loss": 2.0918,
      "step": 13260
    },
    {
      "epoch": 69.11458333333333,
      "grad_norm": 0.5297437906265259,
      "learning_rate": 0.0003711518076151654,
      "loss": 2.0959,
      "step": 13270
    },
    {
      "epoch": 69.16666666666667,
      "grad_norm": 0.4410667419433594,
      "learning_rate": 0.000370971049517024,
      "loss": 2.0939,
      "step": 13280
    },
    {
      "epoch": 69.21875,
      "grad_norm": 0.4341318607330322,
      "learning_rate": 0.0003707902088058943,
      "loss": 2.0973,
      "step": 13290
    },
    {
      "epoch": 69.27083333333333,
      "grad_norm": 0.4084290564060211,
      "learning_rate": 0.0003706092856052754,
      "loss": 2.0929,
      "step": 13300
    },
    {
      "epoch": 69.32291666666667,
      "grad_norm": 0.40599319338798523,
      "learning_rate": 0.0003704282800387225,
      "loss": 2.1004,
      "step": 13310
    },
    {
      "epoch": 69.375,
      "grad_norm": 0.4458339512348175,
      "learning_rate": 0.00037024719222984693,
      "loss": 2.097,
      "step": 13320
    },
    {
      "epoch": 69.42708333333333,
      "grad_norm": 0.3730280101299286,
      "learning_rate": 0.00037006602230231646,
      "loss": 2.1029,
      "step": 13330
    },
    {
      "epoch": 69.47916666666667,
      "grad_norm": 0.43792521953582764,
      "learning_rate": 0.0003698847703798548,
      "loss": 2.1041,
      "step": 13340
    },
    {
      "epoch": 69.53125,
      "grad_norm": 0.45860424637794495,
      "learning_rate": 0.00036970343658624175,
      "loss": 2.1046,
      "step": 13350
    },
    {
      "epoch": 69.58333333333333,
      "grad_norm": 0.4486636221408844,
      "learning_rate": 0.0003695220210453128,
      "loss": 2.1048,
      "step": 13360
    },
    {
      "epoch": 69.63541666666667,
      "grad_norm": 0.3648325800895691,
      "learning_rate": 0.00036934052388095946,
      "loss": 2.1102,
      "step": 13370
    },
    {
      "epoch": 69.6875,
      "grad_norm": 0.5305916666984558,
      "learning_rate": 0.0003691589452171289,
      "loss": 2.1035,
      "step": 13380
    },
    {
      "epoch": 69.73958333333333,
      "grad_norm": 0.4067164957523346,
      "learning_rate": 0.00036897728517782416,
      "loss": 2.0948,
      "step": 13390
    },
    {
      "epoch": 69.79166666666667,
      "grad_norm": 0.6368945240974426,
      "learning_rate": 0.0003687955438871035,
      "loss": 2.1055,
      "step": 13400
    },
    {
      "epoch": 69.84375,
      "grad_norm": 0.36208659410476685,
      "learning_rate": 0.0003686137214690807,
      "loss": 2.0967,
      "step": 13410
    },
    {
      "epoch": 69.89583333333333,
      "grad_norm": 0.3865302801132202,
      "learning_rate": 0.00036843181804792547,
      "loss": 2.1162,
      "step": 13420
    },
    {
      "epoch": 69.94791666666667,
      "grad_norm": 0.3794404864311218,
      "learning_rate": 0.00036824983374786216,
      "loss": 2.1028,
      "step": 13430
    },
    {
      "epoch": 70.0,
      "grad_norm": 0.41661497950553894,
      "learning_rate": 0.0003680677686931707,
      "loss": 2.1062,
      "step": 13440
    },
    {
      "epoch": 70.0,
      "eval_loss": 1.0833638906478882,
      "eval_runtime": 5.4678,
      "eval_samples_per_second": 3631.466,
      "eval_steps_per_second": 14.265,
      "step": 13440
    },
    {
      "epoch": 70.05208333333333,
      "grad_norm": 0.3691428005695343,
      "learning_rate": 0.0003678856230081862,
      "loss": 2.1049,
      "step": 13450
    },
    {
      "epoch": 70.10416666666667,
      "grad_norm": 0.41843390464782715,
      "learning_rate": 0.00036770339681729857,
      "loss": 2.0989,
      "step": 13460
    },
    {
      "epoch": 70.15625,
      "grad_norm": 0.44126179814338684,
      "learning_rate": 0.00036752109024495305,
      "loss": 2.0881,
      "step": 13470
    },
    {
      "epoch": 70.20833333333333,
      "grad_norm": 0.3938388526439667,
      "learning_rate": 0.00036733870341564955,
      "loss": 2.0895,
      "step": 13480
    },
    {
      "epoch": 70.26041666666667,
      "grad_norm": 0.4311496317386627,
      "learning_rate": 0.00036715623645394284,
      "loss": 2.1117,
      "step": 13490
    },
    {
      "epoch": 70.3125,
      "grad_norm": 0.4553389251232147,
      "learning_rate": 0.0003669736894844424,
      "loss": 2.0846,
      "step": 13500
    },
    {
      "epoch": 70.36458333333333,
      "grad_norm": 0.3869834244251251,
      "learning_rate": 0.00036679106263181227,
      "loss": 2.0996,
      "step": 13510
    },
    {
      "epoch": 70.41666666666667,
      "grad_norm": 0.43471378087997437,
      "learning_rate": 0.0003666083560207713,
      "loss": 2.0883,
      "step": 13520
    },
    {
      "epoch": 70.46875,
      "grad_norm": 0.5104724168777466,
      "learning_rate": 0.00036642556977609255,
      "loss": 2.0961,
      "step": 13530
    },
    {
      "epoch": 70.52083333333333,
      "grad_norm": 0.45773324370384216,
      "learning_rate": 0.00036624270402260353,
      "loss": 2.1037,
      "step": 13540
    },
    {
      "epoch": 70.57291666666667,
      "grad_norm": 0.3985294997692108,
      "learning_rate": 0.00036605975888518615,
      "loss": 2.1013,
      "step": 13550
    },
    {
      "epoch": 70.625,
      "grad_norm": 0.4345289468765259,
      "learning_rate": 0.00036587673448877634,
      "loss": 2.103,
      "step": 13560
    },
    {
      "epoch": 70.67708333333333,
      "grad_norm": 0.5104824304580688,
      "learning_rate": 0.00036569363095836444,
      "loss": 2.1123,
      "step": 13570
    },
    {
      "epoch": 70.72916666666667,
      "grad_norm": 0.38377827405929565,
      "learning_rate": 0.0003655104484189946,
      "loss": 2.0939,
      "step": 13580
    },
    {
      "epoch": 70.78125,
      "grad_norm": 0.4217436909675598,
      "learning_rate": 0.0003653271869957648,
      "loss": 2.1104,
      "step": 13590
    },
    {
      "epoch": 70.83333333333333,
      "grad_norm": 0.3685440123081207,
      "learning_rate": 0.00036514384681382735,
      "loss": 2.0892,
      "step": 13600
    },
    {
      "epoch": 70.88541666666667,
      "grad_norm": 0.3888832926750183,
      "learning_rate": 0.0003649604279983879,
      "loss": 2.1139,
      "step": 13610
    },
    {
      "epoch": 70.9375,
      "grad_norm": 0.4335167407989502,
      "learning_rate": 0.00036477693067470606,
      "loss": 2.1065,
      "step": 13620
    },
    {
      "epoch": 70.98958333333333,
      "grad_norm": 0.3979606330394745,
      "learning_rate": 0.000364593354968095,
      "loss": 2.1116,
      "step": 13630
    },
    {
      "epoch": 71.0,
      "eval_loss": 1.0821858644485474,
      "eval_runtime": 5.421,
      "eval_samples_per_second": 3662.773,
      "eval_steps_per_second": 14.388,
      "step": 13632
    },
    {
      "epoch": 71.04166666666667,
      "grad_norm": 0.47850409150123596,
      "learning_rate": 0.00036440970100392136,
      "loss": 2.0974,
      "step": 13640
    },
    {
      "epoch": 71.09375,
      "grad_norm": 0.3483605980873108,
      "learning_rate": 0.00036422596890760517,
      "loss": 2.0779,
      "step": 13650
    },
    {
      "epoch": 71.14583333333333,
      "grad_norm": 0.48779481649398804,
      "learning_rate": 0.00036404215880462003,
      "loss": 2.0933,
      "step": 13660
    },
    {
      "epoch": 71.19791666666667,
      "grad_norm": 0.42624399065971375,
      "learning_rate": 0.0003638582708204926,
      "loss": 2.1087,
      "step": 13670
    },
    {
      "epoch": 71.25,
      "grad_norm": 0.532249927520752,
      "learning_rate": 0.00036367430508080277,
      "loss": 2.0939,
      "step": 13680
    },
    {
      "epoch": 71.30208333333333,
      "grad_norm": 0.4323110282421112,
      "learning_rate": 0.0003634902617111837,
      "loss": 2.0936,
      "step": 13690
    },
    {
      "epoch": 71.35416666666667,
      "grad_norm": 0.6799626350402832,
      "learning_rate": 0.0003633061408373214,
      "loss": 2.1067,
      "step": 13700
    },
    {
      "epoch": 71.40625,
      "grad_norm": 0.40470269322395325,
      "learning_rate": 0.00036312194258495474,
      "loss": 2.0861,
      "step": 13710
    },
    {
      "epoch": 71.45833333333333,
      "grad_norm": 0.40928611159324646,
      "learning_rate": 0.0003629376670798757,
      "loss": 2.0919,
      "step": 13720
    },
    {
      "epoch": 71.51041666666667,
      "grad_norm": 0.4500004053115845,
      "learning_rate": 0.0003627533144479287,
      "loss": 2.1024,
      "step": 13730
    },
    {
      "epoch": 71.5625,
      "grad_norm": 0.4554259479045868,
      "learning_rate": 0.00036256888481501104,
      "loss": 2.1115,
      "step": 13740
    },
    {
      "epoch": 71.61458333333333,
      "grad_norm": 0.49754512310028076,
      "learning_rate": 0.00036238437830707256,
      "loss": 2.0979,
      "step": 13750
    },
    {
      "epoch": 71.66666666666667,
      "grad_norm": 0.44561007618904114,
      "learning_rate": 0.0003621997950501156,
      "loss": 2.0947,
      "step": 13760
    },
    {
      "epoch": 71.71875,
      "grad_norm": 0.37605127692222595,
      "learning_rate": 0.0003620151351701948,
      "loss": 2.1028,
      "step": 13770
    },
    {
      "epoch": 71.77083333333333,
      "grad_norm": 0.45964285731315613,
      "learning_rate": 0.0003618303987934174,
      "loss": 2.1043,
      "step": 13780
    },
    {
      "epoch": 71.82291666666667,
      "grad_norm": 0.3708154857158661,
      "learning_rate": 0.00036164558604594263,
      "loss": 2.1116,
      "step": 13790
    },
    {
      "epoch": 71.875,
      "grad_norm": 0.4447469115257263,
      "learning_rate": 0.00036146069705398194,
      "loss": 2.1023,
      "step": 13800
    },
    {
      "epoch": 71.92708333333333,
      "grad_norm": 0.4013253152370453,
      "learning_rate": 0.00036127573194379885,
      "loss": 2.1106,
      "step": 13810
    },
    {
      "epoch": 71.97916666666667,
      "grad_norm": 0.3762213885784149,
      "learning_rate": 0.0003610906908417089,
      "loss": 2.0957,
      "step": 13820
    },
    {
      "epoch": 72.0,
      "eval_loss": 1.0820225477218628,
      "eval_runtime": 5.4225,
      "eval_samples_per_second": 3661.807,
      "eval_steps_per_second": 14.385,
      "step": 13824
    },
    {
      "epoch": 72.03125,
      "grad_norm": 0.37288978695869446,
      "learning_rate": 0.00036090557387407946,
      "loss": 2.0947,
      "step": 13830
    },
    {
      "epoch": 72.08333333333333,
      "grad_norm": 0.4395579695701599,
      "learning_rate": 0.0003607203811673299,
      "loss": 2.1009,
      "step": 13840
    },
    {
      "epoch": 72.13541666666667,
      "grad_norm": 0.3764316439628601,
      "learning_rate": 0.00036053511284793097,
      "loss": 2.0993,
      "step": 13850
    },
    {
      "epoch": 72.1875,
      "grad_norm": 0.39877602458000183,
      "learning_rate": 0.0003603497690424053,
      "loss": 2.1003,
      "step": 13860
    },
    {
      "epoch": 72.23958333333333,
      "grad_norm": 0.3730687201023102,
      "learning_rate": 0.00036016434987732715,
      "loss": 2.0947,
      "step": 13870
    },
    {
      "epoch": 72.29166666666667,
      "grad_norm": 0.3903252184391022,
      "learning_rate": 0.000359978855479322,
      "loss": 2.096,
      "step": 13880
    },
    {
      "epoch": 72.34375,
      "grad_norm": 0.3842245936393738,
      "learning_rate": 0.00035979328597506683,
      "loss": 2.0991,
      "step": 13890
    },
    {
      "epoch": 72.39583333333333,
      "grad_norm": 0.3798533082008362,
      "learning_rate": 0.00035960764149128995,
      "loss": 2.0973,
      "step": 13900
    },
    {
      "epoch": 72.44791666666667,
      "grad_norm": 0.37744495272636414,
      "learning_rate": 0.00035942192215477074,
      "loss": 2.101,
      "step": 13910
    },
    {
      "epoch": 72.5,
      "grad_norm": 0.40195614099502563,
      "learning_rate": 0.0003592361280923399,
      "loss": 2.0931,
      "step": 13920
    },
    {
      "epoch": 72.55208333333333,
      "grad_norm": 0.3670131266117096,
      "learning_rate": 0.000359050259430879,
      "loss": 2.0871,
      "step": 13930
    },
    {
      "epoch": 72.60416666666667,
      "grad_norm": 0.3880813419818878,
      "learning_rate": 0.00035886431629732055,
      "loss": 2.0965,
      "step": 13940
    },
    {
      "epoch": 72.65625,
      "grad_norm": 0.3505576252937317,
      "learning_rate": 0.0003586782988186481,
      "loss": 2.1035,
      "step": 13950
    },
    {
      "epoch": 72.70833333333333,
      "grad_norm": 0.4350850284099579,
      "learning_rate": 0.0003584922071218958,
      "loss": 2.0871,
      "step": 13960
    },
    {
      "epoch": 72.76041666666667,
      "grad_norm": 0.3921986222267151,
      "learning_rate": 0.0003583060413341484,
      "loss": 2.0954,
      "step": 13970
    },
    {
      "epoch": 72.8125,
      "grad_norm": 0.4572739005088806,
      "learning_rate": 0.00035811980158254156,
      "loss": 2.1017,
      "step": 13980
    },
    {
      "epoch": 72.86458333333333,
      "grad_norm": 0.5359016060829163,
      "learning_rate": 0.00035793348799426116,
      "loss": 2.0963,
      "step": 13990
    },
    {
      "epoch": 72.91666666666667,
      "grad_norm": 0.32106125354766846,
      "learning_rate": 0.00035774710069654366,
      "loss": 2.1043,
      "step": 14000
    },
    {
      "epoch": 72.96875,
      "grad_norm": 0.4050002098083496,
      "learning_rate": 0.00035756063981667575,
      "loss": 2.1088,
      "step": 14010
    },
    {
      "epoch": 73.0,
      "eval_loss": 1.0830693244934082,
      "eval_runtime": 5.5055,
      "eval_samples_per_second": 3606.594,
      "eval_steps_per_second": 14.168,
      "step": 14016
    },
    {
      "epoch": 73.02083333333333,
      "grad_norm": 0.4261767864227295,
      "learning_rate": 0.0003573741054819945,
      "loss": 2.0966,
      "step": 14020
    },
    {
      "epoch": 73.07291666666667,
      "grad_norm": 0.4525618255138397,
      "learning_rate": 0.00035718749781988695,
      "loss": 2.1011,
      "step": 14030
    },
    {
      "epoch": 73.125,
      "grad_norm": 0.45290470123291016,
      "learning_rate": 0.00035700081695779054,
      "loss": 2.1008,
      "step": 14040
    },
    {
      "epoch": 73.17708333333333,
      "grad_norm": 0.5135001540184021,
      "learning_rate": 0.0003568140630231923,
      "loss": 2.0919,
      "step": 14050
    },
    {
      "epoch": 73.22916666666667,
      "grad_norm": 0.434352308511734,
      "learning_rate": 0.00035662723614362954,
      "loss": 2.0875,
      "step": 14060
    },
    {
      "epoch": 73.28125,
      "grad_norm": 0.39837005734443665,
      "learning_rate": 0.000356440336446689,
      "loss": 2.0866,
      "step": 14070
    },
    {
      "epoch": 73.33333333333333,
      "grad_norm": 0.40656203031539917,
      "learning_rate": 0.0003562533640600075,
      "loss": 2.0871,
      "step": 14080
    },
    {
      "epoch": 73.38541666666667,
      "grad_norm": 0.5061772465705872,
      "learning_rate": 0.0003560663191112714,
      "loss": 2.0941,
      "step": 14090
    },
    {
      "epoch": 73.4375,
      "grad_norm": 0.42046692967414856,
      "learning_rate": 0.0003558792017282164,
      "loss": 2.0879,
      "step": 14100
    },
    {
      "epoch": 73.48958333333333,
      "grad_norm": 0.41076353192329407,
      "learning_rate": 0.000355692012038628,
      "loss": 2.1096,
      "step": 14110
    },
    {
      "epoch": 73.54166666666667,
      "grad_norm": 0.35817772150039673,
      "learning_rate": 0.0003555047501703408,
      "loss": 2.0912,
      "step": 14120
    },
    {
      "epoch": 73.59375,
      "grad_norm": 0.5291614532470703,
      "learning_rate": 0.0003553174162512389,
      "loss": 2.1029,
      "step": 14130
    },
    {
      "epoch": 73.64583333333333,
      "grad_norm": 0.4283437728881836,
      "learning_rate": 0.00035513001040925543,
      "loss": 2.0955,
      "step": 14140
    },
    {
      "epoch": 73.69791666666667,
      "grad_norm": 0.6038817763328552,
      "learning_rate": 0.00035494253277237273,
      "loss": 2.105,
      "step": 14150
    },
    {
      "epoch": 73.75,
      "grad_norm": 0.38056427240371704,
      "learning_rate": 0.00035475498346862217,
      "loss": 2.0835,
      "step": 14160
    },
    {
      "epoch": 73.80208333333333,
      "grad_norm": 0.3860711455345154,
      "learning_rate": 0.0003545673626260841,
      "loss": 2.0844,
      "step": 14170
    },
    {
      "epoch": 73.85416666666667,
      "grad_norm": 0.4441365599632263,
      "learning_rate": 0.00035437967037288756,
      "loss": 2.1104,
      "step": 14180
    },
    {
      "epoch": 73.90625,
      "grad_norm": 0.5051261186599731,
      "learning_rate": 0.0003541919068372106,
      "loss": 2.0972,
      "step": 14190
    },
    {
      "epoch": 73.95833333333333,
      "grad_norm": 0.38280120491981506,
      "learning_rate": 0.0003540040721472798,
      "loss": 2.1076,
      "step": 14200
    },
    {
      "epoch": 74.0,
      "eval_loss": 1.0825220346450806,
      "eval_runtime": 5.4697,
      "eval_samples_per_second": 3630.183,
      "eval_steps_per_second": 14.26,
      "step": 14208
    },
    {
      "epoch": 74.01041666666667,
      "grad_norm": 0.4117651581764221,
      "learning_rate": 0.0003538161664313703,
      "loss": 2.0961,
      "step": 14210
    },
    {
      "epoch": 74.0625,
      "grad_norm": 0.42972424626350403,
      "learning_rate": 0.00035362818981780577,
      "loss": 2.0802,
      "step": 14220
    },
    {
      "epoch": 74.11458333333333,
      "grad_norm": 0.45262229442596436,
      "learning_rate": 0.0003534401424349584,
      "loss": 2.0708,
      "step": 14230
    },
    {
      "epoch": 74.16666666666667,
      "grad_norm": 0.3993191421031952,
      "learning_rate": 0.0003532520244112487,
      "loss": 2.1017,
      "step": 14240
    },
    {
      "epoch": 74.21875,
      "grad_norm": 0.4609580934047699,
      "learning_rate": 0.0003530638358751452,
      "loss": 2.0982,
      "step": 14250
    },
    {
      "epoch": 74.27083333333333,
      "grad_norm": 0.5316498279571533,
      "learning_rate": 0.0003528755769551649,
      "loss": 2.0903,
      "step": 14260
    },
    {
      "epoch": 74.32291666666667,
      "grad_norm": 0.38869422674179077,
      "learning_rate": 0.00035268724777987254,
      "loss": 2.0903,
      "step": 14270
    },
    {
      "epoch": 74.375,
      "grad_norm": 0.4226943552494049,
      "learning_rate": 0.0003524988484778812,
      "loss": 2.0866,
      "step": 14280
    },
    {
      "epoch": 74.42708333333333,
      "grad_norm": 0.4018516540527344,
      "learning_rate": 0.0003523103791778515,
      "loss": 2.0905,
      "step": 14290
    },
    {
      "epoch": 74.47916666666667,
      "grad_norm": 0.4482263922691345,
      "learning_rate": 0.00035212184000849207,
      "loss": 2.0956,
      "step": 14300
    },
    {
      "epoch": 74.53125,
      "grad_norm": 0.4107359051704407,
      "learning_rate": 0.0003519332310985592,
      "loss": 2.1003,
      "step": 14310
    },
    {
      "epoch": 74.58333333333333,
      "grad_norm": 0.43264278769493103,
      "learning_rate": 0.00035174455257685686,
      "loss": 2.0843,
      "step": 14320
    },
    {
      "epoch": 74.63541666666667,
      "grad_norm": 0.43627411127090454,
      "learning_rate": 0.0003515558045722364,
      "loss": 2.0932,
      "step": 14330
    },
    {
      "epoch": 74.6875,
      "grad_norm": 0.46326732635498047,
      "learning_rate": 0.0003513669872135968,
      "loss": 2.0913,
      "step": 14340
    },
    {
      "epoch": 74.73958333333333,
      "grad_norm": 0.38469284772872925,
      "learning_rate": 0.0003511781006298844,
      "loss": 2.1024,
      "step": 14350
    },
    {
      "epoch": 74.79166666666667,
      "grad_norm": 0.41141194105148315,
      "learning_rate": 0.0003509891449500927,
      "loss": 2.1006,
      "step": 14360
    },
    {
      "epoch": 74.84375,
      "grad_norm": 0.3418225646018982,
      "learning_rate": 0.00035080012030326243,
      "loss": 2.0974,
      "step": 14370
    },
    {
      "epoch": 74.89583333333333,
      "grad_norm": 0.3836010694503784,
      "learning_rate": 0.0003506110268184814,
      "loss": 2.0943,
      "step": 14380
    },
    {
      "epoch": 74.94791666666667,
      "grad_norm": 0.37790536880493164,
      "learning_rate": 0.00035042186462488445,
      "loss": 2.0916,
      "step": 14390
    },
    {
      "epoch": 75.0,
      "grad_norm": 0.41021156311035156,
      "learning_rate": 0.0003502326338516534,
      "loss": 2.1084,
      "step": 14400
    },
    {
      "epoch": 75.0,
      "eval_loss": 1.0824182033538818,
      "eval_runtime": 5.4445,
      "eval_samples_per_second": 3646.988,
      "eval_steps_per_second": 14.326,
      "step": 14400
    },
    {
      "epoch": 75.0,
      "step": 14400,
      "total_flos": 1.99162893303808e+16,
      "train_loss": 2.3369069291485682,
      "train_runtime": 3907.806,
      "train_samples_per_second": 5029.318,
      "train_steps_per_second": 9.826
    }
  ],
  "logging_steps": 10,
  "max_steps": 38400,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 200,
  "save_steps": 1000,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 20,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 20
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.99162893303808e+16,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
