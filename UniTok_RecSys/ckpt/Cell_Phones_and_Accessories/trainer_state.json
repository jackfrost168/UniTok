{
  "best_metric": 0.978909432888031,
  "best_model_checkpoint": "./ckpt/Cell_Phones_and_Accessories/checkpoint-11935",
  "epoch": 75.0,
  "eval_steps": 1000,
  "global_step": 16275,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.046189376443418015,
      "grad_norm": 18.949668884277344,
      "learning_rate": 1.1574074074074073e-05,
      "loss": 21.8521,
      "step": 10
    },
    {
      "epoch": 0.09237875288683603,
      "grad_norm": 11.986133575439453,
      "learning_rate": 2.3148148148148147e-05,
      "loss": 19.8442,
      "step": 20
    },
    {
      "epoch": 0.13856812933025403,
      "grad_norm": 6.295064449310303,
      "learning_rate": 3.472222222222222e-05,
      "loss": 17.1452,
      "step": 30
    },
    {
      "epoch": 0.18475750577367206,
      "grad_norm": 4.087620735168457,
      "learning_rate": 4.6296296296296294e-05,
      "loss": 15.1074,
      "step": 40
    },
    {
      "epoch": 0.23094688221709006,
      "grad_norm": 4.129591941833496,
      "learning_rate": 5.787037037037037e-05,
      "loss": 13.3508,
      "step": 50
    },
    {
      "epoch": 0.27713625866050806,
      "grad_norm": 3.4117772579193115,
      "learning_rate": 6.944444444444444e-05,
      "loss": 11.3064,
      "step": 60
    },
    {
      "epoch": 0.3233256351039261,
      "grad_norm": 2.2866153717041016,
      "learning_rate": 8.101851851851852e-05,
      "loss": 9.3746,
      "step": 70
    },
    {
      "epoch": 0.3695150115473441,
      "grad_norm": 1.6623927354812622,
      "learning_rate": 9.259259259259259e-05,
      "loss": 8.0128,
      "step": 80
    },
    {
      "epoch": 0.41570438799076215,
      "grad_norm": 1.4242666959762573,
      "learning_rate": 0.00010416666666666667,
      "loss": 7.1407,
      "step": 90
    },
    {
      "epoch": 0.4618937644341801,
      "grad_norm": 1.2369107007980347,
      "learning_rate": 0.00011574074074074075,
      "loss": 6.5021,
      "step": 100
    },
    {
      "epoch": 0.5080831408775982,
      "grad_norm": 1.210528016090393,
      "learning_rate": 0.00012731481481481483,
      "loss": 6.1085,
      "step": 110
    },
    {
      "epoch": 0.5542725173210161,
      "grad_norm": 1.087532877922058,
      "learning_rate": 0.0001388888888888889,
      "loss": 5.805,
      "step": 120
    },
    {
      "epoch": 0.6004618937644342,
      "grad_norm": 0.9817415475845337,
      "learning_rate": 0.00015046296296296297,
      "loss": 5.6807,
      "step": 130
    },
    {
      "epoch": 0.6466512702078522,
      "grad_norm": 0.9634408354759216,
      "learning_rate": 0.00016203703703703703,
      "loss": 5.5009,
      "step": 140
    },
    {
      "epoch": 0.6928406466512702,
      "grad_norm": 0.8985158205032349,
      "learning_rate": 0.00017361111111111112,
      "loss": 5.4201,
      "step": 150
    },
    {
      "epoch": 0.7390300230946882,
      "grad_norm": 0.8437249660491943,
      "learning_rate": 0.00018518518518518518,
      "loss": 5.3051,
      "step": 160
    },
    {
      "epoch": 0.7852193995381063,
      "grad_norm": 0.880966067314148,
      "learning_rate": 0.0001967592592592593,
      "loss": 5.2381,
      "step": 170
    },
    {
      "epoch": 0.8314087759815243,
      "grad_norm": 0.7968400120735168,
      "learning_rate": 0.00020833333333333335,
      "loss": 5.1844,
      "step": 180
    },
    {
      "epoch": 0.8775981524249422,
      "grad_norm": 0.7690421342849731,
      "learning_rate": 0.0002199074074074074,
      "loss": 5.088,
      "step": 190
    },
    {
      "epoch": 0.9237875288683602,
      "grad_norm": 0.7569770812988281,
      "learning_rate": 0.0002314814814814815,
      "loss": 4.9904,
      "step": 200
    },
    {
      "epoch": 0.9699769053117783,
      "grad_norm": 0.7152190208435059,
      "learning_rate": 0.00024305555555555555,
      "loss": 4.9323,
      "step": 210
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.2508015632629395,
      "eval_runtime": 7.5584,
      "eval_samples_per_second": 3688.489,
      "eval_steps_per_second": 14.421,
      "step": 217
    },
    {
      "epoch": 1.0138568129330254,
      "grad_norm": 0.6993396282196045,
      "learning_rate": 0.00025462962962962966,
      "loss": 4.5995,
      "step": 220
    },
    {
      "epoch": 1.0600461893764435,
      "grad_norm": 1.1365913152694702,
      "learning_rate": 0.0002662037037037037,
      "loss": 4.8211,
      "step": 230
    },
    {
      "epoch": 1.1062355658198615,
      "grad_norm": 0.7028582096099854,
      "learning_rate": 0.0002777777777777778,
      "loss": 4.7516,
      "step": 240
    },
    {
      "epoch": 1.1524249422632795,
      "grad_norm": 0.6802138090133667,
      "learning_rate": 0.0002893518518518519,
      "loss": 4.6596,
      "step": 250
    },
    {
      "epoch": 1.1986143187066975,
      "grad_norm": 0.6184759140014648,
      "learning_rate": 0.00030092592592592595,
      "loss": 4.6066,
      "step": 260
    },
    {
      "epoch": 1.2448036951501154,
      "grad_norm": 0.8491776585578918,
      "learning_rate": 0.0003125,
      "loss": 4.5636,
      "step": 270
    },
    {
      "epoch": 1.2909930715935336,
      "grad_norm": 0.5790955424308777,
      "learning_rate": 0.00032407407407407406,
      "loss": 4.4651,
      "step": 280
    },
    {
      "epoch": 1.3371824480369514,
      "grad_norm": 0.559124767780304,
      "learning_rate": 0.0003356481481481481,
      "loss": 4.4661,
      "step": 290
    },
    {
      "epoch": 1.3833718244803694,
      "grad_norm": 0.5518678426742554,
      "learning_rate": 0.00034722222222222224,
      "loss": 4.3836,
      "step": 300
    },
    {
      "epoch": 1.4295612009237875,
      "grad_norm": 0.659106433391571,
      "learning_rate": 0.0003587962962962963,
      "loss": 4.3174,
      "step": 310
    },
    {
      "epoch": 1.4757505773672055,
      "grad_norm": 0.5187242031097412,
      "learning_rate": 0.00037037037037037035,
      "loss": 4.2414,
      "step": 320
    },
    {
      "epoch": 1.5219399538106235,
      "grad_norm": 0.5385774970054626,
      "learning_rate": 0.0003819444444444444,
      "loss": 4.1932,
      "step": 330
    },
    {
      "epoch": 1.5681293302540416,
      "grad_norm": 0.7366417050361633,
      "learning_rate": 0.0003935185185185186,
      "loss": 4.1451,
      "step": 340
    },
    {
      "epoch": 1.6143187066974596,
      "grad_norm": 0.5149598121643066,
      "learning_rate": 0.00040509259259259264,
      "loss": 4.0794,
      "step": 350
    },
    {
      "epoch": 1.6605080831408776,
      "grad_norm": 0.5729170441627502,
      "learning_rate": 0.0004166666666666667,
      "loss": 4.0157,
      "step": 360
    },
    {
      "epoch": 1.7066974595842956,
      "grad_norm": 0.5113710165023804,
      "learning_rate": 0.00042824074074074075,
      "loss": 3.9463,
      "step": 370
    },
    {
      "epoch": 1.7528868360277137,
      "grad_norm": 0.4329143166542053,
      "learning_rate": 0.0004398148148148148,
      "loss": 3.8749,
      "step": 380
    },
    {
      "epoch": 1.7990762124711317,
      "grad_norm": 0.48118656873703003,
      "learning_rate": 0.0004513888888888889,
      "loss": 3.8161,
      "step": 390
    },
    {
      "epoch": 1.8452655889145495,
      "grad_norm": 0.4551994800567627,
      "learning_rate": 0.000462962962962963,
      "loss": 3.7521,
      "step": 400
    },
    {
      "epoch": 1.8914549653579678,
      "grad_norm": 0.4066595733165741,
      "learning_rate": 0.00047453703703703704,
      "loss": 3.6827,
      "step": 410
    },
    {
      "epoch": 1.9376443418013856,
      "grad_norm": 0.4655304551124573,
      "learning_rate": 0.0004861111111111111,
      "loss": 3.652,
      "step": 420
    },
    {
      "epoch": 1.9838337182448038,
      "grad_norm": 0.46310147643089294,
      "learning_rate": 0.0004976851851851852,
      "loss": 3.5573,
      "step": 430
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.6590077877044678,
      "eval_runtime": 7.2913,
      "eval_samples_per_second": 3823.602,
      "eval_steps_per_second": 14.949,
      "step": 434
    },
    {
      "epoch": 2.027713625866051,
      "grad_norm": 0.37357208132743835,
      "learning_rate": 0.000499999956833003,
      "loss": 3.3215,
      "step": 440
    },
    {
      "epoch": 2.0739030023094687,
      "grad_norm": 0.35624104738235474,
      "learning_rate": 0.0004999997814671033,
      "loss": 3.4654,
      "step": 450
    },
    {
      "epoch": 2.120092378752887,
      "grad_norm": 0.35295459628105164,
      "learning_rate": 0.000499999471204458,
      "loss": 3.399,
      "step": 460
    },
    {
      "epoch": 2.1662817551963047,
      "grad_norm": 0.5330461263656616,
      "learning_rate": 0.0004999990260452348,
      "loss": 3.3747,
      "step": 470
    },
    {
      "epoch": 2.212471131639723,
      "grad_norm": 0.38171622157096863,
      "learning_rate": 0.0004999984459896734,
      "loss": 3.3061,
      "step": 480
    },
    {
      "epoch": 2.258660508083141,
      "grad_norm": 0.4329667091369629,
      "learning_rate": 0.0004999977310380874,
      "loss": 3.2357,
      "step": 490
    },
    {
      "epoch": 2.304849884526559,
      "grad_norm": 0.3199305534362793,
      "learning_rate": 0.0004999968811908622,
      "loss": 3.194,
      "step": 500
    },
    {
      "epoch": 2.351039260969977,
      "grad_norm": 0.2999643385410309,
      "learning_rate": 0.0004999958964484564,
      "loss": 3.1568,
      "step": 510
    },
    {
      "epoch": 2.397228637413395,
      "grad_norm": 0.319144606590271,
      "learning_rate": 0.0004999947768114015,
      "loss": 3.0824,
      "step": 520
    },
    {
      "epoch": 2.443418013856813,
      "grad_norm": 0.3420681655406952,
      "learning_rate": 0.0004999935222803015,
      "loss": 3.0247,
      "step": 530
    },
    {
      "epoch": 2.4896073903002307,
      "grad_norm": 0.3118205666542053,
      "learning_rate": 0.0004999921328558333,
      "loss": 3.0105,
      "step": 540
    },
    {
      "epoch": 2.535796766743649,
      "grad_norm": 0.28177258372306824,
      "learning_rate": 0.0004999906085387467,
      "loss": 2.9736,
      "step": 550
    },
    {
      "epoch": 2.581986143187067,
      "grad_norm": 0.3085777759552002,
      "learning_rate": 0.0004999889493298643,
      "loss": 2.9056,
      "step": 560
    },
    {
      "epoch": 2.628175519630485,
      "grad_norm": 0.2871789336204529,
      "learning_rate": 0.0004999871552300812,
      "loss": 2.8937,
      "step": 570
    },
    {
      "epoch": 2.674364896073903,
      "grad_norm": 0.2619120180606842,
      "learning_rate": 0.0004999852262403656,
      "loss": 2.8602,
      "step": 580
    },
    {
      "epoch": 2.720554272517321,
      "grad_norm": 0.2661423683166504,
      "learning_rate": 0.0004999831623617583,
      "loss": 2.7997,
      "step": 590
    },
    {
      "epoch": 2.766743648960739,
      "grad_norm": 0.2612019181251526,
      "learning_rate": 0.0004999809635953729,
      "loss": 2.7742,
      "step": 600
    },
    {
      "epoch": 2.812933025404157,
      "grad_norm": 0.26073387265205383,
      "learning_rate": 0.000499978629942396,
      "loss": 2.7514,
      "step": 610
    },
    {
      "epoch": 2.859122401847575,
      "grad_norm": 0.23318953812122345,
      "learning_rate": 0.0004999761614040867,
      "loss": 2.7231,
      "step": 620
    },
    {
      "epoch": 2.905311778290993,
      "grad_norm": 0.23969131708145142,
      "learning_rate": 0.0004999735579817769,
      "loss": 2.6995,
      "step": 630
    },
    {
      "epoch": 2.951501154734411,
      "grad_norm": 0.30318713188171387,
      "learning_rate": 0.0004999708196768715,
      "loss": 2.6561,
      "step": 640
    },
    {
      "epoch": 2.9976905311778292,
      "grad_norm": 0.2549505829811096,
      "learning_rate": 0.000499967946490848,
      "loss": 2.6362,
      "step": 650
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.2409822940826416,
      "eval_runtime": 7.2767,
      "eval_samples_per_second": 3831.261,
      "eval_steps_per_second": 14.979,
      "step": 651
    },
    {
      "epoch": 3.0415704387990763,
      "grad_norm": 0.2574315071105957,
      "learning_rate": 0.0004999649384252568,
      "loss": 2.493,
      "step": 660
    },
    {
      "epoch": 3.087759815242494,
      "grad_norm": 0.21019817888736725,
      "learning_rate": 0.0004999617954817209,
      "loss": 2.5721,
      "step": 670
    },
    {
      "epoch": 3.1339491916859123,
      "grad_norm": 0.22613364458084106,
      "learning_rate": 0.0004999585176619363,
      "loss": 2.5463,
      "step": 680
    },
    {
      "epoch": 3.18013856812933,
      "grad_norm": 0.24564863741397858,
      "learning_rate": 0.0004999551049676716,
      "loss": 2.5404,
      "step": 690
    },
    {
      "epoch": 3.2263279445727484,
      "grad_norm": 0.20169652998447418,
      "learning_rate": 0.0004999515574007682,
      "loss": 2.516,
      "step": 700
    },
    {
      "epoch": 3.272517321016166,
      "grad_norm": 0.20627938210964203,
      "learning_rate": 0.0004999478749631405,
      "loss": 2.4898,
      "step": 710
    },
    {
      "epoch": 3.3187066974595845,
      "grad_norm": 0.1993071585893631,
      "learning_rate": 0.0004999440576567755,
      "loss": 2.4655,
      "step": 720
    },
    {
      "epoch": 3.3648960739030023,
      "grad_norm": 0.19136591255664825,
      "learning_rate": 0.0004999401054837327,
      "loss": 2.4407,
      "step": 730
    },
    {
      "epoch": 3.4110854503464205,
      "grad_norm": 0.20162035524845123,
      "learning_rate": 0.0004999360184461449,
      "loss": 2.4489,
      "step": 740
    },
    {
      "epoch": 3.4572748267898383,
      "grad_norm": 0.38227763772010803,
      "learning_rate": 0.0004999317965462173,
      "loss": 2.4242,
      "step": 750
    },
    {
      "epoch": 3.503464203233256,
      "grad_norm": 0.1988171637058258,
      "learning_rate": 0.000499927439786228,
      "loss": 2.4073,
      "step": 760
    },
    {
      "epoch": 3.5496535796766744,
      "grad_norm": 0.25771334767341614,
      "learning_rate": 0.0004999229481685278,
      "loss": 2.4046,
      "step": 770
    },
    {
      "epoch": 3.5958429561200926,
      "grad_norm": 0.1795966923236847,
      "learning_rate": 0.0004999183216955406,
      "loss": 2.3999,
      "step": 780
    },
    {
      "epoch": 3.6420323325635104,
      "grad_norm": 0.16360419988632202,
      "learning_rate": 0.0004999135603697624,
      "loss": 2.3769,
      "step": 790
    },
    {
      "epoch": 3.6882217090069283,
      "grad_norm": 0.1881474256515503,
      "learning_rate": 0.0004999086641937625,
      "loss": 2.3539,
      "step": 800
    },
    {
      "epoch": 3.7344110854503465,
      "grad_norm": 0.1813766062259674,
      "learning_rate": 0.0004999036331701828,
      "loss": 2.347,
      "step": 810
    },
    {
      "epoch": 3.7806004618937643,
      "grad_norm": 0.3489852845668793,
      "learning_rate": 0.000499898467301738,
      "loss": 2.339,
      "step": 820
    },
    {
      "epoch": 3.8267898383371826,
      "grad_norm": 0.3373872935771942,
      "learning_rate": 0.0004998931665912157,
      "loss": 2.3366,
      "step": 830
    },
    {
      "epoch": 3.8729792147806004,
      "grad_norm": 0.16337142884731293,
      "learning_rate": 0.0004998877310414759,
      "loss": 2.3098,
      "step": 840
    },
    {
      "epoch": 3.9191685912240186,
      "grad_norm": 0.18238118290901184,
      "learning_rate": 0.0004998821606554515,
      "loss": 2.2961,
      "step": 850
    },
    {
      "epoch": 3.9653579676674364,
      "grad_norm": 0.17884233593940735,
      "learning_rate": 0.0004998764554361484,
      "loss": 2.3227,
      "step": 860
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.094608187675476,
      "eval_runtime": 7.333,
      "eval_samples_per_second": 3801.855,
      "eval_steps_per_second": 14.864,
      "step": 868
    },
    {
      "epoch": 4.009237875288684,
      "grad_norm": 0.18042437732219696,
      "learning_rate": 0.000499870615386645,
      "loss": 2.1756,
      "step": 870
    },
    {
      "epoch": 4.055427251732102,
      "grad_norm": 0.16799664497375488,
      "learning_rate": 0.0004998646405100925,
      "loss": 2.2799,
      "step": 880
    },
    {
      "epoch": 4.1016166281755195,
      "grad_norm": 0.18327710032463074,
      "learning_rate": 0.0004998585308097148,
      "loss": 2.2699,
      "step": 890
    },
    {
      "epoch": 4.147806004618937,
      "grad_norm": 0.15331751108169556,
      "learning_rate": 0.0004998522862888087,
      "loss": 2.2656,
      "step": 900
    },
    {
      "epoch": 4.193995381062356,
      "grad_norm": 0.15422259271144867,
      "learning_rate": 0.0004998459069507437,
      "loss": 2.2645,
      "step": 910
    },
    {
      "epoch": 4.240184757505774,
      "grad_norm": 0.15107561647891998,
      "learning_rate": 0.0004998393927989619,
      "loss": 2.247,
      "step": 920
    },
    {
      "epoch": 4.286374133949192,
      "grad_norm": 0.15323539078235626,
      "learning_rate": 0.0004998327438369783,
      "loss": 2.2392,
      "step": 930
    },
    {
      "epoch": 4.3325635103926095,
      "grad_norm": 0.18073049187660217,
      "learning_rate": 0.0004998259600683807,
      "loss": 2.2408,
      "step": 940
    },
    {
      "epoch": 4.378752886836027,
      "grad_norm": 0.15539498627185822,
      "learning_rate": 0.0004998190414968293,
      "loss": 2.2278,
      "step": 950
    },
    {
      "epoch": 4.424942263279446,
      "grad_norm": 0.15543067455291748,
      "learning_rate": 0.0004998119881260575,
      "loss": 2.2386,
      "step": 960
    },
    {
      "epoch": 4.471131639722864,
      "grad_norm": 0.1575000286102295,
      "learning_rate": 0.0004998047999598712,
      "loss": 2.2182,
      "step": 970
    },
    {
      "epoch": 4.517321016166282,
      "grad_norm": 0.146613210439682,
      "learning_rate": 0.0004997974770021488,
      "loss": 2.2097,
      "step": 980
    },
    {
      "epoch": 4.5635103926097,
      "grad_norm": 0.1537993997335434,
      "learning_rate": 0.000499790019256842,
      "loss": 2.2305,
      "step": 990
    },
    {
      "epoch": 4.609699769053118,
      "grad_norm": 0.2158394455909729,
      "learning_rate": 0.0004997824267279747,
      "loss": 2.2202,
      "step": 1000
    },
    {
      "epoch": 4.655889145496536,
      "grad_norm": 0.1633118838071823,
      "learning_rate": 0.0004997746994196438,
      "loss": 2.1877,
      "step": 1010
    },
    {
      "epoch": 4.702078521939954,
      "grad_norm": 0.18178105354309082,
      "learning_rate": 0.0004997668373360188,
      "loss": 2.2018,
      "step": 1020
    },
    {
      "epoch": 4.7482678983833715,
      "grad_norm": 0.1337715983390808,
      "learning_rate": 0.0004997588404813421,
      "loss": 2.2166,
      "step": 1030
    },
    {
      "epoch": 4.79445727482679,
      "grad_norm": 0.8254597783088684,
      "learning_rate": 0.0004997507088599285,
      "loss": 2.2047,
      "step": 1040
    },
    {
      "epoch": 4.840646651270208,
      "grad_norm": 0.1309298723936081,
      "learning_rate": 0.000499742442476166,
      "loss": 2.1796,
      "step": 1050
    },
    {
      "epoch": 4.886836027713626,
      "grad_norm": 0.1343301385641098,
      "learning_rate": 0.0004997340413345149,
      "loss": 2.1845,
      "step": 1060
    },
    {
      "epoch": 4.933025404157044,
      "grad_norm": 0.14169993996620178,
      "learning_rate": 0.0004997255054395082,
      "loss": 2.1899,
      "step": 1070
    },
    {
      "epoch": 4.979214780600461,
      "grad_norm": 0.14370973408222198,
      "learning_rate": 0.000499716834795752,
      "loss": 2.1907,
      "step": 1080
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.0452070236206055,
      "eval_runtime": 7.3169,
      "eval_samples_per_second": 3810.196,
      "eval_steps_per_second": 14.897,
      "step": 1085
    },
    {
      "epoch": 5.023094688221709,
      "grad_norm": 0.1546740084886551,
      "learning_rate": 0.0004997080294079247,
      "loss": 2.0644,
      "step": 1090
    },
    {
      "epoch": 5.069284064665127,
      "grad_norm": 0.1729416698217392,
      "learning_rate": 0.0004996990892807778,
      "loss": 2.1698,
      "step": 1100
    },
    {
      "epoch": 5.115473441108545,
      "grad_norm": 0.18767359852790833,
      "learning_rate": 0.000499690014419135,
      "loss": 2.1736,
      "step": 1110
    },
    {
      "epoch": 5.161662817551963,
      "grad_norm": 0.15460020303726196,
      "learning_rate": 0.0004996808048278931,
      "loss": 2.1583,
      "step": 1120
    },
    {
      "epoch": 5.2078521939953815,
      "grad_norm": 0.12611287832260132,
      "learning_rate": 0.0004996714605120216,
      "loss": 2.174,
      "step": 1130
    },
    {
      "epoch": 5.254041570438799,
      "grad_norm": 0.16908426582813263,
      "learning_rate": 0.0004996619814765623,
      "loss": 2.1559,
      "step": 1140
    },
    {
      "epoch": 5.300230946882217,
      "grad_norm": 0.15483281016349792,
      "learning_rate": 0.0004996523677266302,
      "loss": 2.1731,
      "step": 1150
    },
    {
      "epoch": 5.346420323325635,
      "grad_norm": 0.17213888466358185,
      "learning_rate": 0.0004996426192674129,
      "loss": 2.1661,
      "step": 1160
    },
    {
      "epoch": 5.392609699769054,
      "grad_norm": 0.35451218485832214,
      "learning_rate": 0.00049963273610417,
      "loss": 2.1724,
      "step": 1170
    },
    {
      "epoch": 5.438799076212471,
      "grad_norm": 0.15578323602676392,
      "learning_rate": 0.0004996227182422349,
      "loss": 2.1592,
      "step": 1180
    },
    {
      "epoch": 5.484988452655889,
      "grad_norm": 0.14016097784042358,
      "learning_rate": 0.0004996125656870128,
      "loss": 2.1472,
      "step": 1190
    },
    {
      "epoch": 5.531177829099307,
      "grad_norm": 0.1549132913351059,
      "learning_rate": 0.000499602278443982,
      "loss": 2.1604,
      "step": 1200
    },
    {
      "epoch": 5.577367205542725,
      "grad_norm": 0.160767063498497,
      "learning_rate": 0.0004995918565186933,
      "loss": 2.1456,
      "step": 1210
    },
    {
      "epoch": 5.6235565819861435,
      "grad_norm": 0.15146981179714203,
      "learning_rate": 0.0004995812999167704,
      "loss": 2.1425,
      "step": 1220
    },
    {
      "epoch": 5.669745958429561,
      "grad_norm": 0.1419612318277359,
      "learning_rate": 0.0004995706086439092,
      "loss": 2.1324,
      "step": 1230
    },
    {
      "epoch": 5.715935334872979,
      "grad_norm": 0.46479785442352295,
      "learning_rate": 0.000499559782705879,
      "loss": 2.1421,
      "step": 1240
    },
    {
      "epoch": 5.762124711316397,
      "grad_norm": 0.1413280963897705,
      "learning_rate": 0.000499548822108521,
      "loss": 2.1362,
      "step": 1250
    },
    {
      "epoch": 5.808314087759816,
      "grad_norm": 0.15755294263362885,
      "learning_rate": 0.0004995377268577494,
      "loss": 2.125,
      "step": 1260
    },
    {
      "epoch": 5.854503464203233,
      "grad_norm": 0.7657623291015625,
      "learning_rate": 0.0004995264969595513,
      "loss": 2.1292,
      "step": 1270
    },
    {
      "epoch": 5.900692840646651,
      "grad_norm": 0.18630552291870117,
      "learning_rate": 0.0004995151324199861,
      "loss": 2.1383,
      "step": 1280
    },
    {
      "epoch": 5.946882217090069,
      "grad_norm": 0.2536488473415375,
      "learning_rate": 0.0004995036332451859,
      "loss": 2.1332,
      "step": 1290
    },
    {
      "epoch": 5.993071593533488,
      "grad_norm": 0.15322940051555634,
      "learning_rate": 0.0004994919994413554,
      "loss": 2.1292,
      "step": 1300
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.0281740427017212,
      "eval_runtime": 7.3153,
      "eval_samples_per_second": 3811.037,
      "eval_steps_per_second": 14.9,
      "step": 1302
    },
    {
      "epoch": 6.036951501154735,
      "grad_norm": 0.14765578508377075,
      "learning_rate": 0.0004994802310147725,
      "loss": 2.0198,
      "step": 1310
    },
    {
      "epoch": 6.083140877598153,
      "grad_norm": 0.22585375607013702,
      "learning_rate": 0.0004994683279717868,
      "loss": 2.1303,
      "step": 1320
    },
    {
      "epoch": 6.12933025404157,
      "grad_norm": 0.16258174180984497,
      "learning_rate": 0.0004994562903188213,
      "loss": 2.1133,
      "step": 1330
    },
    {
      "epoch": 6.175519630484988,
      "grad_norm": 0.2918238341808319,
      "learning_rate": 0.0004994441180623712,
      "loss": 2.131,
      "step": 1340
    },
    {
      "epoch": 6.221709006928407,
      "grad_norm": 0.13356946408748627,
      "learning_rate": 0.0004994318112090048,
      "loss": 2.1245,
      "step": 1350
    },
    {
      "epoch": 6.267898383371825,
      "grad_norm": 0.14072543382644653,
      "learning_rate": 0.0004994193697653624,
      "loss": 2.1258,
      "step": 1360
    },
    {
      "epoch": 6.3140877598152425,
      "grad_norm": 0.16130372881889343,
      "learning_rate": 0.0004994067937381574,
      "loss": 2.1121,
      "step": 1370
    },
    {
      "epoch": 6.36027713625866,
      "grad_norm": 0.1632699817419052,
      "learning_rate": 0.0004993940831341757,
      "loss": 2.1207,
      "step": 1380
    },
    {
      "epoch": 6.406466512702078,
      "grad_norm": 0.1513611078262329,
      "learning_rate": 0.0004993812379602755,
      "loss": 2.1232,
      "step": 1390
    },
    {
      "epoch": 6.452655889145497,
      "grad_norm": 0.12138590216636658,
      "learning_rate": 0.0004993682582233883,
      "loss": 2.1107,
      "step": 1400
    },
    {
      "epoch": 6.498845265588915,
      "grad_norm": 0.14890873432159424,
      "learning_rate": 0.0004993551439305176,
      "loss": 2.1088,
      "step": 1410
    },
    {
      "epoch": 6.545034642032332,
      "grad_norm": 0.13935159146785736,
      "learning_rate": 0.0004993418950887397,
      "loss": 2.1118,
      "step": 1420
    },
    {
      "epoch": 6.59122401847575,
      "grad_norm": 0.1496642529964447,
      "learning_rate": 0.0004993285117052035,
      "loss": 2.1192,
      "step": 1430
    },
    {
      "epoch": 6.637413394919169,
      "grad_norm": 0.15165375173091888,
      "learning_rate": 0.0004993149937871307,
      "loss": 2.1145,
      "step": 1440
    },
    {
      "epoch": 6.683602771362587,
      "grad_norm": 0.1507698893547058,
      "learning_rate": 0.000499301341341815,
      "loss": 2.1122,
      "step": 1450
    },
    {
      "epoch": 6.7297921478060045,
      "grad_norm": 0.15567733347415924,
      "learning_rate": 0.0004992875543766234,
      "loss": 2.1121,
      "step": 1460
    },
    {
      "epoch": 6.775981524249422,
      "grad_norm": 0.13449028134346008,
      "learning_rate": 0.0004992736328989952,
      "loss": 2.1052,
      "step": 1470
    },
    {
      "epoch": 6.822170900692841,
      "grad_norm": 0.1377524882555008,
      "learning_rate": 0.0004992595769164421,
      "loss": 2.1123,
      "step": 1480
    },
    {
      "epoch": 6.868360277136259,
      "grad_norm": 0.14730238914489746,
      "learning_rate": 0.0004992453864365486,
      "loss": 2.1085,
      "step": 1490
    },
    {
      "epoch": 6.914549653579677,
      "grad_norm": 0.12745602428913116,
      "learning_rate": 0.0004992310614669716,
      "loss": 2.1074,
      "step": 1500
    },
    {
      "epoch": 6.9607390300230945,
      "grad_norm": 0.12641167640686035,
      "learning_rate": 0.0004992166020154409,
      "loss": 2.1058,
      "step": 1510
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.016257643699646,
      "eval_runtime": 7.3335,
      "eval_samples_per_second": 3801.62,
      "eval_steps_per_second": 14.863,
      "step": 1519
    },
    {
      "epoch": 7.0046189376443415,
      "grad_norm": 0.14408737421035767,
      "learning_rate": 0.0004992020080897585,
      "loss": 2.0105,
      "step": 1520
    },
    {
      "epoch": 7.05080831408776,
      "grad_norm": 0.15764105319976807,
      "learning_rate": 0.000499187279697799,
      "loss": 2.0979,
      "step": 1530
    },
    {
      "epoch": 7.096997690531178,
      "grad_norm": 0.1275164633989334,
      "learning_rate": 0.0004991724168475098,
      "loss": 2.0925,
      "step": 1540
    },
    {
      "epoch": 7.143187066974596,
      "grad_norm": 0.15374605357646942,
      "learning_rate": 0.0004991574195469106,
      "loss": 2.0982,
      "step": 1550
    },
    {
      "epoch": 7.189376443418014,
      "grad_norm": 0.13008256256580353,
      "learning_rate": 0.000499142287804094,
      "loss": 2.1155,
      "step": 1560
    },
    {
      "epoch": 7.235565819861431,
      "grad_norm": 0.13702450692653656,
      "learning_rate": 0.0004991270216272246,
      "loss": 2.0927,
      "step": 1570
    },
    {
      "epoch": 7.28175519630485,
      "grad_norm": 0.1508687287569046,
      "learning_rate": 0.00049911162102454,
      "loss": 2.1018,
      "step": 1580
    },
    {
      "epoch": 7.327944572748268,
      "grad_norm": 0.13304206728935242,
      "learning_rate": 0.0004990960860043501,
      "loss": 2.0928,
      "step": 1590
    },
    {
      "epoch": 7.374133949191686,
      "grad_norm": 0.1788846105337143,
      "learning_rate": 0.0004990804165750374,
      "loss": 2.0962,
      "step": 1600
    },
    {
      "epoch": 7.4203233256351036,
      "grad_norm": 0.1445566564798355,
      "learning_rate": 0.000499064612745057,
      "loss": 2.0937,
      "step": 1610
    },
    {
      "epoch": 7.466512702078522,
      "grad_norm": 0.12831412255764008,
      "learning_rate": 0.0004990486745229364,
      "loss": 2.0851,
      "step": 1620
    },
    {
      "epoch": 7.51270207852194,
      "grad_norm": 0.14585192501544952,
      "learning_rate": 0.0004990326019172756,
      "loss": 2.0967,
      "step": 1630
    },
    {
      "epoch": 7.558891454965358,
      "grad_norm": 0.13772499561309814,
      "learning_rate": 0.0004990163949367474,
      "loss": 2.0997,
      "step": 1640
    },
    {
      "epoch": 7.605080831408776,
      "grad_norm": 0.14860309660434723,
      "learning_rate": 0.0004990000535900966,
      "loss": 2.0811,
      "step": 1650
    },
    {
      "epoch": 7.651270207852194,
      "grad_norm": 0.1399674415588379,
      "learning_rate": 0.000498983577886141,
      "loss": 2.0878,
      "step": 1660
    },
    {
      "epoch": 7.697459584295612,
      "grad_norm": 0.13237015902996063,
      "learning_rate": 0.0004989669678337706,
      "loss": 2.1009,
      "step": 1670
    },
    {
      "epoch": 7.74364896073903,
      "grad_norm": 0.14734147489070892,
      "learning_rate": 0.000498950223441948,
      "loss": 2.0902,
      "step": 1680
    },
    {
      "epoch": 7.789838337182448,
      "grad_norm": 0.12958288192749023,
      "learning_rate": 0.0004989333447197081,
      "loss": 2.0861,
      "step": 1690
    },
    {
      "epoch": 7.836027713625866,
      "grad_norm": 0.14049534499645233,
      "learning_rate": 0.0004989163316761587,
      "loss": 2.0997,
      "step": 1700
    },
    {
      "epoch": 7.882217090069284,
      "grad_norm": 0.13137692213058472,
      "learning_rate": 0.0004988991843204797,
      "loss": 2.0744,
      "step": 1710
    },
    {
      "epoch": 7.928406466512702,
      "grad_norm": 0.12611131370067596,
      "learning_rate": 0.0004988819026619236,
      "loss": 2.0901,
      "step": 1720
    },
    {
      "epoch": 7.97459584295612,
      "grad_norm": 0.13640853762626648,
      "learning_rate": 0.0004988644867098154,
      "loss": 2.0893,
      "step": 1730
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.0100631713867188,
      "eval_runtime": 7.3268,
      "eval_samples_per_second": 3805.064,
      "eval_steps_per_second": 14.877,
      "step": 1736
    },
    {
      "epoch": 8.018475750577368,
      "grad_norm": 0.13597574830055237,
      "learning_rate": 0.0004988469364735524,
      "loss": 1.9738,
      "step": 1740
    },
    {
      "epoch": 8.064665127020785,
      "grad_norm": 0.14724445343017578,
      "learning_rate": 0.0004988292519626048,
      "loss": 2.0894,
      "step": 1750
    },
    {
      "epoch": 8.110854503464203,
      "grad_norm": 0.14384670555591583,
      "learning_rate": 0.0004988114331865146,
      "loss": 2.0807,
      "step": 1760
    },
    {
      "epoch": 8.157043879907622,
      "grad_norm": 0.15670613944530487,
      "learning_rate": 0.0004987934801548967,
      "loss": 2.0845,
      "step": 1770
    },
    {
      "epoch": 8.203233256351039,
      "grad_norm": 0.15208490192890167,
      "learning_rate": 0.0004987753928774383,
      "loss": 2.0872,
      "step": 1780
    },
    {
      "epoch": 8.249422632794458,
      "grad_norm": 0.1652049720287323,
      "learning_rate": 0.0004987571713638993,
      "loss": 2.0855,
      "step": 1790
    },
    {
      "epoch": 8.295612009237875,
      "grad_norm": 0.16531886160373688,
      "learning_rate": 0.0004987388156241115,
      "loss": 2.0797,
      "step": 1800
    },
    {
      "epoch": 8.341801385681293,
      "grad_norm": 0.1637624353170395,
      "learning_rate": 0.0004987203256679796,
      "loss": 2.0801,
      "step": 1810
    },
    {
      "epoch": 8.387990762124712,
      "grad_norm": 0.14164720475673676,
      "learning_rate": 0.0004987017015054804,
      "loss": 2.0745,
      "step": 1820
    },
    {
      "epoch": 8.434180138568129,
      "grad_norm": 0.13021206855773926,
      "learning_rate": 0.0004986829431466634,
      "loss": 2.069,
      "step": 1830
    },
    {
      "epoch": 8.480369515011548,
      "grad_norm": 0.16381700336933136,
      "learning_rate": 0.0004986640506016504,
      "loss": 2.0754,
      "step": 1840
    },
    {
      "epoch": 8.526558891454965,
      "grad_norm": 0.14127369225025177,
      "learning_rate": 0.0004986450238806355,
      "loss": 2.0825,
      "step": 1850
    },
    {
      "epoch": 8.572748267898383,
      "grad_norm": 0.14496196806430817,
      "learning_rate": 0.0004986258629938853,
      "loss": 2.0894,
      "step": 1860
    },
    {
      "epoch": 8.618937644341802,
      "grad_norm": 0.1605672985315323,
      "learning_rate": 0.0004986065679517387,
      "loss": 2.0752,
      "step": 1870
    },
    {
      "epoch": 8.665127020785219,
      "grad_norm": 0.7445669174194336,
      "learning_rate": 0.0004985871387646071,
      "loss": 2.075,
      "step": 1880
    },
    {
      "epoch": 8.711316397228638,
      "grad_norm": 0.16993099451065063,
      "learning_rate": 0.0004985675754429744,
      "loss": 2.0849,
      "step": 1890
    },
    {
      "epoch": 8.757505773672055,
      "grad_norm": 0.15668731927871704,
      "learning_rate": 0.0004985478779973965,
      "loss": 2.0745,
      "step": 1900
    },
    {
      "epoch": 8.803695150115473,
      "grad_norm": 0.16779612004756927,
      "learning_rate": 0.0004985280464385021,
      "loss": 2.0762,
      "step": 1910
    },
    {
      "epoch": 8.849884526558892,
      "grad_norm": 0.13836362957954407,
      "learning_rate": 0.0004985080807769918,
      "loss": 2.0764,
      "step": 1920
    },
    {
      "epoch": 8.896073903002309,
      "grad_norm": 0.15214282274246216,
      "learning_rate": 0.0004984879810236391,
      "loss": 2.0658,
      "step": 1930
    },
    {
      "epoch": 8.942263279445728,
      "grad_norm": 0.14371615648269653,
      "learning_rate": 0.0004984677471892894,
      "loss": 2.0658,
      "step": 1940
    },
    {
      "epoch": 8.988452655889146,
      "grad_norm": 0.12804101407527924,
      "learning_rate": 0.0004984473792848606,
      "loss": 2.0724,
      "step": 1950
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.0049450397491455,
      "eval_runtime": 7.2992,
      "eval_samples_per_second": 3819.439,
      "eval_steps_per_second": 14.933,
      "step": 1953
    },
    {
      "epoch": 9.032332563510392,
      "grad_norm": 0.1316833347082138,
      "learning_rate": 0.0004984268773213431,
      "loss": 1.9627,
      "step": 1960
    },
    {
      "epoch": 9.078521939953811,
      "grad_norm": 0.1547832190990448,
      "learning_rate": 0.0004984062413097996,
      "loss": 2.057,
      "step": 1970
    },
    {
      "epoch": 9.124711316397228,
      "grad_norm": 0.16568626463413239,
      "learning_rate": 0.0004983854712613647,
      "loss": 2.0856,
      "step": 1980
    },
    {
      "epoch": 9.170900692840647,
      "grad_norm": 0.15935088694095612,
      "learning_rate": 0.0004983645671872459,
      "loss": 2.0582,
      "step": 1990
    },
    {
      "epoch": 9.217090069284065,
      "grad_norm": 0.16971328854560852,
      "learning_rate": 0.0004983435290987227,
      "loss": 2.0566,
      "step": 2000
    },
    {
      "epoch": 9.263279445727482,
      "grad_norm": 0.15283340215682983,
      "learning_rate": 0.0004983223570071469,
      "loss": 2.0791,
      "step": 2010
    },
    {
      "epoch": 9.309468822170901,
      "grad_norm": 0.17209117114543915,
      "learning_rate": 0.0004983010509239429,
      "loss": 2.0828,
      "step": 2020
    },
    {
      "epoch": 9.355658198614318,
      "grad_norm": 0.1477523297071457,
      "learning_rate": 0.000498279610860607,
      "loss": 2.0647,
      "step": 2030
    },
    {
      "epoch": 9.401847575057737,
      "grad_norm": 0.1472332626581192,
      "learning_rate": 0.0004982580368287082,
      "loss": 2.0729,
      "step": 2040
    },
    {
      "epoch": 9.448036951501155,
      "grad_norm": 0.1449660062789917,
      "learning_rate": 0.0004982363288398874,
      "loss": 2.0735,
      "step": 2050
    },
    {
      "epoch": 9.494226327944572,
      "grad_norm": 0.17367404699325562,
      "learning_rate": 0.0004982144869058579,
      "loss": 2.0725,
      "step": 2060
    },
    {
      "epoch": 9.540415704387991,
      "grad_norm": 0.1573100984096527,
      "learning_rate": 0.0004981925110384056,
      "loss": 2.066,
      "step": 2070
    },
    {
      "epoch": 9.586605080831408,
      "grad_norm": 0.13647376000881195,
      "learning_rate": 0.0004981704012493881,
      "loss": 2.0649,
      "step": 2080
    },
    {
      "epoch": 9.632794457274827,
      "grad_norm": 0.14696897566318512,
      "learning_rate": 0.0004981481575507359,
      "loss": 2.0651,
      "step": 2090
    },
    {
      "epoch": 9.678983833718245,
      "grad_norm": 0.15433692932128906,
      "learning_rate": 0.000498125779954451,
      "loss": 2.0748,
      "step": 2100
    },
    {
      "epoch": 9.725173210161662,
      "grad_norm": 0.15075773000717163,
      "learning_rate": 0.0004981032684726086,
      "loss": 2.0654,
      "step": 2110
    },
    {
      "epoch": 9.77136258660508,
      "grad_norm": 0.264458030462265,
      "learning_rate": 0.000498080623117355,
      "loss": 2.0624,
      "step": 2120
    },
    {
      "epoch": 9.8175519630485,
      "grad_norm": 0.14886830747127533,
      "learning_rate": 0.0004980578439009099,
      "loss": 2.0523,
      "step": 2130
    },
    {
      "epoch": 9.863741339491916,
      "grad_norm": 0.15209712088108063,
      "learning_rate": 0.0004980349308355644,
      "loss": 2.0732,
      "step": 2140
    },
    {
      "epoch": 9.909930715935335,
      "grad_norm": 0.14841334521770477,
      "learning_rate": 0.000498011883933682,
      "loss": 2.0656,
      "step": 2150
    },
    {
      "epoch": 9.956120092378752,
      "grad_norm": 0.2493569701910019,
      "learning_rate": 0.0004979887032076989,
      "loss": 2.0605,
      "step": 2160
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.09853485226631165,
      "learning_rate": 0.0004979653886701227,
      "loss": 1.9555,
      "step": 2170
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.0013099908828735,
      "eval_runtime": 7.3983,
      "eval_samples_per_second": 3768.282,
      "eval_steps_per_second": 14.733,
      "step": 2170
    },
    {
      "epoch": 10.046189376443419,
      "grad_norm": 0.14344581961631775,
      "learning_rate": 0.0004979419403335339,
      "loss": 2.063,
      "step": 2180
    },
    {
      "epoch": 10.092378752886836,
      "grad_norm": 0.23437950015068054,
      "learning_rate": 0.0004979183582105849,
      "loss": 2.0531,
      "step": 2190
    },
    {
      "epoch": 10.138568129330254,
      "grad_norm": 0.17154933512210846,
      "learning_rate": 0.0004978946423140002,
      "loss": 2.0551,
      "step": 2200
    },
    {
      "epoch": 10.184757505773671,
      "grad_norm": 0.150832861661911,
      "learning_rate": 0.0004978707926565766,
      "loss": 2.0595,
      "step": 2210
    },
    {
      "epoch": 10.23094688221709,
      "grad_norm": 0.1524607241153717,
      "learning_rate": 0.0004978468092511833,
      "loss": 2.0666,
      "step": 2220
    },
    {
      "epoch": 10.277136258660509,
      "grad_norm": 0.2658870220184326,
      "learning_rate": 0.0004978226921107613,
      "loss": 2.0573,
      "step": 2230
    },
    {
      "epoch": 10.323325635103926,
      "grad_norm": 0.15381312370300293,
      "learning_rate": 0.0004977984412483237,
      "loss": 2.0616,
      "step": 2240
    },
    {
      "epoch": 10.369515011547344,
      "grad_norm": 0.15911699831485748,
      "learning_rate": 0.0004977740566769564,
      "loss": 2.0617,
      "step": 2250
    },
    {
      "epoch": 10.415704387990763,
      "grad_norm": 0.1475028693675995,
      "learning_rate": 0.0004977495384098166,
      "loss": 2.0599,
      "step": 2260
    },
    {
      "epoch": 10.46189376443418,
      "grad_norm": 0.15565261244773865,
      "learning_rate": 0.0004977248864601344,
      "loss": 2.0708,
      "step": 2270
    },
    {
      "epoch": 10.508083140877599,
      "grad_norm": 0.15023991465568542,
      "learning_rate": 0.0004977001008412113,
      "loss": 2.0496,
      "step": 2280
    },
    {
      "epoch": 10.554272517321015,
      "grad_norm": 0.14608973264694214,
      "learning_rate": 0.0004976751815664217,
      "loss": 2.0403,
      "step": 2290
    },
    {
      "epoch": 10.600461893764434,
      "grad_norm": 0.27036944031715393,
      "learning_rate": 0.0004976501286492114,
      "loss": 2.0652,
      "step": 2300
    },
    {
      "epoch": 10.646651270207853,
      "grad_norm": 0.13826638460159302,
      "learning_rate": 0.0004976249421030989,
      "loss": 2.0573,
      "step": 2310
    },
    {
      "epoch": 10.69284064665127,
      "grad_norm": 0.24463039636611938,
      "learning_rate": 0.0004975996219416742,
      "loss": 2.0502,
      "step": 2320
    },
    {
      "epoch": 10.739030023094688,
      "grad_norm": 0.16888315975666046,
      "learning_rate": 0.0004975741681786001,
      "loss": 2.0679,
      "step": 2330
    },
    {
      "epoch": 10.785219399538107,
      "grad_norm": 0.1533796191215515,
      "learning_rate": 0.000497548580827611,
      "loss": 2.0482,
      "step": 2340
    },
    {
      "epoch": 10.831408775981524,
      "grad_norm": 0.14839327335357666,
      "learning_rate": 0.0004975228599025136,
      "loss": 2.0553,
      "step": 2350
    },
    {
      "epoch": 10.877598152424943,
      "grad_norm": 0.16396605968475342,
      "learning_rate": 0.0004974970054171864,
      "loss": 2.0487,
      "step": 2360
    },
    {
      "epoch": 10.92378752886836,
      "grad_norm": 0.15905670821666718,
      "learning_rate": 0.0004974710173855803,
      "loss": 2.0452,
      "step": 2370
    },
    {
      "epoch": 10.969976905311778,
      "grad_norm": 0.1490243822336197,
      "learning_rate": 0.000497444895821718,
      "loss": 2.0538,
      "step": 2380
    },
    {
      "epoch": 11.0,
      "eval_loss": 0.9984052181243896,
      "eval_runtime": 7.3523,
      "eval_samples_per_second": 3791.858,
      "eval_steps_per_second": 14.825,
      "step": 2387
    },
    {
      "epoch": 11.013856812933025,
      "grad_norm": 0.16057060658931732,
      "learning_rate": 0.0004974186407396945,
      "loss": 1.9583,
      "step": 2390
    },
    {
      "epoch": 11.060046189376443,
      "grad_norm": 0.18111473321914673,
      "learning_rate": 0.0004973922521536767,
      "loss": 2.055,
      "step": 2400
    },
    {
      "epoch": 11.106235565819862,
      "grad_norm": 0.1607934832572937,
      "learning_rate": 0.0004973657300779033,
      "loss": 2.0418,
      "step": 2410
    },
    {
      "epoch": 11.152424942263279,
      "grad_norm": 0.14935271441936493,
      "learning_rate": 0.0004973390745266857,
      "loss": 2.0423,
      "step": 2420
    },
    {
      "epoch": 11.198614318706698,
      "grad_norm": 0.14858824014663696,
      "learning_rate": 0.0004973122855144066,
      "loss": 2.0471,
      "step": 2430
    },
    {
      "epoch": 11.244803695150116,
      "grad_norm": 0.16591762006282806,
      "learning_rate": 0.0004972853630555211,
      "loss": 2.0531,
      "step": 2440
    },
    {
      "epoch": 11.290993071593533,
      "grad_norm": 0.16962331533432007,
      "learning_rate": 0.0004972583071645561,
      "loss": 2.0436,
      "step": 2450
    },
    {
      "epoch": 11.337182448036952,
      "grad_norm": 0.15779098868370056,
      "learning_rate": 0.0004972311178561108,
      "loss": 2.0556,
      "step": 2460
    },
    {
      "epoch": 11.383371824480369,
      "grad_norm": 0.17230691015720367,
      "learning_rate": 0.0004972037951448563,
      "loss": 2.048,
      "step": 2470
    },
    {
      "epoch": 11.429561200923787,
      "grad_norm": 0.1696208268404007,
      "learning_rate": 0.0004971763390455352,
      "loss": 2.0407,
      "step": 2480
    },
    {
      "epoch": 11.475750577367206,
      "grad_norm": 0.16537804901599884,
      "learning_rate": 0.0004971487495729629,
      "loss": 2.0403,
      "step": 2490
    },
    {
      "epoch": 11.521939953810623,
      "grad_norm": 0.16531400382518768,
      "learning_rate": 0.0004971210267420261,
      "loss": 2.0504,
      "step": 2500
    },
    {
      "epoch": 11.568129330254042,
      "grad_norm": 0.1470663845539093,
      "learning_rate": 0.0004970931705676837,
      "loss": 2.0477,
      "step": 2510
    },
    {
      "epoch": 11.61431870669746,
      "grad_norm": 0.17695242166519165,
      "learning_rate": 0.0004970651810649666,
      "loss": 2.0515,
      "step": 2520
    },
    {
      "epoch": 11.660508083140877,
      "grad_norm": 0.16660447418689728,
      "learning_rate": 0.0004970370582489775,
      "loss": 2.0528,
      "step": 2530
    },
    {
      "epoch": 11.706697459584296,
      "grad_norm": 0.1417054533958435,
      "learning_rate": 0.0004970088021348912,
      "loss": 2.0548,
      "step": 2540
    },
    {
      "epoch": 11.752886836027713,
      "grad_norm": 0.15675358474254608,
      "learning_rate": 0.0004969804127379542,
      "loss": 2.0556,
      "step": 2550
    },
    {
      "epoch": 11.799076212471132,
      "grad_norm": 0.1426062136888504,
      "learning_rate": 0.0004969518900734854,
      "loss": 2.0405,
      "step": 2560
    },
    {
      "epoch": 11.84526558891455,
      "grad_norm": 0.17324687540531158,
      "learning_rate": 0.0004969232341568749,
      "loss": 2.0504,
      "step": 2570
    },
    {
      "epoch": 11.891454965357967,
      "grad_norm": 0.16208024322986603,
      "learning_rate": 0.0004968944450035853,
      "loss": 2.0474,
      "step": 2580
    },
    {
      "epoch": 11.937644341801386,
      "grad_norm": 0.14657294750213623,
      "learning_rate": 0.0004968655226291508,
      "loss": 2.0546,
      "step": 2590
    },
    {
      "epoch": 11.983833718244803,
      "grad_norm": 0.14010842144489288,
      "learning_rate": 0.0004968364670491775,
      "loss": 2.051,
      "step": 2600
    },
    {
      "epoch": 12.0,
      "eval_loss": 0.9950652122497559,
      "eval_runtime": 7.3068,
      "eval_samples_per_second": 3815.473,
      "eval_steps_per_second": 14.918,
      "step": 2604
    },
    {
      "epoch": 12.02771362586605,
      "grad_norm": 0.3793404698371887,
      "learning_rate": 0.0004968072782793435,
      "loss": 1.9552,
      "step": 2610
    },
    {
      "epoch": 12.07390300230947,
      "grad_norm": 0.1705285757780075,
      "learning_rate": 0.0004967779563353987,
      "loss": 2.048,
      "step": 2620
    },
    {
      "epoch": 12.120092378752886,
      "grad_norm": 0.15794087946414948,
      "learning_rate": 0.0004967485012331648,
      "loss": 2.0363,
      "step": 2630
    },
    {
      "epoch": 12.166281755196305,
      "grad_norm": 0.14400385320186615,
      "learning_rate": 0.0004967189129885353,
      "loss": 2.0417,
      "step": 2640
    },
    {
      "epoch": 12.212471131639722,
      "grad_norm": 0.13971802592277527,
      "learning_rate": 0.0004966891916174759,
      "loss": 2.0488,
      "step": 2650
    },
    {
      "epoch": 12.25866050808314,
      "grad_norm": 0.17637358605861664,
      "learning_rate": 0.0004966593371360237,
      "loss": 2.0392,
      "step": 2660
    },
    {
      "epoch": 12.30484988452656,
      "grad_norm": 0.1755439043045044,
      "learning_rate": 0.0004966293495602879,
      "loss": 2.04,
      "step": 2670
    },
    {
      "epoch": 12.351039260969976,
      "grad_norm": 0.16766367852687836,
      "learning_rate": 0.0004965992289064493,
      "loss": 2.0423,
      "step": 2680
    },
    {
      "epoch": 12.397228637413395,
      "grad_norm": 0.16218993067741394,
      "learning_rate": 0.0004965689751907607,
      "loss": 2.0358,
      "step": 2690
    },
    {
      "epoch": 12.443418013856814,
      "grad_norm": 0.1799621284008026,
      "learning_rate": 0.0004965385884295467,
      "loss": 2.0518,
      "step": 2700
    },
    {
      "epoch": 12.48960739030023,
      "grad_norm": 0.16738305985927582,
      "learning_rate": 0.0004965080686392034,
      "loss": 2.0391,
      "step": 2710
    },
    {
      "epoch": 12.53579676674365,
      "grad_norm": 0.15271113812923431,
      "learning_rate": 0.0004964774158361991,
      "loss": 2.0462,
      "step": 2720
    },
    {
      "epoch": 12.581986143187066,
      "grad_norm": 0.17924900352954865,
      "learning_rate": 0.0004964466300370736,
      "loss": 2.0332,
      "step": 2730
    },
    {
      "epoch": 12.628175519630485,
      "grad_norm": 0.1729496419429779,
      "learning_rate": 0.0004964157112584386,
      "loss": 2.0616,
      "step": 2740
    },
    {
      "epoch": 12.674364896073904,
      "grad_norm": 0.16955037415027618,
      "learning_rate": 0.0004963846595169773,
      "loss": 2.0473,
      "step": 2750
    },
    {
      "epoch": 12.72055427251732,
      "grad_norm": 0.16523250937461853,
      "learning_rate": 0.000496353474829445,
      "loss": 2.0471,
      "step": 2760
    },
    {
      "epoch": 12.76674364896074,
      "grad_norm": 0.16288842260837555,
      "learning_rate": 0.0004963221572126686,
      "loss": 2.0519,
      "step": 2770
    },
    {
      "epoch": 12.812933025404156,
      "grad_norm": 0.18872380256652832,
      "learning_rate": 0.0004962907066835465,
      "loss": 2.0371,
      "step": 2780
    },
    {
      "epoch": 12.859122401847575,
      "grad_norm": 0.16894714534282684,
      "learning_rate": 0.0004962591232590491,
      "loss": 2.0429,
      "step": 2790
    },
    {
      "epoch": 12.905311778290994,
      "grad_norm": 0.18371130526065826,
      "learning_rate": 0.0004962274069562185,
      "loss": 2.0426,
      "step": 2800
    },
    {
      "epoch": 12.95150115473441,
      "grad_norm": 0.15501591563224792,
      "learning_rate": 0.0004961955577921683,
      "loss": 2.0525,
      "step": 2810
    },
    {
      "epoch": 12.99769053117783,
      "grad_norm": 0.16633367538452148,
      "learning_rate": 0.000496163575784084,
      "loss": 2.0334,
      "step": 2820
    },
    {
      "epoch": 13.0,
      "eval_loss": 0.995803952217102,
      "eval_runtime": 7.2834,
      "eval_samples_per_second": 3827.741,
      "eval_steps_per_second": 14.966,
      "step": 2821
    },
    {
      "epoch": 13.041570438799075,
      "grad_norm": 0.15675468742847443,
      "learning_rate": 0.0004961314609492226,
      "loss": 1.933,
      "step": 2830
    },
    {
      "epoch": 13.087759815242494,
      "grad_norm": 0.32256850600242615,
      "learning_rate": 0.000496099213304913,
      "loss": 2.0309,
      "step": 2840
    },
    {
      "epoch": 13.133949191685913,
      "grad_norm": 0.17698556184768677,
      "learning_rate": 0.0004960668328685555,
      "loss": 2.0317,
      "step": 2850
    },
    {
      "epoch": 13.18013856812933,
      "grad_norm": 0.20110853016376495,
      "learning_rate": 0.0004960343196576222,
      "loss": 2.0502,
      "step": 2860
    },
    {
      "epoch": 13.226327944572748,
      "grad_norm": 0.18172325193881989,
      "learning_rate": 0.0004960016736896568,
      "loss": 2.0333,
      "step": 2870
    },
    {
      "epoch": 13.272517321016167,
      "grad_norm": 0.16206923127174377,
      "learning_rate": 0.0004959688949822749,
      "loss": 2.0304,
      "step": 2880
    },
    {
      "epoch": 13.318706697459584,
      "grad_norm": 0.1645997017621994,
      "learning_rate": 0.000495935983553163,
      "loss": 2.0368,
      "step": 2890
    },
    {
      "epoch": 13.364896073903003,
      "grad_norm": 0.1850673258304596,
      "learning_rate": 0.0004959029394200801,
      "loss": 2.0436,
      "step": 2900
    },
    {
      "epoch": 13.41108545034642,
      "grad_norm": 0.1771213561296463,
      "learning_rate": 0.0004958697626008563,
      "loss": 2.0413,
      "step": 2910
    },
    {
      "epoch": 13.457274826789838,
      "grad_norm": 0.1919737160205841,
      "learning_rate": 0.0004958364531133933,
      "loss": 2.0346,
      "step": 2920
    },
    {
      "epoch": 13.503464203233257,
      "grad_norm": 0.19179889559745789,
      "learning_rate": 0.0004958030109756646,
      "loss": 2.0381,
      "step": 2930
    },
    {
      "epoch": 13.549653579676674,
      "grad_norm": 0.2137780338525772,
      "learning_rate": 0.0004957694362057151,
      "loss": 2.0334,
      "step": 2940
    },
    {
      "epoch": 13.595842956120093,
      "grad_norm": 0.18693797290325165,
      "learning_rate": 0.0004957357288216612,
      "loss": 2.0453,
      "step": 2950
    },
    {
      "epoch": 13.64203233256351,
      "grad_norm": 0.17612744867801666,
      "learning_rate": 0.0004957018888416912,
      "loss": 2.0446,
      "step": 2960
    },
    {
      "epoch": 13.688221709006928,
      "grad_norm": 0.2327040582895279,
      "learning_rate": 0.0004956679162840646,
      "loss": 2.0442,
      "step": 2970
    },
    {
      "epoch": 13.734411085450347,
      "grad_norm": 0.20636026561260223,
      "learning_rate": 0.0004956338111671126,
      "loss": 2.0346,
      "step": 2980
    },
    {
      "epoch": 13.780600461893764,
      "grad_norm": 0.17793633043766022,
      "learning_rate": 0.000495599573509238,
      "loss": 2.0409,
      "step": 2990
    },
    {
      "epoch": 13.826789838337183,
      "grad_norm": 0.20775005221366882,
      "learning_rate": 0.0004955652033289149,
      "loss": 2.0369,
      "step": 3000
    },
    {
      "epoch": 13.872979214780601,
      "grad_norm": 0.19647778570652008,
      "learning_rate": 0.0004955307006446889,
      "loss": 2.0485,
      "step": 3010
    },
    {
      "epoch": 13.919168591224018,
      "grad_norm": 0.18229933083057404,
      "learning_rate": 0.0004954960654751774,
      "loss": 2.0398,
      "step": 3020
    },
    {
      "epoch": 13.965357967667437,
      "grad_norm": 0.17502827942371368,
      "learning_rate": 0.000495461297839069,
      "loss": 2.034,
      "step": 3030
    },
    {
      "epoch": 14.0,
      "eval_loss": 0.9965550303459167,
      "eval_runtime": 7.3164,
      "eval_samples_per_second": 3810.456,
      "eval_steps_per_second": 14.898,
      "step": 3038
    },
    {
      "epoch": 14.009237875288683,
      "grad_norm": 0.17221055924892426,
      "learning_rate": 0.000495426397755124,
      "loss": 1.9434,
      "step": 3040
    },
    {
      "epoch": 14.055427251732102,
      "grad_norm": 0.17224130034446716,
      "learning_rate": 0.0004953913652421738,
      "loss": 2.0301,
      "step": 3050
    },
    {
      "epoch": 14.10161662817552,
      "grad_norm": 0.2167399674654007,
      "learning_rate": 0.0004953562003191219,
      "loss": 2.0423,
      "step": 3060
    },
    {
      "epoch": 14.147806004618937,
      "grad_norm": 0.1798515021800995,
      "learning_rate": 0.0004953209030049426,
      "loss": 2.0367,
      "step": 3070
    },
    {
      "epoch": 14.193995381062356,
      "grad_norm": 0.1835029125213623,
      "learning_rate": 0.0004952854733186818,
      "loss": 2.0383,
      "step": 3080
    },
    {
      "epoch": 14.240184757505773,
      "grad_norm": 0.2009192407131195,
      "learning_rate": 0.0004952499112794571,
      "loss": 2.0331,
      "step": 3090
    },
    {
      "epoch": 14.286374133949192,
      "grad_norm": 0.1830795407295227,
      "learning_rate": 0.0004952142169064572,
      "loss": 2.0273,
      "step": 3100
    },
    {
      "epoch": 14.33256351039261,
      "grad_norm": 0.210428386926651,
      "learning_rate": 0.0004951783902189424,
      "loss": 2.0409,
      "step": 3110
    },
    {
      "epoch": 14.378752886836027,
      "grad_norm": 0.20101499557495117,
      "learning_rate": 0.0004951424312362444,
      "loss": 2.0309,
      "step": 3120
    },
    {
      "epoch": 14.424942263279446,
      "grad_norm": 0.20804058015346527,
      "learning_rate": 0.0004951063399777661,
      "loss": 2.0309,
      "step": 3130
    },
    {
      "epoch": 14.471131639722863,
      "grad_norm": 0.20802901685237885,
      "learning_rate": 0.0004950701164629819,
      "loss": 2.0366,
      "step": 3140
    },
    {
      "epoch": 14.517321016166282,
      "grad_norm": 0.20271596312522888,
      "learning_rate": 0.0004950337607114376,
      "loss": 2.0381,
      "step": 3150
    },
    {
      "epoch": 14.5635103926097,
      "grad_norm": 0.23496873676776886,
      "learning_rate": 0.0004949972727427503,
      "loss": 2.0465,
      "step": 3160
    },
    {
      "epoch": 14.609699769053117,
      "grad_norm": 0.2162790447473526,
      "learning_rate": 0.0004949606525766084,
      "loss": 2.0531,
      "step": 3170
    },
    {
      "epoch": 14.655889145496536,
      "grad_norm": 0.20007839798927307,
      "learning_rate": 0.0004949239002327718,
      "loss": 2.0252,
      "step": 3180
    },
    {
      "epoch": 14.702078521939955,
      "grad_norm": 0.24146880209445953,
      "learning_rate": 0.0004948870157310716,
      "loss": 2.0326,
      "step": 3190
    },
    {
      "epoch": 14.748267898383371,
      "grad_norm": 0.20606522262096405,
      "learning_rate": 0.00049484999909141,
      "loss": 2.0302,
      "step": 3200
    },
    {
      "epoch": 14.79445727482679,
      "grad_norm": 0.20502738654613495,
      "learning_rate": 0.0004948128503337608,
      "loss": 2.0276,
      "step": 3210
    },
    {
      "epoch": 14.840646651270207,
      "grad_norm": 0.19515138864517212,
      "learning_rate": 0.0004947755694781692,
      "loss": 2.0414,
      "step": 3220
    },
    {
      "epoch": 14.886836027713626,
      "grad_norm": 0.2620896100997925,
      "learning_rate": 0.0004947381565447513,
      "loss": 2.0281,
      "step": 3230
    },
    {
      "epoch": 14.933025404157044,
      "grad_norm": 0.1888158768415451,
      "learning_rate": 0.0004947006115536948,
      "loss": 2.029,
      "step": 3240
    },
    {
      "epoch": 14.979214780600461,
      "grad_norm": 0.21841657161712646,
      "learning_rate": 0.0004946629345252582,
      "loss": 2.0377,
      "step": 3250
    },
    {
      "epoch": 15.0,
      "eval_loss": 0.9940526485443115,
      "eval_runtime": 7.312,
      "eval_samples_per_second": 3812.766,
      "eval_steps_per_second": 14.907,
      "step": 3255
    },
    {
      "epoch": 15.02309468822171,
      "grad_norm": 0.20667146146297455,
      "learning_rate": 0.0004946251254797718,
      "loss": 1.936,
      "step": 3260
    },
    {
      "epoch": 15.069284064665126,
      "grad_norm": 0.217452734708786,
      "learning_rate": 0.0004945871844376369,
      "loss": 2.0141,
      "step": 3270
    },
    {
      "epoch": 15.115473441108545,
      "grad_norm": 0.20420165359973907,
      "learning_rate": 0.0004945491114193259,
      "loss": 2.0302,
      "step": 3280
    },
    {
      "epoch": 15.161662817551964,
      "grad_norm": 0.21681798994541168,
      "learning_rate": 0.0004945109064453827,
      "loss": 2.0399,
      "step": 3290
    },
    {
      "epoch": 15.20785219399538,
      "grad_norm": 0.2308114916086197,
      "learning_rate": 0.000494472569536422,
      "loss": 2.035,
      "step": 3300
    },
    {
      "epoch": 15.2540415704388,
      "grad_norm": 0.23272299766540527,
      "learning_rate": 0.0004944341007131299,
      "loss": 2.023,
      "step": 3310
    },
    {
      "epoch": 15.300230946882216,
      "grad_norm": 0.2034195512533188,
      "learning_rate": 0.0004943954999962639,
      "loss": 2.0497,
      "step": 3320
    },
    {
      "epoch": 15.346420323325635,
      "grad_norm": 0.21225295960903168,
      "learning_rate": 0.0004943567674066524,
      "loss": 2.0357,
      "step": 3330
    },
    {
      "epoch": 15.392609699769054,
      "grad_norm": 0.23142912983894348,
      "learning_rate": 0.000494317902965195,
      "loss": 2.0387,
      "step": 3340
    },
    {
      "epoch": 15.43879907621247,
      "grad_norm": 0.2173290252685547,
      "learning_rate": 0.0004942789066928624,
      "loss": 2.0317,
      "step": 3350
    },
    {
      "epoch": 15.48498845265589,
      "grad_norm": 0.19151772558689117,
      "learning_rate": 0.0004942397786106965,
      "loss": 2.0335,
      "step": 3360
    },
    {
      "epoch": 15.531177829099308,
      "grad_norm": 0.22217336297035217,
      "learning_rate": 0.0004942005187398104,
      "loss": 2.0281,
      "step": 3370
    },
    {
      "epoch": 15.577367205542725,
      "grad_norm": 0.20282712578773499,
      "learning_rate": 0.0004941611271013882,
      "loss": 2.0321,
      "step": 3380
    },
    {
      "epoch": 15.623556581986143,
      "grad_norm": 0.1998690664768219,
      "learning_rate": 0.0004941216037166853,
      "loss": 2.0285,
      "step": 3390
    },
    {
      "epoch": 15.66974595842956,
      "grad_norm": 0.3544765114784241,
      "learning_rate": 0.0004940819486070277,
      "loss": 2.0357,
      "step": 3400
    },
    {
      "epoch": 15.71593533487298,
      "grad_norm": 0.19194364547729492,
      "learning_rate": 0.000494042161793813,
      "loss": 2.0374,
      "step": 3410
    },
    {
      "epoch": 15.762124711316398,
      "grad_norm": 0.24352936446666718,
      "learning_rate": 0.0004940022432985096,
      "loss": 2.0354,
      "step": 3420
    },
    {
      "epoch": 15.808314087759815,
      "grad_norm": 0.193216472864151,
      "learning_rate": 0.0004939621931426572,
      "loss": 2.0206,
      "step": 3430
    },
    {
      "epoch": 15.854503464203233,
      "grad_norm": 0.22272802889347076,
      "learning_rate": 0.0004939220113478659,
      "loss": 2.0263,
      "step": 3440
    },
    {
      "epoch": 15.900692840646652,
      "grad_norm": 0.2097259759902954,
      "learning_rate": 0.0004938816979358178,
      "loss": 2.0253,
      "step": 3450
    },
    {
      "epoch": 15.946882217090069,
      "grad_norm": 0.19177363812923431,
      "learning_rate": 0.0004938412529282654,
      "loss": 2.035,
      "step": 3460
    },
    {
      "epoch": 15.993071593533488,
      "grad_norm": 0.21128450334072113,
      "learning_rate": 0.0004938006763470321,
      "loss": 2.0272,
      "step": 3470
    },
    {
      "epoch": 16.0,
      "eval_loss": 0.9918773770332336,
      "eval_runtime": 7.3293,
      "eval_samples_per_second": 3803.798,
      "eval_steps_per_second": 14.872,
      "step": 3472
    },
    {
      "epoch": 16.036951501154736,
      "grad_norm": 0.23003579676151276,
      "learning_rate": 0.0004937599682140127,
      "loss": 1.9195,
      "step": 3480
    },
    {
      "epoch": 16.08314087759815,
      "grad_norm": 0.19458574056625366,
      "learning_rate": 0.0004937191285511726,
      "loss": 2.0313,
      "step": 3490
    },
    {
      "epoch": 16.12933025404157,
      "grad_norm": 0.2144865244626999,
      "learning_rate": 0.0004936781573805487,
      "loss": 2.0259,
      "step": 3500
    },
    {
      "epoch": 16.175519630484988,
      "grad_norm": 0.24350152909755707,
      "learning_rate": 0.0004936370547242482,
      "loss": 2.0334,
      "step": 3510
    },
    {
      "epoch": 16.221709006928407,
      "grad_norm": 0.274242103099823,
      "learning_rate": 0.0004935958206044498,
      "loss": 2.0186,
      "step": 3520
    },
    {
      "epoch": 16.267898383371826,
      "grad_norm": 0.20497800409793854,
      "learning_rate": 0.0004935544550434029,
      "loss": 2.0199,
      "step": 3530
    },
    {
      "epoch": 16.314087759815244,
      "grad_norm": 0.27117279171943665,
      "learning_rate": 0.0004935129580634276,
      "loss": 2.0269,
      "step": 3540
    },
    {
      "epoch": 16.36027713625866,
      "grad_norm": 0.2842705547809601,
      "learning_rate": 0.0004934713296869156,
      "loss": 2.0256,
      "step": 3550
    },
    {
      "epoch": 16.406466512702078,
      "grad_norm": 0.2283109873533249,
      "learning_rate": 0.0004934295699363285,
      "loss": 2.0403,
      "step": 3560
    },
    {
      "epoch": 16.452655889145497,
      "grad_norm": 0.235600084066391,
      "learning_rate": 0.0004933876788341997,
      "loss": 2.0307,
      "step": 3570
    },
    {
      "epoch": 16.498845265588916,
      "grad_norm": 0.21538057923316956,
      "learning_rate": 0.000493345656403133,
      "loss": 2.0309,
      "step": 3580
    },
    {
      "epoch": 16.545034642032334,
      "grad_norm": 0.26507332921028137,
      "learning_rate": 0.0004933035026658032,
      "loss": 2.0182,
      "step": 3590
    },
    {
      "epoch": 16.59122401847575,
      "grad_norm": 0.25993621349334717,
      "learning_rate": 0.0004932612176449559,
      "loss": 2.042,
      "step": 3600
    },
    {
      "epoch": 16.637413394919168,
      "grad_norm": 0.1937473565340042,
      "learning_rate": 0.0004932188013634077,
      "loss": 2.0288,
      "step": 3610
    },
    {
      "epoch": 16.683602771362587,
      "grad_norm": 0.324036568403244,
      "learning_rate": 0.0004931762538440457,
      "loss": 2.0267,
      "step": 3620
    },
    {
      "epoch": 16.729792147806005,
      "grad_norm": 0.23673130571842194,
      "learning_rate": 0.0004931335751098281,
      "loss": 2.0379,
      "step": 3630
    },
    {
      "epoch": 16.775981524249424,
      "grad_norm": 0.22988079488277435,
      "learning_rate": 0.0004930907651837838,
      "loss": 2.0361,
      "step": 3640
    },
    {
      "epoch": 16.82217090069284,
      "grad_norm": 0.2369600534439087,
      "learning_rate": 0.0004930478240890126,
      "loss": 2.0209,
      "step": 3650
    },
    {
      "epoch": 16.868360277136258,
      "grad_norm": 0.30169662833213806,
      "learning_rate": 0.0004930047518486848,
      "loss": 2.0336,
      "step": 3660
    },
    {
      "epoch": 16.914549653579677,
      "grad_norm": 0.21147921681404114,
      "learning_rate": 0.0004929615484860417,
      "loss": 2.024,
      "step": 3670
    },
    {
      "epoch": 16.960739030023095,
      "grad_norm": 0.22497689723968506,
      "learning_rate": 0.0004929182140243953,
      "loss": 2.0248,
      "step": 3680
    },
    {
      "epoch": 17.0,
      "eval_loss": 0.9886691570281982,
      "eval_runtime": 7.3458,
      "eval_samples_per_second": 3795.229,
      "eval_steps_per_second": 14.838,
      "step": 3689
    },
    {
      "epoch": 17.00461893764434,
      "grad_norm": 0.19172346591949463,
      "learning_rate": 0.0004928747484871284,
      "loss": 1.9281,
      "step": 3690
    },
    {
      "epoch": 17.05080831408776,
      "grad_norm": 0.2122342884540558,
      "learning_rate": 0.0004928311518976943,
      "loss": 2.0258,
      "step": 3700
    },
    {
      "epoch": 17.09699769053118,
      "grad_norm": 0.24099253118038177,
      "learning_rate": 0.0004927874242796174,
      "loss": 2.0228,
      "step": 3710
    },
    {
      "epoch": 17.143187066974598,
      "grad_norm": 0.21101489663124084,
      "learning_rate": 0.0004927435656564924,
      "loss": 2.022,
      "step": 3720
    },
    {
      "epoch": 17.189376443418013,
      "grad_norm": 0.43804940581321716,
      "learning_rate": 0.0004926995760519848,
      "loss": 2.0303,
      "step": 3730
    },
    {
      "epoch": 17.23556581986143,
      "grad_norm": 0.22514960169792175,
      "learning_rate": 0.0004926554554898311,
      "loss": 2.0216,
      "step": 3740
    },
    {
      "epoch": 17.28175519630485,
      "grad_norm": 0.24668771028518677,
      "learning_rate": 0.000492611203993838,
      "loss": 2.0304,
      "step": 3750
    },
    {
      "epoch": 17.32794457274827,
      "grad_norm": 0.27570798993110657,
      "learning_rate": 0.0004925668215878832,
      "loss": 2.0356,
      "step": 3760
    },
    {
      "epoch": 17.374133949191688,
      "grad_norm": 0.24964885413646698,
      "learning_rate": 0.0004925223082959146,
      "loss": 2.0335,
      "step": 3770
    },
    {
      "epoch": 17.420323325635103,
      "grad_norm": 0.22881391644477844,
      "learning_rate": 0.0004924776641419512,
      "loss": 2.0276,
      "step": 3780
    },
    {
      "epoch": 17.46651270207852,
      "grad_norm": 0.23507685959339142,
      "learning_rate": 0.0004924328891500827,
      "loss": 2.0236,
      "step": 3790
    },
    {
      "epoch": 17.51270207852194,
      "grad_norm": 0.2446174919605255,
      "learning_rate": 0.0004923879833444686,
      "loss": 2.0231,
      "step": 3800
    },
    {
      "epoch": 17.55889145496536,
      "grad_norm": 0.20403052866458893,
      "learning_rate": 0.0004923429467493398,
      "loss": 2.0205,
      "step": 3810
    },
    {
      "epoch": 17.605080831408777,
      "grad_norm": 0.2579505741596222,
      "learning_rate": 0.0004922977793889976,
      "loss": 2.0258,
      "step": 3820
    },
    {
      "epoch": 17.651270207852193,
      "grad_norm": 0.20810502767562866,
      "learning_rate": 0.0004922524812878135,
      "loss": 2.0096,
      "step": 3830
    },
    {
      "epoch": 17.69745958429561,
      "grad_norm": 0.24690896272659302,
      "learning_rate": 0.0004922070524702298,
      "loss": 2.0249,
      "step": 3840
    },
    {
      "epoch": 17.74364896073903,
      "grad_norm": 0.24668370187282562,
      "learning_rate": 0.0004921614929607595,
      "loss": 2.0263,
      "step": 3850
    },
    {
      "epoch": 17.78983833718245,
      "grad_norm": 0.2674816846847534,
      "learning_rate": 0.0004921158027839858,
      "loss": 2.0106,
      "step": 3860
    },
    {
      "epoch": 17.836027713625867,
      "grad_norm": 0.2732953131198883,
      "learning_rate": 0.0004920699819645626,
      "loss": 2.0319,
      "step": 3870
    },
    {
      "epoch": 17.882217090069283,
      "grad_norm": 0.2660897672176361,
      "learning_rate": 0.0004920240305272142,
      "loss": 2.0282,
      "step": 3880
    },
    {
      "epoch": 17.9284064665127,
      "grad_norm": 0.2848200798034668,
      "learning_rate": 0.0004919779484967354,
      "loss": 2.0214,
      "step": 3890
    },
    {
      "epoch": 17.97459584295612,
      "grad_norm": 0.25303152203559875,
      "learning_rate": 0.0004919317358979916,
      "loss": 2.0215,
      "step": 3900
    },
    {
      "epoch": 18.0,
      "eval_loss": 0.9870576858520508,
      "eval_runtime": 7.3384,
      "eval_samples_per_second": 3799.031,
      "eval_steps_per_second": 14.853,
      "step": 3906
    },
    {
      "epoch": 18.018475750577366,
      "grad_norm": 0.21730481088161469,
      "learning_rate": 0.0004918853927559183,
      "loss": 1.9282,
      "step": 3910
    },
    {
      "epoch": 18.064665127020785,
      "grad_norm": 0.2634812593460083,
      "learning_rate": 0.000491838919095522,
      "loss": 2.0206,
      "step": 3920
    },
    {
      "epoch": 18.110854503464203,
      "grad_norm": 0.2564983367919922,
      "learning_rate": 0.0004917923149418791,
      "loss": 2.02,
      "step": 3930
    },
    {
      "epoch": 18.157043879907622,
      "grad_norm": 0.2655017375946045,
      "learning_rate": 0.0004917455803201367,
      "loss": 2.0261,
      "step": 3940
    },
    {
      "epoch": 18.20323325635104,
      "grad_norm": 0.2746678590774536,
      "learning_rate": 0.0004916987152555122,
      "loss": 2.0309,
      "step": 3950
    },
    {
      "epoch": 18.249422632794456,
      "grad_norm": 0.24881213903427124,
      "learning_rate": 0.0004916517197732933,
      "loss": 2.0192,
      "step": 3960
    },
    {
      "epoch": 18.295612009237875,
      "grad_norm": 0.2557835280895233,
      "learning_rate": 0.0004916045938988383,
      "loss": 2.0212,
      "step": 3970
    },
    {
      "epoch": 18.341801385681293,
      "grad_norm": 0.26474177837371826,
      "learning_rate": 0.0004915573376575756,
      "loss": 2.0169,
      "step": 3980
    },
    {
      "epoch": 18.387990762124712,
      "grad_norm": 0.25215181708335876,
      "learning_rate": 0.0004915099510750042,
      "loss": 2.0249,
      "step": 3990
    },
    {
      "epoch": 18.43418013856813,
      "grad_norm": 0.24665498733520508,
      "learning_rate": 0.0004914624341766933,
      "loss": 2.0269,
      "step": 4000
    },
    {
      "epoch": 18.480369515011546,
      "grad_norm": 0.2284296303987503,
      "learning_rate": 0.0004914147869882824,
      "loss": 2.0178,
      "step": 4010
    },
    {
      "epoch": 18.526558891454965,
      "grad_norm": 0.24004781246185303,
      "learning_rate": 0.0004913670095354813,
      "loss": 2.0248,
      "step": 4020
    },
    {
      "epoch": 18.572748267898383,
      "grad_norm": 0.24294424057006836,
      "learning_rate": 0.00049131910184407,
      "loss": 2.0151,
      "step": 4030
    },
    {
      "epoch": 18.618937644341802,
      "grad_norm": 0.2356034219264984,
      "learning_rate": 0.0004912710639398992,
      "loss": 2.0228,
      "step": 4040
    },
    {
      "epoch": 18.66512702078522,
      "grad_norm": 0.2220873385667801,
      "learning_rate": 0.0004912228958488892,
      "loss": 2.0199,
      "step": 4050
    },
    {
      "epoch": 18.711316397228636,
      "grad_norm": 0.2636328339576721,
      "learning_rate": 0.0004911745975970311,
      "loss": 2.0312,
      "step": 4060
    },
    {
      "epoch": 18.757505773672055,
      "grad_norm": 0.23787279427051544,
      "learning_rate": 0.000491126169210386,
      "loss": 2.0297,
      "step": 4070
    },
    {
      "epoch": 18.803695150115473,
      "grad_norm": 0.2254074662923813,
      "learning_rate": 0.0004910776107150853,
      "loss": 2.0213,
      "step": 4080
    },
    {
      "epoch": 18.849884526558892,
      "grad_norm": 0.2154800295829773,
      "learning_rate": 0.0004910289221373304,
      "loss": 2.0081,
      "step": 4090
    },
    {
      "epoch": 18.89607390300231,
      "grad_norm": 0.2694009244441986,
      "learning_rate": 0.0004909801035033933,
      "loss": 2.0103,
      "step": 4100
    },
    {
      "epoch": 18.942263279445726,
      "grad_norm": 0.2473587840795517,
      "learning_rate": 0.0004909311548396156,
      "loss": 2.0145,
      "step": 4110
    },
    {
      "epoch": 18.988452655889144,
      "grad_norm": 0.22734785079956055,
      "learning_rate": 0.0004908820761724096,
      "loss": 2.0148,
      "step": 4120
    },
    {
      "epoch": 19.0,
      "eval_loss": 0.9877156615257263,
      "eval_runtime": 7.2377,
      "eval_samples_per_second": 3851.889,
      "eval_steps_per_second": 15.06,
      "step": 4123
    },
    {
      "epoch": 19.032332563510394,
      "grad_norm": 0.23951393365859985,
      "learning_rate": 0.0004908328675282575,
      "loss": 1.9171,
      "step": 4130
    },
    {
      "epoch": 19.07852193995381,
      "grad_norm": 0.28078797459602356,
      "learning_rate": 0.0004907835289337116,
      "loss": 2.0056,
      "step": 4140
    },
    {
      "epoch": 19.124711316397228,
      "grad_norm": 0.23510199785232544,
      "learning_rate": 0.0004907340604153945,
      "loss": 2.0189,
      "step": 4150
    },
    {
      "epoch": 19.170900692840647,
      "grad_norm": 0.289119690656662,
      "learning_rate": 0.0004906844619999987,
      "loss": 2.008,
      "step": 4160
    },
    {
      "epoch": 19.217090069284065,
      "grad_norm": 0.21866104006767273,
      "learning_rate": 0.0004906347337142869,
      "loss": 2.0109,
      "step": 4170
    },
    {
      "epoch": 19.263279445727484,
      "grad_norm": 0.25908583402633667,
      "learning_rate": 0.0004905848755850919,
      "loss": 2.0249,
      "step": 4180
    },
    {
      "epoch": 19.3094688221709,
      "grad_norm": 0.2550182640552521,
      "learning_rate": 0.0004905348876393164,
      "loss": 2.0237,
      "step": 4190
    },
    {
      "epoch": 19.355658198614318,
      "grad_norm": 0.26380455493927,
      "learning_rate": 0.0004904847699039334,
      "loss": 2.0129,
      "step": 4200
    },
    {
      "epoch": 19.401847575057737,
      "grad_norm": 0.23758243024349213,
      "learning_rate": 0.0004904345224059859,
      "loss": 2.0137,
      "step": 4210
    },
    {
      "epoch": 19.448036951501155,
      "grad_norm": 0.2692485451698303,
      "learning_rate": 0.0004903841451725865,
      "loss": 2.0224,
      "step": 4220
    },
    {
      "epoch": 19.494226327944574,
      "grad_norm": 0.33503907918930054,
      "learning_rate": 0.0004903336382309183,
      "loss": 2.0187,
      "step": 4230
    },
    {
      "epoch": 19.54041570438799,
      "grad_norm": 0.23909299075603485,
      "learning_rate": 0.0004902830016082344,
      "loss": 2.0184,
      "step": 4240
    },
    {
      "epoch": 19.586605080831408,
      "grad_norm": 0.2532329857349396,
      "learning_rate": 0.0004902322353318574,
      "loss": 2.0164,
      "step": 4250
    },
    {
      "epoch": 19.632794457274827,
      "grad_norm": 0.27657586336135864,
      "learning_rate": 0.0004901813394291801,
      "loss": 2.0274,
      "step": 4260
    },
    {
      "epoch": 19.678983833718245,
      "grad_norm": 0.2828240990638733,
      "learning_rate": 0.0004901303139276656,
      "loss": 2.0205,
      "step": 4270
    },
    {
      "epoch": 19.725173210161664,
      "grad_norm": 0.30030253529548645,
      "learning_rate": 0.0004900791588548464,
      "loss": 2.0203,
      "step": 4280
    },
    {
      "epoch": 19.77136258660508,
      "grad_norm": 0.376547634601593,
      "learning_rate": 0.0004900278742383252,
      "loss": 2.0271,
      "step": 4290
    },
    {
      "epoch": 19.817551963048498,
      "grad_norm": 0.32335081696510315,
      "learning_rate": 0.0004899764601057746,
      "loss": 2.0152,
      "step": 4300
    },
    {
      "epoch": 19.863741339491916,
      "grad_norm": 0.2538730502128601,
      "learning_rate": 0.0004899249164849369,
      "loss": 2.0283,
      "step": 4310
    },
    {
      "epoch": 19.909930715935335,
      "grad_norm": 0.27222371101379395,
      "learning_rate": 0.0004898732434036243,
      "loss": 2.0214,
      "step": 4320
    },
    {
      "epoch": 19.956120092378754,
      "grad_norm": 0.2672887146472931,
      "learning_rate": 0.0004898214408897192,
      "loss": 2.0277,
      "step": 4330
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.2179804891347885,
      "learning_rate": 0.0004897695089711735,
      "loss": 1.9134,
      "step": 4340
    },
    {
      "epoch": 20.0,
      "eval_loss": 0.9862393736839294,
      "eval_runtime": 6.8324,
      "eval_samples_per_second": 4080.404,
      "eval_steps_per_second": 15.953,
      "step": 4340
    },
    {
      "epoch": 20.04618937644342,
      "grad_norm": 0.2739851772785187,
      "learning_rate": 0.000489717447676009,
      "loss": 2.0189,
      "step": 4350
    },
    {
      "epoch": 20.092378752886837,
      "grad_norm": 0.2600918114185333,
      "learning_rate": 0.0004896652570323173,
      "loss": 2.0118,
      "step": 4360
    },
    {
      "epoch": 20.138568129330253,
      "grad_norm": 0.3714962303638458,
      "learning_rate": 0.0004896129370682598,
      "loss": 2.0101,
      "step": 4370
    },
    {
      "epoch": 20.18475750577367,
      "grad_norm": 0.2572081983089447,
      "learning_rate": 0.0004895604878120678,
      "loss": 2.0153,
      "step": 4380
    },
    {
      "epoch": 20.23094688221709,
      "grad_norm": 0.34442079067230225,
      "learning_rate": 0.0004895079092920421,
      "loss": 2.009,
      "step": 4390
    },
    {
      "epoch": 20.27713625866051,
      "grad_norm": 0.31108853220939636,
      "learning_rate": 0.0004894552015365535,
      "loss": 2.0196,
      "step": 4400
    },
    {
      "epoch": 20.323325635103927,
      "grad_norm": 0.2962687909603119,
      "learning_rate": 0.0004894023645740423,
      "loss": 2.0222,
      "step": 4410
    },
    {
      "epoch": 20.369515011547342,
      "grad_norm": 0.30217599868774414,
      "learning_rate": 0.0004893493984330189,
      "loss": 2.0212,
      "step": 4420
    },
    {
      "epoch": 20.41570438799076,
      "grad_norm": 0.28343892097473145,
      "learning_rate": 0.0004892963031420631,
      "loss": 2.0184,
      "step": 4430
    },
    {
      "epoch": 20.46189376443418,
      "grad_norm": 0.2831927537918091,
      "learning_rate": 0.0004892430787298244,
      "loss": 2.0229,
      "step": 4440
    },
    {
      "epoch": 20.5080831408776,
      "grad_norm": 0.23800791800022125,
      "learning_rate": 0.0004891897252250221,
      "loss": 2.0237,
      "step": 4450
    },
    {
      "epoch": 20.554272517321017,
      "grad_norm": 0.35455322265625,
      "learning_rate": 0.0004891362426564449,
      "loss": 2.0248,
      "step": 4460
    },
    {
      "epoch": 20.600461893764432,
      "grad_norm": 0.2228461354970932,
      "learning_rate": 0.0004890826310529515,
      "loss": 2.0135,
      "step": 4470
    },
    {
      "epoch": 20.64665127020785,
      "grad_norm": 0.28460824489593506,
      "learning_rate": 0.0004890288904434699,
      "loss": 2.013,
      "step": 4480
    },
    {
      "epoch": 20.69284064665127,
      "grad_norm": 0.25528600811958313,
      "learning_rate": 0.0004889750208569981,
      "loss": 2.0181,
      "step": 4490
    },
    {
      "epoch": 20.73903002309469,
      "grad_norm": 0.2317097932100296,
      "learning_rate": 0.0004889210223226032,
      "loss": 2.0158,
      "step": 4500
    },
    {
      "epoch": 20.785219399538107,
      "grad_norm": 0.2640179991722107,
      "learning_rate": 0.0004888668948694223,
      "loss": 2.0198,
      "step": 4510
    },
    {
      "epoch": 20.831408775981526,
      "grad_norm": 0.23044857382774353,
      "learning_rate": 0.0004888126385266617,
      "loss": 2.0133,
      "step": 4520
    },
    {
      "epoch": 20.87759815242494,
      "grad_norm": 0.311641663312912,
      "learning_rate": 0.0004887582533235977,
      "loss": 2.0184,
      "step": 4530
    },
    {
      "epoch": 20.92378752886836,
      "grad_norm": 0.309631884098053,
      "learning_rate": 0.0004887037392895757,
      "loss": 2.0135,
      "step": 4540
    },
    {
      "epoch": 20.96997690531178,
      "grad_norm": 0.33259469270706177,
      "learning_rate": 0.0004886490964540109,
      "loss": 2.0145,
      "step": 4550
    },
    {
      "epoch": 21.0,
      "eval_loss": 0.9858778715133667,
      "eval_runtime": 6.821,
      "eval_samples_per_second": 4087.234,
      "eval_steps_per_second": 15.98,
      "step": 4557
    },
    {
      "epoch": 21.013856812933025,
      "grad_norm": 0.3679179847240448,
      "learning_rate": 0.0004885943248463878,
      "loss": 1.9186,
      "step": 4560
    },
    {
      "epoch": 21.060046189376443,
      "grad_norm": 0.34991103410720825,
      "learning_rate": 0.0004885394244962605,
      "loss": 2.0092,
      "step": 4570
    },
    {
      "epoch": 21.106235565819862,
      "grad_norm": 0.3595522940158844,
      "learning_rate": 0.0004884843954332524,
      "loss": 2.0204,
      "step": 4580
    },
    {
      "epoch": 21.15242494226328,
      "grad_norm": 0.29162150621414185,
      "learning_rate": 0.0004884292376870567,
      "loss": 2.0126,
      "step": 4590
    },
    {
      "epoch": 21.198614318706696,
      "grad_norm": 0.2841891348361969,
      "learning_rate": 0.0004883739512874358,
      "loss": 2.0116,
      "step": 4600
    },
    {
      "epoch": 21.244803695150114,
      "grad_norm": 0.23704639077186584,
      "learning_rate": 0.0004883185362642215,
      "loss": 2.023,
      "step": 4610
    },
    {
      "epoch": 21.290993071593533,
      "grad_norm": 0.248496413230896,
      "learning_rate": 0.000488262992647315,
      "loss": 2.023,
      "step": 4620
    },
    {
      "epoch": 21.337182448036952,
      "grad_norm": 0.2629351317882538,
      "learning_rate": 0.00048820732046668704,
      "loss": 2.0111,
      "step": 4630
    },
    {
      "epoch": 21.38337182448037,
      "grad_norm": 0.28845155239105225,
      "learning_rate": 0.00048815151975237757,
      "loss": 2.0144,
      "step": 4640
    },
    {
      "epoch": 21.42956120092379,
      "grad_norm": 0.23667755722999573,
      "learning_rate": 0.000488095590534496,
      "loss": 2.0122,
      "step": 4650
    },
    {
      "epoch": 21.475750577367204,
      "grad_norm": 0.29995498061180115,
      "learning_rate": 0.00048803953284322094,
      "loss": 2.0108,
      "step": 4660
    },
    {
      "epoch": 21.521939953810623,
      "grad_norm": 0.24640212953090668,
      "learning_rate": 0.0004879833467088005,
      "loss": 2.0242,
      "step": 4670
    },
    {
      "epoch": 21.56812933025404,
      "grad_norm": 0.22584857046604156,
      "learning_rate": 0.000487927032161552,
      "loss": 2.0074,
      "step": 4680
    },
    {
      "epoch": 21.61431870669746,
      "grad_norm": 0.3002641499042511,
      "learning_rate": 0.000487870589231862,
      "loss": 2.0109,
      "step": 4690
    },
    {
      "epoch": 21.66050808314088,
      "grad_norm": 0.2661297619342804,
      "learning_rate": 0.0004878140179501865,
      "loss": 2.0129,
      "step": 4700
    },
    {
      "epoch": 21.706697459584294,
      "grad_norm": 0.27790766954421997,
      "learning_rate": 0.0004877573183470506,
      "loss": 2.0204,
      "step": 4710
    },
    {
      "epoch": 21.752886836027713,
      "grad_norm": 0.3113383948802948,
      "learning_rate": 0.00048770049045304876,
      "loss": 2.003,
      "step": 4720
    },
    {
      "epoch": 21.79907621247113,
      "grad_norm": 0.3139471411705017,
      "learning_rate": 0.00048764353429884443,
      "loss": 2.0193,
      "step": 4730
    },
    {
      "epoch": 21.84526558891455,
      "grad_norm": 0.24581529200077057,
      "learning_rate": 0.00048758644991517063,
      "loss": 2.0193,
      "step": 4740
    },
    {
      "epoch": 21.89145496535797,
      "grad_norm": 0.2591556906700134,
      "learning_rate": 0.0004875292373328293,
      "loss": 2.0195,
      "step": 4750
    },
    {
      "epoch": 21.937644341801384,
      "grad_norm": 0.3315725326538086,
      "learning_rate": 0.00048747189658269156,
      "loss": 2.0041,
      "step": 4760
    },
    {
      "epoch": 21.983833718244803,
      "grad_norm": 0.26045697927474976,
      "learning_rate": 0.0004874144276956979,
      "loss": 2.0068,
      "step": 4770
    },
    {
      "epoch": 22.0,
      "eval_loss": 0.9860094785690308,
      "eval_runtime": 6.8314,
      "eval_samples_per_second": 4081.021,
      "eval_steps_per_second": 15.956,
      "step": 4774
    },
    {
      "epoch": 22.02771362586605,
      "grad_norm": 0.278956800699234,
      "learning_rate": 0.0004873568307028576,
      "loss": 1.9027,
      "step": 4780
    },
    {
      "epoch": 22.073903002309468,
      "grad_norm": 0.256036639213562,
      "learning_rate": 0.00048729910563524953,
      "loss": 2.0062,
      "step": 4790
    },
    {
      "epoch": 22.120092378752886,
      "grad_norm": 0.26721861958503723,
      "learning_rate": 0.00048724125252402124,
      "loss": 2.0164,
      "step": 4800
    },
    {
      "epoch": 22.166281755196305,
      "grad_norm": 0.25828877091407776,
      "learning_rate": 0.00048718327140038966,
      "loss": 2.0106,
      "step": 4810
    },
    {
      "epoch": 22.212471131639724,
      "grad_norm": 0.29027560353279114,
      "learning_rate": 0.0004871251622956405,
      "loss": 2.022,
      "step": 4820
    },
    {
      "epoch": 22.258660508083143,
      "grad_norm": 0.26357343792915344,
      "learning_rate": 0.00048706692524112886,
      "loss": 2.0076,
      "step": 4830
    },
    {
      "epoch": 22.304849884526558,
      "grad_norm": 0.26174166798591614,
      "learning_rate": 0.00048700856026827864,
      "loss": 2.0092,
      "step": 4840
    },
    {
      "epoch": 22.351039260969976,
      "grad_norm": 0.24935173988342285,
      "learning_rate": 0.000486950067408583,
      "loss": 2.0109,
      "step": 4850
    },
    {
      "epoch": 22.397228637413395,
      "grad_norm": 0.23572319746017456,
      "learning_rate": 0.00048689144669360375,
      "loss": 2.0076,
      "step": 4860
    },
    {
      "epoch": 22.443418013856814,
      "grad_norm": 0.29501089453697205,
      "learning_rate": 0.000486832698154972,
      "loss": 2.0086,
      "step": 4870
    },
    {
      "epoch": 22.489607390300232,
      "grad_norm": 0.2631731927394867,
      "learning_rate": 0.0004867738218243877,
      "loss": 2.0087,
      "step": 4880
    },
    {
      "epoch": 22.535796766743648,
      "grad_norm": 0.26222458481788635,
      "learning_rate": 0.0004867148177336198,
      "loss": 2.0139,
      "step": 4890
    },
    {
      "epoch": 22.581986143187066,
      "grad_norm": 0.2721031606197357,
      "learning_rate": 0.00048665568591450614,
      "loss": 2.0098,
      "step": 4900
    },
    {
      "epoch": 22.628175519630485,
      "grad_norm": 0.258060485124588,
      "learning_rate": 0.00048659642639895353,
      "loss": 2.0145,
      "step": 4910
    },
    {
      "epoch": 22.674364896073904,
      "grad_norm": 0.2696860432624817,
      "learning_rate": 0.00048653703921893766,
      "loss": 2.0179,
      "step": 4920
    },
    {
      "epoch": 22.720554272517322,
      "grad_norm": 0.2952954173088074,
      "learning_rate": 0.00048647752440650306,
      "loss": 2.0144,
      "step": 4930
    },
    {
      "epoch": 22.766743648960738,
      "grad_norm": 0.31885576248168945,
      "learning_rate": 0.0004864178819937632,
      "loss": 2.0047,
      "step": 4940
    },
    {
      "epoch": 22.812933025404156,
      "grad_norm": 0.27786746621131897,
      "learning_rate": 0.0004863581120129004,
      "loss": 2.0219,
      "step": 4950
    },
    {
      "epoch": 22.859122401847575,
      "grad_norm": 0.3027372658252716,
      "learning_rate": 0.00048629821449616586,
      "loss": 2.0181,
      "step": 4960
    },
    {
      "epoch": 22.905311778290994,
      "grad_norm": 0.2945486605167389,
      "learning_rate": 0.0004862381894758794,
      "loss": 2.0049,
      "step": 4970
    },
    {
      "epoch": 22.951501154734412,
      "grad_norm": 0.294484943151474,
      "learning_rate": 0.00048617803698442977,
      "loss": 2.013,
      "step": 4980
    },
    {
      "epoch": 22.997690531177827,
      "grad_norm": 0.25900134444236755,
      "learning_rate": 0.0004861177570542746,
      "loss": 2.009,
      "step": 4990
    },
    {
      "epoch": 23.0,
      "eval_loss": 0.9854586720466614,
      "eval_runtime": 6.823,
      "eval_samples_per_second": 4086.03,
      "eval_steps_per_second": 15.975,
      "step": 4991
    },
    {
      "epoch": 23.041570438799077,
      "grad_norm": 0.2466290444135666,
      "learning_rate": 0.0004860573497179401,
      "loss": 1.9102,
      "step": 5000
    },
    {
      "epoch": 23.087759815242496,
      "grad_norm": 0.23434975743293762,
      "learning_rate": 0.0004859968150080214,
      "loss": 2.0185,
      "step": 5010
    },
    {
      "epoch": 23.13394919168591,
      "grad_norm": 0.2433975785970688,
      "learning_rate": 0.0004859361529571822,
      "loss": 2.0072,
      "step": 5020
    },
    {
      "epoch": 23.18013856812933,
      "grad_norm": 0.2797616422176361,
      "learning_rate": 0.000485875363598155,
      "loss": 2.0021,
      "step": 5030
    },
    {
      "epoch": 23.22632794457275,
      "grad_norm": 0.22881045937538147,
      "learning_rate": 0.00048581444696374086,
      "loss": 2.0127,
      "step": 5040
    },
    {
      "epoch": 23.272517321016167,
      "grad_norm": 0.2480306327342987,
      "learning_rate": 0.00048575340308680987,
      "loss": 2.0047,
      "step": 5050
    },
    {
      "epoch": 23.318706697459586,
      "grad_norm": 0.22379833459854126,
      "learning_rate": 0.0004856922320003004,
      "loss": 1.9985,
      "step": 5060
    },
    {
      "epoch": 23.364896073903,
      "grad_norm": 0.2615097165107727,
      "learning_rate": 0.00048563093373721957,
      "loss": 1.9993,
      "step": 5070
    },
    {
      "epoch": 23.41108545034642,
      "grad_norm": 0.2643035352230072,
      "learning_rate": 0.0004855695083306432,
      "loss": 2.0094,
      "step": 5080
    },
    {
      "epoch": 23.45727482678984,
      "grad_norm": 0.26498663425445557,
      "learning_rate": 0.00048550795581371565,
      "loss": 2.0053,
      "step": 5090
    },
    {
      "epoch": 23.503464203233257,
      "grad_norm": 0.3348544239997864,
      "learning_rate": 0.00048544627621964996,
      "loss": 2.0158,
      "step": 5100
    },
    {
      "epoch": 23.549653579676676,
      "grad_norm": 0.3065654933452606,
      "learning_rate": 0.00048538446958172756,
      "loss": 2.0085,
      "step": 5110
    },
    {
      "epoch": 23.59584295612009,
      "grad_norm": 0.3162863552570343,
      "learning_rate": 0.0004853225359332986,
      "loss": 2.0155,
      "step": 5120
    },
    {
      "epoch": 23.64203233256351,
      "grad_norm": 0.3718910217285156,
      "learning_rate": 0.00048526047530778174,
      "loss": 2.0197,
      "step": 5130
    },
    {
      "epoch": 23.68822170900693,
      "grad_norm": 0.2680281698703766,
      "learning_rate": 0.000485198287738664,
      "loss": 2.0139,
      "step": 5140
    },
    {
      "epoch": 23.734411085450347,
      "grad_norm": 0.2941741347312927,
      "learning_rate": 0.000485135973259501,
      "loss": 2.0229,
      "step": 5150
    },
    {
      "epoch": 23.780600461893766,
      "grad_norm": 0.3261779844760895,
      "learning_rate": 0.000485073531903917,
      "loss": 2.0093,
      "step": 5160
    },
    {
      "epoch": 23.82678983833718,
      "grad_norm": 0.3200162351131439,
      "learning_rate": 0.0004850109637056045,
      "loss": 2.0028,
      "step": 5170
    },
    {
      "epoch": 23.8729792147806,
      "grad_norm": 0.2643745541572571,
      "learning_rate": 0.0004849482686983245,
      "loss": 2.0074,
      "step": 5180
    },
    {
      "epoch": 23.919168591224018,
      "grad_norm": 0.3388506770133972,
      "learning_rate": 0.0004848854469159064,
      "loss": 2.0127,
      "step": 5190
    },
    {
      "epoch": 23.965357967667437,
      "grad_norm": 0.41108524799346924,
      "learning_rate": 0.0004848224983922482,
      "loss": 2.0084,
      "step": 5200
    },
    {
      "epoch": 24.0,
      "eval_loss": 0.9849853515625,
      "eval_runtime": 6.9121,
      "eval_samples_per_second": 4033.368,
      "eval_steps_per_second": 15.769,
      "step": 5208
    },
    {
      "epoch": 24.009237875288683,
      "grad_norm": 0.3097437918186188,
      "learning_rate": 0.00048475942316131596,
      "loss": 1.9086,
      "step": 5210
    },
    {
      "epoch": 24.0554272517321,
      "grad_norm": 0.3100169897079468,
      "learning_rate": 0.0004846962212571443,
      "loss": 2.0079,
      "step": 5220
    },
    {
      "epoch": 24.10161662817552,
      "grad_norm": 0.284156858921051,
      "learning_rate": 0.0004846328927138363,
      "loss": 2.0051,
      "step": 5230
    },
    {
      "epoch": 24.14780600461894,
      "grad_norm": 0.26652979850769043,
      "learning_rate": 0.00048456943756556317,
      "loss": 2.0101,
      "step": 5240
    },
    {
      "epoch": 24.193995381062354,
      "grad_norm": 0.285654753446579,
      "learning_rate": 0.0004845058558465645,
      "loss": 2.0057,
      "step": 5250
    },
    {
      "epoch": 24.240184757505773,
      "grad_norm": 0.30398496985435486,
      "learning_rate": 0.00048444214759114815,
      "loss": 2.0088,
      "step": 5260
    },
    {
      "epoch": 24.28637413394919,
      "grad_norm": 0.32772529125213623,
      "learning_rate": 0.00048437831283369037,
      "loss": 1.9876,
      "step": 5270
    },
    {
      "epoch": 24.33256351039261,
      "grad_norm": 0.5027399063110352,
      "learning_rate": 0.00048431435160863556,
      "loss": 2.0044,
      "step": 5280
    },
    {
      "epoch": 24.37875288683603,
      "grad_norm": 0.2750001549720764,
      "learning_rate": 0.0004842502639504965,
      "loss": 2.0134,
      "step": 5290
    },
    {
      "epoch": 24.424942263279444,
      "grad_norm": 0.3028041422367096,
      "learning_rate": 0.0004841860498938539,
      "loss": 2.0164,
      "step": 5300
    },
    {
      "epoch": 24.471131639722863,
      "grad_norm": 0.2691124975681305,
      "learning_rate": 0.00048412170947335697,
      "loss": 2.0065,
      "step": 5310
    },
    {
      "epoch": 24.51732101616628,
      "grad_norm": 1.023010492324829,
      "learning_rate": 0.000484057242723723,
      "loss": 2.0132,
      "step": 5320
    },
    {
      "epoch": 24.5635103926097,
      "grad_norm": 0.3628580570220947,
      "learning_rate": 0.00048399264967973735,
      "loss": 2.0064,
      "step": 5330
    },
    {
      "epoch": 24.60969976905312,
      "grad_norm": 0.28614526987075806,
      "learning_rate": 0.00048392793037625373,
      "loss": 2.0022,
      "step": 5340
    },
    {
      "epoch": 24.655889145496534,
      "grad_norm": 0.40811657905578613,
      "learning_rate": 0.00048386308484819386,
      "loss": 2.0027,
      "step": 5350
    },
    {
      "epoch": 24.702078521939953,
      "grad_norm": 0.3733631372451782,
      "learning_rate": 0.00048379811313054743,
      "loss": 2.0189,
      "step": 5360
    },
    {
      "epoch": 24.74826789838337,
      "grad_norm": 0.3197111189365387,
      "learning_rate": 0.00048373301525837255,
      "loss": 2.0171,
      "step": 5370
    },
    {
      "epoch": 24.79445727482679,
      "grad_norm": 0.38866937160491943,
      "learning_rate": 0.00048366779126679505,
      "loss": 2.008,
      "step": 5380
    },
    {
      "epoch": 24.84064665127021,
      "grad_norm": 0.5691138505935669,
      "learning_rate": 0.00048360244119100904,
      "loss": 2.0039,
      "step": 5390
    },
    {
      "epoch": 24.886836027713628,
      "grad_norm": 0.30719152092933655,
      "learning_rate": 0.0004835369650662767,
      "loss": 2.0069,
      "step": 5400
    },
    {
      "epoch": 24.933025404157043,
      "grad_norm": 0.32241949439048767,
      "learning_rate": 0.00048347136292792796,
      "loss": 2.0172,
      "step": 5410
    },
    {
      "epoch": 24.97921478060046,
      "grad_norm": 0.3490864634513855,
      "learning_rate": 0.0004834056348113611,
      "loss": 2.012,
      "step": 5420
    },
    {
      "epoch": 25.0,
      "eval_loss": 0.9854236841201782,
      "eval_runtime": 6.8288,
      "eval_samples_per_second": 4082.583,
      "eval_steps_per_second": 15.962,
      "step": 5425
    },
    {
      "epoch": 25.023094688221708,
      "grad_norm": 0.3055857717990875,
      "learning_rate": 0.000483339780752042,
      "loss": 1.8972,
      "step": 5430
    },
    {
      "epoch": 25.069284064665126,
      "grad_norm": 0.38960397243499756,
      "learning_rate": 0.00048327380078550474,
      "loss": 2.0149,
      "step": 5440
    },
    {
      "epoch": 25.115473441108545,
      "grad_norm": 0.3394649922847748,
      "learning_rate": 0.00048320769494735133,
      "loss": 1.9968,
      "step": 5450
    },
    {
      "epoch": 25.161662817551964,
      "grad_norm": 0.44696083664894104,
      "learning_rate": 0.00048314146327325166,
      "loss": 2.0179,
      "step": 5460
    },
    {
      "epoch": 25.207852193995382,
      "grad_norm": 0.393999844789505,
      "learning_rate": 0.0004830751057989434,
      "loss": 2.016,
      "step": 5470
    },
    {
      "epoch": 25.254041570438797,
      "grad_norm": 0.48279324173927307,
      "learning_rate": 0.00048300862256023236,
      "loss": 1.9965,
      "step": 5480
    },
    {
      "epoch": 25.300230946882216,
      "grad_norm": 0.38980770111083984,
      "learning_rate": 0.00048294201359299195,
      "loss": 2.005,
      "step": 5490
    },
    {
      "epoch": 25.346420323325635,
      "grad_norm": 0.46736764907836914,
      "learning_rate": 0.00048287527893316364,
      "loss": 2.0072,
      "step": 5500
    },
    {
      "epoch": 25.392609699769054,
      "grad_norm": 0.36131972074508667,
      "learning_rate": 0.0004828084186167564,
      "loss": 2.0047,
      "step": 5510
    },
    {
      "epoch": 25.438799076212472,
      "grad_norm": 0.4495564103126526,
      "learning_rate": 0.0004827414326798475,
      "loss": 2.0078,
      "step": 5520
    },
    {
      "epoch": 25.484988452655887,
      "grad_norm": 0.3930339813232422,
      "learning_rate": 0.0004826743211585815,
      "loss": 2.0097,
      "step": 5530
    },
    {
      "epoch": 25.531177829099306,
      "grad_norm": 0.4119154214859009,
      "learning_rate": 0.0004826070840891711,
      "loss": 2.007,
      "step": 5540
    },
    {
      "epoch": 25.577367205542725,
      "grad_norm": 0.34536638855934143,
      "learning_rate": 0.0004825397215078964,
      "loss": 1.999,
      "step": 5550
    },
    {
      "epoch": 25.623556581986143,
      "grad_norm": 0.30321040749549866,
      "learning_rate": 0.00048247223345110546,
      "loss": 2.0074,
      "step": 5560
    },
    {
      "epoch": 25.669745958429562,
      "grad_norm": 0.2826947569847107,
      "learning_rate": 0.00048240461995521414,
      "loss": 2.01,
      "step": 5570
    },
    {
      "epoch": 25.71593533487298,
      "grad_norm": 0.29338306188583374,
      "learning_rate": 0.0004823368810567056,
      "loss": 2.0059,
      "step": 5580
    },
    {
      "epoch": 25.762124711316396,
      "grad_norm": 0.294445663690567,
      "learning_rate": 0.00048226901679213107,
      "loss": 2.0088,
      "step": 5590
    },
    {
      "epoch": 25.808314087759815,
      "grad_norm": 0.28742486238479614,
      "learning_rate": 0.0004822010271981092,
      "loss": 2.01,
      "step": 5600
    },
    {
      "epoch": 25.854503464203233,
      "grad_norm": 0.31010714173316956,
      "learning_rate": 0.00048213291231132634,
      "loss": 2.0179,
      "step": 5610
    },
    {
      "epoch": 25.900692840646652,
      "grad_norm": 0.3865293264389038,
      "learning_rate": 0.00048206467216853636,
      "loss": 2.0091,
      "step": 5620
    },
    {
      "epoch": 25.94688221709007,
      "grad_norm": 0.3345126509666443,
      "learning_rate": 0.00048199630680656095,
      "loss": 1.9999,
      "step": 5630
    },
    {
      "epoch": 25.993071593533486,
      "grad_norm": 0.31453272700309753,
      "learning_rate": 0.000481927816262289,
      "loss": 2.0033,
      "step": 5640
    },
    {
      "epoch": 26.0,
      "eval_loss": 0.9836482405662537,
      "eval_runtime": 6.8235,
      "eval_samples_per_second": 4085.713,
      "eval_steps_per_second": 15.974,
      "step": 5642
    },
    {
      "epoch": 26.036951501154736,
      "grad_norm": 0.9247786998748779,
      "learning_rate": 0.0004818592005726772,
      "loss": 1.9124,
      "step": 5650
    },
    {
      "epoch": 26.08314087759815,
      "grad_norm": 0.3612082898616791,
      "learning_rate": 0.0004817904597747498,
      "loss": 2.0088,
      "step": 5660
    },
    {
      "epoch": 26.12933025404157,
      "grad_norm": 0.3553757667541504,
      "learning_rate": 0.0004817215939055984,
      "loss": 1.9967,
      "step": 5670
    },
    {
      "epoch": 26.175519630484988,
      "grad_norm": 0.3153916597366333,
      "learning_rate": 0.00048165260300238224,
      "loss": 2.0019,
      "step": 5680
    },
    {
      "epoch": 26.221709006928407,
      "grad_norm": 0.32786816358566284,
      "learning_rate": 0.0004815834871023278,
      "loss": 1.9983,
      "step": 5690
    },
    {
      "epoch": 26.267898383371826,
      "grad_norm": 0.29661592841148376,
      "learning_rate": 0.00048151424624272933,
      "loss": 2.0035,
      "step": 5700
    },
    {
      "epoch": 26.314087759815244,
      "grad_norm": 0.2539767026901245,
      "learning_rate": 0.0004814448804609482,
      "loss": 2.006,
      "step": 5710
    },
    {
      "epoch": 26.36027713625866,
      "grad_norm": 0.33396223187446594,
      "learning_rate": 0.0004813753897944133,
      "loss": 2.0064,
      "step": 5720
    },
    {
      "epoch": 26.406466512702078,
      "grad_norm": 0.33962777256965637,
      "learning_rate": 0.0004813057742806211,
      "loss": 2.0044,
      "step": 5730
    },
    {
      "epoch": 26.452655889145497,
      "grad_norm": 0.3112996518611908,
      "learning_rate": 0.0004812360339571351,
      "loss": 1.9947,
      "step": 5740
    },
    {
      "epoch": 26.498845265588916,
      "grad_norm": 0.2648254334926605,
      "learning_rate": 0.0004811661688615863,
      "loss": 2.0026,
      "step": 5750
    },
    {
      "epoch": 26.545034642032334,
      "grad_norm": 0.29853788018226624,
      "learning_rate": 0.00048109617903167303,
      "loss": 2.0075,
      "step": 5760
    },
    {
      "epoch": 26.59122401847575,
      "grad_norm": 0.31396955251693726,
      "learning_rate": 0.00048102606450516094,
      "loss": 2.0052,
      "step": 5770
    },
    {
      "epoch": 26.637413394919168,
      "grad_norm": 0.2919415831565857,
      "learning_rate": 0.00048095582531988305,
      "loss": 2.0056,
      "step": 5780
    },
    {
      "epoch": 26.683602771362587,
      "grad_norm": 0.29134121537208557,
      "learning_rate": 0.00048088546151373946,
      "loss": 2.0056,
      "step": 5790
    },
    {
      "epoch": 26.729792147806005,
      "grad_norm": 0.2879268527030945,
      "learning_rate": 0.00048081497312469756,
      "loss": 2.0137,
      "step": 5800
    },
    {
      "epoch": 26.775981524249424,
      "grad_norm": 0.5228953957557678,
      "learning_rate": 0.00048074436019079214,
      "loss": 2.0028,
      "step": 5810
    },
    {
      "epoch": 26.82217090069284,
      "grad_norm": 0.28975388407707214,
      "learning_rate": 0.00048067362275012483,
      "loss": 2.0109,
      "step": 5820
    },
    {
      "epoch": 26.868360277136258,
      "grad_norm": 0.24312487244606018,
      "learning_rate": 0.00048060276084086487,
      "loss": 2.0087,
      "step": 5830
    },
    {
      "epoch": 26.914549653579677,
      "grad_norm": 0.3151874244213104,
      "learning_rate": 0.00048053177450124837,
      "loss": 1.999,
      "step": 5840
    },
    {
      "epoch": 26.960739030023095,
      "grad_norm": 0.37045904994010925,
      "learning_rate": 0.0004804606637695786,
      "loss": 2.0057,
      "step": 5850
    },
    {
      "epoch": 27.0,
      "eval_loss": 0.9834030866622925,
      "eval_runtime": 6.7978,
      "eval_samples_per_second": 4101.159,
      "eval_steps_per_second": 16.035,
      "step": 5859
    },
    {
      "epoch": 27.00461893764434,
      "grad_norm": 0.33156514167785645,
      "learning_rate": 0.0004803894286842262,
      "loss": 1.9001,
      "step": 5860
    },
    {
      "epoch": 27.05080831408776,
      "grad_norm": 0.29784345626831055,
      "learning_rate": 0.0004803180692836285,
      "loss": 1.9939,
      "step": 5870
    },
    {
      "epoch": 27.09699769053118,
      "grad_norm": 0.2948756515979767,
      "learning_rate": 0.00048024658560629044,
      "loss": 1.9987,
      "step": 5880
    },
    {
      "epoch": 27.143187066974598,
      "grad_norm": 0.37934601306915283,
      "learning_rate": 0.0004801749776907834,
      "loss": 1.9993,
      "step": 5890
    },
    {
      "epoch": 27.189376443418013,
      "grad_norm": 0.30975085496902466,
      "learning_rate": 0.00048010324557574627,
      "loss": 2.0011,
      "step": 5900
    },
    {
      "epoch": 27.23556581986143,
      "grad_norm": 0.24636946618556976,
      "learning_rate": 0.00048003138929988477,
      "loss": 1.9896,
      "step": 5910
    },
    {
      "epoch": 27.28175519630485,
      "grad_norm": 0.2843029201030731,
      "learning_rate": 0.00047995940890197165,
      "loss": 2.0047,
      "step": 5920
    },
    {
      "epoch": 27.32794457274827,
      "grad_norm": 0.28154027462005615,
      "learning_rate": 0.0004798873044208466,
      "loss": 1.9954,
      "step": 5930
    },
    {
      "epoch": 27.374133949191688,
      "grad_norm": 0.2977181077003479,
      "learning_rate": 0.0004798150758954164,
      "loss": 2.0124,
      "step": 5940
    },
    {
      "epoch": 27.420323325635103,
      "grad_norm": 0.3096396327018738,
      "learning_rate": 0.00047974272336465454,
      "loss": 2.0003,
      "step": 5950
    },
    {
      "epoch": 27.46651270207852,
      "grad_norm": 0.3111138939857483,
      "learning_rate": 0.00047967024686760163,
      "loss": 2.0038,
      "step": 5960
    },
    {
      "epoch": 27.51270207852194,
      "grad_norm": 0.3244519531726837,
      "learning_rate": 0.00047959764644336494,
      "loss": 1.9929,
      "step": 5970
    },
    {
      "epoch": 27.55889145496536,
      "grad_norm": 0.36963894963264465,
      "learning_rate": 0.00047952492213111886,
      "loss": 2.013,
      "step": 5980
    },
    {
      "epoch": 27.605080831408777,
      "grad_norm": 0.3636731803417206,
      "learning_rate": 0.00047945207397010457,
      "loss": 2.0105,
      "step": 5990
    },
    {
      "epoch": 27.651270207852193,
      "grad_norm": 0.2959941625595093,
      "learning_rate": 0.00047937910199962987,
      "loss": 1.9918,
      "step": 6000
    },
    {
      "epoch": 27.69745958429561,
      "grad_norm": 0.3390125632286072,
      "learning_rate": 0.00047930600625906963,
      "loss": 1.9988,
      "step": 6010
    },
    {
      "epoch": 27.74364896073903,
      "grad_norm": 0.4553549289703369,
      "learning_rate": 0.0004792327867878653,
      "loss": 1.9933,
      "step": 6020
    },
    {
      "epoch": 27.78983833718245,
      "grad_norm": 0.4081546664237976,
      "learning_rate": 0.0004791594436255253,
      "loss": 2.0018,
      "step": 6030
    },
    {
      "epoch": 27.836027713625867,
      "grad_norm": 0.3069152534008026,
      "learning_rate": 0.00047908597681162456,
      "loss": 2.0071,
      "step": 6040
    },
    {
      "epoch": 27.882217090069283,
      "grad_norm": 0.3157463073730469,
      "learning_rate": 0.00047901238638580504,
      "loss": 2.0124,
      "step": 6050
    },
    {
      "epoch": 27.9284064665127,
      "grad_norm": 0.32186874747276306,
      "learning_rate": 0.000478938672387775,
      "loss": 2.0194,
      "step": 6060
    },
    {
      "epoch": 27.97459584295612,
      "grad_norm": 0.2968197464942932,
      "learning_rate": 0.0004788648348573097,
      "loss": 2.0027,
      "step": 6070
    },
    {
      "epoch": 28.0,
      "eval_loss": 0.9825676083564758,
      "eval_runtime": 6.833,
      "eval_samples_per_second": 4080.079,
      "eval_steps_per_second": 15.952,
      "step": 6076
    },
    {
      "epoch": 28.018475750577366,
      "grad_norm": 0.3476946949958801,
      "learning_rate": 0.00047879087383425093,
      "loss": 1.895,
      "step": 6080
    },
    {
      "epoch": 28.064665127020785,
      "grad_norm": 0.34424668550491333,
      "learning_rate": 0.0004787167893585072,
      "loss": 1.9901,
      "step": 6090
    },
    {
      "epoch": 28.110854503464203,
      "grad_norm": 0.5898224115371704,
      "learning_rate": 0.00047864258147005336,
      "loss": 1.9966,
      "step": 6100
    },
    {
      "epoch": 28.157043879907622,
      "grad_norm": 0.4289521872997284,
      "learning_rate": 0.00047856825020893117,
      "loss": 2.004,
      "step": 6110
    },
    {
      "epoch": 28.20323325635104,
      "grad_norm": 0.38827943801879883,
      "learning_rate": 0.00047849379561524895,
      "loss": 2.0008,
      "step": 6120
    },
    {
      "epoch": 28.249422632794456,
      "grad_norm": 0.8047808408737183,
      "learning_rate": 0.00047841921772918137,
      "loss": 1.9994,
      "step": 6130
    },
    {
      "epoch": 28.295612009237875,
      "grad_norm": 0.4059472680091858,
      "learning_rate": 0.00047834451659096967,
      "loss": 2.004,
      "step": 6140
    },
    {
      "epoch": 28.341801385681293,
      "grad_norm": 0.3569865822792053,
      "learning_rate": 0.00047826969224092173,
      "loss": 1.995,
      "step": 6150
    },
    {
      "epoch": 28.387990762124712,
      "grad_norm": 0.34114548563957214,
      "learning_rate": 0.00047819474471941177,
      "loss": 1.9937,
      "step": 6160
    },
    {
      "epoch": 28.43418013856813,
      "grad_norm": 0.36197203397750854,
      "learning_rate": 0.0004781196740668806,
      "loss": 2.008,
      "step": 6170
    },
    {
      "epoch": 28.480369515011546,
      "grad_norm": 0.357692688703537,
      "learning_rate": 0.00047804448032383534,
      "loss": 2.0146,
      "step": 6180
    },
    {
      "epoch": 28.526558891454965,
      "grad_norm": 0.5053752660751343,
      "learning_rate": 0.00047796916353084963,
      "loss": 2.003,
      "step": 6190
    },
    {
      "epoch": 28.572748267898383,
      "grad_norm": 0.3641676902770996,
      "learning_rate": 0.0004778937237285634,
      "loss": 2.0079,
      "step": 6200
    },
    {
      "epoch": 28.618937644341802,
      "grad_norm": 0.44766366481781006,
      "learning_rate": 0.00047781816095768313,
      "loss": 2.0055,
      "step": 6210
    },
    {
      "epoch": 28.66512702078522,
      "grad_norm": 0.5733059048652649,
      "learning_rate": 0.00047774247525898155,
      "loss": 2.0009,
      "step": 6220
    },
    {
      "epoch": 28.711316397228636,
      "grad_norm": 0.45276424288749695,
      "learning_rate": 0.00047766666667329764,
      "loss": 2.002,
      "step": 6230
    },
    {
      "epoch": 28.757505773672055,
      "grad_norm": 0.46999305486679077,
      "learning_rate": 0.00047759073524153667,
      "loss": 2.0078,
      "step": 6240
    },
    {
      "epoch": 28.803695150115473,
      "grad_norm": 0.4804880917072296,
      "learning_rate": 0.0004775146810046704,
      "loss": 1.9975,
      "step": 6250
    },
    {
      "epoch": 28.849884526558892,
      "grad_norm": 0.562572717666626,
      "learning_rate": 0.0004774385040037368,
      "loss": 2.0047,
      "step": 6260
    },
    {
      "epoch": 28.89607390300231,
      "grad_norm": 0.4091339707374573,
      "learning_rate": 0.00047736220427983995,
      "loss": 2.0078,
      "step": 6270
    },
    {
      "epoch": 28.942263279445726,
      "grad_norm": 0.4142574071884155,
      "learning_rate": 0.0004772857818741502,
      "loss": 1.9911,
      "step": 6280
    },
    {
      "epoch": 28.988452655889144,
      "grad_norm": 0.5366794466972351,
      "learning_rate": 0.00047720923682790416,
      "loss": 2.0022,
      "step": 6290
    },
    {
      "epoch": 29.0,
      "eval_loss": 0.9835367798805237,
      "eval_runtime": 6.8385,
      "eval_samples_per_second": 4076.755,
      "eval_steps_per_second": 15.939,
      "step": 6293
    },
    {
      "epoch": 29.032332563510394,
      "grad_norm": 0.7113626599311829,
      "learning_rate": 0.00047713256918240456,
      "loss": 1.9038,
      "step": 6300
    },
    {
      "epoch": 29.07852193995381,
      "grad_norm": 0.3728449046611786,
      "learning_rate": 0.00047705577897902033,
      "loss": 1.9899,
      "step": 6310
    },
    {
      "epoch": 29.124711316397228,
      "grad_norm": 0.38461029529571533,
      "learning_rate": 0.0004769788662591865,
      "loss": 1.9971,
      "step": 6320
    },
    {
      "epoch": 29.170900692840647,
      "grad_norm": 0.439659982919693,
      "learning_rate": 0.0004769018310644041,
      "loss": 2.0135,
      "step": 6330
    },
    {
      "epoch": 29.217090069284065,
      "grad_norm": 0.6838712692260742,
      "learning_rate": 0.00047682467343624046,
      "loss": 2.0024,
      "step": 6340
    },
    {
      "epoch": 29.263279445727484,
      "grad_norm": 0.3530379831790924,
      "learning_rate": 0.00047674739341632894,
      "loss": 2.0017,
      "step": 6350
    },
    {
      "epoch": 29.3094688221709,
      "grad_norm": 0.40693333745002747,
      "learning_rate": 0.0004766699910463687,
      "loss": 1.9885,
      "step": 6360
    },
    {
      "epoch": 29.355658198614318,
      "grad_norm": 0.37136131525039673,
      "learning_rate": 0.0004765924663681252,
      "loss": 1.9966,
      "step": 6370
    },
    {
      "epoch": 29.401847575057737,
      "grad_norm": 0.4147155284881592,
      "learning_rate": 0.0004765148194234297,
      "loss": 1.9943,
      "step": 6380
    },
    {
      "epoch": 29.448036951501155,
      "grad_norm": 0.46954408288002014,
      "learning_rate": 0.00047643705025417963,
      "loss": 1.9937,
      "step": 6390
    },
    {
      "epoch": 29.494226327944574,
      "grad_norm": 0.35603460669517517,
      "learning_rate": 0.00047635915890233816,
      "loss": 2.0018,
      "step": 6400
    },
    {
      "epoch": 29.54041570438799,
      "grad_norm": 0.3287006914615631,
      "learning_rate": 0.0004762811454099346,
      "loss": 2.0062,
      "step": 6410
    },
    {
      "epoch": 29.586605080831408,
      "grad_norm": 0.41846877336502075,
      "learning_rate": 0.0004762030098190638,
      "loss": 2.0012,
      "step": 6420
    },
    {
      "epoch": 29.632794457274827,
      "grad_norm": 0.3037947118282318,
      "learning_rate": 0.00047612475217188703,
      "loss": 1.9951,
      "step": 6430
    },
    {
      "epoch": 29.678983833718245,
      "grad_norm": 0.3405224084854126,
      "learning_rate": 0.00047604637251063105,
      "loss": 2.0096,
      "step": 6440
    },
    {
      "epoch": 29.725173210161664,
      "grad_norm": 0.3514622747898102,
      "learning_rate": 0.00047596787087758846,
      "loss": 2.0073,
      "step": 6450
    },
    {
      "epoch": 29.77136258660508,
      "grad_norm": 0.37329378724098206,
      "learning_rate": 0.00047588924731511783,
      "loss": 1.9972,
      "step": 6460
    },
    {
      "epoch": 29.817551963048498,
      "grad_norm": 0.36574360728263855,
      "learning_rate": 0.00047581050186564346,
      "loss": 2.0034,
      "step": 6470
    },
    {
      "epoch": 29.863741339491916,
      "grad_norm": 0.33265119791030884,
      "learning_rate": 0.0004757316345716554,
      "loss": 2.0035,
      "step": 6480
    },
    {
      "epoch": 29.909930715935335,
      "grad_norm": 0.4204525649547577,
      "learning_rate": 0.0004756526454757093,
      "loss": 1.9968,
      "step": 6490
    },
    {
      "epoch": 29.956120092378754,
      "grad_norm": 0.41149264574050903,
      "learning_rate": 0.00047557353462042684,
      "loss": 2.0092,
      "step": 6500
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.2829795777797699,
      "learning_rate": 0.0004754943020484953,
      "loss": 1.9045,
      "step": 6510
    },
    {
      "epoch": 30.0,
      "eval_loss": 0.9835336804389954,
      "eval_runtime": 6.8213,
      "eval_samples_per_second": 4087.024,
      "eval_steps_per_second": 15.979,
      "step": 6510
    },
    {
      "epoch": 30.04618937644342,
      "grad_norm": 0.32049429416656494,
      "learning_rate": 0.0004754149478026674,
      "loss": 1.9873,
      "step": 6520
    },
    {
      "epoch": 30.092378752886837,
      "grad_norm": 0.39042261242866516,
      "learning_rate": 0.0004753354719257619,
      "loss": 2.0005,
      "step": 6530
    },
    {
      "epoch": 30.138568129330253,
      "grad_norm": 0.497426837682724,
      "learning_rate": 0.0004752558744606628,
      "loss": 2.0048,
      "step": 6540
    },
    {
      "epoch": 30.18475750577367,
      "grad_norm": 0.3569827973842621,
      "learning_rate": 0.00047517615545032,
      "loss": 2.0071,
      "step": 6550
    },
    {
      "epoch": 30.23094688221709,
      "grad_norm": 0.377482146024704,
      "learning_rate": 0.00047509631493774883,
      "loss": 1.9978,
      "step": 6560
    },
    {
      "epoch": 30.27713625866051,
      "grad_norm": 0.293615460395813,
      "learning_rate": 0.0004750163529660303,
      "loss": 2.0055,
      "step": 6570
    },
    {
      "epoch": 30.323325635103927,
      "grad_norm": 0.3640003204345703,
      "learning_rate": 0.0004749362695783108,
      "loss": 1.9943,
      "step": 6580
    },
    {
      "epoch": 30.369515011547342,
      "grad_norm": 0.3449925482273102,
      "learning_rate": 0.0004748560648178024,
      "loss": 1.9918,
      "step": 6590
    },
    {
      "epoch": 30.41570438799076,
      "grad_norm": 0.4381236433982849,
      "learning_rate": 0.0004747757387277825,
      "loss": 2.003,
      "step": 6600
    },
    {
      "epoch": 30.46189376443418,
      "grad_norm": 0.38860785961151123,
      "learning_rate": 0.0004746952913515941,
      "loss": 1.9958,
      "step": 6610
    },
    {
      "epoch": 30.5080831408776,
      "grad_norm": 0.43287986516952515,
      "learning_rate": 0.0004746147227326456,
      "loss": 1.9982,
      "step": 6620
    },
    {
      "epoch": 30.554272517321017,
      "grad_norm": 0.3227965235710144,
      "learning_rate": 0.00047453403291441076,
      "loss": 2.0025,
      "step": 6630
    },
    {
      "epoch": 30.600461893764432,
      "grad_norm": 0.5477273464202881,
      "learning_rate": 0.0004744532219404288,
      "loss": 1.9938,
      "step": 6640
    },
    {
      "epoch": 30.64665127020785,
      "grad_norm": 0.42783647775650024,
      "learning_rate": 0.0004743722898543045,
      "loss": 2.0031,
      "step": 6650
    },
    {
      "epoch": 30.69284064665127,
      "grad_norm": 0.30718979239463806,
      "learning_rate": 0.0004742912366997075,
      "loss": 2.0101,
      "step": 6660
    },
    {
      "epoch": 30.73903002309469,
      "grad_norm": 0.34675103425979614,
      "learning_rate": 0.0004742100625203733,
      "loss": 2.0063,
      "step": 6670
    },
    {
      "epoch": 30.785219399538107,
      "grad_norm": 0.3036424517631531,
      "learning_rate": 0.00047412876736010237,
      "loss": 1.9993,
      "step": 6680
    },
    {
      "epoch": 30.831408775981526,
      "grad_norm": 0.32877740263938904,
      "learning_rate": 0.0004740473512627605,
      "loss": 1.9972,
      "step": 6690
    },
    {
      "epoch": 30.87759815242494,
      "grad_norm": 0.36306679248809814,
      "learning_rate": 0.00047396581427227886,
      "loss": 1.9974,
      "step": 6700
    },
    {
      "epoch": 30.92378752886836,
      "grad_norm": 0.401719331741333,
      "learning_rate": 0.0004738841564326538,
      "loss": 2.0034,
      "step": 6710
    },
    {
      "epoch": 30.96997690531178,
      "grad_norm": 0.36335620284080505,
      "learning_rate": 0.00047380237778794687,
      "loss": 1.9891,
      "step": 6720
    },
    {
      "epoch": 31.0,
      "eval_loss": 0.9823735952377319,
      "eval_runtime": 6.7921,
      "eval_samples_per_second": 4104.601,
      "eval_steps_per_second": 16.048,
      "step": 6727
    },
    {
      "epoch": 31.013856812933025,
      "grad_norm": 0.5623850226402283,
      "learning_rate": 0.0004737204783822848,
      "loss": 1.8939,
      "step": 6730
    },
    {
      "epoch": 31.060046189376443,
      "grad_norm": 0.41708049178123474,
      "learning_rate": 0.0004736384582598594,
      "loss": 2.0042,
      "step": 6740
    },
    {
      "epoch": 31.106235565819862,
      "grad_norm": 0.40260082483291626,
      "learning_rate": 0.00047355631746492786,
      "loss": 1.9948,
      "step": 6750
    },
    {
      "epoch": 31.15242494226328,
      "grad_norm": 0.5507758259773254,
      "learning_rate": 0.00047347405604181213,
      "loss": 2.0005,
      "step": 6760
    },
    {
      "epoch": 31.198614318706696,
      "grad_norm": 0.3319277763366699,
      "learning_rate": 0.0004733916740348996,
      "loss": 1.999,
      "step": 6770
    },
    {
      "epoch": 31.244803695150114,
      "grad_norm": 0.44499120116233826,
      "learning_rate": 0.0004733091714886425,
      "loss": 2.0032,
      "step": 6780
    },
    {
      "epoch": 31.290993071593533,
      "grad_norm": 0.3891398012638092,
      "learning_rate": 0.00047322654844755813,
      "loss": 1.999,
      "step": 6790
    },
    {
      "epoch": 31.337182448036952,
      "grad_norm": 0.5222212672233582,
      "learning_rate": 0.0004731438049562289,
      "loss": 1.9972,
      "step": 6800
    },
    {
      "epoch": 31.38337182448037,
      "grad_norm": 0.39357540011405945,
      "learning_rate": 0.0004730609410593022,
      "loss": 1.9922,
      "step": 6810
    },
    {
      "epoch": 31.42956120092379,
      "grad_norm": 0.29851388931274414,
      "learning_rate": 0.00047297795680149027,
      "loss": 1.9949,
      "step": 6820
    },
    {
      "epoch": 31.475750577367204,
      "grad_norm": 0.39294394850730896,
      "learning_rate": 0.0004728948522275703,
      "loss": 1.9859,
      "step": 6830
    },
    {
      "epoch": 31.521939953810623,
      "grad_norm": 0.3547324538230896,
      "learning_rate": 0.0004728116273823847,
      "loss": 1.997,
      "step": 6840
    },
    {
      "epoch": 31.56812933025404,
      "grad_norm": 0.40158000588417053,
      "learning_rate": 0.0004727282823108404,
      "loss": 1.9846,
      "step": 6850
    },
    {
      "epoch": 31.61431870669746,
      "grad_norm": 0.3927820026874542,
      "learning_rate": 0.0004726448170579094,
      "loss": 1.9952,
      "step": 6860
    },
    {
      "epoch": 31.66050808314088,
      "grad_norm": 0.2933439016342163,
      "learning_rate": 0.00047256123166862854,
      "loss": 1.9936,
      "step": 6870
    },
    {
      "epoch": 31.706697459584294,
      "grad_norm": 0.3437805473804474,
      "learning_rate": 0.0004724775261880993,
      "loss": 1.9972,
      "step": 6880
    },
    {
      "epoch": 31.752886836027713,
      "grad_norm": 1.0475322008132935,
      "learning_rate": 0.00047239370066148824,
      "loss": 2.0018,
      "step": 6890
    },
    {
      "epoch": 31.79907621247113,
      "grad_norm": 0.4454675316810608,
      "learning_rate": 0.0004723097551340265,
      "loss": 1.9993,
      "step": 6900
    },
    {
      "epoch": 31.84526558891455,
      "grad_norm": 0.3946230113506317,
      "learning_rate": 0.00047222568965101007,
      "loss": 1.9987,
      "step": 6910
    },
    {
      "epoch": 31.89145496535797,
      "grad_norm": 0.41794827580451965,
      "learning_rate": 0.00047214150425779966,
      "loss": 1.9954,
      "step": 6920
    },
    {
      "epoch": 31.937644341801384,
      "grad_norm": 0.38042160868644714,
      "learning_rate": 0.0004720571989998206,
      "loss": 1.995,
      "step": 6930
    },
    {
      "epoch": 31.983833718244803,
      "grad_norm": 0.4470931887626648,
      "learning_rate": 0.000471972773922563,
      "loss": 1.9959,
      "step": 6940
    },
    {
      "epoch": 32.0,
      "eval_loss": 0.9815294146537781,
      "eval_runtime": 6.8212,
      "eval_samples_per_second": 4087.129,
      "eval_steps_per_second": 15.98,
      "step": 6944
    },
    {
      "epoch": 32.02771362586605,
      "grad_norm": 0.4365832805633545,
      "learning_rate": 0.0004718882290715815,
      "loss": 1.8761,
      "step": 6950
    },
    {
      "epoch": 32.07390300230947,
      "grad_norm": 0.8415772318840027,
      "learning_rate": 0.0004718035644924954,
      "loss": 1.9878,
      "step": 6960
    },
    {
      "epoch": 32.12009237875289,
      "grad_norm": 0.48817938566207886,
      "learning_rate": 0.0004717187802309888,
      "loss": 1.9889,
      "step": 6970
    },
    {
      "epoch": 32.1662817551963,
      "grad_norm": 0.4343920350074768,
      "learning_rate": 0.0004716338763328101,
      "loss": 2.0012,
      "step": 6980
    },
    {
      "epoch": 32.212471131639724,
      "grad_norm": 0.4823705852031708,
      "learning_rate": 0.0004715488528437724,
      "loss": 1.9852,
      "step": 6990
    },
    {
      "epoch": 32.25866050808314,
      "grad_norm": 0.4180012047290802,
      "learning_rate": 0.0004714637098097534,
      "loss": 2.0004,
      "step": 7000
    },
    {
      "epoch": 32.30484988452656,
      "grad_norm": 0.38069313764572144,
      "learning_rate": 0.0004713784472766951,
      "loss": 1.9963,
      "step": 7010
    },
    {
      "epoch": 32.351039260969976,
      "grad_norm": 0.3374279737472534,
      "learning_rate": 0.0004712930652906041,
      "loss": 1.9961,
      "step": 7020
    },
    {
      "epoch": 32.39722863741339,
      "grad_norm": 0.5742432475090027,
      "learning_rate": 0.0004712075638975516,
      "loss": 1.993,
      "step": 7030
    },
    {
      "epoch": 32.443418013856814,
      "grad_norm": 0.4220382571220398,
      "learning_rate": 0.0004711219431436728,
      "loss": 1.9881,
      "step": 7040
    },
    {
      "epoch": 32.48960739030023,
      "grad_norm": 0.41598716378211975,
      "learning_rate": 0.00047103620307516794,
      "loss": 1.9975,
      "step": 7050
    },
    {
      "epoch": 32.53579676674365,
      "grad_norm": 0.34133535623550415,
      "learning_rate": 0.00047095034373830093,
      "loss": 1.9899,
      "step": 7060
    },
    {
      "epoch": 32.581986143187066,
      "grad_norm": 0.4242001175880432,
      "learning_rate": 0.00047086436517940064,
      "loss": 1.9981,
      "step": 7070
    },
    {
      "epoch": 32.62817551963049,
      "grad_norm": 0.4704672694206238,
      "learning_rate": 0.0004707782674448599,
      "loss": 1.9969,
      "step": 7080
    },
    {
      "epoch": 32.674364896073904,
      "grad_norm": 0.5031076073646545,
      "learning_rate": 0.000470692050581136,
      "loss": 1.9927,
      "step": 7090
    },
    {
      "epoch": 32.72055427251732,
      "grad_norm": 0.4591505229473114,
      "learning_rate": 0.0004706057146347505,
      "loss": 2.0007,
      "step": 7100
    },
    {
      "epoch": 32.76674364896074,
      "grad_norm": 0.38776013255119324,
      "learning_rate": 0.00047051925965228917,
      "loss": 1.9909,
      "step": 7110
    },
    {
      "epoch": 32.812933025404156,
      "grad_norm": 0.44255149364471436,
      "learning_rate": 0.000470432685680402,
      "loss": 1.9949,
      "step": 7120
    },
    {
      "epoch": 32.85912240184758,
      "grad_norm": 0.3992864191532135,
      "learning_rate": 0.00047034599276580326,
      "loss": 2.0055,
      "step": 7130
    },
    {
      "epoch": 32.905311778290994,
      "grad_norm": 1.0386552810668945,
      "learning_rate": 0.00047025918095527144,
      "loss": 2.0073,
      "step": 7140
    },
    {
      "epoch": 32.95150115473441,
      "grad_norm": 0.35122835636138916,
      "learning_rate": 0.00047017225029564894,
      "loss": 1.9989,
      "step": 7150
    },
    {
      "epoch": 32.99769053117783,
      "grad_norm": 0.3971479535102844,
      "learning_rate": 0.0004700852008338425,
      "loss": 1.9917,
      "step": 7160
    },
    {
      "epoch": 33.0,
      "eval_loss": 0.9825619459152222,
      "eval_runtime": 7.0145,
      "eval_samples_per_second": 3974.49,
      "eval_steps_per_second": 15.539,
      "step": 7161
    },
    {
      "epoch": 33.04157043879908,
      "grad_norm": 0.43587014079093933,
      "learning_rate": 0.00046999803261682304,
      "loss": 1.8946,
      "step": 7170
    },
    {
      "epoch": 33.08775981524249,
      "grad_norm": 0.6425369381904602,
      "learning_rate": 0.0004699107456916253,
      "loss": 1.9876,
      "step": 7180
    },
    {
      "epoch": 33.133949191685915,
      "grad_norm": 0.34399160742759705,
      "learning_rate": 0.00046982334010534825,
      "loss": 1.9846,
      "step": 7190
    },
    {
      "epoch": 33.18013856812933,
      "grad_norm": 0.5363377928733826,
      "learning_rate": 0.0004697358159051549,
      "loss": 1.9851,
      "step": 7200
    },
    {
      "epoch": 33.226327944572745,
      "grad_norm": 0.5000133514404297,
      "learning_rate": 0.00046964817313827214,
      "loss": 1.9892,
      "step": 7210
    },
    {
      "epoch": 33.27251732101617,
      "grad_norm": 0.5843369960784912,
      "learning_rate": 0.0004695604118519909,
      "loss": 1.9929,
      "step": 7220
    },
    {
      "epoch": 33.31870669745958,
      "grad_norm": 0.3777691721916199,
      "learning_rate": 0.00046947253209366613,
      "loss": 1.9995,
      "step": 7230
    },
    {
      "epoch": 33.364896073903004,
      "grad_norm": 0.5143181681632996,
      "learning_rate": 0.00046938453391071657,
      "loss": 2.0081,
      "step": 7240
    },
    {
      "epoch": 33.41108545034642,
      "grad_norm": 0.5332314372062683,
      "learning_rate": 0.000469296417350625,
      "loss": 1.9911,
      "step": 7250
    },
    {
      "epoch": 33.45727482678984,
      "grad_norm": 0.516116738319397,
      "learning_rate": 0.00046920818246093805,
      "loss": 1.9909,
      "step": 7260
    },
    {
      "epoch": 33.50346420323326,
      "grad_norm": 0.42190006375312805,
      "learning_rate": 0.0004691198292892661,
      "loss": 1.9898,
      "step": 7270
    },
    {
      "epoch": 33.54965357967667,
      "grad_norm": 0.5698173642158508,
      "learning_rate": 0.00046903135788328335,
      "loss": 2.0007,
      "step": 7280
    },
    {
      "epoch": 33.595842956120094,
      "grad_norm": 0.5313977003097534,
      "learning_rate": 0.0004689427682907279,
      "loss": 1.9794,
      "step": 7290
    },
    {
      "epoch": 33.64203233256351,
      "grad_norm": 0.5805746912956238,
      "learning_rate": 0.0004688540605594017,
      "loss": 1.9999,
      "step": 7300
    },
    {
      "epoch": 33.68822170900693,
      "grad_norm": 0.4393691420555115,
      "learning_rate": 0.0004687652347371702,
      "loss": 1.9857,
      "step": 7310
    },
    {
      "epoch": 33.73441108545035,
      "grad_norm": 0.39184409379959106,
      "learning_rate": 0.0004686762908719627,
      "loss": 1.9956,
      "step": 7320
    },
    {
      "epoch": 33.78060046189376,
      "grad_norm": 0.6617655158042908,
      "learning_rate": 0.00046858722901177224,
      "loss": 1.9888,
      "step": 7330
    },
    {
      "epoch": 33.826789838337184,
      "grad_norm": 0.7482739090919495,
      "learning_rate": 0.00046849804920465557,
      "loss": 1.9904,
      "step": 7340
    },
    {
      "epoch": 33.8729792147806,
      "grad_norm": 0.7324515581130981,
      "learning_rate": 0.00046840875149873273,
      "loss": 2.0039,
      "step": 7350
    },
    {
      "epoch": 33.91916859122402,
      "grad_norm": 0.39214012026786804,
      "learning_rate": 0.0004683193359421879,
      "loss": 1.9909,
      "step": 7360
    },
    {
      "epoch": 33.96535796766744,
      "grad_norm": 0.4286980628967285,
      "learning_rate": 0.0004682298025832685,
      "loss": 1.9974,
      "step": 7370
    },
    {
      "epoch": 34.0,
      "eval_loss": 0.9822744131088257,
      "eval_runtime": 6.8073,
      "eval_samples_per_second": 4095.464,
      "eval_steps_per_second": 16.012,
      "step": 7378
    },
    {
      "epoch": 34.00923787528868,
      "grad_norm": 0.4220113754272461,
      "learning_rate": 0.0004681401514702856,
      "loss": 1.894,
      "step": 7380
    },
    {
      "epoch": 34.0554272517321,
      "grad_norm": 0.4423622786998749,
      "learning_rate": 0.0004680503826516138,
      "loss": 2.0019,
      "step": 7390
    },
    {
      "epoch": 34.10161662817552,
      "grad_norm": 0.4084620177745819,
      "learning_rate": 0.00046796049617569126,
      "loss": 1.9901,
      "step": 7400
    },
    {
      "epoch": 34.147806004618936,
      "grad_norm": 0.3313083350658417,
      "learning_rate": 0.00046787049209101963,
      "loss": 2.0046,
      "step": 7410
    },
    {
      "epoch": 34.19399538106236,
      "grad_norm": 0.41365689039230347,
      "learning_rate": 0.00046778037044616387,
      "loss": 1.9834,
      "step": 7420
    },
    {
      "epoch": 34.24018475750577,
      "grad_norm": 0.33354270458221436,
      "learning_rate": 0.0004676901312897526,
      "loss": 1.9778,
      "step": 7430
    },
    {
      "epoch": 34.286374133949195,
      "grad_norm": 0.5632833242416382,
      "learning_rate": 0.00046759977467047774,
      "loss": 1.9962,
      "step": 7440
    },
    {
      "epoch": 34.33256351039261,
      "grad_norm": 0.37751492857933044,
      "learning_rate": 0.0004675093006370945,
      "loss": 1.9949,
      "step": 7450
    },
    {
      "epoch": 34.378752886836025,
      "grad_norm": 0.44140002131462097,
      "learning_rate": 0.00046741870923842156,
      "loss": 1.9959,
      "step": 7460
    },
    {
      "epoch": 34.42494226327945,
      "grad_norm": 0.7554227113723755,
      "learning_rate": 0.00046732800052334096,
      "loss": 1.9906,
      "step": 7470
    },
    {
      "epoch": 34.47113163972286,
      "grad_norm": 0.30547070503234863,
      "learning_rate": 0.0004672371745407979,
      "loss": 1.9966,
      "step": 7480
    },
    {
      "epoch": 34.517321016166285,
      "grad_norm": 0.504244863986969,
      "learning_rate": 0.000467146231339801,
      "loss": 1.9916,
      "step": 7490
    },
    {
      "epoch": 34.5635103926097,
      "grad_norm": 0.36492156982421875,
      "learning_rate": 0.00046705517096942207,
      "loss": 1.9807,
      "step": 7500
    },
    {
      "epoch": 34.609699769053115,
      "grad_norm": 0.40799853205680847,
      "learning_rate": 0.0004669639934787961,
      "loss": 2.0039,
      "step": 7510
    },
    {
      "epoch": 34.65588914549654,
      "grad_norm": 0.4153348207473755,
      "learning_rate": 0.00046687269891712135,
      "loss": 1.9865,
      "step": 7520
    },
    {
      "epoch": 34.70207852193995,
      "grad_norm": 0.3339024484157562,
      "learning_rate": 0.0004667812873336593,
      "loss": 1.9765,
      "step": 7530
    },
    {
      "epoch": 34.748267898383375,
      "grad_norm": 0.5424243211746216,
      "learning_rate": 0.00046668975877773433,
      "loss": 1.9858,
      "step": 7540
    },
    {
      "epoch": 34.79445727482679,
      "grad_norm": 0.42359670996665955,
      "learning_rate": 0.00046659811329873425,
      "loss": 1.9902,
      "step": 7550
    },
    {
      "epoch": 34.840646651270205,
      "grad_norm": 0.5658791661262512,
      "learning_rate": 0.00046650635094610973,
      "loss": 1.9871,
      "step": 7560
    },
    {
      "epoch": 34.88683602771363,
      "grad_norm": 0.53912353515625,
      "learning_rate": 0.0004664144717693745,
      "loss": 1.9981,
      "step": 7570
    },
    {
      "epoch": 34.93302540415704,
      "grad_norm": 0.32542404532432556,
      "learning_rate": 0.0004663224758181056,
      "loss": 1.9989,
      "step": 7580
    },
    {
      "epoch": 34.979214780600465,
      "grad_norm": 0.5172723531723022,
      "learning_rate": 0.00046623036314194277,
      "loss": 1.9904,
      "step": 7590
    },
    {
      "epoch": 35.0,
      "eval_loss": 0.9811843633651733,
      "eval_runtime": 7.011,
      "eval_samples_per_second": 3976.473,
      "eval_steps_per_second": 15.547,
      "step": 7595
    },
    {
      "epoch": 35.02309468822171,
      "grad_norm": 0.42696380615234375,
      "learning_rate": 0.0004661381337905889,
      "loss": 1.8958,
      "step": 7600
    },
    {
      "epoch": 35.069284064665126,
      "grad_norm": 0.6224256157875061,
      "learning_rate": 0.0004660457878138098,
      "loss": 1.9767,
      "step": 7610
    },
    {
      "epoch": 35.11547344110855,
      "grad_norm": 0.3221101760864258,
      "learning_rate": 0.00046595332526143407,
      "loss": 1.9878,
      "step": 7620
    },
    {
      "epoch": 35.161662817551964,
      "grad_norm": 0.34546253085136414,
      "learning_rate": 0.00046586074618335357,
      "loss": 1.9823,
      "step": 7630
    },
    {
      "epoch": 35.20785219399538,
      "grad_norm": 0.4767361581325531,
      "learning_rate": 0.00046576805062952263,
      "loss": 1.9888,
      "step": 7640
    },
    {
      "epoch": 35.2540415704388,
      "grad_norm": 0.4922201633453369,
      "learning_rate": 0.00046567523864995866,
      "loss": 1.9942,
      "step": 7650
    },
    {
      "epoch": 35.300230946882216,
      "grad_norm": 0.3521899878978729,
      "learning_rate": 0.00046558231029474186,
      "loss": 1.9809,
      "step": 7660
    },
    {
      "epoch": 35.34642032332564,
      "grad_norm": 0.445096880197525,
      "learning_rate": 0.0004654892656140152,
      "loss": 1.9986,
      "step": 7670
    },
    {
      "epoch": 35.392609699769054,
      "grad_norm": 0.5027207732200623,
      "learning_rate": 0.00046539610465798446,
      "loss": 1.9973,
      "step": 7680
    },
    {
      "epoch": 35.43879907621247,
      "grad_norm": 0.357803612947464,
      "learning_rate": 0.000465302827476918,
      "loss": 1.982,
      "step": 7690
    },
    {
      "epoch": 35.48498845265589,
      "grad_norm": 0.4090234935283661,
      "learning_rate": 0.00046520943412114703,
      "loss": 1.9932,
      "step": 7700
    },
    {
      "epoch": 35.531177829099306,
      "grad_norm": 0.41680708527565,
      "learning_rate": 0.00046511592464106564,
      "loss": 1.9888,
      "step": 7710
    },
    {
      "epoch": 35.57736720554273,
      "grad_norm": 0.5504048466682434,
      "learning_rate": 0.0004650222990871301,
      "loss": 1.9962,
      "step": 7720
    },
    {
      "epoch": 35.62355658198614,
      "grad_norm": 0.4274490177631378,
      "learning_rate": 0.00046492855750985987,
      "loss": 1.9837,
      "step": 7730
    },
    {
      "epoch": 35.66974595842956,
      "grad_norm": 0.6071157455444336,
      "learning_rate": 0.0004648346999598364,
      "loss": 1.9988,
      "step": 7740
    },
    {
      "epoch": 35.71593533487298,
      "grad_norm": 0.4194803535938263,
      "learning_rate": 0.00046474072648770425,
      "loss": 1.9913,
      "step": 7750
    },
    {
      "epoch": 35.762124711316396,
      "grad_norm": 0.5214748978614807,
      "learning_rate": 0.0004646466371441704,
      "loss": 1.9919,
      "step": 7760
    },
    {
      "epoch": 35.80831408775982,
      "grad_norm": 0.359336256980896,
      "learning_rate": 0.0004645524319800041,
      "loss": 1.9945,
      "step": 7770
    },
    {
      "epoch": 35.85450346420323,
      "grad_norm": 0.32528001070022583,
      "learning_rate": 0.00046445811104603733,
      "loss": 1.9814,
      "step": 7780
    },
    {
      "epoch": 35.90069284064665,
      "grad_norm": 0.39077597856521606,
      "learning_rate": 0.0004643636743931645,
      "loss": 1.9989,
      "step": 7790
    },
    {
      "epoch": 35.94688221709007,
      "grad_norm": 0.43093401193618774,
      "learning_rate": 0.00046426912207234253,
      "loss": 1.9915,
      "step": 7800
    },
    {
      "epoch": 35.993071593533486,
      "grad_norm": 0.3236866593360901,
      "learning_rate": 0.0004641744541345905,
      "loss": 1.9941,
      "step": 7810
    },
    {
      "epoch": 36.0,
      "eval_loss": 0.9813517332077026,
      "eval_runtime": 6.8017,
      "eval_samples_per_second": 4098.846,
      "eval_steps_per_second": 16.025,
      "step": 7812
    },
    {
      "epoch": 36.03695150115473,
      "grad_norm": 0.36022457480430603,
      "learning_rate": 0.00046407967063099014,
      "loss": 1.8868,
      "step": 7820
    },
    {
      "epoch": 36.083140877598154,
      "grad_norm": 0.32562682032585144,
      "learning_rate": 0.00046398477161268544,
      "loss": 1.9766,
      "step": 7830
    },
    {
      "epoch": 36.12933025404157,
      "grad_norm": 0.34138160943984985,
      "learning_rate": 0.00046388975713088266,
      "loss": 1.9855,
      "step": 7840
    },
    {
      "epoch": 36.17551963048499,
      "grad_norm": 0.34609857201576233,
      "learning_rate": 0.0004637946272368505,
      "loss": 1.9939,
      "step": 7850
    },
    {
      "epoch": 36.22170900692841,
      "grad_norm": 0.3382519483566284,
      "learning_rate": 0.0004636993819819198,
      "loss": 1.9843,
      "step": 7860
    },
    {
      "epoch": 36.26789838337182,
      "grad_norm": 0.37041425704956055,
      "learning_rate": 0.00046360402141748373,
      "loss": 1.9813,
      "step": 7870
    },
    {
      "epoch": 36.314087759815244,
      "grad_norm": 0.4286749064922333,
      "learning_rate": 0.0004635085455949977,
      "loss": 1.9716,
      "step": 7880
    },
    {
      "epoch": 36.36027713625866,
      "grad_norm": 0.3808625042438507,
      "learning_rate": 0.0004634129545659791,
      "loss": 1.9773,
      "step": 7890
    },
    {
      "epoch": 36.40646651270208,
      "grad_norm": 0.32306036353111267,
      "learning_rate": 0.0004633172483820078,
      "loss": 1.9936,
      "step": 7900
    },
    {
      "epoch": 36.4526558891455,
      "grad_norm": 0.431713730096817,
      "learning_rate": 0.0004632214270947256,
      "loss": 2.0017,
      "step": 7910
    },
    {
      "epoch": 36.49884526558891,
      "grad_norm": 0.3856354355812073,
      "learning_rate": 0.0004631254907558365,
      "loss": 1.9849,
      "step": 7920
    },
    {
      "epoch": 36.545034642032334,
      "grad_norm": 0.41311970353126526,
      "learning_rate": 0.0004630294394171066,
      "loss": 1.9923,
      "step": 7930
    },
    {
      "epoch": 36.59122401847575,
      "grad_norm": 0.34142953157424927,
      "learning_rate": 0.00046293327313036393,
      "loss": 1.9984,
      "step": 7940
    },
    {
      "epoch": 36.63741339491917,
      "grad_norm": 0.40178820490837097,
      "learning_rate": 0.00046283699194749853,
      "loss": 1.9861,
      "step": 7950
    },
    {
      "epoch": 36.68360277136259,
      "grad_norm": 0.5242096185684204,
      "learning_rate": 0.00046274059592046256,
      "loss": 1.9946,
      "step": 7960
    },
    {
      "epoch": 36.729792147806,
      "grad_norm": 0.41916710138320923,
      "learning_rate": 0.00046264408510127033,
      "loss": 1.991,
      "step": 7970
    },
    {
      "epoch": 36.775981524249424,
      "grad_norm": 0.43142133951187134,
      "learning_rate": 0.0004625474595419975,
      "loss": 1.9859,
      "step": 7980
    },
    {
      "epoch": 36.82217090069284,
      "grad_norm": 0.3532470464706421,
      "learning_rate": 0.00046245071929478226,
      "loss": 1.9846,
      "step": 7990
    },
    {
      "epoch": 36.86836027713626,
      "grad_norm": 0.3510299324989319,
      "learning_rate": 0.0004623538644118244,
      "loss": 1.9839,
      "step": 8000
    },
    {
      "epoch": 36.91454965357968,
      "grad_norm": 0.47900116443634033,
      "learning_rate": 0.00046225689494538546,
      "loss": 1.9888,
      "step": 8010
    },
    {
      "epoch": 36.96073903002309,
      "grad_norm": 0.5018242597579956,
      "learning_rate": 0.00046215981094778914,
      "loss": 1.9854,
      "step": 8020
    },
    {
      "epoch": 37.0,
      "eval_loss": 0.981029212474823,
      "eval_runtime": 7.03,
      "eval_samples_per_second": 3965.698,
      "eval_steps_per_second": 15.505,
      "step": 8029
    },
    {
      "epoch": 37.004618937644345,
      "grad_norm": 0.33849963545799255,
      "learning_rate": 0.00046206261247142054,
      "loss": 1.8889,
      "step": 8030
    },
    {
      "epoch": 37.05080831408776,
      "grad_norm": 0.3988555669784546,
      "learning_rate": 0.00046196529956872703,
      "loss": 1.9788,
      "step": 8040
    },
    {
      "epoch": 37.096997690531175,
      "grad_norm": 0.31405243277549744,
      "learning_rate": 0.00046186787229221716,
      "loss": 1.9747,
      "step": 8050
    },
    {
      "epoch": 37.1431870669746,
      "grad_norm": 0.4011097550392151,
      "learning_rate": 0.0004617703306944616,
      "loss": 1.9685,
      "step": 8060
    },
    {
      "epoch": 37.18937644341801,
      "grad_norm": 0.36718112230300903,
      "learning_rate": 0.0004616726748280925,
      "loss": 1.9914,
      "step": 8070
    },
    {
      "epoch": 37.235565819861435,
      "grad_norm": 0.42181527614593506,
      "learning_rate": 0.00046157490474580374,
      "loss": 1.9972,
      "step": 8080
    },
    {
      "epoch": 37.28175519630485,
      "grad_norm": 0.35980966687202454,
      "learning_rate": 0.0004614770205003509,
      "loss": 1.9928,
      "step": 8090
    },
    {
      "epoch": 37.327944572748265,
      "grad_norm": 0.41833657026290894,
      "learning_rate": 0.0004613790221445511,
      "loss": 1.9884,
      "step": 8100
    },
    {
      "epoch": 37.37413394919169,
      "grad_norm": 0.3403715193271637,
      "learning_rate": 0.00046128090973128293,
      "loss": 1.9889,
      "step": 8110
    },
    {
      "epoch": 37.4203233256351,
      "grad_norm": 0.46735817193984985,
      "learning_rate": 0.00046118268331348666,
      "loss": 1.9904,
      "step": 8120
    },
    {
      "epoch": 37.466512702078525,
      "grad_norm": 0.3292092978954315,
      "learning_rate": 0.0004610843429441641,
      "loss": 1.981,
      "step": 8130
    },
    {
      "epoch": 37.51270207852194,
      "grad_norm": 0.40424343943595886,
      "learning_rate": 0.0004609858886763784,
      "loss": 1.9938,
      "step": 8140
    },
    {
      "epoch": 37.558891454965355,
      "grad_norm": 0.30724483728408813,
      "learning_rate": 0.0004608873205632542,
      "loss": 1.9787,
      "step": 8150
    },
    {
      "epoch": 37.60508083140878,
      "grad_norm": 0.4104820191860199,
      "learning_rate": 0.00046078863865797775,
      "loss": 1.9863,
      "step": 8160
    },
    {
      "epoch": 37.65127020785219,
      "grad_norm": 0.375139057636261,
      "learning_rate": 0.00046068984301379654,
      "loss": 1.9799,
      "step": 8170
    },
    {
      "epoch": 37.697459584295615,
      "grad_norm": 0.4130590558052063,
      "learning_rate": 0.00046059093368401935,
      "loss": 1.9889,
      "step": 8180
    },
    {
      "epoch": 37.74364896073903,
      "grad_norm": 5.229056358337402,
      "learning_rate": 0.00046049191072201646,
      "loss": 1.9894,
      "step": 8190
    },
    {
      "epoch": 37.789838337182445,
      "grad_norm": 0.4049678444862366,
      "learning_rate": 0.0004603927741812195,
      "loss": 1.9859,
      "step": 8200
    },
    {
      "epoch": 37.83602771362587,
      "grad_norm": 0.3881514072418213,
      "learning_rate": 0.0004602935241151213,
      "loss": 1.9941,
      "step": 8210
    },
    {
      "epoch": 37.88221709006928,
      "grad_norm": 0.4020533859729767,
      "learning_rate": 0.0004601941605772758,
      "loss": 1.9878,
      "step": 8220
    },
    {
      "epoch": 37.928406466512705,
      "grad_norm": 0.641472578048706,
      "learning_rate": 0.0004600946836212985,
      "loss": 1.974,
      "step": 8230
    },
    {
      "epoch": 37.97459584295612,
      "grad_norm": 0.35645022988319397,
      "learning_rate": 0.0004599950933008658,
      "loss": 1.9722,
      "step": 8240
    },
    {
      "epoch": 38.0,
      "eval_loss": 0.9806409478187561,
      "eval_runtime": 6.8244,
      "eval_samples_per_second": 4085.193,
      "eval_steps_per_second": 15.972,
      "step": 8246
    },
    {
      "epoch": 38.018475750577366,
      "grad_norm": 0.3497960865497589,
      "learning_rate": 0.0004598953896697153,
      "loss": 1.8895,
      "step": 8250
    },
    {
      "epoch": 38.06466512702079,
      "grad_norm": 0.534966230392456,
      "learning_rate": 0.0004597955727816461,
      "loss": 1.973,
      "step": 8260
    },
    {
      "epoch": 38.1108545034642,
      "grad_norm": 0.423027366399765,
      "learning_rate": 0.0004596956426905179,
      "loss": 1.9849,
      "step": 8270
    },
    {
      "epoch": 38.15704387990762,
      "grad_norm": 0.41695037484169006,
      "learning_rate": 0.00045959559945025184,
      "loss": 1.9859,
      "step": 8280
    },
    {
      "epoch": 38.20323325635104,
      "grad_norm": 0.5610992908477783,
      "learning_rate": 0.00045949544311483007,
      "loss": 1.9736,
      "step": 8290
    },
    {
      "epoch": 38.249422632794456,
      "grad_norm": 0.4673994481563568,
      "learning_rate": 0.0004593951737382955,
      "loss": 1.9792,
      "step": 8300
    },
    {
      "epoch": 38.29561200923788,
      "grad_norm": 0.3661429286003113,
      "learning_rate": 0.0004592947913747523,
      "loss": 1.9716,
      "step": 8310
    },
    {
      "epoch": 38.34180138568129,
      "grad_norm": 0.4936941862106323,
      "learning_rate": 0.0004591942960783656,
      "loss": 1.9883,
      "step": 8320
    },
    {
      "epoch": 38.38799076212471,
      "grad_norm": 0.31629031896591187,
      "learning_rate": 0.0004590936879033614,
      "loss": 1.9975,
      "step": 8330
    },
    {
      "epoch": 38.43418013856813,
      "grad_norm": 0.3316709101200104,
      "learning_rate": 0.0004589929669040265,
      "loss": 1.9893,
      "step": 8340
    },
    {
      "epoch": 38.480369515011546,
      "grad_norm": 0.5736039876937866,
      "learning_rate": 0.0004588921331347087,
      "loss": 1.9853,
      "step": 8350
    },
    {
      "epoch": 38.52655889145497,
      "grad_norm": 0.4901144206523895,
      "learning_rate": 0.00045879118664981676,
      "loss": 1.9882,
      "step": 8360
    },
    {
      "epoch": 38.57274826789838,
      "grad_norm": 0.38826292753219604,
      "learning_rate": 0.00045869012750382004,
      "loss": 1.9769,
      "step": 8370
    },
    {
      "epoch": 38.6189376443418,
      "grad_norm": 0.4033975899219513,
      "learning_rate": 0.0004585889557512488,
      "loss": 1.9903,
      "step": 8380
    },
    {
      "epoch": 38.66512702078522,
      "grad_norm": 0.4996873140335083,
      "learning_rate": 0.00045848767144669413,
      "loss": 1.9907,
      "step": 8390
    },
    {
      "epoch": 38.711316397228636,
      "grad_norm": 0.4495418071746826,
      "learning_rate": 0.00045838627464480763,
      "loss": 1.983,
      "step": 8400
    },
    {
      "epoch": 38.75750577367206,
      "grad_norm": 0.3930718004703522,
      "learning_rate": 0.00045828476540030183,
      "loss": 1.9785,
      "step": 8410
    },
    {
      "epoch": 38.80369515011547,
      "grad_norm": 0.5408726334571838,
      "learning_rate": 0.00045818314376794983,
      "loss": 1.9817,
      "step": 8420
    },
    {
      "epoch": 38.84988452655889,
      "grad_norm": 0.5101631283760071,
      "learning_rate": 0.0004580814098025854,
      "loss": 1.9922,
      "step": 8430
    },
    {
      "epoch": 38.89607390300231,
      "grad_norm": 0.4518740475177765,
      "learning_rate": 0.00045797956355910294,
      "loss": 1.9862,
      "step": 8440
    },
    {
      "epoch": 38.942263279445726,
      "grad_norm": 0.3609139323234558,
      "learning_rate": 0.00045787760509245724,
      "loss": 1.9817,
      "step": 8450
    },
    {
      "epoch": 38.98845265588915,
      "grad_norm": 0.29202455282211304,
      "learning_rate": 0.00045777553445766405,
      "loss": 1.9907,
      "step": 8460
    },
    {
      "epoch": 39.0,
      "eval_loss": 0.9811583161354065,
      "eval_runtime": 6.8301,
      "eval_samples_per_second": 4081.796,
      "eval_steps_per_second": 15.959,
      "step": 8463
    },
    {
      "epoch": 39.032332563510394,
      "grad_norm": 0.44390225410461426,
      "learning_rate": 0.0004576733517097992,
      "loss": 1.8833,
      "step": 8470
    },
    {
      "epoch": 39.07852193995381,
      "grad_norm": 0.3761148750782013,
      "learning_rate": 0.00045757105690399935,
      "loss": 1.9848,
      "step": 8480
    },
    {
      "epoch": 39.12471131639723,
      "grad_norm": 0.36702659726142883,
      "learning_rate": 0.00045746865009546145,
      "loss": 1.9813,
      "step": 8490
    },
    {
      "epoch": 39.17090069284065,
      "grad_norm": 0.4819881021976471,
      "learning_rate": 0.0004573661313394429,
      "loss": 1.9892,
      "step": 8500
    },
    {
      "epoch": 39.21709006928406,
      "grad_norm": 0.37127724289894104,
      "learning_rate": 0.00045726350069126163,
      "loss": 1.9769,
      "step": 8510
    },
    {
      "epoch": 39.263279445727484,
      "grad_norm": 0.39046531915664673,
      "learning_rate": 0.00045716075820629573,
      "loss": 1.9784,
      "step": 8520
    },
    {
      "epoch": 39.3094688221709,
      "grad_norm": 0.3504806160926819,
      "learning_rate": 0.0004570579039399838,
      "loss": 1.9819,
      "step": 8530
    },
    {
      "epoch": 39.35565819861432,
      "grad_norm": 0.296156108379364,
      "learning_rate": 0.00045695493794782474,
      "loss": 1.9841,
      "step": 8540
    },
    {
      "epoch": 39.40184757505774,
      "grad_norm": 0.4128141701221466,
      "learning_rate": 0.00045685186028537764,
      "loss": 1.9835,
      "step": 8550
    },
    {
      "epoch": 39.44803695150115,
      "grad_norm": 0.4408351480960846,
      "learning_rate": 0.000456748671008262,
      "loss": 1.9816,
      "step": 8560
    },
    {
      "epoch": 39.494226327944574,
      "grad_norm": 0.35151615738868713,
      "learning_rate": 0.0004566453701721574,
      "loss": 1.9957,
      "step": 8570
    },
    {
      "epoch": 39.54041570438799,
      "grad_norm": 0.6309945583343506,
      "learning_rate": 0.0004565419578328037,
      "loss": 1.9884,
      "step": 8580
    },
    {
      "epoch": 39.58660508083141,
      "grad_norm": 0.36984097957611084,
      "learning_rate": 0.00045643843404600095,
      "loss": 1.9886,
      "step": 8590
    },
    {
      "epoch": 39.63279445727483,
      "grad_norm": 0.7206564545631409,
      "learning_rate": 0.0004563347988676092,
      "loss": 1.9819,
      "step": 8600
    },
    {
      "epoch": 39.67898383371824,
      "grad_norm": 0.3215528428554535,
      "learning_rate": 0.00045623105235354866,
      "loss": 1.9875,
      "step": 8610
    },
    {
      "epoch": 39.725173210161664,
      "grad_norm": 0.39060690999031067,
      "learning_rate": 0.00045612719455979977,
      "loss": 1.9948,
      "step": 8620
    },
    {
      "epoch": 39.77136258660508,
      "grad_norm": 0.371357262134552,
      "learning_rate": 0.00045602322554240285,
      "loss": 1.9785,
      "step": 8630
    },
    {
      "epoch": 39.8175519630485,
      "grad_norm": 0.3925569951534271,
      "learning_rate": 0.0004559191453574582,
      "loss": 1.9798,
      "step": 8640
    },
    {
      "epoch": 39.86374133949192,
      "grad_norm": 0.3598320484161377,
      "learning_rate": 0.0004558149540611263,
      "loss": 1.9907,
      "step": 8650
    },
    {
      "epoch": 39.90993071593533,
      "grad_norm": 0.4276026487350464,
      "learning_rate": 0.00045571065170962736,
      "loss": 1.9908,
      "step": 8660
    },
    {
      "epoch": 39.956120092378754,
      "grad_norm": 0.4088597893714905,
      "learning_rate": 0.0004556062383592417,
      "loss": 1.9771,
      "step": 8670
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.35463160276412964,
      "learning_rate": 0.0004555017140663094,
      "loss": 1.884,
      "step": 8680
    },
    {
      "epoch": 40.0,
      "eval_loss": 0.9806516170501709,
      "eval_runtime": 7.0072,
      "eval_samples_per_second": 3978.603,
      "eval_steps_per_second": 15.555,
      "step": 8680
    },
    {
      "epoch": 40.046189376443415,
      "grad_norm": 0.41644278168678284,
      "learning_rate": 0.00045539707888723053,
      "loss": 1.9692,
      "step": 8690
    },
    {
      "epoch": 40.09237875288684,
      "grad_norm": 0.40990862250328064,
      "learning_rate": 0.00045529233287846485,
      "loss": 1.989,
      "step": 8700
    },
    {
      "epoch": 40.13856812933025,
      "grad_norm": 0.45619481801986694,
      "learning_rate": 0.000455187476096532,
      "loss": 1.9872,
      "step": 8710
    },
    {
      "epoch": 40.184757505773675,
      "grad_norm": 0.4093490540981293,
      "learning_rate": 0.00045508250859801135,
      "loss": 1.9814,
      "step": 8720
    },
    {
      "epoch": 40.23094688221709,
      "grad_norm": 0.43090641498565674,
      "learning_rate": 0.0004549774304395422,
      "loss": 1.985,
      "step": 8730
    },
    {
      "epoch": 40.277136258660505,
      "grad_norm": 0.48281431198120117,
      "learning_rate": 0.0004548722416778232,
      "loss": 1.9819,
      "step": 8740
    },
    {
      "epoch": 40.32332563510393,
      "grad_norm": 0.33769434690475464,
      "learning_rate": 0.000454766942369613,
      "loss": 1.9779,
      "step": 8750
    },
    {
      "epoch": 40.36951501154734,
      "grad_norm": 0.4255968928337097,
      "learning_rate": 0.0004546615325717298,
      "loss": 1.9792,
      "step": 8760
    },
    {
      "epoch": 40.415704387990765,
      "grad_norm": 0.3598968982696533,
      "learning_rate": 0.00045455601234105136,
      "loss": 1.9916,
      "step": 8770
    },
    {
      "epoch": 40.46189376443418,
      "grad_norm": 0.3863486051559448,
      "learning_rate": 0.00045445038173451516,
      "loss": 1.9824,
      "step": 8780
    },
    {
      "epoch": 40.508083140877595,
      "grad_norm": 0.33033859729766846,
      "learning_rate": 0.000454344640809118,
      "loss": 1.9787,
      "step": 8790
    },
    {
      "epoch": 40.55427251732102,
      "grad_norm": 0.39392831921577454,
      "learning_rate": 0.00045423878962191645,
      "loss": 1.9866,
      "step": 8800
    },
    {
      "epoch": 40.60046189376443,
      "grad_norm": 0.4237275719642639,
      "learning_rate": 0.00045413282823002644,
      "loss": 1.9843,
      "step": 8810
    },
    {
      "epoch": 40.646651270207855,
      "grad_norm": 0.36081400513648987,
      "learning_rate": 0.0004540267566906234,
      "loss": 1.9925,
      "step": 8820
    },
    {
      "epoch": 40.69284064665127,
      "grad_norm": 0.5002955198287964,
      "learning_rate": 0.0004539205750609423,
      "loss": 1.985,
      "step": 8830
    },
    {
      "epoch": 40.739030023094685,
      "grad_norm": 0.47249892354011536,
      "learning_rate": 0.00045381428339827737,
      "loss": 1.9705,
      "step": 8840
    },
    {
      "epoch": 40.78521939953811,
      "grad_norm": 0.37131020426750183,
      "learning_rate": 0.0004537078817599822,
      "loss": 1.983,
      "step": 8850
    },
    {
      "epoch": 40.83140877598152,
      "grad_norm": 0.37864357233047485,
      "learning_rate": 0.0004536013702034698,
      "loss": 1.9833,
      "step": 8860
    },
    {
      "epoch": 40.877598152424945,
      "grad_norm": 0.3653697371482849,
      "learning_rate": 0.00045349474878621254,
      "loss": 1.9883,
      "step": 8870
    },
    {
      "epoch": 40.92378752886836,
      "grad_norm": 0.418332040309906,
      "learning_rate": 0.0004533880175657419,
      "loss": 1.9782,
      "step": 8880
    },
    {
      "epoch": 40.969976905311775,
      "grad_norm": 0.3496263921260834,
      "learning_rate": 0.00045328117659964874,
      "loss": 1.988,
      "step": 8890
    },
    {
      "epoch": 41.0,
      "eval_loss": 0.9807165861129761,
      "eval_runtime": 6.9085,
      "eval_samples_per_second": 4035.455,
      "eval_steps_per_second": 15.778,
      "step": 8897
    },
    {
      "epoch": 41.01385681293303,
      "grad_norm": 0.3902212977409363,
      "learning_rate": 0.00045317422594558324,
      "loss": 1.8792,
      "step": 8900
    },
    {
      "epoch": 41.06004618937644,
      "grad_norm": 0.34751322865486145,
      "learning_rate": 0.00045306716566125433,
      "loss": 1.9771,
      "step": 8910
    },
    {
      "epoch": 41.10623556581986,
      "grad_norm": 0.4094010293483734,
      "learning_rate": 0.0004529599958044307,
      "loss": 1.9775,
      "step": 8920
    },
    {
      "epoch": 41.15242494226328,
      "grad_norm": 0.4226267337799072,
      "learning_rate": 0.0004528527164329397,
      "loss": 1.9723,
      "step": 8930
    },
    {
      "epoch": 41.198614318706696,
      "grad_norm": 0.3586522936820984,
      "learning_rate": 0.0004527453276046679,
      "loss": 1.9776,
      "step": 8940
    },
    {
      "epoch": 41.24480369515012,
      "grad_norm": 0.32860904932022095,
      "learning_rate": 0.00045263782937756113,
      "loss": 1.982,
      "step": 8950
    },
    {
      "epoch": 41.29099307159353,
      "grad_norm": 0.4289693236351013,
      "learning_rate": 0.0004525302218096239,
      "loss": 1.9919,
      "step": 8960
    },
    {
      "epoch": 41.33718244803695,
      "grad_norm": 0.3249164819717407,
      "learning_rate": 0.0004524225049589201,
      "loss": 1.9723,
      "step": 8970
    },
    {
      "epoch": 41.38337182448037,
      "grad_norm": 0.40771758556365967,
      "learning_rate": 0.00045231467888357224,
      "loss": 1.9765,
      "step": 8980
    },
    {
      "epoch": 41.429561200923786,
      "grad_norm": 0.35359644889831543,
      "learning_rate": 0.00045220674364176197,
      "loss": 1.9799,
      "step": 8990
    },
    {
      "epoch": 41.47575057736721,
      "grad_norm": 0.3224114775657654,
      "learning_rate": 0.0004520986992917297,
      "loss": 1.9817,
      "step": 9000
    },
    {
      "epoch": 41.52193995381062,
      "grad_norm": 0.3563312590122223,
      "learning_rate": 0.00045199054589177497,
      "loss": 1.9932,
      "step": 9010
    },
    {
      "epoch": 41.56812933025404,
      "grad_norm": 0.4147750437259674,
      "learning_rate": 0.0004518822835002559,
      "loss": 1.9909,
      "step": 9020
    },
    {
      "epoch": 41.61431870669746,
      "grad_norm": 0.4640215337276459,
      "learning_rate": 0.0004517739121755895,
      "loss": 1.991,
      "step": 9030
    },
    {
      "epoch": 41.660508083140876,
      "grad_norm": 0.3291410207748413,
      "learning_rate": 0.00045166543197625166,
      "loss": 1.9842,
      "step": 9040
    },
    {
      "epoch": 41.7066974595843,
      "grad_norm": 0.3070317208766937,
      "learning_rate": 0.0004515568429607768,
      "loss": 1.9867,
      "step": 9050
    },
    {
      "epoch": 41.75288683602771,
      "grad_norm": 0.4695499539375305,
      "learning_rate": 0.0004514481451877583,
      "loss": 1.9727,
      "step": 9060
    },
    {
      "epoch": 41.79907621247113,
      "grad_norm": 0.3946673572063446,
      "learning_rate": 0.0004513393387158482,
      "loss": 1.9646,
      "step": 9070
    },
    {
      "epoch": 41.84526558891455,
      "grad_norm": 0.4732406735420227,
      "learning_rate": 0.00045123042360375694,
      "loss": 1.9863,
      "step": 9080
    },
    {
      "epoch": 41.891454965357966,
      "grad_norm": 0.4624844491481781,
      "learning_rate": 0.0004511213999102538,
      "loss": 1.9881,
      "step": 9090
    },
    {
      "epoch": 41.93764434180139,
      "grad_norm": 0.3696446716785431,
      "learning_rate": 0.00045101226769416657,
      "loss": 1.9737,
      "step": 9100
    },
    {
      "epoch": 41.9838337182448,
      "grad_norm": 0.5967977046966553,
      "learning_rate": 0.0004509030270143817,
      "loss": 1.99,
      "step": 9110
    },
    {
      "epoch": 42.0,
      "eval_loss": 0.9799473881721497,
      "eval_runtime": 6.8133,
      "eval_samples_per_second": 4091.88,
      "eval_steps_per_second": 15.998,
      "step": 9114
    },
    {
      "epoch": 42.02771362586605,
      "grad_norm": 0.3727419674396515,
      "learning_rate": 0.000450793677929844,
      "loss": 1.8818,
      "step": 9120
    },
    {
      "epoch": 42.07390300230947,
      "grad_norm": 0.3288881480693817,
      "learning_rate": 0.00045068422049955695,
      "loss": 1.9686,
      "step": 9130
    },
    {
      "epoch": 42.12009237875289,
      "grad_norm": 0.6632506251335144,
      "learning_rate": 0.0004505746547825823,
      "loss": 1.9757,
      "step": 9140
    },
    {
      "epoch": 42.1662817551963,
      "grad_norm": 0.5352742075920105,
      "learning_rate": 0.00045046498083804043,
      "loss": 1.9794,
      "step": 9150
    },
    {
      "epoch": 42.212471131639724,
      "grad_norm": 0.3515239655971527,
      "learning_rate": 0.0004503551987251101,
      "loss": 1.9751,
      "step": 9160
    },
    {
      "epoch": 42.25866050808314,
      "grad_norm": 0.55674809217453,
      "learning_rate": 0.00045024530850302813,
      "loss": 1.9837,
      "step": 9170
    },
    {
      "epoch": 42.30484988452656,
      "grad_norm": 0.4005063772201538,
      "learning_rate": 0.0004501353102310901,
      "loss": 1.9826,
      "step": 9180
    },
    {
      "epoch": 42.351039260969976,
      "grad_norm": 0.3210945725440979,
      "learning_rate": 0.00045002520396864964,
      "loss": 1.98,
      "step": 9190
    },
    {
      "epoch": 42.39722863741339,
      "grad_norm": 0.36873793601989746,
      "learning_rate": 0.0004499149897751187,
      "loss": 1.9743,
      "step": 9200
    },
    {
      "epoch": 42.443418013856814,
      "grad_norm": 0.3345963954925537,
      "learning_rate": 0.00044980466770996744,
      "loss": 1.9766,
      "step": 9210
    },
    {
      "epoch": 42.48960739030023,
      "grad_norm": 0.3586755096912384,
      "learning_rate": 0.00044969423783272427,
      "loss": 1.9887,
      "step": 9220
    },
    {
      "epoch": 42.53579676674365,
      "grad_norm": 0.3594057857990265,
      "learning_rate": 0.0004495837002029759,
      "loss": 1.9733,
      "step": 9230
    },
    {
      "epoch": 42.581986143187066,
      "grad_norm": 0.28023529052734375,
      "learning_rate": 0.00044947305488036684,
      "loss": 1.9758,
      "step": 9240
    },
    {
      "epoch": 42.62817551963049,
      "grad_norm": 0.41045334935188293,
      "learning_rate": 0.00044936230192460004,
      "loss": 1.9776,
      "step": 9250
    },
    {
      "epoch": 42.674364896073904,
      "grad_norm": 0.5084614157676697,
      "learning_rate": 0.0004492514413954364,
      "loss": 1.9786,
      "step": 9260
    },
    {
      "epoch": 42.72055427251732,
      "grad_norm": 0.35694628953933716,
      "learning_rate": 0.0004491404733526949,
      "loss": 1.9847,
      "step": 9270
    },
    {
      "epoch": 42.76674364896074,
      "grad_norm": 0.45790746808052063,
      "learning_rate": 0.00044902939785625243,
      "loss": 1.9827,
      "step": 9280
    },
    {
      "epoch": 42.812933025404156,
      "grad_norm": 0.5413584113121033,
      "learning_rate": 0.0004489182149660439,
      "loss": 1.9721,
      "step": 9290
    },
    {
      "epoch": 42.85912240184758,
      "grad_norm": 0.3425586521625519,
      "learning_rate": 0.00044880692474206233,
      "loss": 1.9816,
      "step": 9300
    },
    {
      "epoch": 42.905311778290994,
      "grad_norm": 0.3523525893688202,
      "learning_rate": 0.0004486955272443584,
      "loss": 1.9846,
      "step": 9310
    },
    {
      "epoch": 42.95150115473441,
      "grad_norm": 0.4047834873199463,
      "learning_rate": 0.000448584022533041,
      "loss": 1.9899,
      "step": 9320
    },
    {
      "epoch": 42.99769053117783,
      "grad_norm": 0.3062343895435333,
      "learning_rate": 0.0004484724106682764,
      "loss": 1.9759,
      "step": 9330
    },
    {
      "epoch": 43.0,
      "eval_loss": 0.9798347353935242,
      "eval_runtime": 7.0193,
      "eval_samples_per_second": 3971.759,
      "eval_steps_per_second": 15.529,
      "step": 9331
    },
    {
      "epoch": 43.04157043879908,
      "grad_norm": 0.3580416440963745,
      "learning_rate": 0.00044836069171028917,
      "loss": 1.8703,
      "step": 9340
    },
    {
      "epoch": 43.08775981524249,
      "grad_norm": 0.454183429479599,
      "learning_rate": 0.00044824886571936143,
      "loss": 1.9761,
      "step": 9350
    },
    {
      "epoch": 43.133949191685915,
      "grad_norm": 0.9300539493560791,
      "learning_rate": 0.0004481369327558329,
      "loss": 1.9816,
      "step": 9360
    },
    {
      "epoch": 43.18013856812933,
      "grad_norm": 0.42683714628219604,
      "learning_rate": 0.00044802489288010144,
      "loss": 1.9685,
      "step": 9370
    },
    {
      "epoch": 43.226327944572745,
      "grad_norm": 0.4820200502872467,
      "learning_rate": 0.00044791274615262234,
      "loss": 1.9795,
      "step": 9380
    },
    {
      "epoch": 43.27251732101617,
      "grad_norm": 0.31374457478523254,
      "learning_rate": 0.0004478004926339084,
      "loss": 1.9658,
      "step": 9390
    },
    {
      "epoch": 43.31870669745958,
      "grad_norm": 0.4514908194541931,
      "learning_rate": 0.0004476881323845303,
      "loss": 1.9708,
      "step": 9400
    },
    {
      "epoch": 43.364896073903004,
      "grad_norm": 0.3770628869533539,
      "learning_rate": 0.0004475756654651162,
      "loss": 1.9976,
      "step": 9410
    },
    {
      "epoch": 43.41108545034642,
      "grad_norm": 0.4284827709197998,
      "learning_rate": 0.0004474630919363519,
      "loss": 1.9717,
      "step": 9420
    },
    {
      "epoch": 43.45727482678984,
      "grad_norm": 0.42482423782348633,
      "learning_rate": 0.0004473504118589807,
      "loss": 1.9737,
      "step": 9430
    },
    {
      "epoch": 43.50346420323326,
      "grad_norm": 0.3636029362678528,
      "learning_rate": 0.0004472376252938032,
      "loss": 1.9804,
      "step": 9440
    },
    {
      "epoch": 43.54965357967667,
      "grad_norm": 0.30637043714523315,
      "learning_rate": 0.0004471247323016777,
      "loss": 1.9722,
      "step": 9450
    },
    {
      "epoch": 43.595842956120094,
      "grad_norm": 0.4389072060585022,
      "learning_rate": 0.0004470117329435198,
      "loss": 1.9845,
      "step": 9460
    },
    {
      "epoch": 43.64203233256351,
      "grad_norm": 0.3793739676475525,
      "learning_rate": 0.0004468986272803027,
      "loss": 1.9829,
      "step": 9470
    },
    {
      "epoch": 43.68822170900693,
      "grad_norm": 0.4763248562812805,
      "learning_rate": 0.0004467854153730566,
      "loss": 1.9839,
      "step": 9480
    },
    {
      "epoch": 43.73441108545035,
      "grad_norm": 0.3838852047920227,
      "learning_rate": 0.00044667209728286927,
      "loss": 1.9702,
      "step": 9490
    },
    {
      "epoch": 43.78060046189376,
      "grad_norm": 0.40218690037727356,
      "learning_rate": 0.0004465586730708858,
      "loss": 1.9817,
      "step": 9500
    },
    {
      "epoch": 43.826789838337184,
      "grad_norm": 0.32945287227630615,
      "learning_rate": 0.00044644514279830846,
      "loss": 1.9847,
      "step": 9510
    },
    {
      "epoch": 43.8729792147806,
      "grad_norm": 0.3804514706134796,
      "learning_rate": 0.0004463315065263966,
      "loss": 1.9763,
      "step": 9520
    },
    {
      "epoch": 43.91916859122402,
      "grad_norm": 0.41695570945739746,
      "learning_rate": 0.0004462177643164672,
      "loss": 1.9792,
      "step": 9530
    },
    {
      "epoch": 43.96535796766744,
      "grad_norm": 0.36696386337280273,
      "learning_rate": 0.0004461039162298939,
      "loss": 1.9901,
      "step": 9540
    },
    {
      "epoch": 44.0,
      "eval_loss": 0.9801459312438965,
      "eval_runtime": 7.0229,
      "eval_samples_per_second": 3969.711,
      "eval_steps_per_second": 15.521,
      "step": 9548
    },
    {
      "epoch": 44.00923787528868,
      "grad_norm": 0.34367722272872925,
      "learning_rate": 0.00044598996232810787,
      "loss": 1.8692,
      "step": 9550
    },
    {
      "epoch": 44.0554272517321,
      "grad_norm": 0.4655226469039917,
      "learning_rate": 0.000445875902672597,
      "loss": 1.9723,
      "step": 9560
    },
    {
      "epoch": 44.10161662817552,
      "grad_norm": 0.6363428831100464,
      "learning_rate": 0.00044576173732490667,
      "loss": 1.9811,
      "step": 9570
    },
    {
      "epoch": 44.147806004618936,
      "grad_norm": 0.37498682737350464,
      "learning_rate": 0.000445647466346639,
      "loss": 1.9528,
      "step": 9580
    },
    {
      "epoch": 44.19399538106236,
      "grad_norm": 0.5161201357841492,
      "learning_rate": 0.00044553308979945305,
      "loss": 1.9801,
      "step": 9590
    },
    {
      "epoch": 44.24018475750577,
      "grad_norm": 0.3191063106060028,
      "learning_rate": 0.0004454186077450651,
      "loss": 1.9811,
      "step": 9600
    },
    {
      "epoch": 44.286374133949195,
      "grad_norm": 0.37503883242607117,
      "learning_rate": 0.0004453040202452482,
      "loss": 1.9761,
      "step": 9610
    },
    {
      "epoch": 44.33256351039261,
      "grad_norm": 0.3749960958957672,
      "learning_rate": 0.0004451893273618323,
      "loss": 1.9688,
      "step": 9620
    },
    {
      "epoch": 44.378752886836025,
      "grad_norm": 1.0880892276763916,
      "learning_rate": 0.00044507452915670424,
      "loss": 1.9675,
      "step": 9630
    },
    {
      "epoch": 44.42494226327945,
      "grad_norm": 0.4666260778903961,
      "learning_rate": 0.0004449596256918078,
      "loss": 1.9711,
      "step": 9640
    },
    {
      "epoch": 44.47113163972286,
      "grad_norm": 1.5750974416732788,
      "learning_rate": 0.00044484461702914334,
      "loss": 1.9622,
      "step": 9650
    },
    {
      "epoch": 44.517321016166285,
      "grad_norm": 0.541342556476593,
      "learning_rate": 0.0004447295032307681,
      "loss": 1.9823,
      "step": 9660
    },
    {
      "epoch": 44.5635103926097,
      "grad_norm": 0.437765896320343,
      "learning_rate": 0.000444614284358796,
      "loss": 1.9882,
      "step": 9670
    },
    {
      "epoch": 44.609699769053115,
      "grad_norm": 0.4170253574848175,
      "learning_rate": 0.0004444989604753978,
      "loss": 1.9791,
      "step": 9680
    },
    {
      "epoch": 44.65588914549654,
      "grad_norm": 0.3846833109855652,
      "learning_rate": 0.00044438353164280076,
      "loss": 1.9788,
      "step": 9690
    },
    {
      "epoch": 44.70207852193995,
      "grad_norm": 0.48842817544937134,
      "learning_rate": 0.00044426799792328885,
      "loss": 1.981,
      "step": 9700
    },
    {
      "epoch": 44.748267898383375,
      "grad_norm": 0.5312727093696594,
      "learning_rate": 0.0004441523593792027,
      "loss": 1.9721,
      "step": 9710
    },
    {
      "epoch": 44.79445727482679,
      "grad_norm": 0.3933790326118469,
      "learning_rate": 0.0004440366160729392,
      "loss": 1.9779,
      "step": 9720
    },
    {
      "epoch": 44.840646651270205,
      "grad_norm": 0.37302109599113464,
      "learning_rate": 0.0004439207680669522,
      "loss": 1.9707,
      "step": 9730
    },
    {
      "epoch": 44.88683602771363,
      "grad_norm": 0.4531574547290802,
      "learning_rate": 0.0004438048154237517,
      "loss": 1.9829,
      "step": 9740
    },
    {
      "epoch": 44.93302540415704,
      "grad_norm": 0.490139901638031,
      "learning_rate": 0.00044368875820590434,
      "loss": 1.9835,
      "step": 9750
    },
    {
      "epoch": 44.979214780600465,
      "grad_norm": 0.3025646209716797,
      "learning_rate": 0.0004435725964760331,
      "loss": 1.9839,
      "step": 9760
    },
    {
      "epoch": 45.0,
      "eval_loss": 0.9798488616943359,
      "eval_runtime": 6.8383,
      "eval_samples_per_second": 4076.864,
      "eval_steps_per_second": 15.94,
      "step": 9765
    },
    {
      "epoch": 45.02309468822171,
      "grad_norm": 0.3392859101295471,
      "learning_rate": 0.00044345633029681746,
      "loss": 1.8635,
      "step": 9770
    },
    {
      "epoch": 45.069284064665126,
      "grad_norm": 0.37861642241477966,
      "learning_rate": 0.0004433399597309932,
      "loss": 1.9592,
      "step": 9780
    },
    {
      "epoch": 45.11547344110855,
      "grad_norm": 0.397879421710968,
      "learning_rate": 0.0004432234848413523,
      "loss": 1.9649,
      "step": 9790
    },
    {
      "epoch": 45.161662817551964,
      "grad_norm": 0.4445500373840332,
      "learning_rate": 0.00044310690569074324,
      "loss": 1.9734,
      "step": 9800
    },
    {
      "epoch": 45.20785219399538,
      "grad_norm": 0.45975422859191895,
      "learning_rate": 0.00044299022234207063,
      "loss": 1.9747,
      "step": 9810
    },
    {
      "epoch": 45.2540415704388,
      "grad_norm": 0.37966006994247437,
      "learning_rate": 0.00044287343485829546,
      "loss": 1.972,
      "step": 9820
    },
    {
      "epoch": 45.300230946882216,
      "grad_norm": 0.5840148329734802,
      "learning_rate": 0.0004427565433024346,
      "loss": 1.9819,
      "step": 9830
    },
    {
      "epoch": 45.34642032332564,
      "grad_norm": 0.4520987272262573,
      "learning_rate": 0.00044263954773756146,
      "loss": 1.9829,
      "step": 9840
    },
    {
      "epoch": 45.392609699769054,
      "grad_norm": 0.4467379152774811,
      "learning_rate": 0.0004425224482268051,
      "loss": 1.9764,
      "step": 9850
    },
    {
      "epoch": 45.43879907621247,
      "grad_norm": 0.6336348056793213,
      "learning_rate": 0.0004424052448333513,
      "loss": 1.9764,
      "step": 9860
    },
    {
      "epoch": 45.48498845265589,
      "grad_norm": 0.4408501386642456,
      "learning_rate": 0.0004422879376204413,
      "loss": 1.9735,
      "step": 9870
    },
    {
      "epoch": 45.531177829099306,
      "grad_norm": 0.4367579221725464,
      "learning_rate": 0.00044217052665137266,
      "loss": 1.9821,
      "step": 9880
    },
    {
      "epoch": 45.57736720554273,
      "grad_norm": 0.4051966369152069,
      "learning_rate": 0.0004420530119894989,
      "loss": 1.9823,
      "step": 9890
    },
    {
      "epoch": 45.62355658198614,
      "grad_norm": 0.5109026432037354,
      "learning_rate": 0.0004419353936982293,
      "loss": 1.9811,
      "step": 9900
    },
    {
      "epoch": 45.66974595842956,
      "grad_norm": 0.3852418065071106,
      "learning_rate": 0.0004418176718410295,
      "loss": 1.9829,
      "step": 9910
    },
    {
      "epoch": 45.71593533487298,
      "grad_norm": 0.4554482698440552,
      "learning_rate": 0.0004416998464814206,
      "loss": 1.9672,
      "step": 9920
    },
    {
      "epoch": 45.762124711316396,
      "grad_norm": 0.5981774926185608,
      "learning_rate": 0.0004415819176829795,
      "loss": 1.9771,
      "step": 9930
    },
    {
      "epoch": 45.80831408775982,
      "grad_norm": 0.40140265226364136,
      "learning_rate": 0.0004414638855093394,
      "loss": 1.9772,
      "step": 9940
    },
    {
      "epoch": 45.85450346420323,
      "grad_norm": 0.3709976375102997,
      "learning_rate": 0.0004413457500241888,
      "loss": 1.9838,
      "step": 9950
    },
    {
      "epoch": 45.90069284064665,
      "grad_norm": 0.42467349767684937,
      "learning_rate": 0.0004412275112912722,
      "loss": 1.9814,
      "step": 9960
    },
    {
      "epoch": 45.94688221709007,
      "grad_norm": 0.44054627418518066,
      "learning_rate": 0.0004411091693743897,
      "loss": 1.9718,
      "step": 9970
    },
    {
      "epoch": 45.993071593533486,
      "grad_norm": 0.3635377585887909,
      "learning_rate": 0.0004409907243373971,
      "loss": 1.9649,
      "step": 9980
    },
    {
      "epoch": 46.0,
      "eval_loss": 0.9808231592178345,
      "eval_runtime": 7.0376,
      "eval_samples_per_second": 3961.423,
      "eval_steps_per_second": 15.488,
      "step": 9982
    },
    {
      "epoch": 46.03695150115473,
      "grad_norm": 0.4321053922176361,
      "learning_rate": 0.0004408721762442059,
      "loss": 1.866,
      "step": 9990
    },
    {
      "epoch": 46.083140877598154,
      "grad_norm": 0.362097829580307,
      "learning_rate": 0.00044075352515878316,
      "loss": 1.9723,
      "step": 10000
    },
    {
      "epoch": 46.12933025404157,
      "grad_norm": 0.4787229001522064,
      "learning_rate": 0.00044063477114515145,
      "loss": 1.9694,
      "step": 10010
    },
    {
      "epoch": 46.17551963048499,
      "grad_norm": 0.43596193194389343,
      "learning_rate": 0.000440515914267389,
      "loss": 1.9752,
      "step": 10020
    },
    {
      "epoch": 46.22170900692841,
      "grad_norm": 0.3314361870288849,
      "learning_rate": 0.00044039695458962953,
      "loss": 1.9774,
      "step": 10030
    },
    {
      "epoch": 46.26789838337182,
      "grad_norm": 0.5143150687217712,
      "learning_rate": 0.0004402778921760621,
      "loss": 1.9761,
      "step": 10040
    },
    {
      "epoch": 46.314087759815244,
      "grad_norm": 0.45152977108955383,
      "learning_rate": 0.0004401587270909314,
      "loss": 1.9777,
      "step": 10050
    },
    {
      "epoch": 46.36027713625866,
      "grad_norm": 0.4444468021392822,
      "learning_rate": 0.0004400394593985373,
      "loss": 1.9752,
      "step": 10060
    },
    {
      "epoch": 46.40646651270208,
      "grad_norm": 0.4843195378780365,
      "learning_rate": 0.00043992008916323523,
      "loss": 1.9701,
      "step": 10070
    },
    {
      "epoch": 46.4526558891455,
      "grad_norm": 0.41457340121269226,
      "learning_rate": 0.00043980061644943583,
      "loss": 1.9744,
      "step": 10080
    },
    {
      "epoch": 46.49884526558891,
      "grad_norm": 0.37261804938316345,
      "learning_rate": 0.0004396810413216051,
      "loss": 1.9733,
      "step": 10090
    },
    {
      "epoch": 46.545034642032334,
      "grad_norm": 0.46572643518447876,
      "learning_rate": 0.0004395613638442643,
      "loss": 1.9794,
      "step": 10100
    },
    {
      "epoch": 46.59122401847575,
      "grad_norm": 0.3312312960624695,
      "learning_rate": 0.0004394415840819898,
      "loss": 1.967,
      "step": 10110
    },
    {
      "epoch": 46.63741339491917,
      "grad_norm": 0.4593958556652069,
      "learning_rate": 0.00043932170209941333,
      "loss": 1.976,
      "step": 10120
    },
    {
      "epoch": 46.68360277136259,
      "grad_norm": 0.8075534701347351,
      "learning_rate": 0.0004392017179612218,
      "loss": 1.9723,
      "step": 10130
    },
    {
      "epoch": 46.729792147806,
      "grad_norm": 0.3401891887187958,
      "learning_rate": 0.000439081631732157,
      "loss": 1.9736,
      "step": 10140
    },
    {
      "epoch": 46.775981524249424,
      "grad_norm": 0.4997062087059021,
      "learning_rate": 0.00043896144347701593,
      "loss": 1.9726,
      "step": 10150
    },
    {
      "epoch": 46.82217090069284,
      "grad_norm": 0.46054914593696594,
      "learning_rate": 0.0004388411532606508,
      "loss": 1.9796,
      "step": 10160
    },
    {
      "epoch": 46.86836027713626,
      "grad_norm": 0.4840955138206482,
      "learning_rate": 0.0004387207611479686,
      "loss": 1.9835,
      "step": 10170
    },
    {
      "epoch": 46.91454965357968,
      "grad_norm": 0.4121989905834198,
      "learning_rate": 0.00043860026720393143,
      "loss": 1.975,
      "step": 10180
    },
    {
      "epoch": 46.96073903002309,
      "grad_norm": 0.4364556074142456,
      "learning_rate": 0.00043847967149355626,
      "loss": 1.9788,
      "step": 10190
    },
    {
      "epoch": 47.0,
      "eval_loss": 0.9794661402702332,
      "eval_runtime": 6.8482,
      "eval_samples_per_second": 4071.007,
      "eval_steps_per_second": 15.917,
      "step": 10199
    },
    {
      "epoch": 47.004618937644345,
      "grad_norm": 0.3992270231246948,
      "learning_rate": 0.00043835897408191514,
      "loss": 1.8728,
      "step": 10200
    },
    {
      "epoch": 47.05080831408776,
      "grad_norm": 0.44594424962997437,
      "learning_rate": 0.0004382381750341349,
      "loss": 1.9696,
      "step": 10210
    },
    {
      "epoch": 47.096997690531175,
      "grad_norm": 0.44490811228752136,
      "learning_rate": 0.000438117274415397,
      "loss": 1.9724,
      "step": 10220
    },
    {
      "epoch": 47.1431870669746,
      "grad_norm": 0.519218385219574,
      "learning_rate": 0.0004379962722909381,
      "loss": 1.9596,
      "step": 10230
    },
    {
      "epoch": 47.18937644341801,
      "grad_norm": 0.4384523630142212,
      "learning_rate": 0.0004378751687260492,
      "loss": 1.9717,
      "step": 10240
    },
    {
      "epoch": 47.235565819861435,
      "grad_norm": 0.4501511752605438,
      "learning_rate": 0.00043775396378607654,
      "loss": 1.9859,
      "step": 10250
    },
    {
      "epoch": 47.28175519630485,
      "grad_norm": 0.3975732624530792,
      "learning_rate": 0.0004376326575364206,
      "loss": 1.9841,
      "step": 10260
    },
    {
      "epoch": 47.327944572748265,
      "grad_norm": 0.8216761350631714,
      "learning_rate": 0.00043751125004253666,
      "loss": 1.9705,
      "step": 10270
    },
    {
      "epoch": 47.37413394919169,
      "grad_norm": 0.46480026841163635,
      "learning_rate": 0.00043738974136993484,
      "loss": 1.9755,
      "step": 10280
    },
    {
      "epoch": 47.4203233256351,
      "grad_norm": 0.6103353500366211,
      "learning_rate": 0.0004372681315841797,
      "loss": 1.9706,
      "step": 10290
    },
    {
      "epoch": 47.466512702078525,
      "grad_norm": 0.38529127836227417,
      "learning_rate": 0.00043714642075089015,
      "loss": 1.9727,
      "step": 10300
    },
    {
      "epoch": 47.51270207852194,
      "grad_norm": 0.4609129726886749,
      "learning_rate": 0.00043702460893574004,
      "loss": 1.9706,
      "step": 10310
    },
    {
      "epoch": 47.558891454965355,
      "grad_norm": 0.7904649972915649,
      "learning_rate": 0.0004369026962044574,
      "loss": 1.9777,
      "step": 10320
    },
    {
      "epoch": 47.60508083140878,
      "grad_norm": 0.5792955756187439,
      "learning_rate": 0.00043678068262282486,
      "loss": 1.9746,
      "step": 10330
    },
    {
      "epoch": 47.65127020785219,
      "grad_norm": 0.3755238950252533,
      "learning_rate": 0.0004366585682566793,
      "loss": 1.972,
      "step": 10340
    },
    {
      "epoch": 47.697459584295615,
      "grad_norm": 0.39476242661476135,
      "learning_rate": 0.00043653635317191224,
      "loss": 1.9629,
      "step": 10350
    },
    {
      "epoch": 47.74364896073903,
      "grad_norm": 0.41284599900245667,
      "learning_rate": 0.0004364140374344694,
      "loss": 1.9774,
      "step": 10360
    },
    {
      "epoch": 47.789838337182445,
      "grad_norm": 0.44100385904312134,
      "learning_rate": 0.0004362916211103507,
      "loss": 1.9864,
      "step": 10370
    },
    {
      "epoch": 47.83602771362587,
      "grad_norm": 0.3762334883213043,
      "learning_rate": 0.00043616910426561055,
      "loss": 1.9721,
      "step": 10380
    },
    {
      "epoch": 47.88221709006928,
      "grad_norm": 0.4820716083049774,
      "learning_rate": 0.00043604648696635753,
      "loss": 1.9646,
      "step": 10390
    },
    {
      "epoch": 47.928406466512705,
      "grad_norm": 0.37227103114128113,
      "learning_rate": 0.00043592376927875426,
      "loss": 1.9688,
      "step": 10400
    },
    {
      "epoch": 47.97459584295612,
      "grad_norm": 0.42796728014945984,
      "learning_rate": 0.00043580095126901773,
      "loss": 1.9865,
      "step": 10410
    },
    {
      "epoch": 48.0,
      "eval_loss": 0.980705976486206,
      "eval_runtime": 6.848,
      "eval_samples_per_second": 4071.118,
      "eval_steps_per_second": 15.917,
      "step": 10416
    },
    {
      "epoch": 48.018475750577366,
      "grad_norm": 0.5109761357307434,
      "learning_rate": 0.0004356780330034191,
      "loss": 1.8732,
      "step": 10420
    },
    {
      "epoch": 48.06466512702079,
      "grad_norm": 0.41528111696243286,
      "learning_rate": 0.0004355550145482834,
      "loss": 1.9788,
      "step": 10430
    },
    {
      "epoch": 48.1108545034642,
      "grad_norm": 0.4749591052532196,
      "learning_rate": 0.0004354318959699899,
      "loss": 1.9646,
      "step": 10440
    },
    {
      "epoch": 48.15704387990762,
      "grad_norm": 0.3835237920284271,
      "learning_rate": 0.00043530867733497183,
      "loss": 1.9685,
      "step": 10450
    },
    {
      "epoch": 48.20323325635104,
      "grad_norm": 0.5495262742042542,
      "learning_rate": 0.0004351853587097164,
      "loss": 1.9781,
      "step": 10460
    },
    {
      "epoch": 48.249422632794456,
      "grad_norm": 0.38105863332748413,
      "learning_rate": 0.00043506194016076477,
      "loss": 1.9798,
      "step": 10470
    },
    {
      "epoch": 48.29561200923788,
      "grad_norm": 0.41931602358818054,
      "learning_rate": 0.0004349384217547121,
      "loss": 1.9798,
      "step": 10480
    },
    {
      "epoch": 48.34180138568129,
      "grad_norm": 0.5047326683998108,
      "learning_rate": 0.00043481480355820733,
      "loss": 1.9627,
      "step": 10490
    },
    {
      "epoch": 48.38799076212471,
      "grad_norm": 0.44413211941719055,
      "learning_rate": 0.00043469108563795334,
      "loss": 1.9702,
      "step": 10500
    },
    {
      "epoch": 48.43418013856813,
      "grad_norm": 0.4898940324783325,
      "learning_rate": 0.00043456726806070673,
      "loss": 1.9739,
      "step": 10510
    },
    {
      "epoch": 48.480369515011546,
      "grad_norm": 0.45811745524406433,
      "learning_rate": 0.00043444335089327794,
      "loss": 1.968,
      "step": 10520
    },
    {
      "epoch": 48.52655889145497,
      "grad_norm": 0.3737873136997223,
      "learning_rate": 0.000434319334202531,
      "loss": 1.9751,
      "step": 10530
    },
    {
      "epoch": 48.57274826789838,
      "grad_norm": 0.33393123745918274,
      "learning_rate": 0.00043419521805538393,
      "loss": 1.974,
      "step": 10540
    },
    {
      "epoch": 48.6189376443418,
      "grad_norm": 0.41490066051483154,
      "learning_rate": 0.00043407100251880814,
      "loss": 1.9723,
      "step": 10550
    },
    {
      "epoch": 48.66512702078522,
      "grad_norm": 0.5385191440582275,
      "learning_rate": 0.0004339466876598288,
      "loss": 1.976,
      "step": 10560
    },
    {
      "epoch": 48.711316397228636,
      "grad_norm": 0.397591769695282,
      "learning_rate": 0.0004338222735455247,
      "loss": 1.9734,
      "step": 10570
    },
    {
      "epoch": 48.75750577367206,
      "grad_norm": 0.43621838092803955,
      "learning_rate": 0.00043369776024302807,
      "loss": 1.9603,
      "step": 10580
    },
    {
      "epoch": 48.80369515011547,
      "grad_norm": 0.30695825815200806,
      "learning_rate": 0.0004335731478195247,
      "loss": 1.9746,
      "step": 10590
    },
    {
      "epoch": 48.84988452655889,
      "grad_norm": 0.38107818365097046,
      "learning_rate": 0.000433448436342254,
      "loss": 1.9719,
      "step": 10600
    },
    {
      "epoch": 48.89607390300231,
      "grad_norm": 0.45418766140937805,
      "learning_rate": 0.0004333236258785086,
      "loss": 1.9779,
      "step": 10610
    },
    {
      "epoch": 48.942263279445726,
      "grad_norm": 0.3424968421459198,
      "learning_rate": 0.0004331987164956347,
      "loss": 1.967,
      "step": 10620
    },
    {
      "epoch": 48.98845265588915,
      "grad_norm": 0.4168732762336731,
      "learning_rate": 0.00043307370826103193,
      "loss": 1.9756,
      "step": 10630
    },
    {
      "epoch": 49.0,
      "eval_loss": 0.9799917936325073,
      "eval_runtime": 6.8773,
      "eval_samples_per_second": 4053.748,
      "eval_steps_per_second": 15.849,
      "step": 10633
    },
    {
      "epoch": 49.032332563510394,
      "grad_norm": 0.3948875665664673,
      "learning_rate": 0.00043294860124215307,
      "loss": 1.8685,
      "step": 10640
    },
    {
      "epoch": 49.07852193995381,
      "grad_norm": 0.46902915835380554,
      "learning_rate": 0.0004328233955065042,
      "loss": 1.9664,
      "step": 10650
    },
    {
      "epoch": 49.12471131639723,
      "grad_norm": 0.40810689330101013,
      "learning_rate": 0.000432698091121645,
      "loss": 1.9777,
      "step": 10660
    },
    {
      "epoch": 49.17090069284065,
      "grad_norm": 0.4647248089313507,
      "learning_rate": 0.000432572688155188,
      "loss": 1.9652,
      "step": 10670
    },
    {
      "epoch": 49.21709006928406,
      "grad_norm": 0.36714187264442444,
      "learning_rate": 0.000432447186674799,
      "loss": 1.9723,
      "step": 10680
    },
    {
      "epoch": 49.263279445727484,
      "grad_norm": 0.3146182894706726,
      "learning_rate": 0.0004323215867481972,
      "loss": 1.9758,
      "step": 10690
    },
    {
      "epoch": 49.3094688221709,
      "grad_norm": 0.31605616211891174,
      "learning_rate": 0.0004321958884431546,
      "loss": 1.9663,
      "step": 10700
    },
    {
      "epoch": 49.35565819861432,
      "grad_norm": 0.4139541685581207,
      "learning_rate": 0.00043207009182749656,
      "loss": 1.9713,
      "step": 10710
    },
    {
      "epoch": 49.40184757505774,
      "grad_norm": 0.4016987085342407,
      "learning_rate": 0.00043194419696910126,
      "loss": 1.9797,
      "step": 10720
    },
    {
      "epoch": 49.44803695150115,
      "grad_norm": 0.29794904589653015,
      "learning_rate": 0.00043181820393589995,
      "loss": 1.978,
      "step": 10730
    },
    {
      "epoch": 49.494226327944574,
      "grad_norm": 0.40187427401542664,
      "learning_rate": 0.0004316921127958769,
      "loss": 1.9621,
      "step": 10740
    },
    {
      "epoch": 49.54041570438799,
      "grad_norm": 0.3269955515861511,
      "learning_rate": 0.00043156592361706946,
      "loss": 1.9739,
      "step": 10750
    },
    {
      "epoch": 49.58660508083141,
      "grad_norm": 0.6423463225364685,
      "learning_rate": 0.0004314396364675676,
      "loss": 1.979,
      "step": 10760
    },
    {
      "epoch": 49.63279445727483,
      "grad_norm": 0.548040509223938,
      "learning_rate": 0.0004313132514155143,
      "loss": 1.9764,
      "step": 10770
    },
    {
      "epoch": 49.67898383371824,
      "grad_norm": 0.4134853184223175,
      "learning_rate": 0.00043118676852910533,
      "loss": 1.9723,
      "step": 10780
    },
    {
      "epoch": 49.725173210161664,
      "grad_norm": 0.5383604168891907,
      "learning_rate": 0.00043106018787658927,
      "loss": 1.9639,
      "step": 10790
    },
    {
      "epoch": 49.77136258660508,
      "grad_norm": 0.4972149133682251,
      "learning_rate": 0.0004309335095262675,
      "loss": 1.9632,
      "step": 10800
    },
    {
      "epoch": 49.8175519630485,
      "grad_norm": 0.42582085728645325,
      "learning_rate": 0.00043080673354649416,
      "loss": 1.9715,
      "step": 10810
    },
    {
      "epoch": 49.86374133949192,
      "grad_norm": 0.3314015865325928,
      "learning_rate": 0.00043067986000567567,
      "loss": 1.9681,
      "step": 10820
    },
    {
      "epoch": 49.90993071593533,
      "grad_norm": 0.5925945043563843,
      "learning_rate": 0.00043055288897227167,
      "loss": 1.968,
      "step": 10830
    },
    {
      "epoch": 49.956120092378754,
      "grad_norm": 0.4991060793399811,
      "learning_rate": 0.0004304258205147941,
      "loss": 1.9712,
      "step": 10840
    },
    {
      "epoch": 50.0,
      "grad_norm": 0.31813177466392517,
      "learning_rate": 0.00043029865470180733,
      "loss": 1.8762,
      "step": 10850
    },
    {
      "epoch": 50.0,
      "eval_loss": 0.9795488715171814,
      "eval_runtime": 6.8547,
      "eval_samples_per_second": 4067.133,
      "eval_steps_per_second": 15.901,
      "step": 10850
    },
    {
      "epoch": 50.046189376443415,
      "grad_norm": 0.5666905045509338,
      "learning_rate": 0.00043017139160192864,
      "loss": 1.9774,
      "step": 10860
    },
    {
      "epoch": 50.09237875288684,
      "grad_norm": 0.3997970223426819,
      "learning_rate": 0.0004300440312838275,
      "loss": 1.9536,
      "step": 10870
    },
    {
      "epoch": 50.13856812933025,
      "grad_norm": 0.43010473251342773,
      "learning_rate": 0.00042991657381622606,
      "loss": 1.9722,
      "step": 10880
    },
    {
      "epoch": 50.184757505773675,
      "grad_norm": 0.4585723876953125,
      "learning_rate": 0.0004297890192678986,
      "loss": 1.9655,
      "step": 10890
    },
    {
      "epoch": 50.23094688221709,
      "grad_norm": 0.45200103521347046,
      "learning_rate": 0.00042966136770767206,
      "loss": 1.972,
      "step": 10900
    },
    {
      "epoch": 50.277136258660505,
      "grad_norm": 0.4121478497982025,
      "learning_rate": 0.0004295336192044256,
      "loss": 1.963,
      "step": 10910
    },
    {
      "epoch": 50.32332563510393,
      "grad_norm": 0.5033197999000549,
      "learning_rate": 0.0004294057738270907,
      "loss": 1.9609,
      "step": 10920
    },
    {
      "epoch": 50.36951501154734,
      "grad_norm": 0.34233927726745605,
      "learning_rate": 0.0004292778316446511,
      "loss": 1.9644,
      "step": 10930
    },
    {
      "epoch": 50.415704387990765,
      "grad_norm": 0.3698129653930664,
      "learning_rate": 0.00042914979272614285,
      "loss": 1.969,
      "step": 10940
    },
    {
      "epoch": 50.46189376443418,
      "grad_norm": 0.5338481664657593,
      "learning_rate": 0.0004290216571406541,
      "loss": 1.9762,
      "step": 10950
    },
    {
      "epoch": 50.508083140877595,
      "grad_norm": 0.3993370234966278,
      "learning_rate": 0.00042889342495732526,
      "loss": 1.9726,
      "step": 10960
    },
    {
      "epoch": 50.55427251732102,
      "grad_norm": 1.2142279148101807,
      "learning_rate": 0.0004287650962453487,
      "loss": 1.9624,
      "step": 10970
    },
    {
      "epoch": 50.60046189376443,
      "grad_norm": 0.6445828080177307,
      "learning_rate": 0.0004286366710739691,
      "loss": 1.9688,
      "step": 10980
    },
    {
      "epoch": 50.646651270207855,
      "grad_norm": 0.38787660002708435,
      "learning_rate": 0.00042850814951248304,
      "loss": 1.9745,
      "step": 10990
    },
    {
      "epoch": 50.69284064665127,
      "grad_norm": 0.4038280248641968,
      "learning_rate": 0.000428379531630239,
      "loss": 1.982,
      "step": 11000
    },
    {
      "epoch": 50.739030023094685,
      "grad_norm": 0.48556384444236755,
      "learning_rate": 0.00042825081749663785,
      "loss": 1.9635,
      "step": 11010
    },
    {
      "epoch": 50.78521939953811,
      "grad_norm": 0.5266548991203308,
      "learning_rate": 0.0004281220071811319,
      "loss": 1.9658,
      "step": 11020
    },
    {
      "epoch": 50.83140877598152,
      "grad_norm": 0.35014188289642334,
      "learning_rate": 0.0004279931007532257,
      "loss": 1.968,
      "step": 11030
    },
    {
      "epoch": 50.877598152424945,
      "grad_norm": 0.37320631742477417,
      "learning_rate": 0.0004278640982824754,
      "loss": 1.9763,
      "step": 11040
    },
    {
      "epoch": 50.92378752886836,
      "grad_norm": 0.37881672382354736,
      "learning_rate": 0.00042773499983848927,
      "loss": 1.9726,
      "step": 11050
    },
    {
      "epoch": 50.969976905311775,
      "grad_norm": 0.40123122930526733,
      "learning_rate": 0.0004276058054909272,
      "loss": 1.9655,
      "step": 11060
    },
    {
      "epoch": 51.0,
      "eval_loss": 0.9808847308158875,
      "eval_runtime": 6.8547,
      "eval_samples_per_second": 4067.157,
      "eval_steps_per_second": 15.902,
      "step": 11067
    },
    {
      "epoch": 51.01385681293303,
      "grad_norm": 0.33224913477897644,
      "learning_rate": 0.00042747651530950073,
      "loss": 1.8787,
      "step": 11070
    },
    {
      "epoch": 51.06004618937644,
      "grad_norm": 0.4030626118183136,
      "learning_rate": 0.00042734712936397327,
      "loss": 1.961,
      "step": 11080
    },
    {
      "epoch": 51.10623556581986,
      "grad_norm": 0.4220256209373474,
      "learning_rate": 0.0004272176477241598,
      "loss": 1.9608,
      "step": 11090
    },
    {
      "epoch": 51.15242494226328,
      "grad_norm": 0.42572739720344543,
      "learning_rate": 0.0004270880704599272,
      "loss": 1.9628,
      "step": 11100
    },
    {
      "epoch": 51.198614318706696,
      "grad_norm": 0.5193037390708923,
      "learning_rate": 0.0004269583976411934,
      "loss": 1.9783,
      "step": 11110
    },
    {
      "epoch": 51.24480369515012,
      "grad_norm": 0.478080689907074,
      "learning_rate": 0.00042682862933792853,
      "loss": 1.9632,
      "step": 11120
    },
    {
      "epoch": 51.29099307159353,
      "grad_norm": 0.3789161443710327,
      "learning_rate": 0.0004266987656201538,
      "loss": 1.973,
      "step": 11130
    },
    {
      "epoch": 51.33718244803695,
      "grad_norm": 0.5934411287307739,
      "learning_rate": 0.00042656880655794207,
      "loss": 1.9755,
      "step": 11140
    },
    {
      "epoch": 51.38337182448037,
      "grad_norm": 0.5805989503860474,
      "learning_rate": 0.0004264387522214176,
      "loss": 1.9687,
      "step": 11150
    },
    {
      "epoch": 51.429561200923786,
      "grad_norm": 0.46755608916282654,
      "learning_rate": 0.0004263086026807561,
      "loss": 1.965,
      "step": 11160
    },
    {
      "epoch": 51.47575057736721,
      "grad_norm": 0.826751172542572,
      "learning_rate": 0.0004261783580061845,
      "loss": 1.9637,
      "step": 11170
    },
    {
      "epoch": 51.52193995381062,
      "grad_norm": 0.6608389616012573,
      "learning_rate": 0.00042604801826798147,
      "loss": 1.955,
      "step": 11180
    },
    {
      "epoch": 51.56812933025404,
      "grad_norm": 0.5018754005432129,
      "learning_rate": 0.00042591758353647646,
      "loss": 1.9819,
      "step": 11190
    },
    {
      "epoch": 51.61431870669746,
      "grad_norm": 0.7459976673126221,
      "learning_rate": 0.0004257870538820505,
      "loss": 1.9687,
      "step": 11200
    },
    {
      "epoch": 51.660508083140876,
      "grad_norm": 0.5459526777267456,
      "learning_rate": 0.0004256564293751358,
      "loss": 1.9768,
      "step": 11210
    },
    {
      "epoch": 51.7066974595843,
      "grad_norm": 0.6190107464790344,
      "learning_rate": 0.0004255257100862156,
      "loss": 1.9661,
      "step": 11220
    },
    {
      "epoch": 51.75288683602771,
      "grad_norm": 0.502424418926239,
      "learning_rate": 0.0004253948960858244,
      "loss": 1.9571,
      "step": 11230
    },
    {
      "epoch": 51.79907621247113,
      "grad_norm": 0.4162086546421051,
      "learning_rate": 0.0004252639874445479,
      "loss": 1.9802,
      "step": 11240
    },
    {
      "epoch": 51.84526558891455,
      "grad_norm": 1.087726354598999,
      "learning_rate": 0.0004251329842330227,
      "loss": 1.9699,
      "step": 11250
    },
    {
      "epoch": 51.891454965357966,
      "grad_norm": 0.8382658958435059,
      "learning_rate": 0.0004250018865219365,
      "loss": 1.9664,
      "step": 11260
    },
    {
      "epoch": 51.93764434180139,
      "grad_norm": 0.5378718972206116,
      "learning_rate": 0.00042487069438202783,
      "loss": 1.9703,
      "step": 11270
    },
    {
      "epoch": 51.9838337182448,
      "grad_norm": 0.5399458408355713,
      "learning_rate": 0.00042473940788408663,
      "loss": 1.9723,
      "step": 11280
    },
    {
      "epoch": 52.0,
      "eval_loss": 0.9805696606636047,
      "eval_runtime": 6.8745,
      "eval_samples_per_second": 4055.397,
      "eval_steps_per_second": 15.856,
      "step": 11284
    },
    {
      "epoch": 52.02771362586605,
      "grad_norm": 0.5393605828285217,
      "learning_rate": 0.0004246080270989531,
      "loss": 1.8665,
      "step": 11290
    },
    {
      "epoch": 52.07390300230947,
      "grad_norm": 0.6124531030654907,
      "learning_rate": 0.00042447655209751903,
      "loss": 1.961,
      "step": 11300
    },
    {
      "epoch": 52.12009237875289,
      "grad_norm": 0.5082789659500122,
      "learning_rate": 0.0004243449829507263,
      "loss": 1.9644,
      "step": 11310
    },
    {
      "epoch": 52.1662817551963,
      "grad_norm": 0.6860030889511108,
      "learning_rate": 0.00042421331972956823,
      "loss": 1.9706,
      "step": 11320
    },
    {
      "epoch": 52.212471131639724,
      "grad_norm": 0.7332034111022949,
      "learning_rate": 0.0004240815625050886,
      "loss": 1.9651,
      "step": 11330
    },
    {
      "epoch": 52.25866050808314,
      "grad_norm": 0.634512186050415,
      "learning_rate": 0.0004239497113483819,
      "loss": 1.9665,
      "step": 11340
    },
    {
      "epoch": 52.30484988452656,
      "grad_norm": 0.5258007645606995,
      "learning_rate": 0.00042381776633059344,
      "loss": 1.9717,
      "step": 11350
    },
    {
      "epoch": 52.351039260969976,
      "grad_norm": 0.4908645451068878,
      "learning_rate": 0.000423685727522919,
      "loss": 1.9691,
      "step": 11360
    },
    {
      "epoch": 52.39722863741339,
      "grad_norm": 0.4452800750732422,
      "learning_rate": 0.00042355359499660506,
      "loss": 1.9599,
      "step": 11370
    },
    {
      "epoch": 52.443418013856814,
      "grad_norm": 0.5221856832504272,
      "learning_rate": 0.0004234213688229488,
      "loss": 1.9713,
      "step": 11380
    },
    {
      "epoch": 52.48960739030023,
      "grad_norm": 0.6603944897651672,
      "learning_rate": 0.0004232890490732977,
      "loss": 1.9659,
      "step": 11390
    },
    {
      "epoch": 52.53579676674365,
      "grad_norm": 0.6276583671569824,
      "learning_rate": 0.0004231566358190498,
      "loss": 1.9738,
      "step": 11400
    },
    {
      "epoch": 52.581986143187066,
      "grad_norm": 0.45071473717689514,
      "learning_rate": 0.0004230241291316537,
      "loss": 1.9687,
      "step": 11410
    },
    {
      "epoch": 52.62817551963049,
      "grad_norm": 0.436957985162735,
      "learning_rate": 0.00042289152908260835,
      "loss": 1.9708,
      "step": 11420
    },
    {
      "epoch": 52.674364896073904,
      "grad_norm": 0.42536845803260803,
      "learning_rate": 0.0004227588357434631,
      "loss": 1.9645,
      "step": 11430
    },
    {
      "epoch": 52.72055427251732,
      "grad_norm": 0.42330920696258545,
      "learning_rate": 0.0004226260491858176,
      "loss": 1.9711,
      "step": 11440
    },
    {
      "epoch": 52.76674364896074,
      "grad_norm": 0.35498499870300293,
      "learning_rate": 0.0004224931694813217,
      "loss": 1.969,
      "step": 11450
    },
    {
      "epoch": 52.812933025404156,
      "grad_norm": 0.4603319764137268,
      "learning_rate": 0.0004223601967016757,
      "loss": 1.9633,
      "step": 11460
    },
    {
      "epoch": 52.85912240184758,
      "grad_norm": 0.6669814586639404,
      "learning_rate": 0.0004222271309186301,
      "loss": 1.9557,
      "step": 11470
    },
    {
      "epoch": 52.905311778290994,
      "grad_norm": 0.37621748447418213,
      "learning_rate": 0.0004220939722039855,
      "loss": 1.9659,
      "step": 11480
    },
    {
      "epoch": 52.95150115473441,
      "grad_norm": 0.4854764938354492,
      "learning_rate": 0.00042196072062959254,
      "loss": 1.9689,
      "step": 11490
    },
    {
      "epoch": 52.99769053117783,
      "grad_norm": 0.5003900527954102,
      "learning_rate": 0.00042182737626735223,
      "loss": 1.9767,
      "step": 11500
    },
    {
      "epoch": 53.0,
      "eval_loss": 0.9804715514183044,
      "eval_runtime": 6.8565,
      "eval_samples_per_second": 4066.067,
      "eval_steps_per_second": 15.897,
      "step": 11501
    },
    {
      "epoch": 53.04157043879908,
      "grad_norm": 0.44242337346076965,
      "learning_rate": 0.0004216939391892156,
      "loss": 1.8609,
      "step": 11510
    },
    {
      "epoch": 53.08775981524249,
      "grad_norm": 0.5140106678009033,
      "learning_rate": 0.00042156040946718344,
      "loss": 1.9661,
      "step": 11520
    },
    {
      "epoch": 53.133949191685915,
      "grad_norm": 0.43284478783607483,
      "learning_rate": 0.00042142678717330676,
      "loss": 1.9634,
      "step": 11530
    },
    {
      "epoch": 53.18013856812933,
      "grad_norm": 0.38428014516830444,
      "learning_rate": 0.0004212930723796865,
      "loss": 1.9709,
      "step": 11540
    },
    {
      "epoch": 53.226327944572745,
      "grad_norm": 0.4300054609775543,
      "learning_rate": 0.00042115926515847346,
      "loss": 1.9561,
      "step": 11550
    },
    {
      "epoch": 53.27251732101617,
      "grad_norm": 0.4404536187648773,
      "learning_rate": 0.00042102536558186844,
      "loss": 1.956,
      "step": 11560
    },
    {
      "epoch": 53.31870669745958,
      "grad_norm": 0.8402985334396362,
      "learning_rate": 0.00042089137372212183,
      "loss": 1.97,
      "step": 11570
    },
    {
      "epoch": 53.364896073903004,
      "grad_norm": 0.5363810658454895,
      "learning_rate": 0.00042075728965153405,
      "loss": 1.9715,
      "step": 11580
    },
    {
      "epoch": 53.41108545034642,
      "grad_norm": 0.5712534189224243,
      "learning_rate": 0.0004206231134424551,
      "loss": 1.9697,
      "step": 11590
    },
    {
      "epoch": 53.45727482678984,
      "grad_norm": 0.3858034014701843,
      "learning_rate": 0.0004204888451672849,
      "loss": 1.9635,
      "step": 11600
    },
    {
      "epoch": 53.50346420323326,
      "grad_norm": 0.41457653045654297,
      "learning_rate": 0.00042035448489847284,
      "loss": 1.9615,
      "step": 11610
    },
    {
      "epoch": 53.54965357967667,
      "grad_norm": 0.5877965688705444,
      "learning_rate": 0.0004202200327085179,
      "loss": 1.9782,
      "step": 11620
    },
    {
      "epoch": 53.595842956120094,
      "grad_norm": 0.4274967610836029,
      "learning_rate": 0.00042008548866996913,
      "loss": 1.9738,
      "step": 11630
    },
    {
      "epoch": 53.64203233256351,
      "grad_norm": 0.44704514741897583,
      "learning_rate": 0.00041995085285542456,
      "loss": 1.9739,
      "step": 11640
    },
    {
      "epoch": 53.68822170900693,
      "grad_norm": 0.4214044213294983,
      "learning_rate": 0.0004198161253375321,
      "loss": 1.9705,
      "step": 11650
    },
    {
      "epoch": 53.73441108545035,
      "grad_norm": 0.41384071111679077,
      "learning_rate": 0.0004196813061889889,
      "loss": 1.9618,
      "step": 11660
    },
    {
      "epoch": 53.78060046189376,
      "grad_norm": 0.44026803970336914,
      "learning_rate": 0.0004195463954825418,
      "loss": 1.9619,
      "step": 11670
    },
    {
      "epoch": 53.826789838337184,
      "grad_norm": 0.44245925545692444,
      "learning_rate": 0.00041941139329098687,
      "loss": 1.9614,
      "step": 11680
    },
    {
      "epoch": 53.8729792147806,
      "grad_norm": 0.41153720021247864,
      "learning_rate": 0.0004192762996871696,
      "loss": 1.9663,
      "step": 11690
    },
    {
      "epoch": 53.91916859122402,
      "grad_norm": 0.4159133732318878,
      "learning_rate": 0.00041914111474398487,
      "loss": 1.9743,
      "step": 11700
    },
    {
      "epoch": 53.96535796766744,
      "grad_norm": 0.5302590131759644,
      "learning_rate": 0.0004190058385343766,
      "loss": 1.9632,
      "step": 11710
    },
    {
      "epoch": 54.0,
      "eval_loss": 0.9794260263442993,
      "eval_runtime": 6.8658,
      "eval_samples_per_second": 4060.533,
      "eval_steps_per_second": 15.876,
      "step": 11718
    },
    {
      "epoch": 54.00923787528868,
      "grad_norm": 0.37322917580604553,
      "learning_rate": 0.0004188704711313384,
      "loss": 1.8717,
      "step": 11720
    },
    {
      "epoch": 54.0554272517321,
      "grad_norm": 0.6085384488105774,
      "learning_rate": 0.0004187350126079126,
      "loss": 1.9654,
      "step": 11730
    },
    {
      "epoch": 54.10161662817552,
      "grad_norm": 0.5114153027534485,
      "learning_rate": 0.00041859946303719097,
      "loss": 1.9651,
      "step": 11740
    },
    {
      "epoch": 54.147806004618936,
      "grad_norm": 0.37812989950180054,
      "learning_rate": 0.00041846382249231443,
      "loss": 1.972,
      "step": 11750
    },
    {
      "epoch": 54.19399538106236,
      "grad_norm": 0.619857907295227,
      "learning_rate": 0.00041832809104647286,
      "loss": 1.9611,
      "step": 11760
    },
    {
      "epoch": 54.24018475750577,
      "grad_norm": 0.48309817910194397,
      "learning_rate": 0.00041819226877290526,
      "loss": 1.9652,
      "step": 11770
    },
    {
      "epoch": 54.286374133949195,
      "grad_norm": 0.7439797520637512,
      "learning_rate": 0.0004180563557448997,
      "loss": 1.9602,
      "step": 11780
    },
    {
      "epoch": 54.33256351039261,
      "grad_norm": 0.46725404262542725,
      "learning_rate": 0.000417920352035793,
      "loss": 1.9661,
      "step": 11790
    },
    {
      "epoch": 54.378752886836025,
      "grad_norm": 0.5458308458328247,
      "learning_rate": 0.0004177842577189711,
      "loss": 1.9571,
      "step": 11800
    },
    {
      "epoch": 54.42494226327945,
      "grad_norm": 0.41636914014816284,
      "learning_rate": 0.00041764807286786887,
      "loss": 1.9688,
      "step": 11810
    },
    {
      "epoch": 54.47113163972286,
      "grad_norm": 0.49876680970191956,
      "learning_rate": 0.00041751179755596986,
      "loss": 1.9661,
      "step": 11820
    },
    {
      "epoch": 54.517321016166285,
      "grad_norm": 0.4089095890522003,
      "learning_rate": 0.00041737543185680655,
      "loss": 1.9553,
      "step": 11830
    },
    {
      "epoch": 54.5635103926097,
      "grad_norm": 0.580475926399231,
      "learning_rate": 0.00041723897584396017,
      "loss": 1.9702,
      "step": 11840
    },
    {
      "epoch": 54.609699769053115,
      "grad_norm": 0.4288688004016876,
      "learning_rate": 0.0004171024295910606,
      "loss": 1.9559,
      "step": 11850
    },
    {
      "epoch": 54.65588914549654,
      "grad_norm": 0.45145362615585327,
      "learning_rate": 0.00041696579317178665,
      "loss": 1.9599,
      "step": 11860
    },
    {
      "epoch": 54.70207852193995,
      "grad_norm": 0.45259496569633484,
      "learning_rate": 0.0004168290666598654,
      "loss": 1.9702,
      "step": 11870
    },
    {
      "epoch": 54.748267898383375,
      "grad_norm": 0.47649455070495605,
      "learning_rate": 0.0004166922501290729,
      "loss": 1.969,
      "step": 11880
    },
    {
      "epoch": 54.79445727482679,
      "grad_norm": 0.42254355549812317,
      "learning_rate": 0.0004165553436532337,
      "loss": 1.972,
      "step": 11890
    },
    {
      "epoch": 54.840646651270205,
      "grad_norm": 0.44640985131263733,
      "learning_rate": 0.0004164183473062206,
      "loss": 1.9708,
      "step": 11900
    },
    {
      "epoch": 54.88683602771363,
      "grad_norm": 0.4563494920730591,
      "learning_rate": 0.0004162812611619553,
      "loss": 1.9701,
      "step": 11910
    },
    {
      "epoch": 54.93302540415704,
      "grad_norm": 0.4780217409133911,
      "learning_rate": 0.0004161440852944076,
      "loss": 1.9678,
      "step": 11920
    },
    {
      "epoch": 54.979214780600465,
      "grad_norm": 0.3569749891757965,
      "learning_rate": 0.0004160068197775961,
      "loss": 1.9659,
      "step": 11930
    },
    {
      "epoch": 55.0,
      "eval_loss": 0.978909432888031,
      "eval_runtime": 6.8517,
      "eval_samples_per_second": 4068.926,
      "eval_steps_per_second": 15.908,
      "step": 11935
    },
    {
      "epoch": 55.02309468822171,
      "grad_norm": 0.4392777681350708,
      "learning_rate": 0.00041586946468558734,
      "loss": 1.8638,
      "step": 11940
    },
    {
      "epoch": 55.069284064665126,
      "grad_norm": 0.47820499539375305,
      "learning_rate": 0.00041573202009249655,
      "loss": 1.961,
      "step": 11950
    },
    {
      "epoch": 55.11547344110855,
      "grad_norm": 0.4428774118423462,
      "learning_rate": 0.000415594486072487,
      "loss": 1.9618,
      "step": 11960
    },
    {
      "epoch": 55.161662817551964,
      "grad_norm": 0.43343669176101685,
      "learning_rate": 0.0004154568626997703,
      "loss": 1.9667,
      "step": 11970
    },
    {
      "epoch": 55.20785219399538,
      "grad_norm": 0.4178869426250458,
      "learning_rate": 0.0004153191500486065,
      "loss": 1.9717,
      "step": 11980
    },
    {
      "epoch": 55.2540415704388,
      "grad_norm": 0.3742590546607971,
      "learning_rate": 0.00041518134819330344,
      "loss": 1.9577,
      "step": 11990
    },
    {
      "epoch": 55.300230946882216,
      "grad_norm": 0.3796558678150177,
      "learning_rate": 0.0004150434572082173,
      "loss": 1.9677,
      "step": 12000
    },
    {
      "epoch": 55.34642032332564,
      "grad_norm": 0.3555927276611328,
      "learning_rate": 0.0004149054771677523,
      "loss": 1.9619,
      "step": 12010
    },
    {
      "epoch": 55.392609699769054,
      "grad_norm": 0.4172746241092682,
      "learning_rate": 0.0004147674081463608,
      "loss": 1.9686,
      "step": 12020
    },
    {
      "epoch": 55.43879907621247,
      "grad_norm": 0.40400397777557373,
      "learning_rate": 0.00041462925021854317,
      "loss": 1.9658,
      "step": 12030
    },
    {
      "epoch": 55.48498845265589,
      "grad_norm": 0.41798365116119385,
      "learning_rate": 0.0004144910034588475,
      "loss": 1.9634,
      "step": 12040
    },
    {
      "epoch": 55.531177829099306,
      "grad_norm": 0.34554433822631836,
      "learning_rate": 0.00041435266794187016,
      "loss": 1.9578,
      "step": 12050
    },
    {
      "epoch": 55.57736720554273,
      "grad_norm": 0.8225587010383606,
      "learning_rate": 0.0004142142437422552,
      "loss": 1.9611,
      "step": 12060
    },
    {
      "epoch": 55.62355658198614,
      "grad_norm": 0.4338567852973938,
      "learning_rate": 0.00041407573093469463,
      "loss": 1.9658,
      "step": 12070
    },
    {
      "epoch": 55.66974595842956,
      "grad_norm": 0.7193775177001953,
      "learning_rate": 0.0004139371295939282,
      "loss": 1.9646,
      "step": 12080
    },
    {
      "epoch": 55.71593533487298,
      "grad_norm": 0.34978365898132324,
      "learning_rate": 0.0004137984397947434,
      "loss": 1.9732,
      "step": 12090
    },
    {
      "epoch": 55.762124711316396,
      "grad_norm": 0.40811875462532043,
      "learning_rate": 0.00041365966161197563,
      "loss": 1.9628,
      "step": 12100
    },
    {
      "epoch": 55.80831408775982,
      "grad_norm": 0.5616245269775391,
      "learning_rate": 0.00041352079512050775,
      "loss": 1.9583,
      "step": 12110
    },
    {
      "epoch": 55.85450346420323,
      "grad_norm": 0.37278133630752563,
      "learning_rate": 0.00041338184039527046,
      "loss": 1.9665,
      "step": 12120
    },
    {
      "epoch": 55.90069284064665,
      "grad_norm": 0.33678966760635376,
      "learning_rate": 0.0004132427975112418,
      "loss": 1.9763,
      "step": 12130
    },
    {
      "epoch": 55.94688221709007,
      "grad_norm": 0.40644124150276184,
      "learning_rate": 0.0004131036665434478,
      "loss": 1.9679,
      "step": 12140
    },
    {
      "epoch": 55.993071593533486,
      "grad_norm": 0.543424129486084,
      "learning_rate": 0.0004129644475669616,
      "loss": 1.9653,
      "step": 12150
    },
    {
      "epoch": 56.0,
      "eval_loss": 0.9795436263084412,
      "eval_runtime": 6.8902,
      "eval_samples_per_second": 4046.168,
      "eval_steps_per_second": 15.82,
      "step": 12152
    },
    {
      "epoch": 56.03695150115473,
      "grad_norm": 0.9326112866401672,
      "learning_rate": 0.0004128251406569042,
      "loss": 1.8488,
      "step": 12160
    },
    {
      "epoch": 56.083140877598154,
      "grad_norm": 0.4831653833389282,
      "learning_rate": 0.00041268574588844377,
      "loss": 1.9525,
      "step": 12170
    },
    {
      "epoch": 56.12933025404157,
      "grad_norm": 0.4567725658416748,
      "learning_rate": 0.0004125462633367959,
      "loss": 1.9647,
      "step": 12180
    },
    {
      "epoch": 56.17551963048499,
      "grad_norm": 0.3978007733821869,
      "learning_rate": 0.0004124066930772237,
      "loss": 1.9512,
      "step": 12190
    },
    {
      "epoch": 56.22170900692841,
      "grad_norm": 0.525203287601471,
      "learning_rate": 0.0004122670351850375,
      "loss": 1.9634,
      "step": 12200
    },
    {
      "epoch": 56.26789838337182,
      "grad_norm": 0.3711370527744293,
      "learning_rate": 0.000412127289735595,
      "loss": 1.968,
      "step": 12210
    },
    {
      "epoch": 56.314087759815244,
      "grad_norm": 0.4588695764541626,
      "learning_rate": 0.00041198745680430103,
      "loss": 1.9575,
      "step": 12220
    },
    {
      "epoch": 56.36027713625866,
      "grad_norm": 0.4119386672973633,
      "learning_rate": 0.00041184753646660775,
      "loss": 1.9605,
      "step": 12230
    },
    {
      "epoch": 56.40646651270208,
      "grad_norm": 0.4236164391040802,
      "learning_rate": 0.00041170752879801436,
      "loss": 1.9711,
      "step": 12240
    },
    {
      "epoch": 56.4526558891455,
      "grad_norm": 0.546588659286499,
      "learning_rate": 0.0004115674338740673,
      "loss": 1.9726,
      "step": 12250
    },
    {
      "epoch": 56.49884526558891,
      "grad_norm": 0.46561387181282043,
      "learning_rate": 0.00041142725177036,
      "loss": 1.9614,
      "step": 12260
    },
    {
      "epoch": 56.545034642032334,
      "grad_norm": 0.39456671476364136,
      "learning_rate": 0.00041128698256253293,
      "loss": 1.9659,
      "step": 12270
    },
    {
      "epoch": 56.59122401847575,
      "grad_norm": 0.6173260807991028,
      "learning_rate": 0.00041114662632627365,
      "loss": 1.9654,
      "step": 12280
    },
    {
      "epoch": 56.63741339491917,
      "grad_norm": 0.43453657627105713,
      "learning_rate": 0.00041100618313731657,
      "loss": 1.9599,
      "step": 12290
    },
    {
      "epoch": 56.68360277136259,
      "grad_norm": 0.39105141162872314,
      "learning_rate": 0.0004108656530714431,
      "loss": 1.9675,
      "step": 12300
    },
    {
      "epoch": 56.729792147806,
      "grad_norm": 0.39305174350738525,
      "learning_rate": 0.00041072503620448155,
      "loss": 1.9597,
      "step": 12310
    },
    {
      "epoch": 56.775981524249424,
      "grad_norm": 0.354572057723999,
      "learning_rate": 0.00041058433261230697,
      "loss": 1.9671,
      "step": 12320
    },
    {
      "epoch": 56.82217090069284,
      "grad_norm": 0.3579232394695282,
      "learning_rate": 0.0004104435423708412,
      "loss": 1.9627,
      "step": 12330
    },
    {
      "epoch": 56.86836027713626,
      "grad_norm": 0.34153324365615845,
      "learning_rate": 0.000410302665556053,
      "loss": 1.9668,
      "step": 12340
    },
    {
      "epoch": 56.91454965357968,
      "grad_norm": 0.3775520324707031,
      "learning_rate": 0.0004101617022439577,
      "loss": 1.9585,
      "step": 12350
    },
    {
      "epoch": 56.96073903002309,
      "grad_norm": 0.350317120552063,
      "learning_rate": 0.0004100206525106172,
      "loss": 1.9762,
      "step": 12360
    },
    {
      "epoch": 57.0,
      "eval_loss": 0.9792489409446716,
      "eval_runtime": 6.8656,
      "eval_samples_per_second": 4060.687,
      "eval_steps_per_second": 15.876,
      "step": 12369
    },
    {
      "epoch": 57.004618937644345,
      "grad_norm": 0.41989463567733765,
      "learning_rate": 0.0004098795164321403,
      "loss": 1.8652,
      "step": 12370
    },
    {
      "epoch": 57.05080831408776,
      "grad_norm": 0.44264522194862366,
      "learning_rate": 0.0004097382940846823,
      "loss": 1.9607,
      "step": 12380
    },
    {
      "epoch": 57.096997690531175,
      "grad_norm": 0.6194407939910889,
      "learning_rate": 0.00040959698554444496,
      "loss": 1.9599,
      "step": 12390
    },
    {
      "epoch": 57.1431870669746,
      "grad_norm": 0.36503276228904724,
      "learning_rate": 0.0004094555908876765,
      "loss": 1.9584,
      "step": 12400
    },
    {
      "epoch": 57.18937644341801,
      "grad_norm": 0.37632614374160767,
      "learning_rate": 0.0004093141101906718,
      "loss": 1.962,
      "step": 12410
    },
    {
      "epoch": 57.235565819861435,
      "grad_norm": 0.5127372741699219,
      "learning_rate": 0.00040917254352977204,
      "loss": 1.9578,
      "step": 12420
    },
    {
      "epoch": 57.28175519630485,
      "grad_norm": 0.45566558837890625,
      "learning_rate": 0.00040903089098136486,
      "loss": 1.9683,
      "step": 12430
    },
    {
      "epoch": 57.327944572748265,
      "grad_norm": 0.4454282522201538,
      "learning_rate": 0.00040888915262188416,
      "loss": 1.9593,
      "step": 12440
    },
    {
      "epoch": 57.37413394919169,
      "grad_norm": 0.43482455611228943,
      "learning_rate": 0.00040874732852781015,
      "loss": 1.9653,
      "step": 12450
    },
    {
      "epoch": 57.4203233256351,
      "grad_norm": 0.3936741054058075,
      "learning_rate": 0.00040860541877566934,
      "loss": 1.967,
      "step": 12460
    },
    {
      "epoch": 57.466512702078525,
      "grad_norm": 0.41432446241378784,
      "learning_rate": 0.0004084634234420345,
      "loss": 1.9702,
      "step": 12470
    },
    {
      "epoch": 57.51270207852194,
      "grad_norm": 0.4232999384403229,
      "learning_rate": 0.0004083213426035245,
      "loss": 1.9697,
      "step": 12480
    },
    {
      "epoch": 57.558891454965355,
      "grad_norm": 0.381811261177063,
      "learning_rate": 0.0004081791763368044,
      "loss": 1.9586,
      "step": 12490
    },
    {
      "epoch": 57.60508083140878,
      "grad_norm": 0.4965498447418213,
      "learning_rate": 0.0004080369247185853,
      "loss": 1.9659,
      "step": 12500
    },
    {
      "epoch": 57.65127020785219,
      "grad_norm": 0.44208621978759766,
      "learning_rate": 0.0004078945878256244,
      "loss": 1.9468,
      "step": 12510
    },
    {
      "epoch": 57.697459584295615,
      "grad_norm": 0.44031786918640137,
      "learning_rate": 0.00040775216573472493,
      "loss": 1.9629,
      "step": 12520
    },
    {
      "epoch": 57.74364896073903,
      "grad_norm": 0.3777337074279785,
      "learning_rate": 0.00040760965852273604,
      "loss": 1.95,
      "step": 12530
    },
    {
      "epoch": 57.789838337182445,
      "grad_norm": 0.3711964786052704,
      "learning_rate": 0.0004074670662665528,
      "loss": 1.946,
      "step": 12540
    },
    {
      "epoch": 57.83602771362587,
      "grad_norm": 0.47269296646118164,
      "learning_rate": 0.0004073243890431163,
      "loss": 1.974,
      "step": 12550
    },
    {
      "epoch": 57.88221709006928,
      "grad_norm": 0.3700965642929077,
      "learning_rate": 0.00040718162692941317,
      "loss": 1.9551,
      "step": 12560
    },
    {
      "epoch": 57.928406466512705,
      "grad_norm": 0.42881491780281067,
      "learning_rate": 0.0004070387800024763,
      "loss": 1.9609,
      "step": 12570
    },
    {
      "epoch": 57.97459584295612,
      "grad_norm": 0.37948310375213623,
      "learning_rate": 0.000406895848339384,
      "loss": 1.9567,
      "step": 12580
    },
    {
      "epoch": 58.0,
      "eval_loss": 0.9798628687858582,
      "eval_runtime": 6.8582,
      "eval_samples_per_second": 4065.082,
      "eval_steps_per_second": 15.893,
      "step": 12586
    },
    {
      "epoch": 58.018475750577366,
      "grad_norm": 0.36608797311782837,
      "learning_rate": 0.0004067528320172604,
      "loss": 1.8791,
      "step": 12590
    },
    {
      "epoch": 58.06466512702079,
      "grad_norm": 0.5278488993644714,
      "learning_rate": 0.00040660973111327533,
      "loss": 1.9592,
      "step": 12600
    },
    {
      "epoch": 58.1108545034642,
      "grad_norm": 0.38646599650382996,
      "learning_rate": 0.0004064665457046442,
      "loss": 1.96,
      "step": 12610
    },
    {
      "epoch": 58.15704387990762,
      "grad_norm": 1.0408639907836914,
      "learning_rate": 0.00040632327586862806,
      "loss": 1.9541,
      "step": 12620
    },
    {
      "epoch": 58.20323325635104,
      "grad_norm": 0.3719557523727417,
      "learning_rate": 0.0004061799216825336,
      "loss": 1.9548,
      "step": 12630
    },
    {
      "epoch": 58.249422632794456,
      "grad_norm": 0.3273271322250366,
      "learning_rate": 0.0004060364832237129,
      "loss": 1.9544,
      "step": 12640
    },
    {
      "epoch": 58.29561200923788,
      "grad_norm": 0.6154713034629822,
      "learning_rate": 0.0004058929605695635,
      "loss": 1.9532,
      "step": 12650
    },
    {
      "epoch": 58.34180138568129,
      "grad_norm": 0.42903217673301697,
      "learning_rate": 0.00040574935379752845,
      "loss": 1.9648,
      "step": 12660
    },
    {
      "epoch": 58.38799076212471,
      "grad_norm": 0.5376131534576416,
      "learning_rate": 0.00040560566298509615,
      "loss": 1.9606,
      "step": 12670
    },
    {
      "epoch": 58.43418013856813,
      "grad_norm": 0.31886622309684753,
      "learning_rate": 0.00040546188820980044,
      "loss": 1.9585,
      "step": 12680
    },
    {
      "epoch": 58.480369515011546,
      "grad_norm": 0.452390193939209,
      "learning_rate": 0.0004053180295492203,
      "loss": 1.9593,
      "step": 12690
    },
    {
      "epoch": 58.52655889145497,
      "grad_norm": 0.4896557629108429,
      "learning_rate": 0.00040517408708098,
      "loss": 1.9567,
      "step": 12700
    },
    {
      "epoch": 58.57274826789838,
      "grad_norm": 0.6466456055641174,
      "learning_rate": 0.00040503006088274927,
      "loss": 1.9548,
      "step": 12710
    },
    {
      "epoch": 58.6189376443418,
      "grad_norm": 0.45563170313835144,
      "learning_rate": 0.0004048859510322427,
      "loss": 1.9635,
      "step": 12720
    },
    {
      "epoch": 58.66512702078522,
      "grad_norm": 0.3473133146762848,
      "learning_rate": 0.0004047417576072203,
      "loss": 1.9586,
      "step": 12730
    },
    {
      "epoch": 58.711316397228636,
      "grad_norm": 0.3789709806442261,
      "learning_rate": 0.00040459748068548683,
      "loss": 1.9569,
      "step": 12740
    },
    {
      "epoch": 58.75750577367206,
      "grad_norm": 0.36074596643447876,
      "learning_rate": 0.00040445312034489246,
      "loss": 1.9657,
      "step": 12750
    },
    {
      "epoch": 58.80369515011547,
      "grad_norm": 0.4935973286628723,
      "learning_rate": 0.00040430867666333217,
      "loss": 1.9562,
      "step": 12760
    },
    {
      "epoch": 58.84988452655889,
      "grad_norm": 0.42091184854507446,
      "learning_rate": 0.00040416414971874596,
      "loss": 1.9721,
      "step": 12770
    },
    {
      "epoch": 58.89607390300231,
      "grad_norm": 0.39414238929748535,
      "learning_rate": 0.00040401953958911876,
      "loss": 1.9701,
      "step": 12780
    },
    {
      "epoch": 58.942263279445726,
      "grad_norm": 0.3246038854122162,
      "learning_rate": 0.00040387484635248037,
      "loss": 1.9752,
      "step": 12790
    },
    {
      "epoch": 58.98845265588915,
      "grad_norm": 0.34885701537132263,
      "learning_rate": 0.00040373007008690545,
      "loss": 1.9585,
      "step": 12800
    },
    {
      "epoch": 59.0,
      "eval_loss": 0.9814086556434631,
      "eval_runtime": 6.8675,
      "eval_samples_per_second": 4059.534,
      "eval_steps_per_second": 15.872,
      "step": 12803
    },
    {
      "epoch": 59.032332563510394,
      "grad_norm": 0.4273402988910675,
      "learning_rate": 0.00040358521087051347,
      "loss": 1.8553,
      "step": 12810
    },
    {
      "epoch": 59.07852193995381,
      "grad_norm": 0.3920277953147888,
      "learning_rate": 0.0004034402687814686,
      "loss": 1.9602,
      "step": 12820
    },
    {
      "epoch": 59.12471131639723,
      "grad_norm": 0.42538732290267944,
      "learning_rate": 0.0004032952438979798,
      "loss": 1.9574,
      "step": 12830
    },
    {
      "epoch": 59.17090069284065,
      "grad_norm": 0.3448431193828583,
      "learning_rate": 0.00040315013629830073,
      "loss": 1.9522,
      "step": 12840
    },
    {
      "epoch": 59.21709006928406,
      "grad_norm": 0.34066709876060486,
      "learning_rate": 0.0004030049460607296,
      "loss": 1.9676,
      "step": 12850
    },
    {
      "epoch": 59.263279445727484,
      "grad_norm": 0.408639520406723,
      "learning_rate": 0.0004028596732636092,
      "loss": 1.9582,
      "step": 12860
    },
    {
      "epoch": 59.3094688221709,
      "grad_norm": 0.4728173017501831,
      "learning_rate": 0.00040271431798532685,
      "loss": 1.9625,
      "step": 12870
    },
    {
      "epoch": 59.35565819861432,
      "grad_norm": 0.6933015584945679,
      "learning_rate": 0.0004025688803043146,
      "loss": 1.9631,
      "step": 12880
    },
    {
      "epoch": 59.40184757505774,
      "grad_norm": 0.3207430839538574,
      "learning_rate": 0.0004024233602990487,
      "loss": 1.9497,
      "step": 12890
    },
    {
      "epoch": 59.44803695150115,
      "grad_norm": 0.692136824131012,
      "learning_rate": 0.00040227775804805,
      "loss": 1.9538,
      "step": 12900
    },
    {
      "epoch": 59.494226327944574,
      "grad_norm": 0.6687999963760376,
      "learning_rate": 0.00040213207362988347,
      "loss": 1.9587,
      "step": 12910
    },
    {
      "epoch": 59.54041570438799,
      "grad_norm": 0.7447516322135925,
      "learning_rate": 0.0004019863071231588,
      "loss": 1.9578,
      "step": 12920
    },
    {
      "epoch": 59.58660508083141,
      "grad_norm": 0.35254809260368347,
      "learning_rate": 0.0004018404586065296,
      "loss": 1.9706,
      "step": 12930
    },
    {
      "epoch": 59.63279445727483,
      "grad_norm": 0.4221850633621216,
      "learning_rate": 0.000401694528158694,
      "loss": 1.9617,
      "step": 12940
    },
    {
      "epoch": 59.67898383371824,
      "grad_norm": 0.42733222246170044,
      "learning_rate": 0.00040154851585839425,
      "loss": 1.959,
      "step": 12950
    },
    {
      "epoch": 59.725173210161664,
      "grad_norm": 0.35438063740730286,
      "learning_rate": 0.00040140242178441667,
      "loss": 1.9532,
      "step": 12960
    },
    {
      "epoch": 59.77136258660508,
      "grad_norm": 0.34798744320869446,
      "learning_rate": 0.00040125624601559186,
      "loss": 1.9619,
      "step": 12970
    },
    {
      "epoch": 59.8175519630485,
      "grad_norm": 0.3395448923110962,
      "learning_rate": 0.0004011099886307944,
      "loss": 1.9609,
      "step": 12980
    },
    {
      "epoch": 59.86374133949192,
      "grad_norm": 0.3467954695224762,
      "learning_rate": 0.000400963649708943,
      "loss": 1.9574,
      "step": 12990
    },
    {
      "epoch": 59.90993071593533,
      "grad_norm": 0.38864970207214355,
      "learning_rate": 0.0004008172293290002,
      "loss": 1.9586,
      "step": 13000
    },
    {
      "epoch": 59.956120092378754,
      "grad_norm": 0.3435667157173157,
      "learning_rate": 0.0004006707275699727,
      "loss": 1.9622,
      "step": 13010
    },
    {
      "epoch": 60.0,
      "grad_norm": 0.3072929084300995,
      "learning_rate": 0.0004005241445109109,
      "loss": 1.8581,
      "step": 13020
    },
    {
      "epoch": 60.0,
      "eval_loss": 0.9797827005386353,
      "eval_runtime": 7.0342,
      "eval_samples_per_second": 3963.328,
      "eval_steps_per_second": 15.496,
      "step": 13020
    },
    {
      "epoch": 60.046189376443415,
      "grad_norm": 0.45177632570266724,
      "learning_rate": 0.00040037748023090934,
      "loss": 1.9528,
      "step": 13030
    },
    {
      "epoch": 60.09237875288684,
      "grad_norm": 0.4431661367416382,
      "learning_rate": 0.00040023073480910604,
      "loss": 1.967,
      "step": 13040
    },
    {
      "epoch": 60.13856812933025,
      "grad_norm": 0.3801228106021881,
      "learning_rate": 0.0004000839083246831,
      "loss": 1.9617,
      "step": 13050
    },
    {
      "epoch": 60.184757505773675,
      "grad_norm": 0.3458348214626312,
      "learning_rate": 0.00039993700085686623,
      "loss": 1.9554,
      "step": 13060
    },
    {
      "epoch": 60.23094688221709,
      "grad_norm": 0.30939334630966187,
      "learning_rate": 0.0003997900124849249,
      "loss": 1.9597,
      "step": 13070
    },
    {
      "epoch": 60.277136258660505,
      "grad_norm": 0.44357800483703613,
      "learning_rate": 0.00039964294328817215,
      "loss": 1.9531,
      "step": 13080
    },
    {
      "epoch": 60.32332563510393,
      "grad_norm": 0.34490999579429626,
      "learning_rate": 0.00039949579334596464,
      "loss": 1.9413,
      "step": 13090
    },
    {
      "epoch": 60.36951501154734,
      "grad_norm": 0.3586011826992035,
      "learning_rate": 0.0003993485627377026,
      "loss": 1.9623,
      "step": 13100
    },
    {
      "epoch": 60.415704387990765,
      "grad_norm": 0.34258347749710083,
      "learning_rate": 0.00039920125154283,
      "loss": 1.96,
      "step": 13110
    },
    {
      "epoch": 60.46189376443418,
      "grad_norm": 0.36543557047843933,
      "learning_rate": 0.00039905385984083397,
      "loss": 1.9441,
      "step": 13120
    },
    {
      "epoch": 60.508083140877595,
      "grad_norm": 0.36075034737586975,
      "learning_rate": 0.0003989063877112452,
      "loss": 1.9546,
      "step": 13130
    },
    {
      "epoch": 60.55427251732102,
      "grad_norm": 0.3166077136993408,
      "learning_rate": 0.0003987588352336379,
      "loss": 1.9593,
      "step": 13140
    },
    {
      "epoch": 60.60046189376443,
      "grad_norm": 0.3721928596496582,
      "learning_rate": 0.00039861120248762936,
      "loss": 1.9602,
      "step": 13150
    },
    {
      "epoch": 60.646651270207855,
      "grad_norm": 0.44222915172576904,
      "learning_rate": 0.0003984634895528806,
      "loss": 1.9605,
      "step": 13160
    },
    {
      "epoch": 60.69284064665127,
      "grad_norm": 0.44066330790519714,
      "learning_rate": 0.00039831569650909557,
      "loss": 1.9695,
      "step": 13170
    },
    {
      "epoch": 60.739030023094685,
      "grad_norm": 0.3677791953086853,
      "learning_rate": 0.0003981678234360214,
      "loss": 1.9515,
      "step": 13180
    },
    {
      "epoch": 60.78521939953811,
      "grad_norm": 0.3080310523509979,
      "learning_rate": 0.0003980198704134488,
      "loss": 1.9641,
      "step": 13190
    },
    {
      "epoch": 60.83140877598152,
      "grad_norm": 0.35189706087112427,
      "learning_rate": 0.00039787183752121113,
      "loss": 1.9538,
      "step": 13200
    },
    {
      "epoch": 60.877598152424945,
      "grad_norm": 0.38450735807418823,
      "learning_rate": 0.00039772372483918526,
      "loss": 1.9556,
      "step": 13210
    },
    {
      "epoch": 60.92378752886836,
      "grad_norm": 0.4645795524120331,
      "learning_rate": 0.0003975755324472908,
      "loss": 1.9569,
      "step": 13220
    },
    {
      "epoch": 60.969976905311775,
      "grad_norm": 0.2901670038700104,
      "learning_rate": 0.00039742726042549053,
      "loss": 1.9636,
      "step": 13230
    },
    {
      "epoch": 61.0,
      "eval_loss": 0.9804787635803223,
      "eval_runtime": 6.8622,
      "eval_samples_per_second": 4062.68,
      "eval_steps_per_second": 15.884,
      "step": 13237
    },
    {
      "epoch": 61.01385681293303,
      "grad_norm": 0.4104427099227905,
      "learning_rate": 0.0003972789088537903,
      "loss": 1.8576,
      "step": 13240
    },
    {
      "epoch": 61.06004618937644,
      "grad_norm": 0.49848267436027527,
      "learning_rate": 0.0003971304778122386,
      "loss": 1.9536,
      "step": 13250
    },
    {
      "epoch": 61.10623556581986,
      "grad_norm": 0.37631726264953613,
      "learning_rate": 0.000396981967380927,
      "loss": 1.9505,
      "step": 13260
    },
    {
      "epoch": 61.15242494226328,
      "grad_norm": 0.4186035692691803,
      "learning_rate": 0.0003968333776399899,
      "loss": 1.9405,
      "step": 13270
    },
    {
      "epoch": 61.198614318706696,
      "grad_norm": 0.5334662795066833,
      "learning_rate": 0.0003966847086696045,
      "loss": 1.9601,
      "step": 13280
    },
    {
      "epoch": 61.24480369515012,
      "grad_norm": 0.5140074491500854,
      "learning_rate": 0.0003965359605499906,
      "loss": 1.9577,
      "step": 13290
    },
    {
      "epoch": 61.29099307159353,
      "grad_norm": 0.47740671038627625,
      "learning_rate": 0.00039638713336141083,
      "loss": 1.9525,
      "step": 13300
    },
    {
      "epoch": 61.33718244803695,
      "grad_norm": 0.46794307231903076,
      "learning_rate": 0.00039623822718417055,
      "loss": 1.9625,
      "step": 13310
    },
    {
      "epoch": 61.38337182448037,
      "grad_norm": 0.5247425436973572,
      "learning_rate": 0.00039608924209861776,
      "loss": 1.9578,
      "step": 13320
    },
    {
      "epoch": 61.429561200923786,
      "grad_norm": 0.37077686190605164,
      "learning_rate": 0.0003959401781851427,
      "loss": 1.9482,
      "step": 13330
    },
    {
      "epoch": 61.47575057736721,
      "grad_norm": 0.3636135458946228,
      "learning_rate": 0.0003957910355241785,
      "loss": 1.9565,
      "step": 13340
    },
    {
      "epoch": 61.52193995381062,
      "grad_norm": 0.4804963767528534,
      "learning_rate": 0.0003956418141962007,
      "loss": 1.9573,
      "step": 13350
    },
    {
      "epoch": 61.56812933025404,
      "grad_norm": 0.32427704334259033,
      "learning_rate": 0.0003954925142817272,
      "loss": 1.9575,
      "step": 13360
    },
    {
      "epoch": 61.61431870669746,
      "grad_norm": 0.32096007466316223,
      "learning_rate": 0.00039534313586131844,
      "loss": 1.9643,
      "step": 13370
    },
    {
      "epoch": 61.660508083140876,
      "grad_norm": 0.34823471307754517,
      "learning_rate": 0.000395193679015577,
      "loss": 1.9559,
      "step": 13380
    },
    {
      "epoch": 61.7066974595843,
      "grad_norm": 0.49793940782546997,
      "learning_rate": 0.0003950441438251481,
      "loss": 1.9553,
      "step": 13390
    },
    {
      "epoch": 61.75288683602771,
      "grad_norm": 0.35728323459625244,
      "learning_rate": 0.00039489453037071893,
      "loss": 1.9447,
      "step": 13400
    },
    {
      "epoch": 61.79907621247113,
      "grad_norm": 0.4392385482788086,
      "learning_rate": 0.00039474483873301906,
      "loss": 1.9508,
      "step": 13410
    },
    {
      "epoch": 61.84526558891455,
      "grad_norm": 0.5178948640823364,
      "learning_rate": 0.00039459506899282027,
      "loss": 1.9694,
      "step": 13420
    },
    {
      "epoch": 61.891454965357966,
      "grad_norm": 0.3126176595687866,
      "learning_rate": 0.00039444522123093634,
      "loss": 1.9543,
      "step": 13430
    },
    {
      "epoch": 61.93764434180139,
      "grad_norm": 0.5355256199836731,
      "learning_rate": 0.0003942952955282233,
      "loss": 1.9543,
      "step": 13440
    },
    {
      "epoch": 61.9838337182448,
      "grad_norm": 0.36667588353157043,
      "learning_rate": 0.00039414529196557914,
      "loss": 1.9489,
      "step": 13450
    },
    {
      "epoch": 62.0,
      "eval_loss": 0.9800688028335571,
      "eval_runtime": 6.88,
      "eval_samples_per_second": 4052.187,
      "eval_steps_per_second": 15.843,
      "step": 13454
    },
    {
      "epoch": 62.02771362586605,
      "grad_norm": 0.41565507650375366,
      "learning_rate": 0.000393995210623944,
      "loss": 1.8624,
      "step": 13460
    },
    {
      "epoch": 62.07390300230947,
      "grad_norm": 0.41904202103614807,
      "learning_rate": 0.0003938450515842998,
      "loss": 1.9444,
      "step": 13470
    },
    {
      "epoch": 62.12009237875289,
      "grad_norm": 0.3800727128982544,
      "learning_rate": 0.00039369481492767047,
      "loss": 1.9554,
      "step": 13480
    },
    {
      "epoch": 62.1662817551963,
      "grad_norm": 0.3885044455528259,
      "learning_rate": 0.00039354450073512184,
      "loss": 1.9474,
      "step": 13490
    },
    {
      "epoch": 62.212471131639724,
      "grad_norm": 0.3882398009300232,
      "learning_rate": 0.00039339410908776154,
      "loss": 1.9537,
      "step": 13500
    },
    {
      "epoch": 62.25866050808314,
      "grad_norm": 0.34410107135772705,
      "learning_rate": 0.0003932436400667391,
      "loss": 1.9466,
      "step": 13510
    },
    {
      "epoch": 62.30484988452656,
      "grad_norm": 0.499168336391449,
      "learning_rate": 0.00039309309375324563,
      "loss": 1.9499,
      "step": 13520
    },
    {
      "epoch": 62.351039260969976,
      "grad_norm": 0.35142531991004944,
      "learning_rate": 0.000392942470228514,
      "loss": 1.9554,
      "step": 13530
    },
    {
      "epoch": 62.39722863741339,
      "grad_norm": 0.48738399147987366,
      "learning_rate": 0.0003927917695738189,
      "loss": 1.95,
      "step": 13540
    },
    {
      "epoch": 62.443418013856814,
      "grad_norm": 0.3590390384197235,
      "learning_rate": 0.0003926409918704765,
      "loss": 1.9588,
      "step": 13550
    },
    {
      "epoch": 62.48960739030023,
      "grad_norm": 0.33434996008872986,
      "learning_rate": 0.0003924901371998445,
      "loss": 1.9536,
      "step": 13560
    },
    {
      "epoch": 62.53579676674365,
      "grad_norm": 0.351452112197876,
      "learning_rate": 0.00039233920564332215,
      "loss": 1.9464,
      "step": 13570
    },
    {
      "epoch": 62.581986143187066,
      "grad_norm": 0.4606298506259918,
      "learning_rate": 0.0003921881972823502,
      "loss": 1.9499,
      "step": 13580
    },
    {
      "epoch": 62.62817551963049,
      "grad_norm": 0.33644312620162964,
      "learning_rate": 0.00039203711219841107,
      "loss": 1.9594,
      "step": 13590
    },
    {
      "epoch": 62.674364896073904,
      "grad_norm": 0.4858242869377136,
      "learning_rate": 0.0003918859504730282,
      "loss": 1.9574,
      "step": 13600
    },
    {
      "epoch": 62.72055427251732,
      "grad_norm": 0.4104061722755432,
      "learning_rate": 0.0003917347121877666,
      "loss": 1.9495,
      "step": 13610
    },
    {
      "epoch": 62.76674364896074,
      "grad_norm": 0.35309112071990967,
      "learning_rate": 0.00039158339742423256,
      "loss": 1.9683,
      "step": 13620
    },
    {
      "epoch": 62.812933025404156,
      "grad_norm": 0.3558746874332428,
      "learning_rate": 0.00039143200626407356,
      "loss": 1.9648,
      "step": 13630
    },
    {
      "epoch": 62.85912240184758,
      "grad_norm": 0.40998411178588867,
      "learning_rate": 0.00039128053878897853,
      "loss": 1.9666,
      "step": 13640
    },
    {
      "epoch": 62.905311778290994,
      "grad_norm": 0.5326336622238159,
      "learning_rate": 0.0003911289950806772,
      "loss": 1.9476,
      "step": 13650
    },
    {
      "epoch": 62.95150115473441,
      "grad_norm": 0.41075000166893005,
      "learning_rate": 0.0003909773752209408,
      "loss": 1.9615,
      "step": 13660
    },
    {
      "epoch": 62.99769053117783,
      "grad_norm": 0.36382877826690674,
      "learning_rate": 0.0003908256792915815,
      "loss": 1.967,
      "step": 13670
    },
    {
      "epoch": 63.0,
      "eval_loss": 0.9798513650894165,
      "eval_runtime": 6.8537,
      "eval_samples_per_second": 4067.738,
      "eval_steps_per_second": 15.904,
      "step": 13671
    },
    {
      "epoch": 63.04157043879908,
      "grad_norm": 0.3748835623264313,
      "learning_rate": 0.00039067390737445256,
      "loss": 1.8461,
      "step": 13680
    },
    {
      "epoch": 63.08775981524249,
      "grad_norm": 0.3424738347530365,
      "learning_rate": 0.0003905220595514481,
      "loss": 1.9504,
      "step": 13690
    },
    {
      "epoch": 63.133949191685915,
      "grad_norm": 0.7199232578277588,
      "learning_rate": 0.0003903701359045033,
      "loss": 1.9553,
      "step": 13700
    },
    {
      "epoch": 63.18013856812933,
      "grad_norm": 0.4580686092376709,
      "learning_rate": 0.00039021813651559436,
      "loss": 1.9448,
      "step": 13710
    },
    {
      "epoch": 63.226327944572745,
      "grad_norm": 0.4059828221797943,
      "learning_rate": 0.00039006606146673817,
      "loss": 1.9633,
      "step": 13720
    },
    {
      "epoch": 63.27251732101617,
      "grad_norm": 0.46434783935546875,
      "learning_rate": 0.0003899139108399925,
      "loss": 1.9525,
      "step": 13730
    },
    {
      "epoch": 63.31870669745958,
      "grad_norm": 0.4755892753601074,
      "learning_rate": 0.00038976168471745594,
      "loss": 1.9509,
      "step": 13740
    },
    {
      "epoch": 63.364896073903004,
      "grad_norm": 0.46847963333129883,
      "learning_rate": 0.0003896093831812678,
      "loss": 1.9482,
      "step": 13750
    },
    {
      "epoch": 63.41108545034642,
      "grad_norm": 0.4759595990180969,
      "learning_rate": 0.00038945700631360806,
      "loss": 1.96,
      "step": 13760
    },
    {
      "epoch": 63.45727482678984,
      "grad_norm": 0.5262286067008972,
      "learning_rate": 0.00038930455419669747,
      "loss": 1.9537,
      "step": 13770
    },
    {
      "epoch": 63.50346420323326,
      "grad_norm": 0.3413017690181732,
      "learning_rate": 0.00038915202691279716,
      "loss": 1.9459,
      "step": 13780
    },
    {
      "epoch": 63.54965357967667,
      "grad_norm": 2.976001739501953,
      "learning_rate": 0.0003889994245442089,
      "loss": 1.9541,
      "step": 13790
    },
    {
      "epoch": 63.595842956120094,
      "grad_norm": 0.5469712615013123,
      "learning_rate": 0.00038884674717327517,
      "loss": 1.9606,
      "step": 13800
    },
    {
      "epoch": 63.64203233256351,
      "grad_norm": 0.46631988883018494,
      "learning_rate": 0.00038869399488237864,
      "loss": 1.9524,
      "step": 13810
    },
    {
      "epoch": 63.68822170900693,
      "grad_norm": 0.4286842942237854,
      "learning_rate": 0.0003885411677539426,
      "loss": 1.9522,
      "step": 13820
    },
    {
      "epoch": 63.73441108545035,
      "grad_norm": 0.41297322511672974,
      "learning_rate": 0.00038838826587043063,
      "loss": 1.9425,
      "step": 13830
    },
    {
      "epoch": 63.78060046189376,
      "grad_norm": 0.4114173352718353,
      "learning_rate": 0.0003882352893143466,
      "loss": 1.956,
      "step": 13840
    },
    {
      "epoch": 63.826789838337184,
      "grad_norm": 0.4057309925556183,
      "learning_rate": 0.00038808223816823485,
      "loss": 1.9546,
      "step": 13850
    },
    {
      "epoch": 63.8729792147806,
      "grad_norm": 0.4094274640083313,
      "learning_rate": 0.0003879291125146798,
      "loss": 1.9576,
      "step": 13860
    },
    {
      "epoch": 63.91916859122402,
      "grad_norm": 0.41555678844451904,
      "learning_rate": 0.0003877759124363062,
      "loss": 1.9542,
      "step": 13870
    },
    {
      "epoch": 63.96535796766744,
      "grad_norm": 0.3874729871749878,
      "learning_rate": 0.0003876226380157787,
      "loss": 1.9628,
      "step": 13880
    },
    {
      "epoch": 64.0,
      "eval_loss": 0.9791460633277893,
      "eval_runtime": 6.8514,
      "eval_samples_per_second": 4069.115,
      "eval_steps_per_second": 15.909,
      "step": 13888
    },
    {
      "epoch": 64.00923787528869,
      "grad_norm": 0.43025684356689453,
      "learning_rate": 0.0003874692893358024,
      "loss": 1.8609,
      "step": 13890
    },
    {
      "epoch": 64.0554272517321,
      "grad_norm": 0.4436792731285095,
      "learning_rate": 0.00038731586647912245,
      "loss": 1.9449,
      "step": 13900
    },
    {
      "epoch": 64.10161662817552,
      "grad_norm": 0.4541539251804352,
      "learning_rate": 0.0003871623695285236,
      "loss": 1.9559,
      "step": 13910
    },
    {
      "epoch": 64.14780600461894,
      "grad_norm": 0.46456852555274963,
      "learning_rate": 0.00038700879856683114,
      "loss": 1.943,
      "step": 13920
    },
    {
      "epoch": 64.19399538106235,
      "grad_norm": 0.46669310331344604,
      "learning_rate": 0.0003868551536769098,
      "loss": 1.9504,
      "step": 13930
    },
    {
      "epoch": 64.24018475750577,
      "grad_norm": 0.38904139399528503,
      "learning_rate": 0.00038670143494166475,
      "loss": 1.9484,
      "step": 13940
    },
    {
      "epoch": 64.2863741339492,
      "grad_norm": 0.3608803451061249,
      "learning_rate": 0.0003865476424440404,
      "loss": 1.9373,
      "step": 13950
    },
    {
      "epoch": 64.3325635103926,
      "grad_norm": 0.4739398956298828,
      "learning_rate": 0.0003863937762670213,
      "loss": 1.9441,
      "step": 13960
    },
    {
      "epoch": 64.37875288683603,
      "grad_norm": 0.5260648131370544,
      "learning_rate": 0.00038623983649363193,
      "loss": 1.954,
      "step": 13970
    },
    {
      "epoch": 64.42494226327945,
      "grad_norm": 0.40957707166671753,
      "learning_rate": 0.000386085823206936,
      "loss": 1.9517,
      "step": 13980
    },
    {
      "epoch": 64.47113163972287,
      "grad_norm": 0.3642750382423401,
      "learning_rate": 0.0003859317364900372,
      "loss": 1.955,
      "step": 13990
    },
    {
      "epoch": 64.51732101616628,
      "grad_norm": 0.38123446702957153,
      "learning_rate": 0.0003857775764260789,
      "loss": 1.9563,
      "step": 14000
    },
    {
      "epoch": 64.5635103926097,
      "grad_norm": 0.4752342700958252,
      "learning_rate": 0.00038562334309824386,
      "loss": 1.9589,
      "step": 14010
    },
    {
      "epoch": 64.60969976905312,
      "grad_norm": 0.40639469027519226,
      "learning_rate": 0.0003854690365897544,
      "loss": 1.9573,
      "step": 14020
    },
    {
      "epoch": 64.65588914549653,
      "grad_norm": 0.3342912197113037,
      "learning_rate": 0.00038531465698387257,
      "loss": 1.9604,
      "step": 14030
    },
    {
      "epoch": 64.70207852193995,
      "grad_norm": 0.42163482308387756,
      "learning_rate": 0.0003851602043638994,
      "loss": 1.9522,
      "step": 14040
    },
    {
      "epoch": 64.74826789838338,
      "grad_norm": 0.45882928371429443,
      "learning_rate": 0.00038500567881317576,
      "loss": 1.9469,
      "step": 14050
    },
    {
      "epoch": 64.79445727482678,
      "grad_norm": 0.8835741281509399,
      "learning_rate": 0.0003848510804150817,
      "loss": 1.9507,
      "step": 14060
    },
    {
      "epoch": 64.8406466512702,
      "grad_norm": 0.4860464036464691,
      "learning_rate": 0.0003846964092530365,
      "loss": 1.9443,
      "step": 14070
    },
    {
      "epoch": 64.88683602771363,
      "grad_norm": 0.35522904992103577,
      "learning_rate": 0.0003845416654104988,
      "loss": 1.9611,
      "step": 14080
    },
    {
      "epoch": 64.93302540415705,
      "grad_norm": 0.43448466062545776,
      "learning_rate": 0.0003843868489709664,
      "loss": 1.9631,
      "step": 14090
    },
    {
      "epoch": 64.97921478060046,
      "grad_norm": 0.3499636948108673,
      "learning_rate": 0.0003842319600179764,
      "loss": 1.9596,
      "step": 14100
    },
    {
      "epoch": 65.0,
      "eval_loss": 0.9797931909561157,
      "eval_runtime": 6.8565,
      "eval_samples_per_second": 4066.084,
      "eval_steps_per_second": 15.897,
      "step": 14105
    },
    {
      "epoch": 65.0230946882217,
      "grad_norm": 0.5480912923812866,
      "learning_rate": 0.00038407699863510496,
      "loss": 1.8483,
      "step": 14110
    },
    {
      "epoch": 65.06928406466513,
      "grad_norm": 0.44200101494789124,
      "learning_rate": 0.00038392196490596715,
      "loss": 1.9451,
      "step": 14120
    },
    {
      "epoch": 65.11547344110855,
      "grad_norm": 0.5839446187019348,
      "learning_rate": 0.0003837668589142174,
      "loss": 1.9479,
      "step": 14130
    },
    {
      "epoch": 65.16166281755196,
      "grad_norm": 0.44049227237701416,
      "learning_rate": 0.00038361168074354867,
      "loss": 1.949,
      "step": 14140
    },
    {
      "epoch": 65.20785219399538,
      "grad_norm": 0.42203405499458313,
      "learning_rate": 0.00038345643047769354,
      "loss": 1.9517,
      "step": 14150
    },
    {
      "epoch": 65.2540415704388,
      "grad_norm": 0.42322075366973877,
      "learning_rate": 0.00038330110820042286,
      "loss": 1.9582,
      "step": 14160
    },
    {
      "epoch": 65.30023094688222,
      "grad_norm": 0.42462313175201416,
      "learning_rate": 0.00038314571399554654,
      "loss": 1.9539,
      "step": 14170
    },
    {
      "epoch": 65.34642032332563,
      "grad_norm": 0.5750473141670227,
      "learning_rate": 0.0003829902479469136,
      "loss": 1.94,
      "step": 14180
    },
    {
      "epoch": 65.39260969976905,
      "grad_norm": 0.29580026865005493,
      "learning_rate": 0.0003828347101384112,
      "loss": 1.9508,
      "step": 14190
    },
    {
      "epoch": 65.43879907621248,
      "grad_norm": 0.36503541469573975,
      "learning_rate": 0.00038267910065396593,
      "loss": 1.9556,
      "step": 14200
    },
    {
      "epoch": 65.48498845265588,
      "grad_norm": 0.43112847208976746,
      "learning_rate": 0.0003825234195775426,
      "loss": 1.9577,
      "step": 14210
    },
    {
      "epoch": 65.5311778290993,
      "grad_norm": 0.38295355439186096,
      "learning_rate": 0.00038236766699314474,
      "loss": 1.9539,
      "step": 14220
    },
    {
      "epoch": 65.57736720554273,
      "grad_norm": 0.39904558658599854,
      "learning_rate": 0.00038221184298481447,
      "loss": 1.9448,
      "step": 14230
    },
    {
      "epoch": 65.62355658198614,
      "grad_norm": 0.5407680869102478,
      "learning_rate": 0.0003820559476366325,
      "loss": 1.9571,
      "step": 14240
    },
    {
      "epoch": 65.66974595842956,
      "grad_norm": 0.4256860315799713,
      "learning_rate": 0.00038189998103271795,
      "loss": 1.957,
      "step": 14250
    },
    {
      "epoch": 65.71593533487298,
      "grad_norm": 0.38395923376083374,
      "learning_rate": 0.0003817439432572286,
      "loss": 1.9431,
      "step": 14260
    },
    {
      "epoch": 65.7621247113164,
      "grad_norm": 0.3601718246936798,
      "learning_rate": 0.00038158783439436026,
      "loss": 1.9495,
      "step": 14270
    },
    {
      "epoch": 65.80831408775981,
      "grad_norm": 0.40270066261291504,
      "learning_rate": 0.00038143165452834743,
      "loss": 1.9563,
      "step": 14280
    },
    {
      "epoch": 65.85450346420323,
      "grad_norm": 0.4146612286567688,
      "learning_rate": 0.0003812754037434629,
      "loss": 1.9498,
      "step": 14290
    },
    {
      "epoch": 65.90069284064666,
      "grad_norm": 0.7133442759513855,
      "learning_rate": 0.00038111908212401746,
      "loss": 1.9474,
      "step": 14300
    },
    {
      "epoch": 65.94688221709006,
      "grad_norm": 0.37381958961486816,
      "learning_rate": 0.00038096268975436044,
      "loss": 1.9552,
      "step": 14310
    },
    {
      "epoch": 65.99307159353349,
      "grad_norm": 0.42579156160354614,
      "learning_rate": 0.00038080622671887905,
      "loss": 1.9529,
      "step": 14320
    },
    {
      "epoch": 66.0,
      "eval_loss": 0.9805078506469727,
      "eval_runtime": 6.8595,
      "eval_samples_per_second": 4064.305,
      "eval_steps_per_second": 15.89,
      "step": 14322
    },
    {
      "epoch": 66.03695150115473,
      "grad_norm": 0.46764659881591797,
      "learning_rate": 0.0003806496931019989,
      "loss": 1.861,
      "step": 14330
    },
    {
      "epoch": 66.08314087759815,
      "grad_norm": 0.6515936255455017,
      "learning_rate": 0.0003804930889881835,
      "loss": 1.9393,
      "step": 14340
    },
    {
      "epoch": 66.12933025404158,
      "grad_norm": 0.4092085659503937,
      "learning_rate": 0.00038033641446193444,
      "loss": 1.9373,
      "step": 14350
    },
    {
      "epoch": 66.17551963048498,
      "grad_norm": 0.47823017835617065,
      "learning_rate": 0.0003801796696077915,
      "loss": 1.9432,
      "step": 14360
    },
    {
      "epoch": 66.2217090069284,
      "grad_norm": 0.39609721302986145,
      "learning_rate": 0.0003800228545103321,
      "loss": 1.9484,
      "step": 14370
    },
    {
      "epoch": 66.26789838337183,
      "grad_norm": 0.5548295974731445,
      "learning_rate": 0.0003798659692541716,
      "loss": 1.9572,
      "step": 14380
    },
    {
      "epoch": 66.31408775981524,
      "grad_norm": 1.8371846675872803,
      "learning_rate": 0.0003797090139239635,
      "loss": 1.9494,
      "step": 14390
    },
    {
      "epoch": 66.36027713625866,
      "grad_norm": 0.5595433115959167,
      "learning_rate": 0.00037955198860439886,
      "loss": 1.9472,
      "step": 14400
    },
    {
      "epoch": 66.40646651270208,
      "grad_norm": 0.43218085169792175,
      "learning_rate": 0.0003793948933802066,
      "loss": 1.9576,
      "step": 14410
    },
    {
      "epoch": 66.45265588914549,
      "grad_norm": 0.4343598484992981,
      "learning_rate": 0.0003792377283361532,
      "loss": 1.9341,
      "step": 14420
    },
    {
      "epoch": 66.49884526558891,
      "grad_norm": 0.3903789520263672,
      "learning_rate": 0.0003790804935570432,
      "loss": 1.9548,
      "step": 14430
    },
    {
      "epoch": 66.54503464203233,
      "grad_norm": 0.3937230408191681,
      "learning_rate": 0.0003789231891277183,
      "loss": 1.958,
      "step": 14440
    },
    {
      "epoch": 66.59122401847576,
      "grad_norm": 0.4471563994884491,
      "learning_rate": 0.00037876581513305804,
      "loss": 1.9545,
      "step": 14450
    },
    {
      "epoch": 66.63741339491916,
      "grad_norm": 0.49115845561027527,
      "learning_rate": 0.00037860837165797946,
      "loss": 1.9566,
      "step": 14460
    },
    {
      "epoch": 66.68360277136259,
      "grad_norm": 0.45429158210754395,
      "learning_rate": 0.0003784508587874371,
      "loss": 1.9614,
      "step": 14470
    },
    {
      "epoch": 66.72979214780601,
      "grad_norm": 0.36709633469581604,
      "learning_rate": 0.0003782932766064229,
      "loss": 1.9488,
      "step": 14480
    },
    {
      "epoch": 66.77598152424942,
      "grad_norm": 0.48396506905555725,
      "learning_rate": 0.0003781356251999663,
      "loss": 1.9537,
      "step": 14490
    },
    {
      "epoch": 66.82217090069284,
      "grad_norm": 0.4160744249820709,
      "learning_rate": 0.00037797790465313397,
      "loss": 1.9438,
      "step": 14500
    },
    {
      "epoch": 66.86836027713626,
      "grad_norm": 0.391525536775589,
      "learning_rate": 0.00037782011505102997,
      "loss": 1.9459,
      "step": 14510
    },
    {
      "epoch": 66.91454965357968,
      "grad_norm": 0.37515419721603394,
      "learning_rate": 0.00037766225647879547,
      "loss": 1.9518,
      "step": 14520
    },
    {
      "epoch": 66.96073903002309,
      "grad_norm": 0.3782539367675781,
      "learning_rate": 0.00037750432902160913,
      "loss": 1.9518,
      "step": 14530
    },
    {
      "epoch": 67.0,
      "eval_loss": 0.9789618849754333,
      "eval_runtime": 6.8478,
      "eval_samples_per_second": 4071.221,
      "eval_steps_per_second": 15.917,
      "step": 14539
    },
    {
      "epoch": 67.00461893764434,
      "grad_norm": 0.45859000086784363,
      "learning_rate": 0.00037734633276468655,
      "loss": 1.8449,
      "step": 14540
    },
    {
      "epoch": 67.05080831408776,
      "grad_norm": 0.47332537174224854,
      "learning_rate": 0.00037718826779328053,
      "loss": 1.9407,
      "step": 14550
    },
    {
      "epoch": 67.09699769053118,
      "grad_norm": 0.4210543930530548,
      "learning_rate": 0.00037703013419268093,
      "loss": 1.9535,
      "step": 14560
    },
    {
      "epoch": 67.14318706697459,
      "grad_norm": 0.37078800797462463,
      "learning_rate": 0.0003768719320482147,
      "loss": 1.9467,
      "step": 14570
    },
    {
      "epoch": 67.18937644341801,
      "grad_norm": 0.429243803024292,
      "learning_rate": 0.0003767136614452458,
      "loss": 1.9511,
      "step": 14580
    },
    {
      "epoch": 67.23556581986143,
      "grad_norm": 0.40779930353164673,
      "learning_rate": 0.0003765553224691749,
      "loss": 1.9417,
      "step": 14590
    },
    {
      "epoch": 67.28175519630484,
      "grad_norm": 0.37991809844970703,
      "learning_rate": 0.00037639691520543973,
      "loss": 1.9485,
      "step": 14600
    },
    {
      "epoch": 67.32794457274827,
      "grad_norm": 0.5055180191993713,
      "learning_rate": 0.00037623843973951497,
      "loss": 1.9582,
      "step": 14610
    },
    {
      "epoch": 67.37413394919169,
      "grad_norm": 0.5285425782203674,
      "learning_rate": 0.000376079896156912,
      "loss": 1.9498,
      "step": 14620
    },
    {
      "epoch": 67.42032332563511,
      "grad_norm": 0.4794129729270935,
      "learning_rate": 0.0003759212845431789,
      "loss": 1.9458,
      "step": 14630
    },
    {
      "epoch": 67.46651270207852,
      "grad_norm": 0.4875871539115906,
      "learning_rate": 0.0003757626049839005,
      "loss": 1.9453,
      "step": 14640
    },
    {
      "epoch": 67.51270207852194,
      "grad_norm": 0.4194355905056,
      "learning_rate": 0.0003756038575646983,
      "loss": 1.9503,
      "step": 14650
    },
    {
      "epoch": 67.55889145496536,
      "grad_norm": 0.40932562947273254,
      "learning_rate": 0.0003754450423712304,
      "loss": 1.9495,
      "step": 14660
    },
    {
      "epoch": 67.60508083140877,
      "grad_norm": 0.5359645485877991,
      "learning_rate": 0.00037528615948919156,
      "loss": 1.9509,
      "step": 14670
    },
    {
      "epoch": 67.65127020785219,
      "grad_norm": 0.45611926913261414,
      "learning_rate": 0.0003751272090043129,
      "loss": 1.9556,
      "step": 14680
    },
    {
      "epoch": 67.69745958429561,
      "grad_norm": 0.3952290713787079,
      "learning_rate": 0.00037496819100236214,
      "loss": 1.9448,
      "step": 14690
    },
    {
      "epoch": 67.74364896073902,
      "grad_norm": 0.4005526602268219,
      "learning_rate": 0.00037480910556914347,
      "loss": 1.947,
      "step": 14700
    },
    {
      "epoch": 67.78983833718245,
      "grad_norm": 0.40193477272987366,
      "learning_rate": 0.0003746499527904972,
      "loss": 1.941,
      "step": 14710
    },
    {
      "epoch": 67.83602771362587,
      "grad_norm": 0.4198952913284302,
      "learning_rate": 0.0003744907327523005,
      "loss": 1.9463,
      "step": 14720
    },
    {
      "epoch": 67.88221709006929,
      "grad_norm": 0.4575952887535095,
      "learning_rate": 0.00037433144554046617,
      "loss": 1.9399,
      "step": 14730
    },
    {
      "epoch": 67.9284064665127,
      "grad_norm": 0.4006485342979431,
      "learning_rate": 0.00037417209124094376,
      "loss": 1.9543,
      "step": 14740
    },
    {
      "epoch": 67.97459584295612,
      "grad_norm": 0.5013596415519714,
      "learning_rate": 0.00037401266993971884,
      "loss": 1.9561,
      "step": 14750
    },
    {
      "epoch": 68.0,
      "eval_loss": 0.9799115657806396,
      "eval_runtime": 7.0325,
      "eval_samples_per_second": 3964.304,
      "eval_steps_per_second": 15.499,
      "step": 14756
    },
    {
      "epoch": 68.01847575057737,
      "grad_norm": 0.3549019396305084,
      "learning_rate": 0.0003738531817228131,
      "loss": 1.8546,
      "step": 14760
    },
    {
      "epoch": 68.06466512702079,
      "grad_norm": 0.5440217852592468,
      "learning_rate": 0.00037369362667628435,
      "loss": 1.9477,
      "step": 14770
    },
    {
      "epoch": 68.1108545034642,
      "grad_norm": 0.43061572313308716,
      "learning_rate": 0.0003735340048862267,
      "loss": 1.9447,
      "step": 14780
    },
    {
      "epoch": 68.15704387990762,
      "grad_norm": 0.38569679856300354,
      "learning_rate": 0.0003733743164387697,
      "loss": 1.9451,
      "step": 14790
    },
    {
      "epoch": 68.20323325635104,
      "grad_norm": 0.5248477458953857,
      "learning_rate": 0.00037321456142007966,
      "loss": 1.9435,
      "step": 14800
    },
    {
      "epoch": 68.24942263279446,
      "grad_norm": 0.39509958028793335,
      "learning_rate": 0.00037305473991635805,
      "loss": 1.9458,
      "step": 14810
    },
    {
      "epoch": 68.29561200923787,
      "grad_norm": 0.5864104628562927,
      "learning_rate": 0.00037289485201384264,
      "loss": 1.9432,
      "step": 14820
    },
    {
      "epoch": 68.3418013856813,
      "grad_norm": 0.45866724848747253,
      "learning_rate": 0.00037273489779880703,
      "loss": 1.9461,
      "step": 14830
    },
    {
      "epoch": 68.38799076212472,
      "grad_norm": 0.3760174512863159,
      "learning_rate": 0.0003725748773575604,
      "loss": 1.9528,
      "step": 14840
    },
    {
      "epoch": 68.43418013856812,
      "grad_norm": 0.39343172311782837,
      "learning_rate": 0.0003724147907764478,
      "loss": 1.9459,
      "step": 14850
    },
    {
      "epoch": 68.48036951501155,
      "grad_norm": 0.4039049744606018,
      "learning_rate": 0.00037225463814185,
      "loss": 1.9451,
      "step": 14860
    },
    {
      "epoch": 68.52655889145497,
      "grad_norm": 0.40894588828086853,
      "learning_rate": 0.0003720944195401833,
      "loss": 1.9485,
      "step": 14870
    },
    {
      "epoch": 68.57274826789839,
      "grad_norm": 0.40154534578323364,
      "learning_rate": 0.00037193413505789963,
      "loss": 1.9552,
      "step": 14880
    },
    {
      "epoch": 68.6189376443418,
      "grad_norm": 0.4626601040363312,
      "learning_rate": 0.00037177378478148653,
      "loss": 1.9397,
      "step": 14890
    },
    {
      "epoch": 68.66512702078522,
      "grad_norm": 0.4121321737766266,
      "learning_rate": 0.0003716133687974669,
      "loss": 1.9423,
      "step": 14900
    },
    {
      "epoch": 68.71131639722864,
      "grad_norm": 0.5197650194168091,
      "learning_rate": 0.00037145288719239933,
      "loss": 1.9434,
      "step": 14910
    },
    {
      "epoch": 68.75750577367205,
      "grad_norm": 0.4205920398235321,
      "learning_rate": 0.0003712923400528776,
      "loss": 1.9525,
      "step": 14920
    },
    {
      "epoch": 68.80369515011547,
      "grad_norm": 0.3901185393333435,
      "learning_rate": 0.0003711317274655309,
      "loss": 1.9489,
      "step": 14930
    },
    {
      "epoch": 68.8498845265589,
      "grad_norm": 0.6006811857223511,
      "learning_rate": 0.000370971049517024,
      "loss": 1.955,
      "step": 14940
    },
    {
      "epoch": 68.8960739030023,
      "grad_norm": 0.44273513555526733,
      "learning_rate": 0.00037081030629405637,
      "loss": 1.9486,
      "step": 14950
    },
    {
      "epoch": 68.94226327944573,
      "grad_norm": 0.5592845678329468,
      "learning_rate": 0.0003706494978833632,
      "loss": 1.9469,
      "step": 14960
    },
    {
      "epoch": 68.98845265588915,
      "grad_norm": 0.512022852897644,
      "learning_rate": 0.0003704886243717147,
      "loss": 1.9573,
      "step": 14970
    },
    {
      "epoch": 69.0,
      "eval_loss": 0.9803992509841919,
      "eval_runtime": 6.9247,
      "eval_samples_per_second": 4026.007,
      "eval_steps_per_second": 15.741,
      "step": 14973
    },
    {
      "epoch": 69.0323325635104,
      "grad_norm": 0.3654720187187195,
      "learning_rate": 0.0003703276858459162,
      "loss": 1.8474,
      "step": 14980
    },
    {
      "epoch": 69.07852193995382,
      "grad_norm": 0.5154033899307251,
      "learning_rate": 0.00037016668239280807,
      "loss": 1.9379,
      "step": 14990
    },
    {
      "epoch": 69.12471131639722,
      "grad_norm": 0.42255714535713196,
      "learning_rate": 0.00037000561409926576,
      "loss": 1.94,
      "step": 15000
    },
    {
      "epoch": 69.17090069284065,
      "grad_norm": 0.37790751457214355,
      "learning_rate": 0.0003698444810521997,
      "loss": 1.9372,
      "step": 15010
    },
    {
      "epoch": 69.21709006928407,
      "grad_norm": 0.4132918417453766,
      "learning_rate": 0.00036968328333855535,
      "loss": 1.9413,
      "step": 15020
    },
    {
      "epoch": 69.26327944572748,
      "grad_norm": 0.3808225393295288,
      "learning_rate": 0.0003695220210453128,
      "loss": 1.956,
      "step": 15030
    },
    {
      "epoch": 69.3094688221709,
      "grad_norm": 0.4711157977581024,
      "learning_rate": 0.00036936069425948725,
      "loss": 1.9411,
      "step": 15040
    },
    {
      "epoch": 69.35565819861432,
      "grad_norm": 0.38611313700675964,
      "learning_rate": 0.00036919930306812866,
      "loss": 1.9489,
      "step": 15050
    },
    {
      "epoch": 69.40184757505774,
      "grad_norm": 0.4549177289009094,
      "learning_rate": 0.0003690378475583216,
      "loss": 1.9413,
      "step": 15060
    },
    {
      "epoch": 69.44803695150115,
      "grad_norm": 0.3956157863140106,
      "learning_rate": 0.00036887632781718553,
      "loss": 1.9549,
      "step": 15070
    },
    {
      "epoch": 69.49422632794457,
      "grad_norm": 0.46572625637054443,
      "learning_rate": 0.0003687147439318745,
      "loss": 1.9391,
      "step": 15080
    },
    {
      "epoch": 69.540415704388,
      "grad_norm": 0.42488178610801697,
      "learning_rate": 0.000368553095989577,
      "loss": 1.9576,
      "step": 15090
    },
    {
      "epoch": 69.5866050808314,
      "grad_norm": 0.46108371019363403,
      "learning_rate": 0.00036839138407751624,
      "loss": 1.947,
      "step": 15100
    },
    {
      "epoch": 69.63279445727483,
      "grad_norm": 0.36516204476356506,
      "learning_rate": 0.00036822960828295013,
      "loss": 1.9365,
      "step": 15110
    },
    {
      "epoch": 69.67898383371825,
      "grad_norm": 0.33794423937797546,
      "learning_rate": 0.0003680677686931707,
      "loss": 1.9353,
      "step": 15120
    },
    {
      "epoch": 69.72517321016166,
      "grad_norm": 0.3864891529083252,
      "learning_rate": 0.0003679058653955046,
      "loss": 1.9403,
      "step": 15130
    },
    {
      "epoch": 69.77136258660508,
      "grad_norm": 0.3886059522628784,
      "learning_rate": 0.00036774389847731275,
      "loss": 1.9385,
      "step": 15140
    },
    {
      "epoch": 69.8175519630485,
      "grad_norm": 0.40909329056739807,
      "learning_rate": 0.0003675818680259906,
      "loss": 1.9615,
      "step": 15150
    },
    {
      "epoch": 69.86374133949192,
      "grad_norm": 0.37472841143608093,
      "learning_rate": 0.0003674197741289677,
      "loss": 1.9486,
      "step": 15160
    },
    {
      "epoch": 69.90993071593533,
      "grad_norm": 0.4175105392932892,
      "learning_rate": 0.00036725761687370783,
      "loss": 1.9447,
      "step": 15170
    },
    {
      "epoch": 69.95612009237875,
      "grad_norm": 0.7896902561187744,
      "learning_rate": 0.00036709539634770906,
      "loss": 1.9453,
      "step": 15180
    },
    {
      "epoch": 70.0,
      "grad_norm": 0.29261845350265503,
      "learning_rate": 0.00036693311263850356,
      "loss": 1.8519,
      "step": 15190
    },
    {
      "epoch": 70.0,
      "eval_loss": 0.9805700778961182,
      "eval_runtime": 6.8469,
      "eval_samples_per_second": 4071.758,
      "eval_steps_per_second": 15.92,
      "step": 15190
    },
    {
      "epoch": 70.04618937644342,
      "grad_norm": 0.3439168632030487,
      "learning_rate": 0.00036677076583365754,
      "loss": 1.9469,
      "step": 15200
    },
    {
      "epoch": 70.09237875288683,
      "grad_norm": 0.45662903785705566,
      "learning_rate": 0.0003666083560207713,
      "loss": 1.9361,
      "step": 15210
    },
    {
      "epoch": 70.13856812933025,
      "grad_norm": 0.410137414932251,
      "learning_rate": 0.0003664458832874792,
      "loss": 1.9431,
      "step": 15220
    },
    {
      "epoch": 70.18475750577367,
      "grad_norm": 0.3546268939971924,
      "learning_rate": 0.0003662833477214493,
      "loss": 1.941,
      "step": 15230
    },
    {
      "epoch": 70.2309468822171,
      "grad_norm": 0.3507339656352997,
      "learning_rate": 0.00036612074941038417,
      "loss": 1.9359,
      "step": 15240
    },
    {
      "epoch": 70.2771362586605,
      "grad_norm": 0.42015141248703003,
      "learning_rate": 0.00036595808844201933,
      "loss": 1.9376,
      "step": 15250
    },
    {
      "epoch": 70.32332563510393,
      "grad_norm": 0.35601744055747986,
      "learning_rate": 0.00036579536490412485,
      "loss": 1.9413,
      "step": 15260
    },
    {
      "epoch": 70.36951501154735,
      "grad_norm": 0.3291834890842438,
      "learning_rate": 0.0003656325788845043,
      "loss": 1.9398,
      "step": 15270
    },
    {
      "epoch": 70.41570438799076,
      "grad_norm": 0.4674346446990967,
      "learning_rate": 0.000365469730470995,
      "loss": 1.9355,
      "step": 15280
    },
    {
      "epoch": 70.46189376443418,
      "grad_norm": 0.393839567899704,
      "learning_rate": 0.00036530681975146785,
      "loss": 1.9394,
      "step": 15290
    },
    {
      "epoch": 70.5080831408776,
      "grad_norm": 0.3679949641227722,
      "learning_rate": 0.00036514384681382735,
      "loss": 1.9479,
      "step": 15300
    },
    {
      "epoch": 70.55427251732101,
      "grad_norm": 0.3231094479560852,
      "learning_rate": 0.0003649808117460117,
      "loss": 1.9446,
      "step": 15310
    },
    {
      "epoch": 70.60046189376443,
      "grad_norm": 0.3354927897453308,
      "learning_rate": 0.00036481771463599277,
      "loss": 1.9486,
      "step": 15320
    },
    {
      "epoch": 70.64665127020785,
      "grad_norm": 0.347088485956192,
      "learning_rate": 0.0003646545555717755,
      "loss": 1.9523,
      "step": 15330
    },
    {
      "epoch": 70.69284064665128,
      "grad_norm": 0.32097744941711426,
      "learning_rate": 0.0003644913346413985,
      "loss": 1.9448,
      "step": 15340
    },
    {
      "epoch": 70.73903002309468,
      "grad_norm": 0.32897648215293884,
      "learning_rate": 0.00036432805193293384,
      "loss": 1.9508,
      "step": 15350
    },
    {
      "epoch": 70.78521939953811,
      "grad_norm": 0.46837347745895386,
      "learning_rate": 0.0003641647075344867,
      "loss": 1.9505,
      "step": 15360
    },
    {
      "epoch": 70.83140877598153,
      "grad_norm": 0.4294271767139435,
      "learning_rate": 0.00036400130153419575,
      "loss": 1.943,
      "step": 15370
    },
    {
      "epoch": 70.87759815242494,
      "grad_norm": 0.41729238629341125,
      "learning_rate": 0.0003638378340202328,
      "loss": 1.9605,
      "step": 15380
    },
    {
      "epoch": 70.92378752886836,
      "grad_norm": 0.5358840823173523,
      "learning_rate": 0.00036367430508080277,
      "loss": 1.9475,
      "step": 15390
    },
    {
      "epoch": 70.96997690531178,
      "grad_norm": 0.4265207052230835,
      "learning_rate": 0.00036351071480414404,
      "loss": 1.9439,
      "step": 15400
    },
    {
      "epoch": 71.0,
      "eval_loss": 0.9797784090042114,
      "eval_runtime": 6.8797,
      "eval_samples_per_second": 4052.374,
      "eval_steps_per_second": 15.844,
      "step": 15407
    },
    {
      "epoch": 71.01385681293303,
      "grad_norm": 0.29660215973854065,
      "learning_rate": 0.00036334706327852774,
      "loss": 1.8395,
      "step": 15410
    },
    {
      "epoch": 71.06004618937645,
      "grad_norm": 0.4900285303592682,
      "learning_rate": 0.000363183350592258,
      "loss": 1.939,
      "step": 15420
    },
    {
      "epoch": 71.10623556581986,
      "grad_norm": 0.4299556612968445,
      "learning_rate": 0.00036301957683367253,
      "loss": 1.9352,
      "step": 15430
    },
    {
      "epoch": 71.15242494226328,
      "grad_norm": 0.45691123604774475,
      "learning_rate": 0.00036285574209114123,
      "loss": 1.9325,
      "step": 15440
    },
    {
      "epoch": 71.1986143187067,
      "grad_norm": 0.5054817199707031,
      "learning_rate": 0.0003626918464530675,
      "loss": 1.9366,
      "step": 15450
    },
    {
      "epoch": 71.24480369515011,
      "grad_norm": 0.3780764043331146,
      "learning_rate": 0.00036252789000788734,
      "loss": 1.9463,
      "step": 15460
    },
    {
      "epoch": 71.29099307159353,
      "grad_norm": 0.4224211573600769,
      "learning_rate": 0.00036236387284406947,
      "loss": 1.9517,
      "step": 15470
    },
    {
      "epoch": 71.33718244803696,
      "grad_norm": 0.3769790530204773,
      "learning_rate": 0.0003621997950501156,
      "loss": 1.9478,
      "step": 15480
    },
    {
      "epoch": 71.38337182448036,
      "grad_norm": 0.49833357334136963,
      "learning_rate": 0.00036203565671456,
      "loss": 1.9391,
      "step": 15490
    },
    {
      "epoch": 71.42956120092379,
      "grad_norm": 0.508572518825531,
      "learning_rate": 0.00036187145792596965,
      "loss": 1.9291,
      "step": 15500
    },
    {
      "epoch": 71.47575057736721,
      "grad_norm": 0.41063663363456726,
      "learning_rate": 0.00036170719877294424,
      "loss": 1.944,
      "step": 15510
    },
    {
      "epoch": 71.52193995381063,
      "grad_norm": 0.4356134235858917,
      "learning_rate": 0.00036154287934411577,
      "loss": 1.9498,
      "step": 15520
    },
    {
      "epoch": 71.56812933025404,
      "grad_norm": 0.39944541454315186,
      "learning_rate": 0.0003613784997281491,
      "loss": 1.9479,
      "step": 15530
    },
    {
      "epoch": 71.61431870669746,
      "grad_norm": 0.341036319732666,
      "learning_rate": 0.0003612140600137415,
      "loss": 1.9449,
      "step": 15540
    },
    {
      "epoch": 71.66050808314088,
      "grad_norm": 0.36679354310035706,
      "learning_rate": 0.00036104956028962227,
      "loss": 1.9434,
      "step": 15550
    },
    {
      "epoch": 71.70669745958429,
      "grad_norm": 0.3719087243080139,
      "learning_rate": 0.00036088500064455366,
      "loss": 1.9441,
      "step": 15560
    },
    {
      "epoch": 71.75288683602771,
      "grad_norm": 0.4138606786727905,
      "learning_rate": 0.0003607203811673299,
      "loss": 1.9465,
      "step": 15570
    },
    {
      "epoch": 71.79907621247114,
      "grad_norm": 0.3420497477054596,
      "learning_rate": 0.0003605557019467775,
      "loss": 1.951,
      "step": 15580
    },
    {
      "epoch": 71.84526558891454,
      "grad_norm": 0.4064956307411194,
      "learning_rate": 0.0003603909630717556,
      "loss": 1.9488,
      "step": 15590
    },
    {
      "epoch": 71.89145496535797,
      "grad_norm": 0.47377222776412964,
      "learning_rate": 0.0003602261646311548,
      "loss": 1.9461,
      "step": 15600
    },
    {
      "epoch": 71.93764434180139,
      "grad_norm": 0.5403757095336914,
      "learning_rate": 0.0003600613067138986,
      "loss": 1.9505,
      "step": 15610
    },
    {
      "epoch": 71.98383371824481,
      "grad_norm": 0.39621126651763916,
      "learning_rate": 0.0003598963894089422,
      "loss": 1.9381,
      "step": 15620
    },
    {
      "epoch": 72.0,
      "eval_loss": 0.9805826544761658,
      "eval_runtime": 6.8517,
      "eval_samples_per_second": 4068.914,
      "eval_steps_per_second": 15.908,
      "step": 15624
    },
    {
      "epoch": 72.02771362586606,
      "grad_norm": 0.5006365180015564,
      "learning_rate": 0.00035973141280527284,
      "loss": 1.8529,
      "step": 15630
    },
    {
      "epoch": 72.07390300230946,
      "grad_norm": 0.3885723948478699,
      "learning_rate": 0.0003595663769919098,
      "loss": 1.9371,
      "step": 15640
    },
    {
      "epoch": 72.12009237875289,
      "grad_norm": 0.5738780498504639,
      "learning_rate": 0.00035940128205790445,
      "loss": 1.9367,
      "step": 15650
    },
    {
      "epoch": 72.16628175519631,
      "grad_norm": 0.46467041969299316,
      "learning_rate": 0.0003592361280923399,
      "loss": 1.9356,
      "step": 15660
    },
    {
      "epoch": 72.21247113163972,
      "grad_norm": 0.422832190990448,
      "learning_rate": 0.0003590709151843311,
      "loss": 1.9481,
      "step": 15670
    },
    {
      "epoch": 72.25866050808314,
      "grad_norm": 0.4169785976409912,
      "learning_rate": 0.00035890564342302495,
      "loss": 1.9373,
      "step": 15680
    },
    {
      "epoch": 72.30484988452656,
      "grad_norm": 0.6075015664100647,
      "learning_rate": 0.0003587403128975999,
      "loss": 1.9427,
      "step": 15690
    },
    {
      "epoch": 72.35103926096998,
      "grad_norm": 0.3583756983280182,
      "learning_rate": 0.0003585749236972664,
      "loss": 1.9393,
      "step": 15700
    },
    {
      "epoch": 72.39722863741339,
      "grad_norm": 0.3647904694080353,
      "learning_rate": 0.0003584094759112662,
      "loss": 1.9468,
      "step": 15710
    },
    {
      "epoch": 72.44341801385681,
      "grad_norm": 0.4433209002017975,
      "learning_rate": 0.000358243969628873,
      "loss": 1.9392,
      "step": 15720
    },
    {
      "epoch": 72.48960739030024,
      "grad_norm": 0.3492101728916168,
      "learning_rate": 0.00035807840493939187,
      "loss": 1.9396,
      "step": 15730
    },
    {
      "epoch": 72.53579676674364,
      "grad_norm": 0.45963358879089355,
      "learning_rate": 0.0003579127819321593,
      "loss": 1.9353,
      "step": 15740
    },
    {
      "epoch": 72.58198614318707,
      "grad_norm": 0.43405550718307495,
      "learning_rate": 0.00035774710069654366,
      "loss": 1.9404,
      "step": 15750
    },
    {
      "epoch": 72.62817551963049,
      "grad_norm": 0.3353232741355896,
      "learning_rate": 0.00035758136132194425,
      "loss": 1.938,
      "step": 15760
    },
    {
      "epoch": 72.6743648960739,
      "grad_norm": 0.40350428223609924,
      "learning_rate": 0.00035741556389779194,
      "loss": 1.9443,
      "step": 15770
    },
    {
      "epoch": 72.72055427251732,
      "grad_norm": 0.41053861379623413,
      "learning_rate": 0.0003572497085135492,
      "loss": 1.9498,
      "step": 15780
    },
    {
      "epoch": 72.76674364896074,
      "grad_norm": 0.6110565066337585,
      "learning_rate": 0.00035708379525870916,
      "loss": 1.9423,
      "step": 15790
    },
    {
      "epoch": 72.81293302540416,
      "grad_norm": 0.48282790184020996,
      "learning_rate": 0.0003569178242227968,
      "loss": 1.944,
      "step": 15800
    },
    {
      "epoch": 72.85912240184757,
      "grad_norm": 0.3517153859138489,
      "learning_rate": 0.0003567517954953679,
      "loss": 1.9446,
      "step": 15810
    },
    {
      "epoch": 72.905311778291,
      "grad_norm": 0.4024982452392578,
      "learning_rate": 0.0003565857091660095,
      "loss": 1.9429,
      "step": 15820
    },
    {
      "epoch": 72.95150115473442,
      "grad_norm": 0.6222698092460632,
      "learning_rate": 0.0003564195653243396,
      "loss": 1.9441,
      "step": 15830
    },
    {
      "epoch": 72.99769053117782,
      "grad_norm": 0.37454766035079956,
      "learning_rate": 0.0003562533640600075,
      "loss": 1.9421,
      "step": 15840
    },
    {
      "epoch": 73.0,
      "eval_loss": 0.9802542328834534,
      "eval_runtime": 7.3022,
      "eval_samples_per_second": 3817.912,
      "eval_steps_per_second": 14.927,
      "step": 15841
    },
    {
      "epoch": 73.04157043879907,
      "grad_norm": 0.40226051211357117,
      "learning_rate": 0.0003560871054626933,
      "loss": 1.8413,
      "step": 15850
    },
    {
      "epoch": 73.08775981524249,
      "grad_norm": 0.44225406646728516,
      "learning_rate": 0.00035592078962210795,
      "loss": 1.9337,
      "step": 15860
    },
    {
      "epoch": 73.13394919168591,
      "grad_norm": 0.3331888020038605,
      "learning_rate": 0.0003557544166279934,
      "loss": 1.937,
      "step": 15870
    },
    {
      "epoch": 73.18013856812934,
      "grad_norm": 0.41469064354896545,
      "learning_rate": 0.00035558798657012245,
      "loss": 1.9288,
      "step": 15880
    },
    {
      "epoch": 73.22632794457274,
      "grad_norm": 0.3670661449432373,
      "learning_rate": 0.0003554214995382988,
      "loss": 1.939,
      "step": 15890
    },
    {
      "epoch": 73.27251732101617,
      "grad_norm": 0.5715593099594116,
      "learning_rate": 0.0003552549556223565,
      "loss": 1.9405,
      "step": 15900
    },
    {
      "epoch": 73.31870669745959,
      "grad_norm": 0.4841529130935669,
      "learning_rate": 0.0003550883549121608,
      "loss": 1.9371,
      "step": 15910
    },
    {
      "epoch": 73.364896073903,
      "grad_norm": 0.48102256655693054,
      "learning_rate": 0.00035492169749760726,
      "loss": 1.9308,
      "step": 15920
    },
    {
      "epoch": 73.41108545034642,
      "grad_norm": 0.3967057764530182,
      "learning_rate": 0.00035475498346862217,
      "loss": 1.9383,
      "step": 15930
    },
    {
      "epoch": 73.45727482678984,
      "grad_norm": 0.40071216225624084,
      "learning_rate": 0.0003545882129151622,
      "loss": 1.935,
      "step": 15940
    },
    {
      "epoch": 73.50346420323325,
      "grad_norm": 0.7237024307250977,
      "learning_rate": 0.00035442138592721483,
      "loss": 1.9462,
      "step": 15950
    },
    {
      "epoch": 73.54965357967667,
      "grad_norm": 0.40224701166152954,
      "learning_rate": 0.0003542545025947976,
      "loss": 1.9409,
      "step": 15960
    },
    {
      "epoch": 73.5958429561201,
      "grad_norm": 0.47655189037323,
      "learning_rate": 0.00035408756300795894,
      "loss": 1.9411,
      "step": 15970
    },
    {
      "epoch": 73.64203233256352,
      "grad_norm": 0.3527604043483734,
      "learning_rate": 0.00035392056725677706,
      "loss": 1.9384,
      "step": 15980
    },
    {
      "epoch": 73.68822170900692,
      "grad_norm": 0.41949930787086487,
      "learning_rate": 0.0003537535154313609,
      "loss": 1.9349,
      "step": 15990
    },
    {
      "epoch": 73.73441108545035,
      "grad_norm": 0.34243059158325195,
      "learning_rate": 0.00035358640762184966,
      "loss": 1.9457,
      "step": 16000
    },
    {
      "epoch": 73.78060046189377,
      "grad_norm": 0.450764000415802,
      "learning_rate": 0.0003534192439184124,
      "loss": 1.9451,
      "step": 16010
    },
    {
      "epoch": 73.82678983833718,
      "grad_norm": 0.416560560464859,
      "learning_rate": 0.0003532520244112487,
      "loss": 1.9449,
      "step": 16020
    },
    {
      "epoch": 73.8729792147806,
      "grad_norm": 0.41424059867858887,
      "learning_rate": 0.0003530847491905881,
      "loss": 1.9471,
      "step": 16030
    },
    {
      "epoch": 73.91916859122402,
      "grad_norm": 0.48551490902900696,
      "learning_rate": 0.00035291741834669004,
      "loss": 1.9361,
      "step": 16040
    },
    {
      "epoch": 73.96535796766743,
      "grad_norm": 0.46273261308670044,
      "learning_rate": 0.0003527500319698444,
      "loss": 1.9415,
      "step": 16050
    },
    {
      "epoch": 74.0,
      "eval_loss": 0.9800111651420593,
      "eval_runtime": 7.2986,
      "eval_samples_per_second": 3819.796,
      "eval_steps_per_second": 14.934,
      "step": 16058
    },
    {
      "epoch": 74.00923787528869,
      "grad_norm": 0.41000938415527344,
      "learning_rate": 0.00035258259015037057,
      "loss": 1.8487,
      "step": 16060
    },
    {
      "epoch": 74.0554272517321,
      "grad_norm": 0.463735431432724,
      "learning_rate": 0.0003524150929786182,
      "loss": 1.9313,
      "step": 16070
    },
    {
      "epoch": 74.10161662817552,
      "grad_norm": 0.6146105527877808,
      "learning_rate": 0.00035224754054496657,
      "loss": 1.9246,
      "step": 16080
    },
    {
      "epoch": 74.14780600461894,
      "grad_norm": 0.4469186067581177,
      "learning_rate": 0.0003520799329398248,
      "loss": 1.9518,
      "step": 16090
    },
    {
      "epoch": 74.19399538106235,
      "grad_norm": 0.4163725972175598,
      "learning_rate": 0.000351912270253632,
      "loss": 1.9375,
      "step": 16100
    },
    {
      "epoch": 74.24018475750577,
      "grad_norm": 0.3565165102481842,
      "learning_rate": 0.00035174455257685686,
      "loss": 1.9308,
      "step": 16110
    },
    {
      "epoch": 74.2863741339492,
      "grad_norm": 0.42114511132240295,
      "learning_rate": 0.0003515767799999976,
      "loss": 1.9498,
      "step": 16120
    },
    {
      "epoch": 74.3325635103926,
      "grad_norm": 0.4566936492919922,
      "learning_rate": 0.0003514089526135823,
      "loss": 1.9527,
      "step": 16130
    },
    {
      "epoch": 74.37875288683603,
      "grad_norm": 0.4135141968727112,
      "learning_rate": 0.0003512410705081684,
      "loss": 1.9362,
      "step": 16140
    },
    {
      "epoch": 74.42494226327945,
      "grad_norm": 0.41284283995628357,
      "learning_rate": 0.00035107313377434314,
      "loss": 1.9358,
      "step": 16150
    },
    {
      "epoch": 74.47113163972287,
      "grad_norm": 0.3867082893848419,
      "learning_rate": 0.000350905142502723,
      "loss": 1.9455,
      "step": 16160
    },
    {
      "epoch": 74.51732101616628,
      "grad_norm": 0.3716796040534973,
      "learning_rate": 0.0003507370967839539,
      "loss": 1.9448,
      "step": 16170
    },
    {
      "epoch": 74.5635103926097,
      "grad_norm": 0.3624798655509949,
      "learning_rate": 0.0003505689967087112,
      "loss": 1.9389,
      "step": 16180
    },
    {
      "epoch": 74.60969976905312,
      "grad_norm": 0.5540136694908142,
      "learning_rate": 0.0003504008423676998,
      "loss": 1.9393,
      "step": 16190
    },
    {
      "epoch": 74.65588914549653,
      "grad_norm": 0.4441204071044922,
      "learning_rate": 0.0003502326338516534,
      "loss": 1.9431,
      "step": 16200
    },
    {
      "epoch": 74.70207852193995,
      "grad_norm": 0.3461616635322571,
      "learning_rate": 0.00035006437125133537,
      "loss": 1.9368,
      "step": 16210
    },
    {
      "epoch": 74.74826789838338,
      "grad_norm": 0.35266831517219543,
      "learning_rate": 0.0003498960546575381,
      "loss": 1.9473,
      "step": 16220
    },
    {
      "epoch": 74.79445727482678,
      "grad_norm": 0.38652753829956055,
      "learning_rate": 0.00034972768416108296,
      "loss": 1.9274,
      "step": 16230
    },
    {
      "epoch": 74.8406466512702,
      "grad_norm": 0.33613473176956177,
      "learning_rate": 0.0003495592598528208,
      "loss": 1.9291,
      "step": 16240
    },
    {
      "epoch": 74.88683602771363,
      "grad_norm": 0.39147454500198364,
      "learning_rate": 0.00034939078182363105,
      "loss": 1.9474,
      "step": 16250
    },
    {
      "epoch": 74.93302540415705,
      "grad_norm": 0.35524487495422363,
      "learning_rate": 0.0003492222501644223,
      "loss": 1.9405,
      "step": 16260
    },
    {
      "epoch": 74.97921478060046,
      "grad_norm": 0.4709763526916504,
      "learning_rate": 0.00034905366496613244,
      "loss": 1.9471,
      "step": 16270
    },
    {
      "epoch": 75.0,
      "eval_loss": 0.9817000031471252,
      "eval_runtime": 7.339,
      "eval_samples_per_second": 3798.742,
      "eval_steps_per_second": 14.852,
      "step": 16275
    },
    {
      "epoch": 75.0,
      "step": 16275,
      "total_flos": 2.2456509061922816e+16,
      "train_loss": 2.1308172144501625,
      "train_runtime": 4137.0713,
      "train_samples_per_second": 5356.543,
      "train_steps_per_second": 10.442
    }
  ],
  "logging_steps": 10,
  "max_steps": 43200,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 200,
  "save_steps": 1000,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 20,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 20
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.2456509061922816e+16,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
