{
  "best_metric": 1.0290464162826538,
  "best_model_checkpoint": "./ckpt/Instruments/checkpoint-14706",
  "epoch": 77.0,
  "eval_steps": 1000,
  "global_step": 19866,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.038834951456310676,
      "grad_norm": 13.624515533447266,
      "learning_rate": 9.72762645914397e-06,
      "loss": 21.8868,
      "step": 10
    },
    {
      "epoch": 0.07766990291262135,
      "grad_norm": 9.649519920349121,
      "learning_rate": 1.945525291828794e-05,
      "loss": 20.5644,
      "step": 20
    },
    {
      "epoch": 0.11650485436893204,
      "grad_norm": 5.905089378356934,
      "learning_rate": 2.918287937743191e-05,
      "loss": 18.7358,
      "step": 30
    },
    {
      "epoch": 0.1553398058252427,
      "grad_norm": 3.7521321773529053,
      "learning_rate": 3.891050583657588e-05,
      "loss": 17.2376,
      "step": 40
    },
    {
      "epoch": 0.1941747572815534,
      "grad_norm": 4.231695175170898,
      "learning_rate": 4.863813229571985e-05,
      "loss": 15.8963,
      "step": 50
    },
    {
      "epoch": 0.23300970873786409,
      "grad_norm": 3.7611842155456543,
      "learning_rate": 5.836575875486382e-05,
      "loss": 14.2259,
      "step": 60
    },
    {
      "epoch": 0.27184466019417475,
      "grad_norm": 3.062971830368042,
      "learning_rate": 6.809338521400777e-05,
      "loss": 12.2995,
      "step": 70
    },
    {
      "epoch": 0.3106796116504854,
      "grad_norm": 2.451059579849243,
      "learning_rate": 7.782101167315176e-05,
      "loss": 10.6499,
      "step": 80
    },
    {
      "epoch": 0.34951456310679613,
      "grad_norm": 1.973580241203308,
      "learning_rate": 8.754863813229571e-05,
      "loss": 9.2861,
      "step": 90
    },
    {
      "epoch": 0.3883495145631068,
      "grad_norm": 1.6530643701553345,
      "learning_rate": 9.72762645914397e-05,
      "loss": 8.4022,
      "step": 100
    },
    {
      "epoch": 0.42718446601941745,
      "grad_norm": 1.5082480907440186,
      "learning_rate": 0.00010700389105058365,
      "loss": 7.6628,
      "step": 110
    },
    {
      "epoch": 0.46601941747572817,
      "grad_norm": 1.3783082962036133,
      "learning_rate": 0.00011673151750972763,
      "loss": 7.191,
      "step": 120
    },
    {
      "epoch": 0.5048543689320388,
      "grad_norm": 1.2201964855194092,
      "learning_rate": 0.0001264591439688716,
      "loss": 6.8248,
      "step": 130
    },
    {
      "epoch": 0.5436893203883495,
      "grad_norm": 1.1961073875427246,
      "learning_rate": 0.00013618677042801555,
      "loss": 6.6073,
      "step": 140
    },
    {
      "epoch": 0.5825242718446602,
      "grad_norm": 1.0953541994094849,
      "learning_rate": 0.00014591439688715956,
      "loss": 6.4377,
      "step": 150
    },
    {
      "epoch": 0.6213592233009708,
      "grad_norm": 1.0246893167495728,
      "learning_rate": 0.0001556420233463035,
      "loss": 6.2656,
      "step": 160
    },
    {
      "epoch": 0.6601941747572816,
      "grad_norm": 1.0055301189422607,
      "learning_rate": 0.00016536964980544747,
      "loss": 6.1465,
      "step": 170
    },
    {
      "epoch": 0.6990291262135923,
      "grad_norm": 1.1167808771133423,
      "learning_rate": 0.00017509727626459142,
      "loss": 5.987,
      "step": 180
    },
    {
      "epoch": 0.7378640776699029,
      "grad_norm": 0.9399782419204712,
      "learning_rate": 0.00018482490272373543,
      "loss": 5.9103,
      "step": 190
    },
    {
      "epoch": 0.7766990291262136,
      "grad_norm": 0.9348872303962708,
      "learning_rate": 0.0001945525291828794,
      "loss": 5.8511,
      "step": 200
    },
    {
      "epoch": 0.8155339805825242,
      "grad_norm": 0.8982278108596802,
      "learning_rate": 0.00020428015564202335,
      "loss": 5.7726,
      "step": 210
    },
    {
      "epoch": 0.8543689320388349,
      "grad_norm": 0.9406687021255493,
      "learning_rate": 0.0002140077821011673,
      "loss": 5.7114,
      "step": 220
    },
    {
      "epoch": 0.8932038834951457,
      "grad_norm": 0.7955750823020935,
      "learning_rate": 0.00022373540856031129,
      "loss": 5.6168,
      "step": 230
    },
    {
      "epoch": 0.9320388349514563,
      "grad_norm": 0.8384376764297485,
      "learning_rate": 0.00023346303501945527,
      "loss": 5.5752,
      "step": 240
    },
    {
      "epoch": 0.970873786407767,
      "grad_norm": 1.2045304775238037,
      "learning_rate": 0.00024319066147859923,
      "loss": 5.4204,
      "step": 250
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.545346736907959,
      "eval_runtime": 6.9189,
      "eval_samples_per_second": 3580.345,
      "eval_steps_per_second": 14.02,
      "step": 258
    },
    {
      "epoch": 1.007766990291262,
      "grad_norm": 0.7916207909584045,
      "learning_rate": 0.0002529182879377432,
      "loss": 5.1247,
      "step": 260
    },
    {
      "epoch": 1.0466019417475727,
      "grad_norm": 0.7170044779777527,
      "learning_rate": 0.0002626459143968872,
      "loss": 5.3119,
      "step": 270
    },
    {
      "epoch": 1.0854368932038836,
      "grad_norm": 0.7511245012283325,
      "learning_rate": 0.0002723735408560311,
      "loss": 5.2718,
      "step": 280
    },
    {
      "epoch": 1.1242718446601943,
      "grad_norm": 0.710224986076355,
      "learning_rate": 0.0002821011673151751,
      "loss": 5.1728,
      "step": 290
    },
    {
      "epoch": 1.163106796116505,
      "grad_norm": 0.6872521042823792,
      "learning_rate": 0.0002918287937743191,
      "loss": 5.088,
      "step": 300
    },
    {
      "epoch": 1.2019417475728156,
      "grad_norm": 0.7002337574958801,
      "learning_rate": 0.000301556420233463,
      "loss": 5.0737,
      "step": 310
    },
    {
      "epoch": 1.2407766990291262,
      "grad_norm": 0.6476044654846191,
      "learning_rate": 0.000311284046692607,
      "loss": 5.0274,
      "step": 320
    },
    {
      "epoch": 1.279611650485437,
      "grad_norm": 0.876553475856781,
      "learning_rate": 0.000321011673151751,
      "loss": 4.9175,
      "step": 330
    },
    {
      "epoch": 1.3184466019417476,
      "grad_norm": 0.5848178863525391,
      "learning_rate": 0.00033073929961089494,
      "loss": 4.8141,
      "step": 340
    },
    {
      "epoch": 1.3572815533980582,
      "grad_norm": 0.7244997024536133,
      "learning_rate": 0.00034046692607003895,
      "loss": 4.77,
      "step": 350
    },
    {
      "epoch": 1.396116504854369,
      "grad_norm": 0.6455138325691223,
      "learning_rate": 0.00035019455252918285,
      "loss": 4.6854,
      "step": 360
    },
    {
      "epoch": 1.4349514563106796,
      "grad_norm": 0.6314650774002075,
      "learning_rate": 0.00035992217898832686,
      "loss": 4.6368,
      "step": 370
    },
    {
      "epoch": 1.4737864077669902,
      "grad_norm": 0.7613315582275391,
      "learning_rate": 0.00036964980544747087,
      "loss": 4.5555,
      "step": 380
    },
    {
      "epoch": 1.512621359223301,
      "grad_norm": 0.65726637840271,
      "learning_rate": 0.00037937743190661477,
      "loss": 4.5206,
      "step": 390
    },
    {
      "epoch": 1.5514563106796118,
      "grad_norm": 0.5581323504447937,
      "learning_rate": 0.0003891050583657588,
      "loss": 4.4257,
      "step": 400
    },
    {
      "epoch": 1.5902912621359224,
      "grad_norm": 0.5695076584815979,
      "learning_rate": 0.00039883268482490274,
      "loss": 4.3787,
      "step": 410
    },
    {
      "epoch": 1.629126213592233,
      "grad_norm": 0.4953877031803131,
      "learning_rate": 0.0004085603112840467,
      "loss": 4.3007,
      "step": 420
    },
    {
      "epoch": 1.6679611650485437,
      "grad_norm": 0.5632104873657227,
      "learning_rate": 0.0004182879377431907,
      "loss": 4.1984,
      "step": 430
    },
    {
      "epoch": 1.7067961165048544,
      "grad_norm": 0.48749399185180664,
      "learning_rate": 0.0004280155642023346,
      "loss": 4.163,
      "step": 440
    },
    {
      "epoch": 1.745631067961165,
      "grad_norm": 0.4764925241470337,
      "learning_rate": 0.0004377431906614786,
      "loss": 4.0862,
      "step": 450
    },
    {
      "epoch": 1.7844660194174757,
      "grad_norm": 0.5484539866447449,
      "learning_rate": 0.00044747081712062257,
      "loss": 4.0024,
      "step": 460
    },
    {
      "epoch": 1.8233009708737864,
      "grad_norm": 0.5237118005752563,
      "learning_rate": 0.00045719844357976653,
      "loss": 3.9791,
      "step": 470
    },
    {
      "epoch": 1.862135922330097,
      "grad_norm": 0.46262967586517334,
      "learning_rate": 0.00046692607003891054,
      "loss": 3.8909,
      "step": 480
    },
    {
      "epoch": 1.9009708737864077,
      "grad_norm": 0.48245057463645935,
      "learning_rate": 0.0004766536964980545,
      "loss": 3.8129,
      "step": 490
    },
    {
      "epoch": 1.9398058252427184,
      "grad_norm": 0.4452262222766876,
      "learning_rate": 0.00048638132295719845,
      "loss": 3.758,
      "step": 500
    },
    {
      "epoch": 1.978640776699029,
      "grad_norm": 1.2292401790618896,
      "learning_rate": 0.0004961089494163424,
      "loss": 3.6846,
      "step": 510
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.7236922979354858,
      "eval_runtime": 6.9371,
      "eval_samples_per_second": 3570.921,
      "eval_steps_per_second": 13.983,
      "step": 516
    },
    {
      "epoch": 2.015533980582524,
      "grad_norm": 0.4707290232181549,
      "learning_rate": 0.0004999999828479661,
      "loss": 3.4352,
      "step": 520
    },
    {
      "epoch": 2.0543689320388347,
      "grad_norm": 0.45111921429634094,
      "learning_rate": 0.0004999998780299894,
      "loss": 3.572,
      "step": 530
    },
    {
      "epoch": 2.0932038834951454,
      "grad_norm": 0.7627472877502441,
      "learning_rate": 0.000499999677922984,
      "loss": 3.5237,
      "step": 540
    },
    {
      "epoch": 2.1320388349514565,
      "grad_norm": 0.3814507722854614,
      "learning_rate": 0.0004999993825270258,
      "loss": 3.4602,
      "step": 550
    },
    {
      "epoch": 2.170873786407767,
      "grad_norm": 1.1206095218658447,
      "learning_rate": 0.0004999989918422276,
      "loss": 3.3713,
      "step": 560
    },
    {
      "epoch": 2.209708737864078,
      "grad_norm": 0.46519458293914795,
      "learning_rate": 0.0004999985058687382,
      "loss": 3.325,
      "step": 570
    },
    {
      "epoch": 2.2485436893203885,
      "grad_norm": 0.49011585116386414,
      "learning_rate": 0.0004999979246067428,
      "loss": 3.2919,
      "step": 580
    },
    {
      "epoch": 2.287378640776699,
      "grad_norm": 0.5917046070098877,
      "learning_rate": 0.0004999972480564631,
      "loss": 3.2546,
      "step": 590
    },
    {
      "epoch": 2.32621359223301,
      "grad_norm": 0.38962897658348083,
      "learning_rate": 0.0004999964762181569,
      "loss": 3.1761,
      "step": 600
    },
    {
      "epoch": 2.3650485436893205,
      "grad_norm": 0.5128026008605957,
      "learning_rate": 0.0004999956090921184,
      "loss": 3.1681,
      "step": 610
    },
    {
      "epoch": 2.403883495145631,
      "grad_norm": 0.3328768312931061,
      "learning_rate": 0.000499994646678678,
      "loss": 3.1132,
      "step": 620
    },
    {
      "epoch": 2.442718446601942,
      "grad_norm": 0.4938942790031433,
      "learning_rate": 0.0004999935889782027,
      "loss": 3.0929,
      "step": 630
    },
    {
      "epoch": 2.4815533980582525,
      "grad_norm": 0.3476950526237488,
      "learning_rate": 0.0004999924359910955,
      "loss": 3.0298,
      "step": 640
    },
    {
      "epoch": 2.520388349514563,
      "grad_norm": 0.30725619196891785,
      "learning_rate": 0.000499991187717796,
      "loss": 2.9858,
      "step": 650
    },
    {
      "epoch": 2.559223300970874,
      "grad_norm": 0.2968302369117737,
      "learning_rate": 0.00049998984415878,
      "loss": 2.9206,
      "step": 660
    },
    {
      "epoch": 2.5980582524271845,
      "grad_norm": 0.8592623472213745,
      "learning_rate": 0.0004999884053145595,
      "loss": 2.9405,
      "step": 670
    },
    {
      "epoch": 2.636893203883495,
      "grad_norm": 0.26280447840690613,
      "learning_rate": 0.000499986871185683,
      "loss": 2.8829,
      "step": 680
    },
    {
      "epoch": 2.675728155339806,
      "grad_norm": 0.2901628911495209,
      "learning_rate": 0.0004999852417727351,
      "loss": 2.8567,
      "step": 690
    },
    {
      "epoch": 2.7145631067961165,
      "grad_norm": 0.3616940379142761,
      "learning_rate": 0.000499983517076337,
      "loss": 2.8458,
      "step": 700
    },
    {
      "epoch": 2.753398058252427,
      "grad_norm": 0.4808861017227173,
      "learning_rate": 0.0004999816970971461,
      "loss": 2.7974,
      "step": 710
    },
    {
      "epoch": 2.792233009708738,
      "grad_norm": 0.5153398513793945,
      "learning_rate": 0.0004999797818358559,
      "loss": 2.774,
      "step": 720
    },
    {
      "epoch": 2.8310679611650484,
      "grad_norm": 0.2633265256881714,
      "learning_rate": 0.0004999777712931967,
      "loss": 2.7638,
      "step": 730
    },
    {
      "epoch": 2.869902912621359,
      "grad_norm": 0.33998194336891174,
      "learning_rate": 0.0004999756654699346,
      "loss": 2.7502,
      "step": 740
    },
    {
      "epoch": 2.9087378640776698,
      "grad_norm": 0.2865006923675537,
      "learning_rate": 0.0004999734643668724,
      "loss": 2.7364,
      "step": 750
    },
    {
      "epoch": 2.9475728155339804,
      "grad_norm": 0.3310157358646393,
      "learning_rate": 0.000499971167984849,
      "loss": 2.6874,
      "step": 760
    },
    {
      "epoch": 2.9864077669902915,
      "grad_norm": 0.21939948201179504,
      "learning_rate": 0.0004999687763247397,
      "loss": 2.6753,
      "step": 770
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.2775955200195312,
      "eval_runtime": 6.9237,
      "eval_samples_per_second": 3577.848,
      "eval_steps_per_second": 14.01,
      "step": 774
    },
    {
      "epoch": 3.0233009708737866,
      "grad_norm": 0.27779608964920044,
      "learning_rate": 0.000499966289387456,
      "loss": 2.5301,
      "step": 780
    },
    {
      "epoch": 3.0621359223300972,
      "grad_norm": 0.2748946249485016,
      "learning_rate": 0.0004999637071739459,
      "loss": 2.6317,
      "step": 790
    },
    {
      "epoch": 3.100970873786408,
      "grad_norm": 0.41448748111724854,
      "learning_rate": 0.0004999610296851936,
      "loss": 2.6402,
      "step": 800
    },
    {
      "epoch": 3.1398058252427186,
      "grad_norm": 0.740319013595581,
      "learning_rate": 0.0004999582569222197,
      "loss": 2.622,
      "step": 810
    },
    {
      "epoch": 3.1786407766990292,
      "grad_norm": 0.3437744677066803,
      "learning_rate": 0.000499955388886081,
      "loss": 2.5879,
      "step": 820
    },
    {
      "epoch": 3.21747572815534,
      "grad_norm": 0.2679804861545563,
      "learning_rate": 0.0004999524255778707,
      "loss": 2.5765,
      "step": 830
    },
    {
      "epoch": 3.2563106796116505,
      "grad_norm": 0.23712070286273956,
      "learning_rate": 0.0004999493669987182,
      "loss": 2.5583,
      "step": 840
    },
    {
      "epoch": 3.295145631067961,
      "grad_norm": 0.20625324547290802,
      "learning_rate": 0.0004999462131497894,
      "loss": 2.538,
      "step": 850
    },
    {
      "epoch": 3.333980582524272,
      "grad_norm": 0.2933183014392853,
      "learning_rate": 0.0004999429640322864,
      "loss": 2.5498,
      "step": 860
    },
    {
      "epoch": 3.3728155339805825,
      "grad_norm": 0.27594563364982605,
      "learning_rate": 0.0004999396196474475,
      "loss": 2.5384,
      "step": 870
    },
    {
      "epoch": 3.411650485436893,
      "grad_norm": 0.22254066169261932,
      "learning_rate": 0.0004999361799965476,
      "loss": 2.5257,
      "step": 880
    },
    {
      "epoch": 3.450485436893204,
      "grad_norm": 0.22532565891742706,
      "learning_rate": 0.0004999326450808977,
      "loss": 2.5221,
      "step": 890
    },
    {
      "epoch": 3.4893203883495145,
      "grad_norm": 0.2611618936061859,
      "learning_rate": 0.000499929014901845,
      "loss": 2.4887,
      "step": 900
    },
    {
      "epoch": 3.528155339805825,
      "grad_norm": 0.20921564102172852,
      "learning_rate": 0.0004999252894607734,
      "loss": 2.5008,
      "step": 910
    },
    {
      "epoch": 3.566990291262136,
      "grad_norm": 0.2379002869129181,
      "learning_rate": 0.0004999214687591028,
      "loss": 2.4913,
      "step": 920
    },
    {
      "epoch": 3.6058252427184465,
      "grad_norm": 0.26354748010635376,
      "learning_rate": 0.0004999175527982894,
      "loss": 2.4969,
      "step": 930
    },
    {
      "epoch": 3.644660194174757,
      "grad_norm": 0.21622395515441895,
      "learning_rate": 0.0004999135415798258,
      "loss": 2.4754,
      "step": 940
    },
    {
      "epoch": 3.683495145631068,
      "grad_norm": 0.24298691749572754,
      "learning_rate": 0.000499909435105241,
      "loss": 2.4748,
      "step": 950
    },
    {
      "epoch": 3.7223300970873785,
      "grad_norm": 0.21996697783470154,
      "learning_rate": 0.0004999052333761002,
      "loss": 2.4536,
      "step": 960
    },
    {
      "epoch": 3.761165048543689,
      "grad_norm": 0.1936461180448532,
      "learning_rate": 0.0004999009363940047,
      "loss": 2.4337,
      "step": 970
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.22305279970169067,
      "learning_rate": 0.0004998965441605927,
      "loss": 2.4482,
      "step": 980
    },
    {
      "epoch": 3.8388349514563105,
      "grad_norm": 0.24770204722881317,
      "learning_rate": 0.000499892056677538,
      "loss": 2.4175,
      "step": 990
    },
    {
      "epoch": 3.877669902912621,
      "grad_norm": 0.18763235211372375,
      "learning_rate": 0.0004998874739465511,
      "loss": 2.4227,
      "step": 1000
    },
    {
      "epoch": 3.916504854368932,
      "grad_norm": 0.26417723298072815,
      "learning_rate": 0.0004998827959693789,
      "loss": 2.4208,
      "step": 1010
    },
    {
      "epoch": 3.9553398058252425,
      "grad_norm": 0.19035488367080688,
      "learning_rate": 0.0004998780227478043,
      "loss": 2.407,
      "step": 1020
    },
    {
      "epoch": 3.994174757281553,
      "grad_norm": 0.1999357044696808,
      "learning_rate": 0.0004998731542836467,
      "loss": 2.391,
      "step": 1030
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.158560037612915,
      "eval_runtime": 6.9499,
      "eval_samples_per_second": 3564.384,
      "eval_steps_per_second": 13.957,
      "step": 1032
    },
    {
      "epoch": 4.031067961165048,
      "grad_norm": 0.23499494791030884,
      "learning_rate": 0.0004998681905787616,
      "loss": 2.2746,
      "step": 1040
    },
    {
      "epoch": 4.069902912621359,
      "grad_norm": 0.1816217005252838,
      "learning_rate": 0.0004998631316350412,
      "loss": 2.403,
      "step": 1050
    },
    {
      "epoch": 4.1087378640776695,
      "grad_norm": 0.18883278965950012,
      "learning_rate": 0.0004998579774544136,
      "loss": 2.3701,
      "step": 1060
    },
    {
      "epoch": 4.14757281553398,
      "grad_norm": 0.23799976706504822,
      "learning_rate": 0.0004998527280388433,
      "loss": 2.3747,
      "step": 1070
    },
    {
      "epoch": 4.186407766990291,
      "grad_norm": 0.18932202458381653,
      "learning_rate": 0.0004998473833903312,
      "loss": 2.4037,
      "step": 1080
    },
    {
      "epoch": 4.2252427184466015,
      "grad_norm": 0.23248448967933655,
      "learning_rate": 0.0004998419435109145,
      "loss": 2.3775,
      "step": 1090
    },
    {
      "epoch": 4.264077669902913,
      "grad_norm": 0.27325665950775146,
      "learning_rate": 0.0004998364084026666,
      "loss": 2.3708,
      "step": 1100
    },
    {
      "epoch": 4.302912621359224,
      "grad_norm": 0.24621057510375977,
      "learning_rate": 0.0004998307780676972,
      "loss": 2.3655,
      "step": 1110
    },
    {
      "epoch": 4.341747572815534,
      "grad_norm": 0.22695961594581604,
      "learning_rate": 0.0004998250525081524,
      "loss": 2.3672,
      "step": 1120
    },
    {
      "epoch": 4.380582524271845,
      "grad_norm": 0.19500583410263062,
      "learning_rate": 0.0004998192317262146,
      "loss": 2.351,
      "step": 1130
    },
    {
      "epoch": 4.419417475728156,
      "grad_norm": 0.3398340046405792,
      "learning_rate": 0.0004998133157241022,
      "loss": 2.3562,
      "step": 1140
    },
    {
      "epoch": 4.458252427184466,
      "grad_norm": 0.18117482960224152,
      "learning_rate": 0.0004998073045040704,
      "loss": 2.3765,
      "step": 1150
    },
    {
      "epoch": 4.497087378640777,
      "grad_norm": 0.26853442192077637,
      "learning_rate": 0.0004998011980684102,
      "loss": 2.3545,
      "step": 1160
    },
    {
      "epoch": 4.535922330097088,
      "grad_norm": 0.22445012629032135,
      "learning_rate": 0.0004997949964194492,
      "loss": 2.3269,
      "step": 1170
    },
    {
      "epoch": 4.574757281553398,
      "grad_norm": 0.24578048288822174,
      "learning_rate": 0.0004997886995595512,
      "loss": 2.3613,
      "step": 1180
    },
    {
      "epoch": 4.613592233009709,
      "grad_norm": 0.2124900072813034,
      "learning_rate": 0.0004997823074911163,
      "loss": 2.3529,
      "step": 1190
    },
    {
      "epoch": 4.65242718446602,
      "grad_norm": 0.4845227301120758,
      "learning_rate": 0.0004997758202165808,
      "loss": 2.3505,
      "step": 1200
    },
    {
      "epoch": 4.69126213592233,
      "grad_norm": 0.4126991629600525,
      "learning_rate": 0.0004997692377384173,
      "loss": 2.3484,
      "step": 1210
    },
    {
      "epoch": 4.730097087378641,
      "grad_norm": 0.20704156160354614,
      "learning_rate": 0.000499762560059135,
      "loss": 2.3427,
      "step": 1220
    },
    {
      "epoch": 4.768932038834952,
      "grad_norm": 0.20315681397914886,
      "learning_rate": 0.000499755787181279,
      "loss": 2.34,
      "step": 1230
    },
    {
      "epoch": 4.807766990291262,
      "grad_norm": 0.19037316739559174,
      "learning_rate": 0.0004997489191074307,
      "loss": 2.3163,
      "step": 1240
    },
    {
      "epoch": 4.846601941747573,
      "grad_norm": 0.19169914722442627,
      "learning_rate": 0.0004997419558402083,
      "loss": 2.3354,
      "step": 1250
    },
    {
      "epoch": 4.885436893203884,
      "grad_norm": 0.19753271341323853,
      "learning_rate": 0.0004997348973822654,
      "loss": 2.3379,
      "step": 1260
    },
    {
      "epoch": 4.924271844660194,
      "grad_norm": 0.19369448721408844,
      "learning_rate": 0.0004997277437362927,
      "loss": 2.3078,
      "step": 1270
    },
    {
      "epoch": 4.963106796116505,
      "grad_norm": 0.22033780813217163,
      "learning_rate": 0.0004997204949050166,
      "loss": 2.3207,
      "step": 1280
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.15286628901958466,
      "learning_rate": 0.0004997131508912004,
      "loss": 2.1926,
      "step": 1290
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.1150766611099243,
      "eval_runtime": 7.1692,
      "eval_samples_per_second": 3455.351,
      "eval_steps_per_second": 13.53,
      "step": 1290
    },
    {
      "epoch": 5.038834951456311,
      "grad_norm": 0.21984049677848816,
      "learning_rate": 0.0004997057116976431,
      "loss": 2.313,
      "step": 1300
    },
    {
      "epoch": 5.077669902912621,
      "grad_norm": 0.2332834154367447,
      "learning_rate": 0.0004996981773271802,
      "loss": 2.3092,
      "step": 1310
    },
    {
      "epoch": 5.116504854368932,
      "grad_norm": 0.191253662109375,
      "learning_rate": 0.0004996905477826834,
      "loss": 2.2983,
      "step": 1320
    },
    {
      "epoch": 5.155339805825243,
      "grad_norm": 0.23155343532562256,
      "learning_rate": 0.0004996828230670609,
      "loss": 2.3005,
      "step": 1330
    },
    {
      "epoch": 5.194174757281553,
      "grad_norm": 0.20037619769573212,
      "learning_rate": 0.000499675003183257,
      "loss": 2.2939,
      "step": 1340
    },
    {
      "epoch": 5.233009708737864,
      "grad_norm": 0.23486430943012238,
      "learning_rate": 0.0004996670881342523,
      "loss": 2.2933,
      "step": 1350
    },
    {
      "epoch": 5.271844660194175,
      "grad_norm": 0.21371030807495117,
      "learning_rate": 0.0004996590779230636,
      "loss": 2.2861,
      "step": 1360
    },
    {
      "epoch": 5.310679611650485,
      "grad_norm": 0.19847188889980316,
      "learning_rate": 0.000499650972552744,
      "loss": 2.2928,
      "step": 1370
    },
    {
      "epoch": 5.349514563106796,
      "grad_norm": 0.2040867805480957,
      "learning_rate": 0.0004996427720263829,
      "loss": 2.2955,
      "step": 1380
    },
    {
      "epoch": 5.388349514563107,
      "grad_norm": 0.17768758535385132,
      "learning_rate": 0.0004996344763471063,
      "loss": 2.2832,
      "step": 1390
    },
    {
      "epoch": 5.427184466019417,
      "grad_norm": 0.2845875024795532,
      "learning_rate": 0.0004996260855180758,
      "loss": 2.3067,
      "step": 1400
    },
    {
      "epoch": 5.466019417475728,
      "grad_norm": 0.22697985172271729,
      "learning_rate": 0.0004996175995424896,
      "loss": 2.2791,
      "step": 1410
    },
    {
      "epoch": 5.504854368932039,
      "grad_norm": 0.27160021662712097,
      "learning_rate": 0.0004996090184235826,
      "loss": 2.2738,
      "step": 1420
    },
    {
      "epoch": 5.543689320388349,
      "grad_norm": 0.20163193345069885,
      "learning_rate": 0.000499600342164625,
      "loss": 2.2842,
      "step": 1430
    },
    {
      "epoch": 5.58252427184466,
      "grad_norm": 0.29950758814811707,
      "learning_rate": 0.0004995915707689243,
      "loss": 2.2862,
      "step": 1440
    },
    {
      "epoch": 5.621359223300971,
      "grad_norm": 0.19526022672653198,
      "learning_rate": 0.0004995827042398233,
      "loss": 2.3039,
      "step": 1450
    },
    {
      "epoch": 5.660194174757281,
      "grad_norm": 0.17336207628250122,
      "learning_rate": 0.000499573742580702,
      "loss": 2.2682,
      "step": 1460
    },
    {
      "epoch": 5.699029126213592,
      "grad_norm": 0.21877619624137878,
      "learning_rate": 0.0004995646857949759,
      "loss": 2.2838,
      "step": 1470
    },
    {
      "epoch": 5.737864077669903,
      "grad_norm": 0.18070268630981445,
      "learning_rate": 0.0004995555338860971,
      "loss": 2.2795,
      "step": 1480
    },
    {
      "epoch": 5.776699029126213,
      "grad_norm": 0.21707934141159058,
      "learning_rate": 0.000499546286857554,
      "loss": 2.2699,
      "step": 1490
    },
    {
      "epoch": 5.815533980582524,
      "grad_norm": 0.19718283414840698,
      "learning_rate": 0.000499536944712871,
      "loss": 2.264,
      "step": 1500
    },
    {
      "epoch": 5.854368932038835,
      "grad_norm": 0.2022370994091034,
      "learning_rate": 0.0004995275074556092,
      "loss": 2.2673,
      "step": 1510
    },
    {
      "epoch": 5.893203883495145,
      "grad_norm": 0.20279337465763092,
      "learning_rate": 0.0004995179750893653,
      "loss": 2.2623,
      "step": 1520
    },
    {
      "epoch": 5.932038834951456,
      "grad_norm": 0.2068249136209488,
      "learning_rate": 0.0004995083476177729,
      "loss": 2.2676,
      "step": 1530
    },
    {
      "epoch": 5.970873786407767,
      "grad_norm": 0.29161033034324646,
      "learning_rate": 0.0004994986250445014,
      "loss": 2.2864,
      "step": 1540
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.093702793121338,
      "eval_runtime": 6.9178,
      "eval_samples_per_second": 3580.91,
      "eval_steps_per_second": 14.022,
      "step": 1548
    },
    {
      "epoch": 6.0077669902912625,
      "grad_norm": 0.1838093250989914,
      "learning_rate": 0.0004994888073732568,
      "loss": 2.1564,
      "step": 1550
    },
    {
      "epoch": 6.046601941747573,
      "grad_norm": 0.22661751508712769,
      "learning_rate": 0.000499478894607781,
      "loss": 2.2457,
      "step": 1560
    },
    {
      "epoch": 6.085436893203884,
      "grad_norm": 0.3302161395549774,
      "learning_rate": 0.0004994688867518523,
      "loss": 2.265,
      "step": 1570
    },
    {
      "epoch": 6.1242718446601945,
      "grad_norm": 0.19920392334461212,
      "learning_rate": 0.0004994587838092854,
      "loss": 2.2528,
      "step": 1580
    },
    {
      "epoch": 6.163106796116505,
      "grad_norm": 0.19725681841373444,
      "learning_rate": 0.0004994485857839311,
      "loss": 2.265,
      "step": 1590
    },
    {
      "epoch": 6.201941747572816,
      "grad_norm": 0.19433076679706573,
      "learning_rate": 0.0004994382926796763,
      "loss": 2.2494,
      "step": 1600
    },
    {
      "epoch": 6.2407766990291265,
      "grad_norm": 0.17256198823451996,
      "learning_rate": 0.0004994279045004445,
      "loss": 2.2515,
      "step": 1610
    },
    {
      "epoch": 6.279611650485437,
      "grad_norm": 0.17233765125274658,
      "learning_rate": 0.0004994174212501949,
      "loss": 2.2501,
      "step": 1620
    },
    {
      "epoch": 6.318446601941748,
      "grad_norm": 0.27210885286331177,
      "learning_rate": 0.0004994068429329236,
      "loss": 2.2637,
      "step": 1630
    },
    {
      "epoch": 6.3572815533980584,
      "grad_norm": 0.17927439510822296,
      "learning_rate": 0.0004993961695526623,
      "loss": 2.2592,
      "step": 1640
    },
    {
      "epoch": 6.396116504854369,
      "grad_norm": 0.19801566004753113,
      "learning_rate": 0.0004993854011134794,
      "loss": 2.2404,
      "step": 1650
    },
    {
      "epoch": 6.43495145631068,
      "grad_norm": 0.22052569687366486,
      "learning_rate": 0.0004993745376194792,
      "loss": 2.2459,
      "step": 1660
    },
    {
      "epoch": 6.47378640776699,
      "grad_norm": 0.17380939424037933,
      "learning_rate": 0.0004993635790748027,
      "loss": 2.2365,
      "step": 1670
    },
    {
      "epoch": 6.512621359223301,
      "grad_norm": 0.18235205113887787,
      "learning_rate": 0.0004993525254836266,
      "loss": 2.2484,
      "step": 1680
    },
    {
      "epoch": 6.551456310679612,
      "grad_norm": 0.22657278180122375,
      "learning_rate": 0.000499341376850164,
      "loss": 2.2287,
      "step": 1690
    },
    {
      "epoch": 6.590291262135922,
      "grad_norm": 0.19148309528827667,
      "learning_rate": 0.0004993301331786643,
      "loss": 2.2542,
      "step": 1700
    },
    {
      "epoch": 6.629126213592233,
      "grad_norm": 0.1701970249414444,
      "learning_rate": 0.0004993187944734131,
      "loss": 2.2542,
      "step": 1710
    },
    {
      "epoch": 6.667961165048544,
      "grad_norm": 0.1771145612001419,
      "learning_rate": 0.0004993073607387324,
      "loss": 2.2407,
      "step": 1720
    },
    {
      "epoch": 6.706796116504854,
      "grad_norm": 0.16886058449745178,
      "learning_rate": 0.00049929583197898,
      "loss": 2.2496,
      "step": 1730
    },
    {
      "epoch": 6.745631067961165,
      "grad_norm": 0.23897291719913483,
      "learning_rate": 0.0004992842081985502,
      "loss": 2.2455,
      "step": 1740
    },
    {
      "epoch": 6.784466019417476,
      "grad_norm": 0.16830311715602875,
      "learning_rate": 0.0004992724894018737,
      "loss": 2.2318,
      "step": 1750
    },
    {
      "epoch": 6.823300970873786,
      "grad_norm": 0.18650254607200623,
      "learning_rate": 0.0004992606755934169,
      "loss": 2.2465,
      "step": 1760
    },
    {
      "epoch": 6.862135922330097,
      "grad_norm": 0.1754639744758606,
      "learning_rate": 0.0004992487667776828,
      "loss": 2.2305,
      "step": 1770
    },
    {
      "epoch": 6.900970873786408,
      "grad_norm": 0.23094117641448975,
      "learning_rate": 0.0004992367629592106,
      "loss": 2.245,
      "step": 1780
    },
    {
      "epoch": 6.939805825242718,
      "grad_norm": 0.24005372822284698,
      "learning_rate": 0.0004992246641425756,
      "loss": 2.2386,
      "step": 1790
    },
    {
      "epoch": 6.978640776699029,
      "grad_norm": 0.2159932553768158,
      "learning_rate": 0.0004992124703323893,
      "loss": 2.2285,
      "step": 1800
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.0783419609069824,
      "eval_runtime": 6.9344,
      "eval_samples_per_second": 3572.352,
      "eval_steps_per_second": 13.988,
      "step": 1806
    },
    {
      "epoch": 7.015533980582524,
      "grad_norm": 0.19407473504543304,
      "learning_rate": 0.0004992001815332995,
      "loss": 2.1258,
      "step": 1810
    },
    {
      "epoch": 7.054368932038835,
      "grad_norm": 0.19930611550807953,
      "learning_rate": 0.0004991877977499901,
      "loss": 2.2252,
      "step": 1820
    },
    {
      "epoch": 7.093203883495145,
      "grad_norm": 0.23604096472263336,
      "learning_rate": 0.0004991753189871813,
      "loss": 2.24,
      "step": 1830
    },
    {
      "epoch": 7.132038834951456,
      "grad_norm": 0.19908225536346436,
      "learning_rate": 0.0004991627452496294,
      "loss": 2.2138,
      "step": 1840
    },
    {
      "epoch": 7.170873786407767,
      "grad_norm": 0.19823375344276428,
      "learning_rate": 0.0004991500765421271,
      "loss": 2.2231,
      "step": 1850
    },
    {
      "epoch": 7.209708737864077,
      "grad_norm": 0.31578150391578674,
      "learning_rate": 0.000499137312869503,
      "loss": 2.2375,
      "step": 1860
    },
    {
      "epoch": 7.248543689320388,
      "grad_norm": 0.17399360239505768,
      "learning_rate": 0.000499124454236622,
      "loss": 2.2209,
      "step": 1870
    },
    {
      "epoch": 7.287378640776699,
      "grad_norm": 0.17626337707042694,
      "learning_rate": 0.0004991115006483855,
      "loss": 2.2218,
      "step": 1880
    },
    {
      "epoch": 7.326213592233009,
      "grad_norm": 0.2551068365573883,
      "learning_rate": 0.0004990984521097306,
      "loss": 2.2246,
      "step": 1890
    },
    {
      "epoch": 7.36504854368932,
      "grad_norm": 0.21429990231990814,
      "learning_rate": 0.0004990853086256309,
      "loss": 2.2309,
      "step": 1900
    },
    {
      "epoch": 7.403883495145631,
      "grad_norm": 0.188127338886261,
      "learning_rate": 0.0004990720702010964,
      "loss": 2.218,
      "step": 1910
    },
    {
      "epoch": 7.442718446601941,
      "grad_norm": 0.20563746988773346,
      "learning_rate": 0.0004990587368411725,
      "loss": 2.2149,
      "step": 1920
    },
    {
      "epoch": 7.481553398058252,
      "grad_norm": 0.18629781901836395,
      "learning_rate": 0.0004990453085509417,
      "loss": 2.2189,
      "step": 1930
    },
    {
      "epoch": 7.520388349514564,
      "grad_norm": 0.17678090929985046,
      "learning_rate": 0.000499031785335522,
      "loss": 2.2083,
      "step": 1940
    },
    {
      "epoch": 7.559223300970874,
      "grad_norm": 0.18539901077747345,
      "learning_rate": 0.0004990181672000682,
      "loss": 2.2266,
      "step": 1950
    },
    {
      "epoch": 7.598058252427185,
      "grad_norm": 0.18280282616615295,
      "learning_rate": 0.0004990044541497706,
      "loss": 2.2125,
      "step": 1960
    },
    {
      "epoch": 7.636893203883496,
      "grad_norm": 0.24820517003536224,
      "learning_rate": 0.0004989906461898562,
      "loss": 2.2137,
      "step": 1970
    },
    {
      "epoch": 7.675728155339806,
      "grad_norm": 0.17805877327919006,
      "learning_rate": 0.0004989767433255879,
      "loss": 2.2291,
      "step": 1980
    },
    {
      "epoch": 7.714563106796117,
      "grad_norm": 0.19860132038593292,
      "learning_rate": 0.0004989627455622649,
      "loss": 2.2221,
      "step": 1990
    },
    {
      "epoch": 7.753398058252428,
      "grad_norm": 0.17755313217639923,
      "learning_rate": 0.0004989486529052225,
      "loss": 2.2478,
      "step": 2000
    },
    {
      "epoch": 7.792233009708738,
      "grad_norm": 0.18726293742656708,
      "learning_rate": 0.0004989344653598323,
      "loss": 2.2243,
      "step": 2010
    },
    {
      "epoch": 7.831067961165049,
      "grad_norm": 0.1878914088010788,
      "learning_rate": 0.000498920182931502,
      "loss": 2.2096,
      "step": 2020
    },
    {
      "epoch": 7.8699029126213595,
      "grad_norm": 0.29757192730903625,
      "learning_rate": 0.0004989058056256752,
      "loss": 2.2037,
      "step": 2030
    },
    {
      "epoch": 7.90873786407767,
      "grad_norm": 0.21425601840019226,
      "learning_rate": 0.0004988913334478322,
      "loss": 2.2111,
      "step": 2040
    },
    {
      "epoch": 7.947572815533981,
      "grad_norm": 0.20132219791412354,
      "learning_rate": 0.0004988767664034889,
      "loss": 2.2152,
      "step": 2050
    },
    {
      "epoch": 7.9864077669902915,
      "grad_norm": 0.21189522743225098,
      "learning_rate": 0.0004988621044981978,
      "loss": 2.2169,
      "step": 2060
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.069238305091858,
      "eval_runtime": 6.9528,
      "eval_samples_per_second": 3562.896,
      "eval_steps_per_second": 13.951,
      "step": 2064
    },
    {
      "epoch": 8.023300970873786,
      "grad_norm": 0.19779933989048004,
      "learning_rate": 0.0004988473477375474,
      "loss": 2.1163,
      "step": 2070
    },
    {
      "epoch": 8.062135922330096,
      "grad_norm": 0.2127455174922943,
      "learning_rate": 0.0004988324961271621,
      "loss": 2.2022,
      "step": 2080
    },
    {
      "epoch": 8.100970873786407,
      "grad_norm": 0.22150394320487976,
      "learning_rate": 0.0004988175496727029,
      "loss": 2.2062,
      "step": 2090
    },
    {
      "epoch": 8.139805825242718,
      "grad_norm": 0.30104658007621765,
      "learning_rate": 0.0004988025083798666,
      "loss": 2.1997,
      "step": 2100
    },
    {
      "epoch": 8.178640776699028,
      "grad_norm": 0.21065081655979156,
      "learning_rate": 0.0004987873722543864,
      "loss": 2.2087,
      "step": 2110
    },
    {
      "epoch": 8.217475728155339,
      "grad_norm": 0.23902305960655212,
      "learning_rate": 0.0004987721413020316,
      "loss": 2.192,
      "step": 2120
    },
    {
      "epoch": 8.25631067961165,
      "grad_norm": 0.3252961039543152,
      "learning_rate": 0.0004987568155286071,
      "loss": 2.2135,
      "step": 2130
    },
    {
      "epoch": 8.29514563106796,
      "grad_norm": 0.18735411763191223,
      "learning_rate": 0.0004987413949399551,
      "loss": 2.2173,
      "step": 2140
    },
    {
      "epoch": 8.333980582524271,
      "grad_norm": 0.1967502385377884,
      "learning_rate": 0.0004987258795419528,
      "loss": 2.219,
      "step": 2150
    },
    {
      "epoch": 8.372815533980582,
      "grad_norm": 0.2064635008573532,
      "learning_rate": 0.0004987102693405143,
      "loss": 2.1917,
      "step": 2160
    },
    {
      "epoch": 8.411650485436894,
      "grad_norm": 0.24049592018127441,
      "learning_rate": 0.0004986945643415891,
      "loss": 2.1977,
      "step": 2170
    },
    {
      "epoch": 8.450485436893203,
      "grad_norm": 0.2033541351556778,
      "learning_rate": 0.0004986787645511636,
      "loss": 2.2046,
      "step": 2180
    },
    {
      "epoch": 8.489320388349515,
      "grad_norm": 0.16175228357315063,
      "learning_rate": 0.0004986628699752599,
      "loss": 2.2164,
      "step": 2190
    },
    {
      "epoch": 8.528155339805826,
      "grad_norm": 0.17979954183101654,
      "learning_rate": 0.0004986468806199363,
      "loss": 2.2112,
      "step": 2200
    },
    {
      "epoch": 8.566990291262137,
      "grad_norm": 0.2015102505683899,
      "learning_rate": 0.0004986307964912872,
      "loss": 2.2162,
      "step": 2210
    },
    {
      "epoch": 8.605825242718447,
      "grad_norm": 0.19575494527816772,
      "learning_rate": 0.0004986146175954432,
      "loss": 2.2135,
      "step": 2220
    },
    {
      "epoch": 8.644660194174758,
      "grad_norm": 0.19177740812301636,
      "learning_rate": 0.0004985983439385711,
      "loss": 2.218,
      "step": 2230
    },
    {
      "epoch": 8.683495145631069,
      "grad_norm": 0.18777519464492798,
      "learning_rate": 0.0004985819755268736,
      "loss": 2.2062,
      "step": 2240
    },
    {
      "epoch": 8.72233009708738,
      "grad_norm": 0.22156576812267303,
      "learning_rate": 0.0004985655123665897,
      "loss": 2.2006,
      "step": 2250
    },
    {
      "epoch": 8.76116504854369,
      "grad_norm": 0.21474991738796234,
      "learning_rate": 0.0004985489544639943,
      "loss": 2.2011,
      "step": 2260
    },
    {
      "epoch": 8.8,
      "grad_norm": 0.18888333439826965,
      "learning_rate": 0.0004985323018253985,
      "loss": 2.1879,
      "step": 2270
    },
    {
      "epoch": 8.838834951456311,
      "grad_norm": 0.1707337200641632,
      "learning_rate": 0.0004985155544571499,
      "loss": 2.218,
      "step": 2280
    },
    {
      "epoch": 8.877669902912622,
      "grad_norm": 0.18809552490711212,
      "learning_rate": 0.0004984987123656315,
      "loss": 2.1927,
      "step": 2290
    },
    {
      "epoch": 8.916504854368933,
      "grad_norm": 0.17608477175235748,
      "learning_rate": 0.000498481775557263,
      "loss": 2.2024,
      "step": 2300
    },
    {
      "epoch": 8.955339805825243,
      "grad_norm": 0.1652604639530182,
      "learning_rate": 0.0004984647440384999,
      "loss": 2.1839,
      "step": 2310
    },
    {
      "epoch": 8.994174757281554,
      "grad_norm": 0.1839730590581894,
      "learning_rate": 0.0004984476178158338,
      "loss": 2.2006,
      "step": 2320
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.0644381046295166,
      "eval_runtime": 6.952,
      "eval_samples_per_second": 3563.266,
      "eval_steps_per_second": 13.953,
      "step": 2322
    },
    {
      "epoch": 9.031067961165048,
      "grad_norm": 0.19441962242126465,
      "learning_rate": 0.0004984303968957925,
      "loss": 2.0809,
      "step": 2330
    },
    {
      "epoch": 9.069902912621359,
      "grad_norm": 0.16746608912944794,
      "learning_rate": 0.00049841308128494,
      "loss": 2.1879,
      "step": 2340
    },
    {
      "epoch": 9.10873786407767,
      "grad_norm": 0.19775663316249847,
      "learning_rate": 0.0004983956709898761,
      "loss": 2.2052,
      "step": 2350
    },
    {
      "epoch": 9.14757281553398,
      "grad_norm": 0.18985804915428162,
      "learning_rate": 0.0004983781660172368,
      "loss": 2.2071,
      "step": 2360
    },
    {
      "epoch": 9.18640776699029,
      "grad_norm": 0.2049446702003479,
      "learning_rate": 0.0004983605663736945,
      "loss": 2.2011,
      "step": 2370
    },
    {
      "epoch": 9.225242718446601,
      "grad_norm": 0.19753454625606537,
      "learning_rate": 0.000498342872065957,
      "loss": 2.2011,
      "step": 2380
    },
    {
      "epoch": 9.264077669902912,
      "grad_norm": 0.1905965358018875,
      "learning_rate": 0.000498325083100769,
      "loss": 2.1815,
      "step": 2390
    },
    {
      "epoch": 9.302912621359223,
      "grad_norm": 0.15282848477363586,
      "learning_rate": 0.0004983071994849106,
      "loss": 2.1907,
      "step": 2400
    },
    {
      "epoch": 9.341747572815533,
      "grad_norm": 0.1956421583890915,
      "learning_rate": 0.0004982892212251984,
      "loss": 2.2052,
      "step": 2410
    },
    {
      "epoch": 9.380582524271844,
      "grad_norm": 0.1935318410396576,
      "learning_rate": 0.0004982711483284849,
      "loss": 2.1974,
      "step": 2420
    },
    {
      "epoch": 9.419417475728155,
      "grad_norm": 0.1935097724199295,
      "learning_rate": 0.0004982529808016587,
      "loss": 2.1822,
      "step": 2430
    },
    {
      "epoch": 9.458252427184465,
      "grad_norm": 0.20671872794628143,
      "learning_rate": 0.0004982347186516443,
      "loss": 2.2025,
      "step": 2440
    },
    {
      "epoch": 9.497087378640776,
      "grad_norm": 0.17240074276924133,
      "learning_rate": 0.0004982163618854028,
      "loss": 2.173,
      "step": 2450
    },
    {
      "epoch": 9.535922330097087,
      "grad_norm": 0.19593343138694763,
      "learning_rate": 0.0004981979105099307,
      "loss": 2.1879,
      "step": 2460
    },
    {
      "epoch": 9.574757281553397,
      "grad_norm": 0.1936543732881546,
      "learning_rate": 0.0004981793645322609,
      "loss": 2.2008,
      "step": 2470
    },
    {
      "epoch": 9.613592233009708,
      "grad_norm": 0.19217535853385925,
      "learning_rate": 0.0004981607239594625,
      "loss": 2.1825,
      "step": 2480
    },
    {
      "epoch": 9.652427184466019,
      "grad_norm": 0.18500526249408722,
      "learning_rate": 0.0004981419887986401,
      "loss": 2.1828,
      "step": 2490
    },
    {
      "epoch": 9.69126213592233,
      "grad_norm": 0.17661139369010925,
      "learning_rate": 0.0004981231590569351,
      "loss": 2.1836,
      "step": 2500
    },
    {
      "epoch": 9.73009708737864,
      "grad_norm": 0.1751716434955597,
      "learning_rate": 0.0004981042347415244,
      "loss": 2.1759,
      "step": 2510
    },
    {
      "epoch": 9.76893203883495,
      "grad_norm": 0.1827528476715088,
      "learning_rate": 0.0004980852158596211,
      "loss": 2.1754,
      "step": 2520
    },
    {
      "epoch": 9.807766990291261,
      "grad_norm": 0.17899951338768005,
      "learning_rate": 0.0004980661024184746,
      "loss": 2.1975,
      "step": 2530
    },
    {
      "epoch": 9.846601941747572,
      "grad_norm": 0.19071166217327118,
      "learning_rate": 0.0004980468944253696,
      "loss": 2.1982,
      "step": 2540
    },
    {
      "epoch": 9.885436893203883,
      "grad_norm": 0.20194441080093384,
      "learning_rate": 0.000498027591887628,
      "loss": 2.1957,
      "step": 2550
    },
    {
      "epoch": 9.924271844660193,
      "grad_norm": 0.18973858654499054,
      "learning_rate": 0.0004980081948126066,
      "loss": 2.1841,
      "step": 2560
    },
    {
      "epoch": 9.963106796116504,
      "grad_norm": 0.2012568861246109,
      "learning_rate": 0.0004979887032076989,
      "loss": 2.1819,
      "step": 2570
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.14467033743858337,
      "learning_rate": 0.0004979691170803342,
      "loss": 2.1116,
      "step": 2580
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.0576813220977783,
      "eval_runtime": 7.1279,
      "eval_samples_per_second": 3475.379,
      "eval_steps_per_second": 13.609,
      "step": 2580
    },
    {
      "epoch": 10.03883495145631,
      "grad_norm": 0.19812354445457458,
      "learning_rate": 0.0004979494364379779,
      "loss": 2.183,
      "step": 2590
    },
    {
      "epoch": 10.077669902912621,
      "grad_norm": 0.17989011108875275,
      "learning_rate": 0.0004979296612881313,
      "loss": 2.1668,
      "step": 2600
    },
    {
      "epoch": 10.116504854368932,
      "grad_norm": 0.1886180341243744,
      "learning_rate": 0.0004979097916383321,
      "loss": 2.1753,
      "step": 2610
    },
    {
      "epoch": 10.155339805825243,
      "grad_norm": 0.2497945874929428,
      "learning_rate": 0.0004978898274961534,
      "loss": 2.1913,
      "step": 2620
    },
    {
      "epoch": 10.194174757281553,
      "grad_norm": 0.1802740842103958,
      "learning_rate": 0.000497869768869205,
      "loss": 2.1874,
      "step": 2630
    },
    {
      "epoch": 10.233009708737864,
      "grad_norm": 0.2076938897371292,
      "learning_rate": 0.0004978496157651321,
      "loss": 2.1966,
      "step": 2640
    },
    {
      "epoch": 10.271844660194175,
      "grad_norm": 0.2801939845085144,
      "learning_rate": 0.0004978293681916163,
      "loss": 2.1788,
      "step": 2650
    },
    {
      "epoch": 10.310679611650485,
      "grad_norm": 0.18247587978839874,
      "learning_rate": 0.000497809026156375,
      "loss": 2.1746,
      "step": 2660
    },
    {
      "epoch": 10.349514563106796,
      "grad_norm": 0.18184857070446014,
      "learning_rate": 0.0004977885896671618,
      "loss": 2.1753,
      "step": 2670
    },
    {
      "epoch": 10.388349514563107,
      "grad_norm": 0.17715904116630554,
      "learning_rate": 0.0004977680587317661,
      "loss": 2.1819,
      "step": 2680
    },
    {
      "epoch": 10.427184466019417,
      "grad_norm": 0.19856512546539307,
      "learning_rate": 0.0004977474333580135,
      "loss": 2.1867,
      "step": 2690
    },
    {
      "epoch": 10.466019417475728,
      "grad_norm": 0.1948765218257904,
      "learning_rate": 0.0004977267135537655,
      "loss": 2.1769,
      "step": 2700
    },
    {
      "epoch": 10.504854368932039,
      "grad_norm": 0.1779412478208542,
      "learning_rate": 0.0004977058993269196,
      "loss": 2.1762,
      "step": 2710
    },
    {
      "epoch": 10.54368932038835,
      "grad_norm": 0.20065797865390778,
      "learning_rate": 0.000497684990685409,
      "loss": 2.1882,
      "step": 2720
    },
    {
      "epoch": 10.58252427184466,
      "grad_norm": 0.17634181678295135,
      "learning_rate": 0.0004976639876372034,
      "loss": 2.1728,
      "step": 2730
    },
    {
      "epoch": 10.62135922330097,
      "grad_norm": 1.2544528245925903,
      "learning_rate": 0.0004976428901903084,
      "loss": 2.1744,
      "step": 2740
    },
    {
      "epoch": 10.660194174757281,
      "grad_norm": 0.257999986410141,
      "learning_rate": 0.000497621698352765,
      "loss": 2.1922,
      "step": 2750
    },
    {
      "epoch": 10.699029126213592,
      "grad_norm": 0.18930740654468536,
      "learning_rate": 0.000497600412132651,
      "loss": 2.1613,
      "step": 2760
    },
    {
      "epoch": 10.737864077669903,
      "grad_norm": 0.2495921105146408,
      "learning_rate": 0.0004975790315380795,
      "loss": 2.1923,
      "step": 2770
    },
    {
      "epoch": 10.776699029126213,
      "grad_norm": 0.19448503851890564,
      "learning_rate": 0.0004975575565772,
      "loss": 2.182,
      "step": 2780
    },
    {
      "epoch": 10.815533980582524,
      "grad_norm": 0.2319476157426834,
      "learning_rate": 0.0004975359872581978,
      "loss": 2.1848,
      "step": 2790
    },
    {
      "epoch": 10.854368932038835,
      "grad_norm": 0.2222367376089096,
      "learning_rate": 0.0004975143235892941,
      "loss": 2.1896,
      "step": 2800
    },
    {
      "epoch": 10.893203883495145,
      "grad_norm": 0.2180439531803131,
      "learning_rate": 0.0004974925655787463,
      "loss": 2.1845,
      "step": 2810
    },
    {
      "epoch": 10.932038834951456,
      "grad_norm": 0.18322497606277466,
      "learning_rate": 0.0004974707132348473,
      "loss": 2.1677,
      "step": 2820
    },
    {
      "epoch": 10.970873786407767,
      "grad_norm": 0.19098220765590668,
      "learning_rate": 0.0004974487665659268,
      "loss": 2.1818,
      "step": 2830
    },
    {
      "epoch": 11.0,
      "eval_loss": 1.0551016330718994,
      "eval_runtime": 6.9082,
      "eval_samples_per_second": 3585.907,
      "eval_steps_per_second": 14.041,
      "step": 2838
    },
    {
      "epoch": 11.007766990291262,
      "grad_norm": 0.18906773626804352,
      "learning_rate": 0.0004974267255803493,
      "loss": 2.0739,
      "step": 2840
    },
    {
      "epoch": 11.046601941747573,
      "grad_norm": 0.1937544196844101,
      "learning_rate": 0.0004974045902865162,
      "loss": 2.1745,
      "step": 2850
    },
    {
      "epoch": 11.085436893203884,
      "grad_norm": 0.20395943522453308,
      "learning_rate": 0.0004973823606928645,
      "loss": 2.1749,
      "step": 2860
    },
    {
      "epoch": 11.124271844660194,
      "grad_norm": 0.20898935198783875,
      "learning_rate": 0.000497360036807867,
      "loss": 2.1769,
      "step": 2870
    },
    {
      "epoch": 11.163106796116505,
      "grad_norm": 0.19494669139385223,
      "learning_rate": 0.0004973376186400328,
      "loss": 2.1806,
      "step": 2880
    },
    {
      "epoch": 11.201941747572816,
      "grad_norm": 0.19168174266815186,
      "learning_rate": 0.0004973151061979065,
      "loss": 2.1702,
      "step": 2890
    },
    {
      "epoch": 11.240776699029126,
      "grad_norm": 0.22963933646678925,
      "learning_rate": 0.0004972924994900691,
      "loss": 2.1677,
      "step": 2900
    },
    {
      "epoch": 11.279611650485437,
      "grad_norm": 0.19064587354660034,
      "learning_rate": 0.000497269798525137,
      "loss": 2.1747,
      "step": 2910
    },
    {
      "epoch": 11.318446601941748,
      "grad_norm": 0.19040708243846893,
      "learning_rate": 0.000497247003311763,
      "loss": 2.1832,
      "step": 2920
    },
    {
      "epoch": 11.357281553398058,
      "grad_norm": 0.1931016743183136,
      "learning_rate": 0.0004972241138586356,
      "loss": 2.171,
      "step": 2930
    },
    {
      "epoch": 11.396116504854369,
      "grad_norm": 0.19696451723575592,
      "learning_rate": 0.0004972011301744793,
      "loss": 2.1902,
      "step": 2940
    },
    {
      "epoch": 11.43495145631068,
      "grad_norm": 0.22164814174175262,
      "learning_rate": 0.0004971780522680546,
      "loss": 2.1542,
      "step": 2950
    },
    {
      "epoch": 11.47378640776699,
      "grad_norm": 0.2038535177707672,
      "learning_rate": 0.0004971548801481575,
      "loss": 2.1872,
      "step": 2960
    },
    {
      "epoch": 11.512621359223301,
      "grad_norm": 0.19708949327468872,
      "learning_rate": 0.0004971316138236202,
      "loss": 2.1675,
      "step": 2970
    },
    {
      "epoch": 11.551456310679612,
      "grad_norm": 0.2156139463186264,
      "learning_rate": 0.0004971082533033111,
      "loss": 2.1639,
      "step": 2980
    },
    {
      "epoch": 11.590291262135922,
      "grad_norm": 0.22569289803504944,
      "learning_rate": 0.0004970847985961341,
      "loss": 2.1788,
      "step": 2990
    },
    {
      "epoch": 11.629126213592233,
      "grad_norm": 0.2015182077884674,
      "learning_rate": 0.0004970612497110289,
      "loss": 2.1676,
      "step": 3000
    },
    {
      "epoch": 11.667961165048544,
      "grad_norm": 0.18636946380138397,
      "learning_rate": 0.0004970376066569716,
      "loss": 2.1823,
      "step": 3010
    },
    {
      "epoch": 11.706796116504854,
      "grad_norm": 0.22444306313991547,
      "learning_rate": 0.0004970138694429737,
      "loss": 2.1808,
      "step": 3020
    },
    {
      "epoch": 11.745631067961165,
      "grad_norm": 0.30570316314697266,
      "learning_rate": 0.0004969900380780829,
      "loss": 2.1712,
      "step": 3030
    },
    {
      "epoch": 11.784466019417476,
      "grad_norm": 0.20695120096206665,
      "learning_rate": 0.0004969661125713826,
      "loss": 2.165,
      "step": 3040
    },
    {
      "epoch": 11.823300970873786,
      "grad_norm": 0.2103945016860962,
      "learning_rate": 0.0004969420929319921,
      "loss": 2.1714,
      "step": 3050
    },
    {
      "epoch": 11.862135922330097,
      "grad_norm": 0.22367240488529205,
      "learning_rate": 0.0004969179791690668,
      "loss": 2.1808,
      "step": 3060
    },
    {
      "epoch": 11.900970873786408,
      "grad_norm": 0.1872936338186264,
      "learning_rate": 0.0004968937712917978,
      "loss": 2.1747,
      "step": 3070
    },
    {
      "epoch": 11.939805825242718,
      "grad_norm": 0.2052425593137741,
      "learning_rate": 0.0004968694693094119,
      "loss": 2.165,
      "step": 3080
    },
    {
      "epoch": 11.978640776699029,
      "grad_norm": 0.21690168976783752,
      "learning_rate": 0.0004968450732311722,
      "loss": 2.1703,
      "step": 3090
    },
    {
      "epoch": 12.0,
      "eval_loss": 1.0530903339385986,
      "eval_runtime": 6.9228,
      "eval_samples_per_second": 3578.303,
      "eval_steps_per_second": 14.012,
      "step": 3096
    },
    {
      "epoch": 12.015533980582525,
      "grad_norm": 0.2612961530685425,
      "learning_rate": 0.0004968205830663772,
      "loss": 2.0543,
      "step": 3100
    },
    {
      "epoch": 12.054368932038836,
      "grad_norm": 0.1825530230998993,
      "learning_rate": 0.0004967959988243616,
      "loss": 2.1632,
      "step": 3110
    },
    {
      "epoch": 12.093203883495146,
      "grad_norm": 0.19245263934135437,
      "learning_rate": 0.0004967713205144958,
      "loss": 2.1673,
      "step": 3120
    },
    {
      "epoch": 12.132038834951457,
      "grad_norm": 0.21564772725105286,
      "learning_rate": 0.0004967465481461862,
      "loss": 2.1617,
      "step": 3130
    },
    {
      "epoch": 12.170873786407768,
      "grad_norm": 0.19997067749500275,
      "learning_rate": 0.0004967216817288747,
      "loss": 2.184,
      "step": 3140
    },
    {
      "epoch": 12.209708737864078,
      "grad_norm": 0.19480670988559723,
      "learning_rate": 0.0004966967212720396,
      "loss": 2.1711,
      "step": 3150
    },
    {
      "epoch": 12.248543689320389,
      "grad_norm": 0.2549811601638794,
      "learning_rate": 0.0004966716667851945,
      "loss": 2.1642,
      "step": 3160
    },
    {
      "epoch": 12.2873786407767,
      "grad_norm": 0.19760887324810028,
      "learning_rate": 0.0004966465182778891,
      "loss": 2.1565,
      "step": 3170
    },
    {
      "epoch": 12.32621359223301,
      "grad_norm": 0.18831531703472137,
      "learning_rate": 0.0004966212757597091,
      "loss": 2.1625,
      "step": 3180
    },
    {
      "epoch": 12.365048543689321,
      "grad_norm": 0.3014968931674957,
      "learning_rate": 0.0004965959392402756,
      "loss": 2.1548,
      "step": 3190
    },
    {
      "epoch": 12.403883495145632,
      "grad_norm": 0.17208582162857056,
      "learning_rate": 0.0004965705087292459,
      "loss": 2.1606,
      "step": 3200
    },
    {
      "epoch": 12.442718446601942,
      "grad_norm": 0.4822382628917694,
      "learning_rate": 0.0004965449842363129,
      "loss": 2.1876,
      "step": 3210
    },
    {
      "epoch": 12.481553398058253,
      "grad_norm": 0.18476471304893494,
      "learning_rate": 0.0004965193657712057,
      "loss": 2.1705,
      "step": 3220
    },
    {
      "epoch": 12.520388349514564,
      "grad_norm": 0.206241175532341,
      "learning_rate": 0.0004964936533436886,
      "loss": 2.1696,
      "step": 3230
    },
    {
      "epoch": 12.559223300970874,
      "grad_norm": 0.1994299292564392,
      "learning_rate": 0.0004964678469635622,
      "loss": 2.1813,
      "step": 3240
    },
    {
      "epoch": 12.598058252427185,
      "grad_norm": 0.18861675262451172,
      "learning_rate": 0.0004964419466406628,
      "loss": 2.1687,
      "step": 3250
    },
    {
      "epoch": 12.636893203883496,
      "grad_norm": 0.2051069587469101,
      "learning_rate": 0.0004964159523848624,
      "loss": 2.1601,
      "step": 3260
    },
    {
      "epoch": 12.675728155339806,
      "grad_norm": 0.17062793672084808,
      "learning_rate": 0.000496389864206069,
      "loss": 2.1616,
      "step": 3270
    },
    {
      "epoch": 12.714563106796117,
      "grad_norm": 0.2108181267976761,
      "learning_rate": 0.0004963636821142261,
      "loss": 2.1648,
      "step": 3280
    },
    {
      "epoch": 12.753398058252428,
      "grad_norm": 0.205444797873497,
      "learning_rate": 0.0004963374061193133,
      "loss": 2.1724,
      "step": 3290
    },
    {
      "epoch": 12.792233009708738,
      "grad_norm": 0.2100435048341751,
      "learning_rate": 0.0004963110362313459,
      "loss": 2.1796,
      "step": 3300
    },
    {
      "epoch": 12.831067961165049,
      "grad_norm": 0.1933242529630661,
      "learning_rate": 0.0004962845724603747,
      "loss": 2.176,
      "step": 3310
    },
    {
      "epoch": 12.86990291262136,
      "grad_norm": 0.21118997037410736,
      "learning_rate": 0.0004962580148164867,
      "loss": 2.1688,
      "step": 3320
    },
    {
      "epoch": 12.90873786407767,
      "grad_norm": 0.18977665901184082,
      "learning_rate": 0.0004962313633098045,
      "loss": 2.1547,
      "step": 3330
    },
    {
      "epoch": 12.94757281553398,
      "grad_norm": 0.21041586995124817,
      "learning_rate": 0.0004962046179504867,
      "loss": 2.1578,
      "step": 3340
    },
    {
      "epoch": 12.986407766990292,
      "grad_norm": 0.17706453800201416,
      "learning_rate": 0.0004961777787487271,
      "loss": 2.1612,
      "step": 3350
    },
    {
      "epoch": 13.0,
      "eval_loss": 1.0493568181991577,
      "eval_runtime": 6.9678,
      "eval_samples_per_second": 3555.193,
      "eval_steps_per_second": 13.921,
      "step": 3354
    },
    {
      "epoch": 13.023300970873786,
      "grad_norm": 0.19683301448822021,
      "learning_rate": 0.0004961508457147558,
      "loss": 2.0528,
      "step": 3360
    },
    {
      "epoch": 13.062135922330096,
      "grad_norm": 0.18902498483657837,
      "learning_rate": 0.0004961238188588384,
      "loss": 2.153,
      "step": 3370
    },
    {
      "epoch": 13.100970873786407,
      "grad_norm": 0.22834846377372742,
      "learning_rate": 0.0004960966981912765,
      "loss": 2.1623,
      "step": 3380
    },
    {
      "epoch": 13.139805825242718,
      "grad_norm": 0.22172780334949493,
      "learning_rate": 0.0004960694837224073,
      "loss": 2.1591,
      "step": 3390
    },
    {
      "epoch": 13.178640776699028,
      "grad_norm": 0.21570131182670593,
      "learning_rate": 0.0004960421754626038,
      "loss": 2.157,
      "step": 3400
    },
    {
      "epoch": 13.217475728155339,
      "grad_norm": 0.2198750376701355,
      "learning_rate": 0.0004960147734222745,
      "loss": 2.1657,
      "step": 3410
    },
    {
      "epoch": 13.25631067961165,
      "grad_norm": 0.27581721544265747,
      "learning_rate": 0.0004959872776118641,
      "loss": 2.1559,
      "step": 3420
    },
    {
      "epoch": 13.29514563106796,
      "grad_norm": 0.18079005181789398,
      "learning_rate": 0.0004959596880418526,
      "loss": 2.174,
      "step": 3430
    },
    {
      "epoch": 13.333980582524271,
      "grad_norm": 0.18630583584308624,
      "learning_rate": 0.0004959320047227561,
      "loss": 2.1725,
      "step": 3440
    },
    {
      "epoch": 13.372815533980582,
      "grad_norm": 0.1895429491996765,
      "learning_rate": 0.0004959042276651263,
      "loss": 2.1541,
      "step": 3450
    },
    {
      "epoch": 13.411650485436894,
      "grad_norm": 0.19503159821033478,
      "learning_rate": 0.0004958763568795503,
      "loss": 2.1546,
      "step": 3460
    },
    {
      "epoch": 13.450485436893203,
      "grad_norm": 0.21037808060646057,
      "learning_rate": 0.0004958483923766515,
      "loss": 2.1695,
      "step": 3470
    },
    {
      "epoch": 13.489320388349515,
      "grad_norm": 0.1763465404510498,
      "learning_rate": 0.0004958203341670888,
      "loss": 2.1615,
      "step": 3480
    },
    {
      "epoch": 13.528155339805826,
      "grad_norm": 0.1938747763633728,
      "learning_rate": 0.0004957921822615565,
      "loss": 2.1622,
      "step": 3490
    },
    {
      "epoch": 13.566990291262137,
      "grad_norm": 0.1876554638147354,
      "learning_rate": 0.0004957639366707851,
      "loss": 2.1697,
      "step": 3500
    },
    {
      "epoch": 13.605825242718447,
      "grad_norm": 0.211782768368721,
      "learning_rate": 0.0004957355974055405,
      "loss": 2.1659,
      "step": 3510
    },
    {
      "epoch": 13.644660194174758,
      "grad_norm": 0.2312617003917694,
      "learning_rate": 0.0004957071644766244,
      "loss": 2.148,
      "step": 3520
    },
    {
      "epoch": 13.683495145631069,
      "grad_norm": 0.3498559594154358,
      "learning_rate": 0.0004956786378948742,
      "loss": 2.1588,
      "step": 3530
    },
    {
      "epoch": 13.72233009708738,
      "grad_norm": 0.21761274337768555,
      "learning_rate": 0.0004956500176711629,
      "loss": 2.1501,
      "step": 3540
    },
    {
      "epoch": 13.76116504854369,
      "grad_norm": 0.1783197522163391,
      "learning_rate": 0.0004956213038163995,
      "loss": 2.1588,
      "step": 3550
    },
    {
      "epoch": 13.8,
      "grad_norm": 0.18217599391937256,
      "learning_rate": 0.0004955924963415281,
      "loss": 2.1577,
      "step": 3560
    },
    {
      "epoch": 13.838834951456311,
      "grad_norm": 0.19478270411491394,
      "learning_rate": 0.0004955635952575292,
      "loss": 2.1645,
      "step": 3570
    },
    {
      "epoch": 13.877669902912622,
      "grad_norm": 0.21425898373126984,
      "learning_rate": 0.0004955346005754186,
      "loss": 2.1536,
      "step": 3580
    },
    {
      "epoch": 13.916504854368933,
      "grad_norm": 0.20293308794498444,
      "learning_rate": 0.0004955055123062475,
      "loss": 2.1593,
      "step": 3590
    },
    {
      "epoch": 13.955339805825243,
      "grad_norm": 0.17626991868019104,
      "learning_rate": 0.0004954763304611034,
      "loss": 2.1706,
      "step": 3600
    },
    {
      "epoch": 13.994174757281554,
      "grad_norm": 0.2003432810306549,
      "learning_rate": 0.000495447055051109,
      "loss": 2.1524,
      "step": 3610
    },
    {
      "epoch": 14.0,
      "eval_loss": 1.0472004413604736,
      "eval_runtime": 6.5484,
      "eval_samples_per_second": 3782.9,
      "eval_steps_per_second": 14.813,
      "step": 3612
    },
    {
      "epoch": 14.031067961165048,
      "grad_norm": 0.1976722925901413,
      "learning_rate": 0.0004954176860874228,
      "loss": 2.0583,
      "step": 3620
    },
    {
      "epoch": 14.069902912621359,
      "grad_norm": 0.30862581729888916,
      "learning_rate": 0.0004953882235812391,
      "loss": 2.1381,
      "step": 3630
    },
    {
      "epoch": 14.10873786407767,
      "grad_norm": 0.20688505470752716,
      "learning_rate": 0.0004953586675437875,
      "loss": 2.1504,
      "step": 3640
    },
    {
      "epoch": 14.14757281553398,
      "grad_norm": 0.2653396725654602,
      "learning_rate": 0.0004953290179863336,
      "loss": 2.1567,
      "step": 3650
    },
    {
      "epoch": 14.18640776699029,
      "grad_norm": 0.218873992562294,
      "learning_rate": 0.0004952992749201786,
      "loss": 2.1452,
      "step": 3660
    },
    {
      "epoch": 14.225242718446601,
      "grad_norm": 0.20406408607959747,
      "learning_rate": 0.000495269438356659,
      "loss": 2.1559,
      "step": 3670
    },
    {
      "epoch": 14.264077669902912,
      "grad_norm": 0.18180020153522491,
      "learning_rate": 0.0004952395083071475,
      "loss": 2.1661,
      "step": 3680
    },
    {
      "epoch": 14.302912621359223,
      "grad_norm": 0.27946075797080994,
      "learning_rate": 0.000495209484783052,
      "loss": 2.1599,
      "step": 3690
    },
    {
      "epoch": 14.341747572815533,
      "grad_norm": 0.2305474579334259,
      "learning_rate": 0.000495179367795816,
      "loss": 2.1581,
      "step": 3700
    },
    {
      "epoch": 14.380582524271844,
      "grad_norm": 0.18148210644721985,
      "learning_rate": 0.0004951491573569191,
      "loss": 2.1592,
      "step": 3710
    },
    {
      "epoch": 14.419417475728155,
      "grad_norm": 0.1896832138299942,
      "learning_rate": 0.0004951188534778758,
      "loss": 2.1668,
      "step": 3720
    },
    {
      "epoch": 14.458252427184465,
      "grad_norm": 0.2154940664768219,
      "learning_rate": 0.000495088456170237,
      "loss": 2.161,
      "step": 3730
    },
    {
      "epoch": 14.497087378640776,
      "grad_norm": 0.2222895324230194,
      "learning_rate": 0.0004950579654455886,
      "loss": 2.1698,
      "step": 3740
    },
    {
      "epoch": 14.535922330097087,
      "grad_norm": 0.19915543496608734,
      "learning_rate": 0.0004950273813155524,
      "loss": 2.1575,
      "step": 3750
    },
    {
      "epoch": 14.574757281553397,
      "grad_norm": 0.277185320854187,
      "learning_rate": 0.0004949967037917857,
      "loss": 2.1566,
      "step": 3760
    },
    {
      "epoch": 14.613592233009708,
      "grad_norm": 0.22642134130001068,
      "learning_rate": 0.0004949659328859815,
      "loss": 2.1593,
      "step": 3770
    },
    {
      "epoch": 14.652427184466019,
      "grad_norm": 0.21789579093456268,
      "learning_rate": 0.0004949350686098682,
      "loss": 2.167,
      "step": 3780
    },
    {
      "epoch": 14.69126213592233,
      "grad_norm": 0.16714729368686676,
      "learning_rate": 0.00049490411097521,
      "loss": 2.1533,
      "step": 3790
    },
    {
      "epoch": 14.73009708737864,
      "grad_norm": 0.19246163964271545,
      "learning_rate": 0.0004948730599938066,
      "loss": 2.1595,
      "step": 3800
    },
    {
      "epoch": 14.76893203883495,
      "grad_norm": 0.21730270981788635,
      "learning_rate": 0.0004948419156774933,
      "loss": 2.136,
      "step": 3810
    },
    {
      "epoch": 14.807766990291261,
      "grad_norm": 0.20445986092090607,
      "learning_rate": 0.000494810678038141,
      "loss": 2.1363,
      "step": 3820
    },
    {
      "epoch": 14.846601941747572,
      "grad_norm": 0.19382111728191376,
      "learning_rate": 0.0004947793470876559,
      "loss": 2.1696,
      "step": 3830
    },
    {
      "epoch": 14.885436893203883,
      "grad_norm": 0.19414639472961426,
      "learning_rate": 0.0004947479228379802,
      "loss": 2.1585,
      "step": 3840
    },
    {
      "epoch": 14.924271844660193,
      "grad_norm": 0.17775550484657288,
      "learning_rate": 0.0004947164053010913,
      "loss": 2.1609,
      "step": 3850
    },
    {
      "epoch": 14.963106796116504,
      "grad_norm": 0.17766351997852325,
      "learning_rate": 0.0004946847944890025,
      "loss": 2.1581,
      "step": 3860
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.22738207876682281,
      "learning_rate": 0.0004946530904137623,
      "loss": 2.0338,
      "step": 3870
    },
    {
      "epoch": 15.0,
      "eval_loss": 1.0454381704330444,
      "eval_runtime": 6.6688,
      "eval_samples_per_second": 3714.589,
      "eval_steps_per_second": 14.545,
      "step": 3870
    },
    {
      "epoch": 15.03883495145631,
      "grad_norm": 0.17911428213119507,
      "learning_rate": 0.0004946212930874549,
      "loss": 2.1776,
      "step": 3880
    },
    {
      "epoch": 15.077669902912621,
      "grad_norm": 0.19155515730381012,
      "learning_rate": 0.0004945894025222002,
      "loss": 2.1371,
      "step": 3890
    },
    {
      "epoch": 15.116504854368932,
      "grad_norm": 0.19626325368881226,
      "learning_rate": 0.0004945574187301534,
      "loss": 2.1414,
      "step": 3900
    },
    {
      "epoch": 15.155339805825243,
      "grad_norm": 0.26596125960350037,
      "learning_rate": 0.0004945253417235053,
      "loss": 2.1346,
      "step": 3910
    },
    {
      "epoch": 15.194174757281553,
      "grad_norm": 0.21090568602085114,
      "learning_rate": 0.0004944931715144822,
      "loss": 2.1543,
      "step": 3920
    },
    {
      "epoch": 15.233009708737864,
      "grad_norm": 0.18611188232898712,
      "learning_rate": 0.0004944609081153461,
      "loss": 2.1614,
      "step": 3930
    },
    {
      "epoch": 15.271844660194175,
      "grad_norm": 0.21413889527320862,
      "learning_rate": 0.0004944285515383944,
      "loss": 2.1416,
      "step": 3940
    },
    {
      "epoch": 15.310679611650485,
      "grad_norm": 0.18803009390830994,
      "learning_rate": 0.0004943961017959599,
      "loss": 2.1479,
      "step": 3950
    },
    {
      "epoch": 15.349514563106796,
      "grad_norm": 0.36171823740005493,
      "learning_rate": 0.0004943635589004111,
      "loss": 2.1403,
      "step": 3960
    },
    {
      "epoch": 15.388349514563107,
      "grad_norm": 0.16215431690216064,
      "learning_rate": 0.000494330922864152,
      "loss": 2.1271,
      "step": 3970
    },
    {
      "epoch": 15.427184466019417,
      "grad_norm": 0.17305301129817963,
      "learning_rate": 0.0004942981936996219,
      "loss": 2.1391,
      "step": 3980
    },
    {
      "epoch": 15.466019417475728,
      "grad_norm": 0.2869853973388672,
      "learning_rate": 0.0004942653714192957,
      "loss": 2.1647,
      "step": 3990
    },
    {
      "epoch": 15.504854368932039,
      "grad_norm": 0.17356587946414948,
      "learning_rate": 0.000494232456035684,
      "loss": 2.1633,
      "step": 4000
    },
    {
      "epoch": 15.54368932038835,
      "grad_norm": 0.2691100537776947,
      "learning_rate": 0.0004941994475613326,
      "loss": 2.1502,
      "step": 4010
    },
    {
      "epoch": 15.58252427184466,
      "grad_norm": 0.18053744733333588,
      "learning_rate": 0.0004941663460088228,
      "loss": 2.1462,
      "step": 4020
    },
    {
      "epoch": 15.62135922330097,
      "grad_norm": 0.17698487639427185,
      "learning_rate": 0.0004941331513907717,
      "loss": 2.1435,
      "step": 4030
    },
    {
      "epoch": 15.660194174757281,
      "grad_norm": 0.19901777803897858,
      "learning_rate": 0.0004940998637198312,
      "loss": 2.1308,
      "step": 4040
    },
    {
      "epoch": 15.699029126213592,
      "grad_norm": 0.19657550752162933,
      "learning_rate": 0.0004940664830086897,
      "loss": 2.1549,
      "step": 4050
    },
    {
      "epoch": 15.737864077669903,
      "grad_norm": 0.2938690483570099,
      "learning_rate": 0.0004940330092700701,
      "loss": 2.1482,
      "step": 4060
    },
    {
      "epoch": 15.776699029126213,
      "grad_norm": 0.19028781354427338,
      "learning_rate": 0.0004939994425167311,
      "loss": 2.1473,
      "step": 4070
    },
    {
      "epoch": 15.815533980582524,
      "grad_norm": 0.17084115743637085,
      "learning_rate": 0.000493965782761467,
      "loss": 2.1594,
      "step": 4080
    },
    {
      "epoch": 15.854368932038835,
      "grad_norm": 0.1739611029624939,
      "learning_rate": 0.0004939320300171075,
      "loss": 2.1705,
      "step": 4090
    },
    {
      "epoch": 15.893203883495145,
      "grad_norm": 0.18196743726730347,
      "learning_rate": 0.0004938981842965176,
      "loss": 2.1508,
      "step": 4100
    },
    {
      "epoch": 15.932038834951456,
      "grad_norm": 0.21274735033512115,
      "learning_rate": 0.0004938642456125975,
      "loss": 2.1633,
      "step": 4110
    },
    {
      "epoch": 15.970873786407767,
      "grad_norm": 0.22006714344024658,
      "learning_rate": 0.0004938302139782837,
      "loss": 2.1431,
      "step": 4120
    },
    {
      "epoch": 16.0,
      "eval_loss": 1.0441685914993286,
      "eval_runtime": 6.5567,
      "eval_samples_per_second": 3778.107,
      "eval_steps_per_second": 14.794,
      "step": 4128
    },
    {
      "epoch": 16.007766990291262,
      "grad_norm": 0.2185809463262558,
      "learning_rate": 0.0004937960894065472,
      "loss": 2.0469,
      "step": 4130
    },
    {
      "epoch": 16.04660194174757,
      "grad_norm": 0.1990998238325119,
      "learning_rate": 0.0004937618719103949,
      "loss": 2.1298,
      "step": 4140
    },
    {
      "epoch": 16.085436893203884,
      "grad_norm": 0.20254190266132355,
      "learning_rate": 0.0004937275615028691,
      "loss": 2.1475,
      "step": 4150
    },
    {
      "epoch": 16.124271844660193,
      "grad_norm": 0.1985395848751068,
      "learning_rate": 0.0004936931581970472,
      "loss": 2.1554,
      "step": 4160
    },
    {
      "epoch": 16.163106796116505,
      "grad_norm": 0.1859028935432434,
      "learning_rate": 0.0004936586620060423,
      "loss": 2.147,
      "step": 4170
    },
    {
      "epoch": 16.201941747572814,
      "grad_norm": 0.21082884073257446,
      "learning_rate": 0.0004936240729430031,
      "loss": 2.1589,
      "step": 4180
    },
    {
      "epoch": 16.240776699029126,
      "grad_norm": 0.21504968404769897,
      "learning_rate": 0.0004935893910211132,
      "loss": 2.1434,
      "step": 4190
    },
    {
      "epoch": 16.279611650485435,
      "grad_norm": 0.22072051465511322,
      "learning_rate": 0.0004935546162535919,
      "loss": 2.1418,
      "step": 4200
    },
    {
      "epoch": 16.318446601941748,
      "grad_norm": 0.19991083443164825,
      "learning_rate": 0.0004935197486536937,
      "loss": 2.1383,
      "step": 4210
    },
    {
      "epoch": 16.357281553398057,
      "grad_norm": 0.18535828590393066,
      "learning_rate": 0.0004934847882347088,
      "loss": 2.1587,
      "step": 4220
    },
    {
      "epoch": 16.39611650485437,
      "grad_norm": 0.24718210101127625,
      "learning_rate": 0.0004934497350099625,
      "loss": 2.1536,
      "step": 4230
    },
    {
      "epoch": 16.434951456310678,
      "grad_norm": 0.20185241103172302,
      "learning_rate": 0.0004934145889928155,
      "loss": 2.1659,
      "step": 4240
    },
    {
      "epoch": 16.47378640776699,
      "grad_norm": 0.2252233922481537,
      "learning_rate": 0.000493379350196664,
      "loss": 2.1474,
      "step": 4250
    },
    {
      "epoch": 16.5126213592233,
      "grad_norm": 0.17611558735370636,
      "learning_rate": 0.0004933440186349395,
      "loss": 2.139,
      "step": 4260
    },
    {
      "epoch": 16.55145631067961,
      "grad_norm": 0.20935162901878357,
      "learning_rate": 0.0004933085943211087,
      "loss": 2.1359,
      "step": 4270
    },
    {
      "epoch": 16.59029126213592,
      "grad_norm": 0.21818168461322784,
      "learning_rate": 0.0004932730772686741,
      "loss": 2.1415,
      "step": 4280
    },
    {
      "epoch": 16.629126213592233,
      "grad_norm": 0.18580026924610138,
      "learning_rate": 0.0004932374674911729,
      "loss": 2.1479,
      "step": 4290
    },
    {
      "epoch": 16.667961165048542,
      "grad_norm": 0.1986985206604004,
      "learning_rate": 0.0004932017650021783,
      "loss": 2.1665,
      "step": 4300
    },
    {
      "epoch": 16.706796116504854,
      "grad_norm": 0.16870374977588654,
      "learning_rate": 0.0004931659698152982,
      "loss": 2.1415,
      "step": 4310
    },
    {
      "epoch": 16.745631067961163,
      "grad_norm": 0.21505729854106903,
      "learning_rate": 0.0004931300819441765,
      "loss": 2.1394,
      "step": 4320
    },
    {
      "epoch": 16.784466019417476,
      "grad_norm": 0.16970181465148926,
      "learning_rate": 0.0004930941014024919,
      "loss": 2.1364,
      "step": 4330
    },
    {
      "epoch": 16.823300970873788,
      "grad_norm": 0.18343771994113922,
      "learning_rate": 0.0004930580282039586,
      "loss": 2.1379,
      "step": 4340
    },
    {
      "epoch": 16.862135922330097,
      "grad_norm": 0.1720818132162094,
      "learning_rate": 0.0004930218623623263,
      "loss": 2.1465,
      "step": 4350
    },
    {
      "epoch": 16.900970873786406,
      "grad_norm": 0.16837726533412933,
      "learning_rate": 0.0004929856038913795,
      "loss": 2.1305,
      "step": 4360
    },
    {
      "epoch": 16.93980582524272,
      "grad_norm": 0.17448142170906067,
      "learning_rate": 0.0004929492528049388,
      "loss": 2.1407,
      "step": 4370
    },
    {
      "epoch": 16.97864077669903,
      "grad_norm": 0.18853765726089478,
      "learning_rate": 0.0004929128091168592,
      "loss": 2.1477,
      "step": 4380
    },
    {
      "epoch": 17.0,
      "eval_loss": 1.0416359901428223,
      "eval_runtime": 6.5457,
      "eval_samples_per_second": 3784.455,
      "eval_steps_per_second": 14.819,
      "step": 4386
    },
    {
      "epoch": 17.015533980582525,
      "grad_norm": 0.20677518844604492,
      "learning_rate": 0.0004928762728410316,
      "loss": 2.0349,
      "step": 4390
    },
    {
      "epoch": 17.054368932038834,
      "grad_norm": 0.19572925567626953,
      "learning_rate": 0.0004928396439913823,
      "loss": 2.1399,
      "step": 4400
    },
    {
      "epoch": 17.093203883495146,
      "grad_norm": 0.19415968656539917,
      "learning_rate": 0.0004928029225818722,
      "loss": 2.1316,
      "step": 4410
    },
    {
      "epoch": 17.132038834951455,
      "grad_norm": 0.19885605573654175,
      "learning_rate": 0.0004927661086264982,
      "loss": 2.1297,
      "step": 4420
    },
    {
      "epoch": 17.170873786407768,
      "grad_norm": 0.1870666742324829,
      "learning_rate": 0.000492729202139292,
      "loss": 2.1245,
      "step": 4430
    },
    {
      "epoch": 17.209708737864077,
      "grad_norm": 0.21486961841583252,
      "learning_rate": 0.0004926922031343209,
      "loss": 2.1388,
      "step": 4440
    },
    {
      "epoch": 17.24854368932039,
      "grad_norm": 0.18230773508548737,
      "learning_rate": 0.000492655111625687,
      "loss": 2.1447,
      "step": 4450
    },
    {
      "epoch": 17.287378640776698,
      "grad_norm": 0.1932251751422882,
      "learning_rate": 0.0004926179276275283,
      "loss": 2.1537,
      "step": 4460
    },
    {
      "epoch": 17.32621359223301,
      "grad_norm": 0.16960567235946655,
      "learning_rate": 0.0004925806511540175,
      "loss": 2.149,
      "step": 4470
    },
    {
      "epoch": 17.36504854368932,
      "grad_norm": 0.1936367303133011,
      "learning_rate": 0.0004925432822193629,
      "loss": 2.146,
      "step": 4480
    },
    {
      "epoch": 17.40388349514563,
      "grad_norm": 0.20769864320755005,
      "learning_rate": 0.0004925058208378078,
      "loss": 2.1467,
      "step": 4490
    },
    {
      "epoch": 17.44271844660194,
      "grad_norm": 0.18847906589508057,
      "learning_rate": 0.000492468267023631,
      "loss": 2.1314,
      "step": 4500
    },
    {
      "epoch": 17.481553398058253,
      "grad_norm": 0.18150685727596283,
      "learning_rate": 0.0004924306207911462,
      "loss": 2.1516,
      "step": 4510
    },
    {
      "epoch": 17.520388349514562,
      "grad_norm": 0.20875614881515503,
      "learning_rate": 0.0004923928821547025,
      "loss": 2.152,
      "step": 4520
    },
    {
      "epoch": 17.559223300970874,
      "grad_norm": 0.17887946963310242,
      "learning_rate": 0.0004923550511286844,
      "loss": 2.1414,
      "step": 4530
    },
    {
      "epoch": 17.598058252427183,
      "grad_norm": 0.23633210361003876,
      "learning_rate": 0.0004923171277275112,
      "loss": 2.1562,
      "step": 4540
    },
    {
      "epoch": 17.636893203883496,
      "grad_norm": 0.1845780462026596,
      "learning_rate": 0.0004922791119656378,
      "loss": 2.1378,
      "step": 4550
    },
    {
      "epoch": 17.675728155339804,
      "grad_norm": 0.1767166703939438,
      "learning_rate": 0.0004922410038575541,
      "loss": 2.1572,
      "step": 4560
    },
    {
      "epoch": 17.714563106796117,
      "grad_norm": 0.24483244121074677,
      "learning_rate": 0.0004922028034177853,
      "loss": 2.1582,
      "step": 4570
    },
    {
      "epoch": 17.753398058252426,
      "grad_norm": 0.18539361655712128,
      "learning_rate": 0.0004921645106608916,
      "loss": 2.1413,
      "step": 4580
    },
    {
      "epoch": 17.792233009708738,
      "grad_norm": 0.19170063734054565,
      "learning_rate": 0.0004921261256014686,
      "loss": 2.1443,
      "step": 4590
    },
    {
      "epoch": 17.831067961165047,
      "grad_norm": 0.19924041628837585,
      "learning_rate": 0.0004920876482541471,
      "loss": 2.1287,
      "step": 4600
    },
    {
      "epoch": 17.86990291262136,
      "grad_norm": 0.2898552119731903,
      "learning_rate": 0.0004920490786335928,
      "loss": 2.1457,
      "step": 4610
    },
    {
      "epoch": 17.90873786407767,
      "grad_norm": 0.20041067898273468,
      "learning_rate": 0.000492010416754507,
      "loss": 2.1395,
      "step": 4620
    },
    {
      "epoch": 17.94757281553398,
      "grad_norm": 0.2279137670993805,
      "learning_rate": 0.0004919716626316257,
      "loss": 2.142,
      "step": 4630
    },
    {
      "epoch": 17.98640776699029,
      "grad_norm": 0.21132323145866394,
      "learning_rate": 0.0004919328162797204,
      "loss": 2.1357,
      "step": 4640
    },
    {
      "epoch": 18.0,
      "eval_loss": 1.0417389869689941,
      "eval_runtime": 6.5467,
      "eval_samples_per_second": 3783.865,
      "eval_steps_per_second": 14.817,
      "step": 4644
    },
    {
      "epoch": 18.023300970873787,
      "grad_norm": 0.1875782012939453,
      "learning_rate": 0.0004918938777135975,
      "loss": 2.0188,
      "step": 4650
    },
    {
      "epoch": 18.062135922330096,
      "grad_norm": 0.2115381807088852,
      "learning_rate": 0.0004918548469480988,
      "loss": 2.1362,
      "step": 4660
    },
    {
      "epoch": 18.10097087378641,
      "grad_norm": 0.21269172430038452,
      "learning_rate": 0.0004918157239981011,
      "loss": 2.148,
      "step": 4670
    },
    {
      "epoch": 18.139805825242718,
      "grad_norm": 0.22466197609901428,
      "learning_rate": 0.0004917765088785163,
      "loss": 2.1293,
      "step": 4680
    },
    {
      "epoch": 18.17864077669903,
      "grad_norm": 0.22288325428962708,
      "learning_rate": 0.0004917372016042916,
      "loss": 2.1422,
      "step": 4690
    },
    {
      "epoch": 18.21747572815534,
      "grad_norm": 0.22633962333202362,
      "learning_rate": 0.0004916978021904092,
      "loss": 2.1568,
      "step": 4700
    },
    {
      "epoch": 18.25631067961165,
      "grad_norm": 0.22388078272342682,
      "learning_rate": 0.0004916583106518862,
      "loss": 2.1261,
      "step": 4710
    },
    {
      "epoch": 18.29514563106796,
      "grad_norm": 0.2227659672498703,
      "learning_rate": 0.0004916187270037755,
      "loss": 2.1297,
      "step": 4720
    },
    {
      "epoch": 18.333980582524273,
      "grad_norm": 0.2580418288707733,
      "learning_rate": 0.0004915790512611642,
      "loss": 2.1603,
      "step": 4730
    },
    {
      "epoch": 18.37281553398058,
      "grad_norm": 0.20122677087783813,
      "learning_rate": 0.0004915392834391752,
      "loss": 2.1318,
      "step": 4740
    },
    {
      "epoch": 18.411650485436894,
      "grad_norm": 0.20709052681922913,
      "learning_rate": 0.0004914994235529662,
      "loss": 2.1441,
      "step": 4750
    },
    {
      "epoch": 18.450485436893203,
      "grad_norm": 0.21653589606285095,
      "learning_rate": 0.0004914594716177301,
      "loss": 2.135,
      "step": 4760
    },
    {
      "epoch": 18.489320388349515,
      "grad_norm": 0.2220006287097931,
      "learning_rate": 0.0004914194276486948,
      "loss": 2.1473,
      "step": 4770
    },
    {
      "epoch": 18.528155339805824,
      "grad_norm": 0.2111377865076065,
      "learning_rate": 0.0004913792916611232,
      "loss": 2.1431,
      "step": 4780
    },
    {
      "epoch": 18.566990291262137,
      "grad_norm": 0.2823188304901123,
      "learning_rate": 0.0004913390636703135,
      "loss": 2.1372,
      "step": 4790
    },
    {
      "epoch": 18.605825242718446,
      "grad_norm": 0.27265459299087524,
      "learning_rate": 0.0004912987436915989,
      "loss": 2.1489,
      "step": 4800
    },
    {
      "epoch": 18.644660194174758,
      "grad_norm": 0.18487975001335144,
      "learning_rate": 0.0004912583317403476,
      "loss": 2.134,
      "step": 4810
    },
    {
      "epoch": 18.683495145631067,
      "grad_norm": 0.23027975857257843,
      "learning_rate": 0.0004912178278319627,
      "loss": 2.134,
      "step": 4820
    },
    {
      "epoch": 18.72233009708738,
      "grad_norm": 0.3051373064517975,
      "learning_rate": 0.0004911772319818827,
      "loss": 2.1514,
      "step": 4830
    },
    {
      "epoch": 18.76116504854369,
      "grad_norm": 0.20654533803462982,
      "learning_rate": 0.0004911365442055809,
      "loss": 2.138,
      "step": 4840
    },
    {
      "epoch": 18.8,
      "grad_norm": 0.1683025360107422,
      "learning_rate": 0.0004910957645185656,
      "loss": 2.1517,
      "step": 4850
    },
    {
      "epoch": 18.83883495145631,
      "grad_norm": 0.19946902990341187,
      "learning_rate": 0.0004910548929363805,
      "loss": 2.1424,
      "step": 4860
    },
    {
      "epoch": 18.877669902912622,
      "grad_norm": 0.2162686586380005,
      "learning_rate": 0.0004910139294746037,
      "loss": 2.1373,
      "step": 4870
    },
    {
      "epoch": 18.91650485436893,
      "grad_norm": 0.18087686598300934,
      "learning_rate": 0.0004909728741488491,
      "loss": 2.1206,
      "step": 4880
    },
    {
      "epoch": 18.955339805825243,
      "grad_norm": 0.20797090232372284,
      "learning_rate": 0.0004909317269747649,
      "loss": 2.1461,
      "step": 4890
    },
    {
      "epoch": 18.994174757281552,
      "grad_norm": 0.1939515918493271,
      "learning_rate": 0.0004908904879680347,
      "loss": 2.1352,
      "step": 4900
    },
    {
      "epoch": 19.0,
      "eval_loss": 1.0397133827209473,
      "eval_runtime": 6.5713,
      "eval_samples_per_second": 3769.697,
      "eval_steps_per_second": 14.761,
      "step": 4902
    },
    {
      "epoch": 19.03106796116505,
      "grad_norm": 0.2285834103822708,
      "learning_rate": 0.000490849157144377,
      "loss": 2.0405,
      "step": 4910
    },
    {
      "epoch": 19.06990291262136,
      "grad_norm": 0.2555939555168152,
      "learning_rate": 0.0004908077345195452,
      "loss": 2.1365,
      "step": 4920
    },
    {
      "epoch": 19.10873786407767,
      "grad_norm": 0.22584271430969238,
      "learning_rate": 0.0004907662201093279,
      "loss": 2.1406,
      "step": 4930
    },
    {
      "epoch": 19.14757281553398,
      "grad_norm": 0.1971568614244461,
      "learning_rate": 0.0004907246139295487,
      "loss": 2.141,
      "step": 4940
    },
    {
      "epoch": 19.186407766990293,
      "grad_norm": 0.2560684084892273,
      "learning_rate": 0.0004906829159960658,
      "loss": 2.1291,
      "step": 4950
    },
    {
      "epoch": 19.2252427184466,
      "grad_norm": 0.3020211458206177,
      "learning_rate": 0.0004906411263247728,
      "loss": 2.1394,
      "step": 4960
    },
    {
      "epoch": 19.264077669902914,
      "grad_norm": 0.22808708250522614,
      "learning_rate": 0.000490599244931598,
      "loss": 2.1277,
      "step": 4970
    },
    {
      "epoch": 19.302912621359223,
      "grad_norm": 0.2561485171318054,
      "learning_rate": 0.0004905572718325049,
      "loss": 2.1261,
      "step": 4980
    },
    {
      "epoch": 19.341747572815535,
      "grad_norm": 0.21632631123065948,
      "learning_rate": 0.0004905152070434917,
      "loss": 2.1374,
      "step": 4990
    },
    {
      "epoch": 19.380582524271844,
      "grad_norm": 0.3773360550403595,
      "learning_rate": 0.0004904730505805916,
      "loss": 2.141,
      "step": 5000
    },
    {
      "epoch": 19.419417475728157,
      "grad_norm": 0.2168014496564865,
      "learning_rate": 0.000490430802459873,
      "loss": 2.1338,
      "step": 5010
    },
    {
      "epoch": 19.458252427184465,
      "grad_norm": 0.21057088673114777,
      "learning_rate": 0.0004903884626974389,
      "loss": 2.1459,
      "step": 5020
    },
    {
      "epoch": 19.497087378640778,
      "grad_norm": 0.20575697720050812,
      "learning_rate": 0.0004903460313094274,
      "loss": 2.1318,
      "step": 5030
    },
    {
      "epoch": 19.535922330097087,
      "grad_norm": 0.18485568463802338,
      "learning_rate": 0.0004903035083120113,
      "loss": 2.1426,
      "step": 5040
    },
    {
      "epoch": 19.5747572815534,
      "grad_norm": 0.19903121888637543,
      "learning_rate": 0.0004902608937213988,
      "loss": 2.1341,
      "step": 5050
    },
    {
      "epoch": 19.613592233009708,
      "grad_norm": 0.21819543838500977,
      "learning_rate": 0.0004902181875538327,
      "loss": 2.1304,
      "step": 5060
    },
    {
      "epoch": 19.65242718446602,
      "grad_norm": 0.20084881782531738,
      "learning_rate": 0.0004901753898255906,
      "loss": 2.1435,
      "step": 5070
    },
    {
      "epoch": 19.69126213592233,
      "grad_norm": 0.37681844830513,
      "learning_rate": 0.000490132500552985,
      "loss": 2.1332,
      "step": 5080
    },
    {
      "epoch": 19.730097087378642,
      "grad_norm": 0.23419885337352753,
      "learning_rate": 0.0004900895197523637,
      "loss": 2.1303,
      "step": 5090
    },
    {
      "epoch": 19.76893203883495,
      "grad_norm": 0.25149449706077576,
      "learning_rate": 0.0004900464474401089,
      "loss": 2.146,
      "step": 5100
    },
    {
      "epoch": 19.807766990291263,
      "grad_norm": 0.22781285643577576,
      "learning_rate": 0.000490003283632638,
      "loss": 2.1408,
      "step": 5110
    },
    {
      "epoch": 19.846601941747572,
      "grad_norm": 0.22263893485069275,
      "learning_rate": 0.0004899600283464031,
      "loss": 2.1375,
      "step": 5120
    },
    {
      "epoch": 19.885436893203885,
      "grad_norm": 0.20931464433670044,
      "learning_rate": 0.0004899166815978913,
      "loss": 2.1423,
      "step": 5130
    },
    {
      "epoch": 19.924271844660193,
      "grad_norm": 0.20222079753875732,
      "learning_rate": 0.0004898732434036243,
      "loss": 2.1198,
      "step": 5140
    },
    {
      "epoch": 19.963106796116506,
      "grad_norm": 0.19754965603351593,
      "learning_rate": 0.0004898297137801591,
      "loss": 2.1392,
      "step": 5150
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.15415751934051514,
      "learning_rate": 0.0004897860927440871,
      "loss": 2.0192,
      "step": 5160
    },
    {
      "epoch": 20.0,
      "eval_loss": 1.0386837720870972,
      "eval_runtime": 6.5116,
      "eval_samples_per_second": 3804.279,
      "eval_steps_per_second": 14.896,
      "step": 5160
    },
    {
      "epoch": 20.038834951456312,
      "grad_norm": 0.21986126899719238,
      "learning_rate": 0.0004897423803120347,
      "loss": 2.1321,
      "step": 5170
    },
    {
      "epoch": 20.07766990291262,
      "grad_norm": 0.19455376267433167,
      "learning_rate": 0.0004896985765006635,
      "loss": 2.1217,
      "step": 5180
    },
    {
      "epoch": 20.116504854368934,
      "grad_norm": 0.20205429196357727,
      "learning_rate": 0.0004896546813266691,
      "loss": 2.1316,
      "step": 5190
    },
    {
      "epoch": 20.155339805825243,
      "grad_norm": 0.2413923293352127,
      "learning_rate": 0.0004896106948067829,
      "loss": 2.1315,
      "step": 5200
    },
    {
      "epoch": 20.194174757281555,
      "grad_norm": 0.20544853806495667,
      "learning_rate": 0.0004895666169577702,
      "loss": 2.1442,
      "step": 5210
    },
    {
      "epoch": 20.233009708737864,
      "grad_norm": 0.18932045996189117,
      "learning_rate": 0.0004895224477964319,
      "loss": 2.1324,
      "step": 5220
    },
    {
      "epoch": 20.271844660194176,
      "grad_norm": 0.20716409385204315,
      "learning_rate": 0.0004894781873396033,
      "loss": 2.1444,
      "step": 5230
    },
    {
      "epoch": 20.310679611650485,
      "grad_norm": 0.29992547631263733,
      "learning_rate": 0.0004894338356041543,
      "loss": 2.1318,
      "step": 5240
    },
    {
      "epoch": 20.349514563106798,
      "grad_norm": 0.2060525268316269,
      "learning_rate": 0.0004893893926069901,
      "loss": 2.128,
      "step": 5250
    },
    {
      "epoch": 20.388349514563107,
      "grad_norm": 0.19590841233730316,
      "learning_rate": 0.0004893448583650504,
      "loss": 2.124,
      "step": 5260
    },
    {
      "epoch": 20.42718446601942,
      "grad_norm": 0.2114723175764084,
      "learning_rate": 0.0004893002328953096,
      "loss": 2.1275,
      "step": 5270
    },
    {
      "epoch": 20.466019417475728,
      "grad_norm": 0.2487199604511261,
      "learning_rate": 0.0004892555162147769,
      "loss": 2.1366,
      "step": 5280
    },
    {
      "epoch": 20.50485436893204,
      "grad_norm": 0.21263961493968964,
      "learning_rate": 0.0004892107083404966,
      "loss": 2.1249,
      "step": 5290
    },
    {
      "epoch": 20.54368932038835,
      "grad_norm": 0.20080526173114777,
      "learning_rate": 0.0004891658092895474,
      "loss": 2.1328,
      "step": 5300
    },
    {
      "epoch": 20.58252427184466,
      "grad_norm": 0.21195654571056366,
      "learning_rate": 0.0004891208190790429,
      "loss": 2.1304,
      "step": 5310
    },
    {
      "epoch": 20.62135922330097,
      "grad_norm": 0.1760578602552414,
      "learning_rate": 0.0004890757377261312,
      "loss": 2.1356,
      "step": 5320
    },
    {
      "epoch": 20.660194174757283,
      "grad_norm": 0.18801864981651306,
      "learning_rate": 0.0004890305652479957,
      "loss": 2.1284,
      "step": 5330
    },
    {
      "epoch": 20.699029126213592,
      "grad_norm": 0.2070172131061554,
      "learning_rate": 0.0004889853016618536,
      "loss": 2.1341,
      "step": 5340
    },
    {
      "epoch": 20.737864077669904,
      "grad_norm": 0.17966587841510773,
      "learning_rate": 0.000488939946984958,
      "loss": 2.1351,
      "step": 5350
    },
    {
      "epoch": 20.776699029126213,
      "grad_norm": 0.1899389624595642,
      "learning_rate": 0.0004888945012345958,
      "loss": 2.1443,
      "step": 5360
    },
    {
      "epoch": 20.815533980582526,
      "grad_norm": 0.21890468895435333,
      "learning_rate": 0.0004888489644280891,
      "loss": 2.1197,
      "step": 5370
    },
    {
      "epoch": 20.854368932038835,
      "grad_norm": 0.21557506918907166,
      "learning_rate": 0.0004888033365827944,
      "loss": 2.1263,
      "step": 5380
    },
    {
      "epoch": 20.893203883495147,
      "grad_norm": 0.21822425723075867,
      "learning_rate": 0.0004887576177161031,
      "loss": 2.1475,
      "step": 5390
    },
    {
      "epoch": 20.932038834951456,
      "grad_norm": 0.2027704119682312,
      "learning_rate": 0.0004887118078454412,
      "loss": 2.1288,
      "step": 5400
    },
    {
      "epoch": 20.97087378640777,
      "grad_norm": 0.25745272636413574,
      "learning_rate": 0.0004886659069882695,
      "loss": 2.1346,
      "step": 5410
    },
    {
      "epoch": 21.0,
      "eval_loss": 1.038108229637146,
      "eval_runtime": 6.491,
      "eval_samples_per_second": 3816.361,
      "eval_steps_per_second": 14.944,
      "step": 5418
    },
    {
      "epoch": 21.007766990291262,
      "grad_norm": 0.21835635602474213,
      "learning_rate": 0.0004886199151620834,
      "loss": 2.0158,
      "step": 5420
    },
    {
      "epoch": 21.04660194174757,
      "grad_norm": 0.20434774458408356,
      "learning_rate": 0.0004885738323844128,
      "loss": 2.1294,
      "step": 5430
    },
    {
      "epoch": 21.085436893203884,
      "grad_norm": 0.23689287900924683,
      "learning_rate": 0.0004885276586728227,
      "loss": 2.125,
      "step": 5440
    },
    {
      "epoch": 21.124271844660193,
      "grad_norm": 0.2190120369195938,
      "learning_rate": 0.0004884813940449122,
      "loss": 2.1269,
      "step": 5450
    },
    {
      "epoch": 21.163106796116505,
      "grad_norm": 0.20190981030464172,
      "learning_rate": 0.0004884350385183157,
      "loss": 2.134,
      "step": 5460
    },
    {
      "epoch": 21.201941747572814,
      "grad_norm": 0.22668281197547913,
      "learning_rate": 0.0004883885921107015,
      "loss": 2.1402,
      "step": 5470
    },
    {
      "epoch": 21.240776699029126,
      "grad_norm": 0.2086094617843628,
      "learning_rate": 0.0004883420548397732,
      "loss": 2.1302,
      "step": 5480
    },
    {
      "epoch": 21.279611650485435,
      "grad_norm": 0.19683782756328583,
      "learning_rate": 0.0004882954267232688,
      "loss": 2.1391,
      "step": 5490
    },
    {
      "epoch": 21.318446601941748,
      "grad_norm": 0.19481614232063293,
      "learning_rate": 0.000488248707778961,
      "loss": 2.1374,
      "step": 5500
    },
    {
      "epoch": 21.357281553398057,
      "grad_norm": 0.29310885071754456,
      "learning_rate": 0.00048820189802465665,
      "loss": 2.1116,
      "step": 5510
    },
    {
      "epoch": 21.39611650485437,
      "grad_norm": 0.20880788564682007,
      "learning_rate": 0.00048815499747819794,
      "loss": 2.1383,
      "step": 5520
    },
    {
      "epoch": 21.434951456310678,
      "grad_norm": 0.22997908294200897,
      "learning_rate": 0.00048810800615746105,
      "loss": 2.1311,
      "step": 5530
    },
    {
      "epoch": 21.47378640776699,
      "grad_norm": 0.211921826004982,
      "learning_rate": 0.0004880609240803571,
      "loss": 2.1264,
      "step": 5540
    },
    {
      "epoch": 21.5126213592233,
      "grad_norm": 0.1865520030260086,
      "learning_rate": 0.00048801375126483184,
      "loss": 2.1327,
      "step": 5550
    },
    {
      "epoch": 21.55145631067961,
      "grad_norm": 0.20303493738174438,
      "learning_rate": 0.0004879664877288653,
      "loss": 2.1167,
      "step": 5560
    },
    {
      "epoch": 21.59029126213592,
      "grad_norm": 0.19921956956386566,
      "learning_rate": 0.00048791913349047243,
      "loss": 2.1338,
      "step": 5570
    },
    {
      "epoch": 21.629126213592233,
      "grad_norm": 0.2260795384645462,
      "learning_rate": 0.0004878716885677026,
      "loss": 2.1302,
      "step": 5580
    },
    {
      "epoch": 21.667961165048542,
      "grad_norm": 0.221516951918602,
      "learning_rate": 0.00048782415297863956,
      "loss": 2.142,
      "step": 5590
    },
    {
      "epoch": 21.706796116504854,
      "grad_norm": 0.19601477682590485,
      "learning_rate": 0.00048777652674140195,
      "loss": 2.1546,
      "step": 5600
    },
    {
      "epoch": 21.745631067961163,
      "grad_norm": 0.19842173159122467,
      "learning_rate": 0.00048772880987414284,
      "loss": 2.1198,
      "step": 5610
    },
    {
      "epoch": 21.784466019417476,
      "grad_norm": 0.20162488520145416,
      "learning_rate": 0.00048768100239504966,
      "loss": 2.1176,
      "step": 5620
    },
    {
      "epoch": 21.823300970873788,
      "grad_norm": 0.19566690921783447,
      "learning_rate": 0.00048763310432234467,
      "loss": 2.1332,
      "step": 5630
    },
    {
      "epoch": 21.862135922330097,
      "grad_norm": 0.19350117444992065,
      "learning_rate": 0.00048758511567428446,
      "loss": 2.1188,
      "step": 5640
    },
    {
      "epoch": 21.900970873786406,
      "grad_norm": 0.21599888801574707,
      "learning_rate": 0.0004875370364691601,
      "loss": 2.1388,
      "step": 5650
    },
    {
      "epoch": 21.93980582524272,
      "grad_norm": 0.23130159080028534,
      "learning_rate": 0.00048748886672529755,
      "loss": 2.13,
      "step": 5660
    },
    {
      "epoch": 21.97864077669903,
      "grad_norm": 0.20087549090385437,
      "learning_rate": 0.00048744060646105695,
      "loss": 2.1356,
      "step": 5670
    },
    {
      "epoch": 22.0,
      "eval_loss": 1.0374438762664795,
      "eval_runtime": 6.5297,
      "eval_samples_per_second": 3793.723,
      "eval_steps_per_second": 14.855,
      "step": 5676
    },
    {
      "epoch": 22.015533980582525,
      "grad_norm": 0.2207987755537033,
      "learning_rate": 0.0004873922556948328,
      "loss": 2.0229,
      "step": 5680
    },
    {
      "epoch": 22.054368932038834,
      "grad_norm": 0.20092466473579407,
      "learning_rate": 0.00048734381444505437,
      "loss": 2.1414,
      "step": 5690
    },
    {
      "epoch": 22.093203883495146,
      "grad_norm": 0.2383486032485962,
      "learning_rate": 0.0004872952827301854,
      "loss": 2.1262,
      "step": 5700
    },
    {
      "epoch": 22.132038834951455,
      "grad_norm": 0.2334337830543518,
      "learning_rate": 0.0004872466605687241,
      "loss": 2.1408,
      "step": 5710
    },
    {
      "epoch": 22.170873786407768,
      "grad_norm": 0.22272594273090363,
      "learning_rate": 0.0004871979479792031,
      "loss": 2.123,
      "step": 5720
    },
    {
      "epoch": 22.209708737864077,
      "grad_norm": 0.21514347195625305,
      "learning_rate": 0.0004871491449801894,
      "loss": 2.1167,
      "step": 5730
    },
    {
      "epoch": 22.24854368932039,
      "grad_norm": 0.22956256568431854,
      "learning_rate": 0.0004871002515902847,
      "loss": 2.1346,
      "step": 5740
    },
    {
      "epoch": 22.287378640776698,
      "grad_norm": 0.2342316210269928,
      "learning_rate": 0.000487051267828125,
      "loss": 2.1279,
      "step": 5750
    },
    {
      "epoch": 22.32621359223301,
      "grad_norm": 0.22841335833072662,
      "learning_rate": 0.00048700219371238066,
      "loss": 2.1298,
      "step": 5760
    },
    {
      "epoch": 22.36504854368932,
      "grad_norm": 0.2472902536392212,
      "learning_rate": 0.00048695302926175674,
      "loss": 2.1324,
      "step": 5770
    },
    {
      "epoch": 22.40388349514563,
      "grad_norm": 0.20154288411140442,
      "learning_rate": 0.00048690377449499246,
      "loss": 2.1166,
      "step": 5780
    },
    {
      "epoch": 22.44271844660194,
      "grad_norm": 0.2351405769586563,
      "learning_rate": 0.0004868544294308617,
      "loss": 2.1158,
      "step": 5790
    },
    {
      "epoch": 22.481553398058253,
      "grad_norm": 0.2201341986656189,
      "learning_rate": 0.0004868049940881725,
      "loss": 2.1282,
      "step": 5800
    },
    {
      "epoch": 22.520388349514562,
      "grad_norm": 0.20142921805381775,
      "learning_rate": 0.0004867554684857675,
      "loss": 2.1219,
      "step": 5810
    },
    {
      "epoch": 22.559223300970874,
      "grad_norm": 0.2487616091966629,
      "learning_rate": 0.00048670585264252373,
      "loss": 2.123,
      "step": 5820
    },
    {
      "epoch": 22.598058252427183,
      "grad_norm": 0.22738881409168243,
      "learning_rate": 0.0004866561465773527,
      "loss": 2.1168,
      "step": 5830
    },
    {
      "epoch": 22.636893203883496,
      "grad_norm": 0.25996893644332886,
      "learning_rate": 0.0004866063503092,
      "loss": 2.1302,
      "step": 5840
    },
    {
      "epoch": 22.675728155339804,
      "grad_norm": 0.21724756062030792,
      "learning_rate": 0.00048655646385704584,
      "loss": 2.1271,
      "step": 5850
    },
    {
      "epoch": 22.714563106796117,
      "grad_norm": 0.21022410690784454,
      "learning_rate": 0.0004865064872399048,
      "loss": 2.1177,
      "step": 5860
    },
    {
      "epoch": 22.753398058252426,
      "grad_norm": 0.2229597270488739,
      "learning_rate": 0.0004864564204768257,
      "loss": 2.1395,
      "step": 5870
    },
    {
      "epoch": 22.792233009708738,
      "grad_norm": 0.24214570224285126,
      "learning_rate": 0.0004864062635868919,
      "loss": 2.1234,
      "step": 5880
    },
    {
      "epoch": 22.831067961165047,
      "grad_norm": 0.21356339752674103,
      "learning_rate": 0.00048635601658922095,
      "loss": 2.1261,
      "step": 5890
    },
    {
      "epoch": 22.86990291262136,
      "grad_norm": 0.25106823444366455,
      "learning_rate": 0.00048630567950296483,
      "loss": 2.1304,
      "step": 5900
    },
    {
      "epoch": 22.90873786407767,
      "grad_norm": 0.2454981803894043,
      "learning_rate": 0.0004862552523473099,
      "loss": 2.1258,
      "step": 5910
    },
    {
      "epoch": 22.94757281553398,
      "grad_norm": 0.1923690289258957,
      "learning_rate": 0.0004862047351414767,
      "loss": 2.1428,
      "step": 5920
    },
    {
      "epoch": 22.98640776699029,
      "grad_norm": 0.216694176197052,
      "learning_rate": 0.0004861541279047201,
      "loss": 2.1333,
      "step": 5930
    },
    {
      "epoch": 23.0,
      "eval_loss": 1.0368727445602417,
      "eval_runtime": 6.5035,
      "eval_samples_per_second": 3809.006,
      "eval_steps_per_second": 14.915,
      "step": 5934
    },
    {
      "epoch": 23.023300970873787,
      "grad_norm": 0.21078133583068848,
      "learning_rate": 0.0004861034306563296,
      "loss": 2.0276,
      "step": 5940
    },
    {
      "epoch": 23.062135922330096,
      "grad_norm": 0.2483409196138382,
      "learning_rate": 0.0004860526434156286,
      "loss": 2.1279,
      "step": 5950
    },
    {
      "epoch": 23.10097087378641,
      "grad_norm": 0.21255578100681305,
      "learning_rate": 0.00048600176620197514,
      "loss": 2.1222,
      "step": 5960
    },
    {
      "epoch": 23.139805825242718,
      "grad_norm": 0.2233491986989975,
      "learning_rate": 0.0004859507990347611,
      "loss": 2.1234,
      "step": 5970
    },
    {
      "epoch": 23.17864077669903,
      "grad_norm": 0.24843212962150574,
      "learning_rate": 0.00048589974193341323,
      "loss": 2.1288,
      "step": 5980
    },
    {
      "epoch": 23.21747572815534,
      "grad_norm": 0.20617753267288208,
      "learning_rate": 0.0004858485949173921,
      "loss": 2.1264,
      "step": 5990
    },
    {
      "epoch": 23.25631067961165,
      "grad_norm": 0.21724167466163635,
      "learning_rate": 0.0004857973580061928,
      "loss": 2.1313,
      "step": 6000
    },
    {
      "epoch": 23.29514563106796,
      "grad_norm": 0.21773894131183624,
      "learning_rate": 0.00048574603121934455,
      "loss": 2.13,
      "step": 6010
    },
    {
      "epoch": 23.333980582524273,
      "grad_norm": 0.20577096939086914,
      "learning_rate": 0.000485694614576411,
      "loss": 2.1363,
      "step": 6020
    },
    {
      "epoch": 23.37281553398058,
      "grad_norm": 0.22226199507713318,
      "learning_rate": 0.00048564310809698965,
      "loss": 2.1281,
      "step": 6030
    },
    {
      "epoch": 23.411650485436894,
      "grad_norm": 0.22457663714885712,
      "learning_rate": 0.0004855915118007128,
      "loss": 2.1231,
      "step": 6040
    },
    {
      "epoch": 23.450485436893203,
      "grad_norm": 0.20070534944534302,
      "learning_rate": 0.0004855398257072466,
      "loss": 2.1324,
      "step": 6050
    },
    {
      "epoch": 23.489320388349515,
      "grad_norm": 0.21482963860034943,
      "learning_rate": 0.00048548804983629146,
      "loss": 2.1161,
      "step": 6060
    },
    {
      "epoch": 23.528155339805824,
      "grad_norm": 0.22595398128032684,
      "learning_rate": 0.0004854361842075823,
      "loss": 2.1441,
      "step": 6070
    },
    {
      "epoch": 23.566990291262137,
      "grad_norm": 0.23873242735862732,
      "learning_rate": 0.00048538422884088775,
      "loss": 2.1136,
      "step": 6080
    },
    {
      "epoch": 23.605825242718446,
      "grad_norm": 0.2182067483663559,
      "learning_rate": 0.00048533218375601105,
      "loss": 2.1168,
      "step": 6090
    },
    {
      "epoch": 23.644660194174758,
      "grad_norm": 0.24294409155845642,
      "learning_rate": 0.00048528004897278957,
      "loss": 2.1403,
      "step": 6100
    },
    {
      "epoch": 23.683495145631067,
      "grad_norm": 0.23357687890529633,
      "learning_rate": 0.0004852278245110948,
      "loss": 2.1078,
      "step": 6110
    },
    {
      "epoch": 23.72233009708738,
      "grad_norm": 0.24926091730594635,
      "learning_rate": 0.0004851755103908323,
      "loss": 2.1247,
      "step": 6120
    },
    {
      "epoch": 23.76116504854369,
      "grad_norm": 0.2647637128829956,
      "learning_rate": 0.00048512310663194206,
      "loss": 2.1217,
      "step": 6130
    },
    {
      "epoch": 23.8,
      "grad_norm": 0.2659265398979187,
      "learning_rate": 0.000485070613254398,
      "loss": 2.1355,
      "step": 6140
    },
    {
      "epoch": 23.83883495145631,
      "grad_norm": 0.21444159746170044,
      "learning_rate": 0.00048501803027820836,
      "loss": 2.1224,
      "step": 6150
    },
    {
      "epoch": 23.877669902912622,
      "grad_norm": 0.2275848537683487,
      "learning_rate": 0.00048496535772341547,
      "loss": 2.1176,
      "step": 6160
    },
    {
      "epoch": 23.91650485436893,
      "grad_norm": 0.23103225231170654,
      "learning_rate": 0.0004849125956100958,
      "loss": 2.1168,
      "step": 6170
    },
    {
      "epoch": 23.955339805825243,
      "grad_norm": 0.2461363524198532,
      "learning_rate": 0.00048485974395836,
      "loss": 2.1248,
      "step": 6180
    },
    {
      "epoch": 23.994174757281552,
      "grad_norm": 0.2585897147655487,
      "learning_rate": 0.0004848068027883528,
      "loss": 2.1145,
      "step": 6190
    },
    {
      "epoch": 24.0,
      "eval_loss": 1.0362845659255981,
      "eval_runtime": 6.5168,
      "eval_samples_per_second": 3801.231,
      "eval_steps_per_second": 14.885,
      "step": 6192
    },
    {
      "epoch": 24.03106796116505,
      "grad_norm": 0.2637539803981781,
      "learning_rate": 0.000484753772120253,
      "loss": 2.026,
      "step": 6200
    },
    {
      "epoch": 24.06990291262136,
      "grad_norm": 0.23564858734607697,
      "learning_rate": 0.0004847006519742736,
      "loss": 2.1249,
      "step": 6210
    },
    {
      "epoch": 24.10873786407767,
      "grad_norm": 0.2716013193130493,
      "learning_rate": 0.00048464744237066164,
      "loss": 2.1193,
      "step": 6220
    },
    {
      "epoch": 24.14757281553398,
      "grad_norm": 0.26475274562835693,
      "learning_rate": 0.0004845941433296984,
      "loss": 2.1142,
      "step": 6230
    },
    {
      "epoch": 24.186407766990293,
      "grad_norm": 0.20879292488098145,
      "learning_rate": 0.0004845407548716991,
      "loss": 2.124,
      "step": 6240
    },
    {
      "epoch": 24.2252427184466,
      "grad_norm": 0.2323063462972641,
      "learning_rate": 0.00048448727701701303,
      "loss": 2.1233,
      "step": 6250
    },
    {
      "epoch": 24.264077669902914,
      "grad_norm": 0.25413453578948975,
      "learning_rate": 0.00048443370978602367,
      "loss": 2.1025,
      "step": 6260
    },
    {
      "epoch": 24.302912621359223,
      "grad_norm": 0.24257637560367584,
      "learning_rate": 0.0004843800531991485,
      "loss": 2.1238,
      "step": 6270
    },
    {
      "epoch": 24.341747572815535,
      "grad_norm": 0.2549440264701843,
      "learning_rate": 0.00048432630727683905,
      "loss": 2.1243,
      "step": 6280
    },
    {
      "epoch": 24.380582524271844,
      "grad_norm": 0.24209381639957428,
      "learning_rate": 0.000484272472039581,
      "loss": 2.1305,
      "step": 6290
    },
    {
      "epoch": 24.419417475728157,
      "grad_norm": 0.24546131491661072,
      "learning_rate": 0.00048421854750789386,
      "loss": 2.1329,
      "step": 6300
    },
    {
      "epoch": 24.458252427184465,
      "grad_norm": 0.2876031696796417,
      "learning_rate": 0.0004841645337023313,
      "loss": 2.1098,
      "step": 6310
    },
    {
      "epoch": 24.497087378640778,
      "grad_norm": 0.28052178025245667,
      "learning_rate": 0.00048411043064348116,
      "loss": 2.1285,
      "step": 6320
    },
    {
      "epoch": 24.535922330097087,
      "grad_norm": 0.22771479189395905,
      "learning_rate": 0.000484056238351965,
      "loss": 2.13,
      "step": 6330
    },
    {
      "epoch": 24.5747572815534,
      "grad_norm": 0.22451792657375336,
      "learning_rate": 0.0004840019568484387,
      "loss": 2.1328,
      "step": 6340
    },
    {
      "epoch": 24.613592233009708,
      "grad_norm": 0.25506317615509033,
      "learning_rate": 0.000483947586153592,
      "loss": 2.133,
      "step": 6350
    },
    {
      "epoch": 24.65242718446602,
      "grad_norm": 0.2342844158411026,
      "learning_rate": 0.0004838931262881485,
      "loss": 2.1147,
      "step": 6360
    },
    {
      "epoch": 24.69126213592233,
      "grad_norm": 0.214119553565979,
      "learning_rate": 0.00048383857727286595,
      "loss": 2.1294,
      "step": 6370
    },
    {
      "epoch": 24.730097087378642,
      "grad_norm": 0.2032831609249115,
      "learning_rate": 0.00048378393912853617,
      "loss": 2.1165,
      "step": 6380
    },
    {
      "epoch": 24.76893203883495,
      "grad_norm": 0.2564980685710907,
      "learning_rate": 0.0004837292118759847,
      "loss": 2.1258,
      "step": 6390
    },
    {
      "epoch": 24.807766990291263,
      "grad_norm": 0.26391303539276123,
      "learning_rate": 0.0004836743955360713,
      "loss": 2.1182,
      "step": 6400
    },
    {
      "epoch": 24.846601941747572,
      "grad_norm": 0.3030546307563782,
      "learning_rate": 0.0004836194901296894,
      "loss": 2.1261,
      "step": 6410
    },
    {
      "epoch": 24.885436893203885,
      "grad_norm": 0.21749535202980042,
      "learning_rate": 0.0004835644956777667,
      "loss": 2.1319,
      "step": 6420
    },
    {
      "epoch": 24.924271844660193,
      "grad_norm": 0.22822166979312897,
      "learning_rate": 0.0004835094122012647,
      "loss": 2.1353,
      "step": 6430
    },
    {
      "epoch": 24.963106796116506,
      "grad_norm": 0.23535658419132233,
      "learning_rate": 0.0004834542397211786,
      "loss": 2.1282,
      "step": 6440
    },
    {
      "epoch": 25.0,
      "grad_norm": 0.171991765499115,
      "learning_rate": 0.0004833989782585379,
      "loss": 2.0178,
      "step": 6450
    },
    {
      "epoch": 25.0,
      "eval_loss": 1.0363308191299438,
      "eval_runtime": 6.7067,
      "eval_samples_per_second": 3693.631,
      "eval_steps_per_second": 14.463,
      "step": 6450
    },
    {
      "epoch": 25.038834951456312,
      "grad_norm": 0.2549017667770386,
      "learning_rate": 0.00048334362783440584,
      "loss": 2.1184,
      "step": 6460
    },
    {
      "epoch": 25.07766990291262,
      "grad_norm": 0.24038785696029663,
      "learning_rate": 0.0004832881884698795,
      "loss": 2.1069,
      "step": 6470
    },
    {
      "epoch": 25.116504854368934,
      "grad_norm": 0.3604862689971924,
      "learning_rate": 0.00048323266018609015,
      "loss": 2.1163,
      "step": 6480
    },
    {
      "epoch": 25.155339805825243,
      "grad_norm": 0.2757375240325928,
      "learning_rate": 0.0004831770430042025,
      "loss": 2.1179,
      "step": 6490
    },
    {
      "epoch": 25.194174757281555,
      "grad_norm": 0.23690523207187653,
      "learning_rate": 0.00048312133694541556,
      "loss": 2.1128,
      "step": 6500
    },
    {
      "epoch": 25.233009708737864,
      "grad_norm": 0.22138884663581848,
      "learning_rate": 0.0004830655420309619,
      "loss": 2.1273,
      "step": 6510
    },
    {
      "epoch": 25.271844660194176,
      "grad_norm": 0.23151782155036926,
      "learning_rate": 0.0004830096582821083,
      "loss": 2.1122,
      "step": 6520
    },
    {
      "epoch": 25.310679611650485,
      "grad_norm": 0.2141461968421936,
      "learning_rate": 0.00048295368572015497,
      "loss": 2.1278,
      "step": 6530
    },
    {
      "epoch": 25.349514563106798,
      "grad_norm": 0.20785118639469147,
      "learning_rate": 0.00048289762436643635,
      "loss": 2.1254,
      "step": 6540
    },
    {
      "epoch": 25.388349514563107,
      "grad_norm": 0.22869379818439484,
      "learning_rate": 0.0004828414742423206,
      "loss": 2.1181,
      "step": 6550
    },
    {
      "epoch": 25.42718446601942,
      "grad_norm": 0.2319951355457306,
      "learning_rate": 0.00048278523536920964,
      "loss": 2.1172,
      "step": 6560
    },
    {
      "epoch": 25.466019417475728,
      "grad_norm": 0.26129981875419617,
      "learning_rate": 0.0004827289077685393,
      "loss": 2.1388,
      "step": 6570
    },
    {
      "epoch": 25.50485436893204,
      "grad_norm": 0.20543557405471802,
      "learning_rate": 0.0004826724914617791,
      "loss": 2.1249,
      "step": 6580
    },
    {
      "epoch": 25.54368932038835,
      "grad_norm": 0.21156661212444305,
      "learning_rate": 0.00048261598647043256,
      "loss": 2.1221,
      "step": 6590
    },
    {
      "epoch": 25.58252427184466,
      "grad_norm": 0.2528868615627289,
      "learning_rate": 0.00048255939281603694,
      "loss": 2.124,
      "step": 6600
    },
    {
      "epoch": 25.62135922330097,
      "grad_norm": 0.24718542397022247,
      "learning_rate": 0.0004825027105201632,
      "loss": 2.1296,
      "step": 6610
    },
    {
      "epoch": 25.660194174757283,
      "grad_norm": 0.2603117823600769,
      "learning_rate": 0.0004824459396044162,
      "loss": 2.1131,
      "step": 6620
    },
    {
      "epoch": 25.699029126213592,
      "grad_norm": 0.2372705191373825,
      "learning_rate": 0.00048238908009043445,
      "loss": 2.1333,
      "step": 6630
    },
    {
      "epoch": 25.737864077669904,
      "grad_norm": 0.22598759829998016,
      "learning_rate": 0.00048233213199989043,
      "loss": 2.1278,
      "step": 6640
    },
    {
      "epoch": 25.776699029126213,
      "grad_norm": 0.25961822271347046,
      "learning_rate": 0.00048227509535449025,
      "loss": 2.1157,
      "step": 6650
    },
    {
      "epoch": 25.815533980582526,
      "grad_norm": 0.389735609292984,
      "learning_rate": 0.0004822179701759737,
      "loss": 2.1222,
      "step": 6660
    },
    {
      "epoch": 25.854368932038835,
      "grad_norm": 0.2229417860507965,
      "learning_rate": 0.00048216075648611445,
      "loss": 2.1136,
      "step": 6670
    },
    {
      "epoch": 25.893203883495147,
      "grad_norm": 0.21973121166229248,
      "learning_rate": 0.00048210345430671985,
      "loss": 2.1268,
      "step": 6680
    },
    {
      "epoch": 25.932038834951456,
      "grad_norm": 0.22223438322544098,
      "learning_rate": 0.00048204606365963103,
      "loss": 2.1142,
      "step": 6690
    },
    {
      "epoch": 25.97087378640777,
      "grad_norm": 0.21917162835597992,
      "learning_rate": 0.0004819885845667228,
      "loss": 2.1141,
      "step": 6700
    },
    {
      "epoch": 26.0,
      "eval_loss": 1.034741997718811,
      "eval_runtime": 6.53,
      "eval_samples_per_second": 3793.581,
      "eval_steps_per_second": 14.855,
      "step": 6708
    },
    {
      "epoch": 26.007766990291262,
      "grad_norm": 0.24883756041526794,
      "learning_rate": 0.00048193101704990354,
      "loss": 2.0137,
      "step": 6710
    },
    {
      "epoch": 26.04660194174757,
      "grad_norm": 0.2199232578277588,
      "learning_rate": 0.00048187336113111564,
      "loss": 2.1183,
      "step": 6720
    },
    {
      "epoch": 26.085436893203884,
      "grad_norm": 0.41718897223472595,
      "learning_rate": 0.0004818156168323349,
      "loss": 2.1224,
      "step": 6730
    },
    {
      "epoch": 26.124271844660193,
      "grad_norm": 0.24148358404636383,
      "learning_rate": 0.00048175778417557097,
      "loss": 2.1212,
      "step": 6740
    },
    {
      "epoch": 26.163106796116505,
      "grad_norm": 0.26215457916259766,
      "learning_rate": 0.0004816998631828672,
      "loss": 2.1078,
      "step": 6750
    },
    {
      "epoch": 26.201941747572814,
      "grad_norm": 0.22097568213939667,
      "learning_rate": 0.0004816418538763004,
      "loss": 2.1264,
      "step": 6760
    },
    {
      "epoch": 26.240776699029126,
      "grad_norm": 0.24831777811050415,
      "learning_rate": 0.00048158375627798127,
      "loss": 2.1069,
      "step": 6770
    },
    {
      "epoch": 26.279611650485435,
      "grad_norm": 0.2299487590789795,
      "learning_rate": 0.00048152557041005405,
      "loss": 2.1114,
      "step": 6780
    },
    {
      "epoch": 26.318446601941748,
      "grad_norm": 0.24377332627773285,
      "learning_rate": 0.00048146729629469675,
      "loss": 2.1103,
      "step": 6790
    },
    {
      "epoch": 26.357281553398057,
      "grad_norm": 0.2276468724012375,
      "learning_rate": 0.00048140893395412076,
      "loss": 2.1345,
      "step": 6800
    },
    {
      "epoch": 26.39611650485437,
      "grad_norm": 0.29106348752975464,
      "learning_rate": 0.0004813504834105713,
      "loss": 2.1234,
      "step": 6810
    },
    {
      "epoch": 26.434951456310678,
      "grad_norm": 0.24739724397659302,
      "learning_rate": 0.0004812919446863272,
      "loss": 2.1244,
      "step": 6820
    },
    {
      "epoch": 26.47378640776699,
      "grad_norm": 0.24090063571929932,
      "learning_rate": 0.0004812333178037009,
      "loss": 2.1143,
      "step": 6830
    },
    {
      "epoch": 26.5126213592233,
      "grad_norm": 0.2884186804294586,
      "learning_rate": 0.0004811746027850383,
      "loss": 2.1194,
      "step": 6840
    },
    {
      "epoch": 26.55145631067961,
      "grad_norm": 0.2738790214061737,
      "learning_rate": 0.0004811157996527191,
      "loss": 2.133,
      "step": 6850
    },
    {
      "epoch": 26.59029126213592,
      "grad_norm": 0.23111554980278015,
      "learning_rate": 0.0004810569084291564,
      "loss": 2.1086,
      "step": 6860
    },
    {
      "epoch": 26.629126213592233,
      "grad_norm": 0.2963479161262512,
      "learning_rate": 0.000480997929136797,
      "loss": 2.1292,
      "step": 6870
    },
    {
      "epoch": 26.667961165048542,
      "grad_norm": 0.23385460674762726,
      "learning_rate": 0.0004809388617981213,
      "loss": 2.1034,
      "step": 6880
    },
    {
      "epoch": 26.706796116504854,
      "grad_norm": 0.23180092871189117,
      "learning_rate": 0.00048087970643564303,
      "loss": 2.1067,
      "step": 6890
    },
    {
      "epoch": 26.745631067961163,
      "grad_norm": 0.29147374629974365,
      "learning_rate": 0.0004808204630719097,
      "loss": 2.1325,
      "step": 6900
    },
    {
      "epoch": 26.784466019417476,
      "grad_norm": 0.2212766706943512,
      "learning_rate": 0.00048076113172950243,
      "loss": 2.1264,
      "step": 6910
    },
    {
      "epoch": 26.823300970873788,
      "grad_norm": 0.2220757007598877,
      "learning_rate": 0.00048070171243103554,
      "loss": 2.1118,
      "step": 6920
    },
    {
      "epoch": 26.862135922330097,
      "grad_norm": 0.23426347970962524,
      "learning_rate": 0.00048064220519915713,
      "loss": 2.1199,
      "step": 6930
    },
    {
      "epoch": 26.900970873786406,
      "grad_norm": 0.25369343161582947,
      "learning_rate": 0.0004805826100565488,
      "loss": 2.1115,
      "step": 6940
    },
    {
      "epoch": 26.93980582524272,
      "grad_norm": 0.22036118805408478,
      "learning_rate": 0.0004805229270259256,
      "loss": 2.118,
      "step": 6950
    },
    {
      "epoch": 26.97864077669903,
      "grad_norm": 0.2221895456314087,
      "learning_rate": 0.000480463156130036,
      "loss": 2.1305,
      "step": 6960
    },
    {
      "epoch": 27.0,
      "eval_loss": 1.0347535610198975,
      "eval_runtime": 6.5148,
      "eval_samples_per_second": 3802.411,
      "eval_steps_per_second": 14.889,
      "step": 6966
    },
    {
      "epoch": 27.015533980582525,
      "grad_norm": 0.2477295845746994,
      "learning_rate": 0.0004804032973916622,
      "loss": 2.0029,
      "step": 6970
    },
    {
      "epoch": 27.054368932038834,
      "grad_norm": 0.19045652449131012,
      "learning_rate": 0.00048034335083361963,
      "loss": 2.1165,
      "step": 6980
    },
    {
      "epoch": 27.093203883495146,
      "grad_norm": 0.2630230784416199,
      "learning_rate": 0.00048028331647875734,
      "loss": 2.1185,
      "step": 6990
    },
    {
      "epoch": 27.132038834951455,
      "grad_norm": 0.32540908455848694,
      "learning_rate": 0.00048022319434995784,
      "loss": 2.1157,
      "step": 7000
    },
    {
      "epoch": 27.170873786407768,
      "grad_norm": 0.23479445278644562,
      "learning_rate": 0.00048016298447013694,
      "loss": 2.1303,
      "step": 7010
    },
    {
      "epoch": 27.209708737864077,
      "grad_norm": 0.23368781805038452,
      "learning_rate": 0.0004801026868622441,
      "loss": 2.1154,
      "step": 7020
    },
    {
      "epoch": 27.24854368932039,
      "grad_norm": 0.2747795581817627,
      "learning_rate": 0.0004800423015492622,
      "loss": 2.1184,
      "step": 7030
    },
    {
      "epoch": 27.287378640776698,
      "grad_norm": 0.22013522684574127,
      "learning_rate": 0.0004799818285542074,
      "loss": 2.1158,
      "step": 7040
    },
    {
      "epoch": 27.32621359223301,
      "grad_norm": 0.2357051521539688,
      "learning_rate": 0.00047992126790012923,
      "loss": 2.1082,
      "step": 7050
    },
    {
      "epoch": 27.36504854368932,
      "grad_norm": 0.2480444759130478,
      "learning_rate": 0.0004798606196101111,
      "loss": 2.117,
      "step": 7060
    },
    {
      "epoch": 27.40388349514563,
      "grad_norm": 0.2806618809700012,
      "learning_rate": 0.00047979988370726914,
      "loss": 2.115,
      "step": 7070
    },
    {
      "epoch": 27.44271844660194,
      "grad_norm": 0.2338377684354782,
      "learning_rate": 0.00047973906021475345,
      "loss": 2.134,
      "step": 7080
    },
    {
      "epoch": 27.481553398058253,
      "grad_norm": 0.24352800846099854,
      "learning_rate": 0.0004796781491557472,
      "loss": 2.1182,
      "step": 7090
    },
    {
      "epoch": 27.520388349514562,
      "grad_norm": 0.28354647755622864,
      "learning_rate": 0.000479617150553467,
      "loss": 2.1115,
      "step": 7100
    },
    {
      "epoch": 27.559223300970874,
      "grad_norm": 0.31171754002571106,
      "learning_rate": 0.00047955606443116295,
      "loss": 2.1202,
      "step": 7110
    },
    {
      "epoch": 27.598058252427183,
      "grad_norm": 0.4722355902194977,
      "learning_rate": 0.00047949489081211826,
      "loss": 2.115,
      "step": 7120
    },
    {
      "epoch": 27.636893203883496,
      "grad_norm": 0.27067330479621887,
      "learning_rate": 0.0004794336297196498,
      "loss": 2.1217,
      "step": 7130
    },
    {
      "epoch": 27.675728155339804,
      "grad_norm": 0.27552664279937744,
      "learning_rate": 0.0004793722811771075,
      "loss": 2.117,
      "step": 7140
    },
    {
      "epoch": 27.714563106796117,
      "grad_norm": 0.22515615820884705,
      "learning_rate": 0.00047931084520787487,
      "loss": 2.1258,
      "step": 7150
    },
    {
      "epoch": 27.753398058252426,
      "grad_norm": 0.35737794637680054,
      "learning_rate": 0.00047924932183536853,
      "loss": 2.0929,
      "step": 7160
    },
    {
      "epoch": 27.792233009708738,
      "grad_norm": 0.24825775623321533,
      "learning_rate": 0.00047918771108303843,
      "loss": 2.1302,
      "step": 7170
    },
    {
      "epoch": 27.831067961165047,
      "grad_norm": 0.22009006142616272,
      "learning_rate": 0.000479126012974368,
      "loss": 2.1293,
      "step": 7180
    },
    {
      "epoch": 27.86990291262136,
      "grad_norm": 0.27319279313087463,
      "learning_rate": 0.0004790642275328739,
      "loss": 2.1274,
      "step": 7190
    },
    {
      "epoch": 27.90873786407767,
      "grad_norm": 0.26662370562553406,
      "learning_rate": 0.00047900235478210595,
      "loss": 2.0998,
      "step": 7200
    },
    {
      "epoch": 27.94757281553398,
      "grad_norm": 0.2471940964460373,
      "learning_rate": 0.0004789403947456474,
      "loss": 2.135,
      "step": 7210
    },
    {
      "epoch": 27.98640776699029,
      "grad_norm": 0.26138779520988464,
      "learning_rate": 0.0004788783474471146,
      "loss": 2.1142,
      "step": 7220
    },
    {
      "epoch": 28.0,
      "eval_loss": 1.0352071523666382,
      "eval_runtime": 6.5567,
      "eval_samples_per_second": 3778.127,
      "eval_steps_per_second": 14.794,
      "step": 7224
    },
    {
      "epoch": 28.023300970873787,
      "grad_norm": 0.26944929361343384,
      "learning_rate": 0.0004788162129101574,
      "loss": 1.9949,
      "step": 7230
    },
    {
      "epoch": 28.062135922330096,
      "grad_norm": 0.2692507803440094,
      "learning_rate": 0.00047875399115845875,
      "loss": 2.1047,
      "step": 7240
    },
    {
      "epoch": 28.10097087378641,
      "grad_norm": 0.31866922974586487,
      "learning_rate": 0.0004786916822157348,
      "loss": 2.1077,
      "step": 7250
    },
    {
      "epoch": 28.139805825242718,
      "grad_norm": 0.2771441638469696,
      "learning_rate": 0.00047862928610573497,
      "loss": 2.1114,
      "step": 7260
    },
    {
      "epoch": 28.17864077669903,
      "grad_norm": 0.31598109006881714,
      "learning_rate": 0.0004785668028522421,
      "loss": 2.1132,
      "step": 7270
    },
    {
      "epoch": 28.21747572815534,
      "grad_norm": 0.26160162687301636,
      "learning_rate": 0.00047850423247907184,
      "loss": 2.0974,
      "step": 7280
    },
    {
      "epoch": 28.25631067961165,
      "grad_norm": 0.2654629349708557,
      "learning_rate": 0.0004784415750100735,
      "loss": 2.1031,
      "step": 7290
    },
    {
      "epoch": 28.29514563106796,
      "grad_norm": 0.4944517910480499,
      "learning_rate": 0.00047837883046912924,
      "loss": 2.1197,
      "step": 7300
    },
    {
      "epoch": 28.333980582524273,
      "grad_norm": 0.3041837215423584,
      "learning_rate": 0.0004783159988801545,
      "loss": 2.1321,
      "step": 7310
    },
    {
      "epoch": 28.37281553398058,
      "grad_norm": 0.2852672040462494,
      "learning_rate": 0.00047825308026709813,
      "loss": 2.1275,
      "step": 7320
    },
    {
      "epoch": 28.411650485436894,
      "grad_norm": 0.28087854385375977,
      "learning_rate": 0.0004781900746539417,
      "loss": 2.1072,
      "step": 7330
    },
    {
      "epoch": 28.450485436893203,
      "grad_norm": 0.2226320505142212,
      "learning_rate": 0.00047812698206470044,
      "loss": 2.1155,
      "step": 7340
    },
    {
      "epoch": 28.489320388349515,
      "grad_norm": 0.4225846230983734,
      "learning_rate": 0.00047806380252342237,
      "loss": 2.1066,
      "step": 7350
    },
    {
      "epoch": 28.528155339805824,
      "grad_norm": 0.396513968706131,
      "learning_rate": 0.0004780005360541887,
      "loss": 2.1363,
      "step": 7360
    },
    {
      "epoch": 28.566990291262137,
      "grad_norm": 0.31819403171539307,
      "learning_rate": 0.00047793718268111394,
      "loss": 2.1188,
      "step": 7370
    },
    {
      "epoch": 28.605825242718446,
      "grad_norm": 0.27161139249801636,
      "learning_rate": 0.0004778737424283457,
      "loss": 2.104,
      "step": 7380
    },
    {
      "epoch": 28.644660194174758,
      "grad_norm": 0.2832176685333252,
      "learning_rate": 0.0004778102153200645,
      "loss": 2.104,
      "step": 7390
    },
    {
      "epoch": 28.683495145631067,
      "grad_norm": 0.26776570081710815,
      "learning_rate": 0.00047774660138048407,
      "loss": 2.1262,
      "step": 7400
    },
    {
      "epoch": 28.72233009708738,
      "grad_norm": 0.25761452317237854,
      "learning_rate": 0.00047768290063385146,
      "loss": 2.1292,
      "step": 7410
    },
    {
      "epoch": 28.76116504854369,
      "grad_norm": 0.3000250458717346,
      "learning_rate": 0.00047761911310444636,
      "loss": 2.1122,
      "step": 7420
    },
    {
      "epoch": 28.8,
      "grad_norm": 0.29219943284988403,
      "learning_rate": 0.00047755523881658197,
      "loss": 2.1204,
      "step": 7430
    },
    {
      "epoch": 28.83883495145631,
      "grad_norm": 0.2948637008666992,
      "learning_rate": 0.00047749127779460435,
      "loss": 2.1072,
      "step": 7440
    },
    {
      "epoch": 28.877669902912622,
      "grad_norm": 0.28648754954338074,
      "learning_rate": 0.00047742723006289256,
      "loss": 2.1161,
      "step": 7450
    },
    {
      "epoch": 28.91650485436893,
      "grad_norm": 0.26317790150642395,
      "learning_rate": 0.0004773630956458588,
      "loss": 2.1144,
      "step": 7460
    },
    {
      "epoch": 28.955339805825243,
      "grad_norm": 0.26730677485466003,
      "learning_rate": 0.00047729887456794847,
      "loss": 2.1265,
      "step": 7470
    },
    {
      "epoch": 28.994174757281552,
      "grad_norm": 0.28391513228416443,
      "learning_rate": 0.0004772345668536397,
      "loss": 2.1234,
      "step": 7480
    },
    {
      "epoch": 29.0,
      "eval_loss": 1.03370201587677,
      "eval_runtime": 6.5102,
      "eval_samples_per_second": 3805.122,
      "eval_steps_per_second": 14.9,
      "step": 7482
    },
    {
      "epoch": 29.03106796116505,
      "grad_norm": 0.3080996572971344,
      "learning_rate": 0.0004771701725274438,
      "loss": 2.0021,
      "step": 7490
    },
    {
      "epoch": 29.06990291262136,
      "grad_norm": 0.32607316970825195,
      "learning_rate": 0.00047710569161390506,
      "loss": 2.1061,
      "step": 7500
    },
    {
      "epoch": 29.10873786407767,
      "grad_norm": 0.282073050737381,
      "learning_rate": 0.0004770411241376008,
      "loss": 2.1055,
      "step": 7510
    },
    {
      "epoch": 29.14757281553398,
      "grad_norm": 0.2848632335662842,
      "learning_rate": 0.00047697647012314137,
      "loss": 2.1114,
      "step": 7520
    },
    {
      "epoch": 29.186407766990293,
      "grad_norm": 0.34060654044151306,
      "learning_rate": 0.00047691172959517003,
      "loss": 2.11,
      "step": 7530
    },
    {
      "epoch": 29.2252427184466,
      "grad_norm": 0.3796640932559967,
      "learning_rate": 0.0004768469025783629,
      "loss": 2.096,
      "step": 7540
    },
    {
      "epoch": 29.264077669902914,
      "grad_norm": 0.33121874928474426,
      "learning_rate": 0.00047678198909742946,
      "loss": 2.124,
      "step": 7550
    },
    {
      "epoch": 29.302912621359223,
      "grad_norm": 0.24460557103157043,
      "learning_rate": 0.00047671698917711177,
      "loss": 2.1239,
      "step": 7560
    },
    {
      "epoch": 29.341747572815535,
      "grad_norm": 0.2564874589443207,
      "learning_rate": 0.0004766519028421849,
      "loss": 2.1231,
      "step": 7570
    },
    {
      "epoch": 29.380582524271844,
      "grad_norm": 0.32397106289863586,
      "learning_rate": 0.00047658673011745703,
      "loss": 2.1069,
      "step": 7580
    },
    {
      "epoch": 29.419417475728157,
      "grad_norm": 0.3840097188949585,
      "learning_rate": 0.00047652147102776897,
      "loss": 2.1117,
      "step": 7590
    },
    {
      "epoch": 29.458252427184465,
      "grad_norm": 0.2619835138320923,
      "learning_rate": 0.00047645612559799483,
      "loss": 2.1273,
      "step": 7600
    },
    {
      "epoch": 29.497087378640778,
      "grad_norm": 0.25645941495895386,
      "learning_rate": 0.00047639069385304136,
      "loss": 2.1199,
      "step": 7610
    },
    {
      "epoch": 29.535922330097087,
      "grad_norm": 0.2936537265777588,
      "learning_rate": 0.0004763251758178483,
      "loss": 2.1167,
      "step": 7620
    },
    {
      "epoch": 29.5747572815534,
      "grad_norm": 0.297003835439682,
      "learning_rate": 0.0004762595715173882,
      "loss": 2.0901,
      "step": 7630
    },
    {
      "epoch": 29.613592233009708,
      "grad_norm": 0.2831520438194275,
      "learning_rate": 0.0004761938809766666,
      "loss": 2.1214,
      "step": 7640
    },
    {
      "epoch": 29.65242718446602,
      "grad_norm": 0.2819717228412628,
      "learning_rate": 0.00047612810422072193,
      "loss": 2.1087,
      "step": 7650
    },
    {
      "epoch": 29.69126213592233,
      "grad_norm": 0.25520193576812744,
      "learning_rate": 0.00047606224127462525,
      "loss": 2.1239,
      "step": 7660
    },
    {
      "epoch": 29.730097087378642,
      "grad_norm": 0.2779335677623749,
      "learning_rate": 0.0004759962921634808,
      "loss": 2.1253,
      "step": 7670
    },
    {
      "epoch": 29.76893203883495,
      "grad_norm": 0.27473217248916626,
      "learning_rate": 0.0004759302569124254,
      "loss": 2.1211,
      "step": 7680
    },
    {
      "epoch": 29.807766990291263,
      "grad_norm": 0.25017014145851135,
      "learning_rate": 0.0004758641355466288,
      "loss": 2.1042,
      "step": 7690
    },
    {
      "epoch": 29.846601941747572,
      "grad_norm": 0.25926798582077026,
      "learning_rate": 0.0004757979280912937,
      "loss": 2.1113,
      "step": 7700
    },
    {
      "epoch": 29.885436893203885,
      "grad_norm": 0.29837116599082947,
      "learning_rate": 0.0004757316345716554,
      "loss": 2.1218,
      "step": 7710
    },
    {
      "epoch": 29.924271844660193,
      "grad_norm": 0.25999319553375244,
      "learning_rate": 0.000475665255012982,
      "loss": 2.1105,
      "step": 7720
    },
    {
      "epoch": 29.963106796116506,
      "grad_norm": 0.3449260890483856,
      "learning_rate": 0.0004755987894405746,
      "loss": 2.1116,
      "step": 7730
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.2556476593017578,
      "learning_rate": 0.0004755322378797669,
      "loss": 2.0144,
      "step": 7740
    },
    {
      "epoch": 30.0,
      "eval_loss": 1.0343029499053955,
      "eval_runtime": 6.4988,
      "eval_samples_per_second": 3811.795,
      "eval_steps_per_second": 14.926,
      "step": 7740
    },
    {
      "epoch": 30.038834951456312,
      "grad_norm": 0.3150591552257538,
      "learning_rate": 0.00047546560035592557,
      "loss": 2.1104,
      "step": 7750
    },
    {
      "epoch": 30.07766990291262,
      "grad_norm": 0.3079608976840973,
      "learning_rate": 0.0004753988768944498,
      "loss": 2.1091,
      "step": 7760
    },
    {
      "epoch": 30.116504854368934,
      "grad_norm": 0.25518155097961426,
      "learning_rate": 0.00047533206752077177,
      "loss": 2.1099,
      "step": 7770
    },
    {
      "epoch": 30.155339805825243,
      "grad_norm": 0.3770059645175934,
      "learning_rate": 0.00047526517226035615,
      "loss": 2.1227,
      "step": 7780
    },
    {
      "epoch": 30.194174757281555,
      "grad_norm": 0.34337732195854187,
      "learning_rate": 0.0004751981911387006,
      "loss": 2.1024,
      "step": 7790
    },
    {
      "epoch": 30.233009708737864,
      "grad_norm": 0.36404842138290405,
      "learning_rate": 0.0004751311241813354,
      "loss": 2.0998,
      "step": 7800
    },
    {
      "epoch": 30.271844660194176,
      "grad_norm": 0.2945767641067505,
      "learning_rate": 0.0004750639714138235,
      "loss": 2.1019,
      "step": 7810
    },
    {
      "epoch": 30.310679611650485,
      "grad_norm": 0.2929607927799225,
      "learning_rate": 0.0004749967328617606,
      "loss": 2.1164,
      "step": 7820
    },
    {
      "epoch": 30.349514563106798,
      "grad_norm": 0.32088419795036316,
      "learning_rate": 0.00047492940855077504,
      "loss": 2.1112,
      "step": 7830
    },
    {
      "epoch": 30.388349514563107,
      "grad_norm": 0.2843661308288574,
      "learning_rate": 0.00047486199850652804,
      "loss": 2.1008,
      "step": 7840
    },
    {
      "epoch": 30.42718446601942,
      "grad_norm": 0.3465114235877991,
      "learning_rate": 0.00047479450275471325,
      "loss": 2.1147,
      "step": 7850
    },
    {
      "epoch": 30.466019417475728,
      "grad_norm": 0.24288517236709595,
      "learning_rate": 0.00047472692132105723,
      "loss": 2.1145,
      "step": 7860
    },
    {
      "epoch": 30.50485436893204,
      "grad_norm": 0.2248469591140747,
      "learning_rate": 0.00047465925423131894,
      "loss": 2.0974,
      "step": 7870
    },
    {
      "epoch": 30.54368932038835,
      "grad_norm": 0.43945470452308655,
      "learning_rate": 0.00047459150151129013,
      "loss": 2.112,
      "step": 7880
    },
    {
      "epoch": 30.58252427184466,
      "grad_norm": 0.26744288206100464,
      "learning_rate": 0.00047452366318679527,
      "loss": 2.1169,
      "step": 7890
    },
    {
      "epoch": 30.62135922330097,
      "grad_norm": 0.2589927911758423,
      "learning_rate": 0.00047445573928369127,
      "loss": 2.115,
      "step": 7900
    },
    {
      "epoch": 30.660194174757283,
      "grad_norm": 0.3106100857257843,
      "learning_rate": 0.00047438772982786784,
      "loss": 2.1042,
      "step": 7910
    },
    {
      "epoch": 30.699029126213592,
      "grad_norm": 0.29614540934562683,
      "learning_rate": 0.0004743196348452471,
      "loss": 2.1083,
      "step": 7920
    },
    {
      "epoch": 30.737864077669904,
      "grad_norm": 0.28526782989501953,
      "learning_rate": 0.00047425145436178395,
      "loss": 2.1148,
      "step": 7930
    },
    {
      "epoch": 30.776699029126213,
      "grad_norm": 0.3315909802913666,
      "learning_rate": 0.0004741831884034659,
      "loss": 2.1236,
      "step": 7940
    },
    {
      "epoch": 30.815533980582526,
      "grad_norm": 0.26976603269577026,
      "learning_rate": 0.0004741148369963127,
      "loss": 2.1078,
      "step": 7950
    },
    {
      "epoch": 30.854368932038835,
      "grad_norm": 0.2661518454551697,
      "learning_rate": 0.00047404640016637713,
      "loss": 2.1178,
      "step": 7960
    },
    {
      "epoch": 30.893203883495147,
      "grad_norm": 0.30610278248786926,
      "learning_rate": 0.0004739778779397443,
      "loss": 2.1254,
      "step": 7970
    },
    {
      "epoch": 30.932038834951456,
      "grad_norm": 0.2612689137458801,
      "learning_rate": 0.00047390927034253184,
      "loss": 2.1114,
      "step": 7980
    },
    {
      "epoch": 30.97087378640777,
      "grad_norm": 0.29434236884117126,
      "learning_rate": 0.0004738405774008899,
      "loss": 2.116,
      "step": 7990
    },
    {
      "epoch": 31.0,
      "eval_loss": 1.033029556274414,
      "eval_runtime": 6.4993,
      "eval_samples_per_second": 3811.47,
      "eval_steps_per_second": 14.925,
      "step": 7998
    },
    {
      "epoch": 31.007766990291262,
      "grad_norm": 0.2304713875055313,
      "learning_rate": 0.0004737717991410014,
      "loss": 2.0008,
      "step": 8000
    },
    {
      "epoch": 31.04660194174757,
      "grad_norm": 0.3348185420036316,
      "learning_rate": 0.0004737029355890815,
      "loss": 2.1024,
      "step": 8010
    },
    {
      "epoch": 31.085436893203884,
      "grad_norm": 0.28875526785850525,
      "learning_rate": 0.000473633986771378,
      "loss": 2.1104,
      "step": 8020
    },
    {
      "epoch": 31.124271844660193,
      "grad_norm": 0.26812994480133057,
      "learning_rate": 0.0004735649527141711,
      "loss": 2.1135,
      "step": 8030
    },
    {
      "epoch": 31.163106796116505,
      "grad_norm": 0.3492373526096344,
      "learning_rate": 0.0004734958334437737,
      "loss": 2.1101,
      "step": 8040
    },
    {
      "epoch": 31.201941747572814,
      "grad_norm": 0.24663901329040527,
      "learning_rate": 0.000473426628986531,
      "loss": 2.1098,
      "step": 8050
    },
    {
      "epoch": 31.240776699029126,
      "grad_norm": 0.32384997606277466,
      "learning_rate": 0.00047335733936882063,
      "loss": 2.1109,
      "step": 8060
    },
    {
      "epoch": 31.279611650485435,
      "grad_norm": 0.3083988428115845,
      "learning_rate": 0.0004732879646170528,
      "loss": 2.1,
      "step": 8070
    },
    {
      "epoch": 31.318446601941748,
      "grad_norm": 0.3251422047615051,
      "learning_rate": 0.00047321850475767025,
      "loss": 2.1068,
      "step": 8080
    },
    {
      "epoch": 31.357281553398057,
      "grad_norm": 0.3341696560382843,
      "learning_rate": 0.0004731489598171479,
      "loss": 2.1134,
      "step": 8090
    },
    {
      "epoch": 31.39611650485437,
      "grad_norm": 0.3473655879497528,
      "learning_rate": 0.0004730793298219933,
      "loss": 2.1194,
      "step": 8100
    },
    {
      "epoch": 31.434951456310678,
      "grad_norm": 0.34123706817626953,
      "learning_rate": 0.0004730096147987464,
      "loss": 2.1281,
      "step": 8110
    },
    {
      "epoch": 31.47378640776699,
      "grad_norm": 0.3181239366531372,
      "learning_rate": 0.0004729398147739794,
      "loss": 2.122,
      "step": 8120
    },
    {
      "epoch": 31.5126213592233,
      "grad_norm": 0.2923945188522339,
      "learning_rate": 0.0004728699297742972,
      "loss": 2.1029,
      "step": 8130
    },
    {
      "epoch": 31.55145631067961,
      "grad_norm": 0.33581292629241943,
      "learning_rate": 0.0004727999598263367,
      "loss": 2.112,
      "step": 8140
    },
    {
      "epoch": 31.59029126213592,
      "grad_norm": 0.4933618903160095,
      "learning_rate": 0.0004727299049567676,
      "loss": 2.1049,
      "step": 8150
    },
    {
      "epoch": 31.629126213592233,
      "grad_norm": 0.8078732490539551,
      "learning_rate": 0.0004726597651922916,
      "loss": 2.1065,
      "step": 8160
    },
    {
      "epoch": 31.667961165048542,
      "grad_norm": 0.34355881810188293,
      "learning_rate": 0.000472589540559643,
      "loss": 2.1167,
      "step": 8170
    },
    {
      "epoch": 31.706796116504854,
      "grad_norm": 0.31425940990448,
      "learning_rate": 0.00047251923108558824,
      "loss": 2.1115,
      "step": 8180
    },
    {
      "epoch": 31.745631067961163,
      "grad_norm": 0.2775671184062958,
      "learning_rate": 0.00047244883679692633,
      "loss": 2.1094,
      "step": 8190
    },
    {
      "epoch": 31.784466019417476,
      "grad_norm": 0.377903550863266,
      "learning_rate": 0.0004723783577204885,
      "loss": 2.1084,
      "step": 8200
    },
    {
      "epoch": 31.823300970873788,
      "grad_norm": 0.38735508918762207,
      "learning_rate": 0.00047230779388313825,
      "loss": 2.1195,
      "step": 8210
    },
    {
      "epoch": 31.862135922330097,
      "grad_norm": 0.3076794147491455,
      "learning_rate": 0.00047223714531177143,
      "loss": 2.1199,
      "step": 8220
    },
    {
      "epoch": 31.900970873786406,
      "grad_norm": 0.43803665041923523,
      "learning_rate": 0.0004721664120333162,
      "loss": 2.1166,
      "step": 8230
    },
    {
      "epoch": 31.93980582524272,
      "grad_norm": 0.3254889249801636,
      "learning_rate": 0.000472095594074733,
      "loss": 2.0993,
      "step": 8240
    },
    {
      "epoch": 31.97864077669903,
      "grad_norm": 0.3974571228027344,
      "learning_rate": 0.00047202469146301454,
      "loss": 2.0983,
      "step": 8250
    },
    {
      "epoch": 32.0,
      "eval_loss": 1.0337345600128174,
      "eval_runtime": 6.5217,
      "eval_samples_per_second": 3798.382,
      "eval_steps_per_second": 14.873,
      "step": 8256
    },
    {
      "epoch": 32.015533980582525,
      "grad_norm": 0.322567880153656,
      "learning_rate": 0.0004719537042251858,
      "loss": 1.9994,
      "step": 8260
    },
    {
      "epoch": 32.054368932038834,
      "grad_norm": 0.3335220217704773,
      "learning_rate": 0.00047188263238830396,
      "loss": 2.1208,
      "step": 8270
    },
    {
      "epoch": 32.09320388349514,
      "grad_norm": 0.3765104115009308,
      "learning_rate": 0.00047181147597945863,
      "loss": 2.1002,
      "step": 8280
    },
    {
      "epoch": 32.13203883495146,
      "grad_norm": 0.3190145492553711,
      "learning_rate": 0.0004717402350257715,
      "loss": 2.1071,
      "step": 8290
    },
    {
      "epoch": 32.17087378640777,
      "grad_norm": 0.37286368012428284,
      "learning_rate": 0.0004716689095543963,
      "loss": 2.1187,
      "step": 8300
    },
    {
      "epoch": 32.20970873786408,
      "grad_norm": 0.35509493947029114,
      "learning_rate": 0.00047159749959251935,
      "loss": 2.1002,
      "step": 8310
    },
    {
      "epoch": 32.248543689320385,
      "grad_norm": 0.34803661704063416,
      "learning_rate": 0.00047152600516735905,
      "loss": 2.1178,
      "step": 8320
    },
    {
      "epoch": 32.2873786407767,
      "grad_norm": 0.3049312233924866,
      "learning_rate": 0.0004714544263061659,
      "loss": 2.1041,
      "step": 8330
    },
    {
      "epoch": 32.32621359223301,
      "grad_norm": 0.3826630115509033,
      "learning_rate": 0.00047138276303622254,
      "loss": 2.1028,
      "step": 8340
    },
    {
      "epoch": 32.36504854368932,
      "grad_norm": 0.38045668601989746,
      "learning_rate": 0.000471311015384844,
      "loss": 2.1007,
      "step": 8350
    },
    {
      "epoch": 32.40388349514563,
      "grad_norm": 0.28313446044921875,
      "learning_rate": 0.0004712391833793773,
      "loss": 2.1015,
      "step": 8360
    },
    {
      "epoch": 32.442718446601944,
      "grad_norm": 0.3306429088115692,
      "learning_rate": 0.0004711672670472017,
      "loss": 2.1022,
      "step": 8370
    },
    {
      "epoch": 32.48155339805825,
      "grad_norm": 0.3456259071826935,
      "learning_rate": 0.00047109526641572855,
      "loss": 2.1157,
      "step": 8380
    },
    {
      "epoch": 32.52038834951456,
      "grad_norm": 0.32463207840919495,
      "learning_rate": 0.0004710231815124013,
      "loss": 2.123,
      "step": 8390
    },
    {
      "epoch": 32.55922330097087,
      "grad_norm": 0.2979872226715088,
      "learning_rate": 0.00047095101236469564,
      "loss": 2.1052,
      "step": 8400
    },
    {
      "epoch": 32.59805825242719,
      "grad_norm": 0.35956305265426636,
      "learning_rate": 0.00047087875900011914,
      "loss": 2.1071,
      "step": 8410
    },
    {
      "epoch": 32.636893203883496,
      "grad_norm": 0.31176167726516724,
      "learning_rate": 0.0004708064214462118,
      "loss": 2.0886,
      "step": 8420
    },
    {
      "epoch": 32.675728155339804,
      "grad_norm": 0.2865552604198456,
      "learning_rate": 0.0004707339997305455,
      "loss": 2.1072,
      "step": 8430
    },
    {
      "epoch": 32.71456310679611,
      "grad_norm": 0.3469618260860443,
      "learning_rate": 0.00047066149388072417,
      "loss": 2.1071,
      "step": 8440
    },
    {
      "epoch": 32.75339805825243,
      "grad_norm": 0.31008538603782654,
      "learning_rate": 0.00047058890392438394,
      "loss": 2.1095,
      "step": 8450
    },
    {
      "epoch": 32.79223300970874,
      "grad_norm": 0.31410154700279236,
      "learning_rate": 0.00047051622988919284,
      "loss": 2.1121,
      "step": 8460
    },
    {
      "epoch": 32.83106796116505,
      "grad_norm": 0.26674434542655945,
      "learning_rate": 0.0004704434718028511,
      "loss": 2.1164,
      "step": 8470
    },
    {
      "epoch": 32.869902912621356,
      "grad_norm": 0.3262958526611328,
      "learning_rate": 0.0004703706296930909,
      "loss": 2.1066,
      "step": 8480
    },
    {
      "epoch": 32.90873786407767,
      "grad_norm": 0.32764965295791626,
      "learning_rate": 0.00047029770358767656,
      "loss": 2.1076,
      "step": 8490
    },
    {
      "epoch": 32.94757281553398,
      "grad_norm": 0.3477872610092163,
      "learning_rate": 0.0004702246935144041,
      "loss": 2.1191,
      "step": 8500
    },
    {
      "epoch": 32.98640776699029,
      "grad_norm": 0.3667609393596649,
      "learning_rate": 0.0004701515995011021,
      "loss": 2.1103,
      "step": 8510
    },
    {
      "epoch": 33.0,
      "eval_loss": 1.0336639881134033,
      "eval_runtime": 6.5233,
      "eval_samples_per_second": 3797.479,
      "eval_steps_per_second": 14.87,
      "step": 8514
    },
    {
      "epoch": 33.023300970873784,
      "grad_norm": 0.31068623065948486,
      "learning_rate": 0.00047007842157563055,
      "loss": 2.0057,
      "step": 8520
    },
    {
      "epoch": 33.0621359223301,
      "grad_norm": 0.36005961894989014,
      "learning_rate": 0.00047000515976588163,
      "loss": 2.1076,
      "step": 8530
    },
    {
      "epoch": 33.10097087378641,
      "grad_norm": 0.2958071231842041,
      "learning_rate": 0.0004699318140997798,
      "loss": 2.1074,
      "step": 8540
    },
    {
      "epoch": 33.13980582524272,
      "grad_norm": 0.2601088583469391,
      "learning_rate": 0.000469858384605281,
      "loss": 2.1012,
      "step": 8550
    },
    {
      "epoch": 33.17864077669903,
      "grad_norm": 0.24948889017105103,
      "learning_rate": 0.0004697848713103735,
      "loss": 2.1246,
      "step": 8560
    },
    {
      "epoch": 33.21747572815534,
      "grad_norm": 0.3268970549106598,
      "learning_rate": 0.00046971127424307724,
      "loss": 2.1077,
      "step": 8570
    },
    {
      "epoch": 33.25631067961165,
      "grad_norm": 0.41444268822669983,
      "learning_rate": 0.00046963759343144425,
      "loss": 2.0969,
      "step": 8580
    },
    {
      "epoch": 33.29514563106796,
      "grad_norm": 0.341427206993103,
      "learning_rate": 0.0004695638289035584,
      "loss": 2.1032,
      "step": 8590
    },
    {
      "epoch": 33.33398058252427,
      "grad_norm": 0.31498098373413086,
      "learning_rate": 0.0004694899806875356,
      "loss": 2.1046,
      "step": 8600
    },
    {
      "epoch": 33.372815533980585,
      "grad_norm": 0.2819599211215973,
      "learning_rate": 0.00046941604881152346,
      "loss": 2.105,
      "step": 8610
    },
    {
      "epoch": 33.411650485436894,
      "grad_norm": 0.279329776763916,
      "learning_rate": 0.00046934203330370163,
      "loss": 2.1199,
      "step": 8620
    },
    {
      "epoch": 33.4504854368932,
      "grad_norm": 0.3354104161262512,
      "learning_rate": 0.0004692679341922816,
      "loss": 2.1009,
      "step": 8630
    },
    {
      "epoch": 33.48932038834951,
      "grad_norm": 0.4099225401878357,
      "learning_rate": 0.00046919375150550666,
      "loss": 2.1043,
      "step": 8640
    },
    {
      "epoch": 33.52815533980583,
      "grad_norm": 0.2769628167152405,
      "learning_rate": 0.00046911948527165206,
      "loss": 2.1034,
      "step": 8650
    },
    {
      "epoch": 33.56699029126214,
      "grad_norm": 0.2854349911212921,
      "learning_rate": 0.0004690451355190248,
      "loss": 2.1084,
      "step": 8660
    },
    {
      "epoch": 33.605825242718446,
      "grad_norm": 0.2982584238052368,
      "learning_rate": 0.00046897070227596376,
      "loss": 2.1109,
      "step": 8670
    },
    {
      "epoch": 33.644660194174755,
      "grad_norm": 0.3135765492916107,
      "learning_rate": 0.0004688961855708397,
      "loss": 2.1084,
      "step": 8680
    },
    {
      "epoch": 33.68349514563107,
      "grad_norm": 0.2772626280784607,
      "learning_rate": 0.0004688215854320551,
      "loss": 2.1136,
      "step": 8690
    },
    {
      "epoch": 33.72233009708738,
      "grad_norm": 0.2728999853134155,
      "learning_rate": 0.00046874690188804426,
      "loss": 2.1074,
      "step": 8700
    },
    {
      "epoch": 33.76116504854369,
      "grad_norm": 0.26057198643684387,
      "learning_rate": 0.00046867213496727325,
      "loss": 2.1114,
      "step": 8710
    },
    {
      "epoch": 33.8,
      "grad_norm": 0.29158663749694824,
      "learning_rate": 0.00046859728469824004,
      "loss": 2.0885,
      "step": 8720
    },
    {
      "epoch": 33.83883495145631,
      "grad_norm": 0.3128547668457031,
      "learning_rate": 0.00046852235110947415,
      "loss": 2.105,
      "step": 8730
    },
    {
      "epoch": 33.87766990291262,
      "grad_norm": 0.25848299264907837,
      "learning_rate": 0.00046844733422953715,
      "loss": 2.1257,
      "step": 8740
    },
    {
      "epoch": 33.91650485436893,
      "grad_norm": 0.4135543406009674,
      "learning_rate": 0.0004683722340870221,
      "loss": 2.1016,
      "step": 8750
    },
    {
      "epoch": 33.95533980582524,
      "grad_norm": 0.2996126413345337,
      "learning_rate": 0.00046829705071055387,
      "loss": 2.105,
      "step": 8760
    },
    {
      "epoch": 33.994174757281556,
      "grad_norm": 0.32606828212738037,
      "learning_rate": 0.00046822178412878925,
      "loss": 2.0988,
      "step": 8770
    },
    {
      "epoch": 34.0,
      "eval_loss": 1.0324336290359497,
      "eval_runtime": 6.4987,
      "eval_samples_per_second": 3811.842,
      "eval_steps_per_second": 14.926,
      "step": 8772
    },
    {
      "epoch": 34.03106796116505,
      "grad_norm": 0.2722040116786957,
      "learning_rate": 0.0004681464343704163,
      "loss": 1.9975,
      "step": 8780
    },
    {
      "epoch": 34.06990291262136,
      "grad_norm": 0.26644793152809143,
      "learning_rate": 0.00046807100146415527,
      "loss": 2.0972,
      "step": 8790
    },
    {
      "epoch": 34.10873786407767,
      "grad_norm": 0.3610527515411377,
      "learning_rate": 0.0004679954854387578,
      "loss": 2.0984,
      "step": 8800
    },
    {
      "epoch": 34.147572815533984,
      "grad_norm": 0.3238087296485901,
      "learning_rate": 0.00046791988632300725,
      "loss": 2.1091,
      "step": 8810
    },
    {
      "epoch": 34.18640776699029,
      "grad_norm": 0.2960769534111023,
      "learning_rate": 0.0004678442041457188,
      "loss": 2.0939,
      "step": 8820
    },
    {
      "epoch": 34.2252427184466,
      "grad_norm": 0.27444010972976685,
      "learning_rate": 0.0004677684389357392,
      "loss": 2.1148,
      "step": 8830
    },
    {
      "epoch": 34.26407766990291,
      "grad_norm": 0.3904855251312256,
      "learning_rate": 0.0004676925907219467,
      "loss": 2.0945,
      "step": 8840
    },
    {
      "epoch": 34.302912621359226,
      "grad_norm": 0.34489837288856506,
      "learning_rate": 0.0004676166595332515,
      "loss": 2.0881,
      "step": 8850
    },
    {
      "epoch": 34.341747572815535,
      "grad_norm": 0.3508037328720093,
      "learning_rate": 0.0004675406453985951,
      "loss": 2.1016,
      "step": 8860
    },
    {
      "epoch": 34.380582524271844,
      "grad_norm": 0.27385082840919495,
      "learning_rate": 0.00046746454834695086,
      "loss": 2.1156,
      "step": 8870
    },
    {
      "epoch": 34.41941747572815,
      "grad_norm": 0.28239208459854126,
      "learning_rate": 0.0004673883684073236,
      "loss": 2.1149,
      "step": 8880
    },
    {
      "epoch": 34.45825242718447,
      "grad_norm": 0.34949991106987,
      "learning_rate": 0.00046731210560874983,
      "loss": 2.0993,
      "step": 8890
    },
    {
      "epoch": 34.49708737864078,
      "grad_norm": 0.2664664387702942,
      "learning_rate": 0.00046723575998029753,
      "loss": 2.1055,
      "step": 8900
    },
    {
      "epoch": 34.53592233009709,
      "grad_norm": 0.2381630539894104,
      "learning_rate": 0.00046715933155106636,
      "loss": 2.0947,
      "step": 8910
    },
    {
      "epoch": 34.574757281553396,
      "grad_norm": 0.22433044016361237,
      "learning_rate": 0.0004670828203501876,
      "loss": 2.1093,
      "step": 8920
    },
    {
      "epoch": 34.61359223300971,
      "grad_norm": 0.2621874213218689,
      "learning_rate": 0.0004670062264068238,
      "loss": 2.1009,
      "step": 8930
    },
    {
      "epoch": 34.65242718446602,
      "grad_norm": 0.27386292815208435,
      "learning_rate": 0.00046692954975016926,
      "loss": 2.099,
      "step": 8940
    },
    {
      "epoch": 34.69126213592233,
      "grad_norm": 0.3848388195037842,
      "learning_rate": 0.00046685279040944983,
      "loss": 2.1056,
      "step": 8950
    },
    {
      "epoch": 34.73009708737864,
      "grad_norm": 0.24789971113204956,
      "learning_rate": 0.0004667759484139228,
      "loss": 2.1014,
      "step": 8960
    },
    {
      "epoch": 34.768932038834954,
      "grad_norm": 0.32733550667762756,
      "learning_rate": 0.000466699023792877,
      "loss": 2.1113,
      "step": 8970
    },
    {
      "epoch": 34.80776699029126,
      "grad_norm": 0.2550244629383087,
      "learning_rate": 0.0004666220165756326,
      "loss": 2.1037,
      "step": 8980
    },
    {
      "epoch": 34.84660194174757,
      "grad_norm": 0.2545250356197357,
      "learning_rate": 0.0004665449267915416,
      "loss": 2.1141,
      "step": 8990
    },
    {
      "epoch": 34.88543689320388,
      "grad_norm": 0.28705573081970215,
      "learning_rate": 0.00046646775446998717,
      "loss": 2.1079,
      "step": 9000
    },
    {
      "epoch": 34.9242718446602,
      "grad_norm": 0.3924214541912079,
      "learning_rate": 0.000466390499640384,
      "loss": 2.1147,
      "step": 9010
    },
    {
      "epoch": 34.963106796116506,
      "grad_norm": 0.3124071955680847,
      "learning_rate": 0.00046631316233217824,
      "loss": 2.1089,
      "step": 9020
    },
    {
      "epoch": 35.0,
      "grad_norm": 0.28697335720062256,
      "learning_rate": 0.0004662357425748475,
      "loss": 2.006,
      "step": 9030
    },
    {
      "epoch": 35.0,
      "eval_loss": 1.0329701900482178,
      "eval_runtime": 6.4997,
      "eval_samples_per_second": 3811.281,
      "eval_steps_per_second": 14.924,
      "step": 9030
    },
    {
      "epoch": 35.03883495145631,
      "grad_norm": 0.4148227572441101,
      "learning_rate": 0.00046615824039790085,
      "loss": 2.1002,
      "step": 9040
    },
    {
      "epoch": 35.077669902912625,
      "grad_norm": 0.30691027641296387,
      "learning_rate": 0.00046608065583087865,
      "loss": 2.0984,
      "step": 9050
    },
    {
      "epoch": 35.116504854368934,
      "grad_norm": 0.2912164032459259,
      "learning_rate": 0.00046600298890335284,
      "loss": 2.1024,
      "step": 9060
    },
    {
      "epoch": 35.15533980582524,
      "grad_norm": 0.32764342427253723,
      "learning_rate": 0.00046592523964492663,
      "loss": 2.1041,
      "step": 9070
    },
    {
      "epoch": 35.19417475728155,
      "grad_norm": 0.3122371435165405,
      "learning_rate": 0.00046584740808523463,
      "loss": 2.1109,
      "step": 9080
    },
    {
      "epoch": 35.23300970873787,
      "grad_norm": 0.2959679663181305,
      "learning_rate": 0.0004657694942539429,
      "loss": 2.1098,
      "step": 9090
    },
    {
      "epoch": 35.271844660194176,
      "grad_norm": 0.2682059705257416,
      "learning_rate": 0.0004656914981807486,
      "loss": 2.1029,
      "step": 9100
    },
    {
      "epoch": 35.310679611650485,
      "grad_norm": 0.2734667956829071,
      "learning_rate": 0.00046561341989538065,
      "loss": 2.0882,
      "step": 9110
    },
    {
      "epoch": 35.349514563106794,
      "grad_norm": 0.40153276920318604,
      "learning_rate": 0.00046553525942759886,
      "loss": 2.1056,
      "step": 9120
    },
    {
      "epoch": 35.38834951456311,
      "grad_norm": 0.34791332483291626,
      "learning_rate": 0.00046545701680719475,
      "loss": 2.1017,
      "step": 9130
    },
    {
      "epoch": 35.42718446601942,
      "grad_norm": 0.2864028811454773,
      "learning_rate": 0.000465378692063991,
      "loss": 2.1019,
      "step": 9140
    },
    {
      "epoch": 35.46601941747573,
      "grad_norm": 0.3463228940963745,
      "learning_rate": 0.0004653002852278414,
      "loss": 2.0978,
      "step": 9150
    },
    {
      "epoch": 35.50485436893204,
      "grad_norm": 0.3188726007938385,
      "learning_rate": 0.00046522179632863144,
      "loss": 2.0909,
      "step": 9160
    },
    {
      "epoch": 35.54368932038835,
      "grad_norm": 0.307790607213974,
      "learning_rate": 0.0004651432253962775,
      "loss": 2.1048,
      "step": 9170
    },
    {
      "epoch": 35.58252427184466,
      "grad_norm": 0.3218299150466919,
      "learning_rate": 0.0004650645724607274,
      "loss": 2.1004,
      "step": 9180
    },
    {
      "epoch": 35.62135922330097,
      "grad_norm": 0.3482523560523987,
      "learning_rate": 0.00046498583755196036,
      "loss": 2.1014,
      "step": 9190
    },
    {
      "epoch": 35.66019417475728,
      "grad_norm": 0.28735849261283875,
      "learning_rate": 0.00046490702069998635,
      "loss": 2.1151,
      "step": 9200
    },
    {
      "epoch": 35.699029126213595,
      "grad_norm": 0.29069823026657104,
      "learning_rate": 0.00046482812193484723,
      "loss": 2.0993,
      "step": 9210
    },
    {
      "epoch": 35.737864077669904,
      "grad_norm": 0.6655622720718384,
      "learning_rate": 0.00046474914128661574,
      "loss": 2.104,
      "step": 9220
    },
    {
      "epoch": 35.77669902912621,
      "grad_norm": 0.27907586097717285,
      "learning_rate": 0.00046467007878539567,
      "loss": 2.1016,
      "step": 9230
    },
    {
      "epoch": 35.81553398058252,
      "grad_norm": 0.35776251554489136,
      "learning_rate": 0.00046459093446132225,
      "loss": 2.1066,
      "step": 9240
    },
    {
      "epoch": 35.85436893203884,
      "grad_norm": 0.3210594058036804,
      "learning_rate": 0.0004645117083445619,
      "loss": 2.1113,
      "step": 9250
    },
    {
      "epoch": 35.89320388349515,
      "grad_norm": 0.31440597772598267,
      "learning_rate": 0.0004644324004653122,
      "loss": 2.106,
      "step": 9260
    },
    {
      "epoch": 35.932038834951456,
      "grad_norm": 0.30162152647972107,
      "learning_rate": 0.00046435301085380167,
      "loss": 2.1026,
      "step": 9270
    },
    {
      "epoch": 35.970873786407765,
      "grad_norm": 0.28741520643234253,
      "learning_rate": 0.00046427353954029034,
      "loss": 2.1056,
      "step": 9280
    },
    {
      "epoch": 36.0,
      "eval_loss": 1.0321089029312134,
      "eval_runtime": 6.5104,
      "eval_samples_per_second": 3804.968,
      "eval_steps_per_second": 14.899,
      "step": 9288
    },
    {
      "epoch": 36.00776699029126,
      "grad_norm": 0.26526451110839844,
      "learning_rate": 0.00046419398655506903,
      "loss": 2.0013,
      "step": 9290
    },
    {
      "epoch": 36.046601941747575,
      "grad_norm": 0.28795328736305237,
      "learning_rate": 0.00046411435192846007,
      "loss": 2.1055,
      "step": 9300
    },
    {
      "epoch": 36.085436893203884,
      "grad_norm": 0.26760002970695496,
      "learning_rate": 0.00046403463569081655,
      "loss": 2.0974,
      "step": 9310
    },
    {
      "epoch": 36.12427184466019,
      "grad_norm": 0.37259453535079956,
      "learning_rate": 0.00046395483787252287,
      "loss": 2.0918,
      "step": 9320
    },
    {
      "epoch": 36.1631067961165,
      "grad_norm": 0.33438247442245483,
      "learning_rate": 0.0004638749585039944,
      "loss": 2.0952,
      "step": 9330
    },
    {
      "epoch": 36.20194174757282,
      "grad_norm": 0.4102880656719208,
      "learning_rate": 0.0004637949976156778,
      "loss": 2.0915,
      "step": 9340
    },
    {
      "epoch": 36.24077669902913,
      "grad_norm": 0.2763432264328003,
      "learning_rate": 0.0004637149552380505,
      "loss": 2.1073,
      "step": 9350
    },
    {
      "epoch": 36.279611650485435,
      "grad_norm": 0.3539981245994568,
      "learning_rate": 0.00046363483140162125,
      "loss": 2.1028,
      "step": 9360
    },
    {
      "epoch": 36.318446601941744,
      "grad_norm": 0.29237499833106995,
      "learning_rate": 0.00046355462613692977,
      "loss": 2.1102,
      "step": 9370
    },
    {
      "epoch": 36.35728155339806,
      "grad_norm": 0.3179434835910797,
      "learning_rate": 0.0004634743394745468,
      "loss": 2.105,
      "step": 9380
    },
    {
      "epoch": 36.39611650485437,
      "grad_norm": 0.36158257722854614,
      "learning_rate": 0.00046339397144507405,
      "loss": 2.1077,
      "step": 9390
    },
    {
      "epoch": 36.43495145631068,
      "grad_norm": 0.31810179352760315,
      "learning_rate": 0.0004633135220791443,
      "loss": 2.0869,
      "step": 9400
    },
    {
      "epoch": 36.47378640776699,
      "grad_norm": 0.3043222725391388,
      "learning_rate": 0.0004632329914074215,
      "loss": 2.1057,
      "step": 9410
    },
    {
      "epoch": 36.5126213592233,
      "grad_norm": 0.3570359945297241,
      "learning_rate": 0.00046315237946060024,
      "loss": 2.1034,
      "step": 9420
    },
    {
      "epoch": 36.55145631067961,
      "grad_norm": 0.31553396582603455,
      "learning_rate": 0.00046307168626940633,
      "loss": 2.0966,
      "step": 9430
    },
    {
      "epoch": 36.59029126213592,
      "grad_norm": 0.35759562253952026,
      "learning_rate": 0.00046299091186459646,
      "loss": 2.1042,
      "step": 9440
    },
    {
      "epoch": 36.62912621359223,
      "grad_norm": 0.2742695212364197,
      "learning_rate": 0.0004629100562769584,
      "loss": 2.092,
      "step": 9450
    },
    {
      "epoch": 36.667961165048546,
      "grad_norm": 0.2682408392429352,
      "learning_rate": 0.00046282911953731055,
      "loss": 2.1031,
      "step": 9460
    },
    {
      "epoch": 36.706796116504854,
      "grad_norm": 0.29458439350128174,
      "learning_rate": 0.0004627481016765027,
      "loss": 2.1094,
      "step": 9470
    },
    {
      "epoch": 36.74563106796116,
      "grad_norm": 0.2548108398914337,
      "learning_rate": 0.00046266700272541516,
      "loss": 2.1066,
      "step": 9480
    },
    {
      "epoch": 36.78446601941748,
      "grad_norm": 0.22950610518455505,
      "learning_rate": 0.0004625858227149594,
      "loss": 2.0986,
      "step": 9490
    },
    {
      "epoch": 36.82330097087379,
      "grad_norm": 0.28669267892837524,
      "learning_rate": 0.0004625045616760777,
      "loss": 2.1074,
      "step": 9500
    },
    {
      "epoch": 36.8621359223301,
      "grad_norm": 0.27619537711143494,
      "learning_rate": 0.0004624232196397431,
      "loss": 2.0985,
      "step": 9510
    },
    {
      "epoch": 36.900970873786406,
      "grad_norm": 0.2701748013496399,
      "learning_rate": 0.0004623417966369598,
      "loss": 2.1056,
      "step": 9520
    },
    {
      "epoch": 36.93980582524272,
      "grad_norm": 0.3271220326423645,
      "learning_rate": 0.00046226029269876256,
      "loss": 2.1092,
      "step": 9530
    },
    {
      "epoch": 36.97864077669903,
      "grad_norm": 0.289999395608902,
      "learning_rate": 0.00046217870785621716,
      "loss": 2.0986,
      "step": 9540
    },
    {
      "epoch": 37.0,
      "eval_loss": 1.0322489738464355,
      "eval_runtime": 6.4924,
      "eval_samples_per_second": 3815.549,
      "eval_steps_per_second": 14.941,
      "step": 9546
    },
    {
      "epoch": 37.015533980582525,
      "grad_norm": 0.2610993981361389,
      "learning_rate": 0.00046209704214042013,
      "loss": 1.9962,
      "step": 9550
    },
    {
      "epoch": 37.054368932038834,
      "grad_norm": 0.2671116590499878,
      "learning_rate": 0.00046201529558249893,
      "loss": 2.0872,
      "step": 9560
    },
    {
      "epoch": 37.09320388349514,
      "grad_norm": 0.29181772470474243,
      "learning_rate": 0.0004619334682136118,
      "loss": 2.1028,
      "step": 9570
    },
    {
      "epoch": 37.13203883495146,
      "grad_norm": 0.3051402270793915,
      "learning_rate": 0.00046185156006494765,
      "loss": 2.1059,
      "step": 9580
    },
    {
      "epoch": 37.17087378640777,
      "grad_norm": 0.25300127267837524,
      "learning_rate": 0.00046176957116772645,
      "loss": 2.0979,
      "step": 9590
    },
    {
      "epoch": 37.20970873786408,
      "grad_norm": 0.2769103944301605,
      "learning_rate": 0.0004616875015531986,
      "loss": 2.0988,
      "step": 9600
    },
    {
      "epoch": 37.248543689320385,
      "grad_norm": 0.3631640672683716,
      "learning_rate": 0.0004616053512526456,
      "loss": 2.0947,
      "step": 9610
    },
    {
      "epoch": 37.2873786407767,
      "grad_norm": 0.3416192829608917,
      "learning_rate": 0.00046152312029737946,
      "loss": 2.1052,
      "step": 9620
    },
    {
      "epoch": 37.32621359223301,
      "grad_norm": 0.4568691551685333,
      "learning_rate": 0.00046144080871874304,
      "loss": 2.0978,
      "step": 9630
    },
    {
      "epoch": 37.36504854368932,
      "grad_norm": 0.27717986702919006,
      "learning_rate": 0.00046135841654811006,
      "loss": 2.1019,
      "step": 9640
    },
    {
      "epoch": 37.40388349514563,
      "grad_norm": 0.30713096261024475,
      "learning_rate": 0.0004612759438168846,
      "loss": 2.1176,
      "step": 9650
    },
    {
      "epoch": 37.442718446601944,
      "grad_norm": 0.3577996492385864,
      "learning_rate": 0.0004611933905565018,
      "loss": 2.1049,
      "step": 9660
    },
    {
      "epoch": 37.48155339805825,
      "grad_norm": 0.3320607542991638,
      "learning_rate": 0.00046111075679842724,
      "loss": 2.1032,
      "step": 9670
    },
    {
      "epoch": 37.52038834951456,
      "grad_norm": 0.28398287296295166,
      "learning_rate": 0.0004610280425741574,
      "loss": 2.0884,
      "step": 9680
    },
    {
      "epoch": 37.55922330097087,
      "grad_norm": 0.268346905708313,
      "learning_rate": 0.0004609452479152193,
      "loss": 2.0895,
      "step": 9690
    },
    {
      "epoch": 37.59805825242719,
      "grad_norm": 0.24873663485050201,
      "learning_rate": 0.0004608623728531707,
      "loss": 2.0917,
      "step": 9700
    },
    {
      "epoch": 37.636893203883496,
      "grad_norm": 0.536124587059021,
      "learning_rate": 0.00046077941741959984,
      "loss": 2.0913,
      "step": 9710
    },
    {
      "epoch": 37.675728155339804,
      "grad_norm": 0.27217379212379456,
      "learning_rate": 0.0004606963816461257,
      "loss": 2.1111,
      "step": 9720
    },
    {
      "epoch": 37.71456310679611,
      "grad_norm": 0.3111865222454071,
      "learning_rate": 0.00046061326556439807,
      "loss": 2.1092,
      "step": 9730
    },
    {
      "epoch": 37.75339805825243,
      "grad_norm": 0.27358710765838623,
      "learning_rate": 0.00046053006920609697,
      "loss": 2.1128,
      "step": 9740
    },
    {
      "epoch": 37.79223300970874,
      "grad_norm": 0.3249487280845642,
      "learning_rate": 0.0004604467926029333,
      "loss": 2.0895,
      "step": 9750
    },
    {
      "epoch": 37.83106796116505,
      "grad_norm": 0.2771809697151184,
      "learning_rate": 0.0004603634357866485,
      "loss": 2.0882,
      "step": 9760
    },
    {
      "epoch": 37.869902912621356,
      "grad_norm": 0.29416826367378235,
      "learning_rate": 0.0004602799987890145,
      "loss": 2.1098,
      "step": 9770
    },
    {
      "epoch": 37.90873786407767,
      "grad_norm": 0.2952842712402344,
      "learning_rate": 0.0004601964816418338,
      "loss": 2.0931,
      "step": 9780
    },
    {
      "epoch": 37.94757281553398,
      "grad_norm": 0.3109605610370636,
      "learning_rate": 0.00046011288437693956,
      "loss": 2.1086,
      "step": 9790
    },
    {
      "epoch": 37.98640776699029,
      "grad_norm": 0.4630383551120758,
      "learning_rate": 0.0004600292070261953,
      "loss": 2.0932,
      "step": 9800
    },
    {
      "epoch": 38.0,
      "eval_loss": 1.0324511528015137,
      "eval_runtime": 6.6091,
      "eval_samples_per_second": 3748.152,
      "eval_steps_per_second": 14.677,
      "step": 9804
    },
    {
      "epoch": 38.023300970873784,
      "grad_norm": 0.2710897922515869,
      "learning_rate": 0.0004599454496214953,
      "loss": 1.9912,
      "step": 9810
    },
    {
      "epoch": 38.0621359223301,
      "grad_norm": 0.31104540824890137,
      "learning_rate": 0.00045986161219476417,
      "loss": 2.1122,
      "step": 9820
    },
    {
      "epoch": 38.10097087378641,
      "grad_norm": 0.334303617477417,
      "learning_rate": 0.00045977769477795704,
      "loss": 2.0968,
      "step": 9830
    },
    {
      "epoch": 38.13980582524272,
      "grad_norm": 0.3021400272846222,
      "learning_rate": 0.0004596936974030596,
      "loss": 2.0992,
      "step": 9840
    },
    {
      "epoch": 38.17864077669903,
      "grad_norm": 0.2775808572769165,
      "learning_rate": 0.00045960962010208793,
      "loss": 2.0973,
      "step": 9850
    },
    {
      "epoch": 38.21747572815534,
      "grad_norm": 0.28270208835601807,
      "learning_rate": 0.00045952546290708876,
      "loss": 2.0951,
      "step": 9860
    },
    {
      "epoch": 38.25631067961165,
      "grad_norm": 0.33758607506752014,
      "learning_rate": 0.000459441225850139,
      "loss": 2.097,
      "step": 9870
    },
    {
      "epoch": 38.29514563106796,
      "grad_norm": 0.2647254765033722,
      "learning_rate": 0.0004593569089633461,
      "loss": 2.0978,
      "step": 9880
    },
    {
      "epoch": 38.33398058252427,
      "grad_norm": 0.2895511984825134,
      "learning_rate": 0.00045927251227884813,
      "loss": 2.1038,
      "step": 9890
    },
    {
      "epoch": 38.372815533980585,
      "grad_norm": 0.2881962060928345,
      "learning_rate": 0.0004591880358288133,
      "loss": 2.0944,
      "step": 9900
    },
    {
      "epoch": 38.411650485436894,
      "grad_norm": 0.3122555911540985,
      "learning_rate": 0.0004591034796454403,
      "loss": 2.091,
      "step": 9910
    },
    {
      "epoch": 38.4504854368932,
      "grad_norm": 0.272461473941803,
      "learning_rate": 0.0004590188437609584,
      "loss": 2.0934,
      "step": 9920
    },
    {
      "epoch": 38.48932038834951,
      "grad_norm": 0.6770145297050476,
      "learning_rate": 0.00045893412820762706,
      "loss": 2.0969,
      "step": 9930
    },
    {
      "epoch": 38.52815533980583,
      "grad_norm": 0.2915550470352173,
      "learning_rate": 0.000458849333017736,
      "loss": 2.1065,
      "step": 9940
    },
    {
      "epoch": 38.56699029126214,
      "grad_norm": 0.247653990983963,
      "learning_rate": 0.00045876445822360567,
      "loss": 2.1102,
      "step": 9950
    },
    {
      "epoch": 38.605825242718446,
      "grad_norm": 0.24772872030735016,
      "learning_rate": 0.00045867950385758644,
      "loss": 2.0816,
      "step": 9960
    },
    {
      "epoch": 38.644660194174755,
      "grad_norm": 0.24253210425376892,
      "learning_rate": 0.00045859446995205936,
      "loss": 2.0903,
      "step": 9970
    },
    {
      "epoch": 38.68349514563107,
      "grad_norm": 0.27428969740867615,
      "learning_rate": 0.00045850935653943546,
      "loss": 2.098,
      "step": 9980
    },
    {
      "epoch": 38.72233009708738,
      "grad_norm": 0.24650418758392334,
      "learning_rate": 0.00045842416365215647,
      "loss": 2.1044,
      "step": 9990
    },
    {
      "epoch": 38.76116504854369,
      "grad_norm": 0.2764521539211273,
      "learning_rate": 0.0004583388913226939,
      "loss": 2.096,
      "step": 10000
    },
    {
      "epoch": 38.8,
      "grad_norm": 0.2475699633359909,
      "learning_rate": 0.00045825353958355014,
      "loss": 2.1062,
      "step": 10010
    },
    {
      "epoch": 38.83883495145631,
      "grad_norm": 0.2994692623615265,
      "learning_rate": 0.00045816810846725743,
      "loss": 2.0978,
      "step": 10020
    },
    {
      "epoch": 38.87766990291262,
      "grad_norm": 0.34292230010032654,
      "learning_rate": 0.0004580825980063783,
      "loss": 2.106,
      "step": 10030
    },
    {
      "epoch": 38.91650485436893,
      "grad_norm": 0.3134896457195282,
      "learning_rate": 0.0004579970082335057,
      "loss": 2.1022,
      "step": 10040
    },
    {
      "epoch": 38.95533980582524,
      "grad_norm": 0.3992932438850403,
      "learning_rate": 0.00045791133918126264,
      "loss": 2.1092,
      "step": 10050
    },
    {
      "epoch": 38.994174757281556,
      "grad_norm": 0.3020406663417816,
      "learning_rate": 0.0004578255908823025,
      "loss": 2.0994,
      "step": 10060
    },
    {
      "epoch": 39.0,
      "eval_loss": 1.0315163135528564,
      "eval_runtime": 6.5025,
      "eval_samples_per_second": 3809.605,
      "eval_steps_per_second": 14.917,
      "step": 10062
    },
    {
      "epoch": 39.03106796116505,
      "grad_norm": 0.2508988082408905,
      "learning_rate": 0.0004577397633693087,
      "loss": 1.9966,
      "step": 10070
    },
    {
      "epoch": 39.06990291262136,
      "grad_norm": 0.3156629800796509,
      "learning_rate": 0.000457653856674995,
      "loss": 2.1015,
      "step": 10080
    },
    {
      "epoch": 39.10873786407767,
      "grad_norm": 0.2769159972667694,
      "learning_rate": 0.0004575678708321053,
      "loss": 2.0897,
      "step": 10090
    },
    {
      "epoch": 39.147572815533984,
      "grad_norm": 0.3521731495857239,
      "learning_rate": 0.00045748180587341355,
      "loss": 2.0926,
      "step": 10100
    },
    {
      "epoch": 39.18640776699029,
      "grad_norm": 0.33106088638305664,
      "learning_rate": 0.000457395661831724,
      "loss": 2.0873,
      "step": 10110
    },
    {
      "epoch": 39.2252427184466,
      "grad_norm": 0.26856234669685364,
      "learning_rate": 0.00045730943873987097,
      "loss": 2.0938,
      "step": 10120
    },
    {
      "epoch": 39.26407766990291,
      "grad_norm": 0.2812787592411041,
      "learning_rate": 0.00045722313663071904,
      "loss": 2.0952,
      "step": 10130
    },
    {
      "epoch": 39.302912621359226,
      "grad_norm": 0.2803960144519806,
      "learning_rate": 0.00045713675553716264,
      "loss": 2.0926,
      "step": 10140
    },
    {
      "epoch": 39.341747572815535,
      "grad_norm": 0.344076931476593,
      "learning_rate": 0.0004570502954921266,
      "loss": 2.1064,
      "step": 10150
    },
    {
      "epoch": 39.380582524271844,
      "grad_norm": 0.3349993824958801,
      "learning_rate": 0.0004569637565285657,
      "loss": 2.0988,
      "step": 10160
    },
    {
      "epoch": 39.41941747572815,
      "grad_norm": 0.2687191665172577,
      "learning_rate": 0.00045687713867946473,
      "loss": 2.0892,
      "step": 10170
    },
    {
      "epoch": 39.45825242718447,
      "grad_norm": 0.2767137885093689,
      "learning_rate": 0.00045679044197783865,
      "loss": 2.1051,
      "step": 10180
    },
    {
      "epoch": 39.49708737864078,
      "grad_norm": 0.2750011384487152,
      "learning_rate": 0.00045670366645673256,
      "loss": 2.1085,
      "step": 10190
    },
    {
      "epoch": 39.53592233009709,
      "grad_norm": 0.289125919342041,
      "learning_rate": 0.0004566168121492214,
      "loss": 2.0916,
      "step": 10200
    },
    {
      "epoch": 39.574757281553396,
      "grad_norm": 0.2941277027130127,
      "learning_rate": 0.00045652987908841015,
      "loss": 2.0958,
      "step": 10210
    },
    {
      "epoch": 39.61359223300971,
      "grad_norm": 0.2695409953594208,
      "learning_rate": 0.00045644286730743403,
      "loss": 2.1014,
      "step": 10220
    },
    {
      "epoch": 39.65242718446602,
      "grad_norm": 0.2970850169658661,
      "learning_rate": 0.0004563557768394582,
      "loss": 2.1066,
      "step": 10230
    },
    {
      "epoch": 39.69126213592233,
      "grad_norm": 0.2953936457633972,
      "learning_rate": 0.0004562686077176775,
      "loss": 2.1005,
      "step": 10240
    },
    {
      "epoch": 39.73009708737864,
      "grad_norm": 1.057676076889038,
      "learning_rate": 0.0004561813599753172,
      "loss": 2.0973,
      "step": 10250
    },
    {
      "epoch": 39.768932038834954,
      "grad_norm": 0.30898964405059814,
      "learning_rate": 0.00045609403364563217,
      "loss": 2.0918,
      "step": 10260
    },
    {
      "epoch": 39.80776699029126,
      "grad_norm": 0.36215415596961975,
      "learning_rate": 0.00045600662876190757,
      "loss": 2.0902,
      "step": 10270
    },
    {
      "epoch": 39.84660194174757,
      "grad_norm": 0.40853628516197205,
      "learning_rate": 0.0004559191453574582,
      "loss": 2.1007,
      "step": 10280
    },
    {
      "epoch": 39.88543689320388,
      "grad_norm": 0.2944371700286865,
      "learning_rate": 0.0004558315834656289,
      "loss": 2.1039,
      "step": 10290
    },
    {
      "epoch": 39.9242718446602,
      "grad_norm": 0.399637907743454,
      "learning_rate": 0.0004557439431197945,
      "loss": 2.0825,
      "step": 10300
    },
    {
      "epoch": 39.963106796116506,
      "grad_norm": 0.33359190821647644,
      "learning_rate": 0.0004556562243533597,
      "loss": 2.0924,
      "step": 10310
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.19058720767498016,
      "learning_rate": 0.00045556842719975886,
      "loss": 1.9977,
      "step": 10320
    },
    {
      "epoch": 40.0,
      "eval_loss": 1.0319099426269531,
      "eval_runtime": 6.6972,
      "eval_samples_per_second": 3698.844,
      "eval_steps_per_second": 14.484,
      "step": 10320
    },
    {
      "epoch": 40.03883495145631,
      "grad_norm": 0.32836034893989563,
      "learning_rate": 0.0004554805516924567,
      "loss": 2.0949,
      "step": 10330
    },
    {
      "epoch": 40.077669902912625,
      "grad_norm": 0.3053673207759857,
      "learning_rate": 0.0004553925978649474,
      "loss": 2.0998,
      "step": 10340
    },
    {
      "epoch": 40.116504854368934,
      "grad_norm": 0.3322024345397949,
      "learning_rate": 0.00045530456575075496,
      "loss": 2.0826,
      "step": 10350
    },
    {
      "epoch": 40.15533980582524,
      "grad_norm": 0.3760985732078552,
      "learning_rate": 0.0004552164553834336,
      "loss": 2.0908,
      "step": 10360
    },
    {
      "epoch": 40.19417475728155,
      "grad_norm": 0.39770379662513733,
      "learning_rate": 0.00045512826679656705,
      "loss": 2.0871,
      "step": 10370
    },
    {
      "epoch": 40.23300970873787,
      "grad_norm": 0.36592012643814087,
      "learning_rate": 0.000455040000023769,
      "loss": 2.111,
      "step": 10380
    },
    {
      "epoch": 40.271844660194176,
      "grad_norm": 0.2902606725692749,
      "learning_rate": 0.00045495165509868275,
      "loss": 2.1055,
      "step": 10390
    },
    {
      "epoch": 40.310679611650485,
      "grad_norm": 0.2627865672111511,
      "learning_rate": 0.00045486323205498163,
      "loss": 2.1086,
      "step": 10400
    },
    {
      "epoch": 40.349514563106794,
      "grad_norm": 0.39308497309684753,
      "learning_rate": 0.00045477473092636866,
      "loss": 2.0966,
      "step": 10410
    },
    {
      "epoch": 40.38834951456311,
      "grad_norm": 0.39192238450050354,
      "learning_rate": 0.00045468615174657656,
      "loss": 2.0798,
      "step": 10420
    },
    {
      "epoch": 40.42718446601942,
      "grad_norm": 0.2719475030899048,
      "learning_rate": 0.0004545974945493678,
      "loss": 2.1035,
      "step": 10430
    },
    {
      "epoch": 40.46601941747573,
      "grad_norm": 0.277917742729187,
      "learning_rate": 0.00045450875936853475,
      "loss": 2.0933,
      "step": 10440
    },
    {
      "epoch": 40.50485436893204,
      "grad_norm": 0.3414122760295868,
      "learning_rate": 0.0004544199462378993,
      "loss": 2.0842,
      "step": 10450
    },
    {
      "epoch": 40.54368932038835,
      "grad_norm": 0.26996690034866333,
      "learning_rate": 0.00045433105519131315,
      "loss": 2.0973,
      "step": 10460
    },
    {
      "epoch": 40.58252427184466,
      "grad_norm": 0.38107413053512573,
      "learning_rate": 0.00045424208626265765,
      "loss": 2.0951,
      "step": 10470
    },
    {
      "epoch": 40.62135922330097,
      "grad_norm": 0.36625027656555176,
      "learning_rate": 0.00045415303948584396,
      "loss": 2.0892,
      "step": 10480
    },
    {
      "epoch": 40.66019417475728,
      "grad_norm": 0.41388240456581116,
      "learning_rate": 0.0004540639148948127,
      "loss": 2.099,
      "step": 10490
    },
    {
      "epoch": 40.699029126213595,
      "grad_norm": 0.2835780680179596,
      "learning_rate": 0.0004539747125235343,
      "loss": 2.0892,
      "step": 10500
    },
    {
      "epoch": 40.737864077669904,
      "grad_norm": 0.417501300573349,
      "learning_rate": 0.0004538854324060089,
      "loss": 2.0977,
      "step": 10510
    },
    {
      "epoch": 40.77669902912621,
      "grad_norm": 0.38746508955955505,
      "learning_rate": 0.0004537960745762661,
      "loss": 2.0966,
      "step": 10520
    },
    {
      "epoch": 40.81553398058252,
      "grad_norm": 0.28534016013145447,
      "learning_rate": 0.0004537066390683652,
      "loss": 2.0895,
      "step": 10530
    },
    {
      "epoch": 40.85436893203884,
      "grad_norm": 0.29712334275245667,
      "learning_rate": 0.00045361712591639517,
      "loss": 2.1127,
      "step": 10540
    },
    {
      "epoch": 40.89320388349515,
      "grad_norm": 0.29735320806503296,
      "learning_rate": 0.00045352753515447435,
      "loss": 2.0962,
      "step": 10550
    },
    {
      "epoch": 40.932038834951456,
      "grad_norm": 0.29113882780075073,
      "learning_rate": 0.00045343786681675103,
      "loss": 2.1098,
      "step": 10560
    },
    {
      "epoch": 40.970873786407765,
      "grad_norm": 0.34276536107063293,
      "learning_rate": 0.00045334812093740274,
      "loss": 2.0908,
      "step": 10570
    },
    {
      "epoch": 41.0,
      "eval_loss": 1.0323822498321533,
      "eval_runtime": 6.5091,
      "eval_samples_per_second": 3805.73,
      "eval_steps_per_second": 14.902,
      "step": 10578
    },
    {
      "epoch": 41.00776699029126,
      "grad_norm": 0.2768736183643341,
      "learning_rate": 0.00045325829755063675,
      "loss": 1.9909,
      "step": 10580
    },
    {
      "epoch": 41.046601941747575,
      "grad_norm": 0.2740004360675812,
      "learning_rate": 0.00045316839669068973,
      "loss": 2.1087,
      "step": 10590
    },
    {
      "epoch": 41.085436893203884,
      "grad_norm": 0.24602337181568146,
      "learning_rate": 0.00045307841839182795,
      "loss": 2.0961,
      "step": 10600
    },
    {
      "epoch": 41.12427184466019,
      "grad_norm": 0.26832011342048645,
      "learning_rate": 0.0004529883626883474,
      "loss": 2.0678,
      "step": 10610
    },
    {
      "epoch": 41.1631067961165,
      "grad_norm": 0.3325740694999695,
      "learning_rate": 0.0004528982296145731,
      "loss": 2.1033,
      "step": 10620
    },
    {
      "epoch": 41.20194174757282,
      "grad_norm": 0.283977210521698,
      "learning_rate": 0.00045280801920486005,
      "loss": 2.1106,
      "step": 10630
    },
    {
      "epoch": 41.24077669902913,
      "grad_norm": 0.2787647247314453,
      "learning_rate": 0.0004527177314935924,
      "loss": 2.1095,
      "step": 10640
    },
    {
      "epoch": 41.279611650485435,
      "grad_norm": 0.29003652930259705,
      "learning_rate": 0.00045262736651518397,
      "loss": 2.0842,
      "step": 10650
    },
    {
      "epoch": 41.318446601941744,
      "grad_norm": 0.3601166605949402,
      "learning_rate": 0.0004525369243040779,
      "loss": 2.1027,
      "step": 10660
    },
    {
      "epoch": 41.35728155339806,
      "grad_norm": 0.8708623051643372,
      "learning_rate": 0.0004524464048947468,
      "loss": 2.0955,
      "step": 10670
    },
    {
      "epoch": 41.39611650485437,
      "grad_norm": 0.2934136986732483,
      "learning_rate": 0.0004523558083216927,
      "loss": 2.0705,
      "step": 10680
    },
    {
      "epoch": 41.43495145631068,
      "grad_norm": 0.2573709189891815,
      "learning_rate": 0.0004522651346194471,
      "loss": 2.0947,
      "step": 10690
    },
    {
      "epoch": 41.47378640776699,
      "grad_norm": 0.2806890606880188,
      "learning_rate": 0.0004521743838225708,
      "loss": 2.0972,
      "step": 10700
    },
    {
      "epoch": 41.5126213592233,
      "grad_norm": 0.3097350001335144,
      "learning_rate": 0.0004520835559656541,
      "loss": 2.1012,
      "step": 10710
    },
    {
      "epoch": 41.55145631067961,
      "grad_norm": 0.516118049621582,
      "learning_rate": 0.0004519926510833165,
      "loss": 2.1044,
      "step": 10720
    },
    {
      "epoch": 41.59029126213592,
      "grad_norm": 0.2927260100841522,
      "learning_rate": 0.0004519016692102071,
      "loss": 2.0918,
      "step": 10730
    },
    {
      "epoch": 41.62912621359223,
      "grad_norm": 0.37730708718299866,
      "learning_rate": 0.0004518106103810041,
      "loss": 2.0956,
      "step": 10740
    },
    {
      "epoch": 41.667961165048546,
      "grad_norm": 0.2719295918941498,
      "learning_rate": 0.00045171947463041527,
      "loss": 2.0889,
      "step": 10750
    },
    {
      "epoch": 41.706796116504854,
      "grad_norm": 0.24693626165390015,
      "learning_rate": 0.00045162826199317746,
      "loss": 2.0918,
      "step": 10760
    },
    {
      "epoch": 41.74563106796116,
      "grad_norm": 0.32724636793136597,
      "learning_rate": 0.000451536972504057,
      "loss": 2.0975,
      "step": 10770
    },
    {
      "epoch": 41.78446601941748,
      "grad_norm": 0.290646493434906,
      "learning_rate": 0.0004514456061978495,
      "loss": 2.0916,
      "step": 10780
    },
    {
      "epoch": 41.82330097087379,
      "grad_norm": 0.28148454427719116,
      "learning_rate": 0.0004513541631093797,
      "loss": 2.0965,
      "step": 10790
    },
    {
      "epoch": 41.8621359223301,
      "grad_norm": 0.25566089153289795,
      "learning_rate": 0.00045126264327350176,
      "loss": 2.0895,
      "step": 10800
    },
    {
      "epoch": 41.900970873786406,
      "grad_norm": 0.2961069941520691,
      "learning_rate": 0.000451171046725099,
      "loss": 2.0906,
      "step": 10810
    },
    {
      "epoch": 41.93980582524272,
      "grad_norm": 0.27161315083503723,
      "learning_rate": 0.0004510793734990841,
      "loss": 2.0957,
      "step": 10820
    },
    {
      "epoch": 41.97864077669903,
      "grad_norm": 0.25190064311027527,
      "learning_rate": 0.00045098762363039886,
      "loss": 2.1018,
      "step": 10830
    },
    {
      "epoch": 42.0,
      "eval_loss": 1.0312646627426147,
      "eval_runtime": 6.5192,
      "eval_samples_per_second": 3799.882,
      "eval_steps_per_second": 14.879,
      "step": 10836
    },
    {
      "epoch": 42.015533980582525,
      "grad_norm": 0.3695134222507477,
      "learning_rate": 0.0004508957971540143,
      "loss": 1.9924,
      "step": 10840
    },
    {
      "epoch": 42.054368932038834,
      "grad_norm": 0.30607151985168457,
      "learning_rate": 0.0004508038941049306,
      "loss": 2.086,
      "step": 10850
    },
    {
      "epoch": 42.09320388349514,
      "grad_norm": 0.3336854875087738,
      "learning_rate": 0.0004507119145181774,
      "loss": 2.0888,
      "step": 10860
    },
    {
      "epoch": 42.13203883495146,
      "grad_norm": 0.2941340506076813,
      "learning_rate": 0.00045061985842881304,
      "loss": 2.1044,
      "step": 10870
    },
    {
      "epoch": 42.17087378640777,
      "grad_norm": 0.33872881531715393,
      "learning_rate": 0.00045052772587192544,
      "loss": 2.0824,
      "step": 10880
    },
    {
      "epoch": 42.20970873786408,
      "grad_norm": 0.26498329639434814,
      "learning_rate": 0.00045043551688263143,
      "loss": 2.0928,
      "step": 10890
    },
    {
      "epoch": 42.248543689320385,
      "grad_norm": 0.28879329562187195,
      "learning_rate": 0.0004503432314960771,
      "loss": 2.0942,
      "step": 10900
    },
    {
      "epoch": 42.2873786407767,
      "grad_norm": 0.2549823820590973,
      "learning_rate": 0.00045025086974743756,
      "loss": 2.1007,
      "step": 10910
    },
    {
      "epoch": 42.32621359223301,
      "grad_norm": 0.27952462434768677,
      "learning_rate": 0.0004501584316719171,
      "loss": 2.0933,
      "step": 10920
    },
    {
      "epoch": 42.36504854368932,
      "grad_norm": 0.2949116826057434,
      "learning_rate": 0.0004500659173047491,
      "loss": 2.1029,
      "step": 10930
    },
    {
      "epoch": 42.40388349514563,
      "grad_norm": 0.2950270175933838,
      "learning_rate": 0.0004499733266811959,
      "loss": 2.1028,
      "step": 10940
    },
    {
      "epoch": 42.442718446601944,
      "grad_norm": 0.35020676255226135,
      "learning_rate": 0.0004498806598365491,
      "loss": 2.1011,
      "step": 10950
    },
    {
      "epoch": 42.48155339805825,
      "grad_norm": 0.26571759581565857,
      "learning_rate": 0.0004497879168061292,
      "loss": 2.0924,
      "step": 10960
    },
    {
      "epoch": 42.52038834951456,
      "grad_norm": 0.2666589617729187,
      "learning_rate": 0.0004496950976252858,
      "loss": 2.0986,
      "step": 10970
    },
    {
      "epoch": 42.55922330097087,
      "grad_norm": 0.26202890276908875,
      "learning_rate": 0.0004496022023293976,
      "loss": 2.0923,
      "step": 10980
    },
    {
      "epoch": 42.59805825242719,
      "grad_norm": 0.3083648979663849,
      "learning_rate": 0.0004495092309538721,
      "loss": 2.094,
      "step": 10990
    },
    {
      "epoch": 42.636893203883496,
      "grad_norm": 0.2386852204799652,
      "learning_rate": 0.00044941618353414595,
      "loss": 2.0975,
      "step": 11000
    },
    {
      "epoch": 42.675728155339804,
      "grad_norm": 0.28429603576660156,
      "learning_rate": 0.0004493230601056848,
      "loss": 2.0931,
      "step": 11010
    },
    {
      "epoch": 42.71456310679611,
      "grad_norm": 0.26068830490112305,
      "learning_rate": 0.0004492298607039832,
      "loss": 2.0805,
      "step": 11020
    },
    {
      "epoch": 42.75339805825243,
      "grad_norm": 0.33286961913108826,
      "learning_rate": 0.0004491365853645647,
      "loss": 2.0841,
      "step": 11030
    },
    {
      "epoch": 42.79223300970874,
      "grad_norm": 0.28309309482574463,
      "learning_rate": 0.0004490432341229819,
      "loss": 2.0851,
      "step": 11040
    },
    {
      "epoch": 42.83106796116505,
      "grad_norm": 0.27342087030410767,
      "learning_rate": 0.00044894980701481595,
      "loss": 2.0996,
      "step": 11050
    },
    {
      "epoch": 42.869902912621356,
      "grad_norm": 0.29151472449302673,
      "learning_rate": 0.0004488563040756774,
      "loss": 2.0847,
      "step": 11060
    },
    {
      "epoch": 42.90873786407767,
      "grad_norm": 0.34421849250793457,
      "learning_rate": 0.00044876272534120546,
      "loss": 2.1012,
      "step": 11070
    },
    {
      "epoch": 42.94757281553398,
      "grad_norm": 0.32702210545539856,
      "learning_rate": 0.0004486690708470681,
      "loss": 2.1098,
      "step": 11080
    },
    {
      "epoch": 42.98640776699029,
      "grad_norm": 0.3318161964416504,
      "learning_rate": 0.00044857534062896253,
      "loss": 2.0755,
      "step": 11090
    },
    {
      "epoch": 43.0,
      "eval_loss": 1.0315533876419067,
      "eval_runtime": 6.5501,
      "eval_samples_per_second": 3781.93,
      "eval_steps_per_second": 14.809,
      "step": 11094
    },
    {
      "epoch": 43.023300970873784,
      "grad_norm": 0.3197917938232422,
      "learning_rate": 0.0004484815347226144,
      "loss": 1.9914,
      "step": 11100
    },
    {
      "epoch": 43.0621359223301,
      "grad_norm": 0.2749590575695038,
      "learning_rate": 0.0004483876531637787,
      "loss": 2.102,
      "step": 11110
    },
    {
      "epoch": 43.10097087378641,
      "grad_norm": 0.45103317499160767,
      "learning_rate": 0.0004482936959882388,
      "loss": 2.0907,
      "step": 11120
    },
    {
      "epoch": 43.13980582524272,
      "grad_norm": 0.30809205770492554,
      "learning_rate": 0.00044819966323180697,
      "loss": 2.0808,
      "step": 11130
    },
    {
      "epoch": 43.17864077669903,
      "grad_norm": 0.31572991609573364,
      "learning_rate": 0.0004481055549303246,
      "loss": 2.098,
      "step": 11140
    },
    {
      "epoch": 43.21747572815534,
      "grad_norm": 0.36157530546188354,
      "learning_rate": 0.0004480113711196615,
      "loss": 2.0859,
      "step": 11150
    },
    {
      "epoch": 43.25631067961165,
      "grad_norm": 0.2933172881603241,
      "learning_rate": 0.0004479171118357165,
      "loss": 2.0865,
      "step": 11160
    },
    {
      "epoch": 43.29514563106796,
      "grad_norm": 1.0041860342025757,
      "learning_rate": 0.0004478227771144171,
      "loss": 2.0989,
      "step": 11170
    },
    {
      "epoch": 43.33398058252427,
      "grad_norm": 0.389392226934433,
      "learning_rate": 0.0004477283669917196,
      "loss": 2.0843,
      "step": 11180
    },
    {
      "epoch": 43.372815533980585,
      "grad_norm": 0.27177348732948303,
      "learning_rate": 0.00044763388150360905,
      "loss": 2.0851,
      "step": 11190
    },
    {
      "epoch": 43.411650485436894,
      "grad_norm": 0.26395076513290405,
      "learning_rate": 0.00044753932068609904,
      "loss": 2.0925,
      "step": 11200
    },
    {
      "epoch": 43.4504854368932,
      "grad_norm": 0.31133610010147095,
      "learning_rate": 0.00044744468457523224,
      "loss": 2.0886,
      "step": 11210
    },
    {
      "epoch": 43.48932038834951,
      "grad_norm": 0.3457876443862915,
      "learning_rate": 0.00044734997320707953,
      "loss": 2.0917,
      "step": 11220
    },
    {
      "epoch": 43.52815533980583,
      "grad_norm": 0.2807832956314087,
      "learning_rate": 0.000447255186617741,
      "loss": 2.0912,
      "step": 11230
    },
    {
      "epoch": 43.56699029126214,
      "grad_norm": 0.3295440971851349,
      "learning_rate": 0.00044716032484334503,
      "loss": 2.0968,
      "step": 11240
    },
    {
      "epoch": 43.605825242718446,
      "grad_norm": 0.2589128315448761,
      "learning_rate": 0.00044706538792004875,
      "loss": 2.0933,
      "step": 11250
    },
    {
      "epoch": 43.644660194174755,
      "grad_norm": 0.3163987398147583,
      "learning_rate": 0.00044697037588403807,
      "loss": 2.0967,
      "step": 11260
    },
    {
      "epoch": 43.68349514563107,
      "grad_norm": 0.35260209441185,
      "learning_rate": 0.0004468752887715273,
      "loss": 2.0816,
      "step": 11270
    },
    {
      "epoch": 43.72233009708738,
      "grad_norm": 0.29633858799934387,
      "learning_rate": 0.00044678012661875967,
      "loss": 2.1001,
      "step": 11280
    },
    {
      "epoch": 43.76116504854369,
      "grad_norm": 0.32986998558044434,
      "learning_rate": 0.00044668488946200663,
      "loss": 2.0876,
      "step": 11290
    },
    {
      "epoch": 43.8,
      "grad_norm": 0.2616370916366577,
      "learning_rate": 0.00044658957733756854,
      "loss": 2.0935,
      "step": 11300
    },
    {
      "epoch": 43.83883495145631,
      "grad_norm": 0.2792101204395294,
      "learning_rate": 0.0004464941902817743,
      "loss": 2.0949,
      "step": 11310
    },
    {
      "epoch": 43.87766990291262,
      "grad_norm": 0.2889719605445862,
      "learning_rate": 0.00044639872833098106,
      "loss": 2.097,
      "step": 11320
    },
    {
      "epoch": 43.91650485436893,
      "grad_norm": 0.29609039425849915,
      "learning_rate": 0.00044630319152157497,
      "loss": 2.1037,
      "step": 11330
    },
    {
      "epoch": 43.95533980582524,
      "grad_norm": 0.2980957329273224,
      "learning_rate": 0.0004462075798899703,
      "loss": 2.0961,
      "step": 11340
    },
    {
      "epoch": 43.994174757281556,
      "grad_norm": 0.33410003781318665,
      "learning_rate": 0.00044611189347261015,
      "loss": 2.1017,
      "step": 11350
    },
    {
      "epoch": 44.0,
      "eval_loss": 1.0313947200775146,
      "eval_runtime": 6.5429,
      "eval_samples_per_second": 3786.099,
      "eval_steps_per_second": 14.825,
      "step": 11352
    },
    {
      "epoch": 44.03106796116505,
      "grad_norm": 0.4915136396884918,
      "learning_rate": 0.0004460161323059659,
      "loss": 1.9724,
      "step": 11360
    },
    {
      "epoch": 44.06990291262136,
      "grad_norm": 0.26313865184783936,
      "learning_rate": 0.00044592029642653776,
      "loss": 2.0737,
      "step": 11370
    },
    {
      "epoch": 44.10873786407767,
      "grad_norm": 0.3513748049736023,
      "learning_rate": 0.0004458243858708538,
      "loss": 2.1048,
      "step": 11380
    },
    {
      "epoch": 44.147572815533984,
      "grad_norm": 0.47524893283843994,
      "learning_rate": 0.00044572840067547126,
      "loss": 2.0865,
      "step": 11390
    },
    {
      "epoch": 44.18640776699029,
      "grad_norm": 0.31294581294059753,
      "learning_rate": 0.00044563234087697536,
      "loss": 2.0848,
      "step": 11400
    },
    {
      "epoch": 44.2252427184466,
      "grad_norm": 0.2721862494945526,
      "learning_rate": 0.0004455362065119799,
      "loss": 2.083,
      "step": 11410
    },
    {
      "epoch": 44.26407766990291,
      "grad_norm": 0.28804126381874084,
      "learning_rate": 0.00044543999761712715,
      "loss": 2.078,
      "step": 11420
    },
    {
      "epoch": 44.302912621359226,
      "grad_norm": 0.27100425958633423,
      "learning_rate": 0.0004453437142290877,
      "loss": 2.0971,
      "step": 11430
    },
    {
      "epoch": 44.341747572815535,
      "grad_norm": 0.38332900404930115,
      "learning_rate": 0.0004452473563845606,
      "loss": 2.0843,
      "step": 11440
    },
    {
      "epoch": 44.380582524271844,
      "grad_norm": 0.3266429901123047,
      "learning_rate": 0.00044515092412027315,
      "loss": 2.0987,
      "step": 11450
    },
    {
      "epoch": 44.41941747572815,
      "grad_norm": 0.31928059458732605,
      "learning_rate": 0.0004450544174729812,
      "loss": 2.1005,
      "step": 11460
    },
    {
      "epoch": 44.45825242718447,
      "grad_norm": 0.27517372369766235,
      "learning_rate": 0.00044495783647946886,
      "loss": 2.1007,
      "step": 11470
    },
    {
      "epoch": 44.49708737864078,
      "grad_norm": 0.3972867727279663,
      "learning_rate": 0.0004448611811765486,
      "loss": 2.0983,
      "step": 11480
    },
    {
      "epoch": 44.53592233009709,
      "grad_norm": 0.4004780650138855,
      "learning_rate": 0.0004447644516010612,
      "loss": 2.0844,
      "step": 11490
    },
    {
      "epoch": 44.574757281553396,
      "grad_norm": 0.32431820034980774,
      "learning_rate": 0.00044466764778987566,
      "loss": 2.0915,
      "step": 11500
    },
    {
      "epoch": 44.61359223300971,
      "grad_norm": 0.3007153272628784,
      "learning_rate": 0.00044457076977988955,
      "loss": 2.0984,
      "step": 11510
    },
    {
      "epoch": 44.65242718446602,
      "grad_norm": 0.3308848738670349,
      "learning_rate": 0.00044447381760802824,
      "loss": 2.0837,
      "step": 11520
    },
    {
      "epoch": 44.69126213592233,
      "grad_norm": 0.40817534923553467,
      "learning_rate": 0.000444376791311246,
      "loss": 2.0978,
      "step": 11530
    },
    {
      "epoch": 44.73009708737864,
      "grad_norm": 0.32134467363357544,
      "learning_rate": 0.0004442796909265247,
      "loss": 2.0764,
      "step": 11540
    },
    {
      "epoch": 44.768932038834954,
      "grad_norm": 0.3136163353919983,
      "learning_rate": 0.0004441825164908749,
      "loss": 2.0929,
      "step": 11550
    },
    {
      "epoch": 44.80776699029126,
      "grad_norm": 0.5699020624160767,
      "learning_rate": 0.0004440852680413354,
      "loss": 2.109,
      "step": 11560
    },
    {
      "epoch": 44.84660194174757,
      "grad_norm": 0.3522476553916931,
      "learning_rate": 0.00044398794561497284,
      "loss": 2.0923,
      "step": 11570
    },
    {
      "epoch": 44.88543689320388,
      "grad_norm": 0.3633773922920227,
      "learning_rate": 0.0004438905492488824,
      "loss": 2.0796,
      "step": 11580
    },
    {
      "epoch": 44.9242718446602,
      "grad_norm": 0.31613674759864807,
      "learning_rate": 0.00044379307898018724,
      "loss": 2.1084,
      "step": 11590
    },
    {
      "epoch": 44.963106796116506,
      "grad_norm": 0.5850658416748047,
      "learning_rate": 0.00044369553484603874,
      "loss": 2.0892,
      "step": 11600
    },
    {
      "epoch": 45.0,
      "grad_norm": 0.45199939608573914,
      "learning_rate": 0.0004435979168836166,
      "loss": 1.9921,
      "step": 11610
    },
    {
      "epoch": 45.0,
      "eval_loss": 1.0317111015319824,
      "eval_runtime": 6.5051,
      "eval_samples_per_second": 3808.113,
      "eval_steps_per_second": 14.911,
      "step": 11610
    },
    {
      "epoch": 45.03883495145631,
      "grad_norm": 0.2925012409687042,
      "learning_rate": 0.00044350022513012845,
      "loss": 2.0824,
      "step": 11620
    },
    {
      "epoch": 45.077669902912625,
      "grad_norm": 0.4024098813533783,
      "learning_rate": 0.0004434024596228101,
      "loss": 2.0804,
      "step": 11630
    },
    {
      "epoch": 45.116504854368934,
      "grad_norm": 0.32288798689842224,
      "learning_rate": 0.0004433046203989254,
      "loss": 2.083,
      "step": 11640
    },
    {
      "epoch": 45.15533980582524,
      "grad_norm": 0.293378621339798,
      "learning_rate": 0.00044320670749576664,
      "loss": 2.0829,
      "step": 11650
    },
    {
      "epoch": 45.19417475728155,
      "grad_norm": 0.2994358539581299,
      "learning_rate": 0.00044310872095065367,
      "loss": 2.09,
      "step": 11660
    },
    {
      "epoch": 45.23300970873787,
      "grad_norm": 0.31861600279808044,
      "learning_rate": 0.0004430106608009349,
      "loss": 2.0865,
      "step": 11670
    },
    {
      "epoch": 45.271844660194176,
      "grad_norm": 0.2973657250404358,
      "learning_rate": 0.0004429125270839864,
      "loss": 2.073,
      "step": 11680
    },
    {
      "epoch": 45.310679611650485,
      "grad_norm": 0.3792996406555176,
      "learning_rate": 0.0004428143198372125,
      "loss": 2.0967,
      "step": 11690
    },
    {
      "epoch": 45.349514563106794,
      "grad_norm": 0.35575875639915466,
      "learning_rate": 0.0004427160390980456,
      "loss": 2.0812,
      "step": 11700
    },
    {
      "epoch": 45.38834951456311,
      "grad_norm": 0.3465070426464081,
      "learning_rate": 0.0004426176849039459,
      "loss": 2.0879,
      "step": 11710
    },
    {
      "epoch": 45.42718446601942,
      "grad_norm": 0.29857590794563293,
      "learning_rate": 0.00044251925729240184,
      "loss": 2.0884,
      "step": 11720
    },
    {
      "epoch": 45.46601941747573,
      "grad_norm": 0.3090818524360657,
      "learning_rate": 0.00044242075630092966,
      "loss": 2.0945,
      "step": 11730
    },
    {
      "epoch": 45.50485436893204,
      "grad_norm": 0.31689926981925964,
      "learning_rate": 0.00044232218196707355,
      "loss": 2.0922,
      "step": 11740
    },
    {
      "epoch": 45.54368932038835,
      "grad_norm": 0.33112257719039917,
      "learning_rate": 0.00044222353432840595,
      "loss": 2.0903,
      "step": 11750
    },
    {
      "epoch": 45.58252427184466,
      "grad_norm": 0.376426100730896,
      "learning_rate": 0.0004421248134225269,
      "loss": 2.0895,
      "step": 11760
    },
    {
      "epoch": 45.62135922330097,
      "grad_norm": 0.32838529348373413,
      "learning_rate": 0.0004420260192870644,
      "loss": 2.0859,
      "step": 11770
    },
    {
      "epoch": 45.66019417475728,
      "grad_norm": 0.3326028883457184,
      "learning_rate": 0.0004419271519596746,
      "loss": 2.0925,
      "step": 11780
    },
    {
      "epoch": 45.699029126213595,
      "grad_norm": 0.34095436334609985,
      "learning_rate": 0.0004418282114780413,
      "loss": 2.0996,
      "step": 11790
    },
    {
      "epoch": 45.737864077669904,
      "grad_norm": 0.3619087338447571,
      "learning_rate": 0.00044172919787987646,
      "loss": 2.0822,
      "step": 11800
    },
    {
      "epoch": 45.77669902912621,
      "grad_norm": 0.376369446516037,
      "learning_rate": 0.0004416301112029196,
      "loss": 2.0849,
      "step": 11810
    },
    {
      "epoch": 45.81553398058252,
      "grad_norm": 0.4085136651992798,
      "learning_rate": 0.00044153095148493824,
      "loss": 2.0924,
      "step": 11820
    },
    {
      "epoch": 45.85436893203884,
      "grad_norm": 0.3029992878437042,
      "learning_rate": 0.00044143171876372773,
      "loss": 2.1031,
      "step": 11830
    },
    {
      "epoch": 45.89320388349515,
      "grad_norm": 0.2684724032878876,
      "learning_rate": 0.0004413324130771113,
      "loss": 2.0851,
      "step": 11840
    },
    {
      "epoch": 45.932038834951456,
      "grad_norm": 0.3571508824825287,
      "learning_rate": 0.00044123303446293996,
      "loss": 2.1066,
      "step": 11850
    },
    {
      "epoch": 45.970873786407765,
      "grad_norm": 0.3157380223274231,
      "learning_rate": 0.0004411335829590923,
      "loss": 2.1134,
      "step": 11860
    },
    {
      "epoch": 46.0,
      "eval_loss": 1.0320407152175903,
      "eval_runtime": 6.495,
      "eval_samples_per_second": 3814.002,
      "eval_steps_per_second": 14.935,
      "step": 11868
    },
    {
      "epoch": 46.00776699029126,
      "grad_norm": 0.42206335067749023,
      "learning_rate": 0.00044103405860347513,
      "loss": 1.9883,
      "step": 11870
    },
    {
      "epoch": 46.046601941747575,
      "grad_norm": 0.3214920461177826,
      "learning_rate": 0.00044093446143402264,
      "loss": 2.0784,
      "step": 11880
    },
    {
      "epoch": 46.085436893203884,
      "grad_norm": 0.2921634018421173,
      "learning_rate": 0.000440834791488697,
      "loss": 2.077,
      "step": 11890
    },
    {
      "epoch": 46.12427184466019,
      "grad_norm": 0.3072816729545593,
      "learning_rate": 0.00044073504880548796,
      "loss": 2.0779,
      "step": 11900
    },
    {
      "epoch": 46.1631067961165,
      "grad_norm": 0.37839779257774353,
      "learning_rate": 0.0004406352334224131,
      "loss": 2.0782,
      "step": 11910
    },
    {
      "epoch": 46.20194174757282,
      "grad_norm": 0.36841508746147156,
      "learning_rate": 0.00044053534537751775,
      "loss": 2.0819,
      "step": 11920
    },
    {
      "epoch": 46.24077669902913,
      "grad_norm": 0.3346721827983856,
      "learning_rate": 0.00044043538470887476,
      "loss": 2.095,
      "step": 11930
    },
    {
      "epoch": 46.279611650485435,
      "grad_norm": 0.39102834463119507,
      "learning_rate": 0.0004403353514545849,
      "loss": 2.0902,
      "step": 11940
    },
    {
      "epoch": 46.318446601941744,
      "grad_norm": 0.3437961935997009,
      "learning_rate": 0.00044023524565277636,
      "loss": 2.0854,
      "step": 11950
    },
    {
      "epoch": 46.35728155339806,
      "grad_norm": 0.558367908000946,
      "learning_rate": 0.00044013506734160514,
      "loss": 2.0978,
      "step": 11960
    },
    {
      "epoch": 46.39611650485437,
      "grad_norm": 0.395675390958786,
      "learning_rate": 0.0004400348165592548,
      "loss": 2.0919,
      "step": 11970
    },
    {
      "epoch": 46.43495145631068,
      "grad_norm": 0.3301467001438141,
      "learning_rate": 0.0004399344933439365,
      "loss": 2.0906,
      "step": 11980
    },
    {
      "epoch": 46.47378640776699,
      "grad_norm": 0.39568302035331726,
      "learning_rate": 0.00043983409773388934,
      "loss": 2.089,
      "step": 11990
    },
    {
      "epoch": 46.5126213592233,
      "grad_norm": 0.97784423828125,
      "learning_rate": 0.0004397336297673794,
      "loss": 2.0907,
      "step": 12000
    },
    {
      "epoch": 46.55145631067961,
      "grad_norm": 0.3234374523162842,
      "learning_rate": 0.0004396330894827009,
      "loss": 2.096,
      "step": 12010
    },
    {
      "epoch": 46.59029126213592,
      "grad_norm": 0.3258405327796936,
      "learning_rate": 0.0004395324769181753,
      "loss": 2.0864,
      "step": 12020
    },
    {
      "epoch": 46.62912621359223,
      "grad_norm": 0.4241040349006653,
      "learning_rate": 0.0004394317921121518,
      "loss": 2.0975,
      "step": 12030
    },
    {
      "epoch": 46.667961165048546,
      "grad_norm": 0.36702054738998413,
      "learning_rate": 0.000439331035103007,
      "loss": 2.0955,
      "step": 12040
    },
    {
      "epoch": 46.706796116504854,
      "grad_norm": 0.3238159120082855,
      "learning_rate": 0.000439230205929145,
      "loss": 2.0906,
      "step": 12050
    },
    {
      "epoch": 46.74563106796116,
      "grad_norm": 0.40389248728752136,
      "learning_rate": 0.00043912930462899755,
      "loss": 2.0896,
      "step": 12060
    },
    {
      "epoch": 46.78446601941748,
      "grad_norm": 0.5058383345603943,
      "learning_rate": 0.0004390283312410238,
      "loss": 2.0815,
      "step": 12070
    },
    {
      "epoch": 46.82330097087379,
      "grad_norm": 0.35605400800704956,
      "learning_rate": 0.0004389272858037104,
      "loss": 2.0881,
      "step": 12080
    },
    {
      "epoch": 46.8621359223301,
      "grad_norm": 0.4281648099422455,
      "learning_rate": 0.0004388261683555714,
      "loss": 2.1093,
      "step": 12090
    },
    {
      "epoch": 46.900970873786406,
      "grad_norm": 0.4225132465362549,
      "learning_rate": 0.00043872497893514853,
      "loss": 2.086,
      "step": 12100
    },
    {
      "epoch": 46.93980582524272,
      "grad_norm": 0.3662753105163574,
      "learning_rate": 0.0004386237175810106,
      "loss": 2.0919,
      "step": 12110
    },
    {
      "epoch": 46.97864077669903,
      "grad_norm": 0.5020958781242371,
      "learning_rate": 0.0004385223843317541,
      "loss": 2.0932,
      "step": 12120
    },
    {
      "epoch": 47.0,
      "eval_loss": 1.031233787536621,
      "eval_runtime": 6.5488,
      "eval_samples_per_second": 3782.705,
      "eval_steps_per_second": 14.812,
      "step": 12126
    },
    {
      "epoch": 47.015533980582525,
      "grad_norm": 0.3175503611564636,
      "learning_rate": 0.00043842097922600266,
      "loss": 1.9881,
      "step": 12130
    },
    {
      "epoch": 47.054368932038834,
      "grad_norm": 0.3780826926231384,
      "learning_rate": 0.0004383195023024077,
      "loss": 2.0807,
      "step": 12140
    },
    {
      "epoch": 47.09320388349514,
      "grad_norm": 0.4170897603034973,
      "learning_rate": 0.00043821795359964773,
      "loss": 2.0841,
      "step": 12150
    },
    {
      "epoch": 47.13203883495146,
      "grad_norm": 0.48630160093307495,
      "learning_rate": 0.0004381163331564286,
      "loss": 2.0948,
      "step": 12160
    },
    {
      "epoch": 47.17087378640777,
      "grad_norm": 0.3729291260242462,
      "learning_rate": 0.0004380146410114837,
      "loss": 2.0866,
      "step": 12170
    },
    {
      "epoch": 47.20970873786408,
      "grad_norm": 0.38846996426582336,
      "learning_rate": 0.00043791287720357355,
      "loss": 2.0798,
      "step": 12180
    },
    {
      "epoch": 47.248543689320385,
      "grad_norm": 0.3656970262527466,
      "learning_rate": 0.000437811041771486,
      "loss": 2.0941,
      "step": 12190
    },
    {
      "epoch": 47.2873786407767,
      "grad_norm": 0.3760281205177307,
      "learning_rate": 0.0004377091347540364,
      "loss": 2.0944,
      "step": 12200
    },
    {
      "epoch": 47.32621359223301,
      "grad_norm": 0.470704048871994,
      "learning_rate": 0.00043760715619006724,
      "loss": 2.0793,
      "step": 12210
    },
    {
      "epoch": 47.36504854368932,
      "grad_norm": 0.41578149795532227,
      "learning_rate": 0.00043750510611844826,
      "loss": 2.0959,
      "step": 12220
    },
    {
      "epoch": 47.40388349514563,
      "grad_norm": 0.3497081398963928,
      "learning_rate": 0.00043740298457807644,
      "loss": 2.0947,
      "step": 12230
    },
    {
      "epoch": 47.442718446601944,
      "grad_norm": 0.37448540329933167,
      "learning_rate": 0.00043730079160787604,
      "loss": 2.0868,
      "step": 12240
    },
    {
      "epoch": 47.48155339805825,
      "grad_norm": 0.40084540843963623,
      "learning_rate": 0.0004371985272467987,
      "loss": 2.0948,
      "step": 12250
    },
    {
      "epoch": 47.52038834951456,
      "grad_norm": 0.3684196174144745,
      "learning_rate": 0.00043709619153382297,
      "loss": 2.0828,
      "step": 12260
    },
    {
      "epoch": 47.55922330097087,
      "grad_norm": 0.3821195363998413,
      "learning_rate": 0.0004369937845079549,
      "loss": 2.0862,
      "step": 12270
    },
    {
      "epoch": 47.59805825242719,
      "grad_norm": 0.3425518870353699,
      "learning_rate": 0.00043689130620822736,
      "loss": 2.0926,
      "step": 12280
    },
    {
      "epoch": 47.636893203883496,
      "grad_norm": 0.39240700006484985,
      "learning_rate": 0.0004367887566737008,
      "loss": 2.095,
      "step": 12290
    },
    {
      "epoch": 47.675728155339804,
      "grad_norm": 0.37904059886932373,
      "learning_rate": 0.00043668613594346253,
      "loss": 2.101,
      "step": 12300
    },
    {
      "epoch": 47.71456310679611,
      "grad_norm": 0.3851543068885803,
      "learning_rate": 0.00043658344405662707,
      "loss": 2.089,
      "step": 12310
    },
    {
      "epoch": 47.75339805825243,
      "grad_norm": 0.42514529824256897,
      "learning_rate": 0.00043648068105233616,
      "loss": 2.0862,
      "step": 12320
    },
    {
      "epoch": 47.79223300970874,
      "grad_norm": 0.37562572956085205,
      "learning_rate": 0.0004363778469697586,
      "loss": 2.0901,
      "step": 12330
    },
    {
      "epoch": 47.83106796116505,
      "grad_norm": 0.27549389004707336,
      "learning_rate": 0.00043627494184809003,
      "loss": 2.1048,
      "step": 12340
    },
    {
      "epoch": 47.869902912621356,
      "grad_norm": 0.38623154163360596,
      "learning_rate": 0.0004361719657265536,
      "loss": 2.0908,
      "step": 12350
    },
    {
      "epoch": 47.90873786407767,
      "grad_norm": 0.372957706451416,
      "learning_rate": 0.00043606891864439917,
      "loss": 2.0838,
      "step": 12360
    },
    {
      "epoch": 47.94757281553398,
      "grad_norm": 0.39943772554397583,
      "learning_rate": 0.0004359658006409039,
      "loss": 2.0795,
      "step": 12370
    },
    {
      "epoch": 47.98640776699029,
      "grad_norm": 0.3225038945674896,
      "learning_rate": 0.0004358626117553718,
      "loss": 2.0998,
      "step": 12380
    },
    {
      "epoch": 48.0,
      "eval_loss": 1.031786561012268,
      "eval_runtime": 6.5204,
      "eval_samples_per_second": 3799.141,
      "eval_steps_per_second": 14.876,
      "step": 12384
    },
    {
      "epoch": 48.023300970873784,
      "grad_norm": 0.31122663617134094,
      "learning_rate": 0.00043575935202713403,
      "loss": 1.9797,
      "step": 12390
    },
    {
      "epoch": 48.0621359223301,
      "grad_norm": 0.28052666783332825,
      "learning_rate": 0.00043565602149554854,
      "loss": 2.0872,
      "step": 12400
    },
    {
      "epoch": 48.10097087378641,
      "grad_norm": 0.2942943274974823,
      "learning_rate": 0.0004355526202000006,
      "loss": 2.0764,
      "step": 12410
    },
    {
      "epoch": 48.13980582524272,
      "grad_norm": 0.3455319404602051,
      "learning_rate": 0.00043544914817990213,
      "loss": 2.0938,
      "step": 12420
    },
    {
      "epoch": 48.17864077669903,
      "grad_norm": 0.4104972779750824,
      "learning_rate": 0.00043534560547469215,
      "loss": 2.0863,
      "step": 12430
    },
    {
      "epoch": 48.21747572815534,
      "grad_norm": 0.32109880447387695,
      "learning_rate": 0.0004352419921238367,
      "loss": 2.0952,
      "step": 12440
    },
    {
      "epoch": 48.25631067961165,
      "grad_norm": 0.35563910007476807,
      "learning_rate": 0.00043513830816682854,
      "loss": 2.0857,
      "step": 12450
    },
    {
      "epoch": 48.29514563106796,
      "grad_norm": 0.2684667408466339,
      "learning_rate": 0.00043503455364318766,
      "loss": 2.0878,
      "step": 12460
    },
    {
      "epoch": 48.33398058252427,
      "grad_norm": 0.3088495433330536,
      "learning_rate": 0.00043493072859246055,
      "loss": 2.0952,
      "step": 12470
    },
    {
      "epoch": 48.372815533980585,
      "grad_norm": 0.27734676003456116,
      "learning_rate": 0.00043482683305422085,
      "loss": 2.0794,
      "step": 12480
    },
    {
      "epoch": 48.411650485436894,
      "grad_norm": 0.3176569938659668,
      "learning_rate": 0.000434722867068069,
      "loss": 2.0874,
      "step": 12490
    },
    {
      "epoch": 48.4504854368932,
      "grad_norm": 0.2934632897377014,
      "learning_rate": 0.0004346188306736323,
      "loss": 2.0992,
      "step": 12500
    },
    {
      "epoch": 48.48932038834951,
      "grad_norm": 0.30890676379203796,
      "learning_rate": 0.00043451472391056495,
      "loss": 2.0928,
      "step": 12510
    },
    {
      "epoch": 48.52815533980583,
      "grad_norm": 0.29224199056625366,
      "learning_rate": 0.00043441054681854773,
      "loss": 2.0866,
      "step": 12520
    },
    {
      "epoch": 48.56699029126214,
      "grad_norm": 0.3249353766441345,
      "learning_rate": 0.0004343062994372886,
      "loss": 2.0864,
      "step": 12530
    },
    {
      "epoch": 48.605825242718446,
      "grad_norm": 0.4107992649078369,
      "learning_rate": 0.0004342019818065219,
      "loss": 2.0844,
      "step": 12540
    },
    {
      "epoch": 48.644660194174755,
      "grad_norm": 0.3164377212524414,
      "learning_rate": 0.00043409759396600907,
      "loss": 2.0976,
      "step": 12550
    },
    {
      "epoch": 48.68349514563107,
      "grad_norm": 0.27653878927230835,
      "learning_rate": 0.00043399313595553815,
      "loss": 2.0833,
      "step": 12560
    },
    {
      "epoch": 48.72233009708738,
      "grad_norm": 0.38227349519729614,
      "learning_rate": 0.000433888607814924,
      "loss": 2.0859,
      "step": 12570
    },
    {
      "epoch": 48.76116504854369,
      "grad_norm": 0.3920912742614746,
      "learning_rate": 0.0004337840095840082,
      "loss": 2.0846,
      "step": 12580
    },
    {
      "epoch": 48.8,
      "grad_norm": 0.3134373128414154,
      "learning_rate": 0.000433679341302659,
      "loss": 2.0911,
      "step": 12590
    },
    {
      "epoch": 48.83883495145631,
      "grad_norm": 0.43072184920310974,
      "learning_rate": 0.00043357460301077135,
      "loss": 2.1079,
      "step": 12600
    },
    {
      "epoch": 48.87766990291262,
      "grad_norm": 0.29419854283332825,
      "learning_rate": 0.000433469794748267,
      "loss": 2.0888,
      "step": 12610
    },
    {
      "epoch": 48.91650485436893,
      "grad_norm": 0.4085584580898285,
      "learning_rate": 0.0004333649165550941,
      "loss": 2.0744,
      "step": 12620
    },
    {
      "epoch": 48.95533980582524,
      "grad_norm": 0.2962542474269867,
      "learning_rate": 0.00043325996847122777,
      "loss": 2.0863,
      "step": 12630
    },
    {
      "epoch": 48.994174757281556,
      "grad_norm": 0.2533922493457794,
      "learning_rate": 0.00043315495053666966,
      "loss": 2.0838,
      "step": 12640
    },
    {
      "epoch": 49.0,
      "eval_loss": 1.030524730682373,
      "eval_runtime": 6.5369,
      "eval_samples_per_second": 3789.554,
      "eval_steps_per_second": 14.839,
      "step": 12642
    },
    {
      "epoch": 49.03106796116505,
      "grad_norm": 0.29980671405792236,
      "learning_rate": 0.00043304986279144785,
      "loss": 1.9617,
      "step": 12650
    },
    {
      "epoch": 49.06990291262136,
      "grad_norm": 0.2837027907371521,
      "learning_rate": 0.00043294470527561747,
      "loss": 2.0891,
      "step": 12660
    },
    {
      "epoch": 49.10873786407767,
      "grad_norm": 0.2959613800048828,
      "learning_rate": 0.0004328394780292597,
      "loss": 2.0888,
      "step": 12670
    },
    {
      "epoch": 49.147572815533984,
      "grad_norm": 0.2841423451900482,
      "learning_rate": 0.0004327341810924827,
      "loss": 2.0825,
      "step": 12680
    },
    {
      "epoch": 49.18640776699029,
      "grad_norm": 0.3176899552345276,
      "learning_rate": 0.000432628814505421,
      "loss": 2.0821,
      "step": 12690
    },
    {
      "epoch": 49.2252427184466,
      "grad_norm": 0.4542734920978546,
      "learning_rate": 0.00043252337830823584,
      "loss": 2.0946,
      "step": 12700
    },
    {
      "epoch": 49.26407766990291,
      "grad_norm": 0.37325114011764526,
      "learning_rate": 0.00043241787254111487,
      "loss": 2.0812,
      "step": 12710
    },
    {
      "epoch": 49.302912621359226,
      "grad_norm": 0.2880699038505554,
      "learning_rate": 0.00043231229724427213,
      "loss": 2.0855,
      "step": 12720
    },
    {
      "epoch": 49.341747572815535,
      "grad_norm": 0.2823934555053711,
      "learning_rate": 0.00043220665245794854,
      "loss": 2.0852,
      "step": 12730
    },
    {
      "epoch": 49.380582524271844,
      "grad_norm": 0.27659592032432556,
      "learning_rate": 0.00043210093822241104,
      "loss": 2.0868,
      "step": 12740
    },
    {
      "epoch": 49.41941747572815,
      "grad_norm": 0.3143651485443115,
      "learning_rate": 0.0004319951545779535,
      "loss": 2.0787,
      "step": 12750
    },
    {
      "epoch": 49.45825242718447,
      "grad_norm": 0.3345423936843872,
      "learning_rate": 0.0004318893015648958,
      "loss": 2.0921,
      "step": 12760
    },
    {
      "epoch": 49.49708737864078,
      "grad_norm": 0.3140992522239685,
      "learning_rate": 0.0004317833792235847,
      "loss": 2.074,
      "step": 12770
    },
    {
      "epoch": 49.53592233009709,
      "grad_norm": 0.31318560242652893,
      "learning_rate": 0.000431677387594393,
      "loss": 2.0963,
      "step": 12780
    },
    {
      "epoch": 49.574757281553396,
      "grad_norm": 0.3008446991443634,
      "learning_rate": 0.00043157132671772016,
      "loss": 2.0968,
      "step": 12790
    },
    {
      "epoch": 49.61359223300971,
      "grad_norm": 0.33332574367523193,
      "learning_rate": 0.0004314651966339919,
      "loss": 2.0926,
      "step": 12800
    },
    {
      "epoch": 49.65242718446602,
      "grad_norm": 0.4414856731891632,
      "learning_rate": 0.00043135899738366043,
      "loss": 2.0867,
      "step": 12810
    },
    {
      "epoch": 49.69126213592233,
      "grad_norm": 0.2972876727581024,
      "learning_rate": 0.00043125272900720424,
      "loss": 2.0808,
      "step": 12820
    },
    {
      "epoch": 49.73009708737864,
      "grad_norm": 0.3453153073787689,
      "learning_rate": 0.0004311463915451281,
      "loss": 2.0817,
      "step": 12830
    },
    {
      "epoch": 49.768932038834954,
      "grad_norm": 0.2777056097984314,
      "learning_rate": 0.00043103998503796345,
      "loss": 2.0976,
      "step": 12840
    },
    {
      "epoch": 49.80776699029126,
      "grad_norm": 0.3052529990673065,
      "learning_rate": 0.0004309335095262675,
      "loss": 2.084,
      "step": 12850
    },
    {
      "epoch": 49.84660194174757,
      "grad_norm": 0.3936610221862793,
      "learning_rate": 0.00043082696505062436,
      "loss": 2.0788,
      "step": 12860
    },
    {
      "epoch": 49.88543689320388,
      "grad_norm": 0.3916580080986023,
      "learning_rate": 0.0004307203516516438,
      "loss": 2.084,
      "step": 12870
    },
    {
      "epoch": 49.9242718446602,
      "grad_norm": 0.2871006429195404,
      "learning_rate": 0.0004306136693699625,
      "loss": 2.0851,
      "step": 12880
    },
    {
      "epoch": 49.963106796116506,
      "grad_norm": 0.2800235152244568,
      "learning_rate": 0.00043050691824624286,
      "loss": 2.0842,
      "step": 12890
    },
    {
      "epoch": 50.0,
      "grad_norm": 0.4006856679916382,
      "learning_rate": 0.0004304000983211739,
      "loss": 1.9724,
      "step": 12900
    },
    {
      "epoch": 50.0,
      "eval_loss": 1.0304120779037476,
      "eval_runtime": 6.5112,
      "eval_samples_per_second": 3804.55,
      "eval_steps_per_second": 14.898,
      "step": 12900
    },
    {
      "epoch": 50.03883495145631,
      "grad_norm": 0.2656415104866028,
      "learning_rate": 0.0004302932096354706,
      "loss": 2.0779,
      "step": 12910
    },
    {
      "epoch": 50.077669902912625,
      "grad_norm": 0.3519059121608734,
      "learning_rate": 0.0004301862522298743,
      "loss": 2.0592,
      "step": 12920
    },
    {
      "epoch": 50.116504854368934,
      "grad_norm": 0.2779659628868103,
      "learning_rate": 0.0004300792261451525,
      "loss": 2.0872,
      "step": 12930
    },
    {
      "epoch": 50.15533980582524,
      "grad_norm": 0.31210997700691223,
      "learning_rate": 0.00042997213142209877,
      "loss": 2.0832,
      "step": 12940
    },
    {
      "epoch": 50.19417475728155,
      "grad_norm": 0.31422990560531616,
      "learning_rate": 0.0004298649681015331,
      "loss": 2.0835,
      "step": 12950
    },
    {
      "epoch": 50.23300970873787,
      "grad_norm": 0.3071277439594269,
      "learning_rate": 0.00042975773622430137,
      "loss": 2.0674,
      "step": 12960
    },
    {
      "epoch": 50.271844660194176,
      "grad_norm": 0.48161715269088745,
      "learning_rate": 0.00042965043583127565,
      "loss": 2.0808,
      "step": 12970
    },
    {
      "epoch": 50.310679611650485,
      "grad_norm": 0.3231089413166046,
      "learning_rate": 0.00042954306696335424,
      "loss": 2.0808,
      "step": 12980
    },
    {
      "epoch": 50.349514563106794,
      "grad_norm": 0.3861757218837738,
      "learning_rate": 0.0004294356296614614,
      "loss": 2.0861,
      "step": 12990
    },
    {
      "epoch": 50.38834951456311,
      "grad_norm": 0.28331509232521057,
      "learning_rate": 0.0004293281239665476,
      "loss": 2.0819,
      "step": 13000
    },
    {
      "epoch": 50.42718446601942,
      "grad_norm": 0.2792426645755768,
      "learning_rate": 0.00042922054991958937,
      "loss": 2.0715,
      "step": 13010
    },
    {
      "epoch": 50.46601941747573,
      "grad_norm": 0.2633766233921051,
      "learning_rate": 0.00042911290756158897,
      "loss": 2.0784,
      "step": 13020
    },
    {
      "epoch": 50.50485436893204,
      "grad_norm": 0.2502445578575134,
      "learning_rate": 0.0004290051969335753,
      "loss": 2.0957,
      "step": 13030
    },
    {
      "epoch": 50.54368932038835,
      "grad_norm": 0.33186379075050354,
      "learning_rate": 0.00042889741807660266,
      "loss": 2.0884,
      "step": 13040
    },
    {
      "epoch": 50.58252427184466,
      "grad_norm": 0.34277480840682983,
      "learning_rate": 0.0004287895710317518,
      "loss": 2.0933,
      "step": 13050
    },
    {
      "epoch": 50.62135922330097,
      "grad_norm": 0.34840062260627747,
      "learning_rate": 0.0004286816558401292,
      "loss": 2.0808,
      "step": 13060
    },
    {
      "epoch": 50.66019417475728,
      "grad_norm": 0.30160725116729736,
      "learning_rate": 0.0004285736725428676,
      "loss": 2.0816,
      "step": 13070
    },
    {
      "epoch": 50.699029126213595,
      "grad_norm": 0.27754393219947815,
      "learning_rate": 0.0004284656211811253,
      "loss": 2.0948,
      "step": 13080
    },
    {
      "epoch": 50.737864077669904,
      "grad_norm": 0.25235843658447266,
      "learning_rate": 0.0004283575017960869,
      "loss": 2.09,
      "step": 13090
    },
    {
      "epoch": 50.77669902912621,
      "grad_norm": 0.25157636404037476,
      "learning_rate": 0.0004282493144289627,
      "loss": 2.0947,
      "step": 13100
    },
    {
      "epoch": 50.81553398058252,
      "grad_norm": 0.26897281408309937,
      "learning_rate": 0.0004281410591209891,
      "loss": 2.0825,
      "step": 13110
    },
    {
      "epoch": 50.85436893203884,
      "grad_norm": 0.3583489954471588,
      "learning_rate": 0.00042803273591342813,
      "loss": 2.0884,
      "step": 13120
    },
    {
      "epoch": 50.89320388349515,
      "grad_norm": 0.2762218713760376,
      "learning_rate": 0.00042792434484756797,
      "loss": 2.0971,
      "step": 13130
    },
    {
      "epoch": 50.932038834951456,
      "grad_norm": 0.3103223741054535,
      "learning_rate": 0.00042781588596472255,
      "loss": 2.0882,
      "step": 13140
    },
    {
      "epoch": 50.970873786407765,
      "grad_norm": 0.3350348472595215,
      "learning_rate": 0.00042770735930623173,
      "loss": 2.0896,
      "step": 13150
    },
    {
      "epoch": 51.0,
      "eval_loss": 1.0304298400878906,
      "eval_runtime": 6.557,
      "eval_samples_per_second": 3777.933,
      "eval_steps_per_second": 14.793,
      "step": 13158
    },
    {
      "epoch": 51.00776699029126,
      "grad_norm": 0.2708371579647064,
      "learning_rate": 0.0004275987649134609,
      "loss": 1.9791,
      "step": 13160
    },
    {
      "epoch": 51.046601941747575,
      "grad_norm": 0.284994900226593,
      "learning_rate": 0.0004274901028278018,
      "loss": 2.079,
      "step": 13170
    },
    {
      "epoch": 51.085436893203884,
      "grad_norm": 0.2922776937484741,
      "learning_rate": 0.0004273813730906715,
      "loss": 2.0754,
      "step": 13180
    },
    {
      "epoch": 51.12427184466019,
      "grad_norm": 0.33816251158714294,
      "learning_rate": 0.00042727257574351295,
      "loss": 2.0755,
      "step": 13190
    },
    {
      "epoch": 51.1631067961165,
      "grad_norm": 0.3350585699081421,
      "learning_rate": 0.0004271637108277951,
      "loss": 2.0927,
      "step": 13200
    },
    {
      "epoch": 51.20194174757282,
      "grad_norm": 0.2895492613315582,
      "learning_rate": 0.00042705477838501243,
      "loss": 2.0831,
      "step": 13210
    },
    {
      "epoch": 51.24077669902913,
      "grad_norm": 0.36155545711517334,
      "learning_rate": 0.00042694577845668526,
      "loss": 2.0797,
      "step": 13220
    },
    {
      "epoch": 51.279611650485435,
      "grad_norm": 0.3201759457588196,
      "learning_rate": 0.0004268367110843595,
      "loss": 2.0688,
      "step": 13230
    },
    {
      "epoch": 51.318446601941744,
      "grad_norm": 0.5149784088134766,
      "learning_rate": 0.00042672757630960703,
      "loss": 2.0802,
      "step": 13240
    },
    {
      "epoch": 51.35728155339806,
      "grad_norm": 0.26859983801841736,
      "learning_rate": 0.00042661837417402507,
      "loss": 2.091,
      "step": 13250
    },
    {
      "epoch": 51.39611650485437,
      "grad_norm": 0.3153683841228485,
      "learning_rate": 0.0004265091047192368,
      "loss": 2.0744,
      "step": 13260
    },
    {
      "epoch": 51.43495145631068,
      "grad_norm": 0.3164708912372589,
      "learning_rate": 0.00042639976798689104,
      "loss": 2.0773,
      "step": 13270
    },
    {
      "epoch": 51.47378640776699,
      "grad_norm": 0.32518377900123596,
      "learning_rate": 0.000426290364018662,
      "loss": 2.0845,
      "step": 13280
    },
    {
      "epoch": 51.5126213592233,
      "grad_norm": 0.3159604072570801,
      "learning_rate": 0.00042618089285624983,
      "loss": 2.084,
      "step": 13290
    },
    {
      "epoch": 51.55145631067961,
      "grad_norm": 0.28468093276023865,
      "learning_rate": 0.0004260713545413801,
      "loss": 2.0818,
      "step": 13300
    },
    {
      "epoch": 51.59029126213592,
      "grad_norm": 0.8120964765548706,
      "learning_rate": 0.0004259617491158041,
      "loss": 2.0959,
      "step": 13310
    },
    {
      "epoch": 51.62912621359223,
      "grad_norm": 0.3156566917896271,
      "learning_rate": 0.0004258520766212985,
      "loss": 2.0609,
      "step": 13320
    },
    {
      "epoch": 51.667961165048546,
      "grad_norm": 0.2965889871120453,
      "learning_rate": 0.00042574233709966573,
      "loss": 2.0763,
      "step": 13330
    },
    {
      "epoch": 51.706796116504854,
      "grad_norm": 0.31962665915489197,
      "learning_rate": 0.00042563253059273376,
      "loss": 2.0818,
      "step": 13340
    },
    {
      "epoch": 51.74563106796116,
      "grad_norm": 0.35177740454673767,
      "learning_rate": 0.0004255226571423559,
      "loss": 2.0966,
      "step": 13350
    },
    {
      "epoch": 51.78446601941748,
      "grad_norm": 0.2692085802555084,
      "learning_rate": 0.00042541271679041116,
      "loss": 2.098,
      "step": 13360
    },
    {
      "epoch": 51.82330097087379,
      "grad_norm": 0.3700035512447357,
      "learning_rate": 0.00042530270957880415,
      "loss": 2.0906,
      "step": 13370
    },
    {
      "epoch": 51.8621359223301,
      "grad_norm": 0.3612454831600189,
      "learning_rate": 0.00042519263554946453,
      "loss": 2.0861,
      "step": 13380
    },
    {
      "epoch": 51.900970873786406,
      "grad_norm": 0.27589479088783264,
      "learning_rate": 0.0004250824947443479,
      "loss": 2.0833,
      "step": 13390
    },
    {
      "epoch": 51.93980582524272,
      "grad_norm": 0.29159441590309143,
      "learning_rate": 0.0004249722872054351,
      "loss": 2.0791,
      "step": 13400
    },
    {
      "epoch": 51.97864077669903,
      "grad_norm": 0.35945871472358704,
      "learning_rate": 0.00042486201297473237,
      "loss": 2.0815,
      "step": 13410
    },
    {
      "epoch": 52.0,
      "eval_loss": 1.029972791671753,
      "eval_runtime": 6.5966,
      "eval_samples_per_second": 3755.259,
      "eval_steps_per_second": 14.705,
      "step": 13416
    },
    {
      "epoch": 52.015533980582525,
      "grad_norm": 0.36278676986694336,
      "learning_rate": 0.0004247516720942716,
      "loss": 1.9849,
      "step": 13420
    },
    {
      "epoch": 52.054368932038834,
      "grad_norm": 0.2791709899902344,
      "learning_rate": 0.0004246412646061096,
      "loss": 2.086,
      "step": 13430
    },
    {
      "epoch": 52.09320388349514,
      "grad_norm": 0.2825530767440796,
      "learning_rate": 0.0004245307905523291,
      "loss": 2.0863,
      "step": 13440
    },
    {
      "epoch": 52.13203883495146,
      "grad_norm": 0.28460896015167236,
      "learning_rate": 0.000424420249975038,
      "loss": 2.0828,
      "step": 13450
    },
    {
      "epoch": 52.17087378640777,
      "grad_norm": 0.3180863559246063,
      "learning_rate": 0.00042430964291636944,
      "loss": 2.0754,
      "step": 13460
    },
    {
      "epoch": 52.20970873786408,
      "grad_norm": 0.37376704812049866,
      "learning_rate": 0.00042419896941848205,
      "loss": 2.0809,
      "step": 13470
    },
    {
      "epoch": 52.248543689320385,
      "grad_norm": 0.308149516582489,
      "learning_rate": 0.00042408822952355975,
      "loss": 2.0721,
      "step": 13480
    },
    {
      "epoch": 52.2873786407767,
      "grad_norm": 0.27983710169792175,
      "learning_rate": 0.0004239774232738117,
      "loss": 2.0695,
      "step": 13490
    },
    {
      "epoch": 52.32621359223301,
      "grad_norm": 0.3127840459346771,
      "learning_rate": 0.00042386655071147237,
      "loss": 2.096,
      "step": 13500
    },
    {
      "epoch": 52.36504854368932,
      "grad_norm": 0.3644263446331024,
      "learning_rate": 0.00042375561187880164,
      "loss": 2.1035,
      "step": 13510
    },
    {
      "epoch": 52.40388349514563,
      "grad_norm": 0.4087483882904053,
      "learning_rate": 0.0004236446068180844,
      "loss": 2.0802,
      "step": 13520
    },
    {
      "epoch": 52.442718446601944,
      "grad_norm": 0.29710498452186584,
      "learning_rate": 0.0004235335355716311,
      "loss": 2.0888,
      "step": 13530
    },
    {
      "epoch": 52.48155339805825,
      "grad_norm": 0.3447829782962799,
      "learning_rate": 0.00042342239818177706,
      "loss": 2.0884,
      "step": 13540
    },
    {
      "epoch": 52.52038834951456,
      "grad_norm": 0.37017661333084106,
      "learning_rate": 0.0004233111946908832,
      "loss": 2.0695,
      "step": 13550
    },
    {
      "epoch": 52.55922330097087,
      "grad_norm": 0.3541148006916046,
      "learning_rate": 0.0004231999251413353,
      "loss": 2.0798,
      "step": 13560
    },
    {
      "epoch": 52.59805825242719,
      "grad_norm": 0.3943348824977875,
      "learning_rate": 0.00042308858957554443,
      "loss": 2.0826,
      "step": 13570
    },
    {
      "epoch": 52.636893203883496,
      "grad_norm": 0.30355286598205566,
      "learning_rate": 0.00042297718803594695,
      "loss": 2.0939,
      "step": 13580
    },
    {
      "epoch": 52.675728155339804,
      "grad_norm": 0.3118036091327667,
      "learning_rate": 0.0004228657205650042,
      "loss": 2.0666,
      "step": 13590
    },
    {
      "epoch": 52.71456310679611,
      "grad_norm": 0.3222012519836426,
      "learning_rate": 0.00042275418720520263,
      "loss": 2.0749,
      "step": 13600
    },
    {
      "epoch": 52.75339805825243,
      "grad_norm": 0.2806083858013153,
      "learning_rate": 0.0004226425879990541,
      "loss": 2.0793,
      "step": 13610
    },
    {
      "epoch": 52.79223300970874,
      "grad_norm": 0.32984206080436707,
      "learning_rate": 0.00042253092298909505,
      "loss": 2.0767,
      "step": 13620
    },
    {
      "epoch": 52.83106796116505,
      "grad_norm": 0.3595656752586365,
      "learning_rate": 0.00042241919221788754,
      "loss": 2.0855,
      "step": 13630
    },
    {
      "epoch": 52.869902912621356,
      "grad_norm": 0.7015686631202698,
      "learning_rate": 0.0004223073957280184,
      "loss": 2.0814,
      "step": 13640
    },
    {
      "epoch": 52.90873786407767,
      "grad_norm": 0.35542330145835876,
      "learning_rate": 0.0004221955335620995,
      "loss": 2.0861,
      "step": 13650
    },
    {
      "epoch": 52.94757281553398,
      "grad_norm": 0.31085821986198425,
      "learning_rate": 0.0004220836057627679,
      "loss": 2.0889,
      "step": 13660
    },
    {
      "epoch": 52.98640776699029,
      "grad_norm": 0.30713188648223877,
      "learning_rate": 0.00042197161237268554,
      "loss": 2.0856,
      "step": 13670
    },
    {
      "epoch": 53.0,
      "eval_loss": 1.0305501222610474,
      "eval_runtime": 6.5597,
      "eval_samples_per_second": 3776.418,
      "eval_steps_per_second": 14.787,
      "step": 13674
    },
    {
      "epoch": 53.023300970873784,
      "grad_norm": 0.290980726480484,
      "learning_rate": 0.0004218595534345394,
      "loss": 1.974,
      "step": 13680
    },
    {
      "epoch": 53.0621359223301,
      "grad_norm": 0.422648161649704,
      "learning_rate": 0.00042174742899104146,
      "loss": 2.0811,
      "step": 13690
    },
    {
      "epoch": 53.10097087378641,
      "grad_norm": 0.3271748423576355,
      "learning_rate": 0.0004216352390849287,
      "loss": 2.0773,
      "step": 13700
    },
    {
      "epoch": 53.13980582524272,
      "grad_norm": 0.3621084690093994,
      "learning_rate": 0.00042152298375896293,
      "loss": 2.0862,
      "step": 13710
    },
    {
      "epoch": 53.17864077669903,
      "grad_norm": 0.7417110204696655,
      "learning_rate": 0.000421410663055931,
      "loss": 2.0704,
      "step": 13720
    },
    {
      "epoch": 53.21747572815534,
      "grad_norm": 0.33499807119369507,
      "learning_rate": 0.0004212982770186447,
      "loss": 2.0792,
      "step": 13730
    },
    {
      "epoch": 53.25631067961165,
      "grad_norm": 0.39520207047462463,
      "learning_rate": 0.00042118582568994055,
      "loss": 2.0774,
      "step": 13740
    },
    {
      "epoch": 53.29514563106796,
      "grad_norm": 0.42740964889526367,
      "learning_rate": 0.00042107330911268033,
      "loss": 2.0779,
      "step": 13750
    },
    {
      "epoch": 53.33398058252427,
      "grad_norm": 0.3855164349079132,
      "learning_rate": 0.0004209607273297502,
      "loss": 2.0788,
      "step": 13760
    },
    {
      "epoch": 53.372815533980585,
      "grad_norm": 0.3597336709499359,
      "learning_rate": 0.00042084808038406153,
      "loss": 2.0809,
      "step": 13770
    },
    {
      "epoch": 53.411650485436894,
      "grad_norm": 0.3005811870098114,
      "learning_rate": 0.0004207353683185503,
      "loss": 2.0854,
      "step": 13780
    },
    {
      "epoch": 53.4504854368932,
      "grad_norm": 0.33725595474243164,
      "learning_rate": 0.0004206225911761776,
      "loss": 2.0771,
      "step": 13790
    },
    {
      "epoch": 53.48932038834951,
      "grad_norm": 0.4499167203903198,
      "learning_rate": 0.0004205097489999291,
      "loss": 2.0958,
      "step": 13800
    },
    {
      "epoch": 53.52815533980583,
      "grad_norm": 0.5439051985740662,
      "learning_rate": 0.00042039684183281517,
      "loss": 2.0948,
      "step": 13810
    },
    {
      "epoch": 53.56699029126214,
      "grad_norm": 0.35954874753952026,
      "learning_rate": 0.00042028386971787126,
      "loss": 2.0887,
      "step": 13820
    },
    {
      "epoch": 53.605825242718446,
      "grad_norm": 0.8949311375617981,
      "learning_rate": 0.00042017083269815726,
      "loss": 2.0885,
      "step": 13830
    },
    {
      "epoch": 53.644660194174755,
      "grad_norm": 0.28081536293029785,
      "learning_rate": 0.00042005773081675807,
      "loss": 2.0868,
      "step": 13840
    },
    {
      "epoch": 53.68349514563107,
      "grad_norm": 0.38327541947364807,
      "learning_rate": 0.0004199445641167831,
      "loss": 2.0786,
      "step": 13850
    },
    {
      "epoch": 53.72233009708738,
      "grad_norm": 0.3425440490245819,
      "learning_rate": 0.00041983133264136656,
      "loss": 2.0784,
      "step": 13860
    },
    {
      "epoch": 53.76116504854369,
      "grad_norm": 0.33240705728530884,
      "learning_rate": 0.0004197180364336674,
      "loss": 2.0865,
      "step": 13870
    },
    {
      "epoch": 53.8,
      "grad_norm": 0.39033177495002747,
      "learning_rate": 0.0004196046755368691,
      "loss": 2.069,
      "step": 13880
    },
    {
      "epoch": 53.83883495145631,
      "grad_norm": 0.3337607979774475,
      "learning_rate": 0.00041949124999418,
      "loss": 2.068,
      "step": 13890
    },
    {
      "epoch": 53.87766990291262,
      "grad_norm": 0.37399956583976746,
      "learning_rate": 0.00041937775984883275,
      "loss": 2.0828,
      "step": 13900
    },
    {
      "epoch": 53.91650485436893,
      "grad_norm": 0.37189748883247375,
      "learning_rate": 0.000419264205144085,
      "loss": 2.0806,
      "step": 13910
    },
    {
      "epoch": 53.95533980582524,
      "grad_norm": 0.46784576773643494,
      "learning_rate": 0.0004191505859232189,
      "loss": 2.0645,
      "step": 13920
    },
    {
      "epoch": 53.994174757281556,
      "grad_norm": 0.4037815034389496,
      "learning_rate": 0.00041903690222954093,
      "loss": 2.0844,
      "step": 13930
    },
    {
      "epoch": 54.0,
      "eval_loss": 1.0303164720535278,
      "eval_runtime": 6.5005,
      "eval_samples_per_second": 3810.782,
      "eval_steps_per_second": 14.922,
      "step": 13932
    },
    {
      "epoch": 54.03106796116505,
      "grad_norm": 1.9631917476654053,
      "learning_rate": 0.0004189231541063825,
      "loss": 1.9717,
      "step": 13940
    },
    {
      "epoch": 54.06990291262136,
      "grad_norm": 0.319347083568573,
      "learning_rate": 0.0004188093415970994,
      "loss": 2.0756,
      "step": 13950
    },
    {
      "epoch": 54.10873786407767,
      "grad_norm": 0.3713918924331665,
      "learning_rate": 0.000418695464745072,
      "loss": 2.0733,
      "step": 13960
    },
    {
      "epoch": 54.147572815533984,
      "grad_norm": 0.7062235474586487,
      "learning_rate": 0.000418581523593705,
      "loss": 2.0986,
      "step": 13970
    },
    {
      "epoch": 54.18640776699029,
      "grad_norm": 0.3972751498222351,
      "learning_rate": 0.0004184675181864281,
      "loss": 2.0758,
      "step": 13980
    },
    {
      "epoch": 54.2252427184466,
      "grad_norm": 0.34211739897727966,
      "learning_rate": 0.00041835344856669496,
      "loss": 2.0825,
      "step": 13990
    },
    {
      "epoch": 54.26407766990291,
      "grad_norm": 0.37889930605888367,
      "learning_rate": 0.00041823931477798394,
      "loss": 2.0886,
      "step": 14000
    },
    {
      "epoch": 54.302912621359226,
      "grad_norm": 0.41764625906944275,
      "learning_rate": 0.0004181251168637979,
      "loss": 2.0822,
      "step": 14010
    },
    {
      "epoch": 54.341747572815535,
      "grad_norm": 0.3046627640724182,
      "learning_rate": 0.0004180108548676641,
      "loss": 2.0843,
      "step": 14020
    },
    {
      "epoch": 54.380582524271844,
      "grad_norm": 0.3045654296875,
      "learning_rate": 0.00041789652883313425,
      "loss": 2.0854,
      "step": 14030
    },
    {
      "epoch": 54.41941747572815,
      "grad_norm": 0.355893075466156,
      "learning_rate": 0.00041778213880378434,
      "loss": 2.0761,
      "step": 14040
    },
    {
      "epoch": 54.45825242718447,
      "grad_norm": 0.42991146445274353,
      "learning_rate": 0.00041766768482321494,
      "loss": 2.0694,
      "step": 14050
    },
    {
      "epoch": 54.49708737864078,
      "grad_norm": 0.343938410282135,
      "learning_rate": 0.00041755316693505094,
      "loss": 2.081,
      "step": 14060
    },
    {
      "epoch": 54.53592233009709,
      "grad_norm": 0.30448952317237854,
      "learning_rate": 0.00041743858518294145,
      "loss": 2.0856,
      "step": 14070
    },
    {
      "epoch": 54.574757281553396,
      "grad_norm": 0.34335821866989136,
      "learning_rate": 0.00041732393961056003,
      "loss": 2.0605,
      "step": 14080
    },
    {
      "epoch": 54.61359223300971,
      "grad_norm": 0.3331858217716217,
      "learning_rate": 0.00041720923026160463,
      "loss": 2.0877,
      "step": 14090
    },
    {
      "epoch": 54.65242718446602,
      "grad_norm": 0.41838929057121277,
      "learning_rate": 0.0004170944571797974,
      "loss": 2.0632,
      "step": 14100
    },
    {
      "epoch": 54.69126213592233,
      "grad_norm": 0.33239874243736267,
      "learning_rate": 0.0004169796204088848,
      "loss": 2.0751,
      "step": 14110
    },
    {
      "epoch": 54.73009708737864,
      "grad_norm": 0.3203107714653015,
      "learning_rate": 0.00041686471999263775,
      "loss": 2.0731,
      "step": 14120
    },
    {
      "epoch": 54.768932038834954,
      "grad_norm": 0.3522607386112213,
      "learning_rate": 0.000416749755974851,
      "loss": 2.0864,
      "step": 14130
    },
    {
      "epoch": 54.80776699029126,
      "grad_norm": 0.3610784411430359,
      "learning_rate": 0.000416634728399344,
      "loss": 2.0828,
      "step": 14140
    },
    {
      "epoch": 54.84660194174757,
      "grad_norm": 0.40765756368637085,
      "learning_rate": 0.00041651963730996025,
      "loss": 2.0874,
      "step": 14150
    },
    {
      "epoch": 54.88543689320388,
      "grad_norm": 0.3786528706550598,
      "learning_rate": 0.0004164044827505673,
      "loss": 2.0813,
      "step": 14160
    },
    {
      "epoch": 54.9242718446602,
      "grad_norm": 0.3315040171146393,
      "learning_rate": 0.0004162892647650572,
      "loss": 2.092,
      "step": 14170
    },
    {
      "epoch": 54.963106796116506,
      "grad_norm": 0.37007442116737366,
      "learning_rate": 0.0004161739833973459,
      "loss": 2.0865,
      "step": 14180
    },
    {
      "epoch": 55.0,
      "grad_norm": 0.28039267659187317,
      "learning_rate": 0.0004160586386913736,
      "loss": 1.9637,
      "step": 14190
    },
    {
      "epoch": 55.0,
      "eval_loss": 1.0299955606460571,
      "eval_runtime": 6.5255,
      "eval_samples_per_second": 3796.188,
      "eval_steps_per_second": 14.865,
      "step": 14190
    },
    {
      "epoch": 55.03883495145631,
      "grad_norm": 0.5997264385223389,
      "learning_rate": 0.0004159432306911047,
      "loss": 2.0691,
      "step": 14200
    },
    {
      "epoch": 55.077669902912625,
      "grad_norm": 0.4882623255252838,
      "learning_rate": 0.0004158277594405278,
      "loss": 2.0789,
      "step": 14210
    },
    {
      "epoch": 55.116504854368934,
      "grad_norm": 0.41067948937416077,
      "learning_rate": 0.00041571222498365534,
      "loss": 2.0736,
      "step": 14220
    },
    {
      "epoch": 55.15533980582524,
      "grad_norm": 0.32672715187072754,
      "learning_rate": 0.000415596627364524,
      "loss": 2.08,
      "step": 14230
    },
    {
      "epoch": 55.19417475728155,
      "grad_norm": 0.34435904026031494,
      "learning_rate": 0.0004154809666271947,
      "loss": 2.0725,
      "step": 14240
    },
    {
      "epoch": 55.23300970873787,
      "grad_norm": 0.40543824434280396,
      "learning_rate": 0.00041536524281575216,
      "loss": 2.0666,
      "step": 14250
    },
    {
      "epoch": 55.271844660194176,
      "grad_norm": 0.3220006823539734,
      "learning_rate": 0.00041524945597430516,
      "loss": 2.0859,
      "step": 14260
    },
    {
      "epoch": 55.310679611650485,
      "grad_norm": 0.3581080138683319,
      "learning_rate": 0.0004151336061469867,
      "loss": 2.0843,
      "step": 14270
    },
    {
      "epoch": 55.349514563106794,
      "grad_norm": 0.29507118463516235,
      "learning_rate": 0.0004150176933779536,
      "loss": 2.0719,
      "step": 14280
    },
    {
      "epoch": 55.38834951456311,
      "grad_norm": 0.35046958923339844,
      "learning_rate": 0.0004149017177113868,
      "loss": 2.0821,
      "step": 14290
    },
    {
      "epoch": 55.42718446601942,
      "grad_norm": 0.326312780380249,
      "learning_rate": 0.0004147856791914911,
      "loss": 2.0822,
      "step": 14300
    },
    {
      "epoch": 55.46601941747573,
      "grad_norm": 0.28975823521614075,
      "learning_rate": 0.0004146695778624954,
      "loss": 2.0802,
      "step": 14310
    },
    {
      "epoch": 55.50485436893204,
      "grad_norm": 0.3529852330684662,
      "learning_rate": 0.00041455341376865233,
      "loss": 2.0821,
      "step": 14320
    },
    {
      "epoch": 55.54368932038835,
      "grad_norm": 0.3070211112499237,
      "learning_rate": 0.0004144371869542387,
      "loss": 2.0716,
      "step": 14330
    },
    {
      "epoch": 55.58252427184466,
      "grad_norm": 0.4346286356449127,
      "learning_rate": 0.00041432089746355505,
      "loss": 2.0712,
      "step": 14340
    },
    {
      "epoch": 55.62135922330097,
      "grad_norm": 0.29194074869155884,
      "learning_rate": 0.0004142045453409258,
      "loss": 2.0825,
      "step": 14350
    },
    {
      "epoch": 55.66019417475728,
      "grad_norm": 0.3314497768878937,
      "learning_rate": 0.0004140881306306993,
      "loss": 2.081,
      "step": 14360
    },
    {
      "epoch": 55.699029126213595,
      "grad_norm": 0.2921115756034851,
      "learning_rate": 0.0004139716533772478,
      "loss": 2.0896,
      "step": 14370
    },
    {
      "epoch": 55.737864077669904,
      "grad_norm": 0.3238389492034912,
      "learning_rate": 0.0004138551136249673,
      "loss": 2.0688,
      "step": 14380
    },
    {
      "epoch": 55.77669902912621,
      "grad_norm": 0.3180137574672699,
      "learning_rate": 0.00041373851141827766,
      "loss": 2.0769,
      "step": 14390
    },
    {
      "epoch": 55.81553398058252,
      "grad_norm": 0.3254711329936981,
      "learning_rate": 0.00041362184680162256,
      "loss": 2.0873,
      "step": 14400
    },
    {
      "epoch": 55.85436893203884,
      "grad_norm": 0.4319937229156494,
      "learning_rate": 0.00041350511981946955,
      "loss": 2.0833,
      "step": 14410
    },
    {
      "epoch": 55.89320388349515,
      "grad_norm": 0.4975670278072357,
      "learning_rate": 0.0004133883305163096,
      "loss": 2.0669,
      "step": 14420
    },
    {
      "epoch": 55.932038834951456,
      "grad_norm": 0.325063019990921,
      "learning_rate": 0.00041327147893665796,
      "loss": 2.0788,
      "step": 14430
    },
    {
      "epoch": 55.970873786407765,
      "grad_norm": 0.37995392084121704,
      "learning_rate": 0.00041315456512505325,
      "loss": 2.0859,
      "step": 14440
    },
    {
      "epoch": 56.0,
      "eval_loss": 1.0290883779525757,
      "eval_runtime": 6.5174,
      "eval_samples_per_second": 3800.923,
      "eval_steps_per_second": 14.883,
      "step": 14448
    },
    {
      "epoch": 56.00776699029126,
      "grad_norm": 0.28395140171051025,
      "learning_rate": 0.0004130375891260579,
      "loss": 1.9768,
      "step": 14450
    },
    {
      "epoch": 56.046601941747575,
      "grad_norm": 0.28132250905036926,
      "learning_rate": 0.00041292055098425794,
      "loss": 2.0903,
      "step": 14460
    },
    {
      "epoch": 56.085436893203884,
      "grad_norm": 0.358623206615448,
      "learning_rate": 0.00041280345074426336,
      "loss": 2.0738,
      "step": 14470
    },
    {
      "epoch": 56.12427184466019,
      "grad_norm": 0.33436402678489685,
      "learning_rate": 0.0004126862884507076,
      "loss": 2.0623,
      "step": 14480
    },
    {
      "epoch": 56.1631067961165,
      "grad_norm": 0.339514821767807,
      "learning_rate": 0.00041256906414824775,
      "loss": 2.0705,
      "step": 14490
    },
    {
      "epoch": 56.20194174757282,
      "grad_norm": 0.37180760502815247,
      "learning_rate": 0.00041245177788156465,
      "loss": 2.0701,
      "step": 14500
    },
    {
      "epoch": 56.24077669902913,
      "grad_norm": 0.361574649810791,
      "learning_rate": 0.0004123344296953627,
      "loss": 2.0772,
      "step": 14510
    },
    {
      "epoch": 56.279611650485435,
      "grad_norm": 0.276753306388855,
      "learning_rate": 0.00041221701963436996,
      "loss": 2.0686,
      "step": 14520
    },
    {
      "epoch": 56.318446601941744,
      "grad_norm": 0.32848837971687317,
      "learning_rate": 0.0004120995477433378,
      "loss": 2.0789,
      "step": 14530
    },
    {
      "epoch": 56.35728155339806,
      "grad_norm": 0.3784327208995819,
      "learning_rate": 0.0004119820140670416,
      "loss": 2.0687,
      "step": 14540
    },
    {
      "epoch": 56.39611650485437,
      "grad_norm": 0.4320051670074463,
      "learning_rate": 0.00041186441865028,
      "loss": 2.0841,
      "step": 14550
    },
    {
      "epoch": 56.43495145631068,
      "grad_norm": 0.3084459900856018,
      "learning_rate": 0.0004117467615378752,
      "loss": 2.0677,
      "step": 14560
    },
    {
      "epoch": 56.47378640776699,
      "grad_norm": 0.3298611640930176,
      "learning_rate": 0.0004116290427746729,
      "loss": 2.0799,
      "step": 14570
    },
    {
      "epoch": 56.5126213592233,
      "grad_norm": 0.3781781792640686,
      "learning_rate": 0.0004115112624055424,
      "loss": 2.0785,
      "step": 14580
    },
    {
      "epoch": 56.55145631067961,
      "grad_norm": 0.2950412929058075,
      "learning_rate": 0.00041139342047537655,
      "loss": 2.0821,
      "step": 14590
    },
    {
      "epoch": 56.59029126213592,
      "grad_norm": 0.38958096504211426,
      "learning_rate": 0.0004112755170290913,
      "loss": 2.0854,
      "step": 14600
    },
    {
      "epoch": 56.62912621359223,
      "grad_norm": 0.32180047035217285,
      "learning_rate": 0.00041115755211162654,
      "loss": 2.0953,
      "step": 14610
    },
    {
      "epoch": 56.667961165048546,
      "grad_norm": 0.31339335441589355,
      "learning_rate": 0.0004110395257679451,
      "loss": 2.0833,
      "step": 14620
    },
    {
      "epoch": 56.706796116504854,
      "grad_norm": 0.352441668510437,
      "learning_rate": 0.00041092143804303367,
      "loss": 2.0677,
      "step": 14630
    },
    {
      "epoch": 56.74563106796116,
      "grad_norm": 0.33950677514076233,
      "learning_rate": 0.0004108032889819021,
      "loss": 2.0752,
      "step": 14640
    },
    {
      "epoch": 56.78446601941748,
      "grad_norm": 0.28125858306884766,
      "learning_rate": 0.00041068507862958346,
      "loss": 2.0667,
      "step": 14650
    },
    {
      "epoch": 56.82330097087379,
      "grad_norm": 0.37344834208488464,
      "learning_rate": 0.00041056680703113464,
      "loss": 2.0866,
      "step": 14660
    },
    {
      "epoch": 56.8621359223301,
      "grad_norm": 0.32624390721321106,
      "learning_rate": 0.00041044847423163546,
      "loss": 2.0614,
      "step": 14670
    },
    {
      "epoch": 56.900970873786406,
      "grad_norm": 0.4553556740283966,
      "learning_rate": 0.00041033008027618916,
      "loss": 2.0896,
      "step": 14680
    },
    {
      "epoch": 56.93980582524272,
      "grad_norm": 0.3514815866947174,
      "learning_rate": 0.0004102116252099225,
      "loss": 2.0842,
      "step": 14690
    },
    {
      "epoch": 56.97864077669903,
      "grad_norm": 0.29050758481025696,
      "learning_rate": 0.00041009310907798513,
      "loss": 2.0789,
      "step": 14700
    },
    {
      "epoch": 57.0,
      "eval_loss": 1.0290464162826538,
      "eval_runtime": 6.4981,
      "eval_samples_per_second": 3812.176,
      "eval_steps_per_second": 14.927,
      "step": 14706
    },
    {
      "epoch": 57.015533980582525,
      "grad_norm": 0.2829625904560089,
      "learning_rate": 0.00040997453192555055,
      "loss": 1.9773,
      "step": 14710
    },
    {
      "epoch": 57.054368932038834,
      "grad_norm": 0.34291723370552063,
      "learning_rate": 0.00040985589379781493,
      "loss": 2.077,
      "step": 14720
    },
    {
      "epoch": 57.09320388349514,
      "grad_norm": 0.31129151582717896,
      "learning_rate": 0.000409737194739998,
      "loss": 2.0866,
      "step": 14730
    },
    {
      "epoch": 57.13203883495146,
      "grad_norm": 0.5036103129386902,
      "learning_rate": 0.0004096184347973427,
      "loss": 2.0881,
      "step": 14740
    },
    {
      "epoch": 57.17087378640777,
      "grad_norm": 0.3114130198955536,
      "learning_rate": 0.0004094996140151152,
      "loss": 2.0672,
      "step": 14750
    },
    {
      "epoch": 57.20970873786408,
      "grad_norm": 0.3689010739326477,
      "learning_rate": 0.00040938073243860465,
      "loss": 2.0767,
      "step": 14760
    },
    {
      "epoch": 57.248543689320385,
      "grad_norm": 0.40507790446281433,
      "learning_rate": 0.0004092617901131235,
      "loss": 2.0716,
      "step": 14770
    },
    {
      "epoch": 57.2873786407767,
      "grad_norm": 0.3238581418991089,
      "learning_rate": 0.00040914278708400743,
      "loss": 2.0849,
      "step": 14780
    },
    {
      "epoch": 57.32621359223301,
      "grad_norm": 0.431396484375,
      "learning_rate": 0.0004090237233966153,
      "loss": 2.0621,
      "step": 14790
    },
    {
      "epoch": 57.36504854368932,
      "grad_norm": 0.34658366441726685,
      "learning_rate": 0.0004089045990963288,
      "loss": 2.0611,
      "step": 14800
    },
    {
      "epoch": 57.40388349514563,
      "grad_norm": 0.49576613306999207,
      "learning_rate": 0.000408785414228553,
      "loss": 2.0757,
      "step": 14810
    },
    {
      "epoch": 57.442718446601944,
      "grad_norm": 0.5167276263237,
      "learning_rate": 0.00040866616883871587,
      "loss": 2.0719,
      "step": 14820
    },
    {
      "epoch": 57.48155339805825,
      "grad_norm": 0.37768039107322693,
      "learning_rate": 0.0004085468629722687,
      "loss": 2.0806,
      "step": 14830
    },
    {
      "epoch": 57.52038834951456,
      "grad_norm": 0.3251391053199768,
      "learning_rate": 0.0004084274966746856,
      "loss": 2.0662,
      "step": 14840
    },
    {
      "epoch": 57.55922330097087,
      "grad_norm": 0.31752482056617737,
      "learning_rate": 0.00040830806999146376,
      "loss": 2.0716,
      "step": 14850
    },
    {
      "epoch": 57.59805825242719,
      "grad_norm": 0.3180117905139923,
      "learning_rate": 0.0004081885829681234,
      "loss": 2.0766,
      "step": 14860
    },
    {
      "epoch": 57.636893203883496,
      "grad_norm": 0.3313608169555664,
      "learning_rate": 0.00040806903565020783,
      "loss": 2.0662,
      "step": 14870
    },
    {
      "epoch": 57.675728155339804,
      "grad_norm": 0.4331302046775818,
      "learning_rate": 0.0004079494280832832,
      "loss": 2.1018,
      "step": 14880
    },
    {
      "epoch": 57.71456310679611,
      "grad_norm": 0.29210996627807617,
      "learning_rate": 0.0004078297603129387,
      "loss": 2.0848,
      "step": 14890
    },
    {
      "epoch": 57.75339805825243,
      "grad_norm": 0.3167859613895416,
      "learning_rate": 0.00040771003238478646,
      "loss": 2.0797,
      "step": 14900
    },
    {
      "epoch": 57.79223300970874,
      "grad_norm": 0.5400946140289307,
      "learning_rate": 0.0004075902443444616,
      "loss": 2.0671,
      "step": 14910
    },
    {
      "epoch": 57.83106796116505,
      "grad_norm": 0.45478373765945435,
      "learning_rate": 0.0004074703962376219,
      "loss": 2.0832,
      "step": 14920
    },
    {
      "epoch": 57.869902912621356,
      "grad_norm": 0.7035648822784424,
      "learning_rate": 0.00040735048810994846,
      "loss": 2.0741,
      "step": 14930
    },
    {
      "epoch": 57.90873786407767,
      "grad_norm": 0.3440328538417816,
      "learning_rate": 0.0004072305200071448,
      "loss": 2.073,
      "step": 14940
    },
    {
      "epoch": 57.94757281553398,
      "grad_norm": 0.4439522922039032,
      "learning_rate": 0.00040711049197493765,
      "loss": 2.0729,
      "step": 14950
    },
    {
      "epoch": 57.98640776699029,
      "grad_norm": 0.41554996371269226,
      "learning_rate": 0.0004069904040590765,
      "loss": 2.0917,
      "step": 14960
    },
    {
      "epoch": 58.0,
      "eval_loss": 1.0297067165374756,
      "eval_runtime": 6.576,
      "eval_samples_per_second": 3767.02,
      "eval_steps_per_second": 14.751,
      "step": 14964
    },
    {
      "epoch": 58.023300970873784,
      "grad_norm": 0.35871633887290955,
      "learning_rate": 0.00040687025630533344,
      "loss": 1.9765,
      "step": 14970
    },
    {
      "epoch": 58.0621359223301,
      "grad_norm": 0.348622590303421,
      "learning_rate": 0.00040675004875950364,
      "loss": 2.0767,
      "step": 14980
    },
    {
      "epoch": 58.10097087378641,
      "grad_norm": 0.27498528361320496,
      "learning_rate": 0.00040662978146740504,
      "loss": 2.073,
      "step": 14990
    },
    {
      "epoch": 58.13980582524272,
      "grad_norm": 0.38500574231147766,
      "learning_rate": 0.00040650945447487813,
      "loss": 2.0645,
      "step": 15000
    },
    {
      "epoch": 58.17864077669903,
      "grad_norm": 0.3231829106807709,
      "learning_rate": 0.0004063890678277864,
      "loss": 2.0748,
      "step": 15010
    },
    {
      "epoch": 58.21747572815534,
      "grad_norm": 0.3811783194541931,
      "learning_rate": 0.00040626862157201596,
      "loss": 2.08,
      "step": 15020
    },
    {
      "epoch": 58.25631067961165,
      "grad_norm": 0.3205796182155609,
      "learning_rate": 0.00040614811575347565,
      "loss": 2.0837,
      "step": 15030
    },
    {
      "epoch": 58.29514563106796,
      "grad_norm": 0.32489752769470215,
      "learning_rate": 0.00040602755041809695,
      "loss": 2.0556,
      "step": 15040
    },
    {
      "epoch": 58.33398058252427,
      "grad_norm": 0.30949944257736206,
      "learning_rate": 0.0004059069256118343,
      "loss": 2.0736,
      "step": 15050
    },
    {
      "epoch": 58.372815533980585,
      "grad_norm": 0.31537535786628723,
      "learning_rate": 0.00040578624138066437,
      "loss": 2.0734,
      "step": 15060
    },
    {
      "epoch": 58.411650485436894,
      "grad_norm": 0.30666592717170715,
      "learning_rate": 0.00040566549777058683,
      "loss": 2.0795,
      "step": 15070
    },
    {
      "epoch": 58.4504854368932,
      "grad_norm": 0.31676605343818665,
      "learning_rate": 0.0004055446948276239,
      "loss": 2.0732,
      "step": 15080
    },
    {
      "epoch": 58.48932038834951,
      "grad_norm": 0.29647165536880493,
      "learning_rate": 0.0004054238325978203,
      "loss": 2.0731,
      "step": 15090
    },
    {
      "epoch": 58.52815533980583,
      "grad_norm": 0.3091593086719513,
      "learning_rate": 0.0004053029111272435,
      "loss": 2.0755,
      "step": 15100
    },
    {
      "epoch": 58.56699029126214,
      "grad_norm": 0.36587560176849365,
      "learning_rate": 0.0004051819304619834,
      "loss": 2.082,
      "step": 15110
    },
    {
      "epoch": 58.605825242718446,
      "grad_norm": 0.3646169602870941,
      "learning_rate": 0.00040506089064815267,
      "loss": 2.0759,
      "step": 15120
    },
    {
      "epoch": 58.644660194174755,
      "grad_norm": 0.3283518850803375,
      "learning_rate": 0.00040493979173188626,
      "loss": 2.0701,
      "step": 15130
    },
    {
      "epoch": 58.68349514563107,
      "grad_norm": 0.44668686389923096,
      "learning_rate": 0.0004048186337593419,
      "loss": 2.0824,
      "step": 15140
    },
    {
      "epoch": 58.72233009708738,
      "grad_norm": 0.2945045530796051,
      "learning_rate": 0.0004046974167766996,
      "loss": 2.087,
      "step": 15150
    },
    {
      "epoch": 58.76116504854369,
      "grad_norm": 0.2717899680137634,
      "learning_rate": 0.00040457614083016206,
      "loss": 2.0731,
      "step": 15160
    },
    {
      "epoch": 58.8,
      "grad_norm": 1.0898019075393677,
      "learning_rate": 0.0004044548059659544,
      "loss": 2.081,
      "step": 15170
    },
    {
      "epoch": 58.83883495145631,
      "grad_norm": 0.37293684482574463,
      "learning_rate": 0.00040433341223032403,
      "loss": 2.073,
      "step": 15180
    },
    {
      "epoch": 58.87766990291262,
      "grad_norm": 0.338207870721817,
      "learning_rate": 0.0004042119596695411,
      "loss": 2.0783,
      "step": 15190
    },
    {
      "epoch": 58.91650485436893,
      "grad_norm": 0.36942967772483826,
      "learning_rate": 0.00040409044832989796,
      "loss": 2.084,
      "step": 15200
    },
    {
      "epoch": 58.95533980582524,
      "grad_norm": 0.3160872459411621,
      "learning_rate": 0.00040396887825770933,
      "loss": 2.0612,
      "step": 15210
    },
    {
      "epoch": 58.994174757281556,
      "grad_norm": 0.3079415261745453,
      "learning_rate": 0.0004038472494993125,
      "loss": 2.0832,
      "step": 15220
    },
    {
      "epoch": 59.0,
      "eval_loss": 1.0292037725448608,
      "eval_runtime": 6.5018,
      "eval_samples_per_second": 3810.016,
      "eval_steps_per_second": 14.919,
      "step": 15222
    },
    {
      "epoch": 59.03106796116505,
      "grad_norm": 0.32519346475601196,
      "learning_rate": 0.00040372556210106704,
      "loss": 1.9643,
      "step": 15230
    },
    {
      "epoch": 59.06990291262136,
      "grad_norm": 0.3429383337497711,
      "learning_rate": 0.0004036038161093549,
      "loss": 2.0566,
      "step": 15240
    },
    {
      "epoch": 59.10873786407767,
      "grad_norm": 0.48944124579429626,
      "learning_rate": 0.00040348201157058025,
      "loss": 2.0786,
      "step": 15250
    },
    {
      "epoch": 59.147572815533984,
      "grad_norm": 0.38123559951782227,
      "learning_rate": 0.00040336014853116964,
      "loss": 2.0701,
      "step": 15260
    },
    {
      "epoch": 59.18640776699029,
      "grad_norm": 0.347476989030838,
      "learning_rate": 0.00040323822703757206,
      "loss": 2.0684,
      "step": 15270
    },
    {
      "epoch": 59.2252427184466,
      "grad_norm": 0.37798744440078735,
      "learning_rate": 0.0004031162471362585,
      "loss": 2.0701,
      "step": 15280
    },
    {
      "epoch": 59.26407766990291,
      "grad_norm": 0.4117891490459442,
      "learning_rate": 0.00040299420887372257,
      "loss": 2.0726,
      "step": 15290
    },
    {
      "epoch": 59.302912621359226,
      "grad_norm": 0.4021993577480316,
      "learning_rate": 0.0004028721122964797,
      "loss": 2.0649,
      "step": 15300
    },
    {
      "epoch": 59.341747572815535,
      "grad_norm": 0.35415056347846985,
      "learning_rate": 0.0004027499574510679,
      "loss": 2.0644,
      "step": 15310
    },
    {
      "epoch": 59.380582524271844,
      "grad_norm": 0.2600250244140625,
      "learning_rate": 0.00040262774438404726,
      "loss": 2.0788,
      "step": 15320
    },
    {
      "epoch": 59.41941747572815,
      "grad_norm": 0.286418080329895,
      "learning_rate": 0.000402505473142,
      "loss": 2.0784,
      "step": 15330
    },
    {
      "epoch": 59.45825242718447,
      "grad_norm": 0.3091634511947632,
      "learning_rate": 0.0004023831437715306,
      "loss": 2.0892,
      "step": 15340
    },
    {
      "epoch": 59.49708737864078,
      "grad_norm": 0.3358786404132843,
      "learning_rate": 0.0004022607563192657,
      "loss": 2.0706,
      "step": 15350
    },
    {
      "epoch": 59.53592233009709,
      "grad_norm": 0.36958977580070496,
      "learning_rate": 0.00040213831083185403,
      "loss": 2.0651,
      "step": 15360
    },
    {
      "epoch": 59.574757281553396,
      "grad_norm": 0.3180299401283264,
      "learning_rate": 0.00040201580735596657,
      "loss": 2.0616,
      "step": 15370
    },
    {
      "epoch": 59.61359223300971,
      "grad_norm": 0.3962058126926422,
      "learning_rate": 0.000401893245938296,
      "loss": 2.0774,
      "step": 15380
    },
    {
      "epoch": 59.65242718446602,
      "grad_norm": 0.33799245953559875,
      "learning_rate": 0.0004017706266255576,
      "loss": 2.0771,
      "step": 15390
    },
    {
      "epoch": 59.69126213592233,
      "grad_norm": 0.3056763708591461,
      "learning_rate": 0.00040164794946448846,
      "loss": 2.0772,
      "step": 15400
    },
    {
      "epoch": 59.73009708737864,
      "grad_norm": 0.3102637231349945,
      "learning_rate": 0.0004015252145018478,
      "loss": 2.0873,
      "step": 15410
    },
    {
      "epoch": 59.768932038834954,
      "grad_norm": 0.36761146783828735,
      "learning_rate": 0.00040140242178441667,
      "loss": 2.0723,
      "step": 15420
    },
    {
      "epoch": 59.80776699029126,
      "grad_norm": 0.3476742208003998,
      "learning_rate": 0.0004012795713589984,
      "loss": 2.071,
      "step": 15430
    },
    {
      "epoch": 59.84660194174757,
      "grad_norm": 0.6726691126823425,
      "learning_rate": 0.0004011566632724183,
      "loss": 2.0748,
      "step": 15440
    },
    {
      "epoch": 59.88543689320388,
      "grad_norm": 0.3578779101371765,
      "learning_rate": 0.0004010336975715233,
      "loss": 2.0761,
      "step": 15450
    },
    {
      "epoch": 59.9242718446602,
      "grad_norm": 0.3176348805427551,
      "learning_rate": 0.00040091067430318277,
      "loss": 2.0905,
      "step": 15460
    },
    {
      "epoch": 59.963106796116506,
      "grad_norm": 0.3050982654094696,
      "learning_rate": 0.00040078759351428773,
      "loss": 2.0725,
      "step": 15470
    },
    {
      "epoch": 60.0,
      "grad_norm": 0.2166762799024582,
      "learning_rate": 0.00040066445525175124,
      "loss": 1.9705,
      "step": 15480
    },
    {
      "epoch": 60.0,
      "eval_loss": 1.0298595428466797,
      "eval_runtime": 6.512,
      "eval_samples_per_second": 3804.072,
      "eval_steps_per_second": 14.896,
      "step": 15480
    },
    {
      "epoch": 60.03883495145631,
      "grad_norm": 0.34394341707229614,
      "learning_rate": 0.00040054125956250807,
      "loss": 2.0649,
      "step": 15490
    },
    {
      "epoch": 60.077669902912625,
      "grad_norm": 0.32112038135528564,
      "learning_rate": 0.0004004180064935153,
      "loss": 2.0576,
      "step": 15500
    },
    {
      "epoch": 60.116504854368934,
      "grad_norm": 0.2996812164783478,
      "learning_rate": 0.0004002946960917514,
      "loss": 2.069,
      "step": 15510
    },
    {
      "epoch": 60.15533980582524,
      "grad_norm": 0.3431912064552307,
      "learning_rate": 0.000400171328404217,
      "loss": 2.0562,
      "step": 15520
    },
    {
      "epoch": 60.19417475728155,
      "grad_norm": 0.33011794090270996,
      "learning_rate": 0.0004000479034779344,
      "loss": 2.0757,
      "step": 15530
    },
    {
      "epoch": 60.23300970873787,
      "grad_norm": 0.3424026668071747,
      "learning_rate": 0.0003999244213599478,
      "loss": 2.0755,
      "step": 15540
    },
    {
      "epoch": 60.271844660194176,
      "grad_norm": 0.32179591059684753,
      "learning_rate": 0.00039980088209732326,
      "loss": 2.0716,
      "step": 15550
    },
    {
      "epoch": 60.310679611650485,
      "grad_norm": 0.32235080003738403,
      "learning_rate": 0.00039967728573714854,
      "loss": 2.0753,
      "step": 15560
    },
    {
      "epoch": 60.349514563106794,
      "grad_norm": 0.3572123944759369,
      "learning_rate": 0.0003995536323265331,
      "loss": 2.0653,
      "step": 15570
    },
    {
      "epoch": 60.38834951456311,
      "grad_norm": 0.40020978450775146,
      "learning_rate": 0.0003994299219126083,
      "loss": 2.0854,
      "step": 15580
    },
    {
      "epoch": 60.42718446601942,
      "grad_norm": 0.6018493175506592,
      "learning_rate": 0.00039930615454252704,
      "loss": 2.0791,
      "step": 15590
    },
    {
      "epoch": 60.46601941747573,
      "grad_norm": 0.36488667130470276,
      "learning_rate": 0.0003991823302634642,
      "loss": 2.0814,
      "step": 15600
    },
    {
      "epoch": 60.50485436893204,
      "grad_norm": 0.3675125539302826,
      "learning_rate": 0.00039905844912261593,
      "loss": 2.0774,
      "step": 15610
    },
    {
      "epoch": 60.54368932038835,
      "grad_norm": 0.3604651093482971,
      "learning_rate": 0.0003989345111672005,
      "loss": 2.0604,
      "step": 15620
    },
    {
      "epoch": 60.58252427184466,
      "grad_norm": 0.3268378973007202,
      "learning_rate": 0.00039881051644445766,
      "loss": 2.079,
      "step": 15630
    },
    {
      "epoch": 60.62135922330097,
      "grad_norm": 0.3216288685798645,
      "learning_rate": 0.00039868646500164866,
      "loss": 2.0811,
      "step": 15640
    },
    {
      "epoch": 60.66019417475728,
      "grad_norm": 0.42593255639076233,
      "learning_rate": 0.00039856235688605655,
      "loss": 2.0804,
      "step": 15650
    },
    {
      "epoch": 60.699029126213595,
      "grad_norm": 0.5300702452659607,
      "learning_rate": 0.00039843819214498594,
      "loss": 2.0811,
      "step": 15660
    },
    {
      "epoch": 60.737864077669904,
      "grad_norm": 0.34562432765960693,
      "learning_rate": 0.000398313970825763,
      "loss": 2.0704,
      "step": 15670
    },
    {
      "epoch": 60.77669902912621,
      "grad_norm": 0.2959706485271454,
      "learning_rate": 0.0003981896929757354,
      "loss": 2.0609,
      "step": 15680
    },
    {
      "epoch": 60.81553398058252,
      "grad_norm": 0.35123372077941895,
      "learning_rate": 0.0003980653586422726,
      "loss": 2.0634,
      "step": 15690
    },
    {
      "epoch": 60.85436893203884,
      "grad_norm": 0.35961002111434937,
      "learning_rate": 0.0003979409678727651,
      "loss": 2.0747,
      "step": 15700
    },
    {
      "epoch": 60.89320388349515,
      "grad_norm": 0.3470418453216553,
      "learning_rate": 0.00039781652071462555,
      "loss": 2.0806,
      "step": 15710
    },
    {
      "epoch": 60.932038834951456,
      "grad_norm": 0.3140920400619507,
      "learning_rate": 0.00039769201721528757,
      "loss": 2.0769,
      "step": 15720
    },
    {
      "epoch": 60.970873786407765,
      "grad_norm": 0.3257600665092468,
      "learning_rate": 0.0003975674574222065,
      "loss": 2.0719,
      "step": 15730
    },
    {
      "epoch": 61.0,
      "eval_loss": 1.0299545526504517,
      "eval_runtime": 6.7931,
      "eval_samples_per_second": 3646.627,
      "eval_steps_per_second": 14.279,
      "step": 15738
    },
    {
      "epoch": 61.00776699029126,
      "grad_norm": 0.3910270631313324,
      "learning_rate": 0.00039744284138285913,
      "loss": 1.9742,
      "step": 15740
    },
    {
      "epoch": 61.046601941747575,
      "grad_norm": 0.9827019572257996,
      "learning_rate": 0.00039731816914474375,
      "loss": 2.0623,
      "step": 15750
    },
    {
      "epoch": 61.085436893203884,
      "grad_norm": 0.415462851524353,
      "learning_rate": 0.0003971934407553797,
      "loss": 2.0658,
      "step": 15760
    },
    {
      "epoch": 61.12427184466019,
      "grad_norm": 0.32978665828704834,
      "learning_rate": 0.00039706865626230816,
      "loss": 2.0788,
      "step": 15770
    },
    {
      "epoch": 61.1631067961165,
      "grad_norm": 0.3528301417827606,
      "learning_rate": 0.00039694381571309144,
      "loss": 2.0681,
      "step": 15780
    },
    {
      "epoch": 61.20194174757282,
      "grad_norm": 0.37327125668525696,
      "learning_rate": 0.00039681891915531356,
      "loss": 2.057,
      "step": 15790
    },
    {
      "epoch": 61.24077669902913,
      "grad_norm": 0.44249606132507324,
      "learning_rate": 0.0003966939666365792,
      "loss": 2.0768,
      "step": 15800
    },
    {
      "epoch": 61.279611650485435,
      "grad_norm": 0.4472002685070038,
      "learning_rate": 0.0003965689582045152,
      "loss": 2.0722,
      "step": 15810
    },
    {
      "epoch": 61.318446601941744,
      "grad_norm": 0.40539559721946716,
      "learning_rate": 0.00039644389390676904,
      "loss": 2.071,
      "step": 15820
    },
    {
      "epoch": 61.35728155339806,
      "grad_norm": 0.3912460505962372,
      "learning_rate": 0.00039631877379101,
      "loss": 2.0529,
      "step": 15830
    },
    {
      "epoch": 61.39611650485437,
      "grad_norm": 0.3277982473373413,
      "learning_rate": 0.00039619359790492813,
      "loss": 2.0853,
      "step": 15840
    },
    {
      "epoch": 61.43495145631068,
      "grad_norm": 0.38706162571907043,
      "learning_rate": 0.0003960683662962352,
      "loss": 2.0791,
      "step": 15850
    },
    {
      "epoch": 61.47378640776699,
      "grad_norm": 0.3851052224636078,
      "learning_rate": 0.00039594307901266403,
      "loss": 2.0677,
      "step": 15860
    },
    {
      "epoch": 61.5126213592233,
      "grad_norm": 0.341248095035553,
      "learning_rate": 0.00039581773610196857,
      "loss": 2.0704,
      "step": 15870
    },
    {
      "epoch": 61.55145631067961,
      "grad_norm": 0.3191686272621155,
      "learning_rate": 0.0003956923376119241,
      "loss": 2.0682,
      "step": 15880
    },
    {
      "epoch": 61.59029126213592,
      "grad_norm": 0.3488735854625702,
      "learning_rate": 0.000395566883590327,
      "loss": 2.0629,
      "step": 15890
    },
    {
      "epoch": 61.62912621359223,
      "grad_norm": 0.397813618183136,
      "learning_rate": 0.0003954413740849949,
      "loss": 2.0813,
      "step": 15900
    },
    {
      "epoch": 61.667961165048546,
      "grad_norm": 0.44491446018218994,
      "learning_rate": 0.0003953158091437666,
      "loss": 2.0743,
      "step": 15910
    },
    {
      "epoch": 61.706796116504854,
      "grad_norm": 0.3325243592262268,
      "learning_rate": 0.0003951901888145019,
      "loss": 2.068,
      "step": 15920
    },
    {
      "epoch": 61.74563106796116,
      "grad_norm": 0.3155834972858429,
      "learning_rate": 0.00039506451314508175,
      "loss": 2.0728,
      "step": 15930
    },
    {
      "epoch": 61.78446601941748,
      "grad_norm": 0.3148331344127655,
      "learning_rate": 0.0003949387821834083,
      "loss": 2.0719,
      "step": 15940
    },
    {
      "epoch": 61.82330097087379,
      "grad_norm": 0.3220985531806946,
      "learning_rate": 0.00039481299597740464,
      "loss": 2.0892,
      "step": 15950
    },
    {
      "epoch": 61.8621359223301,
      "grad_norm": 0.34755027294158936,
      "learning_rate": 0.000394687154575015,
      "loss": 2.0783,
      "step": 15960
    },
    {
      "epoch": 61.900970873786406,
      "grad_norm": 0.33613136410713196,
      "learning_rate": 0.00039456125802420463,
      "loss": 2.0796,
      "step": 15970
    },
    {
      "epoch": 61.93980582524272,
      "grad_norm": 0.31147587299346924,
      "learning_rate": 0.00039443530637295977,
      "loss": 2.0837,
      "step": 15980
    },
    {
      "epoch": 61.97864077669903,
      "grad_norm": 0.37341147661209106,
      "learning_rate": 0.0003943092996692876,
      "loss": 2.0538,
      "step": 15990
    },
    {
      "epoch": 62.0,
      "eval_loss": 1.0297297239303589,
      "eval_runtime": 6.5577,
      "eval_samples_per_second": 3777.522,
      "eval_steps_per_second": 14.792,
      "step": 15996
    },
    {
      "epoch": 62.015533980582525,
      "grad_norm": 0.3740265965461731,
      "learning_rate": 0.0003941832379612166,
      "loss": 1.9687,
      "step": 16000
    },
    {
      "epoch": 62.054368932038834,
      "grad_norm": 0.336250364780426,
      "learning_rate": 0.0003940571212967958,
      "loss": 2.0686,
      "step": 16010
    },
    {
      "epoch": 62.09320388349514,
      "grad_norm": 0.30171722173690796,
      "learning_rate": 0.0003939309497240955,
      "loss": 2.0688,
      "step": 16020
    },
    {
      "epoch": 62.13203883495146,
      "grad_norm": 0.324760377407074,
      "learning_rate": 0.00039380472329120654,
      "loss": 2.062,
      "step": 16030
    },
    {
      "epoch": 62.17087378640777,
      "grad_norm": 0.35929885506629944,
      "learning_rate": 0.0003936784420462412,
      "loss": 2.0694,
      "step": 16040
    },
    {
      "epoch": 62.20970873786408,
      "grad_norm": 0.362040638923645,
      "learning_rate": 0.00039355210603733216,
      "loss": 2.0627,
      "step": 16050
    },
    {
      "epoch": 62.248543689320385,
      "grad_norm": 0.3821971118450165,
      "learning_rate": 0.00039342571531263343,
      "loss": 2.0734,
      "step": 16060
    },
    {
      "epoch": 62.2873786407767,
      "grad_norm": 0.33774662017822266,
      "learning_rate": 0.0003932992699203194,
      "loss": 2.0689,
      "step": 16070
    },
    {
      "epoch": 62.32621359223301,
      "grad_norm": 0.4098230302333832,
      "learning_rate": 0.00039317276990858557,
      "loss": 2.0777,
      "step": 16080
    },
    {
      "epoch": 62.36504854368932,
      "grad_norm": 0.34611308574676514,
      "learning_rate": 0.0003930462153256483,
      "loss": 2.062,
      "step": 16090
    },
    {
      "epoch": 62.40388349514563,
      "grad_norm": 0.32421010732650757,
      "learning_rate": 0.00039291960621974463,
      "loss": 2.0734,
      "step": 16100
    },
    {
      "epoch": 62.442718446601944,
      "grad_norm": 0.49506115913391113,
      "learning_rate": 0.0003927929426391324,
      "loss": 2.0768,
      "step": 16110
    },
    {
      "epoch": 62.48155339805825,
      "grad_norm": 0.3219869136810303,
      "learning_rate": 0.00039266622463209023,
      "loss": 2.0639,
      "step": 16120
    },
    {
      "epoch": 62.52038834951456,
      "grad_norm": 0.3110466003417969,
      "learning_rate": 0.0003925394522469175,
      "loss": 2.07,
      "step": 16130
    },
    {
      "epoch": 62.55922330097087,
      "grad_norm": 0.34828346967697144,
      "learning_rate": 0.0003924126255319344,
      "loss": 2.0691,
      "step": 16140
    },
    {
      "epoch": 62.59805825242719,
      "grad_norm": 0.3979134261608124,
      "learning_rate": 0.0003922857445354815,
      "loss": 2.0722,
      "step": 16150
    },
    {
      "epoch": 62.636893203883496,
      "grad_norm": 0.3203534185886383,
      "learning_rate": 0.00039215880930592044,
      "loss": 2.0623,
      "step": 16160
    },
    {
      "epoch": 62.675728155339804,
      "grad_norm": 0.32148775458335876,
      "learning_rate": 0.0003920318198916334,
      "loss": 2.0727,
      "step": 16170
    },
    {
      "epoch": 62.71456310679611,
      "grad_norm": 0.3433291018009186,
      "learning_rate": 0.0003919047763410233,
      "loss": 2.0731,
      "step": 16180
    },
    {
      "epoch": 62.75339805825243,
      "grad_norm": 0.28603243827819824,
      "learning_rate": 0.00039177767870251324,
      "loss": 2.069,
      "step": 16190
    },
    {
      "epoch": 62.79223300970874,
      "grad_norm": 0.6473296880722046,
      "learning_rate": 0.0003916505270245476,
      "loss": 2.0725,
      "step": 16200
    },
    {
      "epoch": 62.83106796116505,
      "grad_norm": 0.360393226146698,
      "learning_rate": 0.00039152332135559097,
      "loss": 2.0759,
      "step": 16210
    },
    {
      "epoch": 62.869902912621356,
      "grad_norm": 0.3428356945514679,
      "learning_rate": 0.00039139606174412855,
      "loss": 2.0842,
      "step": 16220
    },
    {
      "epoch": 62.90873786407767,
      "grad_norm": 0.30498677492141724,
      "learning_rate": 0.00039126874823866613,
      "loss": 2.0585,
      "step": 16230
    },
    {
      "epoch": 62.94757281553398,
      "grad_norm": 0.30803415179252625,
      "learning_rate": 0.0003911413808877301,
      "loss": 2.0609,
      "step": 16240
    },
    {
      "epoch": 62.98640776699029,
      "grad_norm": 0.31694403290748596,
      "learning_rate": 0.0003910139597398673,
      "loss": 2.0772,
      "step": 16250
    },
    {
      "epoch": 63.0,
      "eval_loss": 1.029883861541748,
      "eval_runtime": 6.5745,
      "eval_samples_per_second": 3767.913,
      "eval_steps_per_second": 14.754,
      "step": 16254
    },
    {
      "epoch": 63.023300970873784,
      "grad_norm": 0.2821144759654999,
      "learning_rate": 0.00039088648484364517,
      "loss": 1.9607,
      "step": 16260
    },
    {
      "epoch": 63.0621359223301,
      "grad_norm": 0.33424562215805054,
      "learning_rate": 0.00039075895624765143,
      "loss": 2.0606,
      "step": 16270
    },
    {
      "epoch": 63.10097087378641,
      "grad_norm": 0.32878974080085754,
      "learning_rate": 0.0003906313740004946,
      "loss": 2.0642,
      "step": 16280
    },
    {
      "epoch": 63.13980582524272,
      "grad_norm": 0.38854536414146423,
      "learning_rate": 0.00039050373815080334,
      "loss": 2.0711,
      "step": 16290
    },
    {
      "epoch": 63.17864077669903,
      "grad_norm": 0.38085269927978516,
      "learning_rate": 0.00039037604874722675,
      "loss": 2.0709,
      "step": 16300
    },
    {
      "epoch": 63.21747572815534,
      "grad_norm": 0.34240856766700745,
      "learning_rate": 0.00039024830583843476,
      "loss": 2.0555,
      "step": 16310
    },
    {
      "epoch": 63.25631067961165,
      "grad_norm": 0.42694512009620667,
      "learning_rate": 0.00039012050947311705,
      "loss": 2.0879,
      "step": 16320
    },
    {
      "epoch": 63.29514563106796,
      "grad_norm": 0.3173041045665741,
      "learning_rate": 0.00038999265969998423,
      "loss": 2.0552,
      "step": 16330
    },
    {
      "epoch": 63.33398058252427,
      "grad_norm": 0.3218177258968353,
      "learning_rate": 0.0003898647565677669,
      "loss": 2.0604,
      "step": 16340
    },
    {
      "epoch": 63.372815533980585,
      "grad_norm": 0.30282464623451233,
      "learning_rate": 0.0003897368001252163,
      "loss": 2.0586,
      "step": 16350
    },
    {
      "epoch": 63.411650485436894,
      "grad_norm": 0.28626111149787903,
      "learning_rate": 0.0003896087904211036,
      "loss": 2.0637,
      "step": 16360
    },
    {
      "epoch": 63.4504854368932,
      "grad_norm": 0.4655974209308624,
      "learning_rate": 0.0003894807275042208,
      "loss": 2.0613,
      "step": 16370
    },
    {
      "epoch": 63.48932038834951,
      "grad_norm": 0.3163113296031952,
      "learning_rate": 0.00038935261142337974,
      "loss": 2.0647,
      "step": 16380
    },
    {
      "epoch": 63.52815533980583,
      "grad_norm": 0.44203072786331177,
      "learning_rate": 0.00038922444222741265,
      "loss": 2.0765,
      "step": 16390
    },
    {
      "epoch": 63.56699029126214,
      "grad_norm": 0.5454599261283875,
      "learning_rate": 0.00038909621996517207,
      "loss": 2.0729,
      "step": 16400
    },
    {
      "epoch": 63.605825242718446,
      "grad_norm": 0.34669172763824463,
      "learning_rate": 0.0003889679446855307,
      "loss": 2.0691,
      "step": 16410
    },
    {
      "epoch": 63.644660194174755,
      "grad_norm": 0.31328266859054565,
      "learning_rate": 0.00038883961643738143,
      "loss": 2.0686,
      "step": 16420
    },
    {
      "epoch": 63.68349514563107,
      "grad_norm": 0.3648994565010071,
      "learning_rate": 0.00038871123526963746,
      "loss": 2.0735,
      "step": 16430
    },
    {
      "epoch": 63.72233009708738,
      "grad_norm": 0.31041327118873596,
      "learning_rate": 0.00038858280123123213,
      "loss": 2.0557,
      "step": 16440
    },
    {
      "epoch": 63.76116504854369,
      "grad_norm": 0.35323163866996765,
      "learning_rate": 0.0003884543143711187,
      "loss": 2.0823,
      "step": 16450
    },
    {
      "epoch": 63.8,
      "grad_norm": 0.3303091824054718,
      "learning_rate": 0.0003883257747382709,
      "loss": 2.0809,
      "step": 16460
    },
    {
      "epoch": 63.83883495145631,
      "grad_norm": 0.2950144112110138,
      "learning_rate": 0.00038819718238168236,
      "loss": 2.0684,
      "step": 16470
    },
    {
      "epoch": 63.87766990291262,
      "grad_norm": 0.37068361043930054,
      "learning_rate": 0.0003880685373503668,
      "loss": 2.0742,
      "step": 16480
    },
    {
      "epoch": 63.91650485436893,
      "grad_norm": 0.28502458333969116,
      "learning_rate": 0.0003879398396933583,
      "loss": 2.0797,
      "step": 16490
    },
    {
      "epoch": 63.95533980582524,
      "grad_norm": 0.35160282254219055,
      "learning_rate": 0.00038781108945971053,
      "loss": 2.0739,
      "step": 16500
    },
    {
      "epoch": 63.994174757281556,
      "grad_norm": 0.36070308089256287,
      "learning_rate": 0.00038768228669849766,
      "loss": 2.0733,
      "step": 16510
    },
    {
      "epoch": 64.0,
      "eval_loss": 1.0305148363113403,
      "eval_runtime": 6.4835,
      "eval_samples_per_second": 3820.777,
      "eval_steps_per_second": 14.961,
      "step": 16512
    },
    {
      "epoch": 64.03106796116505,
      "grad_norm": 0.33798378705978394,
      "learning_rate": 0.0003875534314588135,
      "loss": 1.9714,
      "step": 16520
    },
    {
      "epoch": 64.06990291262136,
      "grad_norm": 0.321518212556839,
      "learning_rate": 0.0003874245237897722,
      "loss": 2.0527,
      "step": 16530
    },
    {
      "epoch": 64.10873786407767,
      "grad_norm": 0.34912627935409546,
      "learning_rate": 0.0003872955637405076,
      "loss": 2.0655,
      "step": 16540
    },
    {
      "epoch": 64.14757281553398,
      "grad_norm": 0.424785315990448,
      "learning_rate": 0.00038716655136017365,
      "loss": 2.0667,
      "step": 16550
    },
    {
      "epoch": 64.18640776699029,
      "grad_norm": 0.36942291259765625,
      "learning_rate": 0.0003870374866979444,
      "loss": 2.0628,
      "step": 16560
    },
    {
      "epoch": 64.22524271844661,
      "grad_norm": 0.3908397853374481,
      "learning_rate": 0.00038690836980301334,
      "loss": 2.0647,
      "step": 16570
    },
    {
      "epoch": 64.26407766990292,
      "grad_norm": 0.5068619847297668,
      "learning_rate": 0.0003867792007245945,
      "loss": 2.0554,
      "step": 16580
    },
    {
      "epoch": 64.30291262135923,
      "grad_norm": 0.3971349000930786,
      "learning_rate": 0.0003866499795119213,
      "loss": 2.073,
      "step": 16590
    },
    {
      "epoch": 64.34174757281554,
      "grad_norm": 0.52939373254776,
      "learning_rate": 0.0003865207062142474,
      "loss": 2.0767,
      "step": 16600
    },
    {
      "epoch": 64.38058252427184,
      "grad_norm": 0.5537197589874268,
      "learning_rate": 0.00038639138088084583,
      "loss": 2.0572,
      "step": 16610
    },
    {
      "epoch": 64.41941747572815,
      "grad_norm": 0.32047832012176514,
      "learning_rate": 0.00038626200356101006,
      "loss": 2.0675,
      "step": 16620
    },
    {
      "epoch": 64.45825242718446,
      "grad_norm": 0.33728957176208496,
      "learning_rate": 0.0003861325743040529,
      "loss": 2.0666,
      "step": 16630
    },
    {
      "epoch": 64.49708737864077,
      "grad_norm": 0.3327423632144928,
      "learning_rate": 0.00038600309315930725,
      "loss": 2.0762,
      "step": 16640
    },
    {
      "epoch": 64.5359223300971,
      "grad_norm": 0.2772270143032074,
      "learning_rate": 0.0003858735601761255,
      "loss": 2.061,
      "step": 16650
    },
    {
      "epoch": 64.5747572815534,
      "grad_norm": 0.34707146883010864,
      "learning_rate": 0.0003857439754038801,
      "loss": 2.0728,
      "step": 16660
    },
    {
      "epoch": 64.61359223300971,
      "grad_norm": 0.313958078622818,
      "learning_rate": 0.00038561433889196305,
      "loss": 2.0708,
      "step": 16670
    },
    {
      "epoch": 64.65242718446602,
      "grad_norm": 0.35506004095077515,
      "learning_rate": 0.0003854846506897862,
      "loss": 2.0597,
      "step": 16680
    },
    {
      "epoch": 64.69126213592233,
      "grad_norm": 0.4767383933067322,
      "learning_rate": 0.00038535491084678084,
      "loss": 2.0737,
      "step": 16690
    },
    {
      "epoch": 64.73009708737864,
      "grad_norm": 0.31502026319503784,
      "learning_rate": 0.00038522511941239826,
      "loss": 2.0816,
      "step": 16700
    },
    {
      "epoch": 64.76893203883495,
      "grad_norm": 0.33266326785087585,
      "learning_rate": 0.0003850952764361093,
      "loss": 2.0689,
      "step": 16710
    },
    {
      "epoch": 64.80776699029126,
      "grad_norm": 0.3138318657875061,
      "learning_rate": 0.0003849653819674044,
      "loss": 2.0775,
      "step": 16720
    },
    {
      "epoch": 64.84660194174758,
      "grad_norm": 0.32015055418014526,
      "learning_rate": 0.00038483543605579367,
      "loss": 2.0593,
      "step": 16730
    },
    {
      "epoch": 64.88543689320389,
      "grad_norm": 0.3927343487739563,
      "learning_rate": 0.0003847054387508068,
      "loss": 2.0734,
      "step": 16740
    },
    {
      "epoch": 64.9242718446602,
      "grad_norm": 0.29665887355804443,
      "learning_rate": 0.00038457539010199304,
      "loss": 2.0728,
      "step": 16750
    },
    {
      "epoch": 64.9631067961165,
      "grad_norm": 0.33305299282073975,
      "learning_rate": 0.0003844452901589213,
      "loss": 2.0559,
      "step": 16760
    },
    {
      "epoch": 65.0,
      "grad_norm": 0.19940149784088135,
      "learning_rate": 0.0003843151389711799,
      "loss": 1.9667,
      "step": 16770
    },
    {
      "epoch": 65.0,
      "eval_loss": 1.0294055938720703,
      "eval_runtime": 6.5177,
      "eval_samples_per_second": 3800.754,
      "eval_steps_per_second": 14.883,
      "step": 16770
    },
    {
      "epoch": 65.03883495145631,
      "grad_norm": 0.4089430570602417,
      "learning_rate": 0.000384184936588377,
      "loss": 2.0671,
      "step": 16780
    },
    {
      "epoch": 65.07766990291262,
      "grad_norm": 0.3657515347003937,
      "learning_rate": 0.0003840546830601399,
      "loss": 2.0615,
      "step": 16790
    },
    {
      "epoch": 65.11650485436893,
      "grad_norm": 0.4170611500740051,
      "learning_rate": 0.0003839243784361155,
      "loss": 2.0456,
      "step": 16800
    },
    {
      "epoch": 65.15533980582525,
      "grad_norm": 0.46843796968460083,
      "learning_rate": 0.0003837940227659704,
      "loss": 2.066,
      "step": 16810
    },
    {
      "epoch": 65.19417475728156,
      "grad_norm": 0.3193427324295044,
      "learning_rate": 0.00038366361609939027,
      "loss": 2.071,
      "step": 16820
    },
    {
      "epoch": 65.23300970873787,
      "grad_norm": 0.4685814678668976,
      "learning_rate": 0.00038353315848608073,
      "loss": 2.0654,
      "step": 16830
    },
    {
      "epoch": 65.27184466019418,
      "grad_norm": 0.3617064952850342,
      "learning_rate": 0.0003834026499757662,
      "loss": 2.0662,
      "step": 16840
    },
    {
      "epoch": 65.31067961165049,
      "grad_norm": 0.3312850296497345,
      "learning_rate": 0.000383272090618191,
      "loss": 2.0778,
      "step": 16850
    },
    {
      "epoch": 65.3495145631068,
      "grad_norm": 0.34917131066322327,
      "learning_rate": 0.00038314148046311865,
      "loss": 2.0637,
      "step": 16860
    },
    {
      "epoch": 65.3883495145631,
      "grad_norm": 0.3671534061431885,
      "learning_rate": 0.000383010819560332,
      "loss": 2.0605,
      "step": 16870
    },
    {
      "epoch": 65.42718446601941,
      "grad_norm": 0.3571719229221344,
      "learning_rate": 0.0003828801079596333,
      "loss": 2.0519,
      "step": 16880
    },
    {
      "epoch": 65.46601941747574,
      "grad_norm": 0.3435002565383911,
      "learning_rate": 0.000382749345710844,
      "loss": 2.0634,
      "step": 16890
    },
    {
      "epoch": 65.50485436893204,
      "grad_norm": 0.3620357811450958,
      "learning_rate": 0.0003826185328638051,
      "loss": 2.0834,
      "step": 16900
    },
    {
      "epoch": 65.54368932038835,
      "grad_norm": 0.3383804261684418,
      "learning_rate": 0.00038248766946837666,
      "loss": 2.0494,
      "step": 16910
    },
    {
      "epoch": 65.58252427184466,
      "grad_norm": 0.3426457941532135,
      "learning_rate": 0.0003823567555744381,
      "loss": 2.0707,
      "step": 16920
    },
    {
      "epoch": 65.62135922330097,
      "grad_norm": 0.3209192156791687,
      "learning_rate": 0.0003822257912318881,
      "loss": 2.0646,
      "step": 16930
    },
    {
      "epoch": 65.66019417475728,
      "grad_norm": 0.2638227343559265,
      "learning_rate": 0.00038209477649064455,
      "loss": 2.0692,
      "step": 16940
    },
    {
      "epoch": 65.69902912621359,
      "grad_norm": 0.28347083926200867,
      "learning_rate": 0.0003819637114006445,
      "loss": 2.0785,
      "step": 16950
    },
    {
      "epoch": 65.7378640776699,
      "grad_norm": 0.33199188113212585,
      "learning_rate": 0.0003818325960118442,
      "loss": 2.0699,
      "step": 16960
    },
    {
      "epoch": 65.77669902912622,
      "grad_norm": 0.3459513187408447,
      "learning_rate": 0.00038170143037421925,
      "loss": 2.0678,
      "step": 16970
    },
    {
      "epoch": 65.81553398058253,
      "grad_norm": 0.2756015956401825,
      "learning_rate": 0.0003815702145377641,
      "loss": 2.0617,
      "step": 16980
    },
    {
      "epoch": 65.85436893203884,
      "grad_norm": 0.323795348405838,
      "learning_rate": 0.0003814389485524926,
      "loss": 2.0708,
      "step": 16990
    },
    {
      "epoch": 65.89320388349515,
      "grad_norm": 0.40719783306121826,
      "learning_rate": 0.0003813076324684375,
      "loss": 2.0675,
      "step": 17000
    },
    {
      "epoch": 65.93203883495146,
      "grad_norm": 0.30831775069236755,
      "learning_rate": 0.00038117626633565085,
      "loss": 2.0663,
      "step": 17010
    },
    {
      "epoch": 65.97087378640776,
      "grad_norm": 0.28447937965393066,
      "learning_rate": 0.0003810448502042037,
      "loss": 2.0582,
      "step": 17020
    },
    {
      "epoch": 66.0,
      "eval_loss": 1.029489517211914,
      "eval_runtime": 6.4864,
      "eval_samples_per_second": 3819.057,
      "eval_steps_per_second": 14.954,
      "step": 17028
    },
    {
      "epoch": 66.00776699029126,
      "grad_norm": 0.28251001238822937,
      "learning_rate": 0.0003809133841241861,
      "loss": 1.9694,
      "step": 17030
    },
    {
      "epoch": 66.04660194174757,
      "grad_norm": 0.42073214054107666,
      "learning_rate": 0.00038078186814570703,
      "loss": 2.0552,
      "step": 17040
    },
    {
      "epoch": 66.08543689320388,
      "grad_norm": 0.3624875545501709,
      "learning_rate": 0.00038065030231889486,
      "loss": 2.0662,
      "step": 17050
    },
    {
      "epoch": 66.1242718446602,
      "grad_norm": 0.5221313238143921,
      "learning_rate": 0.00038051868669389667,
      "loss": 2.05,
      "step": 17060
    },
    {
      "epoch": 66.16310679611651,
      "grad_norm": 0.2903931438922882,
      "learning_rate": 0.00038038702132087854,
      "loss": 2.0511,
      "step": 17070
    },
    {
      "epoch": 66.20194174757282,
      "grad_norm": 0.42825302481651306,
      "learning_rate": 0.0003802553062500256,
      "loss": 2.0608,
      "step": 17080
    },
    {
      "epoch": 66.24077669902913,
      "grad_norm": 0.36343953013420105,
      "learning_rate": 0.0003801235415315418,
      "loss": 2.0769,
      "step": 17090
    },
    {
      "epoch": 66.27961165048544,
      "grad_norm": 0.4670962393283844,
      "learning_rate": 0.0003799917272156501,
      "loss": 2.0657,
      "step": 17100
    },
    {
      "epoch": 66.31844660194174,
      "grad_norm": 0.27782106399536133,
      "learning_rate": 0.00037985986335259246,
      "loss": 2.0616,
      "step": 17110
    },
    {
      "epoch": 66.35728155339805,
      "grad_norm": 0.292341947555542,
      "learning_rate": 0.0003797279499926296,
      "loss": 2.0567,
      "step": 17120
    },
    {
      "epoch": 66.39611650485436,
      "grad_norm": 0.32909417152404785,
      "learning_rate": 0.00037959598718604107,
      "loss": 2.0612,
      "step": 17130
    },
    {
      "epoch": 66.43495145631069,
      "grad_norm": 0.5834903717041016,
      "learning_rate": 0.00037946397498312534,
      "loss": 2.0647,
      "step": 17140
    },
    {
      "epoch": 66.473786407767,
      "grad_norm": 0.48945897817611694,
      "learning_rate": 0.0003793319134341997,
      "loss": 2.0887,
      "step": 17150
    },
    {
      "epoch": 66.5126213592233,
      "grad_norm": 0.35782548785209656,
      "learning_rate": 0.00037919980258960023,
      "loss": 2.0649,
      "step": 17160
    },
    {
      "epoch": 66.55145631067961,
      "grad_norm": 0.4310206174850464,
      "learning_rate": 0.00037906764249968184,
      "loss": 2.053,
      "step": 17170
    },
    {
      "epoch": 66.59029126213592,
      "grad_norm": 0.3152129054069519,
      "learning_rate": 0.0003789354332148182,
      "loss": 2.074,
      "step": 17180
    },
    {
      "epoch": 66.62912621359223,
      "grad_norm": 0.3532100021839142,
      "learning_rate": 0.0003788031747854017,
      "loss": 2.0587,
      "step": 17190
    },
    {
      "epoch": 66.66796116504854,
      "grad_norm": 0.3003247380256653,
      "learning_rate": 0.0003786708672618433,
      "loss": 2.0817,
      "step": 17200
    },
    {
      "epoch": 66.70679611650485,
      "grad_norm": 0.3791848123073578,
      "learning_rate": 0.0003785385106945731,
      "loss": 2.068,
      "step": 17210
    },
    {
      "epoch": 66.74563106796117,
      "grad_norm": 0.3348417580127716,
      "learning_rate": 0.0003784061051340396,
      "loss": 2.073,
      "step": 17220
    },
    {
      "epoch": 66.78446601941748,
      "grad_norm": 0.3390110731124878,
      "learning_rate": 0.00037827365063070983,
      "loss": 2.0615,
      "step": 17230
    },
    {
      "epoch": 66.82330097087379,
      "grad_norm": 0.3226270079612732,
      "learning_rate": 0.00037814114723506986,
      "loss": 2.0614,
      "step": 17240
    },
    {
      "epoch": 66.8621359223301,
      "grad_norm": 0.304801881313324,
      "learning_rate": 0.0003780085949976241,
      "loss": 2.0712,
      "step": 17250
    },
    {
      "epoch": 66.9009708737864,
      "grad_norm": 0.4078071117401123,
      "learning_rate": 0.0003778759939688956,
      "loss": 2.0558,
      "step": 17260
    },
    {
      "epoch": 66.93980582524271,
      "grad_norm": 0.36547040939331055,
      "learning_rate": 0.0003777433441994263,
      "loss": 2.0709,
      "step": 17270
    },
    {
      "epoch": 66.97864077669902,
      "grad_norm": 0.36366716027259827,
      "learning_rate": 0.0003776106457397762,
      "loss": 2.0772,
      "step": 17280
    },
    {
      "epoch": 67.0,
      "eval_loss": 1.029860258102417,
      "eval_runtime": 6.5315,
      "eval_samples_per_second": 3792.716,
      "eval_steps_per_second": 14.851,
      "step": 17286
    },
    {
      "epoch": 67.01553398058252,
      "grad_norm": 0.3257231116294861,
      "learning_rate": 0.0003774778986405245,
      "loss": 1.9668,
      "step": 17290
    },
    {
      "epoch": 67.05436893203884,
      "grad_norm": 0.30324700474739075,
      "learning_rate": 0.00037734510295226825,
      "loss": 2.0628,
      "step": 17300
    },
    {
      "epoch": 67.09320388349515,
      "grad_norm": 0.36473435163497925,
      "learning_rate": 0.0003772122587256236,
      "loss": 2.0541,
      "step": 17310
    },
    {
      "epoch": 67.13203883495146,
      "grad_norm": 0.35401496291160583,
      "learning_rate": 0.00037707936601122485,
      "loss": 2.0539,
      "step": 17320
    },
    {
      "epoch": 67.17087378640777,
      "grad_norm": 0.4036289155483246,
      "learning_rate": 0.00037694642485972495,
      "loss": 2.0656,
      "step": 17330
    },
    {
      "epoch": 67.20970873786408,
      "grad_norm": 0.39007291197776794,
      "learning_rate": 0.00037681343532179525,
      "loss": 2.0599,
      "step": 17340
    },
    {
      "epoch": 67.24854368932039,
      "grad_norm": 0.3247927129268646,
      "learning_rate": 0.0003766803974481254,
      "loss": 2.0684,
      "step": 17350
    },
    {
      "epoch": 67.2873786407767,
      "grad_norm": 0.367119163274765,
      "learning_rate": 0.000376547311289424,
      "loss": 2.0549,
      "step": 17360
    },
    {
      "epoch": 67.326213592233,
      "grad_norm": 0.36103060841560364,
      "learning_rate": 0.00037641417689641726,
      "loss": 2.0769,
      "step": 17370
    },
    {
      "epoch": 67.36504854368933,
      "grad_norm": 0.3614403009414673,
      "learning_rate": 0.0003762809943198504,
      "loss": 2.0636,
      "step": 17380
    },
    {
      "epoch": 67.40388349514564,
      "grad_norm": 0.34519582986831665,
      "learning_rate": 0.00037614776361048676,
      "loss": 2.0632,
      "step": 17390
    },
    {
      "epoch": 67.44271844660194,
      "grad_norm": 0.37568432092666626,
      "learning_rate": 0.0003760144848191081,
      "loss": 2.0578,
      "step": 17400
    },
    {
      "epoch": 67.48155339805825,
      "grad_norm": 0.30448058247566223,
      "learning_rate": 0.0003758811579965145,
      "loss": 2.0733,
      "step": 17410
    },
    {
      "epoch": 67.52038834951456,
      "grad_norm": 0.3403794765472412,
      "learning_rate": 0.0003757477831935242,
      "loss": 2.0849,
      "step": 17420
    },
    {
      "epoch": 67.55922330097087,
      "grad_norm": 0.36666736006736755,
      "learning_rate": 0.0003756143604609739,
      "loss": 2.0709,
      "step": 17430
    },
    {
      "epoch": 67.59805825242718,
      "grad_norm": 0.35801970958709717,
      "learning_rate": 0.0003754808898497186,
      "loss": 2.0471,
      "step": 17440
    },
    {
      "epoch": 67.63689320388349,
      "grad_norm": 0.39512544870376587,
      "learning_rate": 0.00037534737141063136,
      "loss": 2.0759,
      "step": 17450
    },
    {
      "epoch": 67.67572815533981,
      "grad_norm": 0.4049103260040283,
      "learning_rate": 0.00037521380519460354,
      "loss": 2.0531,
      "step": 17460
    },
    {
      "epoch": 67.71456310679612,
      "grad_norm": 0.42362067103385925,
      "learning_rate": 0.0003750801912525449,
      "loss": 2.0597,
      "step": 17470
    },
    {
      "epoch": 67.75339805825243,
      "grad_norm": 0.3358888328075409,
      "learning_rate": 0.0003749465296353831,
      "loss": 2.0736,
      "step": 17480
    },
    {
      "epoch": 67.79223300970874,
      "grad_norm": 0.2990834414958954,
      "learning_rate": 0.0003748128203940641,
      "loss": 2.061,
      "step": 17490
    },
    {
      "epoch": 67.83106796116505,
      "grad_norm": 0.3273005783557892,
      "learning_rate": 0.0003746790635795521,
      "loss": 2.068,
      "step": 17500
    },
    {
      "epoch": 67.86990291262136,
      "grad_norm": 0.34267398715019226,
      "learning_rate": 0.0003745452592428294,
      "loss": 2.0645,
      "step": 17510
    },
    {
      "epoch": 67.90873786407766,
      "grad_norm": 0.3403396010398865,
      "learning_rate": 0.00037441140743489626,
      "loss": 2.0773,
      "step": 17520
    },
    {
      "epoch": 67.94757281553397,
      "grad_norm": 0.33437424898147583,
      "learning_rate": 0.00037427750820677116,
      "loss": 2.0537,
      "step": 17530
    },
    {
      "epoch": 67.9864077669903,
      "grad_norm": 0.3228286802768707,
      "learning_rate": 0.0003741435616094906,
      "loss": 2.0647,
      "step": 17540
    },
    {
      "epoch": 68.0,
      "eval_loss": 1.0297222137451172,
      "eval_runtime": 6.5086,
      "eval_samples_per_second": 3806.015,
      "eval_steps_per_second": 14.903,
      "step": 17544
    },
    {
      "epoch": 68.02330097087379,
      "grad_norm": 0.39196670055389404,
      "learning_rate": 0.00037400956769410924,
      "loss": 1.9309,
      "step": 17550
    },
    {
      "epoch": 68.0621359223301,
      "grad_norm": 0.3820957839488983,
      "learning_rate": 0.00037387552651169977,
      "loss": 2.0711,
      "step": 17560
    },
    {
      "epoch": 68.10097087378641,
      "grad_norm": 0.38994383811950684,
      "learning_rate": 0.0003737414381133527,
      "loss": 2.0583,
      "step": 17570
    },
    {
      "epoch": 68.13980582524272,
      "grad_norm": 0.35095205903053284,
      "learning_rate": 0.0003736073025501767,
      "loss": 2.0525,
      "step": 17580
    },
    {
      "epoch": 68.17864077669903,
      "grad_norm": 0.35812780261039734,
      "learning_rate": 0.0003734731198732983,
      "loss": 2.0634,
      "step": 17590
    },
    {
      "epoch": 68.21747572815534,
      "grad_norm": 0.35810890793800354,
      "learning_rate": 0.0003733388901338623,
      "loss": 2.0795,
      "step": 17600
    },
    {
      "epoch": 68.25631067961164,
      "grad_norm": 0.4643770754337311,
      "learning_rate": 0.000373204613383031,
      "loss": 2.0563,
      "step": 17610
    },
    {
      "epoch": 68.29514563106797,
      "grad_norm": 0.3240717053413391,
      "learning_rate": 0.000373070289671985,
      "loss": 2.0569,
      "step": 17620
    },
    {
      "epoch": 68.33398058252428,
      "grad_norm": 0.31565460562705994,
      "learning_rate": 0.0003729359190519224,
      "loss": 2.0535,
      "step": 17630
    },
    {
      "epoch": 68.37281553398059,
      "grad_norm": 0.29294103384017944,
      "learning_rate": 0.00037280150157405965,
      "loss": 2.0616,
      "step": 17640
    },
    {
      "epoch": 68.4116504854369,
      "grad_norm": 0.35467612743377686,
      "learning_rate": 0.0003726670372896307,
      "loss": 2.0675,
      "step": 17650
    },
    {
      "epoch": 68.4504854368932,
      "grad_norm": 0.5802844762802124,
      "learning_rate": 0.00037253252624988754,
      "loss": 2.0584,
      "step": 17660
    },
    {
      "epoch": 68.48932038834951,
      "grad_norm": 0.3074240982532501,
      "learning_rate": 0.00037239796850609976,
      "loss": 2.0816,
      "step": 17670
    },
    {
      "epoch": 68.52815533980582,
      "grad_norm": 0.3145759701728821,
      "learning_rate": 0.00037226336410955496,
      "loss": 2.0634,
      "step": 17680
    },
    {
      "epoch": 68.56699029126213,
      "grad_norm": 0.3062897026538849,
      "learning_rate": 0.0003721287131115585,
      "loss": 2.0539,
      "step": 17690
    },
    {
      "epoch": 68.60582524271845,
      "grad_norm": 0.33488908410072327,
      "learning_rate": 0.00037199401556343336,
      "loss": 2.0714,
      "step": 17700
    },
    {
      "epoch": 68.64466019417476,
      "grad_norm": 0.43528157472610474,
      "learning_rate": 0.00037185927151652047,
      "loss": 2.066,
      "step": 17710
    },
    {
      "epoch": 68.68349514563107,
      "grad_norm": 0.3375927209854126,
      "learning_rate": 0.0003717244810221784,
      "loss": 2.0553,
      "step": 17720
    },
    {
      "epoch": 68.72233009708738,
      "grad_norm": 0.39272186160087585,
      "learning_rate": 0.00037158964413178315,
      "loss": 2.083,
      "step": 17730
    },
    {
      "epoch": 68.76116504854369,
      "grad_norm": 0.39997780323028564,
      "learning_rate": 0.0003714547608967289,
      "loss": 2.0492,
      "step": 17740
    },
    {
      "epoch": 68.8,
      "grad_norm": 0.3707231879234314,
      "learning_rate": 0.00037131983136842717,
      "loss": 2.0713,
      "step": 17750
    },
    {
      "epoch": 68.8388349514563,
      "grad_norm": 0.33778175711631775,
      "learning_rate": 0.00037118485559830714,
      "loss": 2.0505,
      "step": 17760
    },
    {
      "epoch": 68.87766990291261,
      "grad_norm": 0.3404404819011688,
      "learning_rate": 0.0003710498336378158,
      "loss": 2.0595,
      "step": 17770
    },
    {
      "epoch": 68.91650485436894,
      "grad_norm": 0.3351440727710724,
      "learning_rate": 0.00037091476553841745,
      "loss": 2.0575,
      "step": 17780
    },
    {
      "epoch": 68.95533980582525,
      "grad_norm": 0.3518200218677521,
      "learning_rate": 0.00037077965135159436,
      "loss": 2.0771,
      "step": 17790
    },
    {
      "epoch": 68.99417475728156,
      "grad_norm": 0.371489554643631,
      "learning_rate": 0.000370644491128846,
      "loss": 2.061,
      "step": 17800
    },
    {
      "epoch": 69.0,
      "eval_loss": 1.0298818349838257,
      "eval_runtime": 6.5058,
      "eval_samples_per_second": 3807.69,
      "eval_steps_per_second": 14.91,
      "step": 17802
    },
    {
      "epoch": 69.03106796116505,
      "grad_norm": 0.3027048110961914,
      "learning_rate": 0.0003705092849216896,
      "loss": 1.9637,
      "step": 17810
    },
    {
      "epoch": 69.06990291262136,
      "grad_norm": 0.3273242712020874,
      "learning_rate": 0.00037037403278165974,
      "loss": 2.0652,
      "step": 17820
    },
    {
      "epoch": 69.10873786407767,
      "grad_norm": 0.3065931797027588,
      "learning_rate": 0.00037023873476030886,
      "loss": 2.0701,
      "step": 17830
    },
    {
      "epoch": 69.14757281553398,
      "grad_norm": 0.41522082686424255,
      "learning_rate": 0.0003701033909092064,
      "loss": 2.0425,
      "step": 17840
    },
    {
      "epoch": 69.18640776699029,
      "grad_norm": 0.3193700909614563,
      "learning_rate": 0.0003699680012799397,
      "loss": 2.0577,
      "step": 17850
    },
    {
      "epoch": 69.22524271844661,
      "grad_norm": 0.3118259906768799,
      "learning_rate": 0.0003698325659241133,
      "loss": 2.0528,
      "step": 17860
    },
    {
      "epoch": 69.26407766990292,
      "grad_norm": 0.48908981680870056,
      "learning_rate": 0.0003696970848933493,
      "loss": 2.0548,
      "step": 17870
    },
    {
      "epoch": 69.30291262135923,
      "grad_norm": 0.32196158170700073,
      "learning_rate": 0.000369561558239287,
      "loss": 2.0553,
      "step": 17880
    },
    {
      "epoch": 69.34174757281554,
      "grad_norm": 0.2938918471336365,
      "learning_rate": 0.00036942598601358333,
      "loss": 2.0594,
      "step": 17890
    },
    {
      "epoch": 69.38058252427184,
      "grad_norm": 0.3475985825061798,
      "learning_rate": 0.0003692903682679126,
      "loss": 2.0599,
      "step": 17900
    },
    {
      "epoch": 69.41941747572815,
      "grad_norm": 0.3041396737098694,
      "learning_rate": 0.00036915470505396623,
      "loss": 2.064,
      "step": 17910
    },
    {
      "epoch": 69.45825242718446,
      "grad_norm": 0.33278688788414,
      "learning_rate": 0.00036901899642345317,
      "loss": 2.0619,
      "step": 17920
    },
    {
      "epoch": 69.49708737864077,
      "grad_norm": 0.316293329000473,
      "learning_rate": 0.00036888324242809954,
      "loss": 2.0552,
      "step": 17930
    },
    {
      "epoch": 69.5359223300971,
      "grad_norm": 0.42251071333885193,
      "learning_rate": 0.000368747443119649,
      "loss": 2.0529,
      "step": 17940
    },
    {
      "epoch": 69.5747572815534,
      "grad_norm": 0.3358291983604431,
      "learning_rate": 0.00036861159854986204,
      "loss": 2.0566,
      "step": 17950
    },
    {
      "epoch": 69.61359223300971,
      "grad_norm": 0.3334525525569916,
      "learning_rate": 0.000368475708770517,
      "loss": 2.0757,
      "step": 17960
    },
    {
      "epoch": 69.65242718446602,
      "grad_norm": 0.2919236123561859,
      "learning_rate": 0.0003683397738334089,
      "loss": 2.0557,
      "step": 17970
    },
    {
      "epoch": 69.69126213592233,
      "grad_norm": 0.3664054274559021,
      "learning_rate": 0.00036820379379035024,
      "loss": 2.0596,
      "step": 17980
    },
    {
      "epoch": 69.73009708737864,
      "grad_norm": 0.3667922914028168,
      "learning_rate": 0.0003680677686931707,
      "loss": 2.0632,
      "step": 17990
    },
    {
      "epoch": 69.76893203883495,
      "grad_norm": 0.34734490513801575,
      "learning_rate": 0.0003679316985937171,
      "loss": 2.0574,
      "step": 18000
    },
    {
      "epoch": 69.80776699029126,
      "grad_norm": 0.3410707116127014,
      "learning_rate": 0.0003677955835438534,
      "loss": 2.0803,
      "step": 18010
    },
    {
      "epoch": 69.84660194174758,
      "grad_norm": 0.3097571134567261,
      "learning_rate": 0.0003676594235954608,
      "loss": 2.0641,
      "step": 18020
    },
    {
      "epoch": 69.88543689320389,
      "grad_norm": 0.43471279740333557,
      "learning_rate": 0.0003675232188004373,
      "loss": 2.0718,
      "step": 18030
    },
    {
      "epoch": 69.9242718446602,
      "grad_norm": 0.2776918411254883,
      "learning_rate": 0.00036738696921069844,
      "loss": 2.058,
      "step": 18040
    },
    {
      "epoch": 69.9631067961165,
      "grad_norm": 0.3241272568702698,
      "learning_rate": 0.0003672506748781765,
      "loss": 2.0671,
      "step": 18050
    },
    {
      "epoch": 70.0,
      "grad_norm": 0.19946733117103577,
      "learning_rate": 0.000367114335854821,
      "loss": 1.9711,
      "step": 18060
    },
    {
      "epoch": 70.0,
      "eval_loss": 1.0299195051193237,
      "eval_runtime": 6.5054,
      "eval_samples_per_second": 3807.921,
      "eval_steps_per_second": 14.911,
      "step": 18060
    },
    {
      "epoch": 70.03883495145631,
      "grad_norm": 0.3790755867958069,
      "learning_rate": 0.0003669779521925983,
      "loss": 2.053,
      "step": 18070
    },
    {
      "epoch": 70.07766990291262,
      "grad_norm": 0.3595866858959198,
      "learning_rate": 0.000366841523943492,
      "loss": 2.057,
      "step": 18080
    },
    {
      "epoch": 70.11650485436893,
      "grad_norm": 0.3112979531288147,
      "learning_rate": 0.00036670505115950257,
      "loss": 2.0555,
      "step": 18090
    },
    {
      "epoch": 70.15533980582525,
      "grad_norm": 0.40930643677711487,
      "learning_rate": 0.00036656853389264744,
      "loss": 2.0539,
      "step": 18100
    },
    {
      "epoch": 70.19417475728156,
      "grad_norm": 0.31365689635276794,
      "learning_rate": 0.00036643197219496105,
      "loss": 2.0586,
      "step": 18110
    },
    {
      "epoch": 70.23300970873787,
      "grad_norm": 0.4195583462715149,
      "learning_rate": 0.00036629536611849467,
      "loss": 2.0631,
      "step": 18120
    },
    {
      "epoch": 70.27184466019418,
      "grad_norm": 0.34346652030944824,
      "learning_rate": 0.00036615871571531666,
      "loss": 2.0584,
      "step": 18130
    },
    {
      "epoch": 70.31067961165049,
      "grad_norm": 0.3289528787136078,
      "learning_rate": 0.00036602202103751225,
      "loss": 2.0538,
      "step": 18140
    },
    {
      "epoch": 70.3495145631068,
      "grad_norm": 0.35265806317329407,
      "learning_rate": 0.0003658852821371833,
      "loss": 2.0646,
      "step": 18150
    },
    {
      "epoch": 70.3883495145631,
      "grad_norm": 0.46865591406822205,
      "learning_rate": 0.0003657484990664488,
      "loss": 2.0762,
      "step": 18160
    },
    {
      "epoch": 70.42718446601941,
      "grad_norm": 0.3401123881340027,
      "learning_rate": 0.0003656116718774445,
      "loss": 2.0689,
      "step": 18170
    },
    {
      "epoch": 70.46601941747574,
      "grad_norm": 0.35586971044540405,
      "learning_rate": 0.00036547480062232285,
      "loss": 2.0523,
      "step": 18180
    },
    {
      "epoch": 70.50485436893204,
      "grad_norm": 0.28740864992141724,
      "learning_rate": 0.0003653378853532533,
      "loss": 2.0663,
      "step": 18190
    },
    {
      "epoch": 70.54368932038835,
      "grad_norm": 0.29936546087265015,
      "learning_rate": 0.00036520092612242196,
      "loss": 2.0727,
      "step": 18200
    },
    {
      "epoch": 70.58252427184466,
      "grad_norm": 0.35071226954460144,
      "learning_rate": 0.0003650639229820316,
      "loss": 2.0521,
      "step": 18210
    },
    {
      "epoch": 70.62135922330097,
      "grad_norm": 0.292733758687973,
      "learning_rate": 0.0003649268759843019,
      "loss": 2.0773,
      "step": 18220
    },
    {
      "epoch": 70.66019417475728,
      "grad_norm": 0.38557252287864685,
      "learning_rate": 0.0003647897851814692,
      "loss": 2.0488,
      "step": 18230
    },
    {
      "epoch": 70.69902912621359,
      "grad_norm": 0.31830185651779175,
      "learning_rate": 0.00036465265062578646,
      "loss": 2.0609,
      "step": 18240
    },
    {
      "epoch": 70.7378640776699,
      "grad_norm": 0.356074720621109,
      "learning_rate": 0.00036451547236952353,
      "loss": 2.0529,
      "step": 18250
    },
    {
      "epoch": 70.77669902912622,
      "grad_norm": 0.3299086093902588,
      "learning_rate": 0.0003643782504649666,
      "loss": 2.0501,
      "step": 18260
    },
    {
      "epoch": 70.81553398058253,
      "grad_norm": 0.3586241900920868,
      "learning_rate": 0.0003642409849644187,
      "loss": 2.0569,
      "step": 18270
    },
    {
      "epoch": 70.85436893203884,
      "grad_norm": 0.31892862915992737,
      "learning_rate": 0.0003641036759201995,
      "loss": 2.0646,
      "step": 18280
    },
    {
      "epoch": 70.89320388349515,
      "grad_norm": 0.36155322194099426,
      "learning_rate": 0.0003639663233846452,
      "loss": 2.0501,
      "step": 18290
    },
    {
      "epoch": 70.93203883495146,
      "grad_norm": 0.27615201473236084,
      "learning_rate": 0.0003638289274101085,
      "loss": 2.0629,
      "step": 18300
    },
    {
      "epoch": 70.97087378640776,
      "grad_norm": 0.3570214509963989,
      "learning_rate": 0.00036369148804895886,
      "loss": 2.0745,
      "step": 18310
    },
    {
      "epoch": 71.0,
      "eval_loss": 1.0295220613479614,
      "eval_runtime": 6.5069,
      "eval_samples_per_second": 3807.044,
      "eval_steps_per_second": 14.907,
      "step": 18318
    },
    {
      "epoch": 71.00776699029126,
      "grad_norm": 0.45331504940986633,
      "learning_rate": 0.0003635540053535821,
      "loss": 1.955,
      "step": 18320
    },
    {
      "epoch": 71.04660194174757,
      "grad_norm": 0.3044680953025818,
      "learning_rate": 0.0003634164793763806,
      "loss": 2.078,
      "step": 18330
    },
    {
      "epoch": 71.08543689320388,
      "grad_norm": 0.2838292121887207,
      "learning_rate": 0.00036327891016977324,
      "loss": 2.0563,
      "step": 18340
    },
    {
      "epoch": 71.1242718446602,
      "grad_norm": 0.34061726927757263,
      "learning_rate": 0.0003631412977861954,
      "loss": 2.0387,
      "step": 18350
    },
    {
      "epoch": 71.16310679611651,
      "grad_norm": 0.3853917121887207,
      "learning_rate": 0.000363003642278099,
      "loss": 2.0662,
      "step": 18360
    },
    {
      "epoch": 71.20194174757282,
      "grad_norm": 0.3723796010017395,
      "learning_rate": 0.0003628659436979522,
      "loss": 2.0473,
      "step": 18370
    },
    {
      "epoch": 71.24077669902913,
      "grad_norm": 0.3143497705459595,
      "learning_rate": 0.0003627282020982397,
      "loss": 2.0536,
      "step": 18380
    },
    {
      "epoch": 71.27961165048544,
      "grad_norm": 0.4271869957447052,
      "learning_rate": 0.0003625904175314627,
      "loss": 2.0691,
      "step": 18390
    },
    {
      "epoch": 71.31844660194174,
      "grad_norm": 0.3355030417442322,
      "learning_rate": 0.0003624525900501384,
      "loss": 2.0692,
      "step": 18400
    },
    {
      "epoch": 71.35728155339805,
      "grad_norm": 0.37336575984954834,
      "learning_rate": 0.0003623147197068008,
      "loss": 2.0577,
      "step": 18410
    },
    {
      "epoch": 71.39611650485436,
      "grad_norm": 0.40122148394584656,
      "learning_rate": 0.000362176806554,
      "loss": 2.0544,
      "step": 18420
    },
    {
      "epoch": 71.43495145631069,
      "grad_norm": 0.3518845736980438,
      "learning_rate": 0.00036203885064430247,
      "loss": 2.0533,
      "step": 18430
    },
    {
      "epoch": 71.473786407767,
      "grad_norm": 0.3406514823436737,
      "learning_rate": 0.00036190085203029106,
      "loss": 2.0579,
      "step": 18440
    },
    {
      "epoch": 71.5126213592233,
      "grad_norm": 0.4023200571537018,
      "learning_rate": 0.0003617628107645647,
      "loss": 2.0611,
      "step": 18450
    },
    {
      "epoch": 71.55145631067961,
      "grad_norm": 0.3929646909236908,
      "learning_rate": 0.00036162472689973865,
      "loss": 2.0565,
      "step": 18460
    },
    {
      "epoch": 71.59029126213592,
      "grad_norm": 0.32409536838531494,
      "learning_rate": 0.00036148660048844456,
      "loss": 2.0724,
      "step": 18470
    },
    {
      "epoch": 71.62912621359223,
      "grad_norm": 0.33811891078948975,
      "learning_rate": 0.00036134843158333016,
      "loss": 2.0418,
      "step": 18480
    },
    {
      "epoch": 71.66796116504854,
      "grad_norm": 0.2972520589828491,
      "learning_rate": 0.0003612102202370594,
      "loss": 2.054,
      "step": 18490
    },
    {
      "epoch": 71.70679611650485,
      "grad_norm": 0.33830249309539795,
      "learning_rate": 0.00036107196650231235,
      "loss": 2.0473,
      "step": 18500
    },
    {
      "epoch": 71.74563106796117,
      "grad_norm": 0.3749779760837555,
      "learning_rate": 0.00036093367043178525,
      "loss": 2.0627,
      "step": 18510
    },
    {
      "epoch": 71.78446601941748,
      "grad_norm": 0.3203352689743042,
      "learning_rate": 0.0003607953320781907,
      "loss": 2.0632,
      "step": 18520
    },
    {
      "epoch": 71.82330097087379,
      "grad_norm": 0.34845200181007385,
      "learning_rate": 0.000360656951494257,
      "loss": 2.0602,
      "step": 18530
    },
    {
      "epoch": 71.8621359223301,
      "grad_norm": 0.28139057755470276,
      "learning_rate": 0.0003605185287327291,
      "loss": 2.0514,
      "step": 18540
    },
    {
      "epoch": 71.9009708737864,
      "grad_norm": 0.32373154163360596,
      "learning_rate": 0.0003603800638463674,
      "loss": 2.0647,
      "step": 18550
    },
    {
      "epoch": 71.93980582524271,
      "grad_norm": 0.44192466139793396,
      "learning_rate": 0.0003602415568879488,
      "loss": 2.0562,
      "step": 18560
    },
    {
      "epoch": 71.97864077669902,
      "grad_norm": 0.28752973675727844,
      "learning_rate": 0.00036010300791026605,
      "loss": 2.0615,
      "step": 18570
    },
    {
      "epoch": 72.0,
      "eval_loss": 1.029654622077942,
      "eval_runtime": 6.5308,
      "eval_samples_per_second": 3793.094,
      "eval_steps_per_second": 14.853,
      "step": 18576
    },
    {
      "epoch": 72.01553398058252,
      "grad_norm": 0.35661405324935913,
      "learning_rate": 0.000359964416966128,
      "loss": 1.9556,
      "step": 18580
    },
    {
      "epoch": 72.05436893203884,
      "grad_norm": 0.3611311614513397,
      "learning_rate": 0.0003598257841083596,
      "loss": 2.0586,
      "step": 18590
    },
    {
      "epoch": 72.09320388349515,
      "grad_norm": 0.4192553162574768,
      "learning_rate": 0.0003596871093898014,
      "loss": 2.0516,
      "step": 18600
    },
    {
      "epoch": 72.13203883495146,
      "grad_norm": 0.4105961322784424,
      "learning_rate": 0.0003595483928633102,
      "loss": 2.048,
      "step": 18610
    },
    {
      "epoch": 72.17087378640777,
      "grad_norm": 0.31066346168518066,
      "learning_rate": 0.00035940963458175876,
      "loss": 2.0482,
      "step": 18620
    },
    {
      "epoch": 72.20970873786408,
      "grad_norm": 0.523673951625824,
      "learning_rate": 0.00035927083459803556,
      "loss": 2.06,
      "step": 18630
    },
    {
      "epoch": 72.24854368932039,
      "grad_norm": 0.2926185429096222,
      "learning_rate": 0.00035913199296504526,
      "loss": 2.0568,
      "step": 18640
    },
    {
      "epoch": 72.2873786407767,
      "grad_norm": 0.28259044885635376,
      "learning_rate": 0.0003589931097357081,
      "loss": 2.053,
      "step": 18650
    },
    {
      "epoch": 72.326213592233,
      "grad_norm": 0.3297300636768341,
      "learning_rate": 0.0003588541849629603,
      "loss": 2.0672,
      "step": 18660
    },
    {
      "epoch": 72.36504854368933,
      "grad_norm": 0.2970571219921112,
      "learning_rate": 0.000358715218699754,
      "loss": 2.0506,
      "step": 18670
    },
    {
      "epoch": 72.40388349514564,
      "grad_norm": 0.289063036441803,
      "learning_rate": 0.0003585762109990569,
      "loss": 2.0556,
      "step": 18680
    },
    {
      "epoch": 72.44271844660194,
      "grad_norm": 0.31772956252098083,
      "learning_rate": 0.00035843716191385285,
      "loss": 2.0526,
      "step": 18690
    },
    {
      "epoch": 72.48155339805825,
      "grad_norm": 0.3520582616329193,
      "learning_rate": 0.0003582980714971411,
      "loss": 2.0548,
      "step": 18700
    },
    {
      "epoch": 72.52038834951456,
      "grad_norm": 0.38096895813941956,
      "learning_rate": 0.00035815893980193703,
      "loss": 2.0697,
      "step": 18710
    },
    {
      "epoch": 72.55922330097087,
      "grad_norm": 0.33049488067626953,
      "learning_rate": 0.00035801976688127143,
      "loss": 2.0582,
      "step": 18720
    },
    {
      "epoch": 72.59805825242718,
      "grad_norm": 0.36435291171073914,
      "learning_rate": 0.00035788055278819096,
      "loss": 2.0591,
      "step": 18730
    },
    {
      "epoch": 72.63689320388349,
      "grad_norm": 0.36046820878982544,
      "learning_rate": 0.000357741297575758,
      "loss": 2.0601,
      "step": 18740
    },
    {
      "epoch": 72.67572815533981,
      "grad_norm": 0.3206873834133148,
      "learning_rate": 0.00035760200129705057,
      "loss": 2.0695,
      "step": 18750
    },
    {
      "epoch": 72.71456310679612,
      "grad_norm": 0.387743204832077,
      "learning_rate": 0.0003574626640051621,
      "loss": 2.0586,
      "step": 18760
    },
    {
      "epoch": 72.75339805825243,
      "grad_norm": 0.49816450476646423,
      "learning_rate": 0.0003573232857532022,
      "loss": 2.0633,
      "step": 18770
    },
    {
      "epoch": 72.79223300970874,
      "grad_norm": 0.3632389307022095,
      "learning_rate": 0.0003571838665942955,
      "loss": 2.0708,
      "step": 18780
    },
    {
      "epoch": 72.83106796116505,
      "grad_norm": 0.2947966456413269,
      "learning_rate": 0.0003570444065815828,
      "loss": 2.0617,
      "step": 18790
    },
    {
      "epoch": 72.86990291262136,
      "grad_norm": 0.2761215567588806,
      "learning_rate": 0.00035690490576821977,
      "loss": 2.0549,
      "step": 18800
    },
    {
      "epoch": 72.90873786407766,
      "grad_norm": 0.32986536622047424,
      "learning_rate": 0.0003567653642073783,
      "loss": 2.0498,
      "step": 18810
    },
    {
      "epoch": 72.94757281553397,
      "grad_norm": 0.2874845862388611,
      "learning_rate": 0.00035662578195224537,
      "loss": 2.0617,
      "step": 18820
    },
    {
      "epoch": 72.9864077669903,
      "grad_norm": 0.3090917468070984,
      "learning_rate": 0.0003564861590560238,
      "loss": 2.0497,
      "step": 18830
    },
    {
      "epoch": 73.0,
      "eval_loss": 1.0299789905548096,
      "eval_runtime": 6.5037,
      "eval_samples_per_second": 3808.907,
      "eval_steps_per_second": 14.915,
      "step": 18834
    },
    {
      "epoch": 73.02330097087379,
      "grad_norm": 0.3103024661540985,
      "learning_rate": 0.0003563464955719317,
      "loss": 1.9553,
      "step": 18840
    },
    {
      "epoch": 73.0621359223301,
      "grad_norm": 0.3022203743457794,
      "learning_rate": 0.0003562067915532026,
      "loss": 2.0539,
      "step": 18850
    },
    {
      "epoch": 73.10097087378641,
      "grad_norm": 0.3474291265010834,
      "learning_rate": 0.0003560670470530856,
      "loss": 2.0725,
      "step": 18860
    },
    {
      "epoch": 73.13980582524272,
      "grad_norm": 0.33961644768714905,
      "learning_rate": 0.0003559272621248453,
      "loss": 2.0459,
      "step": 18870
    },
    {
      "epoch": 73.17864077669903,
      "grad_norm": 0.30241966247558594,
      "learning_rate": 0.0003557874368217614,
      "loss": 2.0561,
      "step": 18880
    },
    {
      "epoch": 73.21747572815534,
      "grad_norm": 0.3879588842391968,
      "learning_rate": 0.0003556475711971294,
      "loss": 2.0559,
      "step": 18890
    },
    {
      "epoch": 73.25631067961164,
      "grad_norm": 0.45449021458625793,
      "learning_rate": 0.00035550766530425995,
      "loss": 2.0545,
      "step": 18900
    },
    {
      "epoch": 73.29514563106797,
      "grad_norm": 0.4434860646724701,
      "learning_rate": 0.00035536771919647883,
      "loss": 2.0609,
      "step": 18910
    },
    {
      "epoch": 73.33398058252428,
      "grad_norm": 0.4266393482685089,
      "learning_rate": 0.0003552277329271276,
      "loss": 2.0589,
      "step": 18920
    },
    {
      "epoch": 73.37281553398059,
      "grad_norm": 0.31712618470191956,
      "learning_rate": 0.0003550877065495629,
      "loss": 2.0516,
      "step": 18930
    },
    {
      "epoch": 73.4116504854369,
      "grad_norm": 0.33965545892715454,
      "learning_rate": 0.0003549476401171566,
      "loss": 2.0565,
      "step": 18940
    },
    {
      "epoch": 73.4504854368932,
      "grad_norm": 0.3267667293548584,
      "learning_rate": 0.00035480753368329586,
      "loss": 2.0535,
      "step": 18950
    },
    {
      "epoch": 73.48932038834951,
      "grad_norm": 0.32216185331344604,
      "learning_rate": 0.0003546673873013832,
      "loss": 2.0534,
      "step": 18960
    },
    {
      "epoch": 73.52815533980582,
      "grad_norm": 0.29501140117645264,
      "learning_rate": 0.00035452720102483625,
      "loss": 2.0697,
      "step": 18970
    },
    {
      "epoch": 73.56699029126213,
      "grad_norm": 0.30321839451789856,
      "learning_rate": 0.00035438697490708805,
      "loss": 2.0489,
      "step": 18980
    },
    {
      "epoch": 73.60582524271845,
      "grad_norm": 0.35358354449272156,
      "learning_rate": 0.0003542467090015865,
      "loss": 2.0575,
      "step": 18990
    },
    {
      "epoch": 73.64466019417476,
      "grad_norm": 0.4181424081325531,
      "learning_rate": 0.0003541064033617949,
      "loss": 2.0496,
      "step": 19000
    },
    {
      "epoch": 73.68349514563107,
      "grad_norm": 0.3931998610496521,
      "learning_rate": 0.00035396605804119153,
      "loss": 2.0628,
      "step": 19010
    },
    {
      "epoch": 73.72233009708738,
      "grad_norm": 0.3511526584625244,
      "learning_rate": 0.0003538256730932701,
      "loss": 2.0582,
      "step": 19020
    },
    {
      "epoch": 73.76116504854369,
      "grad_norm": 0.34028923511505127,
      "learning_rate": 0.000353685248571539,
      "loss": 2.0606,
      "step": 19030
    },
    {
      "epoch": 73.8,
      "grad_norm": 0.3256620764732361,
      "learning_rate": 0.00035354478452952204,
      "loss": 2.0475,
      "step": 19040
    },
    {
      "epoch": 73.8388349514563,
      "grad_norm": 0.367147833108902,
      "learning_rate": 0.0003534042810207579,
      "loss": 2.0498,
      "step": 19050
    },
    {
      "epoch": 73.87766990291261,
      "grad_norm": 0.40138307213783264,
      "learning_rate": 0.00035326373809880054,
      "loss": 2.0698,
      "step": 19060
    },
    {
      "epoch": 73.91650485436894,
      "grad_norm": 0.45879554748535156,
      "learning_rate": 0.00035312315581721856,
      "loss": 2.0466,
      "step": 19070
    },
    {
      "epoch": 73.95533980582525,
      "grad_norm": 0.38155099749565125,
      "learning_rate": 0.0003529825342295959,
      "loss": 2.0651,
      "step": 19080
    },
    {
      "epoch": 73.99417475728156,
      "grad_norm": 0.39041104912757874,
      "learning_rate": 0.0003528418733895314,
      "loss": 2.0561,
      "step": 19090
    },
    {
      "epoch": 74.0,
      "eval_loss": 1.0295226573944092,
      "eval_runtime": 6.6791,
      "eval_samples_per_second": 3708.892,
      "eval_steps_per_second": 14.523,
      "step": 19092
    },
    {
      "epoch": 74.03106796116505,
      "grad_norm": 0.3192436397075653,
      "learning_rate": 0.00035270117335063877,
      "loss": 1.9533,
      "step": 19100
    },
    {
      "epoch": 74.06990291262136,
      "grad_norm": 0.34233400225639343,
      "learning_rate": 0.0003525604341665467,
      "loss": 2.0561,
      "step": 19110
    },
    {
      "epoch": 74.10873786407767,
      "grad_norm": 0.3868182897567749,
      "learning_rate": 0.0003524196558908988,
      "loss": 2.0507,
      "step": 19120
    },
    {
      "epoch": 74.14757281553398,
      "grad_norm": 0.3380627930164337,
      "learning_rate": 0.00035227883857735375,
      "loss": 2.0511,
      "step": 19130
    },
    {
      "epoch": 74.18640776699029,
      "grad_norm": 0.3624793291091919,
      "learning_rate": 0.0003521379822795848,
      "loss": 2.0358,
      "step": 19140
    },
    {
      "epoch": 74.22524271844661,
      "grad_norm": 0.42465201020240784,
      "learning_rate": 0.0003519970870512802,
      "loss": 2.0487,
      "step": 19150
    },
    {
      "epoch": 74.26407766990292,
      "grad_norm": 0.3735371232032776,
      "learning_rate": 0.00035185615294614316,
      "loss": 2.0462,
      "step": 19160
    },
    {
      "epoch": 74.30291262135923,
      "grad_norm": 0.41211381554603577,
      "learning_rate": 0.0003517151800178916,
      "loss": 2.0535,
      "step": 19170
    },
    {
      "epoch": 74.34174757281554,
      "grad_norm": 0.37556296586990356,
      "learning_rate": 0.0003515741683202582,
      "loss": 2.056,
      "step": 19180
    },
    {
      "epoch": 74.38058252427184,
      "grad_norm": 0.5512443780899048,
      "learning_rate": 0.0003514331179069904,
      "loss": 2.0507,
      "step": 19190
    },
    {
      "epoch": 74.41941747572815,
      "grad_norm": 0.3576740026473999,
      "learning_rate": 0.00035129202883185044,
      "loss": 2.0579,
      "step": 19200
    },
    {
      "epoch": 74.45825242718446,
      "grad_norm": 0.42768362164497375,
      "learning_rate": 0.0003511509011486155,
      "loss": 2.0467,
      "step": 19210
    },
    {
      "epoch": 74.49708737864077,
      "grad_norm": 0.3342919647693634,
      "learning_rate": 0.00035100973491107714,
      "loss": 2.0597,
      "step": 19220
    },
    {
      "epoch": 74.5359223300971,
      "grad_norm": 0.30869585275650024,
      "learning_rate": 0.00035086853017304176,
      "loss": 2.0586,
      "step": 19230
    },
    {
      "epoch": 74.5747572815534,
      "grad_norm": 0.4320116937160492,
      "learning_rate": 0.00035072728698833046,
      "loss": 2.0502,
      "step": 19240
    },
    {
      "epoch": 74.61359223300971,
      "grad_norm": 0.39002054929733276,
      "learning_rate": 0.000350586005410779,
      "loss": 2.0631,
      "step": 19250
    },
    {
      "epoch": 74.65242718446602,
      "grad_norm": 0.34379807114601135,
      "learning_rate": 0.0003504446854942377,
      "loss": 2.0478,
      "step": 19260
    },
    {
      "epoch": 74.69126213592233,
      "grad_norm": 0.4486444890499115,
      "learning_rate": 0.0003503033272925715,
      "loss": 2.0586,
      "step": 19270
    },
    {
      "epoch": 74.73009708737864,
      "grad_norm": 0.33339229226112366,
      "learning_rate": 0.00035016193085966006,
      "loss": 2.0493,
      "step": 19280
    },
    {
      "epoch": 74.76893203883495,
      "grad_norm": 0.3313598036766052,
      "learning_rate": 0.00035002049624939757,
      "loss": 2.056,
      "step": 19290
    },
    {
      "epoch": 74.80776699029126,
      "grad_norm": 0.3708805739879608,
      "learning_rate": 0.00034987902351569253,
      "loss": 2.0738,
      "step": 19300
    },
    {
      "epoch": 74.84660194174758,
      "grad_norm": 0.32750996947288513,
      "learning_rate": 0.0003497375127124682,
      "loss": 2.0513,
      "step": 19310
    },
    {
      "epoch": 74.88543689320389,
      "grad_norm": 0.34584853053092957,
      "learning_rate": 0.00034959596389366255,
      "loss": 2.0613,
      "step": 19320
    },
    {
      "epoch": 74.9242718446602,
      "grad_norm": 0.417991042137146,
      "learning_rate": 0.0003494543771132276,
      "loss": 2.059,
      "step": 19330
    },
    {
      "epoch": 74.9631067961165,
      "grad_norm": 1.742672324180603,
      "learning_rate": 0.0003493127524251301,
      "loss": 2.0589,
      "step": 19340
    },
    {
      "epoch": 75.0,
      "grad_norm": 0.21405337750911713,
      "learning_rate": 0.000349171089883351,
      "loss": 1.9604,
      "step": 19350
    },
    {
      "epoch": 75.0,
      "eval_loss": 1.029841661453247,
      "eval_runtime": 6.5711,
      "eval_samples_per_second": 3769.845,
      "eval_steps_per_second": 14.762,
      "step": 19350
    },
    {
      "epoch": 75.03883495145631,
      "grad_norm": 0.3204469382762909,
      "learning_rate": 0.00034902938954188616,
      "loss": 2.0472,
      "step": 19360
    },
    {
      "epoch": 75.07766990291262,
      "grad_norm": 0.3863217830657959,
      "learning_rate": 0.0003488876514547455,
      "loss": 2.048,
      "step": 19370
    },
    {
      "epoch": 75.11650485436893,
      "grad_norm": 0.6141877174377441,
      "learning_rate": 0.00034874587567595327,
      "loss": 2.042,
      "step": 19380
    },
    {
      "epoch": 75.15533980582525,
      "grad_norm": 0.3410460948944092,
      "learning_rate": 0.0003486040622595483,
      "loss": 2.0501,
      "step": 19390
    },
    {
      "epoch": 75.19417475728156,
      "grad_norm": 0.4102934002876282,
      "learning_rate": 0.00034846221125958357,
      "loss": 2.0487,
      "step": 19400
    },
    {
      "epoch": 75.23300970873787,
      "grad_norm": 0.44823864102363586,
      "learning_rate": 0.00034832032273012653,
      "loss": 2.0629,
      "step": 19410
    },
    {
      "epoch": 75.27184466019418,
      "grad_norm": 0.377668172121048,
      "learning_rate": 0.00034817839672525897,
      "loss": 2.0413,
      "step": 19420
    },
    {
      "epoch": 75.31067961165049,
      "grad_norm": 0.3482756018638611,
      "learning_rate": 0.00034803643329907677,
      "loss": 2.0508,
      "step": 19430
    },
    {
      "epoch": 75.3495145631068,
      "grad_norm": 0.33668845891952515,
      "learning_rate": 0.0003478944325056902,
      "loss": 2.0394,
      "step": 19440
    },
    {
      "epoch": 75.3883495145631,
      "grad_norm": 0.41435420513153076,
      "learning_rate": 0.0003477523943992238,
      "loss": 2.0483,
      "step": 19450
    },
    {
      "epoch": 75.42718446601941,
      "grad_norm": 0.4230649471282959,
      "learning_rate": 0.0003476103190338162,
      "loss": 2.0366,
      "step": 19460
    },
    {
      "epoch": 75.46601941747574,
      "grad_norm": 0.3878103494644165,
      "learning_rate": 0.0003474682064636205,
      "loss": 2.0419,
      "step": 19470
    },
    {
      "epoch": 75.50485436893204,
      "grad_norm": 0.4365476965904236,
      "learning_rate": 0.00034732605674280367,
      "loss": 2.0479,
      "step": 19480
    },
    {
      "epoch": 75.54368932038835,
      "grad_norm": 0.417843759059906,
      "learning_rate": 0.00034718386992554695,
      "loss": 2.0575,
      "step": 19490
    },
    {
      "epoch": 75.58252427184466,
      "grad_norm": 0.3894597291946411,
      "learning_rate": 0.0003470416460660458,
      "loss": 2.0558,
      "step": 19500
    },
    {
      "epoch": 75.62135922330097,
      "grad_norm": 0.40668466687202454,
      "learning_rate": 0.00034689938521850967,
      "loss": 2.0636,
      "step": 19510
    },
    {
      "epoch": 75.66019417475728,
      "grad_norm": 0.307628333568573,
      "learning_rate": 0.0003467570874371623,
      "loss": 2.0634,
      "step": 19520
    },
    {
      "epoch": 75.69902912621359,
      "grad_norm": 0.4047493636608124,
      "learning_rate": 0.0003466147527762413,
      "loss": 2.0548,
      "step": 19530
    },
    {
      "epoch": 75.7378640776699,
      "grad_norm": 0.35763201117515564,
      "learning_rate": 0.00034647238128999845,
      "loss": 2.0638,
      "step": 19540
    },
    {
      "epoch": 75.77669902912622,
      "grad_norm": 0.46336597204208374,
      "learning_rate": 0.0003463299730326995,
      "loss": 2.06,
      "step": 19550
    },
    {
      "epoch": 75.81553398058253,
      "grad_norm": 0.537421703338623,
      "learning_rate": 0.0003461875280586243,
      "loss": 2.0591,
      "step": 19560
    },
    {
      "epoch": 75.85436893203884,
      "grad_norm": 0.3591804802417755,
      "learning_rate": 0.00034604504642206667,
      "loss": 2.0626,
      "step": 19570
    },
    {
      "epoch": 75.89320388349515,
      "grad_norm": 0.4123026430606842,
      "learning_rate": 0.00034590252817733437,
      "loss": 2.0527,
      "step": 19580
    },
    {
      "epoch": 75.93203883495146,
      "grad_norm": 0.3385690152645111,
      "learning_rate": 0.000345759973378749,
      "loss": 2.068,
      "step": 19590
    },
    {
      "epoch": 75.97087378640776,
      "grad_norm": 0.3328481912612915,
      "learning_rate": 0.0003456173820806464,
      "loss": 2.0487,
      "step": 19600
    },
    {
      "epoch": 76.0,
      "eval_loss": 1.0304213762283325,
      "eval_runtime": 6.7135,
      "eval_samples_per_second": 3689.886,
      "eval_steps_per_second": 14.449,
      "step": 19608
    },
    {
      "epoch": 76.00776699029126,
      "grad_norm": 0.3210916519165039,
      "learning_rate": 0.00034547475433737606,
      "loss": 1.9629,
      "step": 19610
    },
    {
      "epoch": 76.04660194174757,
      "grad_norm": 0.317383736371994,
      "learning_rate": 0.0003453320902033015,
      "loss": 2.0358,
      "step": 19620
    },
    {
      "epoch": 76.08543689320388,
      "grad_norm": 0.35861703753471375,
      "learning_rate": 0.00034518938973279994,
      "loss": 2.0604,
      "step": 19630
    },
    {
      "epoch": 76.1242718446602,
      "grad_norm": 0.3556954562664032,
      "learning_rate": 0.0003450466529802626,
      "loss": 2.049,
      "step": 19640
    },
    {
      "epoch": 76.16310679611651,
      "grad_norm": 0.32979023456573486,
      "learning_rate": 0.0003449038800000945,
      "loss": 2.0542,
      "step": 19650
    },
    {
      "epoch": 76.20194174757282,
      "grad_norm": 0.3405205011367798,
      "learning_rate": 0.0003447610708467146,
      "loss": 2.0508,
      "step": 19660
    },
    {
      "epoch": 76.24077669902913,
      "grad_norm": 0.3483659625053406,
      "learning_rate": 0.00034461822557455533,
      "loss": 2.0529,
      "step": 19670
    },
    {
      "epoch": 76.27961165048544,
      "grad_norm": 0.3760240077972412,
      "learning_rate": 0.00034447534423806314,
      "loss": 2.0485,
      "step": 19680
    },
    {
      "epoch": 76.31844660194174,
      "grad_norm": 0.36232733726501465,
      "learning_rate": 0.00034433242689169813,
      "loss": 2.0464,
      "step": 19690
    },
    {
      "epoch": 76.35728155339805,
      "grad_norm": 0.3418654501438141,
      "learning_rate": 0.00034418947358993415,
      "loss": 2.0568,
      "step": 19700
    },
    {
      "epoch": 76.39611650485436,
      "grad_norm": 0.3144834041595459,
      "learning_rate": 0.0003440464843872588,
      "loss": 2.0528,
      "step": 19710
    },
    {
      "epoch": 76.43495145631069,
      "grad_norm": 0.3029888868331909,
      "learning_rate": 0.00034390345933817324,
      "loss": 2.052,
      "step": 19720
    },
    {
      "epoch": 76.473786407767,
      "grad_norm": 0.39274683594703674,
      "learning_rate": 0.0003437603984971923,
      "loss": 2.0417,
      "step": 19730
    },
    {
      "epoch": 76.5126213592233,
      "grad_norm": 0.2848382890224457,
      "learning_rate": 0.0003436173019188447,
      "loss": 2.0544,
      "step": 19740
    },
    {
      "epoch": 76.55145631067961,
      "grad_norm": 0.3994585871696472,
      "learning_rate": 0.0003434741696576726,
      "loss": 2.044,
      "step": 19750
    },
    {
      "epoch": 76.59029126213592,
      "grad_norm": 0.4929729402065277,
      "learning_rate": 0.0003433310017682316,
      "loss": 2.0475,
      "step": 19760
    },
    {
      "epoch": 76.62912621359223,
      "grad_norm": 0.3935001790523529,
      "learning_rate": 0.00034318779830509115,
      "loss": 2.0616,
      "step": 19770
    },
    {
      "epoch": 76.66796116504854,
      "grad_norm": 0.3670908212661743,
      "learning_rate": 0.0003430445593228342,
      "loss": 2.0607,
      "step": 19780
    },
    {
      "epoch": 76.70679611650485,
      "grad_norm": 0.3806934952735901,
      "learning_rate": 0.0003429012848760571,
      "loss": 2.0538,
      "step": 19790
    },
    {
      "epoch": 76.74563106796117,
      "grad_norm": 0.30413293838500977,
      "learning_rate": 0.0003427579750193698,
      "loss": 2.0512,
      "step": 19800
    },
    {
      "epoch": 76.78446601941748,
      "grad_norm": 0.33987563848495483,
      "learning_rate": 0.0003426146298073958,
      "loss": 2.0724,
      "step": 19810
    },
    {
      "epoch": 76.82330097087379,
      "grad_norm": 0.37074464559555054,
      "learning_rate": 0.00034247124929477195,
      "loss": 2.0484,
      "step": 19820
    },
    {
      "epoch": 76.8621359223301,
      "grad_norm": 0.364671528339386,
      "learning_rate": 0.0003423278335361488,
      "loss": 2.0491,
      "step": 19830
    },
    {
      "epoch": 76.9009708737864,
      "grad_norm": 0.33639469742774963,
      "learning_rate": 0.00034218438258619,
      "loss": 2.0522,
      "step": 19840
    },
    {
      "epoch": 76.93980582524271,
      "grad_norm": 0.3150968551635742,
      "learning_rate": 0.00034204089649957287,
      "loss": 2.0424,
      "step": 19850
    },
    {
      "epoch": 76.97864077669902,
      "grad_norm": 0.30513110756874084,
      "learning_rate": 0.0003418973753309881,
      "loss": 2.0414,
      "step": 19860
    },
    {
      "epoch": 77.0,
      "eval_loss": 1.0306270122528076,
      "eval_runtime": 6.5369,
      "eval_samples_per_second": 3789.555,
      "eval_steps_per_second": 14.839,
      "step": 19866
    },
    {
      "epoch": 77.0,
      "step": 19866,
      "total_flos": 2.7432401581899776e+16,
      "train_loss": 2.2513718659767603,
      "train_runtime": 5129.1462,
      "train_samples_per_second": 5140.7,
      "train_steps_per_second": 10.021
    }
  ],
  "logging_steps": 10,
  "max_steps": 51400,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 200,
  "save_steps": 1000,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 20,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 20
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.7432401581899776e+16,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
