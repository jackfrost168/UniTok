{
  "best_metric": 1.0546443462371826,
  "best_model_checkpoint": "./ckpt/Grocery_and_Gourmet_Food/checkpoint-8610",
  "epoch": 61.0,
  "eval_steps": 1000,
  "global_step": 12810,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0477326968973747,
      "grad_norm": 16.987943649291992,
      "learning_rate": 1.1961722488038278e-05,
      "loss": 21.5673,
      "step": 10
    },
    {
      "epoch": 0.0954653937947494,
      "grad_norm": 11.101958274841309,
      "learning_rate": 2.3923444976076556e-05,
      "loss": 19.6401,
      "step": 20
    },
    {
      "epoch": 0.1431980906921241,
      "grad_norm": 5.774414539337158,
      "learning_rate": 3.5885167464114834e-05,
      "loss": 17.1932,
      "step": 30
    },
    {
      "epoch": 0.1909307875894988,
      "grad_norm": 4.238267421722412,
      "learning_rate": 4.784688995215311e-05,
      "loss": 15.4445,
      "step": 40
    },
    {
      "epoch": 0.2386634844868735,
      "grad_norm": 4.049271583557129,
      "learning_rate": 5.980861244019139e-05,
      "loss": 13.8047,
      "step": 50
    },
    {
      "epoch": 0.2863961813842482,
      "grad_norm": 3.341317653656006,
      "learning_rate": 7.177033492822967e-05,
      "loss": 11.715,
      "step": 60
    },
    {
      "epoch": 0.3341288782816229,
      "grad_norm": 2.5233657360076904,
      "learning_rate": 8.373205741626795e-05,
      "loss": 9.906,
      "step": 70
    },
    {
      "epoch": 0.3818615751789976,
      "grad_norm": 1.7823245525360107,
      "learning_rate": 9.569377990430622e-05,
      "loss": 8.4206,
      "step": 80
    },
    {
      "epoch": 0.4295942720763723,
      "grad_norm": 1.4933881759643555,
      "learning_rate": 0.00010765550239234451,
      "loss": 7.5383,
      "step": 90
    },
    {
      "epoch": 0.477326968973747,
      "grad_norm": 1.3427989482879639,
      "learning_rate": 0.00011961722488038278,
      "loss": 6.9786,
      "step": 100
    },
    {
      "epoch": 0.5250596658711217,
      "grad_norm": 1.200443983078003,
      "learning_rate": 0.00013157894736842105,
      "loss": 6.5502,
      "step": 110
    },
    {
      "epoch": 0.5727923627684964,
      "grad_norm": 1.0924360752105713,
      "learning_rate": 0.00014354066985645933,
      "loss": 6.2891,
      "step": 120
    },
    {
      "epoch": 0.6205250596658711,
      "grad_norm": 1.045331358909607,
      "learning_rate": 0.00015550239234449762,
      "loss": 6.0574,
      "step": 130
    },
    {
      "epoch": 0.6682577565632458,
      "grad_norm": 0.9874061346054077,
      "learning_rate": 0.0001674641148325359,
      "loss": 5.9192,
      "step": 140
    },
    {
      "epoch": 0.7159904534606205,
      "grad_norm": 0.9004001617431641,
      "learning_rate": 0.00017942583732057416,
      "loss": 5.7856,
      "step": 150
    },
    {
      "epoch": 0.7637231503579952,
      "grad_norm": 0.8976677656173706,
      "learning_rate": 0.00019138755980861245,
      "loss": 5.7032,
      "step": 160
    },
    {
      "epoch": 0.8114558472553699,
      "grad_norm": 0.9107539057731628,
      "learning_rate": 0.00020334928229665073,
      "loss": 5.5978,
      "step": 170
    },
    {
      "epoch": 0.8591885441527446,
      "grad_norm": 0.826259434223175,
      "learning_rate": 0.00021531100478468902,
      "loss": 5.4747,
      "step": 180
    },
    {
      "epoch": 0.9069212410501193,
      "grad_norm": 0.7880362868309021,
      "learning_rate": 0.00022727272727272727,
      "loss": 5.3818,
      "step": 190
    },
    {
      "epoch": 0.954653937947494,
      "grad_norm": 0.7574262619018555,
      "learning_rate": 0.00023923444976076556,
      "loss": 5.2964,
      "step": 200
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.4821344316005707,
      "learning_rate": 0.0002511961722488038,
      "loss": 4.9512,
      "step": 210
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.511110544204712,
      "eval_runtime": 4.2257,
      "eval_samples_per_second": 3474.256,
      "eval_steps_per_second": 13.726,
      "step": 210
    },
    {
      "epoch": 1.0477326968973748,
      "grad_norm": 0.7296544313430786,
      "learning_rate": 0.0002631578947368421,
      "loss": 5.149,
      "step": 220
    },
    {
      "epoch": 1.0954653937947494,
      "grad_norm": 0.7012721300125122,
      "learning_rate": 0.00027511961722488036,
      "loss": 5.0744,
      "step": 230
    },
    {
      "epoch": 1.1431980906921242,
      "grad_norm": 0.6772642135620117,
      "learning_rate": 0.00028708133971291867,
      "loss": 4.9941,
      "step": 240
    },
    {
      "epoch": 1.1909307875894988,
      "grad_norm": 0.688619077205658,
      "learning_rate": 0.0002990430622009569,
      "loss": 4.9368,
      "step": 250
    },
    {
      "epoch": 1.2386634844868736,
      "grad_norm": 0.6666927337646484,
      "learning_rate": 0.00031100478468899524,
      "loss": 4.8744,
      "step": 260
    },
    {
      "epoch": 1.2863961813842482,
      "grad_norm": 0.7699140906333923,
      "learning_rate": 0.0003229665071770335,
      "loss": 4.8063,
      "step": 270
    },
    {
      "epoch": 1.334128878281623,
      "grad_norm": 0.6505792737007141,
      "learning_rate": 0.0003349282296650718,
      "loss": 4.7423,
      "step": 280
    },
    {
      "epoch": 1.3818615751789975,
      "grad_norm": 0.6592571139335632,
      "learning_rate": 0.00034688995215311,
      "loss": 4.6591,
      "step": 290
    },
    {
      "epoch": 1.4295942720763724,
      "grad_norm": 0.5966163277626038,
      "learning_rate": 0.0003588516746411483,
      "loss": 4.5496,
      "step": 300
    },
    {
      "epoch": 1.477326968973747,
      "grad_norm": 0.5681347846984863,
      "learning_rate": 0.0003708133971291866,
      "loss": 4.5363,
      "step": 310
    },
    {
      "epoch": 1.5250596658711217,
      "grad_norm": 0.6328891515731812,
      "learning_rate": 0.0003827751196172249,
      "loss": 4.4358,
      "step": 320
    },
    {
      "epoch": 1.5727923627684963,
      "grad_norm": 0.6398823857307434,
      "learning_rate": 0.00039473684210526315,
      "loss": 4.3632,
      "step": 330
    },
    {
      "epoch": 1.6205250596658711,
      "grad_norm": 0.5426605343818665,
      "learning_rate": 0.00040669856459330146,
      "loss": 4.3165,
      "step": 340
    },
    {
      "epoch": 1.668257756563246,
      "grad_norm": 0.5237721800804138,
      "learning_rate": 0.0004186602870813397,
      "loss": 4.2275,
      "step": 350
    },
    {
      "epoch": 1.7159904534606205,
      "grad_norm": 0.5248255133628845,
      "learning_rate": 0.00043062200956937803,
      "loss": 4.1586,
      "step": 360
    },
    {
      "epoch": 1.763723150357995,
      "grad_norm": 0.5841947197914124,
      "learning_rate": 0.00044258373205741623,
      "loss": 4.1114,
      "step": 370
    },
    {
      "epoch": 1.81145584725537,
      "grad_norm": 0.7567971348762512,
      "learning_rate": 0.00045454545454545455,
      "loss": 4.0111,
      "step": 380
    },
    {
      "epoch": 1.8591885441527447,
      "grad_norm": 0.5632107257843018,
      "learning_rate": 0.0004665071770334928,
      "loss": 3.934,
      "step": 390
    },
    {
      "epoch": 1.9069212410501193,
      "grad_norm": 0.45493680238723755,
      "learning_rate": 0.0004784688995215311,
      "loss": 3.8836,
      "step": 400
    },
    {
      "epoch": 1.9546539379474939,
      "grad_norm": 0.5327443480491638,
      "learning_rate": 0.0004904306220095694,
      "loss": 3.8301,
      "step": 410
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.23039133846759796,
      "learning_rate": 0.0004999999971183132,
      "loss": 3.5635,
      "step": 420
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.8362765312194824,
      "eval_runtime": 4.1988,
      "eval_samples_per_second": 3496.508,
      "eval_steps_per_second": 13.814,
      "step": 420
    },
    {
      "epoch": 2.047732696897375,
      "grad_norm": 0.45888909697532654,
      "learning_rate": 0.0004999998962592776,
      "loss": 3.6699,
      "step": 430
    },
    {
      "epoch": 2.0954653937947496,
      "grad_norm": 0.4429573714733124,
      "learning_rate": 0.0004999996513159624,
      "loss": 3.6193,
      "step": 440
    },
    {
      "epoch": 2.143198090692124,
      "grad_norm": 0.381296306848526,
      "learning_rate": 0.0004999992622885083,
      "loss": 3.548,
      "step": 450
    },
    {
      "epoch": 2.1909307875894988,
      "grad_norm": 0.4775904417037964,
      "learning_rate": 0.0004999987291771399,
      "loss": 3.4983,
      "step": 460
    },
    {
      "epoch": 2.2386634844868736,
      "grad_norm": 0.3675824999809265,
      "learning_rate": 0.0004999980519821642,
      "loss": 3.4485,
      "step": 470
    },
    {
      "epoch": 2.2863961813842484,
      "grad_norm": 0.5375182628631592,
      "learning_rate": 0.0004999972307039715,
      "loss": 3.3791,
      "step": 480
    },
    {
      "epoch": 2.3341288782816227,
      "grad_norm": 0.33890771865844727,
      "learning_rate": 0.0004999962653430354,
      "loss": 3.3224,
      "step": 490
    },
    {
      "epoch": 2.3818615751789975,
      "grad_norm": 0.4347069263458252,
      "learning_rate": 0.0004999951558999118,
      "loss": 3.2501,
      "step": 500
    },
    {
      "epoch": 2.4295942720763724,
      "grad_norm": 0.3312840461730957,
      "learning_rate": 0.0004999939023752405,
      "loss": 3.2179,
      "step": 510
    },
    {
      "epoch": 2.477326968973747,
      "grad_norm": 0.4021073281764984,
      "learning_rate": 0.0004999925047697438,
      "loss": 3.1683,
      "step": 520
    },
    {
      "epoch": 2.5250596658711215,
      "grad_norm": 0.3578287959098816,
      "learning_rate": 0.0004999909630842273,
      "loss": 3.1525,
      "step": 530
    },
    {
      "epoch": 2.5727923627684963,
      "grad_norm": 0.4531056582927704,
      "learning_rate": 0.0004999892773195795,
      "loss": 3.0708,
      "step": 540
    },
    {
      "epoch": 2.620525059665871,
      "grad_norm": 0.4898902177810669,
      "learning_rate": 0.0004999874474767718,
      "loss": 3.0407,
      "step": 550
    },
    {
      "epoch": 2.668257756563246,
      "grad_norm": 0.27259913086891174,
      "learning_rate": 0.000499985473556859,
      "loss": 2.9879,
      "step": 560
    },
    {
      "epoch": 2.7159904534606207,
      "grad_norm": 0.3035893440246582,
      "learning_rate": 0.0004999833555609786,
      "loss": 2.9742,
      "step": 570
    },
    {
      "epoch": 2.763723150357995,
      "grad_norm": 0.38387858867645264,
      "learning_rate": 0.0004999810934903515,
      "loss": 2.9144,
      "step": 580
    },
    {
      "epoch": 2.81145584725537,
      "grad_norm": 0.2755391299724579,
      "learning_rate": 0.0004999786873462811,
      "loss": 2.898,
      "step": 590
    },
    {
      "epoch": 2.8591885441527447,
      "grad_norm": 0.24229849874973297,
      "learning_rate": 0.0004999761371301544,
      "loss": 2.8793,
      "step": 600
    },
    {
      "epoch": 2.906921241050119,
      "grad_norm": 0.3456198573112488,
      "learning_rate": 0.0004999734428434412,
      "loss": 2.8255,
      "step": 610
    },
    {
      "epoch": 2.954653937947494,
      "grad_norm": 0.30348142981529236,
      "learning_rate": 0.0004999706044876941,
      "loss": 2.8259,
      "step": 620
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.16321593523025513,
      "learning_rate": 0.0004999676220645491,
      "loss": 2.6375,
      "step": 630
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.3784959316253662,
      "eval_runtime": 4.1871,
      "eval_samples_per_second": 3506.22,
      "eval_steps_per_second": 13.852,
      "step": 630
    },
    {
      "epoch": 3.047732696897375,
      "grad_norm": 0.27404943108558655,
      "learning_rate": 0.0004999644955757252,
      "loss": 2.771,
      "step": 640
    },
    {
      "epoch": 3.0954653937947496,
      "grad_norm": 0.24266642332077026,
      "learning_rate": 0.000499961225023024,
      "loss": 2.7254,
      "step": 650
    },
    {
      "epoch": 3.143198090692124,
      "grad_norm": 0.2632388472557068,
      "learning_rate": 0.0004999578104083307,
      "loss": 2.7118,
      "step": 660
    },
    {
      "epoch": 3.1909307875894988,
      "grad_norm": 0.3478826582431793,
      "learning_rate": 0.0004999542517336132,
      "loss": 2.6686,
      "step": 670
    },
    {
      "epoch": 3.2386634844868736,
      "grad_norm": 0.23744143545627594,
      "learning_rate": 0.0004999505490009224,
      "loss": 2.6526,
      "step": 680
    },
    {
      "epoch": 3.2863961813842484,
      "grad_norm": 0.23154610395431519,
      "learning_rate": 0.0004999467022123924,
      "loss": 2.651,
      "step": 690
    },
    {
      "epoch": 3.3341288782816227,
      "grad_norm": 0.23398782312870026,
      "learning_rate": 0.0004999427113702403,
      "loss": 2.6291,
      "step": 700
    },
    {
      "epoch": 3.3818615751789975,
      "grad_norm": 0.2889360785484314,
      "learning_rate": 0.0004999385764767662,
      "loss": 2.5863,
      "step": 710
    },
    {
      "epoch": 3.4295942720763724,
      "grad_norm": 0.22486011683940887,
      "learning_rate": 0.000499934297534353,
      "loss": 2.5792,
      "step": 720
    },
    {
      "epoch": 3.477326968973747,
      "grad_norm": 0.21567432582378387,
      "learning_rate": 0.000499929874545467,
      "loss": 2.5596,
      "step": 730
    },
    {
      "epoch": 3.5250596658711215,
      "grad_norm": 0.21621710062026978,
      "learning_rate": 0.0004999253075126572,
      "loss": 2.5427,
      "step": 740
    },
    {
      "epoch": 3.5727923627684963,
      "grad_norm": 0.23802787065505981,
      "learning_rate": 0.0004999205964385559,
      "loss": 2.538,
      "step": 750
    },
    {
      "epoch": 3.620525059665871,
      "grad_norm": 0.30583834648132324,
      "learning_rate": 0.0004999157413258782,
      "loss": 2.5282,
      "step": 760
    },
    {
      "epoch": 3.668257756563246,
      "grad_norm": 0.1973673552274704,
      "learning_rate": 0.0004999107421774222,
      "loss": 2.4973,
      "step": 770
    },
    {
      "epoch": 3.7159904534606207,
      "grad_norm": 0.1860683113336563,
      "learning_rate": 0.0004999055989960691,
      "loss": 2.5001,
      "step": 780
    },
    {
      "epoch": 3.763723150357995,
      "grad_norm": 0.33911681175231934,
      "learning_rate": 0.0004999003117847833,
      "loss": 2.4836,
      "step": 790
    },
    {
      "epoch": 3.81145584725537,
      "grad_norm": 0.31086522340774536,
      "learning_rate": 0.0004998948805466118,
      "loss": 2.4811,
      "step": 800
    },
    {
      "epoch": 3.8591885441527447,
      "grad_norm": 0.33213135600090027,
      "learning_rate": 0.0004998893052846849,
      "loss": 2.4736,
      "step": 810
    },
    {
      "epoch": 3.906921241050119,
      "grad_norm": 0.17756657302379608,
      "learning_rate": 0.000499883586002216,
      "loss": 2.4631,
      "step": 820
    },
    {
      "epoch": 3.954653937947494,
      "grad_norm": 0.27723896503448486,
      "learning_rate": 0.000499877722702501,
      "loss": 2.4443,
      "step": 830
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.14789603650569916,
      "learning_rate": 0.0004998717153889194,
      "loss": 2.3084,
      "step": 840
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.218569040298462,
      "eval_runtime": 4.1743,
      "eval_samples_per_second": 3516.992,
      "eval_steps_per_second": 13.895,
      "step": 840
    },
    {
      "epoch": 4.047732696897374,
      "grad_norm": 0.2068677842617035,
      "learning_rate": 0.0004998655640649334,
      "loss": 2.4191,
      "step": 850
    },
    {
      "epoch": 4.09546539379475,
      "grad_norm": 0.20454752445220947,
      "learning_rate": 0.000499859268734088,
      "loss": 2.4071,
      "step": 860
    },
    {
      "epoch": 4.143198090692124,
      "grad_norm": 0.19424968957901,
      "learning_rate": 0.0004998528294000118,
      "loss": 2.4079,
      "step": 870
    },
    {
      "epoch": 4.190930787589499,
      "grad_norm": 0.4699189364910126,
      "learning_rate": 0.0004998462460664159,
      "loss": 2.4032,
      "step": 880
    },
    {
      "epoch": 4.238663484486874,
      "grad_norm": 0.21202124655246735,
      "learning_rate": 0.0004998395187370945,
      "loss": 2.3896,
      "step": 890
    },
    {
      "epoch": 4.286396181384248,
      "grad_norm": 0.2007710486650467,
      "learning_rate": 0.0004998326474159247,
      "loss": 2.3825,
      "step": 900
    },
    {
      "epoch": 4.334128878281623,
      "grad_norm": 0.22146473824977875,
      "learning_rate": 0.0004998256321068668,
      "loss": 2.381,
      "step": 910
    },
    {
      "epoch": 4.3818615751789975,
      "grad_norm": 0.48905208706855774,
      "learning_rate": 0.0004998184728139639,
      "loss": 2.3781,
      "step": 920
    },
    {
      "epoch": 4.429594272076372,
      "grad_norm": 0.4006662368774414,
      "learning_rate": 0.0004998111695413424,
      "loss": 2.3555,
      "step": 930
    },
    {
      "epoch": 4.477326968973747,
      "grad_norm": 0.18496142327785492,
      "learning_rate": 0.0004998037222932113,
      "loss": 2.3346,
      "step": 940
    },
    {
      "epoch": 4.5250596658711215,
      "grad_norm": 0.25663045048713684,
      "learning_rate": 0.0004997961310738625,
      "loss": 2.3495,
      "step": 950
    },
    {
      "epoch": 4.572792362768497,
      "grad_norm": 0.18252941966056824,
      "learning_rate": 0.0004997883958876715,
      "loss": 2.3291,
      "step": 960
    },
    {
      "epoch": 4.620525059665871,
      "grad_norm": 0.2116013616323471,
      "learning_rate": 0.0004997805167390962,
      "loss": 2.3277,
      "step": 970
    },
    {
      "epoch": 4.6682577565632455,
      "grad_norm": 0.34310296177864075,
      "learning_rate": 0.0004997724936326776,
      "loss": 2.3194,
      "step": 980
    },
    {
      "epoch": 4.715990453460621,
      "grad_norm": 0.2206721305847168,
      "learning_rate": 0.0004997643265730399,
      "loss": 2.3202,
      "step": 990
    },
    {
      "epoch": 4.763723150357995,
      "grad_norm": 0.26794007420539856,
      "learning_rate": 0.0004997560155648897,
      "loss": 2.3231,
      "step": 1000
    },
    {
      "epoch": 4.81145584725537,
      "grad_norm": 0.21499860286712646,
      "learning_rate": 0.0004997475606130174,
      "loss": 2.3165,
      "step": 1010
    },
    {
      "epoch": 4.859188544152745,
      "grad_norm": 0.21923890709877014,
      "learning_rate": 0.0004997389617222956,
      "loss": 2.307,
      "step": 1020
    },
    {
      "epoch": 4.906921241050119,
      "grad_norm": 0.22703926265239716,
      "learning_rate": 0.0004997302188976802,
      "loss": 2.2948,
      "step": 1030
    },
    {
      "epoch": 4.954653937947494,
      "grad_norm": 0.34477078914642334,
      "learning_rate": 0.0004997213321442102,
      "loss": 2.2948,
      "step": 1040
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.1532532423734665,
      "learning_rate": 0.0004997123014670072,
      "loss": 2.1746,
      "step": 1050
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.1539771556854248,
      "eval_runtime": 4.1938,
      "eval_samples_per_second": 3500.661,
      "eval_steps_per_second": 13.83,
      "step": 1050
    },
    {
      "epoch": 5.047732696897374,
      "grad_norm": 0.1791560798883438,
      "learning_rate": 0.000499703126871276,
      "loss": 2.291,
      "step": 1060
    },
    {
      "epoch": 5.09546539379475,
      "grad_norm": 0.24933525919914246,
      "learning_rate": 0.0004996938083623041,
      "loss": 2.289,
      "step": 1070
    },
    {
      "epoch": 5.143198090692124,
      "grad_norm": 0.23978900909423828,
      "learning_rate": 0.0004996843459454624,
      "loss": 2.2591,
      "step": 1080
    },
    {
      "epoch": 5.190930787589499,
      "grad_norm": 0.19239014387130737,
      "learning_rate": 0.0004996747396262041,
      "loss": 2.2846,
      "step": 1090
    },
    {
      "epoch": 5.238663484486874,
      "grad_norm": 0.20632894337177277,
      "learning_rate": 0.000499664989410066,
      "loss": 2.2747,
      "step": 1100
    },
    {
      "epoch": 5.286396181384248,
      "grad_norm": 0.2256929874420166,
      "learning_rate": 0.0004996550953026672,
      "loss": 2.255,
      "step": 1110
    },
    {
      "epoch": 5.334128878281623,
      "grad_norm": 0.21785341203212738,
      "learning_rate": 0.0004996450573097103,
      "loss": 2.2672,
      "step": 1120
    },
    {
      "epoch": 5.3818615751789975,
      "grad_norm": 0.22216112911701202,
      "learning_rate": 0.0004996348754369805,
      "loss": 2.2518,
      "step": 1130
    },
    {
      "epoch": 5.429594272076372,
      "grad_norm": 0.24888771772384644,
      "learning_rate": 0.000499624549690346,
      "loss": 2.2675,
      "step": 1140
    },
    {
      "epoch": 5.477326968973747,
      "grad_norm": 0.2600691318511963,
      "learning_rate": 0.0004996140800757578,
      "loss": 2.2464,
      "step": 1150
    },
    {
      "epoch": 5.5250596658711215,
      "grad_norm": 0.19870159029960632,
      "learning_rate": 0.0004996034665992501,
      "loss": 2.2519,
      "step": 1160
    },
    {
      "epoch": 5.572792362768497,
      "grad_norm": 0.19346366822719574,
      "learning_rate": 0.0004995927092669397,
      "loss": 2.2365,
      "step": 1170
    },
    {
      "epoch": 5.620525059665871,
      "grad_norm": 0.24135009944438934,
      "learning_rate": 0.0004995818080850264,
      "loss": 2.2379,
      "step": 1180
    },
    {
      "epoch": 5.6682577565632455,
      "grad_norm": 0.20480576157569885,
      "learning_rate": 0.0004995707630597932,
      "loss": 2.2399,
      "step": 1190
    },
    {
      "epoch": 5.715990453460621,
      "grad_norm": 0.7157854437828064,
      "learning_rate": 0.0004995595741976057,
      "loss": 2.2459,
      "step": 1200
    },
    {
      "epoch": 5.763723150357995,
      "grad_norm": 0.20913471281528473,
      "learning_rate": 0.0004995482415049123,
      "loss": 2.232,
      "step": 1210
    },
    {
      "epoch": 5.81145584725537,
      "grad_norm": 0.21279163658618927,
      "learning_rate": 0.0004995367649882445,
      "loss": 2.2276,
      "step": 1220
    },
    {
      "epoch": 5.859188544152745,
      "grad_norm": 0.1961023509502411,
      "learning_rate": 0.0004995251446542167,
      "loss": 2.2348,
      "step": 1230
    },
    {
      "epoch": 5.906921241050119,
      "grad_norm": 0.2388780415058136,
      "learning_rate": 0.0004995133805095262,
      "loss": 2.2435,
      "step": 1240
    },
    {
      "epoch": 5.954653937947494,
      "grad_norm": 0.2169170379638672,
      "learning_rate": 0.000499501472560953,
      "loss": 2.2114,
      "step": 1250
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.2142474502325058,
      "learning_rate": 0.0004994894208153602,
      "loss": 2.1258,
      "step": 1260
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.127056360244751,
      "eval_runtime": 4.3625,
      "eval_samples_per_second": 3365.288,
      "eval_steps_per_second": 13.295,
      "step": 1260
    },
    {
      "epoch": 6.047732696897374,
      "grad_norm": 0.24103878438472748,
      "learning_rate": 0.0004994772252796935,
      "loss": 2.2075,
      "step": 1270
    },
    {
      "epoch": 6.09546539379475,
      "grad_norm": 0.21496452391147614,
      "learning_rate": 0.0004994648859609818,
      "loss": 2.2235,
      "step": 1280
    },
    {
      "epoch": 6.143198090692124,
      "grad_norm": 0.24795320630073547,
      "learning_rate": 0.0004994524028663366,
      "loss": 2.2006,
      "step": 1290
    },
    {
      "epoch": 6.190930787589499,
      "grad_norm": 0.22390080988407135,
      "learning_rate": 0.0004994397760029525,
      "loss": 2.2012,
      "step": 1300
    },
    {
      "epoch": 6.238663484486874,
      "grad_norm": 0.23739778995513916,
      "learning_rate": 0.0004994270053781067,
      "loss": 2.2046,
      "step": 1310
    },
    {
      "epoch": 6.286396181384248,
      "grad_norm": 0.22814105451107025,
      "learning_rate": 0.0004994140909991595,
      "loss": 2.2083,
      "step": 1320
    },
    {
      "epoch": 6.334128878281623,
      "grad_norm": 0.2384575605392456,
      "learning_rate": 0.0004994010328735538,
      "loss": 2.2067,
      "step": 1330
    },
    {
      "epoch": 6.3818615751789975,
      "grad_norm": 0.274851530790329,
      "learning_rate": 0.0004993878310088158,
      "loss": 2.2171,
      "step": 1340
    },
    {
      "epoch": 6.429594272076372,
      "grad_norm": 0.22302499413490295,
      "learning_rate": 0.0004993744854125538,
      "loss": 2.2004,
      "step": 1350
    },
    {
      "epoch": 6.477326968973747,
      "grad_norm": 0.2464727759361267,
      "learning_rate": 0.0004993609960924596,
      "loss": 2.187,
      "step": 1360
    },
    {
      "epoch": 6.5250596658711215,
      "grad_norm": 0.24525292217731476,
      "learning_rate": 0.0004993473630563077,
      "loss": 2.1958,
      "step": 1370
    },
    {
      "epoch": 6.572792362768497,
      "grad_norm": 0.23593451082706451,
      "learning_rate": 0.0004993335863119551,
      "loss": 2.2029,
      "step": 1380
    },
    {
      "epoch": 6.620525059665871,
      "grad_norm": 0.2618066966533661,
      "learning_rate": 0.0004993196658673419,
      "loss": 2.2067,
      "step": 1390
    },
    {
      "epoch": 6.6682577565632455,
      "grad_norm": 0.2420128881931305,
      "learning_rate": 0.0004993056017304911,
      "loss": 2.179,
      "step": 1400
    },
    {
      "epoch": 6.715990453460621,
      "grad_norm": 0.2244042158126831,
      "learning_rate": 0.0004992913939095083,
      "loss": 2.1918,
      "step": 1410
    },
    {
      "epoch": 6.763723150357995,
      "grad_norm": 0.2815913259983063,
      "learning_rate": 0.000499277042412582,
      "loss": 2.1823,
      "step": 1420
    },
    {
      "epoch": 6.81145584725537,
      "grad_norm": 0.25583720207214355,
      "learning_rate": 0.0004992625472479835,
      "loss": 2.1877,
      "step": 1430
    },
    {
      "epoch": 6.859188544152745,
      "grad_norm": 0.250040739774704,
      "learning_rate": 0.000499247908424067,
      "loss": 2.1741,
      "step": 1440
    },
    {
      "epoch": 6.906921241050119,
      "grad_norm": 0.24114985764026642,
      "learning_rate": 0.0004992331259492692,
      "loss": 2.1916,
      "step": 1450
    },
    {
      "epoch": 6.954653937947494,
      "grad_norm": 0.22994276881217957,
      "learning_rate": 0.0004992181998321099,
      "loss": 2.1935,
      "step": 1460
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.17834194004535675,
      "learning_rate": 0.0004992031300811916,
      "loss": 2.0737,
      "step": 1470
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.111549735069275,
      "eval_runtime": 4.187,
      "eval_samples_per_second": 3506.319,
      "eval_steps_per_second": 13.852,
      "step": 1470
    },
    {
      "epoch": 7.047732696897374,
      "grad_norm": 0.2302863597869873,
      "learning_rate": 0.0004991879167051997,
      "loss": 2.1607,
      "step": 1480
    },
    {
      "epoch": 7.09546539379475,
      "grad_norm": 0.25013548135757446,
      "learning_rate": 0.000499172559712902,
      "loss": 2.1582,
      "step": 1490
    },
    {
      "epoch": 7.143198090692124,
      "grad_norm": 0.2598956525325775,
      "learning_rate": 0.0004991570591131493,
      "loss": 2.195,
      "step": 1500
    },
    {
      "epoch": 7.190930787589499,
      "grad_norm": 0.23304229974746704,
      "learning_rate": 0.0004991414149148754,
      "loss": 2.16,
      "step": 1510
    },
    {
      "epoch": 7.238663484486874,
      "grad_norm": 0.23509398102760315,
      "learning_rate": 0.0004991256271270965,
      "loss": 2.167,
      "step": 1520
    },
    {
      "epoch": 7.286396181384248,
      "grad_norm": 0.23491255939006805,
      "learning_rate": 0.0004991096957589116,
      "loss": 2.1689,
      "step": 1530
    },
    {
      "epoch": 7.334128878281623,
      "grad_norm": 0.26893073320388794,
      "learning_rate": 0.0004990936208195027,
      "loss": 2.1575,
      "step": 1540
    },
    {
      "epoch": 7.3818615751789975,
      "grad_norm": 0.2466244101524353,
      "learning_rate": 0.0004990774023181343,
      "loss": 2.1661,
      "step": 1550
    },
    {
      "epoch": 7.429594272076372,
      "grad_norm": 0.23937371373176575,
      "learning_rate": 0.0004990610402641539,
      "loss": 2.1552,
      "step": 1560
    },
    {
      "epoch": 7.477326968973747,
      "grad_norm": 0.2573588490486145,
      "learning_rate": 0.0004990445346669913,
      "loss": 2.1667,
      "step": 1570
    },
    {
      "epoch": 7.5250596658711215,
      "grad_norm": 0.2310638129711151,
      "learning_rate": 0.0004990278855361594,
      "loss": 2.1673,
      "step": 1580
    },
    {
      "epoch": 7.572792362768497,
      "grad_norm": 0.2950027883052826,
      "learning_rate": 0.0004990110928812536,
      "loss": 2.1888,
      "step": 1590
    },
    {
      "epoch": 7.620525059665871,
      "grad_norm": 0.25371330976486206,
      "learning_rate": 0.0004989941567119524,
      "loss": 2.1494,
      "step": 1600
    },
    {
      "epoch": 7.6682577565632455,
      "grad_norm": 0.2560241222381592,
      "learning_rate": 0.0004989770770380168,
      "loss": 2.1708,
      "step": 1610
    },
    {
      "epoch": 7.715990453460621,
      "grad_norm": 0.2997075915336609,
      "learning_rate": 0.00049895985386929,
      "loss": 2.1617,
      "step": 1620
    },
    {
      "epoch": 7.763723150357995,
      "grad_norm": 0.27144402265548706,
      "learning_rate": 0.0004989424872156987,
      "loss": 2.1425,
      "step": 1630
    },
    {
      "epoch": 7.81145584725537,
      "grad_norm": 0.24273909628391266,
      "learning_rate": 0.0004989249770872519,
      "loss": 2.1413,
      "step": 1640
    },
    {
      "epoch": 7.859188544152745,
      "grad_norm": 0.36205804347991943,
      "learning_rate": 0.0004989073234940413,
      "loss": 2.1379,
      "step": 1650
    },
    {
      "epoch": 7.906921241050119,
      "grad_norm": 0.28445833921432495,
      "learning_rate": 0.0004988895264462413,
      "loss": 2.1346,
      "step": 1660
    },
    {
      "epoch": 7.954653937947494,
      "grad_norm": 0.3087998330593109,
      "learning_rate": 0.000498871585954109,
      "loss": 2.1527,
      "step": 1670
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.19814157485961914,
      "learning_rate": 0.0004988535020279843,
      "loss": 2.0502,
      "step": 1680
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.1027356386184692,
      "eval_runtime": 4.2135,
      "eval_samples_per_second": 3484.241,
      "eval_steps_per_second": 13.765,
      "step": 1680
    },
    {
      "epoch": 8.047732696897375,
      "grad_norm": 0.3318539261817932,
      "learning_rate": 0.0004988352746782895,
      "loss": 2.1437,
      "step": 1690
    },
    {
      "epoch": 8.095465393794749,
      "grad_norm": 0.23190522193908691,
      "learning_rate": 0.0004988169039155298,
      "loss": 2.1364,
      "step": 1700
    },
    {
      "epoch": 8.143198090692124,
      "grad_norm": 0.27130943536758423,
      "learning_rate": 0.000498798389750293,
      "loss": 2.1315,
      "step": 1710
    },
    {
      "epoch": 8.1909307875895,
      "grad_norm": 0.2545838952064514,
      "learning_rate": 0.0004987797321932493,
      "loss": 2.1344,
      "step": 1720
    },
    {
      "epoch": 8.238663484486873,
      "grad_norm": 0.22249163687229156,
      "learning_rate": 0.0004987609312551519,
      "loss": 2.1338,
      "step": 1730
    },
    {
      "epoch": 8.286396181384248,
      "grad_norm": 0.244005486369133,
      "learning_rate": 0.0004987419869468365,
      "loss": 2.1566,
      "step": 1740
    },
    {
      "epoch": 8.334128878281623,
      "grad_norm": 0.3140502870082855,
      "learning_rate": 0.0004987228992792213,
      "loss": 2.1522,
      "step": 1750
    },
    {
      "epoch": 8.381861575178998,
      "grad_norm": 0.25600719451904297,
      "learning_rate": 0.0004987036682633074,
      "loss": 2.1433,
      "step": 1760
    },
    {
      "epoch": 8.429594272076372,
      "grad_norm": 0.3139743208885193,
      "learning_rate": 0.0004986842939101781,
      "loss": 2.1487,
      "step": 1770
    },
    {
      "epoch": 8.477326968973747,
      "grad_norm": 0.22583937644958496,
      "learning_rate": 0.0004986647762309998,
      "loss": 2.1438,
      "step": 1780
    },
    {
      "epoch": 8.525059665871122,
      "grad_norm": 0.5365909934043884,
      "learning_rate": 0.0004986451152370212,
      "loss": 2.1386,
      "step": 1790
    },
    {
      "epoch": 8.572792362768496,
      "grad_norm": 0.2977139353752136,
      "learning_rate": 0.0004986253109395736,
      "loss": 2.115,
      "step": 1800
    },
    {
      "epoch": 8.620525059665871,
      "grad_norm": 0.24836136400699615,
      "learning_rate": 0.0004986053633500711,
      "loss": 2.1365,
      "step": 1810
    },
    {
      "epoch": 8.668257756563246,
      "grad_norm": 0.2672763466835022,
      "learning_rate": 0.0004985852724800101,
      "loss": 2.1249,
      "step": 1820
    },
    {
      "epoch": 8.71599045346062,
      "grad_norm": 0.28149867057800293,
      "learning_rate": 0.0004985650383409698,
      "loss": 2.1353,
      "step": 1830
    },
    {
      "epoch": 8.763723150357995,
      "grad_norm": 0.29404330253601074,
      "learning_rate": 0.0004985446609446118,
      "loss": 2.1369,
      "step": 1840
    },
    {
      "epoch": 8.81145584725537,
      "grad_norm": 0.3681953251361847,
      "learning_rate": 0.0004985241403026805,
      "loss": 2.1397,
      "step": 1850
    },
    {
      "epoch": 8.859188544152744,
      "grad_norm": 0.24731922149658203,
      "learning_rate": 0.0004985034764270025,
      "loss": 2.1177,
      "step": 1860
    },
    {
      "epoch": 8.906921241050119,
      "grad_norm": 0.2791517376899719,
      "learning_rate": 0.0004984826693294874,
      "loss": 2.1269,
      "step": 1870
    },
    {
      "epoch": 8.954653937947494,
      "grad_norm": 0.29756277799606323,
      "learning_rate": 0.0004984617190221268,
      "loss": 2.1169,
      "step": 1880
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.21121849119663239,
      "learning_rate": 0.0004984406255169957,
      "loss": 2.0217,
      "step": 1890
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.0922540426254272,
      "eval_runtime": 4.1874,
      "eval_samples_per_second": 3505.965,
      "eval_steps_per_second": 13.851,
      "step": 1890
    },
    {
      "epoch": 9.047732696897375,
      "grad_norm": 0.2655092775821686,
      "learning_rate": 0.0004984193888262504,
      "loss": 2.1337,
      "step": 1900
    },
    {
      "epoch": 9.095465393794749,
      "grad_norm": 0.2591720223426819,
      "learning_rate": 0.0004983980089621308,
      "loss": 2.1104,
      "step": 1910
    },
    {
      "epoch": 9.143198090692124,
      "grad_norm": 0.283412367105484,
      "learning_rate": 0.000498376485936959,
      "loss": 2.1103,
      "step": 1920
    },
    {
      "epoch": 9.1909307875895,
      "grad_norm": 0.25323617458343506,
      "learning_rate": 0.0004983548197631391,
      "loss": 2.1203,
      "step": 1930
    },
    {
      "epoch": 9.238663484486873,
      "grad_norm": 0.27150315046310425,
      "learning_rate": 0.0004983330104531585,
      "loss": 2.1122,
      "step": 1940
    },
    {
      "epoch": 9.286396181384248,
      "grad_norm": 0.32615312933921814,
      "learning_rate": 0.0004983110580195866,
      "loss": 2.133,
      "step": 1950
    },
    {
      "epoch": 9.334128878281623,
      "grad_norm": 0.2671658396720886,
      "learning_rate": 0.0004982889624750754,
      "loss": 2.1181,
      "step": 1960
    },
    {
      "epoch": 9.381861575178998,
      "grad_norm": 0.25402504205703735,
      "learning_rate": 0.0004982667238323594,
      "loss": 2.1274,
      "step": 1970
    },
    {
      "epoch": 9.429594272076372,
      "grad_norm": 0.25710391998291016,
      "learning_rate": 0.0004982443421042555,
      "loss": 2.1138,
      "step": 1980
    },
    {
      "epoch": 9.477326968973747,
      "grad_norm": 0.2747381627559662,
      "learning_rate": 0.0004982218173036632,
      "loss": 2.1206,
      "step": 1990
    },
    {
      "epoch": 9.525059665871122,
      "grad_norm": 0.3290383219718933,
      "learning_rate": 0.0004981991494435644,
      "loss": 2.1309,
      "step": 2000
    },
    {
      "epoch": 9.572792362768496,
      "grad_norm": 0.2922075092792511,
      "learning_rate": 0.0004981763385370234,
      "loss": 2.1157,
      "step": 2010
    },
    {
      "epoch": 9.620525059665871,
      "grad_norm": 0.2796359062194824,
      "learning_rate": 0.000498153384597187,
      "loss": 2.0979,
      "step": 2020
    },
    {
      "epoch": 9.668257756563246,
      "grad_norm": 0.24951115250587463,
      "learning_rate": 0.0004981302876372843,
      "loss": 2.121,
      "step": 2030
    },
    {
      "epoch": 9.71599045346062,
      "grad_norm": 0.2740353047847748,
      "learning_rate": 0.0004981070476706271,
      "loss": 2.1108,
      "step": 2040
    },
    {
      "epoch": 9.763723150357995,
      "grad_norm": 0.27409249544143677,
      "learning_rate": 0.0004980836647106093,
      "loss": 2.1029,
      "step": 2050
    },
    {
      "epoch": 9.81145584725537,
      "grad_norm": 0.2789916694164276,
      "learning_rate": 0.0004980601387707075,
      "loss": 2.1087,
      "step": 2060
    },
    {
      "epoch": 9.859188544152744,
      "grad_norm": 0.26736411452293396,
      "learning_rate": 0.0004980364698644808,
      "loss": 2.113,
      "step": 2070
    },
    {
      "epoch": 9.906921241050119,
      "grad_norm": 0.25551295280456543,
      "learning_rate": 0.0004980126580055698,
      "loss": 2.0975,
      "step": 2080
    },
    {
      "epoch": 9.954653937947494,
      "grad_norm": 0.25971683859825134,
      "learning_rate": 0.0004979887032076989,
      "loss": 2.115,
      "step": 2090
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.1967199295759201,
      "learning_rate": 0.0004979646054846736,
      "loss": 2.0097,
      "step": 2100
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.0897160768508911,
      "eval_runtime": 4.1885,
      "eval_samples_per_second": 3505.043,
      "eval_steps_per_second": 13.847,
      "step": 2100
    },
    {
      "epoch": 10.047732696897375,
      "grad_norm": 0.2833581566810608,
      "learning_rate": 0.0004979403648503826,
      "loss": 2.0999,
      "step": 2110
    },
    {
      "epoch": 10.095465393794749,
      "grad_norm": 0.27483808994293213,
      "learning_rate": 0.0004979159813187968,
      "loss": 2.113,
      "step": 2120
    },
    {
      "epoch": 10.143198090692124,
      "grad_norm": 0.2885165214538574,
      "learning_rate": 0.0004978914549039691,
      "loss": 2.1049,
      "step": 2130
    },
    {
      "epoch": 10.1909307875895,
      "grad_norm": 0.27970412373542786,
      "learning_rate": 0.000497866785620035,
      "loss": 2.1038,
      "step": 2140
    },
    {
      "epoch": 10.238663484486873,
      "grad_norm": 0.27601486444473267,
      "learning_rate": 0.0004978419734812123,
      "loss": 2.1152,
      "step": 2150
    },
    {
      "epoch": 10.286396181384248,
      "grad_norm": 0.3343854546546936,
      "learning_rate": 0.0004978170185018013,
      "loss": 2.0941,
      "step": 2160
    },
    {
      "epoch": 10.334128878281623,
      "grad_norm": 0.2733025848865509,
      "learning_rate": 0.0004977919206961845,
      "loss": 2.0849,
      "step": 2170
    },
    {
      "epoch": 10.381861575178998,
      "grad_norm": 0.2557155191898346,
      "learning_rate": 0.0004977666800788267,
      "loss": 2.1026,
      "step": 2180
    },
    {
      "epoch": 10.429594272076372,
      "grad_norm": 0.27316978573799133,
      "learning_rate": 0.0004977412966642749,
      "loss": 2.0837,
      "step": 2190
    },
    {
      "epoch": 10.477326968973747,
      "grad_norm": 0.2779415249824524,
      "learning_rate": 0.0004977157704671584,
      "loss": 2.1052,
      "step": 2200
    },
    {
      "epoch": 10.525059665871122,
      "grad_norm": 0.24965952336788177,
      "learning_rate": 0.0004976901015021892,
      "loss": 2.1028,
      "step": 2210
    },
    {
      "epoch": 10.572792362768496,
      "grad_norm": 0.30032220482826233,
      "learning_rate": 0.0004976642897841612,
      "loss": 2.0869,
      "step": 2220
    },
    {
      "epoch": 10.620525059665871,
      "grad_norm": 0.2675836980342865,
      "learning_rate": 0.0004976383353279505,
      "loss": 2.0999,
      "step": 2230
    },
    {
      "epoch": 10.668257756563246,
      "grad_norm": 0.2956569194793701,
      "learning_rate": 0.0004976122381485157,
      "loss": 2.0811,
      "step": 2240
    },
    {
      "epoch": 10.71599045346062,
      "grad_norm": 0.2905334532260895,
      "learning_rate": 0.0004975859982608977,
      "loss": 2.0987,
      "step": 2250
    },
    {
      "epoch": 10.763723150357995,
      "grad_norm": 0.25208383798599243,
      "learning_rate": 0.0004975596156802194,
      "loss": 2.0999,
      "step": 2260
    },
    {
      "epoch": 10.81145584725537,
      "grad_norm": 0.2944118082523346,
      "learning_rate": 0.0004975330904216861,
      "loss": 2.1159,
      "step": 2270
    },
    {
      "epoch": 10.859188544152744,
      "grad_norm": 0.31022217869758606,
      "learning_rate": 0.0004975064225005853,
      "loss": 2.1029,
      "step": 2280
    },
    {
      "epoch": 10.906921241050119,
      "grad_norm": 0.2793399393558502,
      "learning_rate": 0.0004974796119322867,
      "loss": 2.0917,
      "step": 2290
    },
    {
      "epoch": 10.954653937947494,
      "grad_norm": 0.3091522753238678,
      "learning_rate": 0.0004974526587322423,
      "loss": 2.0971,
      "step": 2300
    },
    {
      "epoch": 11.0,
      "grad_norm": 0.2363751381635666,
      "learning_rate": 0.0004974255629159861,
      "loss": 1.9965,
      "step": 2310
    },
    {
      "epoch": 11.0,
      "eval_loss": 1.0844241380691528,
      "eval_runtime": 4.4175,
      "eval_samples_per_second": 3323.383,
      "eval_steps_per_second": 13.13,
      "step": 2310
    },
    {
      "epoch": 11.047732696897375,
      "grad_norm": 0.353847861289978,
      "learning_rate": 0.0004973983244991346,
      "loss": 2.0795,
      "step": 2320
    },
    {
      "epoch": 11.095465393794749,
      "grad_norm": 0.2590043842792511,
      "learning_rate": 0.0004973709434973861,
      "loss": 2.0897,
      "step": 2330
    },
    {
      "epoch": 11.143198090692124,
      "grad_norm": 0.27996018528938293,
      "learning_rate": 0.0004973434199265215,
      "loss": 2.0865,
      "step": 2340
    },
    {
      "epoch": 11.1909307875895,
      "grad_norm": 0.5422293543815613,
      "learning_rate": 0.0004973157538024037,
      "loss": 2.0979,
      "step": 2350
    },
    {
      "epoch": 11.238663484486873,
      "grad_norm": 0.30538028478622437,
      "learning_rate": 0.0004972879451409774,
      "loss": 2.0929,
      "step": 2360
    },
    {
      "epoch": 11.286396181384248,
      "grad_norm": 0.3023416996002197,
      "learning_rate": 0.0004972599939582702,
      "loss": 2.0933,
      "step": 2370
    },
    {
      "epoch": 11.334128878281623,
      "grad_norm": 0.3131187856197357,
      "learning_rate": 0.0004972319002703911,
      "loss": 2.0908,
      "step": 2380
    },
    {
      "epoch": 11.381861575178998,
      "grad_norm": 0.315562903881073,
      "learning_rate": 0.0004972036640935316,
      "loss": 2.0816,
      "step": 2390
    },
    {
      "epoch": 11.429594272076372,
      "grad_norm": 0.30116188526153564,
      "learning_rate": 0.0004971752854439653,
      "loss": 2.0919,
      "step": 2400
    },
    {
      "epoch": 11.477326968973747,
      "grad_norm": 0.26826179027557373,
      "learning_rate": 0.0004971467643380479,
      "loss": 2.0827,
      "step": 2410
    },
    {
      "epoch": 11.525059665871122,
      "grad_norm": 0.29218724370002747,
      "learning_rate": 0.0004971181007922171,
      "loss": 2.095,
      "step": 2420
    },
    {
      "epoch": 11.572792362768496,
      "grad_norm": 0.30202358961105347,
      "learning_rate": 0.0004970892948229928,
      "loss": 2.0903,
      "step": 2430
    },
    {
      "epoch": 11.620525059665871,
      "grad_norm": 0.2962397336959839,
      "learning_rate": 0.000497060346446977,
      "loss": 2.081,
      "step": 2440
    },
    {
      "epoch": 11.668257756563246,
      "grad_norm": 0.2723020911216736,
      "learning_rate": 0.0004970312556808539,
      "loss": 2.0694,
      "step": 2450
    },
    {
      "epoch": 11.71599045346062,
      "grad_norm": 0.26237428188323975,
      "learning_rate": 0.0004970020225413892,
      "loss": 2.0784,
      "step": 2460
    },
    {
      "epoch": 11.763723150357995,
      "grad_norm": 0.30283284187316895,
      "learning_rate": 0.0004969726470454314,
      "loss": 2.0841,
      "step": 2470
    },
    {
      "epoch": 11.81145584725537,
      "grad_norm": 0.31111469864845276,
      "learning_rate": 0.0004969431292099104,
      "loss": 2.0854,
      "step": 2480
    },
    {
      "epoch": 11.859188544152744,
      "grad_norm": 0.2769571840763092,
      "learning_rate": 0.0004969134690518386,
      "loss": 2.0853,
      "step": 2490
    },
    {
      "epoch": 11.906921241050119,
      "grad_norm": 0.2844129800796509,
      "learning_rate": 0.0004968836665883103,
      "loss": 2.0804,
      "step": 2500
    },
    {
      "epoch": 11.954653937947494,
      "grad_norm": 0.3162038028240204,
      "learning_rate": 0.0004968537218365017,
      "loss": 2.0702,
      "step": 2510
    },
    {
      "epoch": 12.0,
      "grad_norm": 0.22351780533790588,
      "learning_rate": 0.000496823634813671,
      "loss": 1.9775,
      "step": 2520
    },
    {
      "epoch": 12.0,
      "eval_loss": 1.0787827968597412,
      "eval_runtime": 4.2255,
      "eval_samples_per_second": 3474.358,
      "eval_steps_per_second": 13.726,
      "step": 2520
    },
    {
      "epoch": 12.047732696897375,
      "grad_norm": 0.28940603137016296,
      "learning_rate": 0.0004967934055371587,
      "loss": 2.0742,
      "step": 2530
    },
    {
      "epoch": 12.095465393794749,
      "grad_norm": 0.29665878415107727,
      "learning_rate": 0.0004967630340243869,
      "loss": 2.0826,
      "step": 2540
    },
    {
      "epoch": 12.143198090692124,
      "grad_norm": 0.2989829182624817,
      "learning_rate": 0.0004967325202928598,
      "loss": 2.0715,
      "step": 2550
    },
    {
      "epoch": 12.1909307875895,
      "grad_norm": 0.2928704023361206,
      "learning_rate": 0.0004967018643601637,
      "loss": 2.0781,
      "step": 2560
    },
    {
      "epoch": 12.238663484486873,
      "grad_norm": 0.32519859075546265,
      "learning_rate": 0.0004966710662439669,
      "loss": 2.0904,
      "step": 2570
    },
    {
      "epoch": 12.286396181384248,
      "grad_norm": 0.3368043005466461,
      "learning_rate": 0.0004966401259620192,
      "loss": 2.0823,
      "step": 2580
    },
    {
      "epoch": 12.334128878281623,
      "grad_norm": 0.2950943410396576,
      "learning_rate": 0.0004966090435321527,
      "loss": 2.0772,
      "step": 2590
    },
    {
      "epoch": 12.381861575178998,
      "grad_norm": 0.3001510202884674,
      "learning_rate": 0.0004965778189722815,
      "loss": 2.0621,
      "step": 2600
    },
    {
      "epoch": 12.429594272076372,
      "grad_norm": 0.2747657001018524,
      "learning_rate": 0.0004965464523004014,
      "loss": 2.0694,
      "step": 2610
    },
    {
      "epoch": 12.477326968973747,
      "grad_norm": 0.3082585036754608,
      "learning_rate": 0.0004965149435345902,
      "loss": 2.0676,
      "step": 2620
    },
    {
      "epoch": 12.525059665871122,
      "grad_norm": 0.29042693972587585,
      "learning_rate": 0.0004964832926930077,
      "loss": 2.0724,
      "step": 2630
    },
    {
      "epoch": 12.572792362768496,
      "grad_norm": 0.2823672294616699,
      "learning_rate": 0.0004964514997938951,
      "loss": 2.0754,
      "step": 2640
    },
    {
      "epoch": 12.620525059665871,
      "grad_norm": 0.33565017580986023,
      "learning_rate": 0.0004964195648555763,
      "loss": 2.0704,
      "step": 2650
    },
    {
      "epoch": 12.668257756563246,
      "grad_norm": 0.34747645258903503,
      "learning_rate": 0.0004963874878964562,
      "loss": 2.0709,
      "step": 2660
    },
    {
      "epoch": 12.71599045346062,
      "grad_norm": 0.28284281492233276,
      "learning_rate": 0.0004963552689350223,
      "loss": 2.0599,
      "step": 2670
    },
    {
      "epoch": 12.763723150357995,
      "grad_norm": 0.32058799266815186,
      "learning_rate": 0.0004963229079898435,
      "loss": 2.0792,
      "step": 2680
    },
    {
      "epoch": 12.81145584725537,
      "grad_norm": 0.32602760195732117,
      "learning_rate": 0.0004962904050795704,
      "loss": 2.0783,
      "step": 2690
    },
    {
      "epoch": 12.859188544152744,
      "grad_norm": 0.28743621706962585,
      "learning_rate": 0.0004962577602229358,
      "loss": 2.0854,
      "step": 2700
    },
    {
      "epoch": 12.906921241050119,
      "grad_norm": 0.31603431701660156,
      "learning_rate": 0.000496224973438754,
      "loss": 2.0597,
      "step": 2710
    },
    {
      "epoch": 12.954653937947494,
      "grad_norm": 0.35698145627975464,
      "learning_rate": 0.0004961920447459216,
      "loss": 2.0747,
      "step": 2720
    },
    {
      "epoch": 13.0,
      "grad_norm": 0.21778149902820587,
      "learning_rate": 0.0004961589741634163,
      "loss": 1.9514,
      "step": 2730
    },
    {
      "epoch": 13.0,
      "eval_loss": 1.079858660697937,
      "eval_runtime": 4.5619,
      "eval_samples_per_second": 3218.191,
      "eval_steps_per_second": 12.714,
      "step": 2730
    },
    {
      "epoch": 13.047732696897375,
      "grad_norm": 0.33357638120651245,
      "learning_rate": 0.0004961257617102981,
      "loss": 2.0727,
      "step": 2740
    },
    {
      "epoch": 13.095465393794749,
      "grad_norm": 0.34069669246673584,
      "learning_rate": 0.0004960924074057084,
      "loss": 2.069,
      "step": 2750
    },
    {
      "epoch": 13.143198090692124,
      "grad_norm": 0.3200088143348694,
      "learning_rate": 0.0004960589112688707,
      "loss": 2.0846,
      "step": 2760
    },
    {
      "epoch": 13.1909307875895,
      "grad_norm": 0.3024740517139435,
      "learning_rate": 0.00049602527331909,
      "loss": 2.0608,
      "step": 2770
    },
    {
      "epoch": 13.238663484486873,
      "grad_norm": 0.34852004051208496,
      "learning_rate": 0.0004959914935757532,
      "loss": 2.0655,
      "step": 2780
    },
    {
      "epoch": 13.286396181384248,
      "grad_norm": 0.32559725642204285,
      "learning_rate": 0.0004959575720583287,
      "loss": 2.0638,
      "step": 2790
    },
    {
      "epoch": 13.334128878281623,
      "grad_norm": 0.3030804395675659,
      "learning_rate": 0.0004959235087863668,
      "loss": 2.0676,
      "step": 2800
    },
    {
      "epoch": 13.381861575178998,
      "grad_norm": 0.3463856279850006,
      "learning_rate": 0.0004958893037794994,
      "loss": 2.0664,
      "step": 2810
    },
    {
      "epoch": 13.429594272076372,
      "grad_norm": 0.2866534888744354,
      "learning_rate": 0.0004958549570574401,
      "loss": 2.064,
      "step": 2820
    },
    {
      "epoch": 13.477326968973747,
      "grad_norm": 0.29402634501457214,
      "learning_rate": 0.0004958204686399844,
      "loss": 2.059,
      "step": 2830
    },
    {
      "epoch": 13.525059665871122,
      "grad_norm": 0.3951232433319092,
      "learning_rate": 0.000495785838547009,
      "loss": 2.068,
      "step": 2840
    },
    {
      "epoch": 13.572792362768496,
      "grad_norm": 0.40250644087791443,
      "learning_rate": 0.0004957510667984726,
      "loss": 2.0544,
      "step": 2850
    },
    {
      "epoch": 13.620525059665871,
      "grad_norm": 0.2941347062587738,
      "learning_rate": 0.0004957161534144156,
      "loss": 2.0743,
      "step": 2860
    },
    {
      "epoch": 13.668257756563246,
      "grad_norm": 0.334502637386322,
      "learning_rate": 0.0004956810984149597,
      "loss": 2.0646,
      "step": 2870
    },
    {
      "epoch": 13.71599045346062,
      "grad_norm": 0.33360663056373596,
      "learning_rate": 0.0004956459018203085,
      "loss": 2.0507,
      "step": 2880
    },
    {
      "epoch": 13.763723150357995,
      "grad_norm": 0.3014518618583679,
      "learning_rate": 0.000495610563650747,
      "loss": 2.0641,
      "step": 2890
    },
    {
      "epoch": 13.81145584725537,
      "grad_norm": 0.3294133245944977,
      "learning_rate": 0.0004955750839266421,
      "loss": 2.0575,
      "step": 2900
    },
    {
      "epoch": 13.859188544152744,
      "grad_norm": 0.2938583493232727,
      "learning_rate": 0.0004955394626684419,
      "loss": 2.0618,
      "step": 2910
    },
    {
      "epoch": 13.906921241050119,
      "grad_norm": 0.30071571469306946,
      "learning_rate": 0.0004955036998966764,
      "loss": 2.0637,
      "step": 2920
    },
    {
      "epoch": 13.954653937947494,
      "grad_norm": 0.3258448541164398,
      "learning_rate": 0.000495467795631957,
      "loss": 2.0597,
      "step": 2930
    },
    {
      "epoch": 14.0,
      "grad_norm": 0.2406139075756073,
      "learning_rate": 0.0004954317498949766,
      "loss": 1.9554,
      "step": 2940
    },
    {
      "epoch": 14.0,
      "eval_loss": 1.0763670206069946,
      "eval_runtime": 4.5899,
      "eval_samples_per_second": 3198.563,
      "eval_steps_per_second": 12.637,
      "step": 2940
    },
    {
      "epoch": 14.047732696897375,
      "grad_norm": 0.30461347103118896,
      "learning_rate": 0.0004953955627065098,
      "loss": 2.0565,
      "step": 2950
    },
    {
      "epoch": 14.095465393794749,
      "grad_norm": 0.2900533676147461,
      "learning_rate": 0.0004953592340874124,
      "loss": 2.0574,
      "step": 2960
    },
    {
      "epoch": 14.143198090692124,
      "grad_norm": 0.32979243993759155,
      "learning_rate": 0.0004953227640586223,
      "loss": 2.058,
      "step": 2970
    },
    {
      "epoch": 14.1909307875895,
      "grad_norm": 0.31347453594207764,
      "learning_rate": 0.0004952861526411582,
      "loss": 2.0517,
      "step": 2980
    },
    {
      "epoch": 14.238663484486873,
      "grad_norm": 0.2710130214691162,
      "learning_rate": 0.000495249399856121,
      "loss": 2.0619,
      "step": 2990
    },
    {
      "epoch": 14.286396181384248,
      "grad_norm": 0.3279511332511902,
      "learning_rate": 0.0004952125057246923,
      "loss": 2.0662,
      "step": 3000
    },
    {
      "epoch": 14.334128878281623,
      "grad_norm": 0.29269635677337646,
      "learning_rate": 0.0004951754702681359,
      "loss": 2.0379,
      "step": 3010
    },
    {
      "epoch": 14.381861575178998,
      "grad_norm": 0.31466034054756165,
      "learning_rate": 0.0004951382935077965,
      "loss": 2.0528,
      "step": 3020
    },
    {
      "epoch": 14.429594272076372,
      "grad_norm": 0.2921893894672394,
      "learning_rate": 0.0004951009754651005,
      "loss": 2.0642,
      "step": 3030
    },
    {
      "epoch": 14.477326968973747,
      "grad_norm": 0.29937490820884705,
      "learning_rate": 0.0004950635161615557,
      "loss": 2.0659,
      "step": 3040
    },
    {
      "epoch": 14.525059665871122,
      "grad_norm": 0.2988585829734802,
      "learning_rate": 0.0004950259156187513,
      "loss": 2.0392,
      "step": 3050
    },
    {
      "epoch": 14.572792362768496,
      "grad_norm": 0.3551545739173889,
      "learning_rate": 0.000494988173858358,
      "loss": 2.0379,
      "step": 3060
    },
    {
      "epoch": 14.620525059665871,
      "grad_norm": 0.34536877274513245,
      "learning_rate": 0.0004949502909021276,
      "loss": 2.0609,
      "step": 3070
    },
    {
      "epoch": 14.668257756563246,
      "grad_norm": 0.2973182797431946,
      "learning_rate": 0.0004949122667718934,
      "loss": 2.0568,
      "step": 3080
    },
    {
      "epoch": 14.71599045346062,
      "grad_norm": 0.28881120681762695,
      "learning_rate": 0.0004948741014895705,
      "loss": 2.0538,
      "step": 3090
    },
    {
      "epoch": 14.763723150357995,
      "grad_norm": 0.31242460012435913,
      "learning_rate": 0.0004948357950771547,
      "loss": 2.0488,
      "step": 3100
    },
    {
      "epoch": 14.81145584725537,
      "grad_norm": 0.3026752769947052,
      "learning_rate": 0.0004947973475567235,
      "loss": 2.0534,
      "step": 3110
    },
    {
      "epoch": 14.859188544152744,
      "grad_norm": 0.31304165720939636,
      "learning_rate": 0.0004947587589504356,
      "loss": 2.064,
      "step": 3120
    },
    {
      "epoch": 14.906921241050119,
      "grad_norm": 0.26716330647468567,
      "learning_rate": 0.0004947200292805309,
      "loss": 2.0474,
      "step": 3130
    },
    {
      "epoch": 14.954653937947494,
      "grad_norm": 0.318486750125885,
      "learning_rate": 0.0004946811585693311,
      "loss": 2.0544,
      "step": 3140
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.24824164807796478,
      "learning_rate": 0.0004946421468392387,
      "loss": 1.9603,
      "step": 3150
    },
    {
      "epoch": 15.0,
      "eval_loss": 1.0734024047851562,
      "eval_runtime": 4.4138,
      "eval_samples_per_second": 3326.187,
      "eval_steps_per_second": 13.141,
      "step": 3150
    },
    {
      "epoch": 15.047732696897375,
      "grad_norm": 0.2916032373905182,
      "learning_rate": 0.0004946029941127375,
      "loss": 2.0523,
      "step": 3160
    },
    {
      "epoch": 15.095465393794749,
      "grad_norm": 0.3099236488342285,
      "learning_rate": 0.0004945637004123927,
      "loss": 2.0424,
      "step": 3170
    },
    {
      "epoch": 15.143198090692124,
      "grad_norm": 0.3159181773662567,
      "learning_rate": 0.0004945242657608509,
      "loss": 2.0532,
      "step": 3180
    },
    {
      "epoch": 15.1909307875895,
      "grad_norm": 0.30141645669937134,
      "learning_rate": 0.0004944846901808397,
      "loss": 2.0557,
      "step": 3190
    },
    {
      "epoch": 15.238663484486873,
      "grad_norm": 0.2966237962245941,
      "learning_rate": 0.0004944449736951678,
      "loss": 2.0347,
      "step": 3200
    },
    {
      "epoch": 15.286396181384248,
      "grad_norm": 0.3205042779445648,
      "learning_rate": 0.0004944051163267254,
      "loss": 2.0552,
      "step": 3210
    },
    {
      "epoch": 15.334128878281623,
      "grad_norm": 0.33853065967559814,
      "learning_rate": 0.000494365118098484,
      "loss": 2.0482,
      "step": 3220
    },
    {
      "epoch": 15.381861575178998,
      "grad_norm": 0.3688315749168396,
      "learning_rate": 0.0004943249790334959,
      "loss": 2.0479,
      "step": 3230
    },
    {
      "epoch": 15.429594272076372,
      "grad_norm": 0.3945794999599457,
      "learning_rate": 0.0004942846991548946,
      "loss": 2.0349,
      "step": 3240
    },
    {
      "epoch": 15.477326968973747,
      "grad_norm": 0.29798424243927,
      "learning_rate": 0.0004942442784858951,
      "loss": 2.0622,
      "step": 3250
    },
    {
      "epoch": 15.525059665871122,
      "grad_norm": 0.3095040023326874,
      "learning_rate": 0.0004942037170497933,
      "loss": 2.0391,
      "step": 3260
    },
    {
      "epoch": 15.572792362768496,
      "grad_norm": 0.35143280029296875,
      "learning_rate": 0.0004941630148699662,
      "loss": 2.0322,
      "step": 3270
    },
    {
      "epoch": 15.620525059665871,
      "grad_norm": 0.3160543739795685,
      "learning_rate": 0.000494122171969872,
      "loss": 2.0605,
      "step": 3280
    },
    {
      "epoch": 15.668257756563246,
      "grad_norm": 0.3080327808856964,
      "learning_rate": 0.0004940811883730501,
      "loss": 2.0526,
      "step": 3290
    },
    {
      "epoch": 15.71599045346062,
      "grad_norm": 0.2948169708251953,
      "learning_rate": 0.0004940400641031208,
      "loss": 2.0474,
      "step": 3300
    },
    {
      "epoch": 15.763723150357995,
      "grad_norm": 0.3301815986633301,
      "learning_rate": 0.0004939987991837855,
      "loss": 2.0562,
      "step": 3310
    },
    {
      "epoch": 15.81145584725537,
      "grad_norm": 0.31588053703308105,
      "learning_rate": 0.0004939573936388269,
      "loss": 2.0431,
      "step": 3320
    },
    {
      "epoch": 15.859188544152744,
      "grad_norm": 0.27199822664260864,
      "learning_rate": 0.0004939158474921084,
      "loss": 2.0305,
      "step": 3330
    },
    {
      "epoch": 15.906921241050119,
      "grad_norm": 0.338651180267334,
      "learning_rate": 0.0004938741607675745,
      "loss": 2.0396,
      "step": 3340
    },
    {
      "epoch": 15.954653937947494,
      "grad_norm": 0.2970816195011139,
      "learning_rate": 0.0004938323334892511,
      "loss": 2.0516,
      "step": 3350
    },
    {
      "epoch": 16.0,
      "grad_norm": 0.25694289803504944,
      "learning_rate": 0.0004937903656812445,
      "loss": 1.9412,
      "step": 3360
    },
    {
      "epoch": 16.0,
      "eval_loss": 1.0722682476043701,
      "eval_runtime": 4.3708,
      "eval_samples_per_second": 3358.851,
      "eval_steps_per_second": 13.27,
      "step": 3360
    },
    {
      "epoch": 16.047732696897373,
      "grad_norm": 0.3375014662742615,
      "learning_rate": 0.0004937482573677427,
      "loss": 2.0359,
      "step": 3370
    },
    {
      "epoch": 16.09546539379475,
      "grad_norm": 0.3032914996147156,
      "learning_rate": 0.000493706008573014,
      "loss": 2.0246,
      "step": 3380
    },
    {
      "epoch": 16.143198090692124,
      "grad_norm": 0.30231231451034546,
      "learning_rate": 0.000493663619321408,
      "loss": 2.0384,
      "step": 3390
    },
    {
      "epoch": 16.190930787589497,
      "grad_norm": 0.3158394992351532,
      "learning_rate": 0.0004936210896373553,
      "loss": 2.0529,
      "step": 3400
    },
    {
      "epoch": 16.238663484486874,
      "grad_norm": 0.3593074381351471,
      "learning_rate": 0.0004935784195453674,
      "loss": 2.0527,
      "step": 3410
    },
    {
      "epoch": 16.286396181384248,
      "grad_norm": 0.32267147302627563,
      "learning_rate": 0.0004935356090700363,
      "loss": 2.0376,
      "step": 3420
    },
    {
      "epoch": 16.33412887828162,
      "grad_norm": 0.4091903269290924,
      "learning_rate": 0.0004934926582360357,
      "loss": 2.0303,
      "step": 3430
    },
    {
      "epoch": 16.381861575179,
      "grad_norm": 0.3440397083759308,
      "learning_rate": 0.0004934495670681195,
      "loss": 2.0425,
      "step": 3440
    },
    {
      "epoch": 16.429594272076372,
      "grad_norm": 0.30453404784202576,
      "learning_rate": 0.000493406335591123,
      "loss": 2.0527,
      "step": 3450
    },
    {
      "epoch": 16.477326968973745,
      "grad_norm": 0.3262629806995392,
      "learning_rate": 0.0004933629638299619,
      "loss": 2.0359,
      "step": 3460
    },
    {
      "epoch": 16.525059665871122,
      "grad_norm": 0.27785056829452515,
      "learning_rate": 0.0004933194518096331,
      "loss": 2.0241,
      "step": 3470
    },
    {
      "epoch": 16.572792362768496,
      "grad_norm": 0.3582846522331238,
      "learning_rate": 0.0004932757995552141,
      "loss": 2.0383,
      "step": 3480
    },
    {
      "epoch": 16.620525059665873,
      "grad_norm": 0.2992042005062103,
      "learning_rate": 0.0004932320070918634,
      "loss": 2.0423,
      "step": 3490
    },
    {
      "epoch": 16.668257756563246,
      "grad_norm": 0.3286915123462677,
      "learning_rate": 0.0004931880744448201,
      "loss": 2.0627,
      "step": 3500
    },
    {
      "epoch": 16.71599045346062,
      "grad_norm": 0.3218488395214081,
      "learning_rate": 0.0004931440016394045,
      "loss": 2.0382,
      "step": 3510
    },
    {
      "epoch": 16.763723150357997,
      "grad_norm": 0.3271619975566864,
      "learning_rate": 0.000493099788701017,
      "loss": 2.0395,
      "step": 3520
    },
    {
      "epoch": 16.81145584725537,
      "grad_norm": 0.34373921155929565,
      "learning_rate": 0.0004930554356551395,
      "loss": 2.0381,
      "step": 3530
    },
    {
      "epoch": 16.859188544152744,
      "grad_norm": 0.39162957668304443,
      "learning_rate": 0.0004930109425273344,
      "loss": 2.0368,
      "step": 3540
    },
    {
      "epoch": 16.90692124105012,
      "grad_norm": 0.3399108648300171,
      "learning_rate": 0.0004929663093432443,
      "loss": 2.0316,
      "step": 3550
    },
    {
      "epoch": 16.954653937947494,
      "grad_norm": 0.29926449060440063,
      "learning_rate": 0.0004929215361285935,
      "loss": 2.0507,
      "step": 3560
    },
    {
      "epoch": 17.0,
      "grad_norm": 0.22651071846485138,
      "learning_rate": 0.000492876622909186,
      "loss": 1.9252,
      "step": 3570
    },
    {
      "epoch": 17.0,
      "eval_loss": 1.0722540616989136,
      "eval_runtime": 4.4095,
      "eval_samples_per_second": 3329.368,
      "eval_steps_per_second": 13.153,
      "step": 3570
    },
    {
      "epoch": 17.047732696897373,
      "grad_norm": 0.346622496843338,
      "learning_rate": 0.0004928315697109072,
      "loss": 2.0227,
      "step": 3580
    },
    {
      "epoch": 17.09546539379475,
      "grad_norm": 0.3126860558986664,
      "learning_rate": 0.000492786376559723,
      "loss": 2.023,
      "step": 3590
    },
    {
      "epoch": 17.143198090692124,
      "grad_norm": 0.3597099184989929,
      "learning_rate": 0.0004927410434816798,
      "loss": 2.0313,
      "step": 3600
    },
    {
      "epoch": 17.190930787589497,
      "grad_norm": 0.4655027985572815,
      "learning_rate": 0.0004926955705029048,
      "loss": 2.0365,
      "step": 3610
    },
    {
      "epoch": 17.238663484486874,
      "grad_norm": 0.33827173709869385,
      "learning_rate": 0.0004926499576496057,
      "loss": 2.0326,
      "step": 3620
    },
    {
      "epoch": 17.286396181384248,
      "grad_norm": 0.3673020005226135,
      "learning_rate": 0.000492604204948071,
      "loss": 2.0536,
      "step": 3630
    },
    {
      "epoch": 17.33412887828162,
      "grad_norm": 0.3488663136959076,
      "learning_rate": 0.0004925583124246696,
      "loss": 2.0338,
      "step": 3640
    },
    {
      "epoch": 17.381861575179,
      "grad_norm": 0.3532848358154297,
      "learning_rate": 0.0004925122801058511,
      "loss": 2.024,
      "step": 3650
    },
    {
      "epoch": 17.429594272076372,
      "grad_norm": 0.33669620752334595,
      "learning_rate": 0.0004924661080181457,
      "loss": 2.0391,
      "step": 3660
    },
    {
      "epoch": 17.477326968973745,
      "grad_norm": 0.3142904043197632,
      "learning_rate": 0.000492419796188164,
      "loss": 2.0376,
      "step": 3670
    },
    {
      "epoch": 17.525059665871122,
      "grad_norm": 0.32772618532180786,
      "learning_rate": 0.0004923733446425973,
      "loss": 2.0352,
      "step": 3680
    },
    {
      "epoch": 17.572792362768496,
      "grad_norm": 0.3552709221839905,
      "learning_rate": 0.0004923267534082174,
      "loss": 2.0395,
      "step": 3690
    },
    {
      "epoch": 17.620525059665873,
      "grad_norm": 0.36271947622299194,
      "learning_rate": 0.0004922800225118765,
      "loss": 2.028,
      "step": 3700
    },
    {
      "epoch": 17.668257756563246,
      "grad_norm": 0.33552736043930054,
      "learning_rate": 0.0004922331519805073,
      "loss": 2.0344,
      "step": 3710
    },
    {
      "epoch": 17.71599045346062,
      "grad_norm": 0.3430877923965454,
      "learning_rate": 0.0004921861418411232,
      "loss": 2.0213,
      "step": 3720
    },
    {
      "epoch": 17.763723150357997,
      "grad_norm": 0.3497520983219147,
      "learning_rate": 0.0004921389921208177,
      "loss": 2.0344,
      "step": 3730
    },
    {
      "epoch": 17.81145584725537,
      "grad_norm": 0.3248749077320099,
      "learning_rate": 0.0004920917028467652,
      "loss": 2.0418,
      "step": 3740
    },
    {
      "epoch": 17.859188544152744,
      "grad_norm": 0.33127954602241516,
      "learning_rate": 0.0004920442740462201,
      "loss": 2.0417,
      "step": 3750
    },
    {
      "epoch": 17.90692124105012,
      "grad_norm": 0.3266010284423828,
      "learning_rate": 0.0004919967057465174,
      "loss": 2.0337,
      "step": 3760
    },
    {
      "epoch": 17.954653937947494,
      "grad_norm": 0.3120409846305847,
      "learning_rate": 0.0004919489979750726,
      "loss": 2.0346,
      "step": 3770
    },
    {
      "epoch": 18.0,
      "grad_norm": 0.2821260988712311,
      "learning_rate": 0.0004919011507593812,
      "loss": 1.9326,
      "step": 3780
    },
    {
      "epoch": 18.0,
      "eval_loss": 1.068289875984192,
      "eval_runtime": 4.3705,
      "eval_samples_per_second": 3359.126,
      "eval_steps_per_second": 13.271,
      "step": 3780
    },
    {
      "epoch": 18.047732696897373,
      "grad_norm": 0.3528023660182953,
      "learning_rate": 0.0004918531641270197,
      "loss": 2.0094,
      "step": 3790
    },
    {
      "epoch": 18.09546539379475,
      "grad_norm": 0.3918580114841461,
      "learning_rate": 0.0004918050381056444,
      "loss": 2.0295,
      "step": 3800
    },
    {
      "epoch": 18.143198090692124,
      "grad_norm": 0.3610546886920929,
      "learning_rate": 0.000491756772722992,
      "loss": 2.0256,
      "step": 3810
    },
    {
      "epoch": 18.190930787589497,
      "grad_norm": 0.36460140347480774,
      "learning_rate": 0.00049170836800688,
      "loss": 2.0202,
      "step": 3820
    },
    {
      "epoch": 18.238663484486874,
      "grad_norm": 0.31703877449035645,
      "learning_rate": 0.0004916598239852055,
      "loss": 2.0376,
      "step": 3830
    },
    {
      "epoch": 18.286396181384248,
      "grad_norm": 0.37359464168548584,
      "learning_rate": 0.0004916111406859463,
      "loss": 2.0186,
      "step": 3840
    },
    {
      "epoch": 18.33412887828162,
      "grad_norm": 0.3197270631790161,
      "learning_rate": 0.0004915623181371605,
      "loss": 2.0311,
      "step": 3850
    },
    {
      "epoch": 18.381861575179,
      "grad_norm": 0.346571147441864,
      "learning_rate": 0.0004915133563669863,
      "loss": 2.0305,
      "step": 3860
    },
    {
      "epoch": 18.429594272076372,
      "grad_norm": 0.37356847524642944,
      "learning_rate": 0.0004914642554036424,
      "loss": 2.0194,
      "step": 3870
    },
    {
      "epoch": 18.477326968973745,
      "grad_norm": 0.33142659068107605,
      "learning_rate": 0.0004914150152754272,
      "loss": 2.0332,
      "step": 3880
    },
    {
      "epoch": 18.525059665871122,
      "grad_norm": 0.3204745650291443,
      "learning_rate": 0.0004913656360107197,
      "loss": 2.0289,
      "step": 3890
    },
    {
      "epoch": 18.572792362768496,
      "grad_norm": 0.3402104079723358,
      "learning_rate": 0.0004913161176379792,
      "loss": 2.0275,
      "step": 3900
    },
    {
      "epoch": 18.620525059665873,
      "grad_norm": 0.34137988090515137,
      "learning_rate": 0.0004912664601857448,
      "loss": 2.0257,
      "step": 3910
    },
    {
      "epoch": 18.668257756563246,
      "grad_norm": 0.3288652300834656,
      "learning_rate": 0.000491216663682636,
      "loss": 2.0242,
      "step": 3920
    },
    {
      "epoch": 18.71599045346062,
      "grad_norm": 0.44872406125068665,
      "learning_rate": 0.0004911667281573526,
      "loss": 2.029,
      "step": 3930
    },
    {
      "epoch": 18.763723150357997,
      "grad_norm": 0.4225165545940399,
      "learning_rate": 0.0004911166536386739,
      "loss": 2.0363,
      "step": 3940
    },
    {
      "epoch": 18.81145584725537,
      "grad_norm": 0.30292320251464844,
      "learning_rate": 0.00049106644015546,
      "loss": 2.0377,
      "step": 3950
    },
    {
      "epoch": 18.859188544152744,
      "grad_norm": 0.32818758487701416,
      "learning_rate": 0.0004910160877366507,
      "loss": 2.0427,
      "step": 3960
    },
    {
      "epoch": 18.90692124105012,
      "grad_norm": 0.30612778663635254,
      "learning_rate": 0.000490965596411266,
      "loss": 2.0378,
      "step": 3970
    },
    {
      "epoch": 18.954653937947494,
      "grad_norm": 0.29409468173980713,
      "learning_rate": 0.0004909149662084059,
      "loss": 2.0225,
      "step": 3980
    },
    {
      "epoch": 19.0,
      "grad_norm": 0.23406356573104858,
      "learning_rate": 0.0004908641971572506,
      "loss": 1.9337,
      "step": 3990
    },
    {
      "epoch": 19.0,
      "eval_loss": 1.0652265548706055,
      "eval_runtime": 4.3864,
      "eval_samples_per_second": 3346.91,
      "eval_steps_per_second": 13.223,
      "step": 3990
    },
    {
      "epoch": 19.047732696897373,
      "grad_norm": 0.3247121572494507,
      "learning_rate": 0.0004908132892870601,
      "loss": 2.0197,
      "step": 4000
    },
    {
      "epoch": 19.09546539379475,
      "grad_norm": 0.3190862834453583,
      "learning_rate": 0.0004907622426271746,
      "loss": 2.011,
      "step": 4010
    },
    {
      "epoch": 19.143198090692124,
      "grad_norm": 0.35648319125175476,
      "learning_rate": 0.000490711057207014,
      "loss": 2.0245,
      "step": 4020
    },
    {
      "epoch": 19.190930787589497,
      "grad_norm": 0.316729336977005,
      "learning_rate": 0.0004906597330560787,
      "loss": 2.0307,
      "step": 4030
    },
    {
      "epoch": 19.238663484486874,
      "grad_norm": 0.4070347845554352,
      "learning_rate": 0.0004906082702039484,
      "loss": 2.005,
      "step": 4040
    },
    {
      "epoch": 19.286396181384248,
      "grad_norm": 0.3257354497909546,
      "learning_rate": 0.0004905566686802832,
      "loss": 2.0395,
      "step": 4050
    },
    {
      "epoch": 19.33412887828162,
      "grad_norm": 0.3200022280216217,
      "learning_rate": 0.0004905049285148229,
      "loss": 2.0192,
      "step": 4060
    },
    {
      "epoch": 19.381861575179,
      "grad_norm": 0.3962157666683197,
      "learning_rate": 0.0004904530497373875,
      "loss": 2.0173,
      "step": 4070
    },
    {
      "epoch": 19.429594272076372,
      "grad_norm": 0.3876560628414154,
      "learning_rate": 0.0004904010323778764,
      "loss": 2.0208,
      "step": 4080
    },
    {
      "epoch": 19.477326968973745,
      "grad_norm": 0.3375721573829651,
      "learning_rate": 0.0004903488764662694,
      "loss": 2.0196,
      "step": 4090
    },
    {
      "epoch": 19.525059665871122,
      "grad_norm": 0.36962178349494934,
      "learning_rate": 0.0004902965820326257,
      "loss": 2.0137,
      "step": 4100
    },
    {
      "epoch": 19.572792362768496,
      "grad_norm": 0.3638036251068115,
      "learning_rate": 0.0004902441491070847,
      "loss": 2.0331,
      "step": 4110
    },
    {
      "epoch": 19.620525059665873,
      "grad_norm": 0.3650885224342346,
      "learning_rate": 0.0004901915777198654,
      "loss": 2.0196,
      "step": 4120
    },
    {
      "epoch": 19.668257756563246,
      "grad_norm": 0.42792344093322754,
      "learning_rate": 0.0004901388679012666,
      "loss": 2.0235,
      "step": 4130
    },
    {
      "epoch": 19.71599045346062,
      "grad_norm": 0.33373257517814636,
      "learning_rate": 0.000490086019681667,
      "loss": 2.0327,
      "step": 4140
    },
    {
      "epoch": 19.763723150357997,
      "grad_norm": 0.3789386451244354,
      "learning_rate": 0.0004900330330915249,
      "loss": 2.0148,
      "step": 4150
    },
    {
      "epoch": 19.81145584725537,
      "grad_norm": 0.4075780510902405,
      "learning_rate": 0.0004899799081613787,
      "loss": 2.0208,
      "step": 4160
    },
    {
      "epoch": 19.859188544152744,
      "grad_norm": 0.4051632285118103,
      "learning_rate": 0.0004899266449218459,
      "loss": 2.0285,
      "step": 4170
    },
    {
      "epoch": 19.90692124105012,
      "grad_norm": 0.3718712031841278,
      "learning_rate": 0.0004898732434036243,
      "loss": 2.0355,
      "step": 4180
    },
    {
      "epoch": 19.954653937947494,
      "grad_norm": 0.3937753438949585,
      "learning_rate": 0.0004898197036374913,
      "loss": 2.033,
      "step": 4190
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.2891690731048584,
      "learning_rate": 0.0004897660256543038,
      "loss": 1.9315,
      "step": 4200
    },
    {
      "epoch": 20.0,
      "eval_loss": 1.0675634145736694,
      "eval_runtime": 4.3833,
      "eval_samples_per_second": 3349.329,
      "eval_steps_per_second": 13.232,
      "step": 4200
    },
    {
      "epoch": 20.047732696897373,
      "grad_norm": 0.379223108291626,
      "learning_rate": 0.0004897122094849983,
      "loss": 2.0189,
      "step": 4210
    },
    {
      "epoch": 20.09546539379475,
      "grad_norm": 0.38023442029953003,
      "learning_rate": 0.0004896582551605912,
      "loss": 2.0366,
      "step": 4220
    },
    {
      "epoch": 20.143198090692124,
      "grad_norm": 0.33410879969596863,
      "learning_rate": 0.0004896041627121783,
      "loss": 2.0231,
      "step": 4230
    },
    {
      "epoch": 20.190930787589497,
      "grad_norm": 0.32841140031814575,
      "learning_rate": 0.0004895499321709352,
      "loss": 2.005,
      "step": 4240
    },
    {
      "epoch": 20.238663484486874,
      "grad_norm": 0.3550075888633728,
      "learning_rate": 0.0004894955635681169,
      "loss": 2.0136,
      "step": 4250
    },
    {
      "epoch": 20.286396181384248,
      "grad_norm": 0.32436561584472656,
      "learning_rate": 0.0004894410569350582,
      "loss": 2.0082,
      "step": 4260
    },
    {
      "epoch": 20.33412887828162,
      "grad_norm": 0.35796910524368286,
      "learning_rate": 0.0004893864123031731,
      "loss": 2.0265,
      "step": 4270
    },
    {
      "epoch": 20.381861575179,
      "grad_norm": 0.36240503191947937,
      "learning_rate": 0.0004893316297039555,
      "loss": 2.0194,
      "step": 4280
    },
    {
      "epoch": 20.429594272076372,
      "grad_norm": 0.4017258584499359,
      "learning_rate": 0.0004892767091689785,
      "loss": 2.0267,
      "step": 4290
    },
    {
      "epoch": 20.477326968973745,
      "grad_norm": 0.3870597779750824,
      "learning_rate": 0.0004892216507298951,
      "loss": 2.0188,
      "step": 4300
    },
    {
      "epoch": 20.525059665871122,
      "grad_norm": 0.3619564175605774,
      "learning_rate": 0.0004891664544184373,
      "loss": 2.031,
      "step": 4310
    },
    {
      "epoch": 20.572792362768496,
      "grad_norm": 0.34029388427734375,
      "learning_rate": 0.0004891111202664169,
      "loss": 2.026,
      "step": 4320
    },
    {
      "epoch": 20.620525059665873,
      "grad_norm": 0.35426706075668335,
      "learning_rate": 0.000489055648305725,
      "loss": 2.0179,
      "step": 4330
    },
    {
      "epoch": 20.668257756563246,
      "grad_norm": 0.3261318504810333,
      "learning_rate": 0.0004890000385683323,
      "loss": 2.0164,
      "step": 4340
    },
    {
      "epoch": 20.71599045346062,
      "grad_norm": 0.3277524709701538,
      "learning_rate": 0.0004889442910862886,
      "loss": 2.0171,
      "step": 4350
    },
    {
      "epoch": 20.763723150357997,
      "grad_norm": 0.35866212844848633,
      "learning_rate": 0.0004888884058917234,
      "loss": 1.9987,
      "step": 4360
    },
    {
      "epoch": 20.81145584725537,
      "grad_norm": 0.30407676100730896,
      "learning_rate": 0.0004888323830168452,
      "loss": 2.0251,
      "step": 4370
    },
    {
      "epoch": 20.859188544152744,
      "grad_norm": 0.32235828042030334,
      "learning_rate": 0.0004887762224939422,
      "loss": 2.0295,
      "step": 4380
    },
    {
      "epoch": 20.90692124105012,
      "grad_norm": 0.34024694561958313,
      "learning_rate": 0.0004887199243553819,
      "loss": 2.0092,
      "step": 4390
    },
    {
      "epoch": 20.954653937947494,
      "grad_norm": 0.34911760687828064,
      "learning_rate": 0.0004886634886336111,
      "loss": 2.0272,
      "step": 4400
    },
    {
      "epoch": 21.0,
      "grad_norm": 0.2568504214286804,
      "learning_rate": 0.0004886069153611554,
      "loss": 1.9274,
      "step": 4410
    },
    {
      "epoch": 21.0,
      "eval_loss": 1.0654324293136597,
      "eval_runtime": 4.3588,
      "eval_samples_per_second": 3368.098,
      "eval_steps_per_second": 13.306,
      "step": 4410
    },
    {
      "epoch": 21.047732696897373,
      "grad_norm": 0.3615625500679016,
      "learning_rate": 0.0004885502045706206,
      "loss": 2.0148,
      "step": 4420
    },
    {
      "epoch": 21.09546539379475,
      "grad_norm": 0.37282952666282654,
      "learning_rate": 0.0004884933562946908,
      "loss": 1.9991,
      "step": 4430
    },
    {
      "epoch": 21.143198090692124,
      "grad_norm": 0.35187622904777527,
      "learning_rate": 0.0004884363705661302,
      "loss": 2.0241,
      "step": 4440
    },
    {
      "epoch": 21.190930787589497,
      "grad_norm": 0.350648432970047,
      "learning_rate": 0.0004883792474177813,
      "loss": 1.9988,
      "step": 4450
    },
    {
      "epoch": 21.238663484486874,
      "grad_norm": 0.3728126287460327,
      "learning_rate": 0.0004883219868825668,
      "loss": 2.0135,
      "step": 4460
    },
    {
      "epoch": 21.286396181384248,
      "grad_norm": 0.37158292531967163,
      "learning_rate": 0.0004882645889934878,
      "loss": 2.0044,
      "step": 4470
    },
    {
      "epoch": 21.33412887828162,
      "grad_norm": 0.37203454971313477,
      "learning_rate": 0.00048820705378362496,
      "loss": 2.0266,
      "step": 4480
    },
    {
      "epoch": 21.381861575179,
      "grad_norm": 0.37408342957496643,
      "learning_rate": 0.000488149381286138,
      "loss": 2.0109,
      "step": 4490
    },
    {
      "epoch": 21.429594272076372,
      "grad_norm": 0.3871036171913147,
      "learning_rate": 0.0004880915715342655,
      "loss": 2.0262,
      "step": 4500
    },
    {
      "epoch": 21.477326968973745,
      "grad_norm": 0.38752666115760803,
      "learning_rate": 0.0004880336245613257,
      "loss": 2.022,
      "step": 4510
    },
    {
      "epoch": 21.525059665871122,
      "grad_norm": 0.3775339424610138,
      "learning_rate": 0.00048797554040071547,
      "loss": 2.0352,
      "step": 4520
    },
    {
      "epoch": 21.572792362768496,
      "grad_norm": 0.39976200461387634,
      "learning_rate": 0.0004879173190859107,
      "loss": 2.0105,
      "step": 4530
    },
    {
      "epoch": 21.620525059665873,
      "grad_norm": 0.3895244598388672,
      "learning_rate": 0.00048785896065046687,
      "loss": 2.0093,
      "step": 4540
    },
    {
      "epoch": 21.668257756563246,
      "grad_norm": 0.4220346510410309,
      "learning_rate": 0.00048780046512801785,
      "loss": 2.0174,
      "step": 4550
    },
    {
      "epoch": 21.71599045346062,
      "grad_norm": 0.3508740961551666,
      "learning_rate": 0.0004877418325522769,
      "loss": 2.0211,
      "step": 4560
    },
    {
      "epoch": 21.763723150357997,
      "grad_norm": 0.3922165632247925,
      "learning_rate": 0.0004876830629570361,
      "loss": 2.0273,
      "step": 4570
    },
    {
      "epoch": 21.81145584725537,
      "grad_norm": 0.41359496116638184,
      "learning_rate": 0.0004876241563761667,
      "loss": 2.0079,
      "step": 4580
    },
    {
      "epoch": 21.859188544152744,
      "grad_norm": 0.43101099133491516,
      "learning_rate": 0.0004875651128436186,
      "loss": 2.0295,
      "step": 4590
    },
    {
      "epoch": 21.90692124105012,
      "grad_norm": 0.40112772583961487,
      "learning_rate": 0.0004875059323934209,
      "loss": 2.0165,
      "step": 4600
    },
    {
      "epoch": 21.954653937947494,
      "grad_norm": 0.39246052503585815,
      "learning_rate": 0.00048744661505968146,
      "loss": 2.0168,
      "step": 4610
    },
    {
      "epoch": 22.0,
      "grad_norm": 0.2610582113265991,
      "learning_rate": 0.00048738716087658705,
      "loss": 1.9138,
      "step": 4620
    },
    {
      "epoch": 22.0,
      "eval_loss": 1.0656979084014893,
      "eval_runtime": 4.5542,
      "eval_samples_per_second": 3223.598,
      "eval_steps_per_second": 12.735,
      "step": 4620
    },
    {
      "epoch": 22.047732696897373,
      "grad_norm": 0.43943890929222107,
      "learning_rate": 0.00048732756987840344,
      "loss": 1.9931,
      "step": 4630
    },
    {
      "epoch": 22.09546539379475,
      "grad_norm": 0.36579766869544983,
      "learning_rate": 0.000487267842099475,
      "loss": 2.002,
      "step": 4640
    },
    {
      "epoch": 22.143198090692124,
      "grad_norm": 0.3750050365924835,
      "learning_rate": 0.0004872079775742252,
      "loss": 2.0097,
      "step": 4650
    },
    {
      "epoch": 22.190930787589497,
      "grad_norm": 0.4345272481441498,
      "learning_rate": 0.00048714797633715614,
      "loss": 2.0084,
      "step": 4660
    },
    {
      "epoch": 22.238663484486874,
      "grad_norm": 0.41578197479248047,
      "learning_rate": 0.0004870878384228488,
      "loss": 2.0145,
      "step": 4670
    },
    {
      "epoch": 22.286396181384248,
      "grad_norm": 0.3674285113811493,
      "learning_rate": 0.00048702756386596294,
      "loss": 2.0104,
      "step": 4680
    },
    {
      "epoch": 22.33412887828162,
      "grad_norm": 0.41029953956604004,
      "learning_rate": 0.000486967152701237,
      "loss": 2.0226,
      "step": 4690
    },
    {
      "epoch": 22.381861575179,
      "grad_norm": 0.355497270822525,
      "learning_rate": 0.00048690660496348816,
      "loss": 2.0184,
      "step": 4700
    },
    {
      "epoch": 22.429594272076372,
      "grad_norm": 0.3818902373313904,
      "learning_rate": 0.0004868459206876124,
      "loss": 2.0179,
      "step": 4710
    },
    {
      "epoch": 22.477326968973745,
      "grad_norm": 0.3900165259838104,
      "learning_rate": 0.0004867850999085843,
      "loss": 2.0162,
      "step": 4720
    },
    {
      "epoch": 22.525059665871122,
      "grad_norm": 0.39874568581581116,
      "learning_rate": 0.00048672414266145715,
      "loss": 2.0161,
      "step": 4730
    },
    {
      "epoch": 22.572792362768496,
      "grad_norm": 0.3478304445743561,
      "learning_rate": 0.00048666304898136294,
      "loss": 2.0046,
      "step": 4740
    },
    {
      "epoch": 22.620525059665873,
      "grad_norm": 0.4061431288719177,
      "learning_rate": 0.00048660181890351214,
      "loss": 1.9956,
      "step": 4750
    },
    {
      "epoch": 22.668257756563246,
      "grad_norm": 0.4028300642967224,
      "learning_rate": 0.000486540452463194,
      "loss": 2.0144,
      "step": 4760
    },
    {
      "epoch": 22.71599045346062,
      "grad_norm": 0.37587469816207886,
      "learning_rate": 0.0004864789496957763,
      "loss": 2.0005,
      "step": 4770
    },
    {
      "epoch": 22.763723150357997,
      "grad_norm": 0.41017985343933105,
      "learning_rate": 0.0004864173106367054,
      "loss": 2.0264,
      "step": 4780
    },
    {
      "epoch": 22.81145584725537,
      "grad_norm": 0.4540348947048187,
      "learning_rate": 0.0004863555353215061,
      "loss": 1.9943,
      "step": 4790
    },
    {
      "epoch": 22.859188544152744,
      "grad_norm": 0.42513909935951233,
      "learning_rate": 0.0004862936237857819,
      "loss": 2.0128,
      "step": 4800
    },
    {
      "epoch": 22.90692124105012,
      "grad_norm": 0.38109901547431946,
      "learning_rate": 0.00048623157606521474,
      "loss": 2.0094,
      "step": 4810
    },
    {
      "epoch": 22.954653937947494,
      "grad_norm": 0.3760828971862793,
      "learning_rate": 0.00048616939219556487,
      "loss": 2.0185,
      "step": 4820
    },
    {
      "epoch": 23.0,
      "grad_norm": 0.3332407772541046,
      "learning_rate": 0.0004861070722126715,
      "loss": 1.9112,
      "step": 4830
    },
    {
      "epoch": 23.0,
      "eval_loss": 1.0664563179016113,
      "eval_runtime": 4.3865,
      "eval_samples_per_second": 3346.855,
      "eval_steps_per_second": 13.222,
      "step": 4830
    },
    {
      "epoch": 23.047732696897373,
      "grad_norm": 0.39600709080696106,
      "learning_rate": 0.00048604461615245163,
      "loss": 1.9984,
      "step": 4840
    },
    {
      "epoch": 23.09546539379475,
      "grad_norm": 0.38163959980010986,
      "learning_rate": 0.0004859820240509013,
      "loss": 1.9962,
      "step": 4850
    },
    {
      "epoch": 23.143198090692124,
      "grad_norm": 0.3808971345424652,
      "learning_rate": 0.00048591929594409445,
      "loss": 1.9993,
      "step": 4860
    },
    {
      "epoch": 23.190930787589497,
      "grad_norm": 0.3864985704421997,
      "learning_rate": 0.00048585643186818385,
      "loss": 2.0186,
      "step": 4870
    },
    {
      "epoch": 23.238663484486874,
      "grad_norm": 0.3605997562408447,
      "learning_rate": 0.00048579343185940017,
      "loss": 2.0128,
      "step": 4880
    },
    {
      "epoch": 23.286396181384248,
      "grad_norm": 0.4264458417892456,
      "learning_rate": 0.00048573029595405285,
      "loss": 2.0083,
      "step": 4890
    },
    {
      "epoch": 23.33412887828162,
      "grad_norm": 0.38372084498405457,
      "learning_rate": 0.0004856670241885294,
      "loss": 2.0011,
      "step": 4900
    },
    {
      "epoch": 23.381861575179,
      "grad_norm": 0.43951401114463806,
      "learning_rate": 0.00048560361659929574,
      "loss": 2.0024,
      "step": 4910
    },
    {
      "epoch": 23.429594272076372,
      "grad_norm": 0.3516651690006256,
      "learning_rate": 0.00048554007322289597,
      "loss": 2.0124,
      "step": 4920
    },
    {
      "epoch": 23.477326968973745,
      "grad_norm": 0.39892980456352234,
      "learning_rate": 0.0004854763940959526,
      "loss": 2.0114,
      "step": 4930
    },
    {
      "epoch": 23.525059665871122,
      "grad_norm": 0.374656617641449,
      "learning_rate": 0.00048541257925516614,
      "loss": 2.009,
      "step": 4940
    },
    {
      "epoch": 23.572792362768496,
      "grad_norm": 0.4220615327358246,
      "learning_rate": 0.00048534862873731566,
      "loss": 1.998,
      "step": 4950
    },
    {
      "epoch": 23.620525059665873,
      "grad_norm": 0.37475332617759705,
      "learning_rate": 0.00048528454257925816,
      "loss": 2.0234,
      "step": 4960
    },
    {
      "epoch": 23.668257756563246,
      "grad_norm": 0.39505067467689514,
      "learning_rate": 0.0004852203208179288,
      "loss": 2.0096,
      "step": 4970
    },
    {
      "epoch": 23.71599045346062,
      "grad_norm": 0.3935834765434265,
      "learning_rate": 0.0004851559634903411,
      "loss": 2.0026,
      "step": 4980
    },
    {
      "epoch": 23.763723150357997,
      "grad_norm": 0.4166756272315979,
      "learning_rate": 0.0004850914706335865,
      "loss": 2.0075,
      "step": 4990
    },
    {
      "epoch": 23.81145584725537,
      "grad_norm": 0.38648486137390137,
      "learning_rate": 0.0004850268422848346,
      "loss": 2.0062,
      "step": 5000
    },
    {
      "epoch": 23.859188544152744,
      "grad_norm": 0.33495986461639404,
      "learning_rate": 0.0004849620784813333,
      "loss": 1.9981,
      "step": 5010
    },
    {
      "epoch": 23.90692124105012,
      "grad_norm": 0.3348847031593323,
      "learning_rate": 0.00048489717926040836,
      "loss": 2.0055,
      "step": 5020
    },
    {
      "epoch": 23.954653937947494,
      "grad_norm": 0.3628762662410736,
      "learning_rate": 0.0004848321446594636,
      "loss": 2.0093,
      "step": 5030
    },
    {
      "epoch": 24.0,
      "grad_norm": 0.3183940351009369,
      "learning_rate": 0.00048476697471598075,
      "loss": 1.9005,
      "step": 5040
    },
    {
      "epoch": 24.0,
      "eval_loss": 1.0622453689575195,
      "eval_runtime": 4.39,
      "eval_samples_per_second": 3344.165,
      "eval_steps_per_second": 13.212,
      "step": 5040
    },
    {
      "epoch": 24.047732696897373,
      "grad_norm": 0.4035479724407196,
      "learning_rate": 0.00048470166946751987,
      "loss": 1.9933,
      "step": 5050
    },
    {
      "epoch": 24.09546539379475,
      "grad_norm": 0.4079675078392029,
      "learning_rate": 0.00048463622895171874,
      "loss": 2.0058,
      "step": 5060
    },
    {
      "epoch": 24.143198090692124,
      "grad_norm": 0.4075423777103424,
      "learning_rate": 0.0004845706532062931,
      "loss": 2.0075,
      "step": 5070
    },
    {
      "epoch": 24.190930787589497,
      "grad_norm": 0.36414724588394165,
      "learning_rate": 0.0004845049422690369,
      "loss": 2.0167,
      "step": 5080
    },
    {
      "epoch": 24.238663484486874,
      "grad_norm": 0.40709659457206726,
      "learning_rate": 0.00048443909617782165,
      "loss": 2.0144,
      "step": 5090
    },
    {
      "epoch": 24.286396181384248,
      "grad_norm": 0.3816843032836914,
      "learning_rate": 0.00048437311497059697,
      "loss": 2.0081,
      "step": 5100
    },
    {
      "epoch": 24.33412887828162,
      "grad_norm": 0.3097044825553894,
      "learning_rate": 0.00048430699868539024,
      "loss": 1.9836,
      "step": 5110
    },
    {
      "epoch": 24.381861575179,
      "grad_norm": 0.4416266977787018,
      "learning_rate": 0.00048424074736030676,
      "loss": 1.9992,
      "step": 5120
    },
    {
      "epoch": 24.429594272076372,
      "grad_norm": 0.371377557516098,
      "learning_rate": 0.00048417436103352976,
      "loss": 2.0064,
      "step": 5130
    },
    {
      "epoch": 24.477326968973745,
      "grad_norm": 0.36530375480651855,
      "learning_rate": 0.00048410783974332,
      "loss": 2.0054,
      "step": 5140
    },
    {
      "epoch": 24.525059665871122,
      "grad_norm": 0.3542492389678955,
      "learning_rate": 0.0004840411835280163,
      "loss": 2.0071,
      "step": 5150
    },
    {
      "epoch": 24.572792362768496,
      "grad_norm": 0.42972472310066223,
      "learning_rate": 0.00048397439242603505,
      "loss": 2.0035,
      "step": 5160
    },
    {
      "epoch": 24.620525059665873,
      "grad_norm": 0.3376767039299011,
      "learning_rate": 0.0004839074664758704,
      "loss": 1.997,
      "step": 5170
    },
    {
      "epoch": 24.668257756563246,
      "grad_norm": 0.39514556527137756,
      "learning_rate": 0.00048384040571609443,
      "loss": 1.987,
      "step": 5180
    },
    {
      "epoch": 24.71599045346062,
      "grad_norm": 0.43195945024490356,
      "learning_rate": 0.00048377321018535675,
      "loss": 1.9997,
      "step": 5190
    },
    {
      "epoch": 24.763723150357997,
      "grad_norm": 0.39033007621765137,
      "learning_rate": 0.00048370587992238454,
      "loss": 1.9952,
      "step": 5200
    },
    {
      "epoch": 24.81145584725537,
      "grad_norm": 0.40150389075279236,
      "learning_rate": 0.00048363841496598285,
      "loss": 2.006,
      "step": 5210
    },
    {
      "epoch": 24.859188544152744,
      "grad_norm": 0.43175122141838074,
      "learning_rate": 0.0004835708153550341,
      "loss": 2.0041,
      "step": 5220
    },
    {
      "epoch": 24.90692124105012,
      "grad_norm": 0.33837050199508667,
      "learning_rate": 0.00048350308112849865,
      "loss": 2.0008,
      "step": 5230
    },
    {
      "epoch": 24.954653937947494,
      "grad_norm": 0.3768225610256195,
      "learning_rate": 0.0004834352123254142,
      "loss": 2.0028,
      "step": 5240
    },
    {
      "epoch": 25.0,
      "grad_norm": 0.29383981227874756,
      "learning_rate": 0.0004833672089848961,
      "loss": 1.9155,
      "step": 5250
    },
    {
      "epoch": 25.0,
      "eval_loss": 1.061023235321045,
      "eval_runtime": 4.3679,
      "eval_samples_per_second": 3361.15,
      "eval_steps_per_second": 13.279,
      "step": 5250
    },
    {
      "epoch": 25.047732696897373,
      "grad_norm": 0.38165563344955444,
      "learning_rate": 0.0004832990711461371,
      "loss": 2.0099,
      "step": 5260
    },
    {
      "epoch": 25.09546539379475,
      "grad_norm": 0.38863393664360046,
      "learning_rate": 0.0004832307988484077,
      "loss": 1.9963,
      "step": 5270
    },
    {
      "epoch": 25.143198090692124,
      "grad_norm": 0.4851089119911194,
      "learning_rate": 0.0004831623921310558,
      "loss": 1.9952,
      "step": 5280
    },
    {
      "epoch": 25.190930787589497,
      "grad_norm": 0.41488584876060486,
      "learning_rate": 0.0004830938510335066,
      "loss": 1.9942,
      "step": 5290
    },
    {
      "epoch": 25.238663484486874,
      "grad_norm": 0.36410996317863464,
      "learning_rate": 0.00048302517559526304,
      "loss": 2.0027,
      "step": 5300
    },
    {
      "epoch": 25.286396181384248,
      "grad_norm": 0.4229690432548523,
      "learning_rate": 0.0004829563658559053,
      "loss": 2.0039,
      "step": 5310
    },
    {
      "epoch": 25.33412887828162,
      "grad_norm": 0.49056148529052734,
      "learning_rate": 0.00048288742185509094,
      "loss": 2.0077,
      "step": 5320
    },
    {
      "epoch": 25.381861575179,
      "grad_norm": 0.4188312888145447,
      "learning_rate": 0.00048281834363255507,
      "loss": 2.0012,
      "step": 5330
    },
    {
      "epoch": 25.429594272076372,
      "grad_norm": 0.4481809735298157,
      "learning_rate": 0.0004827491312281099,
      "loss": 2.0025,
      "step": 5340
    },
    {
      "epoch": 25.477326968973745,
      "grad_norm": 3.567173957824707,
      "learning_rate": 0.0004826797846816453,
      "loss": 2.0013,
      "step": 5350
    },
    {
      "epoch": 25.525059665871122,
      "grad_norm": 0.603327214717865,
      "learning_rate": 0.0004826103040331282,
      "loss": 1.9896,
      "step": 5360
    },
    {
      "epoch": 25.572792362768496,
      "grad_norm": 0.3821704685688019,
      "learning_rate": 0.00048254068932260285,
      "loss": 2.0085,
      "step": 5370
    },
    {
      "epoch": 25.620525059665873,
      "grad_norm": 0.3916340470314026,
      "learning_rate": 0.00048247094059019095,
      "loss": 2.0034,
      "step": 5380
    },
    {
      "epoch": 25.668257756563246,
      "grad_norm": 0.4698870778083801,
      "learning_rate": 0.000482401057876091,
      "loss": 1.9981,
      "step": 5390
    },
    {
      "epoch": 25.71599045346062,
      "grad_norm": 0.4649282991886139,
      "learning_rate": 0.00048233104122057937,
      "loss": 1.9901,
      "step": 5400
    },
    {
      "epoch": 25.763723150357997,
      "grad_norm": 0.4310988783836365,
      "learning_rate": 0.000482260890664009,
      "loss": 2.0024,
      "step": 5410
    },
    {
      "epoch": 25.81145584725537,
      "grad_norm": 0.45224443078041077,
      "learning_rate": 0.00048219060624681053,
      "loss": 1.9884,
      "step": 5420
    },
    {
      "epoch": 25.859188544152744,
      "grad_norm": 0.468177855014801,
      "learning_rate": 0.00048212018800949133,
      "loss": 1.9977,
      "step": 5430
    },
    {
      "epoch": 25.90692124105012,
      "grad_norm": 0.3885985016822815,
      "learning_rate": 0.000482049635992636,
      "loss": 2.0089,
      "step": 5440
    },
    {
      "epoch": 25.954653937947494,
      "grad_norm": 0.4739956855773926,
      "learning_rate": 0.0004819789502369064,
      "loss": 1.9954,
      "step": 5450
    },
    {
      "epoch": 26.0,
      "grad_norm": 0.2937949299812317,
      "learning_rate": 0.0004819081307830415,
      "loss": 1.8994,
      "step": 5460
    },
    {
      "epoch": 26.0,
      "eval_loss": 1.0603232383728027,
      "eval_runtime": 4.3764,
      "eval_samples_per_second": 3354.566,
      "eval_steps_per_second": 13.253,
      "step": 5460
    },
    {
      "epoch": 26.047732696897373,
      "grad_norm": 0.37202438712120056,
      "learning_rate": 0.000481837177671857,
      "loss": 1.9855,
      "step": 5470
    },
    {
      "epoch": 26.09546539379475,
      "grad_norm": 0.4457522928714752,
      "learning_rate": 0.00048176609094424585,
      "loss": 1.995,
      "step": 5480
    },
    {
      "epoch": 26.143198090692124,
      "grad_norm": 0.3793525695800781,
      "learning_rate": 0.000481694870641178,
      "loss": 1.9983,
      "step": 5490
    },
    {
      "epoch": 26.190930787589497,
      "grad_norm": 0.4008592367172241,
      "learning_rate": 0.0004816235168037004,
      "loss": 1.9986,
      "step": 5500
    },
    {
      "epoch": 26.238663484486874,
      "grad_norm": 0.3991551697254181,
      "learning_rate": 0.000481552029472937,
      "loss": 1.9927,
      "step": 5510
    },
    {
      "epoch": 26.286396181384248,
      "grad_norm": 0.5522400736808777,
      "learning_rate": 0.00048148040869008856,
      "loss": 1.9988,
      "step": 5520
    },
    {
      "epoch": 26.33412887828162,
      "grad_norm": 0.39163893461227417,
      "learning_rate": 0.0004814086544964328,
      "loss": 1.9922,
      "step": 5530
    },
    {
      "epoch": 26.381861575179,
      "grad_norm": 0.40865573287010193,
      "learning_rate": 0.00048133676693332426,
      "loss": 2.0046,
      "step": 5540
    },
    {
      "epoch": 26.429594272076372,
      "grad_norm": 0.4382113814353943,
      "learning_rate": 0.0004812647460421946,
      "loss": 1.9965,
      "step": 5550
    },
    {
      "epoch": 26.477326968973745,
      "grad_norm": 0.4662855565547943,
      "learning_rate": 0.0004811925918645521,
      "loss": 2.0023,
      "step": 5560
    },
    {
      "epoch": 26.525059665871122,
      "grad_norm": 0.36996975541114807,
      "learning_rate": 0.00048112030444198174,
      "loss": 2.0208,
      "step": 5570
    },
    {
      "epoch": 26.572792362768496,
      "grad_norm": 0.458901584148407,
      "learning_rate": 0.0004810478838161457,
      "loss": 1.9907,
      "step": 5580
    },
    {
      "epoch": 26.620525059665873,
      "grad_norm": 0.36657071113586426,
      "learning_rate": 0.0004809753300287826,
      "loss": 1.9851,
      "step": 5590
    },
    {
      "epoch": 26.668257756563246,
      "grad_norm": 0.4636096954345703,
      "learning_rate": 0.00048090264312170786,
      "loss": 1.9925,
      "step": 5600
    },
    {
      "epoch": 26.71599045346062,
      "grad_norm": 0.4669531285762787,
      "learning_rate": 0.0004808298231368136,
      "loss": 1.9899,
      "step": 5610
    },
    {
      "epoch": 26.763723150357997,
      "grad_norm": 0.35800445079803467,
      "learning_rate": 0.0004807568701160688,
      "loss": 1.9991,
      "step": 5620
    },
    {
      "epoch": 26.81145584725537,
      "grad_norm": 0.368564248085022,
      "learning_rate": 0.00048068378410151915,
      "loss": 2.0027,
      "step": 5630
    },
    {
      "epoch": 26.859188544152744,
      "grad_norm": 0.35774916410446167,
      "learning_rate": 0.00048061056513528657,
      "loss": 1.9883,
      "step": 5640
    },
    {
      "epoch": 26.90692124105012,
      "grad_norm": 0.4202442765235901,
      "learning_rate": 0.00048053721325957,
      "loss": 2.0029,
      "step": 5650
    },
    {
      "epoch": 26.954653937947494,
      "grad_norm": 0.40784698724746704,
      "learning_rate": 0.00048046372851664494,
      "loss": 2.0073,
      "step": 5660
    },
    {
      "epoch": 27.0,
      "grad_norm": 0.2797105610370636,
      "learning_rate": 0.0004803901109488633,
      "loss": 1.8759,
      "step": 5670
    },
    {
      "epoch": 27.0,
      "eval_loss": 1.0591553449630737,
      "eval_runtime": 4.3876,
      "eval_samples_per_second": 3346.037,
      "eval_steps_per_second": 13.219,
      "step": 5670
    },
    {
      "epoch": 27.047732696897373,
      "grad_norm": 0.475058913230896,
      "learning_rate": 0.0004803163605986537,
      "loss": 1.9935,
      "step": 5680
    },
    {
      "epoch": 27.09546539379475,
      "grad_norm": 0.4496651589870453,
      "learning_rate": 0.00048024247750852114,
      "loss": 1.9907,
      "step": 5690
    },
    {
      "epoch": 27.143198090692124,
      "grad_norm": 0.3843993842601776,
      "learning_rate": 0.00048016846172104725,
      "loss": 1.9789,
      "step": 5700
    },
    {
      "epoch": 27.190930787589497,
      "grad_norm": 0.38248544931411743,
      "learning_rate": 0.0004800943132788901,
      "loss": 1.9894,
      "step": 5710
    },
    {
      "epoch": 27.238663484486874,
      "grad_norm": 0.4613403081893921,
      "learning_rate": 0.0004800200322247842,
      "loss": 1.9996,
      "step": 5720
    },
    {
      "epoch": 27.286396181384248,
      "grad_norm": 0.39865827560424805,
      "learning_rate": 0.0004799456186015405,
      "loss": 2.0053,
      "step": 5730
    },
    {
      "epoch": 27.33412887828162,
      "grad_norm": 0.4262089431285858,
      "learning_rate": 0.0004798710724520464,
      "loss": 2.002,
      "step": 5740
    },
    {
      "epoch": 27.381861575179,
      "grad_norm": 0.4025948941707611,
      "learning_rate": 0.00047979639381926555,
      "loss": 1.9831,
      "step": 5750
    },
    {
      "epoch": 27.429594272076372,
      "grad_norm": 0.43968164920806885,
      "learning_rate": 0.000479721582746238,
      "loss": 1.9864,
      "step": 5760
    },
    {
      "epoch": 27.477326968973745,
      "grad_norm": 0.40056195855140686,
      "learning_rate": 0.00047964663927608034,
      "loss": 1.977,
      "step": 5770
    },
    {
      "epoch": 27.525059665871122,
      "grad_norm": 0.609961986541748,
      "learning_rate": 0.0004795715634519851,
      "loss": 2.001,
      "step": 5780
    },
    {
      "epoch": 27.572792362768496,
      "grad_norm": 0.4060610234737396,
      "learning_rate": 0.00047949635531722144,
      "loss": 1.9837,
      "step": 5790
    },
    {
      "epoch": 27.620525059665873,
      "grad_norm": 0.4149600565433502,
      "learning_rate": 0.00047942101491513445,
      "loss": 1.9901,
      "step": 5800
    },
    {
      "epoch": 27.668257756563246,
      "grad_norm": 0.4244151711463928,
      "learning_rate": 0.0004793455422891458,
      "loss": 1.9984,
      "step": 5810
    },
    {
      "epoch": 27.71599045346062,
      "grad_norm": 0.3998471796512604,
      "learning_rate": 0.00047926993748275304,
      "loss": 1.987,
      "step": 5820
    },
    {
      "epoch": 27.763723150357997,
      "grad_norm": 0.4008236527442932,
      "learning_rate": 0.0004791942005395302,
      "loss": 1.9897,
      "step": 5830
    },
    {
      "epoch": 27.81145584725537,
      "grad_norm": 0.4221245348453522,
      "learning_rate": 0.0004791183315031271,
      "loss": 1.9836,
      "step": 5840
    },
    {
      "epoch": 27.859188544152744,
      "grad_norm": 0.37385377287864685,
      "learning_rate": 0.0004790423304172701,
      "loss": 2.0027,
      "step": 5850
    },
    {
      "epoch": 27.90692124105012,
      "grad_norm": 0.4034649729728699,
      "learning_rate": 0.0004789661973257613,
      "loss": 1.9968,
      "step": 5860
    },
    {
      "epoch": 27.954653937947494,
      "grad_norm": 0.3825249969959259,
      "learning_rate": 0.00047888993227247913,
      "loss": 1.9987,
      "step": 5870
    },
    {
      "epoch": 28.0,
      "grad_norm": 0.3468050956726074,
      "learning_rate": 0.00047881353530137796,
      "loss": 1.892,
      "step": 5880
    },
    {
      "epoch": 28.0,
      "eval_loss": 1.0625640153884888,
      "eval_runtime": 4.3814,
      "eval_samples_per_second": 3350.77,
      "eval_steps_per_second": 13.238,
      "step": 5880
    },
    {
      "epoch": 28.047732696897373,
      "grad_norm": 0.41247791051864624,
      "learning_rate": 0.0004787370064564883,
      "loss": 1.9929,
      "step": 5890
    },
    {
      "epoch": 28.09546539379475,
      "grad_norm": 0.40484192967414856,
      "learning_rate": 0.0004786603457819165,
      "loss": 1.9887,
      "step": 5900
    },
    {
      "epoch": 28.143198090692124,
      "grad_norm": 0.417782187461853,
      "learning_rate": 0.000478583553321845,
      "loss": 1.9814,
      "step": 5910
    },
    {
      "epoch": 28.190930787589497,
      "grad_norm": 0.4082696735858917,
      "learning_rate": 0.0004785066291205321,
      "loss": 1.9883,
      "step": 5920
    },
    {
      "epoch": 28.238663484486874,
      "grad_norm": 0.4338394105434418,
      "learning_rate": 0.0004784295732223122,
      "loss": 1.9824,
      "step": 5930
    },
    {
      "epoch": 28.286396181384248,
      "grad_norm": 0.3907965421676636,
      "learning_rate": 0.00047835238567159544,
      "loss": 1.9873,
      "step": 5940
    },
    {
      "epoch": 28.33412887828162,
      "grad_norm": 0.44953012466430664,
      "learning_rate": 0.00047827506651286787,
      "loss": 1.9899,
      "step": 5950
    },
    {
      "epoch": 28.381861575179,
      "grad_norm": 0.43504923582077026,
      "learning_rate": 0.0004781976157906914,
      "loss": 1.9953,
      "step": 5960
    },
    {
      "epoch": 28.429594272076372,
      "grad_norm": 0.43298059701919556,
      "learning_rate": 0.0004781200335497039,
      "loss": 1.9921,
      "step": 5970
    },
    {
      "epoch": 28.477326968973745,
      "grad_norm": 0.4541921019554138,
      "learning_rate": 0.0004780423198346188,
      "loss": 1.9868,
      "step": 5980
    },
    {
      "epoch": 28.525059665871122,
      "grad_norm": 0.4313323199748993,
      "learning_rate": 0.0004779644746902253,
      "loss": 1.9825,
      "step": 5990
    },
    {
      "epoch": 28.572792362768496,
      "grad_norm": 0.4484446048736572,
      "learning_rate": 0.0004778864981613887,
      "loss": 1.9943,
      "step": 6000
    },
    {
      "epoch": 28.620525059665873,
      "grad_norm": 0.4558032751083374,
      "learning_rate": 0.0004778083902930497,
      "loss": 1.9893,
      "step": 6010
    },
    {
      "epoch": 28.668257756563246,
      "grad_norm": 0.39816245436668396,
      "learning_rate": 0.00047773015113022476,
      "loss": 1.9916,
      "step": 6020
    },
    {
      "epoch": 28.71599045346062,
      "grad_norm": 0.39733627438545227,
      "learning_rate": 0.00047765178071800603,
      "loss": 1.9942,
      "step": 6030
    },
    {
      "epoch": 28.763723150357997,
      "grad_norm": 0.4768894612789154,
      "learning_rate": 0.00047757327910156127,
      "loss": 2.0103,
      "step": 6040
    },
    {
      "epoch": 28.81145584725537,
      "grad_norm": 0.3718123137950897,
      "learning_rate": 0.00047749464632613396,
      "loss": 1.9923,
      "step": 6050
    },
    {
      "epoch": 28.859188544152744,
      "grad_norm": 0.430913507938385,
      "learning_rate": 0.00047741588243704316,
      "loss": 1.9862,
      "step": 6060
    },
    {
      "epoch": 28.90692124105012,
      "grad_norm": 0.39777374267578125,
      "learning_rate": 0.0004773369874796833,
      "loss": 1.9858,
      "step": 6070
    },
    {
      "epoch": 28.954653937947494,
      "grad_norm": 0.3524916470050812,
      "learning_rate": 0.0004772579614995246,
      "loss": 1.9791,
      "step": 6080
    },
    {
      "epoch": 29.0,
      "grad_norm": 0.30295059084892273,
      "learning_rate": 0.0004771788045421126,
      "loss": 1.9029,
      "step": 6090
    },
    {
      "epoch": 29.0,
      "eval_loss": 1.0595217943191528,
      "eval_runtime": 4.3735,
      "eval_samples_per_second": 3356.818,
      "eval_steps_per_second": 13.262,
      "step": 6090
    },
    {
      "epoch": 29.047732696897373,
      "grad_norm": 0.42064228653907776,
      "learning_rate": 0.0004770995166530685,
      "loss": 1.973,
      "step": 6100
    },
    {
      "epoch": 29.09546539379475,
      "grad_norm": 0.5554247498512268,
      "learning_rate": 0.00047702009787808876,
      "loss": 1.9883,
      "step": 6110
    },
    {
      "epoch": 29.143198090692124,
      "grad_norm": 0.44745340943336487,
      "learning_rate": 0.00047694054826294554,
      "loss": 1.9903,
      "step": 6120
    },
    {
      "epoch": 29.190930787589497,
      "grad_norm": 0.46960628032684326,
      "learning_rate": 0.00047686086785348614,
      "loss": 1.9755,
      "step": 6130
    },
    {
      "epoch": 29.238663484486874,
      "grad_norm": 0.42889949679374695,
      "learning_rate": 0.0004767810566956334,
      "loss": 1.9794,
      "step": 6140
    },
    {
      "epoch": 29.286396181384248,
      "grad_norm": 0.47122177481651306,
      "learning_rate": 0.0004767011148353854,
      "loss": 2.0028,
      "step": 6150
    },
    {
      "epoch": 29.33412887828162,
      "grad_norm": 0.4042910635471344,
      "learning_rate": 0.00047662104231881576,
      "loss": 1.987,
      "step": 6160
    },
    {
      "epoch": 29.381861575179,
      "grad_norm": 0.4250604510307312,
      "learning_rate": 0.00047654083919207316,
      "loss": 1.9975,
      "step": 6170
    },
    {
      "epoch": 29.429594272076372,
      "grad_norm": 0.40165600180625916,
      "learning_rate": 0.00047646050550138164,
      "loss": 1.9943,
      "step": 6180
    },
    {
      "epoch": 29.477326968973745,
      "grad_norm": 0.44536468386650085,
      "learning_rate": 0.0004763800412930406,
      "loss": 1.9934,
      "step": 6190
    },
    {
      "epoch": 29.525059665871122,
      "grad_norm": 0.4218010902404785,
      "learning_rate": 0.0004762994466134245,
      "loss": 1.9805,
      "step": 6200
    },
    {
      "epoch": 29.572792362768496,
      "grad_norm": 0.3696245849132538,
      "learning_rate": 0.000476218721508983,
      "loss": 1.9887,
      "step": 6210
    },
    {
      "epoch": 29.620525059665873,
      "grad_norm": 0.42558231949806213,
      "learning_rate": 0.0004761378660262412,
      "loss": 1.9826,
      "step": 6220
    },
    {
      "epoch": 29.668257756563246,
      "grad_norm": 0.43848228454589844,
      "learning_rate": 0.00047605688021179894,
      "loss": 1.9854,
      "step": 6230
    },
    {
      "epoch": 29.71599045346062,
      "grad_norm": 0.4300755560398102,
      "learning_rate": 0.0004759757641123315,
      "loss": 1.99,
      "step": 6240
    },
    {
      "epoch": 29.763723150357997,
      "grad_norm": 0.4457932412624359,
      "learning_rate": 0.000475894517774589,
      "loss": 1.9974,
      "step": 6250
    },
    {
      "epoch": 29.81145584725537,
      "grad_norm": 0.4774366617202759,
      "learning_rate": 0.0004758131412453969,
      "loss": 1.9811,
      "step": 6260
    },
    {
      "epoch": 29.859188544152744,
      "grad_norm": 0.41339218616485596,
      "learning_rate": 0.0004757316345716554,
      "loss": 1.9765,
      "step": 6270
    },
    {
      "epoch": 29.90692124105012,
      "grad_norm": 0.378121942281723,
      "learning_rate": 0.0004756499978003398,
      "loss": 2.0004,
      "step": 6280
    },
    {
      "epoch": 29.954653937947494,
      "grad_norm": 0.40445053577423096,
      "learning_rate": 0.0004755682309785005,
      "loss": 1.9685,
      "step": 6290
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.3171806335449219,
      "learning_rate": 0.0004754863341532628,
      "loss": 1.8791,
      "step": 6300
    },
    {
      "epoch": 30.0,
      "eval_loss": 1.058462142944336,
      "eval_runtime": 4.3972,
      "eval_samples_per_second": 3338.689,
      "eval_steps_per_second": 13.19,
      "step": 6300
    },
    {
      "epoch": 30.047732696897373,
      "grad_norm": 0.4125877916812897,
      "learning_rate": 0.00047540430737182685,
      "loss": 1.968,
      "step": 6310
    },
    {
      "epoch": 30.09546539379475,
      "grad_norm": 0.41005557775497437,
      "learning_rate": 0.00047532215068146776,
      "loss": 1.9845,
      "step": 6320
    },
    {
      "epoch": 30.143198090692124,
      "grad_norm": 0.3801003694534302,
      "learning_rate": 0.0004752398641295356,
      "loss": 1.9815,
      "step": 6330
    },
    {
      "epoch": 30.190930787589497,
      "grad_norm": 0.4540914297103882,
      "learning_rate": 0.00047515744776345503,
      "loss": 1.9798,
      "step": 6340
    },
    {
      "epoch": 30.238663484486874,
      "grad_norm": 0.4155827760696411,
      "learning_rate": 0.0004750749016307257,
      "loss": 1.9769,
      "step": 6350
    },
    {
      "epoch": 30.286396181384248,
      "grad_norm": 0.41197654604911804,
      "learning_rate": 0.0004749922257789221,
      "loss": 1.9987,
      "step": 6360
    },
    {
      "epoch": 30.33412887828162,
      "grad_norm": 0.46380528807640076,
      "learning_rate": 0.00047490942025569345,
      "loss": 1.989,
      "step": 6370
    },
    {
      "epoch": 30.381861575179,
      "grad_norm": 0.42507562041282654,
      "learning_rate": 0.00047482648510876357,
      "loss": 1.9875,
      "step": 6380
    },
    {
      "epoch": 30.429594272076372,
      "grad_norm": 0.4250091016292572,
      "learning_rate": 0.0004747434203859311,
      "loss": 1.9946,
      "step": 6390
    },
    {
      "epoch": 30.477326968973745,
      "grad_norm": 0.41105058789253235,
      "learning_rate": 0.00047466022613506934,
      "loss": 1.9861,
      "step": 6400
    },
    {
      "epoch": 30.525059665871122,
      "grad_norm": 0.424704372882843,
      "learning_rate": 0.0004745769024041263,
      "loss": 2.0002,
      "step": 6410
    },
    {
      "epoch": 30.572792362768496,
      "grad_norm": 0.3794594407081604,
      "learning_rate": 0.0004744934492411245,
      "loss": 1.976,
      "step": 6420
    },
    {
      "epoch": 30.620525059665873,
      "grad_norm": 0.4236079156398773,
      "learning_rate": 0.00047440986669416117,
      "loss": 1.9789,
      "step": 6430
    },
    {
      "epoch": 30.668257756563246,
      "grad_norm": 0.43503981828689575,
      "learning_rate": 0.00047432615481140795,
      "loss": 1.969,
      "step": 6440
    },
    {
      "epoch": 30.71599045346062,
      "grad_norm": 0.3595326840877533,
      "learning_rate": 0.0004742423136411113,
      "loss": 1.9791,
      "step": 6450
    },
    {
      "epoch": 30.763723150357997,
      "grad_norm": 0.37580832839012146,
      "learning_rate": 0.00047415834323159177,
      "loss": 1.9906,
      "step": 6460
    },
    {
      "epoch": 30.81145584725537,
      "grad_norm": 0.42316174507141113,
      "learning_rate": 0.00047407424363124495,
      "loss": 2.0041,
      "step": 6470
    },
    {
      "epoch": 30.859188544152744,
      "grad_norm": 0.4592427611351013,
      "learning_rate": 0.0004739900148885403,
      "loss": 1.9959,
      "step": 6480
    },
    {
      "epoch": 30.90692124105012,
      "grad_norm": 0.38847479224205017,
      "learning_rate": 0.0004739056570520222,
      "loss": 1.9755,
      "step": 6490
    },
    {
      "epoch": 30.954653937947494,
      "grad_norm": 0.37535080313682556,
      "learning_rate": 0.00047382117017030913,
      "loss": 1.974,
      "step": 6500
    },
    {
      "epoch": 31.0,
      "grad_norm": 0.29188457131385803,
      "learning_rate": 0.000473736554292094,
      "loss": 1.8703,
      "step": 6510
    },
    {
      "epoch": 31.0,
      "eval_loss": 1.0633569955825806,
      "eval_runtime": 4.435,
      "eval_samples_per_second": 3310.241,
      "eval_steps_per_second": 13.078,
      "step": 6510
    },
    {
      "epoch": 31.047732696897373,
      "grad_norm": 0.399953156709671,
      "learning_rate": 0.0004736518094661442,
      "loss": 1.9751,
      "step": 6520
    },
    {
      "epoch": 31.09546539379475,
      "grad_norm": 0.44982782006263733,
      "learning_rate": 0.00047356693574130115,
      "loss": 1.9861,
      "step": 6530
    },
    {
      "epoch": 31.143198090692124,
      "grad_norm": 0.3736770749092102,
      "learning_rate": 0.00047348193316648103,
      "loss": 1.9681,
      "step": 6540
    },
    {
      "epoch": 31.190930787589497,
      "grad_norm": 0.41956838965415955,
      "learning_rate": 0.0004733968017906738,
      "loss": 1.9727,
      "step": 6550
    },
    {
      "epoch": 31.238663484486874,
      "grad_norm": 0.3644246459007263,
      "learning_rate": 0.0004733115416629439,
      "loss": 1.9833,
      "step": 6560
    },
    {
      "epoch": 31.286396181384248,
      "grad_norm": 0.4243057668209076,
      "learning_rate": 0.00047322615283242986,
      "loss": 1.9665,
      "step": 6570
    },
    {
      "epoch": 31.33412887828162,
      "grad_norm": 0.38724419474601746,
      "learning_rate": 0.0004731406353483446,
      "loss": 1.982,
      "step": 6580
    },
    {
      "epoch": 31.381861575179,
      "grad_norm": 0.40494441986083984,
      "learning_rate": 0.0004730549892599749,
      "loss": 1.9816,
      "step": 6590
    },
    {
      "epoch": 31.429594272076372,
      "grad_norm": 0.46278616786003113,
      "learning_rate": 0.00047296921461668196,
      "loss": 1.9831,
      "step": 6600
    },
    {
      "epoch": 31.477326968973745,
      "grad_norm": 0.38448071479797363,
      "learning_rate": 0.00047288331146790074,
      "loss": 1.9751,
      "step": 6610
    },
    {
      "epoch": 31.525059665871122,
      "grad_norm": 0.38840848207473755,
      "learning_rate": 0.0004727972798631406,
      "loss": 1.9836,
      "step": 6620
    },
    {
      "epoch": 31.572792362768496,
      "grad_norm": 0.44036680459976196,
      "learning_rate": 0.0004727111198519846,
      "loss": 1.9682,
      "step": 6630
    },
    {
      "epoch": 31.620525059665873,
      "grad_norm": 0.389072060585022,
      "learning_rate": 0.00047262483148409007,
      "loss": 1.9826,
      "step": 6640
    },
    {
      "epoch": 31.668257756563246,
      "grad_norm": 0.3792594075202942,
      "learning_rate": 0.0004725384148091882,
      "loss": 1.9766,
      "step": 6650
    },
    {
      "epoch": 31.71599045346062,
      "grad_norm": 0.4025798439979553,
      "learning_rate": 0.0004724518698770841,
      "loss": 1.9871,
      "step": 6660
    },
    {
      "epoch": 31.763723150357997,
      "grad_norm": 0.40610092878341675,
      "learning_rate": 0.00047236519673765696,
      "loss": 1.994,
      "step": 6670
    },
    {
      "epoch": 31.81145584725537,
      "grad_norm": 0.3715648949146271,
      "learning_rate": 0.0004722783954408597,
      "loss": 1.9905,
      "step": 6680
    },
    {
      "epoch": 31.859188544152744,
      "grad_norm": 0.4110927879810333,
      "learning_rate": 0.00047219146603671904,
      "loss": 1.993,
      "step": 6690
    },
    {
      "epoch": 31.90692124105012,
      "grad_norm": 0.37021851539611816,
      "learning_rate": 0.00047210440857533583,
      "loss": 1.9814,
      "step": 6700
    },
    {
      "epoch": 31.954653937947494,
      "grad_norm": 0.4202837646007538,
      "learning_rate": 0.00047201722310688445,
      "loss": 1.9787,
      "step": 6710
    },
    {
      "epoch": 32.0,
      "grad_norm": 0.2967550754547119,
      "learning_rate": 0.000471929909681613,
      "loss": 1.8746,
      "step": 6720
    },
    {
      "epoch": 32.0,
      "eval_loss": 1.0606380701065063,
      "eval_runtime": 4.3906,
      "eval_samples_per_second": 3343.75,
      "eval_steps_per_second": 13.21,
      "step": 6720
    },
    {
      "epoch": 32.04773269689738,
      "grad_norm": 0.41668885946273804,
      "learning_rate": 0.00047184246834984376,
      "loss": 1.9831,
      "step": 6730
    },
    {
      "epoch": 32.09546539379475,
      "grad_norm": 0.43960893154144287,
      "learning_rate": 0.0004717548991619722,
      "loss": 1.9838,
      "step": 6740
    },
    {
      "epoch": 32.143198090692124,
      "grad_norm": 0.4386574625968933,
      "learning_rate": 0.00047166720216846783,
      "loss": 1.9845,
      "step": 6750
    },
    {
      "epoch": 32.1909307875895,
      "grad_norm": 0.41326409578323364,
      "learning_rate": 0.0004715793774198737,
      "loss": 1.9765,
      "step": 6760
    },
    {
      "epoch": 32.23866348448687,
      "grad_norm": 0.43199968338012695,
      "learning_rate": 0.0004714914249668064,
      "loss": 1.9716,
      "step": 6770
    },
    {
      "epoch": 32.28639618138425,
      "grad_norm": 0.402785986661911,
      "learning_rate": 0.0004714033448599563,
      "loss": 1.9623,
      "step": 6780
    },
    {
      "epoch": 32.334128878281625,
      "grad_norm": 0.41570407152175903,
      "learning_rate": 0.0004713151371500872,
      "loss": 1.9589,
      "step": 6790
    },
    {
      "epoch": 32.381861575178995,
      "grad_norm": 0.42268484830856323,
      "learning_rate": 0.0004712268018880366,
      "loss": 1.9695,
      "step": 6800
    },
    {
      "epoch": 32.42959427207637,
      "grad_norm": 0.40344488620758057,
      "learning_rate": 0.0004711383391247153,
      "loss": 1.9834,
      "step": 6810
    },
    {
      "epoch": 32.47732696897375,
      "grad_norm": 0.4586932957172394,
      "learning_rate": 0.00047104974891110774,
      "loss": 1.9869,
      "step": 6820
    },
    {
      "epoch": 32.52505966587112,
      "grad_norm": 0.4098266363143921,
      "learning_rate": 0.00047096103129827186,
      "loss": 1.9913,
      "step": 6830
    },
    {
      "epoch": 32.572792362768496,
      "grad_norm": 0.43009859323501587,
      "learning_rate": 0.00047087218633733873,
      "loss": 1.9829,
      "step": 6840
    },
    {
      "epoch": 32.62052505966587,
      "grad_norm": 0.47056207060813904,
      "learning_rate": 0.0004707832140795132,
      "loss": 1.9716,
      "step": 6850
    },
    {
      "epoch": 32.66825775656324,
      "grad_norm": 0.3831067979335785,
      "learning_rate": 0.0004706941145760732,
      "loss": 1.9947,
      "step": 6860
    },
    {
      "epoch": 32.71599045346062,
      "grad_norm": 0.3712010979652405,
      "learning_rate": 0.0004706048878783702,
      "loss": 1.9733,
      "step": 6870
    },
    {
      "epoch": 32.763723150358,
      "grad_norm": 0.4047577977180481,
      "learning_rate": 0.0004705155340378288,
      "loss": 1.9849,
      "step": 6880
    },
    {
      "epoch": 32.81145584725537,
      "grad_norm": 0.37949466705322266,
      "learning_rate": 0.00047042605310594686,
      "loss": 1.978,
      "step": 6890
    },
    {
      "epoch": 32.859188544152744,
      "grad_norm": 0.40874630212783813,
      "learning_rate": 0.00047033644513429587,
      "loss": 1.9879,
      "step": 6900
    },
    {
      "epoch": 32.90692124105012,
      "grad_norm": 0.3869785666465759,
      "learning_rate": 0.00047024671017452006,
      "loss": 1.9571,
      "step": 6910
    },
    {
      "epoch": 32.95465393794749,
      "grad_norm": 0.36898767948150635,
      "learning_rate": 0.00047015684827833695,
      "loss": 1.9808,
      "step": 6920
    },
    {
      "epoch": 33.0,
      "grad_norm": 0.2838718891143799,
      "learning_rate": 0.00047006685949753754,
      "loss": 1.883,
      "step": 6930
    },
    {
      "epoch": 33.0,
      "eval_loss": 1.061200737953186,
      "eval_runtime": 4.3795,
      "eval_samples_per_second": 3352.226,
      "eval_steps_per_second": 13.244,
      "step": 6930
    },
    {
      "epoch": 33.04773269689738,
      "grad_norm": 0.3588356077671051,
      "learning_rate": 0.0004699767438839856,
      "loss": 1.9591,
      "step": 6940
    },
    {
      "epoch": 33.09546539379475,
      "grad_norm": 0.45447778701782227,
      "learning_rate": 0.0004698865014896181,
      "loss": 1.9559,
      "step": 6950
    },
    {
      "epoch": 33.143198090692124,
      "grad_norm": 0.38870248198509216,
      "learning_rate": 0.0004697961323664451,
      "loss": 1.9588,
      "step": 6960
    },
    {
      "epoch": 33.1909307875895,
      "grad_norm": 0.44301387667655945,
      "learning_rate": 0.00046970563656654975,
      "loss": 1.9608,
      "step": 6970
    },
    {
      "epoch": 33.23866348448687,
      "grad_norm": 0.41428297758102417,
      "learning_rate": 0.00046961501414208816,
      "loss": 1.9653,
      "step": 6980
    },
    {
      "epoch": 33.28639618138425,
      "grad_norm": 0.48765894770622253,
      "learning_rate": 0.00046952426514528943,
      "loss": 1.9874,
      "step": 6990
    },
    {
      "epoch": 33.334128878281625,
      "grad_norm": 0.40375590324401855,
      "learning_rate": 0.00046943338962845553,
      "loss": 1.9681,
      "step": 7000
    },
    {
      "epoch": 33.381861575178995,
      "grad_norm": 0.3872358798980713,
      "learning_rate": 0.0004693423876439615,
      "loss": 1.9704,
      "step": 7010
    },
    {
      "epoch": 33.42959427207637,
      "grad_norm": 0.41059041023254395,
      "learning_rate": 0.00046925125924425514,
      "loss": 1.9727,
      "step": 7020
    },
    {
      "epoch": 33.47732696897375,
      "grad_norm": 0.5233047008514404,
      "learning_rate": 0.00046916000448185715,
      "loss": 1.9848,
      "step": 7030
    },
    {
      "epoch": 33.52505966587112,
      "grad_norm": 0.39542555809020996,
      "learning_rate": 0.0004690686234093611,
      "loss": 1.9705,
      "step": 7040
    },
    {
      "epoch": 33.572792362768496,
      "grad_norm": 0.39869028329849243,
      "learning_rate": 0.0004689771160794332,
      "loss": 1.985,
      "step": 7050
    },
    {
      "epoch": 33.62052505966587,
      "grad_norm": 0.3913992941379547,
      "learning_rate": 0.0004688854825448127,
      "loss": 1.9642,
      "step": 7060
    },
    {
      "epoch": 33.66825775656324,
      "grad_norm": 0.4394989013671875,
      "learning_rate": 0.00046879372285831125,
      "loss": 1.9811,
      "step": 7070
    },
    {
      "epoch": 33.71599045346062,
      "grad_norm": 0.42559748888015747,
      "learning_rate": 0.00046870183707281354,
      "loss": 1.9815,
      "step": 7080
    },
    {
      "epoch": 33.763723150358,
      "grad_norm": 0.38749080896377563,
      "learning_rate": 0.0004686098252412768,
      "loss": 1.9772,
      "step": 7090
    },
    {
      "epoch": 33.81145584725537,
      "grad_norm": 0.42137253284454346,
      "learning_rate": 0.00046851768741673074,
      "loss": 1.9712,
      "step": 7100
    },
    {
      "epoch": 33.859188544152744,
      "grad_norm": 0.4286211431026459,
      "learning_rate": 0.00046842542365227793,
      "loss": 1.9665,
      "step": 7110
    },
    {
      "epoch": 33.90692124105012,
      "grad_norm": 0.4765039384365082,
      "learning_rate": 0.00046833303400109326,
      "loss": 1.9857,
      "step": 7120
    },
    {
      "epoch": 33.95465393794749,
      "grad_norm": 0.4103729724884033,
      "learning_rate": 0.0004682405185164247,
      "loss": 1.983,
      "step": 7130
    },
    {
      "epoch": 34.0,
      "grad_norm": 0.2922306954860687,
      "learning_rate": 0.00046814787725159204,
      "loss": 1.8872,
      "step": 7140
    },
    {
      "epoch": 34.0,
      "eval_loss": 1.0560040473937988,
      "eval_runtime": 4.4088,
      "eval_samples_per_second": 3329.919,
      "eval_steps_per_second": 13.155,
      "step": 7140
    },
    {
      "epoch": 34.04773269689738,
      "grad_norm": 0.4379071891307831,
      "learning_rate": 0.00046805511025998803,
      "loss": 1.9707,
      "step": 7150
    },
    {
      "epoch": 34.09546539379475,
      "grad_norm": 0.698220431804657,
      "learning_rate": 0.00046796221759507774,
      "loss": 1.9661,
      "step": 7160
    },
    {
      "epoch": 34.143198090692124,
      "grad_norm": 0.4632558524608612,
      "learning_rate": 0.00046786919931039863,
      "loss": 1.9667,
      "step": 7170
    },
    {
      "epoch": 34.1909307875895,
      "grad_norm": 0.4298354685306549,
      "learning_rate": 0.0004677760554595607,
      "loss": 1.9786,
      "step": 7180
    },
    {
      "epoch": 34.23866348448687,
      "grad_norm": 0.4185296893119812,
      "learning_rate": 0.0004676827860962463,
      "loss": 1.9858,
      "step": 7190
    },
    {
      "epoch": 34.28639618138425,
      "grad_norm": 0.3828994929790497,
      "learning_rate": 0.0004675893912742098,
      "loss": 1.9495,
      "step": 7200
    },
    {
      "epoch": 34.334128878281625,
      "grad_norm": 0.4287359118461609,
      "learning_rate": 0.0004674958710472783,
      "loss": 1.9693,
      "step": 7210
    },
    {
      "epoch": 34.381861575178995,
      "grad_norm": 0.4347655177116394,
      "learning_rate": 0.00046740222546935104,
      "loss": 1.9698,
      "step": 7220
    },
    {
      "epoch": 34.42959427207637,
      "grad_norm": 0.4351155161857605,
      "learning_rate": 0.0004673084545943993,
      "loss": 1.9735,
      "step": 7230
    },
    {
      "epoch": 34.47732696897375,
      "grad_norm": 0.44775867462158203,
      "learning_rate": 0.0004672145584764669,
      "loss": 1.9607,
      "step": 7240
    },
    {
      "epoch": 34.52505966587112,
      "grad_norm": 0.3920242190361023,
      "learning_rate": 0.0004671205371696696,
      "loss": 1.9682,
      "step": 7250
    },
    {
      "epoch": 34.572792362768496,
      "grad_norm": 0.4491819739341736,
      "learning_rate": 0.0004670263907281954,
      "loss": 1.974,
      "step": 7260
    },
    {
      "epoch": 34.62052505966587,
      "grad_norm": 0.3902326226234436,
      "learning_rate": 0.0004669321192063045,
      "loss": 1.9699,
      "step": 7270
    },
    {
      "epoch": 34.66825775656324,
      "grad_norm": 0.4250607192516327,
      "learning_rate": 0.0004668377226583289,
      "loss": 1.9826,
      "step": 7280
    },
    {
      "epoch": 34.71599045346062,
      "grad_norm": 0.3658389747142792,
      "learning_rate": 0.00046674320113867303,
      "loss": 1.984,
      "step": 7290
    },
    {
      "epoch": 34.763723150358,
      "grad_norm": 0.4630069434642792,
      "learning_rate": 0.00046664855470181314,
      "loss": 1.9722,
      "step": 7300
    },
    {
      "epoch": 34.81145584725537,
      "grad_norm": 0.36104074120521545,
      "learning_rate": 0.00046655378340229744,
      "loss": 1.9731,
      "step": 7310
    },
    {
      "epoch": 34.859188544152744,
      "grad_norm": 0.43666261434555054,
      "learning_rate": 0.0004664588872947462,
      "loss": 1.979,
      "step": 7320
    },
    {
      "epoch": 34.90692124105012,
      "grad_norm": 0.4030912220478058,
      "learning_rate": 0.00046636386643385166,
      "loss": 1.9771,
      "step": 7330
    },
    {
      "epoch": 34.95465393794749,
      "grad_norm": 0.457909494638443,
      "learning_rate": 0.00046626872087437776,
      "loss": 1.9812,
      "step": 7340
    },
    {
      "epoch": 35.0,
      "grad_norm": 0.30424076318740845,
      "learning_rate": 0.0004661734506711606,
      "loss": 1.8791,
      "step": 7350
    },
    {
      "epoch": 35.0,
      "eval_loss": 1.0570725202560425,
      "eval_runtime": 4.416,
      "eval_samples_per_second": 3324.523,
      "eval_steps_per_second": 13.134,
      "step": 7350
    },
    {
      "epoch": 35.04773269689738,
      "grad_norm": 0.43415310978889465,
      "learning_rate": 0.0004660780558791079,
      "loss": 1.9543,
      "step": 7360
    },
    {
      "epoch": 35.09546539379475,
      "grad_norm": 0.4213113784790039,
      "learning_rate": 0.0004659825365531991,
      "loss": 1.978,
      "step": 7370
    },
    {
      "epoch": 35.143198090692124,
      "grad_norm": 0.4227789044380188,
      "learning_rate": 0.0004658868927484858,
      "loss": 1.9562,
      "step": 7380
    },
    {
      "epoch": 35.1909307875895,
      "grad_norm": 0.44255053997039795,
      "learning_rate": 0.00046579112452009087,
      "loss": 1.9553,
      "step": 7390
    },
    {
      "epoch": 35.23866348448687,
      "grad_norm": 0.390239953994751,
      "learning_rate": 0.0004656952319232093,
      "loss": 1.9766,
      "step": 7400
    },
    {
      "epoch": 35.28639618138425,
      "grad_norm": 0.601814866065979,
      "learning_rate": 0.0004655992150131075,
      "loss": 1.9614,
      "step": 7410
    },
    {
      "epoch": 35.334128878281625,
      "grad_norm": 0.42202994227409363,
      "learning_rate": 0.00046550307384512357,
      "loss": 1.9847,
      "step": 7420
    },
    {
      "epoch": 35.381861575178995,
      "grad_norm": 0.49751830101013184,
      "learning_rate": 0.0004654068084746673,
      "loss": 1.9894,
      "step": 7430
    },
    {
      "epoch": 35.42959427207637,
      "grad_norm": 0.4064485728740692,
      "learning_rate": 0.0004653104189572199,
      "loss": 1.9606,
      "step": 7440
    },
    {
      "epoch": 35.47732696897375,
      "grad_norm": 0.3973292112350464,
      "learning_rate": 0.0004652139053483345,
      "loss": 1.9655,
      "step": 7450
    },
    {
      "epoch": 35.52505966587112,
      "grad_norm": 0.4024481475353241,
      "learning_rate": 0.0004651172677036353,
      "loss": 1.9648,
      "step": 7460
    },
    {
      "epoch": 35.572792362768496,
      "grad_norm": 0.3686107397079468,
      "learning_rate": 0.00046502050607881825,
      "loss": 1.9666,
      "step": 7470
    },
    {
      "epoch": 35.62052505966587,
      "grad_norm": 0.4636234939098358,
      "learning_rate": 0.0004649236205296507,
      "loss": 1.9643,
      "step": 7480
    },
    {
      "epoch": 35.66825775656324,
      "grad_norm": 0.3914010524749756,
      "learning_rate": 0.00046482661111197135,
      "loss": 1.963,
      "step": 7490
    },
    {
      "epoch": 35.71599045346062,
      "grad_norm": 0.4485487639904022,
      "learning_rate": 0.0004647294778816904,
      "loss": 1.974,
      "step": 7500
    },
    {
      "epoch": 35.763723150358,
      "grad_norm": 0.4126048982143402,
      "learning_rate": 0.00046463222089478936,
      "loss": 1.9662,
      "step": 7510
    },
    {
      "epoch": 35.81145584725537,
      "grad_norm": 0.403148889541626,
      "learning_rate": 0.00046453484020732104,
      "loss": 1.9627,
      "step": 7520
    },
    {
      "epoch": 35.859188544152744,
      "grad_norm": 0.48974138498306274,
      "learning_rate": 0.00046443733587540957,
      "loss": 1.9882,
      "step": 7530
    },
    {
      "epoch": 35.90692124105012,
      "grad_norm": 0.4023936986923218,
      "learning_rate": 0.0004643397079552504,
      "loss": 1.9612,
      "step": 7540
    },
    {
      "epoch": 35.95465393794749,
      "grad_norm": 0.3601970076560974,
      "learning_rate": 0.00046424195650311006,
      "loss": 1.9749,
      "step": 7550
    },
    {
      "epoch": 36.0,
      "grad_norm": 0.30834680795669556,
      "learning_rate": 0.0004641440815753264,
      "loss": 1.8717,
      "step": 7560
    },
    {
      "epoch": 36.0,
      "eval_loss": 1.0550528764724731,
      "eval_runtime": 4.4136,
      "eval_samples_per_second": 3326.286,
      "eval_steps_per_second": 13.141,
      "step": 7560
    },
    {
      "epoch": 36.04773269689738,
      "grad_norm": 0.39438897371292114,
      "learning_rate": 0.00046404608322830844,
      "loss": 1.9766,
      "step": 7570
    },
    {
      "epoch": 36.09546539379475,
      "grad_norm": 0.4099855422973633,
      "learning_rate": 0.00046394796151853627,
      "loss": 1.957,
      "step": 7580
    },
    {
      "epoch": 36.143198090692124,
      "grad_norm": 0.487314373254776,
      "learning_rate": 0.000463849716502561,
      "loss": 1.946,
      "step": 7590
    },
    {
      "epoch": 36.1909307875895,
      "grad_norm": 0.42043575644493103,
      "learning_rate": 0.000463751348237005,
      "loss": 1.9649,
      "step": 7600
    },
    {
      "epoch": 36.23866348448687,
      "grad_norm": 0.43700864911079407,
      "learning_rate": 0.0004636528567785616,
      "loss": 1.9584,
      "step": 7610
    },
    {
      "epoch": 36.28639618138425,
      "grad_norm": 0.41670385003089905,
      "learning_rate": 0.000463554242183995,
      "loss": 1.9672,
      "step": 7620
    },
    {
      "epoch": 36.334128878281625,
      "grad_norm": 0.4372159242630005,
      "learning_rate": 0.00046345550451014063,
      "loss": 1.9508,
      "step": 7630
    },
    {
      "epoch": 36.381861575178995,
      "grad_norm": 0.4313116669654846,
      "learning_rate": 0.00046335664381390453,
      "loss": 1.9746,
      "step": 7640
    },
    {
      "epoch": 36.42959427207637,
      "grad_norm": 0.4783361554145813,
      "learning_rate": 0.00046325766015226387,
      "loss": 1.9721,
      "step": 7650
    },
    {
      "epoch": 36.47732696897375,
      "grad_norm": 0.4291263818740845,
      "learning_rate": 0.00046315855358226675,
      "loss": 1.9661,
      "step": 7660
    },
    {
      "epoch": 36.52505966587112,
      "grad_norm": 0.4249700903892517,
      "learning_rate": 0.0004630593241610318,
      "loss": 1.9634,
      "step": 7670
    },
    {
      "epoch": 36.572792362768496,
      "grad_norm": 0.5889187455177307,
      "learning_rate": 0.0004629599719457488,
      "loss": 1.9706,
      "step": 7680
    },
    {
      "epoch": 36.62052505966587,
      "grad_norm": 0.43427637219429016,
      "learning_rate": 0.00046286049699367803,
      "loss": 1.9662,
      "step": 7690
    },
    {
      "epoch": 36.66825775656324,
      "grad_norm": 0.5398543477058411,
      "learning_rate": 0.0004627608993621507,
      "loss": 1.9662,
      "step": 7700
    },
    {
      "epoch": 36.71599045346062,
      "grad_norm": 0.40558499097824097,
      "learning_rate": 0.00046266117910856864,
      "loss": 1.979,
      "step": 7710
    },
    {
      "epoch": 36.763723150358,
      "grad_norm": 0.42061445116996765,
      "learning_rate": 0.00046256133629040433,
      "loss": 1.9665,
      "step": 7720
    },
    {
      "epoch": 36.81145584725537,
      "grad_norm": 0.41132238507270813,
      "learning_rate": 0.00046246137096520083,
      "loss": 1.9648,
      "step": 7730
    },
    {
      "epoch": 36.859188544152744,
      "grad_norm": 0.3886338174343109,
      "learning_rate": 0.00046236128319057207,
      "loss": 1.9723,
      "step": 7740
    },
    {
      "epoch": 36.90692124105012,
      "grad_norm": 0.4113054871559143,
      "learning_rate": 0.0004622610730242023,
      "loss": 1.9602,
      "step": 7750
    },
    {
      "epoch": 36.95465393794749,
      "grad_norm": 0.4452650845050812,
      "learning_rate": 0.00046216074052384627,
      "loss": 1.968,
      "step": 7760
    },
    {
      "epoch": 37.0,
      "grad_norm": 0.30119872093200684,
      "learning_rate": 0.0004620602857473295,
      "loss": 1.8771,
      "step": 7770
    },
    {
      "epoch": 37.0,
      "eval_loss": 1.0584548711776733,
      "eval_runtime": 4.3801,
      "eval_samples_per_second": 3351.772,
      "eval_steps_per_second": 13.242,
      "step": 7770
    },
    {
      "epoch": 37.04773269689738,
      "grad_norm": 0.4548887610435486,
      "learning_rate": 0.00046195970875254777,
      "loss": 1.9516,
      "step": 7780
    },
    {
      "epoch": 37.09546539379475,
      "grad_norm": 0.4436338543891907,
      "learning_rate": 0.00046185900959746736,
      "loss": 1.9596,
      "step": 7790
    },
    {
      "epoch": 37.143198090692124,
      "grad_norm": 0.3995225131511688,
      "learning_rate": 0.00046175818834012496,
      "loss": 1.9619,
      "step": 7800
    },
    {
      "epoch": 37.1909307875895,
      "grad_norm": 0.4260985255241394,
      "learning_rate": 0.0004616572450386276,
      "loss": 1.9625,
      "step": 7810
    },
    {
      "epoch": 37.23866348448687,
      "grad_norm": 0.4443005621433258,
      "learning_rate": 0.0004615561797511528,
      "loss": 1.9622,
      "step": 7820
    },
    {
      "epoch": 37.28639618138425,
      "grad_norm": 0.390662282705307,
      "learning_rate": 0.00046145499253594805,
      "loss": 1.9596,
      "step": 7830
    },
    {
      "epoch": 37.334128878281625,
      "grad_norm": 0.393748015165329,
      "learning_rate": 0.0004613536834513315,
      "loss": 1.966,
      "step": 7840
    },
    {
      "epoch": 37.381861575178995,
      "grad_norm": 0.41299834847450256,
      "learning_rate": 0.00046125225255569125,
      "loss": 1.969,
      "step": 7850
    },
    {
      "epoch": 37.42959427207637,
      "grad_norm": 0.3944969177246094,
      "learning_rate": 0.0004611506999074858,
      "loss": 1.9639,
      "step": 7860
    },
    {
      "epoch": 37.47732696897375,
      "grad_norm": 0.427068293094635,
      "learning_rate": 0.00046104902556524366,
      "loss": 1.9592,
      "step": 7870
    },
    {
      "epoch": 37.52505966587112,
      "grad_norm": 0.360785573720932,
      "learning_rate": 0.00046094722958756366,
      "loss": 1.9624,
      "step": 7880
    },
    {
      "epoch": 37.572792362768496,
      "grad_norm": 0.38737213611602783,
      "learning_rate": 0.00046084531203311455,
      "loss": 1.9614,
      "step": 7890
    },
    {
      "epoch": 37.62052505966587,
      "grad_norm": 0.39869093894958496,
      "learning_rate": 0.0004607432729606351,
      "loss": 1.9635,
      "step": 7900
    },
    {
      "epoch": 37.66825775656324,
      "grad_norm": 0.40252014994621277,
      "learning_rate": 0.00046064111242893446,
      "loss": 1.957,
      "step": 7910
    },
    {
      "epoch": 37.71599045346062,
      "grad_norm": 0.36948108673095703,
      "learning_rate": 0.00046053883049689145,
      "loss": 1.9673,
      "step": 7920
    },
    {
      "epoch": 37.763723150358,
      "grad_norm": 0.39438483119010925,
      "learning_rate": 0.00046043642722345496,
      "loss": 1.9662,
      "step": 7930
    },
    {
      "epoch": 37.81145584725537,
      "grad_norm": 0.4096459746360779,
      "learning_rate": 0.0004603339026676439,
      "loss": 1.9517,
      "step": 7940
    },
    {
      "epoch": 37.859188544152744,
      "grad_norm": 0.3989003300666809,
      "learning_rate": 0.00046023125688854697,
      "loss": 1.97,
      "step": 7950
    },
    {
      "epoch": 37.90692124105012,
      "grad_norm": 0.44140252470970154,
      "learning_rate": 0.0004601284899453226,
      "loss": 1.9547,
      "step": 7960
    },
    {
      "epoch": 37.95465393794749,
      "grad_norm": 0.38323667645454407,
      "learning_rate": 0.00046002560189719954,
      "loss": 1.9752,
      "step": 7970
    },
    {
      "epoch": 38.0,
      "grad_norm": 0.3565889894962311,
      "learning_rate": 0.0004599225928034757,
      "loss": 1.8827,
      "step": 7980
    },
    {
      "epoch": 38.0,
      "eval_loss": 1.0578898191452026,
      "eval_runtime": 4.4134,
      "eval_samples_per_second": 3326.434,
      "eval_steps_per_second": 13.142,
      "step": 7980
    },
    {
      "epoch": 38.04773269689738,
      "grad_norm": 0.4487173557281494,
      "learning_rate": 0.0004598194627235193,
      "loss": 1.9475,
      "step": 7990
    },
    {
      "epoch": 38.09546539379475,
      "grad_norm": 0.40002521872520447,
      "learning_rate": 0.00045971621171676797,
      "loss": 1.9559,
      "step": 8000
    },
    {
      "epoch": 38.143198090692124,
      "grad_norm": 0.39689716696739197,
      "learning_rate": 0.0004596128398427291,
      "loss": 1.9579,
      "step": 8010
    },
    {
      "epoch": 38.1909307875895,
      "grad_norm": 0.41469210386276245,
      "learning_rate": 0.00045950934716097974,
      "loss": 1.9589,
      "step": 8020
    },
    {
      "epoch": 38.23866348448687,
      "grad_norm": 0.3981187641620636,
      "learning_rate": 0.00045940573373116667,
      "loss": 1.9524,
      "step": 8030
    },
    {
      "epoch": 38.28639618138425,
      "grad_norm": 0.42143672704696655,
      "learning_rate": 0.00045930199961300615,
      "loss": 1.9654,
      "step": 8040
    },
    {
      "epoch": 38.334128878281625,
      "grad_norm": 0.3980424702167511,
      "learning_rate": 0.000459198144866284,
      "loss": 1.9622,
      "step": 8050
    },
    {
      "epoch": 38.381861575178995,
      "grad_norm": 0.43546000123023987,
      "learning_rate": 0.0004590941695508556,
      "loss": 1.9629,
      "step": 8060
    },
    {
      "epoch": 38.42959427207637,
      "grad_norm": 0.452338844537735,
      "learning_rate": 0.00045899007372664593,
      "loss": 1.9632,
      "step": 8070
    },
    {
      "epoch": 38.47732696897375,
      "grad_norm": 0.3968997597694397,
      "learning_rate": 0.00045888585745364907,
      "loss": 1.9665,
      "step": 8080
    },
    {
      "epoch": 38.52505966587112,
      "grad_norm": 0.4247469902038574,
      "learning_rate": 0.0004587815207919289,
      "loss": 1.9621,
      "step": 8090
    },
    {
      "epoch": 38.572792362768496,
      "grad_norm": 0.3771016299724579,
      "learning_rate": 0.0004586770638016185,
      "loss": 1.9619,
      "step": 8100
    },
    {
      "epoch": 38.62052505966587,
      "grad_norm": 0.3677908778190613,
      "learning_rate": 0.0004585724865429204,
      "loss": 1.9624,
      "step": 8110
    },
    {
      "epoch": 38.66825775656324,
      "grad_norm": 0.35539883375167847,
      "learning_rate": 0.00045846778907610627,
      "loss": 1.9664,
      "step": 8120
    },
    {
      "epoch": 38.71599045346062,
      "grad_norm": 0.40252062678337097,
      "learning_rate": 0.0004583629714615172,
      "loss": 1.9599,
      "step": 8130
    },
    {
      "epoch": 38.763723150358,
      "grad_norm": 0.376094251871109,
      "learning_rate": 0.0004582580337595636,
      "loss": 1.9705,
      "step": 8140
    },
    {
      "epoch": 38.81145584725537,
      "grad_norm": 0.42281240224838257,
      "learning_rate": 0.0004581529760307249,
      "loss": 1.9551,
      "step": 8150
    },
    {
      "epoch": 38.859188544152744,
      "grad_norm": 0.38511598110198975,
      "learning_rate": 0.0004580477983355498,
      "loss": 1.9697,
      "step": 8160
    },
    {
      "epoch": 38.90692124105012,
      "grad_norm": 0.39520788192749023,
      "learning_rate": 0.0004579425007346561,
      "loss": 1.9579,
      "step": 8170
    },
    {
      "epoch": 38.95465393794749,
      "grad_norm": 0.4347715675830841,
      "learning_rate": 0.0004578370832887308,
      "loss": 1.9647,
      "step": 8180
    },
    {
      "epoch": 39.0,
      "grad_norm": 0.3792418837547302,
      "learning_rate": 0.00045773154605852995,
      "loss": 1.8655,
      "step": 8190
    },
    {
      "epoch": 39.0,
      "eval_loss": 1.0567193031311035,
      "eval_runtime": 4.5678,
      "eval_samples_per_second": 3213.986,
      "eval_steps_per_second": 12.697,
      "step": 8190
    },
    {
      "epoch": 39.04773269689738,
      "grad_norm": 0.37226587533950806,
      "learning_rate": 0.00045762588910487845,
      "loss": 1.9473,
      "step": 8200
    },
    {
      "epoch": 39.09546539379475,
      "grad_norm": 0.3687986731529236,
      "learning_rate": 0.0004575201124886705,
      "loss": 1.9513,
      "step": 8210
    },
    {
      "epoch": 39.143198090692124,
      "grad_norm": 0.4004983603954315,
      "learning_rate": 0.00045741421627086906,
      "loss": 1.9543,
      "step": 8220
    },
    {
      "epoch": 39.1909307875895,
      "grad_norm": 0.43306493759155273,
      "learning_rate": 0.00045730820051250603,
      "loss": 1.9433,
      "step": 8230
    },
    {
      "epoch": 39.23866348448687,
      "grad_norm": 0.39195388555526733,
      "learning_rate": 0.00045720206527468234,
      "loss": 1.9438,
      "step": 8240
    },
    {
      "epoch": 39.28639618138425,
      "grad_norm": 0.3496376574039459,
      "learning_rate": 0.00045709581061856763,
      "loss": 1.9515,
      "step": 8250
    },
    {
      "epoch": 39.334128878281625,
      "grad_norm": 0.3820301294326782,
      "learning_rate": 0.00045698943660540047,
      "loss": 1.9538,
      "step": 8260
    },
    {
      "epoch": 39.381861575178995,
      "grad_norm": 0.362176775932312,
      "learning_rate": 0.00045688294329648816,
      "loss": 1.9626,
      "step": 8270
    },
    {
      "epoch": 39.42959427207637,
      "grad_norm": 0.5065898895263672,
      "learning_rate": 0.00045677633075320677,
      "loss": 1.9687,
      "step": 8280
    },
    {
      "epoch": 39.47732696897375,
      "grad_norm": 0.42775577306747437,
      "learning_rate": 0.00045666959903700103,
      "loss": 1.9533,
      "step": 8290
    },
    {
      "epoch": 39.52505966587112,
      "grad_norm": 0.38851943612098694,
      "learning_rate": 0.0004565627482093845,
      "loss": 1.9585,
      "step": 8300
    },
    {
      "epoch": 39.572792362768496,
      "grad_norm": 0.4107118248939514,
      "learning_rate": 0.00045645577833193935,
      "loss": 1.9561,
      "step": 8310
    },
    {
      "epoch": 39.62052505966587,
      "grad_norm": 0.38698723912239075,
      "learning_rate": 0.0004563486894663162,
      "loss": 1.9627,
      "step": 8320
    },
    {
      "epoch": 39.66825775656324,
      "grad_norm": 0.3837272524833679,
      "learning_rate": 0.0004562414816742344,
      "loss": 1.9645,
      "step": 8330
    },
    {
      "epoch": 39.71599045346062,
      "grad_norm": 0.4220168888568878,
      "learning_rate": 0.0004561341550174818,
      "loss": 1.9734,
      "step": 8340
    },
    {
      "epoch": 39.763723150358,
      "grad_norm": 0.3574896454811096,
      "learning_rate": 0.0004560267095579148,
      "loss": 1.9663,
      "step": 8350
    },
    {
      "epoch": 39.81145584725537,
      "grad_norm": 0.417605459690094,
      "learning_rate": 0.0004559191453574582,
      "loss": 1.9701,
      "step": 8360
    },
    {
      "epoch": 39.859188544152744,
      "grad_norm": 0.359840989112854,
      "learning_rate": 0.00045581146247810527,
      "loss": 1.9495,
      "step": 8370
    },
    {
      "epoch": 39.90692124105012,
      "grad_norm": 0.3814852833747864,
      "learning_rate": 0.00045570366098191776,
      "loss": 1.9518,
      "step": 8380
    },
    {
      "epoch": 39.95465393794749,
      "grad_norm": 0.38574451208114624,
      "learning_rate": 0.0004555957409310255,
      "loss": 1.9581,
      "step": 8390
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.3110145330429077,
      "learning_rate": 0.00045548770238762704,
      "loss": 1.8524,
      "step": 8400
    },
    {
      "epoch": 40.0,
      "eval_loss": 1.05640709400177,
      "eval_runtime": 4.3981,
      "eval_samples_per_second": 3338.009,
      "eval_steps_per_second": 13.187,
      "step": 8400
    },
    {
      "epoch": 40.04773269689738,
      "grad_norm": 0.4746358096599579,
      "learning_rate": 0.0004553795454139889,
      "loss": 1.9386,
      "step": 8410
    },
    {
      "epoch": 40.09546539379475,
      "grad_norm": 0.36042800545692444,
      "learning_rate": 0.00045527127007244605,
      "loss": 1.9527,
      "step": 8420
    },
    {
      "epoch": 40.143198090692124,
      "grad_norm": 0.42709267139434814,
      "learning_rate": 0.00045516287642540166,
      "loss": 1.9423,
      "step": 8430
    },
    {
      "epoch": 40.1909307875895,
      "grad_norm": 0.3862525224685669,
      "learning_rate": 0.000455054364535327,
      "loss": 1.9308,
      "step": 8440
    },
    {
      "epoch": 40.23866348448687,
      "grad_norm": 0.44010284543037415,
      "learning_rate": 0.0004549457344647615,
      "loss": 1.942,
      "step": 8450
    },
    {
      "epoch": 40.28639618138425,
      "grad_norm": 0.4335061013698578,
      "learning_rate": 0.00045483698627631265,
      "loss": 1.9561,
      "step": 8460
    },
    {
      "epoch": 40.334128878281625,
      "grad_norm": 0.39659345149993896,
      "learning_rate": 0.0004547281200326563,
      "loss": 1.9572,
      "step": 8470
    },
    {
      "epoch": 40.381861575178995,
      "grad_norm": 0.4633249342441559,
      "learning_rate": 0.00045461913579653593,
      "loss": 1.9559,
      "step": 8480
    },
    {
      "epoch": 40.42959427207637,
      "grad_norm": 0.37421250343322754,
      "learning_rate": 0.00045451003363076336,
      "loss": 1.9745,
      "step": 8490
    },
    {
      "epoch": 40.47732696897375,
      "grad_norm": 0.3617387115955353,
      "learning_rate": 0.0004544008135982182,
      "loss": 1.9566,
      "step": 8500
    },
    {
      "epoch": 40.52505966587112,
      "grad_norm": 0.36787816882133484,
      "learning_rate": 0.000454291475761848,
      "loss": 1.9592,
      "step": 8510
    },
    {
      "epoch": 40.572792362768496,
      "grad_norm": 0.39537402987480164,
      "learning_rate": 0.00045418202018466825,
      "loss": 1.9634,
      "step": 8520
    },
    {
      "epoch": 40.62052505966587,
      "grad_norm": 0.3746778666973114,
      "learning_rate": 0.0004540724469297624,
      "loss": 1.9533,
      "step": 8530
    },
    {
      "epoch": 40.66825775656324,
      "grad_norm": 0.36999842524528503,
      "learning_rate": 0.00045396275606028147,
      "loss": 1.9574,
      "step": 8540
    },
    {
      "epoch": 40.71599045346062,
      "grad_norm": 0.3903273642063141,
      "learning_rate": 0.0004538529476394444,
      "loss": 1.9559,
      "step": 8550
    },
    {
      "epoch": 40.763723150358,
      "grad_norm": 0.3952668607234955,
      "learning_rate": 0.00045374302173053805,
      "loss": 1.9645,
      "step": 8560
    },
    {
      "epoch": 40.81145584725537,
      "grad_norm": 0.41303038597106934,
      "learning_rate": 0.00045363297839691664,
      "loss": 1.9605,
      "step": 8570
    },
    {
      "epoch": 40.859188544152744,
      "grad_norm": 0.4100685119628906,
      "learning_rate": 0.00045352281770200234,
      "loss": 1.946,
      "step": 8580
    },
    {
      "epoch": 40.90692124105012,
      "grad_norm": 0.39909234642982483,
      "learning_rate": 0.00045341253970928485,
      "loss": 1.9707,
      "step": 8590
    },
    {
      "epoch": 40.95465393794749,
      "grad_norm": 0.36459267139434814,
      "learning_rate": 0.00045330214448232155,
      "loss": 1.9468,
      "step": 8600
    },
    {
      "epoch": 41.0,
      "grad_norm": 0.2722196877002716,
      "learning_rate": 0.00045319163208473734,
      "loss": 1.8596,
      "step": 8610
    },
    {
      "epoch": 41.0,
      "eval_loss": 1.0546443462371826,
      "eval_runtime": 4.3952,
      "eval_samples_per_second": 3340.273,
      "eval_steps_per_second": 13.196,
      "step": 8610
    },
    {
      "epoch": 41.04773269689738,
      "grad_norm": 0.4581820070743561,
      "learning_rate": 0.00045308100258022453,
      "loss": 1.9643,
      "step": 8620
    },
    {
      "epoch": 41.09546539379475,
      "grad_norm": 0.3601738214492798,
      "learning_rate": 0.00045297025603254317,
      "loss": 1.9716,
      "step": 8630
    },
    {
      "epoch": 41.143198090692124,
      "grad_norm": 0.38376355171203613,
      "learning_rate": 0.00045285939250552055,
      "loss": 1.9509,
      "step": 8640
    },
    {
      "epoch": 41.1909307875895,
      "grad_norm": 0.40694087743759155,
      "learning_rate": 0.00045274841206305143,
      "loss": 1.9532,
      "step": 8650
    },
    {
      "epoch": 41.23866348448687,
      "grad_norm": 0.46925029158592224,
      "learning_rate": 0.0004526373147690981,
      "loss": 1.9543,
      "step": 8660
    },
    {
      "epoch": 41.28639618138425,
      "grad_norm": 0.4768635332584381,
      "learning_rate": 0.00045252610068769,
      "loss": 1.9529,
      "step": 8670
    },
    {
      "epoch": 41.334128878281625,
      "grad_norm": 0.40867018699645996,
      "learning_rate": 0.00045241476988292395,
      "loss": 1.9395,
      "step": 8680
    },
    {
      "epoch": 41.381861575178995,
      "grad_norm": 0.4616222381591797,
      "learning_rate": 0.0004523033224189641,
      "loss": 1.9431,
      "step": 8690
    },
    {
      "epoch": 41.42959427207637,
      "grad_norm": 0.3881088197231293,
      "learning_rate": 0.00045219175836004176,
      "loss": 1.9549,
      "step": 8700
    },
    {
      "epoch": 41.47732696897375,
      "grad_norm": 0.38770219683647156,
      "learning_rate": 0.0004520800777704555,
      "loss": 1.9537,
      "step": 8710
    },
    {
      "epoch": 41.52505966587112,
      "grad_norm": 0.4354257583618164,
      "learning_rate": 0.00045196828071457097,
      "loss": 1.9384,
      "step": 8720
    },
    {
      "epoch": 41.572792362768496,
      "grad_norm": 0.37751367688179016,
      "learning_rate": 0.00045185636725682103,
      "loss": 1.9561,
      "step": 8730
    },
    {
      "epoch": 41.62052505966587,
      "grad_norm": 0.4444482922554016,
      "learning_rate": 0.00045174433746170557,
      "loss": 1.9565,
      "step": 8740
    },
    {
      "epoch": 41.66825775656324,
      "grad_norm": 0.4506610333919525,
      "learning_rate": 0.00045163219139379154,
      "loss": 1.9519,
      "step": 8750
    },
    {
      "epoch": 41.71599045346062,
      "grad_norm": 0.42645809054374695,
      "learning_rate": 0.0004515199291177129,
      "loss": 1.948,
      "step": 8760
    },
    {
      "epoch": 41.763723150358,
      "grad_norm": 0.42162802815437317,
      "learning_rate": 0.0004514075506981706,
      "loss": 1.9461,
      "step": 8770
    },
    {
      "epoch": 41.81145584725537,
      "grad_norm": 0.43513670563697815,
      "learning_rate": 0.0004512950561999325,
      "loss": 1.9601,
      "step": 8780
    },
    {
      "epoch": 41.859188544152744,
      "grad_norm": 0.4069511294364929,
      "learning_rate": 0.0004511824456878334,
      "loss": 1.9423,
      "step": 8790
    },
    {
      "epoch": 41.90692124105012,
      "grad_norm": 0.40204307436943054,
      "learning_rate": 0.000451069719226775,
      "loss": 1.9513,
      "step": 8800
    },
    {
      "epoch": 41.95465393794749,
      "grad_norm": 0.4238857924938202,
      "learning_rate": 0.00045095687688172573,
      "loss": 1.9626,
      "step": 8810
    },
    {
      "epoch": 42.0,
      "grad_norm": 0.368556946516037,
      "learning_rate": 0.0004508439187177208,
      "loss": 1.8614,
      "step": 8820
    },
    {
      "epoch": 42.0,
      "eval_loss": 1.0584832429885864,
      "eval_runtime": 4.3799,
      "eval_samples_per_second": 3351.908,
      "eval_steps_per_second": 13.242,
      "step": 8820
    },
    {
      "epoch": 42.04773269689738,
      "grad_norm": 0.3972354233264923,
      "learning_rate": 0.00045073084479986227,
      "loss": 1.9584,
      "step": 8830
    },
    {
      "epoch": 42.09546539379475,
      "grad_norm": 0.43696263432502747,
      "learning_rate": 0.00045061765519331887,
      "loss": 1.9473,
      "step": 8840
    },
    {
      "epoch": 42.143198090692124,
      "grad_norm": 0.5126162171363831,
      "learning_rate": 0.000450504349963326,
      "loss": 1.9529,
      "step": 8850
    },
    {
      "epoch": 42.1909307875895,
      "grad_norm": 0.4304538667201996,
      "learning_rate": 0.00045039092917518563,
      "loss": 1.939,
      "step": 8860
    },
    {
      "epoch": 42.23866348448687,
      "grad_norm": 0.42498451471328735,
      "learning_rate": 0.0004502773928942665,
      "loss": 1.9632,
      "step": 8870
    },
    {
      "epoch": 42.28639618138425,
      "grad_norm": 0.4488472044467926,
      "learning_rate": 0.00045016374118600375,
      "loss": 1.9415,
      "step": 8880
    },
    {
      "epoch": 42.334128878281625,
      "grad_norm": 0.4108577072620392,
      "learning_rate": 0.0004500499741158991,
      "loss": 1.942,
      "step": 8890
    },
    {
      "epoch": 42.381861575178995,
      "grad_norm": 0.4675026535987854,
      "learning_rate": 0.00044993609174952075,
      "loss": 1.9595,
      "step": 8900
    },
    {
      "epoch": 42.42959427207637,
      "grad_norm": 0.3827655017375946,
      "learning_rate": 0.0004498220941525034,
      "loss": 1.9459,
      "step": 8910
    },
    {
      "epoch": 42.47732696897375,
      "grad_norm": 0.400983065366745,
      "learning_rate": 0.00044970798139054813,
      "loss": 1.9468,
      "step": 8920
    },
    {
      "epoch": 42.52505966587112,
      "grad_norm": 0.4103914499282837,
      "learning_rate": 0.0004495937535294224,
      "loss": 1.9557,
      "step": 8930
    },
    {
      "epoch": 42.572792362768496,
      "grad_norm": 0.3897761404514313,
      "learning_rate": 0.00044947941063495987,
      "loss": 1.9532,
      "step": 8940
    },
    {
      "epoch": 42.62052505966587,
      "grad_norm": 0.39250075817108154,
      "learning_rate": 0.0004493649527730608,
      "loss": 1.9398,
      "step": 8950
    },
    {
      "epoch": 42.66825775656324,
      "grad_norm": 0.42467790842056274,
      "learning_rate": 0.00044925038000969146,
      "loss": 1.9648,
      "step": 8960
    },
    {
      "epoch": 42.71599045346062,
      "grad_norm": 0.42235320806503296,
      "learning_rate": 0.00044913569241088435,
      "loss": 1.9433,
      "step": 8970
    },
    {
      "epoch": 42.763723150358,
      "grad_norm": 0.39087429642677307,
      "learning_rate": 0.0004490208900427383,
      "loss": 1.9621,
      "step": 8980
    },
    {
      "epoch": 42.81145584725537,
      "grad_norm": 0.4209168553352356,
      "learning_rate": 0.0004489059729714182,
      "loss": 1.9561,
      "step": 8990
    },
    {
      "epoch": 42.859188544152744,
      "grad_norm": 0.41613656282424927,
      "learning_rate": 0.000448790941263155,
      "loss": 1.937,
      "step": 9000
    },
    {
      "epoch": 42.90692124105012,
      "grad_norm": 0.36744752526283264,
      "learning_rate": 0.00044867579498424575,
      "loss": 1.9495,
      "step": 9010
    },
    {
      "epoch": 42.95465393794749,
      "grad_norm": 0.4072802662849426,
      "learning_rate": 0.0004485605342010537,
      "loss": 1.9431,
      "step": 9020
    },
    {
      "epoch": 43.0,
      "grad_norm": 0.30227380990982056,
      "learning_rate": 0.0004484451589800077,
      "loss": 1.8496,
      "step": 9030
    },
    {
      "epoch": 43.0,
      "eval_loss": 1.057590365409851,
      "eval_runtime": 4.3752,
      "eval_samples_per_second": 3355.499,
      "eval_steps_per_second": 13.257,
      "step": 9030
    },
    {
      "epoch": 43.04773269689738,
      "grad_norm": 0.4778228998184204,
      "learning_rate": 0.00044832966938760304,
      "loss": 1.9508,
      "step": 9040
    },
    {
      "epoch": 43.09546539379475,
      "grad_norm": 0.3830653727054596,
      "learning_rate": 0.00044821406549040054,
      "loss": 1.9453,
      "step": 9050
    },
    {
      "epoch": 43.143198090692124,
      "grad_norm": 0.4191519618034363,
      "learning_rate": 0.0004480983473550272,
      "loss": 1.9341,
      "step": 9060
    },
    {
      "epoch": 43.1909307875895,
      "grad_norm": 0.412986695766449,
      "learning_rate": 0.0004479825150481755,
      "loss": 1.9265,
      "step": 9070
    },
    {
      "epoch": 43.23866348448687,
      "grad_norm": 0.4338655471801758,
      "learning_rate": 0.000447866568636604,
      "loss": 1.9427,
      "step": 9080
    },
    {
      "epoch": 43.28639618138425,
      "grad_norm": 0.43567124009132385,
      "learning_rate": 0.000447750508187137,
      "loss": 1.9566,
      "step": 9090
    },
    {
      "epoch": 43.334128878281625,
      "grad_norm": 0.41544726490974426,
      "learning_rate": 0.0004476343337666645,
      "loss": 1.9474,
      "step": 9100
    },
    {
      "epoch": 43.381861575178995,
      "grad_norm": 0.4271943271160126,
      "learning_rate": 0.0004475180454421421,
      "loss": 1.9548,
      "step": 9110
    },
    {
      "epoch": 43.42959427207637,
      "grad_norm": 0.4283648729324341,
      "learning_rate": 0.00044740164328059106,
      "loss": 1.9314,
      "step": 9120
    },
    {
      "epoch": 43.47732696897375,
      "grad_norm": 0.448916494846344,
      "learning_rate": 0.00044728512734909845,
      "loss": 1.9539,
      "step": 9130
    },
    {
      "epoch": 43.52505966587112,
      "grad_norm": 0.38583260774612427,
      "learning_rate": 0.0004471684977148165,
      "loss": 1.9556,
      "step": 9140
    },
    {
      "epoch": 43.572792362768496,
      "grad_norm": 0.4285825490951538,
      "learning_rate": 0.0004470517544449635,
      "loss": 1.9534,
      "step": 9150
    },
    {
      "epoch": 43.62052505966587,
      "grad_norm": 0.38121551275253296,
      "learning_rate": 0.00044693489760682276,
      "loss": 1.9482,
      "step": 9160
    },
    {
      "epoch": 43.66825775656324,
      "grad_norm": 0.428765207529068,
      "learning_rate": 0.0004468179272677433,
      "loss": 1.9304,
      "step": 9170
    },
    {
      "epoch": 43.71599045346062,
      "grad_norm": 0.37857699394226074,
      "learning_rate": 0.0004467008434951396,
      "loss": 1.9564,
      "step": 9180
    },
    {
      "epoch": 43.763723150358,
      "grad_norm": 0.42724311351776123,
      "learning_rate": 0.00044658364635649124,
      "loss": 1.9415,
      "step": 9190
    },
    {
      "epoch": 43.81145584725537,
      "grad_norm": 0.4304260313510895,
      "learning_rate": 0.00044646633591934336,
      "loss": 1.948,
      "step": 9200
    },
    {
      "epoch": 43.859188544152744,
      "grad_norm": 0.40790075063705444,
      "learning_rate": 0.00044634891225130645,
      "loss": 1.9545,
      "step": 9210
    },
    {
      "epoch": 43.90692124105012,
      "grad_norm": 0.3923434317111969,
      "learning_rate": 0.0004462313754200561,
      "loss": 1.9593,
      "step": 9220
    },
    {
      "epoch": 43.95465393794749,
      "grad_norm": 0.4517359435558319,
      "learning_rate": 0.0004461137254933332,
      "loss": 1.9393,
      "step": 9230
    },
    {
      "epoch": 44.0,
      "grad_norm": 0.30411210656166077,
      "learning_rate": 0.00044599596253894365,
      "loss": 1.8654,
      "step": 9240
    },
    {
      "epoch": 44.0,
      "eval_loss": 1.0572315454483032,
      "eval_runtime": 4.3985,
      "eval_samples_per_second": 3337.739,
      "eval_steps_per_second": 13.186,
      "step": 9240
    },
    {
      "epoch": 44.04773269689738,
      "grad_norm": 0.40687912702560425,
      "learning_rate": 0.00044587808662475883,
      "loss": 1.9336,
      "step": 9250
    },
    {
      "epoch": 44.09546539379475,
      "grad_norm": 0.39510807394981384,
      "learning_rate": 0.0004457600978187149,
      "loss": 1.9342,
      "step": 9260
    },
    {
      "epoch": 44.143198090692124,
      "grad_norm": 0.4587381184101105,
      "learning_rate": 0.0004456419961888133,
      "loss": 1.9497,
      "step": 9270
    },
    {
      "epoch": 44.1909307875895,
      "grad_norm": 0.42719319462776184,
      "learning_rate": 0.00044552378180312037,
      "loss": 1.936,
      "step": 9280
    },
    {
      "epoch": 44.23866348448687,
      "grad_norm": 0.4549878239631653,
      "learning_rate": 0.00044540545472976747,
      "loss": 1.9372,
      "step": 9290
    },
    {
      "epoch": 44.28639618138425,
      "grad_norm": 0.42457282543182373,
      "learning_rate": 0.00044528701503695095,
      "loss": 1.9517,
      "step": 9300
    },
    {
      "epoch": 44.334128878281625,
      "grad_norm": 0.4943361282348633,
      "learning_rate": 0.000445168462792932,
      "loss": 1.946,
      "step": 9310
    },
    {
      "epoch": 44.381861575178995,
      "grad_norm": 0.43783047795295715,
      "learning_rate": 0.00044504979806603675,
      "loss": 1.9493,
      "step": 9320
    },
    {
      "epoch": 44.42959427207637,
      "grad_norm": 0.44870004057884216,
      "learning_rate": 0.0004449310209246561,
      "loss": 1.9521,
      "step": 9330
    },
    {
      "epoch": 44.47732696897375,
      "grad_norm": 0.3895975649356842,
      "learning_rate": 0.0004448121314372457,
      "loss": 1.932,
      "step": 9340
    },
    {
      "epoch": 44.52505966587112,
      "grad_norm": 0.43937012553215027,
      "learning_rate": 0.000444693129672326,
      "loss": 1.9608,
      "step": 9350
    },
    {
      "epoch": 44.572792362768496,
      "grad_norm": 0.4181674122810364,
      "learning_rate": 0.0004445740156984823,
      "loss": 1.9582,
      "step": 9360
    },
    {
      "epoch": 44.62052505966587,
      "grad_norm": 0.42148107290267944,
      "learning_rate": 0.00044445478958436425,
      "loss": 1.9422,
      "step": 9370
    },
    {
      "epoch": 44.66825775656324,
      "grad_norm": 0.42130526900291443,
      "learning_rate": 0.00044433545139868646,
      "loss": 1.9576,
      "step": 9380
    },
    {
      "epoch": 44.71599045346062,
      "grad_norm": 0.4518558382987976,
      "learning_rate": 0.00044421600121022787,
      "loss": 1.9469,
      "step": 9390
    },
    {
      "epoch": 44.763723150358,
      "grad_norm": 0.4853089451789856,
      "learning_rate": 0.0004440964390878323,
      "loss": 1.9343,
      "step": 9400
    },
    {
      "epoch": 44.81145584725537,
      "grad_norm": 0.4432104825973511,
      "learning_rate": 0.0004439767651004075,
      "loss": 1.9354,
      "step": 9410
    },
    {
      "epoch": 44.859188544152744,
      "grad_norm": 0.45387032628059387,
      "learning_rate": 0.0004438569793169264,
      "loss": 1.954,
      "step": 9420
    },
    {
      "epoch": 44.90692124105012,
      "grad_norm": 0.45882999897003174,
      "learning_rate": 0.0004437370818064258,
      "loss": 1.9441,
      "step": 9430
    },
    {
      "epoch": 44.95465393794749,
      "grad_norm": 0.43809378147125244,
      "learning_rate": 0.00044361707263800725,
      "loss": 1.9256,
      "step": 9440
    },
    {
      "epoch": 45.0,
      "grad_norm": 0.2671137750148773,
      "learning_rate": 0.0004434969518808365,
      "loss": 1.8523,
      "step": 9450
    },
    {
      "epoch": 45.0,
      "eval_loss": 1.059613585472107,
      "eval_runtime": 4.3761,
      "eval_samples_per_second": 3354.783,
      "eval_steps_per_second": 13.254,
      "step": 9450
    },
    {
      "epoch": 45.04773269689738,
      "grad_norm": 0.40678203105926514,
      "learning_rate": 0.0004433767196041436,
      "loss": 1.9398,
      "step": 9460
    },
    {
      "epoch": 45.09546539379475,
      "grad_norm": 0.4803856313228607,
      "learning_rate": 0.00044325637587722285,
      "loss": 1.9214,
      "step": 9470
    },
    {
      "epoch": 45.143198090692124,
      "grad_norm": 0.5538767576217651,
      "learning_rate": 0.0004431359207694329,
      "loss": 1.9414,
      "step": 9480
    },
    {
      "epoch": 45.1909307875895,
      "grad_norm": 0.4680096507072449,
      "learning_rate": 0.0004430153543501966,
      "loss": 1.9397,
      "step": 9490
    },
    {
      "epoch": 45.23866348448687,
      "grad_norm": 0.39745768904685974,
      "learning_rate": 0.0004428946766890007,
      "loss": 1.9321,
      "step": 9500
    },
    {
      "epoch": 45.28639618138425,
      "grad_norm": 0.4566214084625244,
      "learning_rate": 0.0004427738878553964,
      "loss": 1.944,
      "step": 9510
    },
    {
      "epoch": 45.334128878281625,
      "grad_norm": 0.39863109588623047,
      "learning_rate": 0.00044265298791899875,
      "loss": 1.9355,
      "step": 9520
    },
    {
      "epoch": 45.381861575178995,
      "grad_norm": 0.42871415615081787,
      "learning_rate": 0.000442531976949487,
      "loss": 1.9415,
      "step": 9530
    },
    {
      "epoch": 45.42959427207637,
      "grad_norm": 0.39056411385536194,
      "learning_rate": 0.00044241085501660403,
      "loss": 1.9498,
      "step": 9540
    },
    {
      "epoch": 45.47732696897375,
      "grad_norm": 0.4131435453891754,
      "learning_rate": 0.0004422896221901572,
      "loss": 1.9406,
      "step": 9550
    },
    {
      "epoch": 45.52505966587112,
      "grad_norm": 0.42080581188201904,
      "learning_rate": 0.0004421682785400175,
      "loss": 1.9423,
      "step": 9560
    },
    {
      "epoch": 45.572792362768496,
      "grad_norm": 0.47584542632102966,
      "learning_rate": 0.0004420468241361196,
      "loss": 1.9404,
      "step": 9570
    },
    {
      "epoch": 45.62052505966587,
      "grad_norm": 0.4294535219669342,
      "learning_rate": 0.0004419252590484625,
      "loss": 1.949,
      "step": 9580
    },
    {
      "epoch": 45.66825775656324,
      "grad_norm": 0.49020814895629883,
      "learning_rate": 0.00044180358334710846,
      "loss": 1.9531,
      "step": 9590
    },
    {
      "epoch": 45.71599045346062,
      "grad_norm": 0.41571512818336487,
      "learning_rate": 0.0004416817971021838,
      "loss": 1.9603,
      "step": 9600
    },
    {
      "epoch": 45.763723150358,
      "grad_norm": 0.4410346448421478,
      "learning_rate": 0.0004415599003838785,
      "loss": 1.9379,
      "step": 9610
    },
    {
      "epoch": 45.81145584725537,
      "grad_norm": 0.40649762749671936,
      "learning_rate": 0.00044143789326244625,
      "loss": 1.9469,
      "step": 9620
    },
    {
      "epoch": 45.859188544152744,
      "grad_norm": 0.4323725700378418,
      "learning_rate": 0.00044131577580820426,
      "loss": 1.9386,
      "step": 9630
    },
    {
      "epoch": 45.90692124105012,
      "grad_norm": 0.3784668743610382,
      "learning_rate": 0.00044119354809153336,
      "loss": 1.9478,
      "step": 9640
    },
    {
      "epoch": 45.95465393794749,
      "grad_norm": 0.4544561803340912,
      "learning_rate": 0.00044107121018287796,
      "loss": 1.9325,
      "step": 9650
    },
    {
      "epoch": 46.0,
      "grad_norm": 0.2878405451774597,
      "learning_rate": 0.00044094876215274595,
      "loss": 1.8583,
      "step": 9660
    },
    {
      "epoch": 46.0,
      "eval_loss": 1.0557105541229248,
      "eval_runtime": 4.389,
      "eval_samples_per_second": 3344.973,
      "eval_steps_per_second": 13.215,
      "step": 9660
    },
    {
      "epoch": 46.04773269689738,
      "grad_norm": 0.4244159758090973,
      "learning_rate": 0.00044082620407170876,
      "loss": 1.9114,
      "step": 9670
    },
    {
      "epoch": 46.09546539379475,
      "grad_norm": 0.423907071352005,
      "learning_rate": 0.00044070353601040113,
      "loss": 1.9377,
      "step": 9680
    },
    {
      "epoch": 46.143198090692124,
      "grad_norm": 0.4802289307117462,
      "learning_rate": 0.00044058075803952133,
      "loss": 1.9399,
      "step": 9690
    },
    {
      "epoch": 46.1909307875895,
      "grad_norm": 0.48963287472724915,
      "learning_rate": 0.00044045787022983085,
      "loss": 1.9335,
      "step": 9700
    },
    {
      "epoch": 46.23866348448687,
      "grad_norm": 0.4305822551250458,
      "learning_rate": 0.00044033487265215444,
      "loss": 1.9509,
      "step": 9710
    },
    {
      "epoch": 46.28639618138425,
      "grad_norm": 0.43578213453292847,
      "learning_rate": 0.0004402117653773803,
      "loss": 1.9397,
      "step": 9720
    },
    {
      "epoch": 46.334128878281625,
      "grad_norm": 0.4645689129829407,
      "learning_rate": 0.0004400885484764597,
      "loss": 1.9449,
      "step": 9730
    },
    {
      "epoch": 46.381861575178995,
      "grad_norm": 0.3889153301715851,
      "learning_rate": 0.0004399652220204072,
      "loss": 1.9382,
      "step": 9740
    },
    {
      "epoch": 46.42959427207637,
      "grad_norm": 0.4676287770271301,
      "learning_rate": 0.00043984178608030047,
      "loss": 1.9442,
      "step": 9750
    },
    {
      "epoch": 46.47732696897375,
      "grad_norm": 0.39200568199157715,
      "learning_rate": 0.0004397182407272802,
      "loss": 1.9483,
      "step": 9760
    },
    {
      "epoch": 46.52505966587112,
      "grad_norm": 0.4481337368488312,
      "learning_rate": 0.0004395945860325501,
      "loss": 1.9256,
      "step": 9770
    },
    {
      "epoch": 46.572792362768496,
      "grad_norm": 0.42816075682640076,
      "learning_rate": 0.0004394708220673771,
      "loss": 1.9414,
      "step": 9780
    },
    {
      "epoch": 46.62052505966587,
      "grad_norm": 0.41578924655914307,
      "learning_rate": 0.00043934694890309094,
      "loss": 1.9192,
      "step": 9790
    },
    {
      "epoch": 46.66825775656324,
      "grad_norm": 0.46713492274284363,
      "learning_rate": 0.0004392229666110845,
      "loss": 1.9461,
      "step": 9800
    },
    {
      "epoch": 46.71599045346062,
      "grad_norm": 0.4352056682109833,
      "learning_rate": 0.00043909887526281314,
      "loss": 1.9191,
      "step": 9810
    },
    {
      "epoch": 46.763723150358,
      "grad_norm": 0.45611461997032166,
      "learning_rate": 0.0004389746749297956,
      "loss": 1.951,
      "step": 9820
    },
    {
      "epoch": 46.81145584725537,
      "grad_norm": 0.42944765090942383,
      "learning_rate": 0.000438850365683613,
      "loss": 1.952,
      "step": 9830
    },
    {
      "epoch": 46.859188544152744,
      "grad_norm": 0.4268656373023987,
      "learning_rate": 0.00043872594759590956,
      "loss": 1.9324,
      "step": 9840
    },
    {
      "epoch": 46.90692124105012,
      "grad_norm": 0.402068167924881,
      "learning_rate": 0.00043860142073839193,
      "loss": 1.9441,
      "step": 9850
    },
    {
      "epoch": 46.95465393794749,
      "grad_norm": 0.3961600661277771,
      "learning_rate": 0.00043847678518282965,
      "loss": 1.9442,
      "step": 9860
    },
    {
      "epoch": 47.0,
      "grad_norm": 0.3109181523323059,
      "learning_rate": 0.00043835204100105485,
      "loss": 1.852,
      "step": 9870
    },
    {
      "epoch": 47.0,
      "eval_loss": 1.056139349937439,
      "eval_runtime": 4.3704,
      "eval_samples_per_second": 3359.169,
      "eval_steps_per_second": 13.271,
      "step": 9870
    },
    {
      "epoch": 47.04773269689738,
      "grad_norm": 0.44145697355270386,
      "learning_rate": 0.00043822718826496223,
      "loss": 1.9346,
      "step": 9880
    },
    {
      "epoch": 47.09546539379475,
      "grad_norm": 0.39347466826438904,
      "learning_rate": 0.0004381022270465091,
      "loss": 1.9209,
      "step": 9890
    },
    {
      "epoch": 47.143198090692124,
      "grad_norm": 0.44221654534339905,
      "learning_rate": 0.00043797715741771524,
      "loss": 1.9499,
      "step": 9900
    },
    {
      "epoch": 47.1909307875895,
      "grad_norm": 0.4206071197986603,
      "learning_rate": 0.00043785197945066305,
      "loss": 1.9283,
      "step": 9910
    },
    {
      "epoch": 47.23866348448687,
      "grad_norm": 0.5405429601669312,
      "learning_rate": 0.00043772669321749723,
      "loss": 1.9378,
      "step": 9920
    },
    {
      "epoch": 47.28639618138425,
      "grad_norm": 0.4407154619693756,
      "learning_rate": 0.0004376012987904249,
      "loss": 1.9358,
      "step": 9930
    },
    {
      "epoch": 47.334128878281625,
      "grad_norm": 0.4544122815132141,
      "learning_rate": 0.0004374757962417155,
      "loss": 1.9211,
      "step": 9940
    },
    {
      "epoch": 47.381861575178995,
      "grad_norm": 0.4329568147659302,
      "learning_rate": 0.0004373501856437009,
      "loss": 1.9502,
      "step": 9950
    },
    {
      "epoch": 47.42959427207637,
      "grad_norm": 0.4008854627609253,
      "learning_rate": 0.0004372244670687752,
      "loss": 1.9309,
      "step": 9960
    },
    {
      "epoch": 47.47732696897375,
      "grad_norm": 0.45230111479759216,
      "learning_rate": 0.0004370986405893947,
      "loss": 1.935,
      "step": 9970
    },
    {
      "epoch": 47.52505966587112,
      "grad_norm": 0.4509139955043793,
      "learning_rate": 0.00043697270627807784,
      "loss": 1.9296,
      "step": 9980
    },
    {
      "epoch": 47.572792362768496,
      "grad_norm": 0.4558056592941284,
      "learning_rate": 0.00043684666420740534,
      "loss": 1.927,
      "step": 9990
    },
    {
      "epoch": 47.62052505966587,
      "grad_norm": 0.4685547351837158,
      "learning_rate": 0.0004367205144500199,
      "loss": 1.9507,
      "step": 10000
    },
    {
      "epoch": 47.66825775656324,
      "grad_norm": 0.4201333224773407,
      "learning_rate": 0.00043659425707862635,
      "loss": 1.9371,
      "step": 10010
    },
    {
      "epoch": 47.71599045346062,
      "grad_norm": 0.43550407886505127,
      "learning_rate": 0.0004364678921659916,
      "loss": 1.9344,
      "step": 10020
    },
    {
      "epoch": 47.763723150358,
      "grad_norm": 0.4260283410549164,
      "learning_rate": 0.00043634141978494436,
      "loss": 1.9368,
      "step": 10030
    },
    {
      "epoch": 47.81145584725537,
      "grad_norm": 0.4316471815109253,
      "learning_rate": 0.0004362148400083754,
      "loss": 1.9298,
      "step": 10040
    },
    {
      "epoch": 47.859188544152744,
      "grad_norm": 0.45374906063079834,
      "learning_rate": 0.00043608815290923747,
      "loss": 1.9308,
      "step": 10050
    },
    {
      "epoch": 47.90692124105012,
      "grad_norm": 0.4294142723083496,
      "learning_rate": 0.0004359613585605451,
      "loss": 1.9558,
      "step": 10060
    },
    {
      "epoch": 47.95465393794749,
      "grad_norm": 0.3934078514575958,
      "learning_rate": 0.0004358344570353744,
      "loss": 1.9392,
      "step": 10070
    },
    {
      "epoch": 48.0,
      "grad_norm": 0.49010220170021057,
      "learning_rate": 0.0004357074484068636,
      "loss": 1.8373,
      "step": 10080
    },
    {
      "epoch": 48.0,
      "eval_loss": 1.0602185726165771,
      "eval_runtime": 4.3881,
      "eval_samples_per_second": 3345.668,
      "eval_steps_per_second": 13.218,
      "step": 10080
    },
    {
      "epoch": 48.04773269689738,
      "grad_norm": 0.39305269718170166,
      "learning_rate": 0.00043558033274821264,
      "loss": 1.9199,
      "step": 10090
    },
    {
      "epoch": 48.09546539379475,
      "grad_norm": 0.44659167528152466,
      "learning_rate": 0.00043545311013268274,
      "loss": 1.9216,
      "step": 10100
    },
    {
      "epoch": 48.143198090692124,
      "grad_norm": 0.42882856726646423,
      "learning_rate": 0.0004353257806335973,
      "loss": 1.9307,
      "step": 10110
    },
    {
      "epoch": 48.1909307875895,
      "grad_norm": 0.40321892499923706,
      "learning_rate": 0.00043519834432434093,
      "loss": 1.9243,
      "step": 10120
    },
    {
      "epoch": 48.23866348448687,
      "grad_norm": 0.4379710853099823,
      "learning_rate": 0.00043507080127836,
      "loss": 1.9448,
      "step": 10130
    },
    {
      "epoch": 48.28639618138425,
      "grad_norm": 0.39573922753334045,
      "learning_rate": 0.00043494315156916225,
      "loss": 1.9261,
      "step": 10140
    },
    {
      "epoch": 48.334128878281625,
      "grad_norm": 0.39771130681037903,
      "learning_rate": 0.00043481539527031704,
      "loss": 1.9243,
      "step": 10150
    },
    {
      "epoch": 48.381861575178995,
      "grad_norm": 0.46433553099632263,
      "learning_rate": 0.0004346875324554551,
      "loss": 1.9346,
      "step": 10160
    },
    {
      "epoch": 48.42959427207637,
      "grad_norm": 0.44085100293159485,
      "learning_rate": 0.0004345595631982686,
      "loss": 1.948,
      "step": 10170
    },
    {
      "epoch": 48.47732696897375,
      "grad_norm": 0.37238433957099915,
      "learning_rate": 0.00043443148757251084,
      "loss": 1.9317,
      "step": 10180
    },
    {
      "epoch": 48.52505966587112,
      "grad_norm": 0.4746060073375702,
      "learning_rate": 0.0004343033056519967,
      "loss": 1.9356,
      "step": 10190
    },
    {
      "epoch": 48.572792362768496,
      "grad_norm": 0.44333168864250183,
      "learning_rate": 0.0004341750175106023,
      "loss": 1.9344,
      "step": 10200
    },
    {
      "epoch": 48.62052505966587,
      "grad_norm": 0.4093611538410187,
      "learning_rate": 0.0004340466232222647,
      "loss": 1.9281,
      "step": 10210
    },
    {
      "epoch": 48.66825775656324,
      "grad_norm": 0.3851985037326813,
      "learning_rate": 0.00043391812286098244,
      "loss": 1.9346,
      "step": 10220
    },
    {
      "epoch": 48.71599045346062,
      "grad_norm": 0.42163166403770447,
      "learning_rate": 0.000433789516500815,
      "loss": 1.9404,
      "step": 10230
    },
    {
      "epoch": 48.763723150358,
      "grad_norm": 0.41006627678871155,
      "learning_rate": 0.0004336608042158831,
      "loss": 1.9346,
      "step": 10240
    },
    {
      "epoch": 48.81145584725537,
      "grad_norm": 0.42159101366996765,
      "learning_rate": 0.0004335319860803684,
      "loss": 1.9534,
      "step": 10250
    },
    {
      "epoch": 48.859188544152744,
      "grad_norm": 0.42779648303985596,
      "learning_rate": 0.0004334030621685137,
      "loss": 1.9357,
      "step": 10260
    },
    {
      "epoch": 48.90692124105012,
      "grad_norm": 0.38310161232948303,
      "learning_rate": 0.0004332740325546225,
      "loss": 1.9378,
      "step": 10270
    },
    {
      "epoch": 48.95465393794749,
      "grad_norm": 0.3743734657764435,
      "learning_rate": 0.0004331448973130595,
      "loss": 1.9252,
      "step": 10280
    },
    {
      "epoch": 49.0,
      "grad_norm": 0.3390069901943207,
      "learning_rate": 0.00043301565651825016,
      "loss": 1.8403,
      "step": 10290
    },
    {
      "epoch": 49.0,
      "eval_loss": 1.0568159818649292,
      "eval_runtime": 4.3781,
      "eval_samples_per_second": 3353.298,
      "eval_steps_per_second": 13.248,
      "step": 10290
    },
    {
      "epoch": 49.04773269689738,
      "grad_norm": 0.4359510540962219,
      "learning_rate": 0.00043288631024468075,
      "loss": 1.9249,
      "step": 10300
    },
    {
      "epoch": 49.09546539379475,
      "grad_norm": 0.40482932329177856,
      "learning_rate": 0.00043275685856689836,
      "loss": 1.9306,
      "step": 10310
    },
    {
      "epoch": 49.143198090692124,
      "grad_norm": 0.446769118309021,
      "learning_rate": 0.0004326273015595108,
      "loss": 1.9184,
      "step": 10320
    },
    {
      "epoch": 49.1909307875895,
      "grad_norm": 0.4686852693557739,
      "learning_rate": 0.0004324976392971867,
      "loss": 1.9256,
      "step": 10330
    },
    {
      "epoch": 49.23866348448687,
      "grad_norm": 0.40830036997795105,
      "learning_rate": 0.0004323678718546552,
      "loss": 1.9287,
      "step": 10340
    },
    {
      "epoch": 49.28639618138425,
      "grad_norm": 0.8398653864860535,
      "learning_rate": 0.00043223799930670615,
      "loss": 1.9391,
      "step": 10350
    },
    {
      "epoch": 49.334128878281625,
      "grad_norm": 0.4353552460670471,
      "learning_rate": 0.0004321080217281899,
      "loss": 1.9219,
      "step": 10360
    },
    {
      "epoch": 49.381861575178995,
      "grad_norm": 0.4769308865070343,
      "learning_rate": 0.00043197793919401753,
      "loss": 1.9148,
      "step": 10370
    },
    {
      "epoch": 49.42959427207637,
      "grad_norm": 0.465300589799881,
      "learning_rate": 0.00043184775177916026,
      "loss": 1.9173,
      "step": 10380
    },
    {
      "epoch": 49.47732696897375,
      "grad_norm": 0.40632912516593933,
      "learning_rate": 0.00043171745955865006,
      "loss": 1.9224,
      "step": 10390
    },
    {
      "epoch": 49.52505966587112,
      "grad_norm": 0.41700419783592224,
      "learning_rate": 0.0004315870626075792,
      "loss": 1.9361,
      "step": 10400
    },
    {
      "epoch": 49.572792362768496,
      "grad_norm": 0.48057296872138977,
      "learning_rate": 0.0004314565610011003,
      "loss": 1.9446,
      "step": 10410
    },
    {
      "epoch": 49.62052505966587,
      "grad_norm": 0.4347505271434784,
      "learning_rate": 0.0004313259548144264,
      "loss": 1.9413,
      "step": 10420
    },
    {
      "epoch": 49.66825775656324,
      "grad_norm": 0.4217771589756012,
      "learning_rate": 0.0004311952441228306,
      "loss": 1.9298,
      "step": 10430
    },
    {
      "epoch": 49.71599045346062,
      "grad_norm": 0.3709682822227478,
      "learning_rate": 0.0004310644290016465,
      "loss": 1.9408,
      "step": 10440
    },
    {
      "epoch": 49.763723150358,
      "grad_norm": 0.7262851595878601,
      "learning_rate": 0.0004309335095262675,
      "loss": 1.9261,
      "step": 10450
    },
    {
      "epoch": 49.81145584725537,
      "grad_norm": 0.40608876943588257,
      "learning_rate": 0.00043080248577214765,
      "loss": 1.9237,
      "step": 10460
    },
    {
      "epoch": 49.859188544152744,
      "grad_norm": 0.4087478220462799,
      "learning_rate": 0.0004306713578148007,
      "loss": 1.92,
      "step": 10470
    },
    {
      "epoch": 49.90692124105012,
      "grad_norm": 0.42247274518013,
      "learning_rate": 0.00043054012572980063,
      "loss": 1.9338,
      "step": 10480
    },
    {
      "epoch": 49.95465393794749,
      "grad_norm": 0.4118998348712921,
      "learning_rate": 0.0004304087895927813,
      "loss": 1.9297,
      "step": 10490
    },
    {
      "epoch": 50.0,
      "grad_norm": 0.3662174642086029,
      "learning_rate": 0.0004302773494794368,
      "loss": 1.8467,
      "step": 10500
    },
    {
      "epoch": 50.0,
      "eval_loss": 1.0619181394577026,
      "eval_runtime": 4.5612,
      "eval_samples_per_second": 3218.636,
      "eval_steps_per_second": 12.716,
      "step": 10500
    },
    {
      "epoch": 50.04773269689738,
      "grad_norm": 0.41276630759239197,
      "learning_rate": 0.0004301458054655207,
      "loss": 1.9215,
      "step": 10510
    },
    {
      "epoch": 50.09546539379475,
      "grad_norm": 0.5019689202308655,
      "learning_rate": 0.00043001415762684717,
      "loss": 1.9279,
      "step": 10520
    },
    {
      "epoch": 50.143198090692124,
      "grad_norm": 0.3928029239177704,
      "learning_rate": 0.0004298824060392893,
      "loss": 1.9426,
      "step": 10530
    },
    {
      "epoch": 50.1909307875895,
      "grad_norm": 0.4853156805038452,
      "learning_rate": 0.0004297505507787808,
      "loss": 1.9317,
      "step": 10540
    },
    {
      "epoch": 50.23866348448687,
      "grad_norm": 0.43789806962013245,
      "learning_rate": 0.0004296185919213146,
      "loss": 1.9253,
      "step": 10550
    },
    {
      "epoch": 50.28639618138425,
      "grad_norm": 0.4407956004142761,
      "learning_rate": 0.0004294865295429436,
      "loss": 1.9104,
      "step": 10560
    },
    {
      "epoch": 50.334128878281625,
      "grad_norm": 0.44294410943984985,
      "learning_rate": 0.0004293543637197802,
      "loss": 1.9334,
      "step": 10570
    },
    {
      "epoch": 50.381861575178995,
      "grad_norm": 0.42286843061447144,
      "learning_rate": 0.00042922209452799664,
      "loss": 1.9265,
      "step": 10580
    },
    {
      "epoch": 50.42959427207637,
      "grad_norm": 0.4292617440223694,
      "learning_rate": 0.0004290897220438245,
      "loss": 1.9251,
      "step": 10590
    },
    {
      "epoch": 50.47732696897375,
      "grad_norm": 0.4147302508354187,
      "learning_rate": 0.0004289572463435549,
      "loss": 1.9201,
      "step": 10600
    },
    {
      "epoch": 50.52505966587112,
      "grad_norm": 0.41723930835723877,
      "learning_rate": 0.0004288246675035388,
      "loss": 1.9259,
      "step": 10610
    },
    {
      "epoch": 50.572792362768496,
      "grad_norm": 0.41237708926200867,
      "learning_rate": 0.0004286919856001861,
      "loss": 1.9233,
      "step": 10620
    },
    {
      "epoch": 50.62052505966587,
      "grad_norm": 0.42029869556427,
      "learning_rate": 0.00042855920070996635,
      "loss": 1.9282,
      "step": 10630
    },
    {
      "epoch": 50.66825775656324,
      "grad_norm": 0.3961014151573181,
      "learning_rate": 0.0004284263129094086,
      "loss": 1.9336,
      "step": 10640
    },
    {
      "epoch": 50.71599045346062,
      "grad_norm": 0.4310885965824127,
      "learning_rate": 0.00042829332227510087,
      "loss": 1.922,
      "step": 10650
    },
    {
      "epoch": 50.763723150358,
      "grad_norm": 0.4391620457172394,
      "learning_rate": 0.0004281602288836908,
      "loss": 1.9389,
      "step": 10660
    },
    {
      "epoch": 50.81145584725537,
      "grad_norm": 0.3906958997249603,
      "learning_rate": 0.000428027032811885,
      "loss": 1.9217,
      "step": 10670
    },
    {
      "epoch": 50.859188544152744,
      "grad_norm": 0.3864111006259918,
      "learning_rate": 0.00042789373413644927,
      "loss": 1.9249,
      "step": 10680
    },
    {
      "epoch": 50.90692124105012,
      "grad_norm": 0.40510109066963196,
      "learning_rate": 0.0004277603329342088,
      "loss": 1.9264,
      "step": 10690
    },
    {
      "epoch": 50.95465393794749,
      "grad_norm": 0.44219228625297546,
      "learning_rate": 0.0004276268292820475,
      "loss": 1.9314,
      "step": 10700
    },
    {
      "epoch": 51.0,
      "grad_norm": 0.38682374358177185,
      "learning_rate": 0.00042749322325690866,
      "loss": 1.827,
      "step": 10710
    },
    {
      "epoch": 51.0,
      "eval_loss": 1.0572636127471924,
      "eval_runtime": 4.3881,
      "eval_samples_per_second": 3345.668,
      "eval_steps_per_second": 13.218,
      "step": 10710
    },
    {
      "epoch": 51.04773269689738,
      "grad_norm": 0.469865620136261,
      "learning_rate": 0.0004273595149357943,
      "loss": 1.9173,
      "step": 10720
    },
    {
      "epoch": 51.09546539379475,
      "grad_norm": 0.4360215961933136,
      "learning_rate": 0.00042722570439576556,
      "loss": 1.9164,
      "step": 10730
    },
    {
      "epoch": 51.143198090692124,
      "grad_norm": 0.4603208005428314,
      "learning_rate": 0.0004270917917139425,
      "loss": 1.9146,
      "step": 10740
    },
    {
      "epoch": 51.1909307875895,
      "grad_norm": 0.4137554168701172,
      "learning_rate": 0.000426957776967504,
      "loss": 1.9132,
      "step": 10750
    },
    {
      "epoch": 51.23866348448687,
      "grad_norm": 0.4182548224925995,
      "learning_rate": 0.00042682366023368766,
      "loss": 1.9037,
      "step": 10760
    },
    {
      "epoch": 51.28639618138425,
      "grad_norm": 0.4636152982711792,
      "learning_rate": 0.0004266894415897901,
      "loss": 1.934,
      "step": 10770
    },
    {
      "epoch": 51.334128878281625,
      "grad_norm": 0.40417882800102234,
      "learning_rate": 0.0004265551211131665,
      "loss": 1.9192,
      "step": 10780
    },
    {
      "epoch": 51.381861575178995,
      "grad_norm": 0.39532792568206787,
      "learning_rate": 0.0004264206988812307,
      "loss": 1.9391,
      "step": 10790
    },
    {
      "epoch": 51.42959427207637,
      "grad_norm": 0.432468056678772,
      "learning_rate": 0.0004262861749714553,
      "loss": 1.9258,
      "step": 10800
    },
    {
      "epoch": 51.47732696897375,
      "grad_norm": 0.4247656762599945,
      "learning_rate": 0.00042615154946137147,
      "loss": 1.9198,
      "step": 10810
    },
    {
      "epoch": 51.52505966587112,
      "grad_norm": 0.3999633491039276,
      "learning_rate": 0.0004260168224285689,
      "loss": 1.9425,
      "step": 10820
    },
    {
      "epoch": 51.572792362768496,
      "grad_norm": 0.3732757866382599,
      "learning_rate": 0.0004258819939506958,
      "loss": 1.9363,
      "step": 10830
    },
    {
      "epoch": 51.62052505966587,
      "grad_norm": 0.39322417974472046,
      "learning_rate": 0.0004257470641054589,
      "loss": 1.9121,
      "step": 10840
    },
    {
      "epoch": 51.66825775656324,
      "grad_norm": 0.4067598283290863,
      "learning_rate": 0.0004256120329706233,
      "loss": 1.9218,
      "step": 10850
    },
    {
      "epoch": 51.71599045346062,
      "grad_norm": 0.43757662177085876,
      "learning_rate": 0.0004254769006240126,
      "loss": 1.923,
      "step": 10860
    },
    {
      "epoch": 51.763723150358,
      "grad_norm": 0.44503599405288696,
      "learning_rate": 0.00042534166714350833,
      "loss": 1.9275,
      "step": 10870
    },
    {
      "epoch": 51.81145584725537,
      "grad_norm": 0.45509934425354004,
      "learning_rate": 0.00042520633260705076,
      "loss": 1.93,
      "step": 10880
    },
    {
      "epoch": 51.859188544152744,
      "grad_norm": 0.38545823097229004,
      "learning_rate": 0.00042507089709263834,
      "loss": 1.9273,
      "step": 10890
    },
    {
      "epoch": 51.90692124105012,
      "grad_norm": 0.3730256259441376,
      "learning_rate": 0.0004249353606783274,
      "loss": 1.923,
      "step": 10900
    },
    {
      "epoch": 51.95465393794749,
      "grad_norm": 0.39450475573539734,
      "learning_rate": 0.00042479972344223283,
      "loss": 1.9435,
      "step": 10910
    },
    {
      "epoch": 52.0,
      "grad_norm": 0.36458510160446167,
      "learning_rate": 0.0004246639854625274,
      "loss": 1.8204,
      "step": 10920
    },
    {
      "epoch": 52.0,
      "eval_loss": 1.0583571195602417,
      "eval_runtime": 4.3794,
      "eval_samples_per_second": 3352.304,
      "eval_steps_per_second": 13.244,
      "step": 10920
    },
    {
      "epoch": 52.04773269689738,
      "grad_norm": 0.46172621846199036,
      "learning_rate": 0.0004245281468174419,
      "loss": 1.9124,
      "step": 10930
    },
    {
      "epoch": 52.09546539379475,
      "grad_norm": 0.5000693798065186,
      "learning_rate": 0.0004243922075852653,
      "loss": 1.9067,
      "step": 10940
    },
    {
      "epoch": 52.143198090692124,
      "grad_norm": 0.4889536201953888,
      "learning_rate": 0.0004242561678443443,
      "loss": 1.9069,
      "step": 10950
    },
    {
      "epoch": 52.1909307875895,
      "grad_norm": 0.39689570665359497,
      "learning_rate": 0.0004241200276730839,
      "loss": 1.9178,
      "step": 10960
    },
    {
      "epoch": 52.23866348448687,
      "grad_norm": 0.4171341359615326,
      "learning_rate": 0.00042398378714994663,
      "loss": 1.9317,
      "step": 10970
    },
    {
      "epoch": 52.28639618138425,
      "grad_norm": 0.4374983012676239,
      "learning_rate": 0.0004238474463534531,
      "loss": 1.936,
      "step": 10980
    },
    {
      "epoch": 52.334128878281625,
      "grad_norm": 0.39966654777526855,
      "learning_rate": 0.0004237110053621814,
      "loss": 1.9236,
      "step": 10990
    },
    {
      "epoch": 52.381861575178995,
      "grad_norm": 0.43078964948654175,
      "learning_rate": 0.00042357446425476784,
      "loss": 1.923,
      "step": 11000
    },
    {
      "epoch": 52.42959427207637,
      "grad_norm": 0.40633830428123474,
      "learning_rate": 0.00042343782310990595,
      "loss": 1.9056,
      "step": 11010
    },
    {
      "epoch": 52.47732696897375,
      "grad_norm": 0.5000266432762146,
      "learning_rate": 0.00042330108200634725,
      "loss": 1.9256,
      "step": 11020
    },
    {
      "epoch": 52.52505966587112,
      "grad_norm": 0.4632454514503479,
      "learning_rate": 0.0004231642410229007,
      "loss": 1.906,
      "step": 11030
    },
    {
      "epoch": 52.572792362768496,
      "grad_norm": 0.45171919465065,
      "learning_rate": 0.00042302730023843283,
      "loss": 1.9192,
      "step": 11040
    },
    {
      "epoch": 52.62052505966587,
      "grad_norm": 0.4703204035758972,
      "learning_rate": 0.00042289025973186783,
      "loss": 1.9149,
      "step": 11050
    },
    {
      "epoch": 52.66825775656324,
      "grad_norm": 0.47019341588020325,
      "learning_rate": 0.0004227531195821872,
      "loss": 1.9384,
      "step": 11060
    },
    {
      "epoch": 52.71599045346062,
      "grad_norm": 0.4277929365634918,
      "learning_rate": 0.00042261587986842984,
      "loss": 1.9332,
      "step": 11070
    },
    {
      "epoch": 52.763723150358,
      "grad_norm": 0.44265639781951904,
      "learning_rate": 0.0004224785406696924,
      "loss": 1.9133,
      "step": 11080
    },
    {
      "epoch": 52.81145584725537,
      "grad_norm": 0.41631749272346497,
      "learning_rate": 0.00042234110206512834,
      "loss": 1.924,
      "step": 11090
    },
    {
      "epoch": 52.859188544152744,
      "grad_norm": 0.41526058316230774,
      "learning_rate": 0.0004222035641339486,
      "loss": 1.9185,
      "step": 11100
    },
    {
      "epoch": 52.90692124105012,
      "grad_norm": 0.5418366193771362,
      "learning_rate": 0.00042206592695542166,
      "loss": 1.9238,
      "step": 11110
    },
    {
      "epoch": 52.95465393794749,
      "grad_norm": 0.39792755246162415,
      "learning_rate": 0.0004219281906088729,
      "loss": 1.9211,
      "step": 11120
    },
    {
      "epoch": 53.0,
      "grad_norm": 0.3464113175868988,
      "learning_rate": 0.0004217903551736849,
      "loss": 1.8256,
      "step": 11130
    },
    {
      "epoch": 53.0,
      "eval_loss": 1.0621333122253418,
      "eval_runtime": 4.3779,
      "eval_samples_per_second": 3353.402,
      "eval_steps_per_second": 13.248,
      "step": 11130
    },
    {
      "epoch": 53.04773269689738,
      "grad_norm": 0.3955542743206024,
      "learning_rate": 0.00042165242072929733,
      "loss": 1.9157,
      "step": 11140
    },
    {
      "epoch": 53.09546539379475,
      "grad_norm": 0.40383291244506836,
      "learning_rate": 0.000421514387355207,
      "loss": 1.9075,
      "step": 11150
    },
    {
      "epoch": 53.143198090692124,
      "grad_norm": 0.46337026357650757,
      "learning_rate": 0.00042137625513096773,
      "loss": 1.9006,
      "step": 11160
    },
    {
      "epoch": 53.1909307875895,
      "grad_norm": 0.4585254490375519,
      "learning_rate": 0.00042123802413619017,
      "loss": 1.9177,
      "step": 11170
    },
    {
      "epoch": 53.23866348448687,
      "grad_norm": 0.4126072824001312,
      "learning_rate": 0.00042109969445054213,
      "loss": 1.9095,
      "step": 11180
    },
    {
      "epoch": 53.28639618138425,
      "grad_norm": 0.406509667634964,
      "learning_rate": 0.00042096126615374815,
      "loss": 1.915,
      "step": 11190
    },
    {
      "epoch": 53.334128878281625,
      "grad_norm": 0.445681095123291,
      "learning_rate": 0.0004208227393255896,
      "loss": 1.9231,
      "step": 11200
    },
    {
      "epoch": 53.381861575178995,
      "grad_norm": 0.49082130193710327,
      "learning_rate": 0.00042068411404590466,
      "loss": 1.9041,
      "step": 11210
    },
    {
      "epoch": 53.42959427207637,
      "grad_norm": 0.3909035921096802,
      "learning_rate": 0.00042054539039458827,
      "loss": 1.9278,
      "step": 11220
    },
    {
      "epoch": 53.47732696897375,
      "grad_norm": 0.38812580704689026,
      "learning_rate": 0.000420406568451592,
      "loss": 1.915,
      "step": 11230
    },
    {
      "epoch": 53.52505966587112,
      "grad_norm": 0.43832141160964966,
      "learning_rate": 0.00042026764829692433,
      "loss": 1.9311,
      "step": 11240
    },
    {
      "epoch": 53.572792362768496,
      "grad_norm": 0.466764897108078,
      "learning_rate": 0.0004201286300106499,
      "loss": 1.9136,
      "step": 11250
    },
    {
      "epoch": 53.62052505966587,
      "grad_norm": 0.374546617269516,
      "learning_rate": 0.0004199895136728902,
      "loss": 1.9243,
      "step": 11260
    },
    {
      "epoch": 53.66825775656324,
      "grad_norm": 0.3913799822330475,
      "learning_rate": 0.0004198502993638232,
      "loss": 1.9231,
      "step": 11270
    },
    {
      "epoch": 53.71599045346062,
      "grad_norm": 0.4340902268886566,
      "learning_rate": 0.0004197109871636834,
      "loss": 1.9214,
      "step": 11280
    },
    {
      "epoch": 53.763723150358,
      "grad_norm": 0.42030251026153564,
      "learning_rate": 0.0004195715771527614,
      "loss": 1.9182,
      "step": 11290
    },
    {
      "epoch": 53.81145584725537,
      "grad_norm": 0.3829275965690613,
      "learning_rate": 0.00041943206941140454,
      "loss": 1.9223,
      "step": 11300
    },
    {
      "epoch": 53.859188544152744,
      "grad_norm": 0.41072532534599304,
      "learning_rate": 0.0004192924640200164,
      "loss": 1.9061,
      "step": 11310
    },
    {
      "epoch": 53.90692124105012,
      "grad_norm": 0.4245983958244324,
      "learning_rate": 0.0004191527610590567,
      "loss": 1.918,
      "step": 11320
    },
    {
      "epoch": 53.95465393794749,
      "grad_norm": 0.43490156531333923,
      "learning_rate": 0.0004190129606090415,
      "loss": 1.9188,
      "step": 11330
    },
    {
      "epoch": 54.0,
      "grad_norm": 0.389840692281723,
      "learning_rate": 0.00041887306275054293,
      "loss": 1.8408,
      "step": 11340
    },
    {
      "epoch": 54.0,
      "eval_loss": 1.058082103729248,
      "eval_runtime": 4.3733,
      "eval_samples_per_second": 3356.967,
      "eval_steps_per_second": 13.262,
      "step": 11340
    },
    {
      "epoch": 54.04773269689738,
      "grad_norm": 0.46487900614738464,
      "learning_rate": 0.0004187330675641895,
      "loss": 1.9114,
      "step": 11350
    },
    {
      "epoch": 54.09546539379475,
      "grad_norm": 0.3892078399658203,
      "learning_rate": 0.00041859297513066563,
      "loss": 1.9133,
      "step": 11360
    },
    {
      "epoch": 54.143198090692124,
      "grad_norm": 0.45842278003692627,
      "learning_rate": 0.0004184527855307117,
      "loss": 1.9007,
      "step": 11370
    },
    {
      "epoch": 54.1909307875895,
      "grad_norm": 0.4386545419692993,
      "learning_rate": 0.00041831249884512434,
      "loss": 1.9048,
      "step": 11380
    },
    {
      "epoch": 54.23866348448687,
      "grad_norm": 0.4252486824989319,
      "learning_rate": 0.00041817211515475603,
      "loss": 1.9074,
      "step": 11390
    },
    {
      "epoch": 54.28639618138425,
      "grad_norm": 0.46475642919540405,
      "learning_rate": 0.000418031634540515,
      "loss": 1.9155,
      "step": 11400
    },
    {
      "epoch": 54.334128878281625,
      "grad_norm": 0.4717930555343628,
      "learning_rate": 0.00041789105708336564,
      "loss": 1.9065,
      "step": 11410
    },
    {
      "epoch": 54.381861575178995,
      "grad_norm": 0.3954233229160309,
      "learning_rate": 0.0004177503828643278,
      "loss": 1.9123,
      "step": 11420
    },
    {
      "epoch": 54.42959427207637,
      "grad_norm": 0.44616758823394775,
      "learning_rate": 0.0004176096119644775,
      "loss": 1.9181,
      "step": 11430
    },
    {
      "epoch": 54.47732696897375,
      "grad_norm": 0.39007237553596497,
      "learning_rate": 0.0004174687444649461,
      "loss": 1.9167,
      "step": 11440
    },
    {
      "epoch": 54.52505966587112,
      "grad_norm": 0.41950374841690063,
      "learning_rate": 0.0004173277804469209,
      "loss": 1.9141,
      "step": 11450
    },
    {
      "epoch": 54.572792362768496,
      "grad_norm": 0.4046274423599243,
      "learning_rate": 0.0004171867199916446,
      "loss": 1.9102,
      "step": 11460
    },
    {
      "epoch": 54.62052505966587,
      "grad_norm": 0.5095316767692566,
      "learning_rate": 0.0004170455631804158,
      "loss": 1.907,
      "step": 11470
    },
    {
      "epoch": 54.66825775656324,
      "grad_norm": 0.49046581983566284,
      "learning_rate": 0.0004169043100945883,
      "loss": 1.9258,
      "step": 11480
    },
    {
      "epoch": 54.71599045346062,
      "grad_norm": 0.4222904443740845,
      "learning_rate": 0.00041676296081557163,
      "loss": 1.9189,
      "step": 11490
    },
    {
      "epoch": 54.763723150358,
      "grad_norm": 0.4299575388431549,
      "learning_rate": 0.0004166215154248305,
      "loss": 1.9079,
      "step": 11500
    },
    {
      "epoch": 54.81145584725537,
      "grad_norm": 0.4373838007450104,
      "learning_rate": 0.00041647997400388545,
      "loss": 1.9158,
      "step": 11510
    },
    {
      "epoch": 54.859188544152744,
      "grad_norm": 0.3992112874984741,
      "learning_rate": 0.0004163383366343118,
      "loss": 1.929,
      "step": 11520
    },
    {
      "epoch": 54.90692124105012,
      "grad_norm": 0.4996625781059265,
      "learning_rate": 0.00041619660339774065,
      "loss": 1.9268,
      "step": 11530
    },
    {
      "epoch": 54.95465393794749,
      "grad_norm": 0.46852269768714905,
      "learning_rate": 0.00041605477437585804,
      "loss": 1.9192,
      "step": 11540
    },
    {
      "epoch": 55.0,
      "grad_norm": 0.2879461646080017,
      "learning_rate": 0.0004159128496504053,
      "loss": 1.8289,
      "step": 11550
    },
    {
      "epoch": 55.0,
      "eval_loss": 1.0575922727584839,
      "eval_runtime": 4.5504,
      "eval_samples_per_second": 3226.287,
      "eval_steps_per_second": 12.746,
      "step": 11550
    },
    {
      "epoch": 55.04773269689738,
      "grad_norm": 0.40521833300590515,
      "learning_rate": 0.00041577082930317923,
      "loss": 1.8895,
      "step": 11560
    },
    {
      "epoch": 55.09546539379475,
      "grad_norm": 0.40453681349754333,
      "learning_rate": 0.0004156287134160311,
      "loss": 1.904,
      "step": 11570
    },
    {
      "epoch": 55.143198090692124,
      "grad_norm": 0.44129303097724915,
      "learning_rate": 0.0004154865020708678,
      "loss": 1.9029,
      "step": 11580
    },
    {
      "epoch": 55.1909307875895,
      "grad_norm": 0.44286099076271057,
      "learning_rate": 0.00041534419534965106,
      "loss": 1.9022,
      "step": 11590
    },
    {
      "epoch": 55.23866348448687,
      "grad_norm": 0.41284501552581787,
      "learning_rate": 0.00041520179333439744,
      "loss": 1.9015,
      "step": 11600
    },
    {
      "epoch": 55.28639618138425,
      "grad_norm": 0.4606340229511261,
      "learning_rate": 0.00041505929610717866,
      "loss": 1.901,
      "step": 11610
    },
    {
      "epoch": 55.334128878281625,
      "grad_norm": 0.3911014497280121,
      "learning_rate": 0.0004149167037501212,
      "loss": 1.9271,
      "step": 11620
    },
    {
      "epoch": 55.381861575178995,
      "grad_norm": 0.43223506212234497,
      "learning_rate": 0.0004147740163454062,
      "loss": 1.9015,
      "step": 11630
    },
    {
      "epoch": 55.42959427207637,
      "grad_norm": 0.4805702269077301,
      "learning_rate": 0.0004146312339752699,
      "loss": 1.9112,
      "step": 11640
    },
    {
      "epoch": 55.47732696897375,
      "grad_norm": 0.3908537030220032,
      "learning_rate": 0.00041448835672200303,
      "loss": 1.9053,
      "step": 11650
    },
    {
      "epoch": 55.52505966587112,
      "grad_norm": 0.4131835699081421,
      "learning_rate": 0.00041434538466795124,
      "loss": 1.9229,
      "step": 11660
    },
    {
      "epoch": 55.572792362768496,
      "grad_norm": 0.3969515562057495,
      "learning_rate": 0.00041420231789551445,
      "loss": 1.8989,
      "step": 11670
    },
    {
      "epoch": 55.62052505966587,
      "grad_norm": 0.3977926969528198,
      "learning_rate": 0.0004140591564871475,
      "loss": 1.9201,
      "step": 11680
    },
    {
      "epoch": 55.66825775656324,
      "grad_norm": 0.46083295345306396,
      "learning_rate": 0.0004139159005253597,
      "loss": 1.9145,
      "step": 11690
    },
    {
      "epoch": 55.71599045346062,
      "grad_norm": 0.4107828140258789,
      "learning_rate": 0.0004137725500927146,
      "loss": 1.9214,
      "step": 11700
    },
    {
      "epoch": 55.763723150358,
      "grad_norm": 0.4064542055130005,
      "learning_rate": 0.00041362910527183074,
      "loss": 1.9291,
      "step": 11710
    },
    {
      "epoch": 55.81145584725537,
      "grad_norm": 0.4397692084312439,
      "learning_rate": 0.00041348556614538047,
      "loss": 1.9067,
      "step": 11720
    },
    {
      "epoch": 55.859188544152744,
      "grad_norm": 0.4209090769290924,
      "learning_rate": 0.00041334193279609076,
      "loss": 1.9225,
      "step": 11730
    },
    {
      "epoch": 55.90692124105012,
      "grad_norm": 0.42366406321525574,
      "learning_rate": 0.0004131982053067431,
      "loss": 1.9198,
      "step": 11740
    },
    {
      "epoch": 55.95465393794749,
      "grad_norm": 0.3946131765842438,
      "learning_rate": 0.0004130543837601728,
      "loss": 1.8987,
      "step": 11750
    },
    {
      "epoch": 56.0,
      "grad_norm": 0.282812237739563,
      "learning_rate": 0.0004129104682392697,
      "loss": 1.8418,
      "step": 11760
    },
    {
      "epoch": 56.0,
      "eval_loss": 1.0565948486328125,
      "eval_runtime": 4.424,
      "eval_samples_per_second": 3318.465,
      "eval_steps_per_second": 13.11,
      "step": 11760
    },
    {
      "epoch": 56.04773269689738,
      "grad_norm": 0.44548454880714417,
      "learning_rate": 0.00041276645882697756,
      "loss": 1.9102,
      "step": 11770
    },
    {
      "epoch": 56.09546539379475,
      "grad_norm": 0.4382898509502411,
      "learning_rate": 0.0004126223556062945,
      "loss": 1.9069,
      "step": 11780
    },
    {
      "epoch": 56.143198090692124,
      "grad_norm": 0.4311332702636719,
      "learning_rate": 0.00041247815866027256,
      "loss": 1.8989,
      "step": 11790
    },
    {
      "epoch": 56.1909307875895,
      "grad_norm": 0.458490788936615,
      "learning_rate": 0.00041233386807201783,
      "loss": 1.9054,
      "step": 11800
    },
    {
      "epoch": 56.23866348448687,
      "grad_norm": 0.4012974500656128,
      "learning_rate": 0.00041218948392469034,
      "loss": 1.8935,
      "step": 11810
    },
    {
      "epoch": 56.28639618138425,
      "grad_norm": 0.3933075964450836,
      "learning_rate": 0.0004120450063015042,
      "loss": 1.9049,
      "step": 11820
    },
    {
      "epoch": 56.334128878281625,
      "grad_norm": 0.4177786707878113,
      "learning_rate": 0.00041190043528572704,
      "loss": 1.9119,
      "step": 11830
    },
    {
      "epoch": 56.381861575178995,
      "grad_norm": 0.42800992727279663,
      "learning_rate": 0.00041175577096068064,
      "loss": 1.8996,
      "step": 11840
    },
    {
      "epoch": 56.42959427207637,
      "grad_norm": 0.44413769245147705,
      "learning_rate": 0.0004116110134097405,
      "loss": 1.9032,
      "step": 11850
    },
    {
      "epoch": 56.47732696897375,
      "grad_norm": 0.4113961458206177,
      "learning_rate": 0.0004114661627163357,
      "loss": 1.9123,
      "step": 11860
    },
    {
      "epoch": 56.52505966587112,
      "grad_norm": 0.41866281628608704,
      "learning_rate": 0.0004113212189639493,
      "loss": 1.9086,
      "step": 11870
    },
    {
      "epoch": 56.572792362768496,
      "grad_norm": 0.43501853942871094,
      "learning_rate": 0.00041117618223611766,
      "loss": 1.9122,
      "step": 11880
    },
    {
      "epoch": 56.62052505966587,
      "grad_norm": 0.3722912669181824,
      "learning_rate": 0.0004110310526164308,
      "loss": 1.9103,
      "step": 11890
    },
    {
      "epoch": 56.66825775656324,
      "grad_norm": 0.40725165605545044,
      "learning_rate": 0.00041088583018853244,
      "loss": 1.9086,
      "step": 11900
    },
    {
      "epoch": 56.71599045346062,
      "grad_norm": 0.42664188146591187,
      "learning_rate": 0.00041074051503611964,
      "loss": 1.9318,
      "step": 11910
    },
    {
      "epoch": 56.763723150358,
      "grad_norm": 0.4071873128414154,
      "learning_rate": 0.000410595107242943,
      "loss": 1.9156,
      "step": 11920
    },
    {
      "epoch": 56.81145584725537,
      "grad_norm": 0.40089064836502075,
      "learning_rate": 0.00041044960689280653,
      "loss": 1.9105,
      "step": 11930
    },
    {
      "epoch": 56.859188544152744,
      "grad_norm": 0.38494259119033813,
      "learning_rate": 0.00041030401406956735,
      "loss": 1.9086,
      "step": 11940
    },
    {
      "epoch": 56.90692124105012,
      "grad_norm": 0.4255584180355072,
      "learning_rate": 0.00041015832885713617,
      "loss": 1.9004,
      "step": 11950
    },
    {
      "epoch": 56.95465393794749,
      "grad_norm": 0.42784202098846436,
      "learning_rate": 0.0004100125513394768,
      "loss": 1.9108,
      "step": 11960
    },
    {
      "epoch": 57.0,
      "grad_norm": 0.31946784257888794,
      "learning_rate": 0.00040986668160060614,
      "loss": 1.8234,
      "step": 11970
    },
    {
      "epoch": 57.0,
      "eval_loss": 1.058152198791504,
      "eval_runtime": 4.4213,
      "eval_samples_per_second": 3320.547,
      "eval_steps_per_second": 13.118,
      "step": 11970
    },
    {
      "epoch": 57.04773269689738,
      "grad_norm": 0.4075625240802765,
      "learning_rate": 0.0004097207197245945,
      "loss": 1.8991,
      "step": 11980
    },
    {
      "epoch": 57.09546539379475,
      "grad_norm": 0.391613632440567,
      "learning_rate": 0.00040957466579556517,
      "loss": 1.8883,
      "step": 11990
    },
    {
      "epoch": 57.143198090692124,
      "grad_norm": 0.4500851631164551,
      "learning_rate": 0.0004094285198976945,
      "loss": 1.8873,
      "step": 12000
    },
    {
      "epoch": 57.1909307875895,
      "grad_norm": 0.421485960483551,
      "learning_rate": 0.0004092822821152117,
      "loss": 1.9141,
      "step": 12010
    },
    {
      "epoch": 57.23866348448687,
      "grad_norm": 0.4070688784122467,
      "learning_rate": 0.00040913595253239923,
      "loss": 1.9135,
      "step": 12020
    },
    {
      "epoch": 57.28639618138425,
      "grad_norm": 0.42678147554397583,
      "learning_rate": 0.0004089895312335922,
      "loss": 1.9066,
      "step": 12030
    },
    {
      "epoch": 57.334128878281625,
      "grad_norm": 0.4170439541339874,
      "learning_rate": 0.0004088430183031786,
      "loss": 1.9101,
      "step": 12040
    },
    {
      "epoch": 57.381861575178995,
      "grad_norm": 0.43560513854026794,
      "learning_rate": 0.0004086964138255995,
      "loss": 1.899,
      "step": 12050
    },
    {
      "epoch": 57.42959427207637,
      "grad_norm": 0.43515151739120483,
      "learning_rate": 0.00040854971788534836,
      "loss": 1.9063,
      "step": 12060
    },
    {
      "epoch": 57.47732696897375,
      "grad_norm": 0.4334840178489685,
      "learning_rate": 0.00040840293056697166,
      "loss": 1.9085,
      "step": 12070
    },
    {
      "epoch": 57.52505966587112,
      "grad_norm": 0.41437867283821106,
      "learning_rate": 0.00040825605195506836,
      "loss": 1.8935,
      "step": 12080
    },
    {
      "epoch": 57.572792362768496,
      "grad_norm": 0.39386364817619324,
      "learning_rate": 0.0004081090821342901,
      "loss": 1.9091,
      "step": 12090
    },
    {
      "epoch": 57.62052505966587,
      "grad_norm": 0.4249221682548523,
      "learning_rate": 0.000407962021189341,
      "loss": 1.9097,
      "step": 12100
    },
    {
      "epoch": 57.66825775656324,
      "grad_norm": 0.41722050309181213,
      "learning_rate": 0.0004078148692049779,
      "loss": 1.9067,
      "step": 12110
    },
    {
      "epoch": 57.71599045346062,
      "grad_norm": 0.4135090112686157,
      "learning_rate": 0.00040766762626600993,
      "loss": 1.912,
      "step": 12120
    },
    {
      "epoch": 57.763723150358,
      "grad_norm": 0.4372018873691559,
      "learning_rate": 0.00040752029245729864,
      "loss": 1.9021,
      "step": 12130
    },
    {
      "epoch": 57.81145584725537,
      "grad_norm": 0.4163013696670532,
      "learning_rate": 0.00040737286786375816,
      "loss": 1.9143,
      "step": 12140
    },
    {
      "epoch": 57.859188544152744,
      "grad_norm": 0.4364969730377197,
      "learning_rate": 0.00040722535257035463,
      "loss": 1.9068,
      "step": 12150
    },
    {
      "epoch": 57.90692124105012,
      "grad_norm": 0.39756330847740173,
      "learning_rate": 0.00040707774666210676,
      "loss": 1.9089,
      "step": 12160
    },
    {
      "epoch": 57.95465393794749,
      "grad_norm": 0.4493390619754791,
      "learning_rate": 0.00040693005022408526,
      "loss": 1.9036,
      "step": 12170
    },
    {
      "epoch": 58.0,
      "grad_norm": 0.33634915947914124,
      "learning_rate": 0.00040678226334141303,
      "loss": 1.8122,
      "step": 12180
    },
    {
      "epoch": 58.0,
      "eval_loss": 1.0594186782836914,
      "eval_runtime": 4.3817,
      "eval_samples_per_second": 3350.5,
      "eval_steps_per_second": 13.237,
      "step": 12180
    },
    {
      "epoch": 58.04773269689738,
      "grad_norm": 0.44080305099487305,
      "learning_rate": 0.0004066343860992654,
      "loss": 1.8924,
      "step": 12190
    },
    {
      "epoch": 58.09546539379475,
      "grad_norm": 0.44394776225090027,
      "learning_rate": 0.00040648641858286933,
      "loss": 1.8823,
      "step": 12200
    },
    {
      "epoch": 58.143198090692124,
      "grad_norm": 0.4725317060947418,
      "learning_rate": 0.00040633836087750416,
      "loss": 1.8822,
      "step": 12210
    },
    {
      "epoch": 58.1909307875895,
      "grad_norm": 0.4312087595462799,
      "learning_rate": 0.000406190213068501,
      "loss": 1.8991,
      "step": 12220
    },
    {
      "epoch": 58.23866348448687,
      "grad_norm": 0.4567883014678955,
      "learning_rate": 0.000406041975241243,
      "loss": 1.9062,
      "step": 12230
    },
    {
      "epoch": 58.28639618138425,
      "grad_norm": 0.4235696494579315,
      "learning_rate": 0.0004058936474811652,
      "loss": 1.9003,
      "step": 12240
    },
    {
      "epoch": 58.334128878281625,
      "grad_norm": 0.44663476943969727,
      "learning_rate": 0.00040574522987375436,
      "loss": 1.8912,
      "step": 12250
    },
    {
      "epoch": 58.381861575178995,
      "grad_norm": 0.45384055376052856,
      "learning_rate": 0.0004055967225045491,
      "loss": 1.904,
      "step": 12260
    },
    {
      "epoch": 58.42959427207637,
      "grad_norm": 0.39446234703063965,
      "learning_rate": 0.0004054481254591398,
      "loss": 1.906,
      "step": 12270
    },
    {
      "epoch": 58.47732696897375,
      "grad_norm": 0.3996211886405945,
      "learning_rate": 0.0004052994388231684,
      "loss": 1.9043,
      "step": 12280
    },
    {
      "epoch": 58.52505966587112,
      "grad_norm": 0.5880366563796997,
      "learning_rate": 0.00040515066268232883,
      "loss": 1.9106,
      "step": 12290
    },
    {
      "epoch": 58.572792362768496,
      "grad_norm": 0.41276928782463074,
      "learning_rate": 0.00040500179712236594,
      "loss": 1.9182,
      "step": 12300
    },
    {
      "epoch": 58.62052505966587,
      "grad_norm": 0.44836124777793884,
      "learning_rate": 0.0004048528422290768,
      "loss": 1.9096,
      "step": 12310
    },
    {
      "epoch": 58.66825775656324,
      "grad_norm": 0.4221169948577881,
      "learning_rate": 0.0004047037980883096,
      "loss": 1.9179,
      "step": 12320
    },
    {
      "epoch": 58.71599045346062,
      "grad_norm": 0.4048744738101959,
      "learning_rate": 0.000404554664785964,
      "loss": 1.917,
      "step": 12330
    },
    {
      "epoch": 58.763723150358,
      "grad_norm": 0.39898064732551575,
      "learning_rate": 0.00040440544240799114,
      "loss": 1.8932,
      "step": 12340
    },
    {
      "epoch": 58.81145584725537,
      "grad_norm": 0.40288427472114563,
      "learning_rate": 0.0004042561310403935,
      "loss": 1.9021,
      "step": 12350
    },
    {
      "epoch": 58.859188544152744,
      "grad_norm": 0.4465094208717346,
      "learning_rate": 0.0004041067307692247,
      "loss": 1.8987,
      "step": 12360
    },
    {
      "epoch": 58.90692124105012,
      "grad_norm": 0.4099334180355072,
      "learning_rate": 0.0004039572416805898,
      "loss": 1.8919,
      "step": 12370
    },
    {
      "epoch": 58.95465393794749,
      "grad_norm": 0.3946338891983032,
      "learning_rate": 0.00040380766386064485,
      "loss": 1.9031,
      "step": 12380
    },
    {
      "epoch": 59.0,
      "grad_norm": 0.30276036262512207,
      "learning_rate": 0.0004036579973955972,
      "loss": 1.8099,
      "step": 12390
    },
    {
      "epoch": 59.0,
      "eval_loss": 1.0605857372283936,
      "eval_runtime": 4.3808,
      "eval_samples_per_second": 3351.239,
      "eval_steps_per_second": 13.24,
      "step": 12390
    },
    {
      "epoch": 59.04773269689738,
      "grad_norm": 0.4089978039264679,
      "learning_rate": 0.00040350824237170513,
      "loss": 1.8831,
      "step": 12400
    },
    {
      "epoch": 59.09546539379475,
      "grad_norm": 0.4319576025009155,
      "learning_rate": 0.00040335839887527817,
      "loss": 1.8905,
      "step": 12410
    },
    {
      "epoch": 59.143198090692124,
      "grad_norm": 0.4780678153038025,
      "learning_rate": 0.0004032084669926767,
      "loss": 1.8945,
      "step": 12420
    },
    {
      "epoch": 59.1909307875895,
      "grad_norm": 0.44995394349098206,
      "learning_rate": 0.00040305844681031203,
      "loss": 1.8946,
      "step": 12430
    },
    {
      "epoch": 59.23866348448687,
      "grad_norm": 0.4112642705440521,
      "learning_rate": 0.00040290833841464635,
      "loss": 1.8904,
      "step": 12440
    },
    {
      "epoch": 59.28639618138425,
      "grad_norm": 0.3891552984714508,
      "learning_rate": 0.0004027581418921929,
      "loss": 1.91,
      "step": 12450
    },
    {
      "epoch": 59.334128878281625,
      "grad_norm": 0.39992085099220276,
      "learning_rate": 0.00040260785732951546,
      "loss": 1.8989,
      "step": 12460
    },
    {
      "epoch": 59.381861575178995,
      "grad_norm": 0.43020278215408325,
      "learning_rate": 0.0004024574848132285,
      "loss": 1.9006,
      "step": 12470
    },
    {
      "epoch": 59.42959427207637,
      "grad_norm": 0.40343838930130005,
      "learning_rate": 0.0004023070244299975,
      "loss": 1.8864,
      "step": 12480
    },
    {
      "epoch": 59.47732696897375,
      "grad_norm": 0.4003022015094757,
      "learning_rate": 0.0004021564762665384,
      "loss": 1.8933,
      "step": 12490
    },
    {
      "epoch": 59.52505966587112,
      "grad_norm": 0.4183287024497986,
      "learning_rate": 0.0004020058404096176,
      "loss": 1.8981,
      "step": 12500
    },
    {
      "epoch": 59.572792362768496,
      "grad_norm": 0.39907997846603394,
      "learning_rate": 0.00040185511694605224,
      "loss": 1.905,
      "step": 12510
    },
    {
      "epoch": 59.62052505966587,
      "grad_norm": 0.4130619466304779,
      "learning_rate": 0.0004017043059627099,
      "loss": 1.901,
      "step": 12520
    },
    {
      "epoch": 59.66825775656324,
      "grad_norm": 0.38405027985572815,
      "learning_rate": 0.0004015534075465086,
      "loss": 1.8967,
      "step": 12530
    },
    {
      "epoch": 59.71599045346062,
      "grad_norm": 0.42334800958633423,
      "learning_rate": 0.00040140242178441667,
      "loss": 1.8931,
      "step": 12540
    },
    {
      "epoch": 59.763723150358,
      "grad_norm": 0.40737777948379517,
      "learning_rate": 0.00040125134876345294,
      "loss": 1.9125,
      "step": 12550
    },
    {
      "epoch": 59.81145584725537,
      "grad_norm": 0.3928855061531067,
      "learning_rate": 0.0004011001885706863,
      "loss": 1.9018,
      "step": 12560
    },
    {
      "epoch": 59.859188544152744,
      "grad_norm": 0.4543447494506836,
      "learning_rate": 0.00040094894129323616,
      "loss": 1.8919,
      "step": 12570
    },
    {
      "epoch": 59.90692124105012,
      "grad_norm": 0.38776078820228577,
      "learning_rate": 0.00040079760701827185,
      "loss": 1.8987,
      "step": 12580
    },
    {
      "epoch": 59.95465393794749,
      "grad_norm": 0.3721619248390198,
      "learning_rate": 0.00040064618583301304,
      "loss": 1.9124,
      "step": 12590
    },
    {
      "epoch": 60.0,
      "grad_norm": 0.3109825551509857,
      "learning_rate": 0.00040049467782472944,
      "loss": 1.7999,
      "step": 12600
    },
    {
      "epoch": 60.0,
      "eval_loss": 1.0634082555770874,
      "eval_runtime": 4.395,
      "eval_samples_per_second": 3340.374,
      "eval_steps_per_second": 13.197,
      "step": 12600
    },
    {
      "epoch": 60.04773269689738,
      "grad_norm": 0.3909595310688019,
      "learning_rate": 0.00040034308308074075,
      "loss": 1.8821,
      "step": 12610
    },
    {
      "epoch": 60.09546539379475,
      "grad_norm": 0.4132120907306671,
      "learning_rate": 0.0004001914016884166,
      "loss": 1.8818,
      "step": 12620
    },
    {
      "epoch": 60.143198090692124,
      "grad_norm": 0.6905714869499207,
      "learning_rate": 0.00040003963373517673,
      "loss": 1.8953,
      "step": 12630
    },
    {
      "epoch": 60.1909307875895,
      "grad_norm": 0.40457090735435486,
      "learning_rate": 0.00039988777930849065,
      "loss": 1.8941,
      "step": 12640
    },
    {
      "epoch": 60.23866348448687,
      "grad_norm": 0.4562190771102905,
      "learning_rate": 0.0003997358384958778,
      "loss": 1.8923,
      "step": 12650
    },
    {
      "epoch": 60.28639618138425,
      "grad_norm": 0.396816223859787,
      "learning_rate": 0.0003995838113849073,
      "loss": 1.8953,
      "step": 12660
    },
    {
      "epoch": 60.334128878281625,
      "grad_norm": 0.4056251645088196,
      "learning_rate": 0.000399431698063198,
      "loss": 1.8928,
      "step": 12670
    },
    {
      "epoch": 60.381861575178995,
      "grad_norm": 0.45319676399230957,
      "learning_rate": 0.00039927949861841863,
      "loss": 1.8956,
      "step": 12680
    },
    {
      "epoch": 60.42959427207637,
      "grad_norm": 0.4487920105457306,
      "learning_rate": 0.0003991272131382873,
      "loss": 1.886,
      "step": 12690
    },
    {
      "epoch": 60.47732696897375,
      "grad_norm": 0.37923678755760193,
      "learning_rate": 0.00039897484171057187,
      "loss": 1.9055,
      "step": 12700
    },
    {
      "epoch": 60.52505966587112,
      "grad_norm": 0.3730517029762268,
      "learning_rate": 0.0003988223844230896,
      "loss": 1.8888,
      "step": 12710
    },
    {
      "epoch": 60.572792362768496,
      "grad_norm": 0.46347418427467346,
      "learning_rate": 0.0003986698413637074,
      "loss": 1.9043,
      "step": 12720
    },
    {
      "epoch": 60.62052505966587,
      "grad_norm": 0.44243279099464417,
      "learning_rate": 0.00039851721262034156,
      "loss": 1.9016,
      "step": 12730
    },
    {
      "epoch": 60.66825775656324,
      "grad_norm": 0.4017469882965088,
      "learning_rate": 0.0003983644982809577,
      "loss": 1.8966,
      "step": 12740
    },
    {
      "epoch": 60.71599045346062,
      "grad_norm": 0.41545239090919495,
      "learning_rate": 0.00039821169843357073,
      "loss": 1.9065,
      "step": 12750
    },
    {
      "epoch": 60.763723150358,
      "grad_norm": 0.4276812672615051,
      "learning_rate": 0.000398058813166245,
      "loss": 1.8975,
      "step": 12760
    },
    {
      "epoch": 60.81145584725537,
      "grad_norm": 0.3980806767940521,
      "learning_rate": 0.000397905842567094,
      "loss": 1.9034,
      "step": 12770
    },
    {
      "epoch": 60.859188544152744,
      "grad_norm": 0.4303804039955139,
      "learning_rate": 0.00039775278672428025,
      "loss": 1.9001,
      "step": 12780
    },
    {
      "epoch": 60.90692124105012,
      "grad_norm": 0.45067837834358215,
      "learning_rate": 0.0003975996457260158,
      "loss": 1.8897,
      "step": 12790
    },
    {
      "epoch": 60.95465393794749,
      "grad_norm": 0.4621531665325165,
      "learning_rate": 0.00039744641966056143,
      "loss": 1.8971,
      "step": 12800
    },
    {
      "epoch": 61.0,
      "grad_norm": 0.3168897330760956,
      "learning_rate": 0.0003972931086162269,
      "loss": 1.7946,
      "step": 12810
    },
    {
      "epoch": 61.0,
      "eval_loss": 1.0595115423202515,
      "eval_runtime": 4.3879,
      "eval_samples_per_second": 3345.758,
      "eval_steps_per_second": 13.218,
      "step": 12810
    },
    {
      "epoch": 61.0,
      "step": 12810,
      "total_flos": 1.76727842095104e+16,
      "train_loss": 2.1822104107858986,
      "train_runtime": 3696.6644,
      "train_samples_per_second": 5800.418,
      "train_steps_per_second": 11.307
    }
  ],
  "logging_steps": 10,
  "max_steps": 41800,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 200,
  "save_steps": 1000,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 20,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 20
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.76727842095104e+16,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
