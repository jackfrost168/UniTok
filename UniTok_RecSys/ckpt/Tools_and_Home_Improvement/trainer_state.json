{
  "best_metric": 1.1307239532470703,
  "best_model_checkpoint": "./ckpt/Tools_and_Home_Improvement/checkpoint-10292",
  "epoch": 82.0,
  "eval_steps": 1000,
  "global_step": 13612,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06042296072507553,
      "grad_norm": 12.079938888549805,
      "learning_rate": 1.5151515151515153e-05,
      "loss": 21.7003,
      "step": 10
    },
    {
      "epoch": 0.12084592145015106,
      "grad_norm": 7.689033031463623,
      "learning_rate": 3.0303030303030306e-05,
      "loss": 20.057,
      "step": 20
    },
    {
      "epoch": 0.18126888217522658,
      "grad_norm": 4.517756938934326,
      "learning_rate": 4.545454545454546e-05,
      "loss": 18.0158,
      "step": 30
    },
    {
      "epoch": 0.24169184290030213,
      "grad_norm": 3.6527833938598633,
      "learning_rate": 6.060606060606061e-05,
      "loss": 16.3871,
      "step": 40
    },
    {
      "epoch": 0.3021148036253776,
      "grad_norm": 3.3631398677825928,
      "learning_rate": 7.575757575757576e-05,
      "loss": 14.6497,
      "step": 50
    },
    {
      "epoch": 0.36253776435045315,
      "grad_norm": 2.912344455718994,
      "learning_rate": 9.090909090909092e-05,
      "loss": 12.6479,
      "step": 60
    },
    {
      "epoch": 0.4229607250755287,
      "grad_norm": 2.670689105987549,
      "learning_rate": 0.00010606060606060606,
      "loss": 10.8245,
      "step": 70
    },
    {
      "epoch": 0.48338368580060426,
      "grad_norm": 2.0088887214660645,
      "learning_rate": 0.00012121212121212122,
      "loss": 9.2462,
      "step": 80
    },
    {
      "epoch": 0.5438066465256798,
      "grad_norm": 1.4805423021316528,
      "learning_rate": 0.00013636363636363637,
      "loss": 8.1328,
      "step": 90
    },
    {
      "epoch": 0.6042296072507553,
      "grad_norm": 1.229559302330017,
      "learning_rate": 0.00015151515151515152,
      "loss": 7.4352,
      "step": 100
    },
    {
      "epoch": 0.6646525679758308,
      "grad_norm": 1.1308456659317017,
      "learning_rate": 0.00016666666666666666,
      "loss": 6.9845,
      "step": 110
    },
    {
      "epoch": 0.7250755287009063,
      "grad_norm": 0.9940710663795471,
      "learning_rate": 0.00018181818181818183,
      "loss": 6.6149,
      "step": 120
    },
    {
      "epoch": 0.7854984894259819,
      "grad_norm": 0.9690824747085571,
      "learning_rate": 0.00019696969696969695,
      "loss": 6.3367,
      "step": 130
    },
    {
      "epoch": 0.8459214501510574,
      "grad_norm": 0.8935335874557495,
      "learning_rate": 0.00021212121212121213,
      "loss": 6.1799,
      "step": 140
    },
    {
      "epoch": 0.9063444108761329,
      "grad_norm": 0.8402791619300842,
      "learning_rate": 0.00022727272727272727,
      "loss": 6.0009,
      "step": 150
    },
    {
      "epoch": 0.9667673716012085,
      "grad_norm": 1.0698411464691162,
      "learning_rate": 0.00024242424242424245,
      "loss": 5.8961,
      "step": 160
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.755506753921509,
      "eval_runtime": 4.5446,
      "eval_samples_per_second": 3661.033,
      "eval_steps_per_second": 14.303,
      "step": 166
    },
    {
      "epoch": 1.0241691842900302,
      "grad_norm": 0.7281096577644348,
      "learning_rate": 0.00025757575757575756,
      "loss": 5.4999,
      "step": 170
    },
    {
      "epoch": 1.0845921450151057,
      "grad_norm": 0.7227909564971924,
      "learning_rate": 0.00027272727272727274,
      "loss": 5.6931,
      "step": 180
    },
    {
      "epoch": 1.1450151057401814,
      "grad_norm": 0.6572670340538025,
      "learning_rate": 0.0002878787878787879,
      "loss": 5.621,
      "step": 190
    },
    {
      "epoch": 1.2054380664652569,
      "grad_norm": 0.842445433139801,
      "learning_rate": 0.00030303030303030303,
      "loss": 5.5134,
      "step": 200
    },
    {
      "epoch": 1.2658610271903323,
      "grad_norm": 0.6341268420219421,
      "learning_rate": 0.0003181818181818182,
      "loss": 5.4722,
      "step": 210
    },
    {
      "epoch": 1.3262839879154078,
      "grad_norm": 1.0330170392990112,
      "learning_rate": 0.0003333333333333333,
      "loss": 5.3635,
      "step": 220
    },
    {
      "epoch": 1.3867069486404833,
      "grad_norm": 0.6588951349258423,
      "learning_rate": 0.0003484848484848485,
      "loss": 5.3039,
      "step": 230
    },
    {
      "epoch": 1.447129909365559,
      "grad_norm": 0.6912065744400024,
      "learning_rate": 0.00036363636363636367,
      "loss": 5.2264,
      "step": 240
    },
    {
      "epoch": 1.5075528700906344,
      "grad_norm": 0.5855735540390015,
      "learning_rate": 0.0003787878787878788,
      "loss": 5.162,
      "step": 250
    },
    {
      "epoch": 1.5679758308157101,
      "grad_norm": 0.5724233984947205,
      "learning_rate": 0.0003939393939393939,
      "loss": 5.066,
      "step": 260
    },
    {
      "epoch": 1.6283987915407856,
      "grad_norm": 0.6109152436256409,
      "learning_rate": 0.00040909090909090913,
      "loss": 5.0081,
      "step": 270
    },
    {
      "epoch": 1.688821752265861,
      "grad_norm": 0.5305494666099548,
      "learning_rate": 0.00042424242424242425,
      "loss": 4.9367,
      "step": 280
    },
    {
      "epoch": 1.7492447129909365,
      "grad_norm": 0.5952295064926147,
      "learning_rate": 0.0004393939393939394,
      "loss": 4.8609,
      "step": 290
    },
    {
      "epoch": 1.809667673716012,
      "grad_norm": 0.4922146797180176,
      "learning_rate": 0.00045454545454545455,
      "loss": 4.7613,
      "step": 300
    },
    {
      "epoch": 1.8700906344410875,
      "grad_norm": 0.4800945520401001,
      "learning_rate": 0.0004696969696969697,
      "loss": 4.6853,
      "step": 310
    },
    {
      "epoch": 1.9305135951661632,
      "grad_norm": 0.4612559676170349,
      "learning_rate": 0.0004848484848484849,
      "loss": 4.5916,
      "step": 320
    },
    {
      "epoch": 1.9909365558912386,
      "grad_norm": 0.518921971321106,
      "learning_rate": 0.0005,
      "loss": 4.5064,
      "step": 330
    },
    {
      "epoch": 2.0,
      "eval_loss": 2.1685588359832764,
      "eval_runtime": 4.5784,
      "eval_samples_per_second": 3634.017,
      "eval_steps_per_second": 14.197,
      "step": 332
    },
    {
      "epoch": 2.0483383685800605,
      "grad_norm": 0.860261857509613,
      "learning_rate": 0.0004999998844123442,
      "loss": 4.2324,
      "step": 340
    },
    {
      "epoch": 2.108761329305136,
      "grad_norm": 0.5395888686180115,
      "learning_rate": 0.0004999995376494837,
      "loss": 4.3815,
      "step": 350
    },
    {
      "epoch": 2.1691842900302114,
      "grad_norm": 0.4387736916542053,
      "learning_rate": 0.0004999989597117392,
      "loss": 4.2906,
      "step": 360
    },
    {
      "epoch": 2.229607250755287,
      "grad_norm": 0.5196046829223633,
      "learning_rate": 0.000499998150599645,
      "loss": 4.1943,
      "step": 370
    },
    {
      "epoch": 2.290030211480363,
      "grad_norm": 0.44631922245025635,
      "learning_rate": 0.0004999971103139495,
      "loss": 4.1344,
      "step": 380
    },
    {
      "epoch": 2.3504531722054383,
      "grad_norm": 0.5631475448608398,
      "learning_rate": 0.0004999958388556144,
      "loss": 4.0525,
      "step": 390
    },
    {
      "epoch": 2.4108761329305137,
      "grad_norm": 0.4020879864692688,
      "learning_rate": 0.0004999943362258156,
      "loss": 3.9713,
      "step": 400
    },
    {
      "epoch": 2.471299093655589,
      "grad_norm": 0.36707738041877747,
      "learning_rate": 0.0004999926024259425,
      "loss": 3.9179,
      "step": 410
    },
    {
      "epoch": 2.5317220543806647,
      "grad_norm": 0.3908873200416565,
      "learning_rate": 0.0004999906374575983,
      "loss": 3.8491,
      "step": 420
    },
    {
      "epoch": 2.59214501510574,
      "grad_norm": 0.3572808802127838,
      "learning_rate": 0.0004999884413226001,
      "loss": 3.7847,
      "step": 430
    },
    {
      "epoch": 2.6525679758308156,
      "grad_norm": 0.3894193768501282,
      "learning_rate": 0.0004999860140229787,
      "loss": 3.7164,
      "step": 440
    },
    {
      "epoch": 2.712990936555891,
      "grad_norm": 0.5276638865470886,
      "learning_rate": 0.0004999833555609786,
      "loss": 3.6399,
      "step": 450
    },
    {
      "epoch": 2.7734138972809665,
      "grad_norm": 0.3940548896789551,
      "learning_rate": 0.000499980465939058,
      "loss": 3.5765,
      "step": 460
    },
    {
      "epoch": 2.8338368580060425,
      "grad_norm": 0.40789487957954407,
      "learning_rate": 0.000499977345159889,
      "loss": 3.5435,
      "step": 470
    },
    {
      "epoch": 2.894259818731118,
      "grad_norm": 0.3337283730506897,
      "learning_rate": 0.0004999739932263574,
      "loss": 3.4616,
      "step": 480
    },
    {
      "epoch": 2.9546827794561934,
      "grad_norm": 0.3759295642375946,
      "learning_rate": 0.0004999704101415627,
      "loss": 3.445,
      "step": 490
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.6300855875015259,
      "eval_runtime": 4.5631,
      "eval_samples_per_second": 3646.222,
      "eval_steps_per_second": 14.245,
      "step": 498
    },
    {
      "epoch": 3.012084592145015,
      "grad_norm": 0.32182300090789795,
      "learning_rate": 0.0004999665959088182,
      "loss": 3.205,
      "step": 500
    },
    {
      "epoch": 3.0725075528700905,
      "grad_norm": 0.32738593220710754,
      "learning_rate": 0.0004999625505316509,
      "loss": 3.344,
      "step": 510
    },
    {
      "epoch": 3.1329305135951664,
      "grad_norm": 0.31285786628723145,
      "learning_rate": 0.0004999582740138017,
      "loss": 3.2738,
      "step": 520
    },
    {
      "epoch": 3.193353474320242,
      "grad_norm": 0.3380979001522064,
      "learning_rate": 0.0004999537663592249,
      "loss": 3.2411,
      "step": 530
    },
    {
      "epoch": 3.2537764350453173,
      "grad_norm": 0.29323312640190125,
      "learning_rate": 0.0004999490275720888,
      "loss": 3.1903,
      "step": 540
    },
    {
      "epoch": 3.314199395770393,
      "grad_norm": 0.2700639069080353,
      "learning_rate": 0.0004999440576567755,
      "loss": 3.1709,
      "step": 550
    },
    {
      "epoch": 3.3746223564954683,
      "grad_norm": 0.2590751647949219,
      "learning_rate": 0.0004999388566178805,
      "loss": 3.1319,
      "step": 560
    },
    {
      "epoch": 3.4350453172205437,
      "grad_norm": 0.28203085064888,
      "learning_rate": 0.0004999334244602133,
      "loss": 3.0974,
      "step": 570
    },
    {
      "epoch": 3.495468277945619,
      "grad_norm": 0.3264124393463135,
      "learning_rate": 0.0004999277611887969,
      "loss": 3.0525,
      "step": 580
    },
    {
      "epoch": 3.5558912386706947,
      "grad_norm": 0.25748953223228455,
      "learning_rate": 0.0004999218668088685,
      "loss": 3.0348,
      "step": 590
    },
    {
      "epoch": 3.61631419939577,
      "grad_norm": 0.24272668361663818,
      "learning_rate": 0.0004999157413258782,
      "loss": 2.9849,
      "step": 600
    },
    {
      "epoch": 3.676737160120846,
      "grad_norm": 0.2307821363210678,
      "learning_rate": 0.0004999093847454903,
      "loss": 2.9871,
      "step": 610
    },
    {
      "epoch": 3.7371601208459215,
      "grad_norm": 0.3588586449623108,
      "learning_rate": 0.0004999027970735831,
      "loss": 2.9269,
      "step": 620
    },
    {
      "epoch": 3.797583081570997,
      "grad_norm": 0.2330201268196106,
      "learning_rate": 0.0004998959783162479,
      "loss": 2.9312,
      "step": 630
    },
    {
      "epoch": 3.8580060422960725,
      "grad_norm": 0.22714821994304657,
      "learning_rate": 0.0004998889284797901,
      "loss": 2.8763,
      "step": 640
    },
    {
      "epoch": 3.918429003021148,
      "grad_norm": 0.23587071895599365,
      "learning_rate": 0.0004998816475707286,
      "loss": 2.8736,
      "step": 650
    },
    {
      "epoch": 3.9788519637462234,
      "grad_norm": 0.3104115128517151,
      "learning_rate": 0.0004998741355957963,
      "loss": 2.8518,
      "step": 660
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.3803061246871948,
      "eval_runtime": 4.6359,
      "eval_samples_per_second": 3588.981,
      "eval_steps_per_second": 14.021,
      "step": 664
    },
    {
      "epoch": 4.0362537764350455,
      "grad_norm": 0.21313580870628357,
      "learning_rate": 0.0004998663925619393,
      "loss": 2.6824,
      "step": 670
    },
    {
      "epoch": 4.096676737160121,
      "grad_norm": 0.2375272959470749,
      "learning_rate": 0.0004998584184763178,
      "loss": 2.7913,
      "step": 680
    },
    {
      "epoch": 4.157099697885196,
      "grad_norm": 0.5713143944740295,
      "learning_rate": 0.0004998502133463052,
      "loss": 2.797,
      "step": 690
    },
    {
      "epoch": 4.217522658610272,
      "grad_norm": 0.20511506497859955,
      "learning_rate": 0.0004998417771794891,
      "loss": 2.7819,
      "step": 700
    },
    {
      "epoch": 4.277945619335347,
      "grad_norm": 0.27402591705322266,
      "learning_rate": 0.00049983310998367,
      "loss": 2.7465,
      "step": 710
    },
    {
      "epoch": 4.338368580060423,
      "grad_norm": 0.20525911450386047,
      "learning_rate": 0.000499824211766863,
      "loss": 2.7342,
      "step": 720
    },
    {
      "epoch": 4.398791540785498,
      "grad_norm": 0.23746436834335327,
      "learning_rate": 0.0004998150825372958,
      "loss": 2.7477,
      "step": 730
    },
    {
      "epoch": 4.459214501510574,
      "grad_norm": 0.18542057275772095,
      "learning_rate": 0.0004998057223034106,
      "loss": 2.7236,
      "step": 740
    },
    {
      "epoch": 4.519637462235649,
      "grad_norm": 0.20638452470302582,
      "learning_rate": 0.0004997961310738625,
      "loss": 2.6909,
      "step": 750
    },
    {
      "epoch": 4.580060422960726,
      "grad_norm": 0.6068717241287231,
      "learning_rate": 0.0004997863088575208,
      "loss": 2.7163,
      "step": 760
    },
    {
      "epoch": 4.640483383685801,
      "grad_norm": 0.2098163664340973,
      "learning_rate": 0.000499776255663468,
      "loss": 2.6863,
      "step": 770
    },
    {
      "epoch": 4.7009063444108765,
      "grad_norm": 0.2984548509120941,
      "learning_rate": 0.0004997659715010002,
      "loss": 2.6802,
      "step": 780
    },
    {
      "epoch": 4.761329305135952,
      "grad_norm": 0.1889696717262268,
      "learning_rate": 0.0004997554563796273,
      "loss": 2.6764,
      "step": 790
    },
    {
      "epoch": 4.8217522658610275,
      "grad_norm": 0.2358175367116928,
      "learning_rate": 0.0004997447103090726,
      "loss": 2.6652,
      "step": 800
    },
    {
      "epoch": 4.882175226586103,
      "grad_norm": 0.1912878453731537,
      "learning_rate": 0.000499733733299273,
      "loss": 2.6351,
      "step": 810
    },
    {
      "epoch": 4.942598187311178,
      "grad_norm": 0.20566630363464355,
      "learning_rate": 0.000499722525360379,
      "loss": 2.6317,
      "step": 820
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.196431964635849,
      "learning_rate": 0.0004997110865027545,
      "loss": 2.4953,
      "step": 830
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.279880404472351,
      "eval_runtime": 4.5899,
      "eval_samples_per_second": 3624.946,
      "eval_steps_per_second": 14.162,
      "step": 830
    },
    {
      "epoch": 5.0604229607250755,
      "grad_norm": 0.19604867696762085,
      "learning_rate": 0.0004996994167369772,
      "loss": 2.6158,
      "step": 840
    },
    {
      "epoch": 5.120845921450151,
      "grad_norm": 0.17605246603488922,
      "learning_rate": 0.000499687516073838,
      "loss": 2.6106,
      "step": 850
    },
    {
      "epoch": 5.181268882175226,
      "grad_norm": 0.16157369315624237,
      "learning_rate": 0.0004996753845243415,
      "loss": 2.6155,
      "step": 860
    },
    {
      "epoch": 5.241691842900302,
      "grad_norm": 0.16412127017974854,
      "learning_rate": 0.0004996630220997058,
      "loss": 2.5758,
      "step": 870
    },
    {
      "epoch": 5.302114803625377,
      "grad_norm": 0.18799647688865662,
      "learning_rate": 0.0004996504288113623,
      "loss": 2.594,
      "step": 880
    },
    {
      "epoch": 5.362537764350453,
      "grad_norm": 0.1491999626159668,
      "learning_rate": 0.0004996376046709563,
      "loss": 2.5743,
      "step": 890
    },
    {
      "epoch": 5.422960725075528,
      "grad_norm": 0.16328617930412292,
      "learning_rate": 0.000499624549690346,
      "loss": 2.5648,
      "step": 900
    },
    {
      "epoch": 5.483383685800605,
      "grad_norm": 0.15765222907066345,
      "learning_rate": 0.0004996112638816035,
      "loss": 2.559,
      "step": 910
    },
    {
      "epoch": 5.54380664652568,
      "grad_norm": 0.2747078239917755,
      "learning_rate": 0.0004995977472570141,
      "loss": 2.5638,
      "step": 920
    },
    {
      "epoch": 5.604229607250756,
      "grad_norm": 0.181906059384346,
      "learning_rate": 0.0004995839998290769,
      "loss": 2.5689,
      "step": 930
    },
    {
      "epoch": 5.664652567975831,
      "grad_norm": 0.1833166629076004,
      "learning_rate": 0.0004995700216105039,
      "loss": 2.5486,
      "step": 940
    },
    {
      "epoch": 5.7250755287009065,
      "grad_norm": 0.17530693113803864,
      "learning_rate": 0.000499555812614221,
      "loss": 2.5477,
      "step": 950
    },
    {
      "epoch": 5.785498489425982,
      "grad_norm": 0.17326763272285461,
      "learning_rate": 0.000499541372853367,
      "loss": 2.5349,
      "step": 960
    },
    {
      "epoch": 5.8459214501510575,
      "grad_norm": 0.18288838863372803,
      "learning_rate": 0.0004995267023412946,
      "loss": 2.53,
      "step": 970
    },
    {
      "epoch": 5.906344410876133,
      "grad_norm": 0.15663954615592957,
      "learning_rate": 0.0004995118010915696,
      "loss": 2.542,
      "step": 980
    },
    {
      "epoch": 5.966767371601208,
      "grad_norm": 0.1689215749502182,
      "learning_rate": 0.0004994966691179711,
      "loss": 2.5238,
      "step": 990
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.2308623790740967,
      "eval_runtime": 4.5716,
      "eval_samples_per_second": 3639.45,
      "eval_steps_per_second": 14.218,
      "step": 996
    },
    {
      "epoch": 6.02416918429003,
      "grad_norm": 0.22958847880363464,
      "learning_rate": 0.0004994813064344918,
      "loss": 2.4134,
      "step": 1000
    },
    {
      "epoch": 6.0845921450151055,
      "grad_norm": 0.20531518757343292,
      "learning_rate": 0.0004994657130553374,
      "loss": 2.5321,
      "step": 1010
    },
    {
      "epoch": 6.145015105740181,
      "grad_norm": 0.167294442653656,
      "learning_rate": 0.0004994498889949273,
      "loss": 2.5199,
      "step": 1020
    },
    {
      "epoch": 6.205438066465256,
      "grad_norm": 0.8785817623138428,
      "learning_rate": 0.0004994338342678938,
      "loss": 2.5016,
      "step": 1030
    },
    {
      "epoch": 6.265861027190333,
      "grad_norm": 0.1617569774389267,
      "learning_rate": 0.000499417548889083,
      "loss": 2.5077,
      "step": 1040
    },
    {
      "epoch": 6.326283987915408,
      "grad_norm": 0.8918225169181824,
      "learning_rate": 0.0004994010328735538,
      "loss": 2.4965,
      "step": 1050
    },
    {
      "epoch": 6.386706948640484,
      "grad_norm": 0.1495518833398819,
      "learning_rate": 0.0004993842862365788,
      "loss": 2.5052,
      "step": 1060
    },
    {
      "epoch": 6.447129909365559,
      "grad_norm": 0.17807677388191223,
      "learning_rate": 0.0004993673089936435,
      "loss": 2.4912,
      "step": 1070
    },
    {
      "epoch": 6.507552870090635,
      "grad_norm": 0.17036861181259155,
      "learning_rate": 0.0004993501011604467,
      "loss": 2.4913,
      "step": 1080
    },
    {
      "epoch": 6.56797583081571,
      "grad_norm": 0.6271350979804993,
      "learning_rate": 0.0004993326627529006,
      "loss": 2.4884,
      "step": 1090
    },
    {
      "epoch": 6.628398791540786,
      "grad_norm": 0.287506103515625,
      "learning_rate": 0.0004993149937871307,
      "loss": 2.4903,
      "step": 1100
    },
    {
      "epoch": 6.688821752265861,
      "grad_norm": 0.16376271843910217,
      "learning_rate": 0.0004992970942794751,
      "loss": 2.4791,
      "step": 1110
    },
    {
      "epoch": 6.7492447129909365,
      "grad_norm": 0.1598086953163147,
      "learning_rate": 0.0004992789642464857,
      "loss": 2.4821,
      "step": 1120
    },
    {
      "epoch": 6.809667673716012,
      "grad_norm": 0.15440022945404053,
      "learning_rate": 0.0004992606037049275,
      "loss": 2.4749,
      "step": 1130
    },
    {
      "epoch": 6.8700906344410875,
      "grad_norm": 0.16270750761032104,
      "learning_rate": 0.0004992420126717783,
      "loss": 2.4636,
      "step": 1140
    },
    {
      "epoch": 6.930513595166163,
      "grad_norm": 0.1631639301776886,
      "learning_rate": 0.0004992231911642294,
      "loss": 2.485,
      "step": 1150
    },
    {
      "epoch": 6.990936555891238,
      "grad_norm": 0.4807393550872803,
      "learning_rate": 0.0004992041391996851,
      "loss": 2.4698,
      "step": 1160
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.2072645425796509,
      "eval_runtime": 4.5714,
      "eval_samples_per_second": 3639.598,
      "eval_steps_per_second": 14.219,
      "step": 1162
    },
    {
      "epoch": 7.04833836858006,
      "grad_norm": 0.15132077038288116,
      "learning_rate": 0.0004991848567957625,
      "loss": 2.3419,
      "step": 1170
    },
    {
      "epoch": 7.108761329305136,
      "grad_norm": 0.3717087209224701,
      "learning_rate": 0.0004991653439702924,
      "loss": 2.4696,
      "step": 1180
    },
    {
      "epoch": 7.169184290030212,
      "grad_norm": 0.14137916266918182,
      "learning_rate": 0.0004991456007413182,
      "loss": 2.4583,
      "step": 1190
    },
    {
      "epoch": 7.229607250755287,
      "grad_norm": 0.1491810530424118,
      "learning_rate": 0.0004991256271270965,
      "loss": 2.4706,
      "step": 1200
    },
    {
      "epoch": 7.290030211480363,
      "grad_norm": 0.14493165910243988,
      "learning_rate": 0.0004991054231460968,
      "loss": 2.4621,
      "step": 1210
    },
    {
      "epoch": 7.350453172205438,
      "grad_norm": 0.14720666408538818,
      "learning_rate": 0.0004990849888170019,
      "loss": 2.462,
      "step": 1220
    },
    {
      "epoch": 7.410876132930514,
      "grad_norm": 0.14923642575740814,
      "learning_rate": 0.0004990643241587075,
      "loss": 2.4528,
      "step": 1230
    },
    {
      "epoch": 7.471299093655589,
      "grad_norm": 0.19646693766117096,
      "learning_rate": 0.000499043429190322,
      "loss": 2.4573,
      "step": 1240
    },
    {
      "epoch": 7.531722054380665,
      "grad_norm": 0.15211722254753113,
      "learning_rate": 0.0004990223039311672,
      "loss": 2.4466,
      "step": 1250
    },
    {
      "epoch": 7.59214501510574,
      "grad_norm": 0.4231773018836975,
      "learning_rate": 0.0004990009484007776,
      "loss": 2.4469,
      "step": 1260
    },
    {
      "epoch": 7.652567975830816,
      "grad_norm": 0.17397531867027283,
      "learning_rate": 0.0004989793626189006,
      "loss": 2.4585,
      "step": 1270
    },
    {
      "epoch": 7.712990936555891,
      "grad_norm": 0.23595081269741058,
      "learning_rate": 0.0004989575466054968,
      "loss": 2.4614,
      "step": 1280
    },
    {
      "epoch": 7.7734138972809665,
      "grad_norm": 0.15549123287200928,
      "learning_rate": 0.0004989355003807393,
      "loss": 2.4353,
      "step": 1290
    },
    {
      "epoch": 7.833836858006042,
      "grad_norm": 0.15813003480434418,
      "learning_rate": 0.0004989132239650144,
      "loss": 2.4485,
      "step": 1300
    },
    {
      "epoch": 7.8942598187311175,
      "grad_norm": 0.16566993296146393,
      "learning_rate": 0.000498890717378921,
      "loss": 2.4389,
      "step": 1310
    },
    {
      "epoch": 7.954682779456194,
      "grad_norm": 0.21564963459968567,
      "learning_rate": 0.0004988679806432712,
      "loss": 2.4359,
      "step": 1320
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.1927971839904785,
      "eval_runtime": 4.5576,
      "eval_samples_per_second": 3650.61,
      "eval_steps_per_second": 14.262,
      "step": 1328
    },
    {
      "epoch": 8.012084592145015,
      "grad_norm": 0.23416440188884735,
      "learning_rate": 0.0004988450137790895,
      "loss": 2.3206,
      "step": 1330
    },
    {
      "epoch": 8.072507552870091,
      "grad_norm": 0.1448921114206314,
      "learning_rate": 0.0004988218168076133,
      "loss": 2.4357,
      "step": 1340
    },
    {
      "epoch": 8.132930513595166,
      "grad_norm": 0.6437972784042358,
      "learning_rate": 0.000498798389750293,
      "loss": 2.4278,
      "step": 1350
    },
    {
      "epoch": 8.193353474320242,
      "grad_norm": 0.17656688392162323,
      "learning_rate": 0.0004987747326287916,
      "loss": 2.4487,
      "step": 1360
    },
    {
      "epoch": 8.253776435045317,
      "grad_norm": 0.15253372490406036,
      "learning_rate": 0.000498750845464985,
      "loss": 2.4327,
      "step": 1370
    },
    {
      "epoch": 8.314199395770393,
      "grad_norm": 0.20323112607002258,
      "learning_rate": 0.0004987267282809615,
      "loss": 2.4199,
      "step": 1380
    },
    {
      "epoch": 8.374622356495468,
      "grad_norm": 0.4518110752105713,
      "learning_rate": 0.0004987023810990223,
      "loss": 2.432,
      "step": 1390
    },
    {
      "epoch": 8.435045317220544,
      "grad_norm": 0.157196044921875,
      "learning_rate": 0.0004986778039416815,
      "loss": 2.4365,
      "step": 1400
    },
    {
      "epoch": 8.49546827794562,
      "grad_norm": 0.2873118817806244,
      "learning_rate": 0.0004986529968316653,
      "loss": 2.4268,
      "step": 1410
    },
    {
      "epoch": 8.555891238670695,
      "grad_norm": 0.17565259337425232,
      "learning_rate": 0.0004986279597919131,
      "loss": 2.4319,
      "step": 1420
    },
    {
      "epoch": 8.61631419939577,
      "grad_norm": 0.14338575303554535,
      "learning_rate": 0.0004986026928455767,
      "loss": 2.4242,
      "step": 1430
    },
    {
      "epoch": 8.676737160120846,
      "grad_norm": 0.15024957060813904,
      "learning_rate": 0.0004985771960160203,
      "loss": 2.4162,
      "step": 1440
    },
    {
      "epoch": 8.737160120845921,
      "grad_norm": 0.1577526181936264,
      "learning_rate": 0.000498551469326821,
      "loss": 2.4151,
      "step": 1450
    },
    {
      "epoch": 8.797583081570997,
      "grad_norm": 0.15350903570652008,
      "learning_rate": 0.0004985255128017682,
      "loss": 2.4216,
      "step": 1460
    },
    {
      "epoch": 8.858006042296072,
      "grad_norm": 0.16413235664367676,
      "learning_rate": 0.0004984993264648639,
      "loss": 2.428,
      "step": 1470
    },
    {
      "epoch": 8.918429003021147,
      "grad_norm": 0.18114888668060303,
      "learning_rate": 0.0004984729103403228,
      "loss": 2.415,
      "step": 1480
    },
    {
      "epoch": 8.978851963746223,
      "grad_norm": 0.15341749787330627,
      "learning_rate": 0.0004984462644525718,
      "loss": 2.4056,
      "step": 1490
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.182629108428955,
      "eval_runtime": 4.7315,
      "eval_samples_per_second": 3516.403,
      "eval_steps_per_second": 13.738,
      "step": 1494
    },
    {
      "epoch": 9.036253776435045,
      "grad_norm": 0.14524441957473755,
      "learning_rate": 0.0004984193888262504,
      "loss": 2.2919,
      "step": 1500
    },
    {
      "epoch": 9.09667673716012,
      "grad_norm": 0.2408137023448944,
      "learning_rate": 0.0004983922834862106,
      "loss": 2.4143,
      "step": 1510
    },
    {
      "epoch": 9.157099697885196,
      "grad_norm": 0.19754253327846527,
      "learning_rate": 0.0004983649484575167,
      "loss": 2.4083,
      "step": 1520
    },
    {
      "epoch": 9.217522658610273,
      "grad_norm": 0.14333440363407135,
      "learning_rate": 0.0004983373837654454,
      "loss": 2.4227,
      "step": 1530
    },
    {
      "epoch": 9.277945619335348,
      "grad_norm": 0.1825643628835678,
      "learning_rate": 0.0004983095894354857,
      "loss": 2.4077,
      "step": 1540
    },
    {
      "epoch": 9.338368580060424,
      "grad_norm": 0.18893243372440338,
      "learning_rate": 0.0004982815654933394,
      "loss": 2.4168,
      "step": 1550
    },
    {
      "epoch": 9.3987915407855,
      "grad_norm": 0.2509304881095886,
      "learning_rate": 0.0004982533119649199,
      "loss": 2.4156,
      "step": 1560
    },
    {
      "epoch": 9.459214501510575,
      "grad_norm": 0.22427509725093842,
      "learning_rate": 0.0004982248288763534,
      "loss": 2.4058,
      "step": 1570
    },
    {
      "epoch": 9.51963746223565,
      "grad_norm": 0.1395501047372818,
      "learning_rate": 0.0004981961162539784,
      "loss": 2.4,
      "step": 1580
    },
    {
      "epoch": 9.580060422960726,
      "grad_norm": 0.1613806039094925,
      "learning_rate": 0.0004981671741243454,
      "loss": 2.4126,
      "step": 1590
    },
    {
      "epoch": 9.640483383685801,
      "grad_norm": 0.14055193960666656,
      "learning_rate": 0.000498138002514217,
      "loss": 2.4036,
      "step": 1600
    },
    {
      "epoch": 9.700906344410877,
      "grad_norm": 0.14456717669963837,
      "learning_rate": 0.0004981086014505684,
      "loss": 2.4011,
      "step": 1610
    },
    {
      "epoch": 9.761329305135952,
      "grad_norm": 0.1775735467672348,
      "learning_rate": 0.000498078970960587,
      "loss": 2.4157,
      "step": 1620
    },
    {
      "epoch": 9.821752265861027,
      "grad_norm": 0.16321411728858948,
      "learning_rate": 0.0004980491110716719,
      "loss": 2.3985,
      "step": 1630
    },
    {
      "epoch": 9.882175226586103,
      "grad_norm": 0.13898111879825592,
      "learning_rate": 0.0004980190218114346,
      "loss": 2.3919,
      "step": 1640
    },
    {
      "epoch": 9.942598187311178,
      "grad_norm": 0.28145840764045715,
      "learning_rate": 0.0004979887032076989,
      "loss": 2.3951,
      "step": 1650
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.16713058948516846,
      "learning_rate": 0.0004979581552885001,
      "loss": 2.2767,
      "step": 1660
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.175491452217102,
      "eval_runtime": 4.5721,
      "eval_samples_per_second": 3639.031,
      "eval_steps_per_second": 14.217,
      "step": 1660
    },
    {
      "epoch": 10.060422960725075,
      "grad_norm": 0.14650824666023254,
      "learning_rate": 0.0004979273780820862,
      "loss": 2.3958,
      "step": 1670
    },
    {
      "epoch": 10.120845921450151,
      "grad_norm": 0.16761213541030884,
      "learning_rate": 0.0004978963716169166,
      "loss": 2.4027,
      "step": 1680
    },
    {
      "epoch": 10.181268882175226,
      "grad_norm": 0.16542436182498932,
      "learning_rate": 0.0004978651359216633,
      "loss": 2.4018,
      "step": 1690
    },
    {
      "epoch": 10.241691842900302,
      "grad_norm": 0.17666921019554138,
      "learning_rate": 0.0004978336710252099,
      "loss": 2.3863,
      "step": 1700
    },
    {
      "epoch": 10.302114803625377,
      "grad_norm": 0.14938898384571075,
      "learning_rate": 0.000497801976956652,
      "loss": 2.3985,
      "step": 1710
    },
    {
      "epoch": 10.362537764350453,
      "grad_norm": 0.16009902954101562,
      "learning_rate": 0.0004977700537452973,
      "loss": 2.3943,
      "step": 1720
    },
    {
      "epoch": 10.422960725075528,
      "grad_norm": 0.1335088312625885,
      "learning_rate": 0.000497737901420665,
      "loss": 2.3829,
      "step": 1730
    },
    {
      "epoch": 10.483383685800604,
      "grad_norm": 0.16318221390247345,
      "learning_rate": 0.0004977055200124865,
      "loss": 2.4092,
      "step": 1740
    },
    {
      "epoch": 10.54380664652568,
      "grad_norm": 0.16722515225410461,
      "learning_rate": 0.0004976729095507048,
      "loss": 2.3969,
      "step": 1750
    },
    {
      "epoch": 10.604229607250755,
      "grad_norm": 0.1486234962940216,
      "learning_rate": 0.0004976400700654752,
      "loss": 2.3895,
      "step": 1760
    },
    {
      "epoch": 10.66465256797583,
      "grad_norm": 0.15265169739723206,
      "learning_rate": 0.0004976070015871641,
      "loss": 2.3725,
      "step": 1770
    },
    {
      "epoch": 10.725075528700906,
      "grad_norm": 0.17795796692371368,
      "learning_rate": 0.0004975737041463499,
      "loss": 2.3956,
      "step": 1780
    },
    {
      "epoch": 10.785498489425981,
      "grad_norm": 0.13882631063461304,
      "learning_rate": 0.0004975401777738231,
      "loss": 2.3692,
      "step": 1790
    },
    {
      "epoch": 10.845921450151057,
      "grad_norm": 0.15706990659236908,
      "learning_rate": 0.0004975064225005853,
      "loss": 2.3772,
      "step": 1800
    },
    {
      "epoch": 10.906344410876134,
      "grad_norm": 0.14465118944644928,
      "learning_rate": 0.0004974724383578501,
      "loss": 2.3823,
      "step": 1810
    },
    {
      "epoch": 10.96676737160121,
      "grad_norm": 0.12930715084075928,
      "learning_rate": 0.0004974382253770429,
      "loss": 2.3848,
      "step": 1820
    },
    {
      "epoch": 11.0,
      "eval_loss": 1.1694226264953613,
      "eval_runtime": 4.585,
      "eval_samples_per_second": 3628.786,
      "eval_steps_per_second": 14.177,
      "step": 1826
    },
    {
      "epoch": 11.024169184290031,
      "grad_norm": 0.14733745157718658,
      "learning_rate": 0.0004974037835898001,
      "loss": 2.2647,
      "step": 1830
    },
    {
      "epoch": 11.084592145015106,
      "grad_norm": 0.22704334557056427,
      "learning_rate": 0.0004973691130279703,
      "loss": 2.3712,
      "step": 1840
    },
    {
      "epoch": 11.145015105740182,
      "grad_norm": 0.13070924580097198,
      "learning_rate": 0.0004973342137236136,
      "loss": 2.3753,
      "step": 1850
    },
    {
      "epoch": 11.205438066465257,
      "grad_norm": 0.17377802729606628,
      "learning_rate": 0.0004972990857090011,
      "loss": 2.385,
      "step": 1860
    },
    {
      "epoch": 11.265861027190333,
      "grad_norm": 0.17079029977321625,
      "learning_rate": 0.0004972637290166158,
      "loss": 2.3831,
      "step": 1870
    },
    {
      "epoch": 11.326283987915408,
      "grad_norm": 0.14421868324279785,
      "learning_rate": 0.0004972281436791521,
      "loss": 2.3782,
      "step": 1880
    },
    {
      "epoch": 11.386706948640484,
      "grad_norm": 0.16519713401794434,
      "learning_rate": 0.0004971923297295158,
      "loss": 2.3948,
      "step": 1890
    },
    {
      "epoch": 11.44712990936556,
      "grad_norm": 0.171681746840477,
      "learning_rate": 0.0004971562872008241,
      "loss": 2.372,
      "step": 1900
    },
    {
      "epoch": 11.507552870090635,
      "grad_norm": 0.15693950653076172,
      "learning_rate": 0.0004971200161264056,
      "loss": 2.3718,
      "step": 1910
    },
    {
      "epoch": 11.56797583081571,
      "grad_norm": 0.14244157075881958,
      "learning_rate": 0.0004970835165398004,
      "loss": 2.3733,
      "step": 1920
    },
    {
      "epoch": 11.628398791540786,
      "grad_norm": 0.2137005627155304,
      "learning_rate": 0.0004970467884747592,
      "loss": 2.3836,
      "step": 1930
    },
    {
      "epoch": 11.688821752265861,
      "grad_norm": 0.21568171679973602,
      "learning_rate": 0.000497009831965245,
      "loss": 2.3795,
      "step": 1940
    },
    {
      "epoch": 11.749244712990937,
      "grad_norm": 0.14661523699760437,
      "learning_rate": 0.0004969726470454314,
      "loss": 2.3736,
      "step": 1950
    },
    {
      "epoch": 11.809667673716012,
      "grad_norm": 0.14552035927772522,
      "learning_rate": 0.0004969352337497031,
      "loss": 2.3728,
      "step": 1960
    },
    {
      "epoch": 11.870090634441087,
      "grad_norm": 0.16620276868343353,
      "learning_rate": 0.0004968975921126564,
      "loss": 2.3785,
      "step": 1970
    },
    {
      "epoch": 11.930513595166163,
      "grad_norm": 0.14317195117473602,
      "learning_rate": 0.0004968597221690986,
      "loss": 2.3705,
      "step": 1980
    },
    {
      "epoch": 11.990936555891238,
      "grad_norm": 0.13441722095012665,
      "learning_rate": 0.0004968216239540481,
      "loss": 2.3853,
      "step": 1990
    },
    {
      "epoch": 12.0,
      "eval_loss": 1.1641823053359985,
      "eval_runtime": 4.5712,
      "eval_samples_per_second": 3639.74,
      "eval_steps_per_second": 14.219,
      "step": 1992
    },
    {
      "epoch": 12.04833836858006,
      "grad_norm": 0.1537737250328064,
      "learning_rate": 0.0004967832975027342,
      "loss": 2.253,
      "step": 2000
    },
    {
      "epoch": 12.108761329305135,
      "grad_norm": 0.20548465847969055,
      "learning_rate": 0.0004967447428505976,
      "loss": 2.3718,
      "step": 2010
    },
    {
      "epoch": 12.169184290030211,
      "grad_norm": 0.14785119891166687,
      "learning_rate": 0.0004967059600332898,
      "loss": 2.3738,
      "step": 2020
    },
    {
      "epoch": 12.229607250755286,
      "grad_norm": 0.1590459942817688,
      "learning_rate": 0.0004966669490866732,
      "loss": 2.3803,
      "step": 2030
    },
    {
      "epoch": 12.290030211480362,
      "grad_norm": 0.13677829504013062,
      "learning_rate": 0.0004966277100468214,
      "loss": 2.3676,
      "step": 2040
    },
    {
      "epoch": 12.350453172205437,
      "grad_norm": 0.14805781841278076,
      "learning_rate": 0.0004965882429500188,
      "loss": 2.3769,
      "step": 2050
    },
    {
      "epoch": 12.410876132930513,
      "grad_norm": 0.1422678381204605,
      "learning_rate": 0.0004965485478327606,
      "loss": 2.3712,
      "step": 2060
    },
    {
      "epoch": 12.471299093655588,
      "grad_norm": 0.1711723357439041,
      "learning_rate": 0.0004965086247317529,
      "loss": 2.3746,
      "step": 2070
    },
    {
      "epoch": 12.531722054380666,
      "grad_norm": 0.16440540552139282,
      "learning_rate": 0.0004964684736839126,
      "loss": 2.3668,
      "step": 2080
    },
    {
      "epoch": 12.59214501510574,
      "grad_norm": 0.16016782820224762,
      "learning_rate": 0.0004964280947263676,
      "loss": 2.3839,
      "step": 2090
    },
    {
      "epoch": 12.652567975830816,
      "grad_norm": 0.14887847006320953,
      "learning_rate": 0.0004963874878964562,
      "loss": 2.3605,
      "step": 2100
    },
    {
      "epoch": 12.712990936555892,
      "grad_norm": 0.16598264873027802,
      "learning_rate": 0.0004963466532317279,
      "loss": 2.3629,
      "step": 2110
    },
    {
      "epoch": 12.773413897280967,
      "grad_norm": 0.14962002635002136,
      "learning_rate": 0.0004963055907699421,
      "loss": 2.3637,
      "step": 2120
    },
    {
      "epoch": 12.833836858006043,
      "grad_norm": 0.3171256184577942,
      "learning_rate": 0.0004962643005490696,
      "loss": 2.367,
      "step": 2130
    },
    {
      "epoch": 12.894259818731118,
      "grad_norm": 0.3238374888896942,
      "learning_rate": 0.0004962227826072915,
      "loss": 2.3584,
      "step": 2140
    },
    {
      "epoch": 12.954682779456194,
      "grad_norm": 0.15328416228294373,
      "learning_rate": 0.0004961810369829994,
      "loss": 2.3645,
      "step": 2150
    },
    {
      "epoch": 13.0,
      "eval_loss": 1.1598538160324097,
      "eval_runtime": 4.5745,
      "eval_samples_per_second": 3637.1,
      "eval_steps_per_second": 14.209,
      "step": 2158
    },
    {
      "epoch": 13.012084592145015,
      "grad_norm": 0.14771245419979095,
      "learning_rate": 0.0004961390637147956,
      "loss": 2.2438,
      "step": 2160
    },
    {
      "epoch": 13.072507552870091,
      "grad_norm": 0.16342130303382874,
      "learning_rate": 0.0004960968628414929,
      "loss": 2.3534,
      "step": 2170
    },
    {
      "epoch": 13.132930513595166,
      "grad_norm": 0.19763009250164032,
      "learning_rate": 0.0004960544344021143,
      "loss": 2.3677,
      "step": 2180
    },
    {
      "epoch": 13.193353474320242,
      "grad_norm": 0.15198640525341034,
      "learning_rate": 0.0004960117784358936,
      "loss": 2.3602,
      "step": 2190
    },
    {
      "epoch": 13.253776435045317,
      "grad_norm": 0.2912924289703369,
      "learning_rate": 0.0004959688949822749,
      "loss": 2.3651,
      "step": 2200
    },
    {
      "epoch": 13.314199395770393,
      "grad_norm": 0.16082215309143066,
      "learning_rate": 0.0004959257840809123,
      "loss": 2.3517,
      "step": 2210
    },
    {
      "epoch": 13.374622356495468,
      "grad_norm": 0.142287015914917,
      "learning_rate": 0.0004958824457716707,
      "loss": 2.3634,
      "step": 2220
    },
    {
      "epoch": 13.435045317220544,
      "grad_norm": 0.1583608090877533,
      "learning_rate": 0.000495838880094625,
      "loss": 2.3762,
      "step": 2230
    },
    {
      "epoch": 13.49546827794562,
      "grad_norm": 0.15014788508415222,
      "learning_rate": 0.0004957950870900605,
      "loss": 2.3629,
      "step": 2240
    },
    {
      "epoch": 13.555891238670695,
      "grad_norm": 0.13233165442943573,
      "learning_rate": 0.0004957510667984726,
      "loss": 2.363,
      "step": 2250
    },
    {
      "epoch": 13.61631419939577,
      "grad_norm": 0.1675167828798294,
      "learning_rate": 0.000495706819260567,
      "loss": 2.3471,
      "step": 2260
    },
    {
      "epoch": 13.676737160120846,
      "grad_norm": 0.1603284627199173,
      "learning_rate": 0.0004956623445172594,
      "loss": 2.3606,
      "step": 2270
    },
    {
      "epoch": 13.737160120845921,
      "grad_norm": 0.1603000909090042,
      "learning_rate": 0.0004956176426096757,
      "loss": 2.3581,
      "step": 2280
    },
    {
      "epoch": 13.797583081570997,
      "grad_norm": 0.1767510026693344,
      "learning_rate": 0.0004955727135791517,
      "loss": 2.3552,
      "step": 2290
    },
    {
      "epoch": 13.858006042296072,
      "grad_norm": 0.16262836754322052,
      "learning_rate": 0.0004955275574672333,
      "loss": 2.3577,
      "step": 2300
    },
    {
      "epoch": 13.918429003021147,
      "grad_norm": 0.1703806221485138,
      "learning_rate": 0.0004954821743156767,
      "loss": 2.3655,
      "step": 2310
    },
    {
      "epoch": 13.978851963746223,
      "grad_norm": 0.14650258421897888,
      "learning_rate": 0.0004954365641664474,
      "loss": 2.3476,
      "step": 2320
    },
    {
      "epoch": 14.0,
      "eval_loss": 1.157325267791748,
      "eval_runtime": 4.5638,
      "eval_samples_per_second": 3645.657,
      "eval_steps_per_second": 14.243,
      "step": 2324
    },
    {
      "epoch": 14.036253776435045,
      "grad_norm": 0.1689741313457489,
      "learning_rate": 0.0004953907270617214,
      "loss": 2.2361,
      "step": 2330
    },
    {
      "epoch": 14.09667673716012,
      "grad_norm": 0.19228196144104004,
      "learning_rate": 0.0004953446630438843,
      "loss": 2.3439,
      "step": 2340
    },
    {
      "epoch": 14.157099697885196,
      "grad_norm": 0.15797457098960876,
      "learning_rate": 0.0004952983721555315,
      "loss": 2.3591,
      "step": 2350
    },
    {
      "epoch": 14.217522658610273,
      "grad_norm": 0.15367701649665833,
      "learning_rate": 0.0004952518544394682,
      "loss": 2.3547,
      "step": 2360
    },
    {
      "epoch": 14.277945619335348,
      "grad_norm": 0.16478736698627472,
      "learning_rate": 0.0004952051099387095,
      "loss": 2.3561,
      "step": 2370
    },
    {
      "epoch": 14.338368580060424,
      "grad_norm": 0.17523252964019775,
      "learning_rate": 0.0004951581386964799,
      "loss": 2.3586,
      "step": 2380
    },
    {
      "epoch": 14.3987915407855,
      "grad_norm": 0.18967831134796143,
      "learning_rate": 0.000495110940756214,
      "loss": 2.3578,
      "step": 2390
    },
    {
      "epoch": 14.459214501510575,
      "grad_norm": 0.14998403191566467,
      "learning_rate": 0.0004950635161615557,
      "loss": 2.3605,
      "step": 2400
    },
    {
      "epoch": 14.51963746223565,
      "grad_norm": 0.15359781682491302,
      "learning_rate": 0.0004950158649563585,
      "loss": 2.3458,
      "step": 2410
    },
    {
      "epoch": 14.580060422960726,
      "grad_norm": 0.17673225700855255,
      "learning_rate": 0.0004949679871846857,
      "loss": 2.3527,
      "step": 2420
    },
    {
      "epoch": 14.640483383685801,
      "grad_norm": 0.19938822090625763,
      "learning_rate": 0.0004949198828908099,
      "loss": 2.3617,
      "step": 2430
    },
    {
      "epoch": 14.700906344410877,
      "grad_norm": 0.20702293515205383,
      "learning_rate": 0.000494871552119213,
      "loss": 2.3666,
      "step": 2440
    },
    {
      "epoch": 14.761329305135952,
      "grad_norm": 0.1558641940355301,
      "learning_rate": 0.0004948229949145867,
      "loss": 2.3321,
      "step": 2450
    },
    {
      "epoch": 14.821752265861027,
      "grad_norm": 0.1600877195596695,
      "learning_rate": 0.000494774211321832,
      "loss": 2.3433,
      "step": 2460
    },
    {
      "epoch": 14.882175226586103,
      "grad_norm": 0.14320865273475647,
      "learning_rate": 0.0004947252013860589,
      "loss": 2.3482,
      "step": 2470
    },
    {
      "epoch": 14.942598187311178,
      "grad_norm": 0.14565569162368774,
      "learning_rate": 0.0004946759651525872,
      "loss": 2.3502,
      "step": 2480
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.1816851794719696,
      "learning_rate": 0.0004946265026669455,
      "loss": 2.2308,
      "step": 2490
    },
    {
      "epoch": 15.0,
      "eval_loss": 1.1539567708969116,
      "eval_runtime": 4.5742,
      "eval_samples_per_second": 3637.345,
      "eval_steps_per_second": 14.21,
      "step": 2490
    },
    {
      "epoch": 15.060422960725075,
      "grad_norm": 0.16242973506450653,
      "learning_rate": 0.0004945768139748717,
      "loss": 2.3511,
      "step": 2500
    },
    {
      "epoch": 15.120845921450151,
      "grad_norm": 0.15567907691001892,
      "learning_rate": 0.0004945268991223135,
      "loss": 2.3427,
      "step": 2510
    },
    {
      "epoch": 15.181268882175226,
      "grad_norm": 0.17111434042453766,
      "learning_rate": 0.0004944767581554268,
      "loss": 2.3504,
      "step": 2520
    },
    {
      "epoch": 15.241691842900302,
      "grad_norm": 0.1612304300069809,
      "learning_rate": 0.0004944263911205772,
      "loss": 2.3432,
      "step": 2530
    },
    {
      "epoch": 15.302114803625377,
      "grad_norm": 0.17086189985275269,
      "learning_rate": 0.0004943757980643389,
      "loss": 2.3359,
      "step": 2540
    },
    {
      "epoch": 15.362537764350453,
      "grad_norm": 0.17388886213302612,
      "learning_rate": 0.0004943249790334959,
      "loss": 2.3422,
      "step": 2550
    },
    {
      "epoch": 15.422960725075528,
      "grad_norm": 0.1630839854478836,
      "learning_rate": 0.00049427393407504,
      "loss": 2.3535,
      "step": 2560
    },
    {
      "epoch": 15.483383685800604,
      "grad_norm": 0.16090093553066254,
      "learning_rate": 0.0004942226632361729,
      "loss": 2.3381,
      "step": 2570
    },
    {
      "epoch": 15.54380664652568,
      "grad_norm": 0.798608124256134,
      "learning_rate": 0.0004941711665643047,
      "loss": 2.3455,
      "step": 2580
    },
    {
      "epoch": 15.604229607250755,
      "grad_norm": 0.19125328958034515,
      "learning_rate": 0.0004941194441070545,
      "loss": 2.3576,
      "step": 2590
    },
    {
      "epoch": 15.66465256797583,
      "grad_norm": 0.1521081179380417,
      "learning_rate": 0.0004940674959122502,
      "loss": 2.3401,
      "step": 2600
    },
    {
      "epoch": 15.725075528700906,
      "grad_norm": 0.15849153697490692,
      "learning_rate": 0.0004940153220279281,
      "loss": 2.355,
      "step": 2610
    },
    {
      "epoch": 15.785498489425981,
      "grad_norm": 0.1502954661846161,
      "learning_rate": 0.0004939629225023337,
      "loss": 2.3345,
      "step": 2620
    },
    {
      "epoch": 15.845921450151057,
      "grad_norm": 0.157374769449234,
      "learning_rate": 0.0004939102973839207,
      "loss": 2.3401,
      "step": 2630
    },
    {
      "epoch": 15.906344410876134,
      "grad_norm": 0.16173537075519562,
      "learning_rate": 0.0004938574467213517,
      "loss": 2.3542,
      "step": 2640
    },
    {
      "epoch": 15.96676737160121,
      "grad_norm": 0.1713542342185974,
      "learning_rate": 0.0004938043705634979,
      "loss": 2.3458,
      "step": 2650
    },
    {
      "epoch": 16.0,
      "eval_loss": 1.1531896591186523,
      "eval_runtime": 4.557,
      "eval_samples_per_second": 3651.093,
      "eval_steps_per_second": 14.264,
      "step": 2656
    },
    {
      "epoch": 16.02416918429003,
      "grad_norm": 0.20561766624450684,
      "learning_rate": 0.0004937510689594388,
      "loss": 2.2278,
      "step": 2660
    },
    {
      "epoch": 16.084592145015105,
      "grad_norm": 0.1615961641073227,
      "learning_rate": 0.0004936975419584623,
      "loss": 2.3322,
      "step": 2670
    },
    {
      "epoch": 16.145015105740182,
      "grad_norm": 0.19816668331623077,
      "learning_rate": 0.0004936437896100651,
      "loss": 2.336,
      "step": 2680
    },
    {
      "epoch": 16.205438066465256,
      "grad_norm": 0.19251614809036255,
      "learning_rate": 0.0004935898119639521,
      "loss": 2.347,
      "step": 2690
    },
    {
      "epoch": 16.265861027190333,
      "grad_norm": 0.162262961268425,
      "learning_rate": 0.0004935356090700363,
      "loss": 2.3439,
      "step": 2700
    },
    {
      "epoch": 16.326283987915406,
      "grad_norm": 0.2607284486293793,
      "learning_rate": 0.0004934811809784393,
      "loss": 2.3483,
      "step": 2710
    },
    {
      "epoch": 16.386706948640484,
      "grad_norm": 0.17754127085208893,
      "learning_rate": 0.0004934265277394907,
      "loss": 2.3337,
      "step": 2720
    },
    {
      "epoch": 16.447129909365557,
      "grad_norm": 0.16698592901229858,
      "learning_rate": 0.0004933716494037285,
      "loss": 2.334,
      "step": 2730
    },
    {
      "epoch": 16.507552870090635,
      "grad_norm": 0.17796838283538818,
      "learning_rate": 0.000493316546021899,
      "loss": 2.3507,
      "step": 2740
    },
    {
      "epoch": 16.56797583081571,
      "grad_norm": 0.17571887373924255,
      "learning_rate": 0.0004932612176449559,
      "loss": 2.3403,
      "step": 2750
    },
    {
      "epoch": 16.628398791540786,
      "grad_norm": 0.3187488615512848,
      "learning_rate": 0.0004932056643240618,
      "loss": 2.3317,
      "step": 2760
    },
    {
      "epoch": 16.68882175226586,
      "grad_norm": 0.15348747372627258,
      "learning_rate": 0.0004931498861105867,
      "loss": 2.339,
      "step": 2770
    },
    {
      "epoch": 16.749244712990937,
      "grad_norm": 0.22098596394062042,
      "learning_rate": 0.000493093883056109,
      "loss": 2.3385,
      "step": 2780
    },
    {
      "epoch": 16.809667673716014,
      "grad_norm": 0.16653959453105927,
      "learning_rate": 0.0004930376552124146,
      "loss": 2.3616,
      "step": 2790
    },
    {
      "epoch": 16.870090634441087,
      "grad_norm": 0.19366268813610077,
      "learning_rate": 0.0004929812026314975,
      "loss": 2.3521,
      "step": 2800
    },
    {
      "epoch": 16.930513595166165,
      "grad_norm": 0.2574567496776581,
      "learning_rate": 0.0004929245253655595,
      "loss": 2.3453,
      "step": 2810
    },
    {
      "epoch": 16.99093655589124,
      "grad_norm": 0.26039522886276245,
      "learning_rate": 0.0004928676234670102,
      "loss": 2.3305,
      "step": 2820
    },
    {
      "epoch": 17.0,
      "eval_loss": 1.152489185333252,
      "eval_runtime": 4.6265,
      "eval_samples_per_second": 3596.261,
      "eval_steps_per_second": 14.05,
      "step": 2822
    },
    {
      "epoch": 17.048338368580062,
      "grad_norm": 0.16699138283729553,
      "learning_rate": 0.0004928104969884668,
      "loss": 2.2285,
      "step": 2830
    },
    {
      "epoch": 17.108761329305135,
      "grad_norm": 0.1988532841205597,
      "learning_rate": 0.0004927531459827542,
      "loss": 2.3317,
      "step": 2840
    },
    {
      "epoch": 17.169184290030213,
      "grad_norm": 0.17347407341003418,
      "learning_rate": 0.0004926955705029048,
      "loss": 2.3339,
      "step": 2850
    },
    {
      "epoch": 17.229607250755286,
      "grad_norm": 0.17054548859596252,
      "learning_rate": 0.000492637770602159,
      "loss": 2.3247,
      "step": 2860
    },
    {
      "epoch": 17.290030211480364,
      "grad_norm": 0.18745902180671692,
      "learning_rate": 0.0004925797463339644,
      "loss": 2.3428,
      "step": 2870
    },
    {
      "epoch": 17.350453172205437,
      "grad_norm": 2.0833675861358643,
      "learning_rate": 0.0004925214977519759,
      "loss": 2.3282,
      "step": 2880
    },
    {
      "epoch": 17.410876132930515,
      "grad_norm": 0.17461127042770386,
      "learning_rate": 0.0004924630249100563,
      "loss": 2.3386,
      "step": 2890
    },
    {
      "epoch": 17.47129909365559,
      "grad_norm": 0.2325480431318283,
      "learning_rate": 0.0004924043278622753,
      "loss": 2.3476,
      "step": 2900
    },
    {
      "epoch": 17.531722054380666,
      "grad_norm": 0.18110856413841248,
      "learning_rate": 0.0004923454066629102,
      "loss": 2.3423,
      "step": 2910
    },
    {
      "epoch": 17.59214501510574,
      "grad_norm": 0.206316739320755,
      "learning_rate": 0.0004922862613664455,
      "loss": 2.3354,
      "step": 2920
    },
    {
      "epoch": 17.652567975830816,
      "grad_norm": 0.1800331324338913,
      "learning_rate": 0.000492226892027573,
      "loss": 2.3444,
      "step": 2930
    },
    {
      "epoch": 17.71299093655589,
      "grad_norm": 0.17847804725170135,
      "learning_rate": 0.0004921672987011916,
      "loss": 2.3424,
      "step": 2940
    },
    {
      "epoch": 17.773413897280967,
      "grad_norm": 0.17556865513324738,
      "learning_rate": 0.0004921074814424073,
      "loss": 2.3491,
      "step": 2950
    },
    {
      "epoch": 17.83383685800604,
      "grad_norm": 0.1701183170080185,
      "learning_rate": 0.000492047440306533,
      "loss": 2.3235,
      "step": 2960
    },
    {
      "epoch": 17.89425981873112,
      "grad_norm": 0.22448250651359558,
      "learning_rate": 0.0004919871753490891,
      "loss": 2.3462,
      "step": 2970
    },
    {
      "epoch": 17.954682779456192,
      "grad_norm": 0.18722762167453766,
      "learning_rate": 0.0004919266866258025,
      "loss": 2.3379,
      "step": 2980
    },
    {
      "epoch": 18.0,
      "eval_loss": 1.1499630212783813,
      "eval_runtime": 4.5742,
      "eval_samples_per_second": 3637.388,
      "eval_steps_per_second": 14.21,
      "step": 2988
    },
    {
      "epoch": 18.012084592145015,
      "grad_norm": 0.1685069054365158,
      "learning_rate": 0.0004918659741926073,
      "loss": 2.2245,
      "step": 2990
    },
    {
      "epoch": 18.07250755287009,
      "grad_norm": 0.16794836521148682,
      "learning_rate": 0.0004918050381056444,
      "loss": 2.3389,
      "step": 3000
    },
    {
      "epoch": 18.132930513595166,
      "grad_norm": 0.16476355493068695,
      "learning_rate": 0.0004917438784212612,
      "loss": 2.3385,
      "step": 3010
    },
    {
      "epoch": 18.19335347432024,
      "grad_norm": 0.183340385556221,
      "learning_rate": 0.0004916824951960125,
      "loss": 2.3369,
      "step": 3020
    },
    {
      "epoch": 18.253776435045317,
      "grad_norm": 0.17436037957668304,
      "learning_rate": 0.0004916208884866593,
      "loss": 2.321,
      "step": 3030
    },
    {
      "epoch": 18.31419939577039,
      "grad_norm": 0.1807071566581726,
      "learning_rate": 0.0004915590583501692,
      "loss": 2.3267,
      "step": 3040
    },
    {
      "epoch": 18.37462235649547,
      "grad_norm": 0.17582765221595764,
      "learning_rate": 0.0004914970048437169,
      "loss": 2.3269,
      "step": 3050
    },
    {
      "epoch": 18.435045317220546,
      "grad_norm": 0.1835165172815323,
      "learning_rate": 0.0004914347280246833,
      "loss": 2.333,
      "step": 3060
    },
    {
      "epoch": 18.49546827794562,
      "grad_norm": 0.1602739542722702,
      "learning_rate": 0.0004913722279506558,
      "loss": 2.3202,
      "step": 3070
    },
    {
      "epoch": 18.555891238670696,
      "grad_norm": 0.1955024152994156,
      "learning_rate": 0.0004913095046794281,
      "loss": 2.3345,
      "step": 3080
    },
    {
      "epoch": 18.61631419939577,
      "grad_norm": 0.16833139955997467,
      "learning_rate": 0.0004912465582690009,
      "loss": 2.331,
      "step": 3090
    },
    {
      "epoch": 18.676737160120847,
      "grad_norm": 0.17755036056041718,
      "learning_rate": 0.0004911833887775805,
      "loss": 2.3295,
      "step": 3100
    },
    {
      "epoch": 18.73716012084592,
      "grad_norm": 0.19702188670635223,
      "learning_rate": 0.0004911199962635799,
      "loss": 2.3221,
      "step": 3110
    },
    {
      "epoch": 18.797583081571,
      "grad_norm": 0.17716319859027863,
      "learning_rate": 0.0004910563807856182,
      "loss": 2.352,
      "step": 3120
    },
    {
      "epoch": 18.858006042296072,
      "grad_norm": 0.1624731868505478,
      "learning_rate": 0.0004909925424025209,
      "loss": 2.3468,
      "step": 3130
    },
    {
      "epoch": 18.91842900302115,
      "grad_norm": 0.1635226607322693,
      "learning_rate": 0.0004909284811733191,
      "loss": 2.3311,
      "step": 3140
    },
    {
      "epoch": 18.978851963746223,
      "grad_norm": 0.23436959087848663,
      "learning_rate": 0.0004908641971572506,
      "loss": 2.328,
      "step": 3150
    },
    {
      "epoch": 19.0,
      "eval_loss": 1.1472055912017822,
      "eval_runtime": 4.5598,
      "eval_samples_per_second": 3648.827,
      "eval_steps_per_second": 14.255,
      "step": 3154
    },
    {
      "epoch": 19.036253776435046,
      "grad_norm": 0.17455869913101196,
      "learning_rate": 0.0004907996904137588,
      "loss": 2.2126,
      "step": 3160
    },
    {
      "epoch": 19.09667673716012,
      "grad_norm": 0.1758727878332138,
      "learning_rate": 0.0004907349610024931,
      "loss": 2.3355,
      "step": 3170
    },
    {
      "epoch": 19.157099697885197,
      "grad_norm": 0.18972839415073395,
      "learning_rate": 0.000490670008983309,
      "loss": 2.3221,
      "step": 3180
    },
    {
      "epoch": 19.21752265861027,
      "grad_norm": 0.1696007400751114,
      "learning_rate": 0.0004906048344162677,
      "loss": 2.3249,
      "step": 3190
    },
    {
      "epoch": 19.27794561933535,
      "grad_norm": 0.16004809737205505,
      "learning_rate": 0.0004905394373616361,
      "loss": 2.3298,
      "step": 3200
    },
    {
      "epoch": 19.338368580060422,
      "grad_norm": 0.16333532333374023,
      "learning_rate": 0.0004904738178798869,
      "loss": 2.3294,
      "step": 3210
    },
    {
      "epoch": 19.3987915407855,
      "grad_norm": 0.1683400273323059,
      "learning_rate": 0.0004904079760316986,
      "loss": 2.3351,
      "step": 3220
    },
    {
      "epoch": 19.459214501510573,
      "grad_norm": 0.1688394546508789,
      "learning_rate": 0.0004903419118779553,
      "loss": 2.3258,
      "step": 3230
    },
    {
      "epoch": 19.51963746223565,
      "grad_norm": 0.16163603961467743,
      "learning_rate": 0.0004902756254797465,
      "loss": 2.3232,
      "step": 3240
    },
    {
      "epoch": 19.580060422960724,
      "grad_norm": 0.1630144715309143,
      "learning_rate": 0.0004902091168983674,
      "loss": 2.3233,
      "step": 3250
    },
    {
      "epoch": 19.6404833836858,
      "grad_norm": 0.16648058593273163,
      "learning_rate": 0.0004901423861953186,
      "loss": 2.3325,
      "step": 3260
    },
    {
      "epoch": 19.700906344410875,
      "grad_norm": 0.21552015841007233,
      "learning_rate": 0.0004900754334323059,
      "loss": 2.3305,
      "step": 3270
    },
    {
      "epoch": 19.761329305135952,
      "grad_norm": 0.15090446174144745,
      "learning_rate": 0.0004900082586712407,
      "loss": 2.3441,
      "step": 3280
    },
    {
      "epoch": 19.821752265861026,
      "grad_norm": 0.16020610928535461,
      "learning_rate": 0.0004899408619742396,
      "loss": 2.3306,
      "step": 3290
    },
    {
      "epoch": 19.882175226586103,
      "grad_norm": 0.21149984002113342,
      "learning_rate": 0.0004898732434036243,
      "loss": 2.3358,
      "step": 3300
    },
    {
      "epoch": 19.942598187311177,
      "grad_norm": 0.19164516031742096,
      "learning_rate": 0.000489805403021922,
      "loss": 2.3262,
      "step": 3310
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.18936549127101898,
      "learning_rate": 0.0004897373408918646,
      "loss": 2.2054,
      "step": 3320
    },
    {
      "epoch": 20.0,
      "eval_loss": 1.1449649333953857,
      "eval_runtime": 4.7348,
      "eval_samples_per_second": 3514.0,
      "eval_steps_per_second": 13.728,
      "step": 3320
    },
    {
      "epoch": 20.060422960725077,
      "grad_norm": 0.18472452461719513,
      "learning_rate": 0.0004896690570763893,
      "loss": 2.3208,
      "step": 3330
    },
    {
      "epoch": 20.12084592145015,
      "grad_norm": 0.2626977264881134,
      "learning_rate": 0.0004896005516386383,
      "loss": 2.329,
      "step": 3340
    },
    {
      "epoch": 20.181268882175228,
      "grad_norm": 0.18144290149211884,
      "learning_rate": 0.0004895318246419584,
      "loss": 2.3213,
      "step": 3350
    },
    {
      "epoch": 20.241691842900302,
      "grad_norm": 0.18064668774604797,
      "learning_rate": 0.0004894628761499018,
      "loss": 2.3176,
      "step": 3360
    },
    {
      "epoch": 20.30211480362538,
      "grad_norm": 0.21768121421337128,
      "learning_rate": 0.0004893937062262253,
      "loss": 2.3161,
      "step": 3370
    },
    {
      "epoch": 20.362537764350453,
      "grad_norm": 0.2016030102968216,
      "learning_rate": 0.0004893243149348902,
      "loss": 2.3385,
      "step": 3380
    },
    {
      "epoch": 20.42296072507553,
      "grad_norm": 0.20284666121006012,
      "learning_rate": 0.0004892547023400628,
      "loss": 2.3281,
      "step": 3390
    },
    {
      "epoch": 20.483383685800604,
      "grad_norm": 0.21035413444042206,
      "learning_rate": 0.0004891848685061139,
      "loss": 2.3397,
      "step": 3400
    },
    {
      "epoch": 20.54380664652568,
      "grad_norm": 0.17150473594665527,
      "learning_rate": 0.000489114813497619,
      "loss": 2.318,
      "step": 3410
    },
    {
      "epoch": 20.604229607250755,
      "grad_norm": 0.22979533672332764,
      "learning_rate": 0.0004890445373793581,
      "loss": 2.3258,
      "step": 3420
    },
    {
      "epoch": 20.664652567975832,
      "grad_norm": 0.6489852070808411,
      "learning_rate": 0.0004889740402163156,
      "loss": 2.317,
      "step": 3430
    },
    {
      "epoch": 20.725075528700906,
      "grad_norm": 0.17305167019367218,
      "learning_rate": 0.0004889033220736802,
      "loss": 2.3194,
      "step": 3440
    },
    {
      "epoch": 20.785498489425983,
      "grad_norm": 0.23292513191699982,
      "learning_rate": 0.0004888323830168452,
      "loss": 2.3208,
      "step": 3450
    },
    {
      "epoch": 20.845921450151057,
      "grad_norm": 0.19184164702892303,
      "learning_rate": 0.0004887612231114079,
      "loss": 2.335,
      "step": 3460
    },
    {
      "epoch": 20.906344410876134,
      "grad_norm": 0.19634048640727997,
      "learning_rate": 0.00048868984242317,
      "loss": 2.3195,
      "step": 3470
    },
    {
      "epoch": 20.966767371601208,
      "grad_norm": 0.19725744426250458,
      "learning_rate": 0.0004886182410181374,
      "loss": 2.3372,
      "step": 3480
    },
    {
      "epoch": 21.0,
      "eval_loss": 1.1452007293701172,
      "eval_runtime": 4.5624,
      "eval_samples_per_second": 3646.73,
      "eval_steps_per_second": 14.247,
      "step": 3486
    },
    {
      "epoch": 21.02416918429003,
      "grad_norm": 0.20389209687709808,
      "learning_rate": 0.0004885464189625199,
      "loss": 2.2038,
      "step": 3490
    },
    {
      "epoch": 21.084592145015105,
      "grad_norm": 0.20792652666568756,
      "learning_rate": 0.0004884743763227316,
      "loss": 2.3208,
      "step": 3500
    },
    {
      "epoch": 21.145015105740182,
      "grad_norm": 0.25560063123703003,
      "learning_rate": 0.0004884021131653902,
      "loss": 2.3163,
      "step": 3510
    },
    {
      "epoch": 21.205438066465256,
      "grad_norm": 0.2259833812713623,
      "learning_rate": 0.0004883296295573175,
      "loss": 2.318,
      "step": 3520
    },
    {
      "epoch": 21.265861027190333,
      "grad_norm": 0.23311062157154083,
      "learning_rate": 0.00048825692556553953,
      "loss": 2.3229,
      "step": 3530
    },
    {
      "epoch": 21.326283987915406,
      "grad_norm": 0.3055798411369324,
      "learning_rate": 0.00048818400125728547,
      "loss": 2.3248,
      "step": 3540
    },
    {
      "epoch": 21.386706948640484,
      "grad_norm": 0.2166740745306015,
      "learning_rate": 0.00048811085669998855,
      "loss": 2.3181,
      "step": 3550
    },
    {
      "epoch": 21.447129909365557,
      "grad_norm": 0.265289843082428,
      "learning_rate": 0.0004880374919612857,
      "loss": 2.3169,
      "step": 3560
    },
    {
      "epoch": 21.507552870090635,
      "grad_norm": 0.18969282507896423,
      "learning_rate": 0.0004879639071090174,
      "loss": 2.3249,
      "step": 3570
    },
    {
      "epoch": 21.56797583081571,
      "grad_norm": 0.20040671527385712,
      "learning_rate": 0.00048789010221122765,
      "loss": 2.3249,
      "step": 3580
    },
    {
      "epoch": 21.628398791540786,
      "grad_norm": 0.1905737668275833,
      "learning_rate": 0.00048781607733616386,
      "loss": 2.321,
      "step": 3590
    },
    {
      "epoch": 21.68882175226586,
      "grad_norm": 0.2013416886329651,
      "learning_rate": 0.0004877418325522769,
      "loss": 2.334,
      "step": 3600
    },
    {
      "epoch": 21.749244712990937,
      "grad_norm": 0.17319627106189728,
      "learning_rate": 0.00048766736792822115,
      "loss": 2.328,
      "step": 3610
    },
    {
      "epoch": 21.809667673716014,
      "grad_norm": 0.1633111834526062,
      "learning_rate": 0.00048759268353285403,
      "loss": 2.3118,
      "step": 3620
    },
    {
      "epoch": 21.870090634441087,
      "grad_norm": 0.24473655223846436,
      "learning_rate": 0.0004875177794352363,
      "loss": 2.3197,
      "step": 3630
    },
    {
      "epoch": 21.930513595166165,
      "grad_norm": 0.19894665479660034,
      "learning_rate": 0.00048744265570463196,
      "loss": 2.3194,
      "step": 3640
    },
    {
      "epoch": 21.99093655589124,
      "grad_norm": 0.21439974009990692,
      "learning_rate": 0.000487367312410508,
      "loss": 2.3238,
      "step": 3650
    },
    {
      "epoch": 22.0,
      "eval_loss": 1.1474918127059937,
      "eval_runtime": 4.5723,
      "eval_samples_per_second": 3638.87,
      "eval_steps_per_second": 14.216,
      "step": 3652
    },
    {
      "epoch": 22.048338368580062,
      "grad_norm": 0.19133135676383972,
      "learning_rate": 0.0004872917496225344,
      "loss": 2.2083,
      "step": 3660
    },
    {
      "epoch": 22.108761329305135,
      "grad_norm": 0.1865391880273819,
      "learning_rate": 0.00048721596741058414,
      "loss": 2.3155,
      "step": 3670
    },
    {
      "epoch": 22.169184290030213,
      "grad_norm": 0.19677047431468964,
      "learning_rate": 0.00048713996584473317,
      "loss": 2.3295,
      "step": 3680
    },
    {
      "epoch": 22.229607250755286,
      "grad_norm": 0.19593589007854462,
      "learning_rate": 0.0004870637449952603,
      "loss": 2.322,
      "step": 3690
    },
    {
      "epoch": 22.290030211480364,
      "grad_norm": 0.23059596121311188,
      "learning_rate": 0.00048698730493264693,
      "loss": 2.3191,
      "step": 3700
    },
    {
      "epoch": 22.350453172205437,
      "grad_norm": 0.2005251944065094,
      "learning_rate": 0.0004869106457275774,
      "loss": 2.318,
      "step": 3710
    },
    {
      "epoch": 22.410876132930515,
      "grad_norm": 0.1829320192337036,
      "learning_rate": 0.0004868337674509384,
      "loss": 2.3109,
      "step": 3720
    },
    {
      "epoch": 22.47129909365559,
      "grad_norm": 0.18777689337730408,
      "learning_rate": 0.00048675667017381946,
      "loss": 2.3071,
      "step": 3730
    },
    {
      "epoch": 22.531722054380666,
      "grad_norm": 0.21548999845981598,
      "learning_rate": 0.00048667935396751264,
      "loss": 2.3109,
      "step": 3740
    },
    {
      "epoch": 22.59214501510574,
      "grad_norm": 0.24305711686611176,
      "learning_rate": 0.00048660181890351214,
      "loss": 2.3249,
      "step": 3750
    },
    {
      "epoch": 22.652567975830816,
      "grad_norm": 0.19587747752666473,
      "learning_rate": 0.0004865240650535149,
      "loss": 2.3154,
      "step": 3760
    },
    {
      "epoch": 22.71299093655589,
      "grad_norm": 0.22359545528888702,
      "learning_rate": 0.00048644609248941985,
      "loss": 2.3253,
      "step": 3770
    },
    {
      "epoch": 22.773413897280967,
      "grad_norm": 0.19871504604816437,
      "learning_rate": 0.0004863679012833284,
      "loss": 2.3192,
      "step": 3780
    },
    {
      "epoch": 22.83383685800604,
      "grad_norm": 0.1978173404932022,
      "learning_rate": 0.000486289491507544,
      "loss": 2.3247,
      "step": 3790
    },
    {
      "epoch": 22.89425981873112,
      "grad_norm": 0.22079907357692719,
      "learning_rate": 0.0004862108632345724,
      "loss": 2.3154,
      "step": 3800
    },
    {
      "epoch": 22.954682779456192,
      "grad_norm": 0.1977059543132782,
      "learning_rate": 0.00048613201653712113,
      "loss": 2.3202,
      "step": 3810
    },
    {
      "epoch": 23.0,
      "eval_loss": 1.142723560333252,
      "eval_runtime": 4.5862,
      "eval_samples_per_second": 3627.856,
      "eval_steps_per_second": 14.173,
      "step": 3818
    },
    {
      "epoch": 23.012084592145015,
      "grad_norm": 0.19951236248016357,
      "learning_rate": 0.0004860529514880999,
      "loss": 2.2076,
      "step": 3820
    },
    {
      "epoch": 23.07250755287009,
      "grad_norm": 0.18646956980228424,
      "learning_rate": 0.0004859736681606202,
      "loss": 2.3188,
      "step": 3830
    },
    {
      "epoch": 23.132930513595166,
      "grad_norm": 0.19716721773147583,
      "learning_rate": 0.00048589416662799553,
      "loss": 2.3108,
      "step": 3840
    },
    {
      "epoch": 23.19335347432024,
      "grad_norm": 0.22405481338500977,
      "learning_rate": 0.00048581444696374086,
      "loss": 2.3163,
      "step": 3850
    },
    {
      "epoch": 23.253776435045317,
      "grad_norm": 0.2068936824798584,
      "learning_rate": 0.00048573450924157326,
      "loss": 2.3137,
      "step": 3860
    },
    {
      "epoch": 23.31419939577039,
      "grad_norm": 0.19905371963977814,
      "learning_rate": 0.0004856543535354112,
      "loss": 2.3211,
      "step": 3870
    },
    {
      "epoch": 23.37462235649547,
      "grad_norm": 0.22009477019309998,
      "learning_rate": 0.0004855739799193747,
      "loss": 2.3205,
      "step": 3880
    },
    {
      "epoch": 23.435045317220546,
      "grad_norm": 0.23506999015808105,
      "learning_rate": 0.0004854933884677854,
      "loss": 2.3149,
      "step": 3890
    },
    {
      "epoch": 23.49546827794562,
      "grad_norm": 0.3651335835456848,
      "learning_rate": 0.00048541257925516614,
      "loss": 2.3128,
      "step": 3900
    },
    {
      "epoch": 23.555891238670696,
      "grad_norm": 0.20161153376102448,
      "learning_rate": 0.0004853315523562416,
      "loss": 2.3107,
      "step": 3910
    },
    {
      "epoch": 23.61631419939577,
      "grad_norm": 0.21171294152736664,
      "learning_rate": 0.0004852503078459372,
      "loss": 2.331,
      "step": 3920
    },
    {
      "epoch": 23.676737160120847,
      "grad_norm": 0.3858526945114136,
      "learning_rate": 0.00048516884579938004,
      "loss": 2.3105,
      "step": 3930
    },
    {
      "epoch": 23.73716012084592,
      "grad_norm": 0.5190656781196594,
      "learning_rate": 0.000485087166291898,
      "loss": 2.3164,
      "step": 3940
    },
    {
      "epoch": 23.797583081571,
      "grad_norm": 0.21051283180713654,
      "learning_rate": 0.0004850052693990203,
      "loss": 2.3147,
      "step": 3950
    },
    {
      "epoch": 23.858006042296072,
      "grad_norm": 0.2522173523902893,
      "learning_rate": 0.0004849231551964771,
      "loss": 2.3022,
      "step": 3960
    },
    {
      "epoch": 23.91842900302115,
      "grad_norm": 0.21810905635356903,
      "learning_rate": 0.00048484082376019954,
      "loss": 2.3161,
      "step": 3970
    },
    {
      "epoch": 23.978851963746223,
      "grad_norm": 0.1912369430065155,
      "learning_rate": 0.00048475827516631954,
      "loss": 2.3157,
      "step": 3980
    },
    {
      "epoch": 24.0,
      "eval_loss": 1.1421681642532349,
      "eval_runtime": 4.5595,
      "eval_samples_per_second": 3649.067,
      "eval_steps_per_second": 14.256,
      "step": 3984
    },
    {
      "epoch": 24.036253776435046,
      "grad_norm": 0.198611781001091,
      "learning_rate": 0.0004846755094911699,
      "loss": 2.1785,
      "step": 3990
    },
    {
      "epoch": 24.09667673716012,
      "grad_norm": 0.2394900619983673,
      "learning_rate": 0.0004845925268112842,
      "loss": 2.3157,
      "step": 4000
    },
    {
      "epoch": 24.157099697885197,
      "grad_norm": 0.19062016904354095,
      "learning_rate": 0.0004845093272033965,
      "loss": 2.3149,
      "step": 4010
    },
    {
      "epoch": 24.21752265861027,
      "grad_norm": 0.22245749831199646,
      "learning_rate": 0.00048442591074444175,
      "loss": 2.3237,
      "step": 4020
    },
    {
      "epoch": 24.27794561933535,
      "grad_norm": 0.21307699382305145,
      "learning_rate": 0.00048434227751155515,
      "loss": 2.3092,
      "step": 4030
    },
    {
      "epoch": 24.338368580060422,
      "grad_norm": 0.22169175744056702,
      "learning_rate": 0.0004842584275820724,
      "loss": 2.3059,
      "step": 4040
    },
    {
      "epoch": 24.3987915407855,
      "grad_norm": 0.22518770396709442,
      "learning_rate": 0.00048417436103352976,
      "loss": 2.3123,
      "step": 4050
    },
    {
      "epoch": 24.459214501510573,
      "grad_norm": 0.22602657973766327,
      "learning_rate": 0.00048409007794366363,
      "loss": 2.3086,
      "step": 4060
    },
    {
      "epoch": 24.51963746223565,
      "grad_norm": 0.2135748267173767,
      "learning_rate": 0.00048400557839041057,
      "loss": 2.3021,
      "step": 4070
    },
    {
      "epoch": 24.580060422960724,
      "grad_norm": 0.21181541681289673,
      "learning_rate": 0.0004839208624519077,
      "loss": 2.3101,
      "step": 4080
    },
    {
      "epoch": 24.6404833836858,
      "grad_norm": 0.19739338755607605,
      "learning_rate": 0.00048383593020649165,
      "loss": 2.3156,
      "step": 4090
    },
    {
      "epoch": 24.700906344410875,
      "grad_norm": 0.22236081957817078,
      "learning_rate": 0.0004837507817326996,
      "loss": 2.321,
      "step": 4100
    },
    {
      "epoch": 24.761329305135952,
      "grad_norm": 0.1845286637544632,
      "learning_rate": 0.0004836654171092683,
      "loss": 2.3128,
      "step": 4110
    },
    {
      "epoch": 24.821752265861026,
      "grad_norm": 0.21360686421394348,
      "learning_rate": 0.00048357983641513457,
      "loss": 2.3078,
      "step": 4120
    },
    {
      "epoch": 24.882175226586103,
      "grad_norm": 0.17903251945972443,
      "learning_rate": 0.000483494039729435,
      "loss": 2.3178,
      "step": 4130
    },
    {
      "epoch": 24.942598187311177,
      "grad_norm": 0.17849069833755493,
      "learning_rate": 0.00048340802713150587,
      "loss": 2.3172,
      "step": 4140
    },
    {
      "epoch": 25.0,
      "grad_norm": 0.202117919921875,
      "learning_rate": 0.0004833217987008832,
      "loss": 2.1891,
      "step": 4150
    },
    {
      "epoch": 25.0,
      "eval_loss": 1.1398906707763672,
      "eval_runtime": 4.5619,
      "eval_samples_per_second": 3647.196,
      "eval_steps_per_second": 14.249,
      "step": 4150
    },
    {
      "epoch": 25.060422960725077,
      "grad_norm": 0.20989982783794403,
      "learning_rate": 0.0004832353545173025,
      "loss": 2.3119,
      "step": 4160
    },
    {
      "epoch": 25.12084592145015,
      "grad_norm": 0.2108498066663742,
      "learning_rate": 0.0004831486946606988,
      "loss": 2.2974,
      "step": 4170
    },
    {
      "epoch": 25.181268882175228,
      "grad_norm": 0.8140398859977722,
      "learning_rate": 0.00048306181921120643,
      "loss": 2.3232,
      "step": 4180
    },
    {
      "epoch": 25.241691842900302,
      "grad_norm": 0.18266597390174866,
      "learning_rate": 0.0004829747282491595,
      "loss": 2.3033,
      "step": 4190
    },
    {
      "epoch": 25.30211480362538,
      "grad_norm": 0.23925134539604187,
      "learning_rate": 0.00048288742185509094,
      "loss": 2.308,
      "step": 4200
    },
    {
      "epoch": 25.362537764350453,
      "grad_norm": 0.23539650440216064,
      "learning_rate": 0.0004827999001097332,
      "loss": 2.323,
      "step": 4210
    },
    {
      "epoch": 25.42296072507553,
      "grad_norm": 0.1789817214012146,
      "learning_rate": 0.00048271216309401767,
      "loss": 2.3074,
      "step": 4220
    },
    {
      "epoch": 25.483383685800604,
      "grad_norm": 0.24250651895999908,
      "learning_rate": 0.00048262421088907483,
      "loss": 2.3075,
      "step": 4230
    },
    {
      "epoch": 25.54380664652568,
      "grad_norm": 0.1995212435722351,
      "learning_rate": 0.00048253604357623424,
      "loss": 2.3158,
      "step": 4240
    },
    {
      "epoch": 25.604229607250755,
      "grad_norm": 0.21929892897605896,
      "learning_rate": 0.00048244766123702444,
      "loss": 2.3194,
      "step": 4250
    },
    {
      "epoch": 25.664652567975832,
      "grad_norm": 0.2055879384279251,
      "learning_rate": 0.0004823590639531726,
      "loss": 2.3083,
      "step": 4260
    },
    {
      "epoch": 25.725075528700906,
      "grad_norm": 0.2263101041316986,
      "learning_rate": 0.0004822702518066047,
      "loss": 2.3102,
      "step": 4270
    },
    {
      "epoch": 25.785498489425983,
      "grad_norm": 0.18363222479820251,
      "learning_rate": 0.00048218122487944545,
      "loss": 2.3058,
      "step": 4280
    },
    {
      "epoch": 25.845921450151057,
      "grad_norm": 0.21953460574150085,
      "learning_rate": 0.00048209198325401817,
      "loss": 2.3016,
      "step": 4290
    },
    {
      "epoch": 25.906344410876134,
      "grad_norm": 0.19394852221012115,
      "learning_rate": 0.00048200252701284475,
      "loss": 2.3128,
      "step": 4300
    },
    {
      "epoch": 25.966767371601208,
      "grad_norm": 0.1730251908302307,
      "learning_rate": 0.00048191285623864545,
      "loss": 2.3145,
      "step": 4310
    },
    {
      "epoch": 26.0,
      "eval_loss": 1.1390360593795776,
      "eval_runtime": 4.5768,
      "eval_samples_per_second": 3635.317,
      "eval_steps_per_second": 14.202,
      "step": 4316
    },
    {
      "epoch": 26.02416918429003,
      "grad_norm": 0.23813791573047638,
      "learning_rate": 0.0004818229710143389,
      "loss": 2.191,
      "step": 4320
    },
    {
      "epoch": 26.084592145015105,
      "grad_norm": 0.19046343863010406,
      "learning_rate": 0.0004817328714230422,
      "loss": 2.3031,
      "step": 4330
    },
    {
      "epoch": 26.145015105740182,
      "grad_norm": 0.19725528359413147,
      "learning_rate": 0.0004816425575480704,
      "loss": 2.3023,
      "step": 4340
    },
    {
      "epoch": 26.205438066465256,
      "grad_norm": 0.21544133126735687,
      "learning_rate": 0.000481552029472937,
      "loss": 2.306,
      "step": 4350
    },
    {
      "epoch": 26.265861027190333,
      "grad_norm": 0.21697553992271423,
      "learning_rate": 0.0004814612872813534,
      "loss": 2.3128,
      "step": 4360
    },
    {
      "epoch": 26.326283987915406,
      "grad_norm": 0.19642432034015656,
      "learning_rate": 0.00048137033105722895,
      "loss": 2.311,
      "step": 4370
    },
    {
      "epoch": 26.386706948640484,
      "grad_norm": 0.19046653807163239,
      "learning_rate": 0.00048127916088467097,
      "loss": 2.3175,
      "step": 4380
    },
    {
      "epoch": 26.447129909365557,
      "grad_norm": 0.20937539637088776,
      "learning_rate": 0.00048118777684798465,
      "loss": 2.3077,
      "step": 4390
    },
    {
      "epoch": 26.507552870090635,
      "grad_norm": 0.20041751861572266,
      "learning_rate": 0.00048109617903167303,
      "loss": 2.3071,
      "step": 4400
    },
    {
      "epoch": 26.56797583081571,
      "grad_norm": 0.2199918031692505,
      "learning_rate": 0.0004810043675204366,
      "loss": 2.2879,
      "step": 4410
    },
    {
      "epoch": 26.628398791540786,
      "grad_norm": 0.2676900625228882,
      "learning_rate": 0.0004809123423991736,
      "loss": 2.3169,
      "step": 4420
    },
    {
      "epoch": 26.68882175226586,
      "grad_norm": 0.19835034012794495,
      "learning_rate": 0.0004808201037529798,
      "loss": 2.3096,
      "step": 4430
    },
    {
      "epoch": 26.749244712990937,
      "grad_norm": 0.2513218820095062,
      "learning_rate": 0.00048072765166714843,
      "loss": 2.3154,
      "step": 4440
    },
    {
      "epoch": 26.809667673716014,
      "grad_norm": 0.19613967835903168,
      "learning_rate": 0.00048063498622717,
      "loss": 2.3076,
      "step": 4450
    },
    {
      "epoch": 26.870090634441087,
      "grad_norm": 0.2052503079175949,
      "learning_rate": 0.0004805421075187323,
      "loss": 2.2888,
      "step": 4460
    },
    {
      "epoch": 26.930513595166165,
      "grad_norm": 0.2569703757762909,
      "learning_rate": 0.00048044901562772045,
      "loss": 2.2994,
      "step": 4470
    },
    {
      "epoch": 26.99093655589124,
      "grad_norm": 0.1840694695711136,
      "learning_rate": 0.0004803557106402168,
      "loss": 2.3032,
      "step": 4480
    },
    {
      "epoch": 27.0,
      "eval_loss": 1.1392104625701904,
      "eval_runtime": 4.6149,
      "eval_samples_per_second": 3605.281,
      "eval_steps_per_second": 14.085,
      "step": 4482
    },
    {
      "epoch": 27.048338368580062,
      "grad_norm": 0.21694257855415344,
      "learning_rate": 0.0004802621926425003,
      "loss": 2.187,
      "step": 4490
    },
    {
      "epoch": 27.108761329305135,
      "grad_norm": 0.22776134312152863,
      "learning_rate": 0.00048016846172104725,
      "loss": 2.2948,
      "step": 4500
    },
    {
      "epoch": 27.169184290030213,
      "grad_norm": 0.25308340787887573,
      "learning_rate": 0.00048007451796253076,
      "loss": 2.2993,
      "step": 4510
    },
    {
      "epoch": 27.229607250755286,
      "grad_norm": 0.2395467609167099,
      "learning_rate": 0.00047998036145382084,
      "loss": 2.3085,
      "step": 4520
    },
    {
      "epoch": 27.290030211480364,
      "grad_norm": 0.2685711681842804,
      "learning_rate": 0.00047988599228198406,
      "loss": 2.3073,
      "step": 4530
    },
    {
      "epoch": 27.350453172205437,
      "grad_norm": 0.25573664903640747,
      "learning_rate": 0.00047979141053428373,
      "loss": 2.2978,
      "step": 4540
    },
    {
      "epoch": 27.410876132930515,
      "grad_norm": 0.22414866089820862,
      "learning_rate": 0.00047969661629817964,
      "loss": 2.2985,
      "step": 4550
    },
    {
      "epoch": 27.47129909365559,
      "grad_norm": 0.2359444499015808,
      "learning_rate": 0.00047960160966132817,
      "loss": 2.3039,
      "step": 4560
    },
    {
      "epoch": 27.531722054380666,
      "grad_norm": 0.24596507847309113,
      "learning_rate": 0.0004795063907115821,
      "loss": 2.3012,
      "step": 4570
    },
    {
      "epoch": 27.59214501510574,
      "grad_norm": 0.23300305008888245,
      "learning_rate": 0.00047941095953699055,
      "loss": 2.3045,
      "step": 4580
    },
    {
      "epoch": 27.652567975830816,
      "grad_norm": 0.29743513464927673,
      "learning_rate": 0.00047931531622579876,
      "loss": 2.3074,
      "step": 4590
    },
    {
      "epoch": 27.71299093655589,
      "grad_norm": 0.21845997869968414,
      "learning_rate": 0.0004792194608664483,
      "loss": 2.3131,
      "step": 4600
    },
    {
      "epoch": 27.773413897280967,
      "grad_norm": 0.23859578371047974,
      "learning_rate": 0.0004791233935475766,
      "loss": 2.314,
      "step": 4610
    },
    {
      "epoch": 27.83383685800604,
      "grad_norm": 0.42867496609687805,
      "learning_rate": 0.0004790271143580174,
      "loss": 2.3077,
      "step": 4620
    },
    {
      "epoch": 27.89425981873112,
      "grad_norm": 0.2067721039056778,
      "learning_rate": 0.00047893062338680016,
      "loss": 2.3067,
      "step": 4630
    },
    {
      "epoch": 27.954682779456192,
      "grad_norm": 0.24714401364326477,
      "learning_rate": 0.00047883392072315,
      "loss": 2.3107,
      "step": 4640
    },
    {
      "epoch": 28.0,
      "eval_loss": 1.1388181447982788,
      "eval_runtime": 4.7537,
      "eval_samples_per_second": 3500.026,
      "eval_steps_per_second": 13.674,
      "step": 4648
    },
    {
      "epoch": 28.012084592145015,
      "grad_norm": 0.20700566470623016,
      "learning_rate": 0.0004787370064564883,
      "loss": 2.1819,
      "step": 4650
    },
    {
      "epoch": 28.07250755287009,
      "grad_norm": 0.22427873313426971,
      "learning_rate": 0.0004786398806764316,
      "loss": 2.3004,
      "step": 4660
    },
    {
      "epoch": 28.132930513595166,
      "grad_norm": 0.38048142194747925,
      "learning_rate": 0.00047854254347279225,
      "loss": 2.2975,
      "step": 4670
    },
    {
      "epoch": 28.19335347432024,
      "grad_norm": 0.2739615738391876,
      "learning_rate": 0.0004784449949355781,
      "loss": 2.2982,
      "step": 4680
    },
    {
      "epoch": 28.253776435045317,
      "grad_norm": 0.2532006502151489,
      "learning_rate": 0.00047834723515499254,
      "loss": 2.2977,
      "step": 4690
    },
    {
      "epoch": 28.31419939577039,
      "grad_norm": 0.2229459434747696,
      "learning_rate": 0.00047824926422143394,
      "loss": 2.3077,
      "step": 4700
    },
    {
      "epoch": 28.37462235649547,
      "grad_norm": 0.28020191192626953,
      "learning_rate": 0.0004781510822254963,
      "loss": 2.3144,
      "step": 4710
    },
    {
      "epoch": 28.435045317220546,
      "grad_norm": 0.22527414560317993,
      "learning_rate": 0.00047805268925796854,
      "loss": 2.3127,
      "step": 4720
    },
    {
      "epoch": 28.49546827794562,
      "grad_norm": 0.22307650744915009,
      "learning_rate": 0.00047795408540983475,
      "loss": 2.3174,
      "step": 4730
    },
    {
      "epoch": 28.555891238670696,
      "grad_norm": 0.2018287032842636,
      "learning_rate": 0.0004778552707722742,
      "loss": 2.3115,
      "step": 4740
    },
    {
      "epoch": 28.61631419939577,
      "grad_norm": 0.23529082536697388,
      "learning_rate": 0.00047775624543666077,
      "loss": 2.3068,
      "step": 4750
    },
    {
      "epoch": 28.676737160120847,
      "grad_norm": 0.19171689450740814,
      "learning_rate": 0.00047765700949456327,
      "loss": 2.3081,
      "step": 4760
    },
    {
      "epoch": 28.73716012084592,
      "grad_norm": 0.18850241601467133,
      "learning_rate": 0.0004775575630377453,
      "loss": 2.3008,
      "step": 4770
    },
    {
      "epoch": 28.797583081571,
      "grad_norm": 0.31587961316108704,
      "learning_rate": 0.00047745790615816525,
      "loss": 2.3055,
      "step": 4780
    },
    {
      "epoch": 28.858006042296072,
      "grad_norm": 0.20589151978492737,
      "learning_rate": 0.0004773580389479759,
      "loss": 2.29,
      "step": 4790
    },
    {
      "epoch": 28.91842900302115,
      "grad_norm": 0.18877582252025604,
      "learning_rate": 0.0004772579614995246,
      "loss": 2.2991,
      "step": 4800
    },
    {
      "epoch": 28.978851963746223,
      "grad_norm": 0.20078139007091522,
      "learning_rate": 0.00047715767390535304,
      "loss": 2.2857,
      "step": 4810
    },
    {
      "epoch": 29.0,
      "eval_loss": 1.1376893520355225,
      "eval_runtime": 4.5679,
      "eval_samples_per_second": 3642.372,
      "eval_steps_per_second": 14.23,
      "step": 4814
    },
    {
      "epoch": 29.036253776435046,
      "grad_norm": 0.19794200360774994,
      "learning_rate": 0.0004770571762581973,
      "loss": 2.1857,
      "step": 4820
    },
    {
      "epoch": 29.09667673716012,
      "grad_norm": 0.21623292565345764,
      "learning_rate": 0.0004769564686509877,
      "loss": 2.2842,
      "step": 4830
    },
    {
      "epoch": 29.157099697885197,
      "grad_norm": 0.2150130420923233,
      "learning_rate": 0.00047685555117684867,
      "loss": 2.3014,
      "step": 4840
    },
    {
      "epoch": 29.21752265861027,
      "grad_norm": 0.2630000114440918,
      "learning_rate": 0.0004767544239290987,
      "loss": 2.2889,
      "step": 4850
    },
    {
      "epoch": 29.27794561933535,
      "grad_norm": 0.3730926513671875,
      "learning_rate": 0.0004766530870012504,
      "loss": 2.3143,
      "step": 4860
    },
    {
      "epoch": 29.338368580060422,
      "grad_norm": 0.276011198759079,
      "learning_rate": 0.00047655154048701,
      "loss": 2.3006,
      "step": 4870
    },
    {
      "epoch": 29.3987915407855,
      "grad_norm": 0.21756677329540253,
      "learning_rate": 0.00047644978448027777,
      "loss": 2.2994,
      "step": 4880
    },
    {
      "epoch": 29.459214501510573,
      "grad_norm": 0.23848550021648407,
      "learning_rate": 0.0004763478190751476,
      "loss": 2.2984,
      "step": 4890
    },
    {
      "epoch": 29.51963746223565,
      "grad_norm": 0.24978232383728027,
      "learning_rate": 0.0004762456443659071,
      "loss": 2.3017,
      "step": 4900
    },
    {
      "epoch": 29.580060422960724,
      "grad_norm": 0.23563234508037567,
      "learning_rate": 0.0004761432604470372,
      "loss": 2.312,
      "step": 4910
    },
    {
      "epoch": 29.6404833836858,
      "grad_norm": 0.23883740603923798,
      "learning_rate": 0.00047604066741321254,
      "loss": 2.3007,
      "step": 4920
    },
    {
      "epoch": 29.700906344410875,
      "grad_norm": 0.19368989765644073,
      "learning_rate": 0.00047593786535930104,
      "loss": 2.31,
      "step": 4930
    },
    {
      "epoch": 29.761329305135952,
      "grad_norm": 0.25144726037979126,
      "learning_rate": 0.00047583485438036383,
      "loss": 2.2919,
      "step": 4940
    },
    {
      "epoch": 29.821752265861026,
      "grad_norm": 0.2573068141937256,
      "learning_rate": 0.0004757316345716554,
      "loss": 2.2992,
      "step": 4950
    },
    {
      "epoch": 29.882175226586103,
      "grad_norm": 0.2718740999698639,
      "learning_rate": 0.000475628206028623,
      "loss": 2.3005,
      "step": 4960
    },
    {
      "epoch": 29.942598187311177,
      "grad_norm": 0.2500925660133362,
      "learning_rate": 0.0004755245688469073,
      "loss": 2.294,
      "step": 4970
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.27349522709846497,
      "learning_rate": 0.00047542072312234174,
      "loss": 2.1842,
      "step": 4980
    },
    {
      "epoch": 30.0,
      "eval_loss": 1.1372275352478027,
      "eval_runtime": 4.5487,
      "eval_samples_per_second": 3657.782,
      "eval_steps_per_second": 14.29,
      "step": 4980
    },
    {
      "epoch": 30.060422960725077,
      "grad_norm": 0.23478956520557404,
      "learning_rate": 0.0004753166689509526,
      "loss": 2.3013,
      "step": 4990
    },
    {
      "epoch": 30.12084592145015,
      "grad_norm": 0.22773799300193787,
      "learning_rate": 0.0004752124064289589,
      "loss": 2.2989,
      "step": 5000
    },
    {
      "epoch": 30.181268882175228,
      "grad_norm": 0.2686910033226013,
      "learning_rate": 0.0004751079356527722,
      "loss": 2.2961,
      "step": 5010
    },
    {
      "epoch": 30.241691842900302,
      "grad_norm": 0.30262860655784607,
      "learning_rate": 0.0004750032567189969,
      "loss": 2.2977,
      "step": 5020
    },
    {
      "epoch": 30.30211480362538,
      "grad_norm": 0.2559047341346741,
      "learning_rate": 0.0004748983697244297,
      "loss": 2.303,
      "step": 5030
    },
    {
      "epoch": 30.362537764350453,
      "grad_norm": 0.24965661764144897,
      "learning_rate": 0.00047479327476605967,
      "loss": 2.297,
      "step": 5040
    },
    {
      "epoch": 30.42296072507553,
      "grad_norm": 0.25559619069099426,
      "learning_rate": 0.00047468797194106827,
      "loss": 2.2947,
      "step": 5050
    },
    {
      "epoch": 30.483383685800604,
      "grad_norm": 0.24426259100437164,
      "learning_rate": 0.00047458246134682926,
      "loss": 2.3011,
      "step": 5060
    },
    {
      "epoch": 30.54380664652568,
      "grad_norm": 0.23292233049869537,
      "learning_rate": 0.0004744767430809083,
      "loss": 2.3099,
      "step": 5070
    },
    {
      "epoch": 30.604229607250755,
      "grad_norm": 0.23840178549289703,
      "learning_rate": 0.00047437081724106334,
      "loss": 2.3033,
      "step": 5080
    },
    {
      "epoch": 30.664652567975832,
      "grad_norm": 0.2868287265300751,
      "learning_rate": 0.0004742646839252439,
      "loss": 2.3061,
      "step": 5090
    },
    {
      "epoch": 30.725075528700906,
      "grad_norm": 0.23715685307979584,
      "learning_rate": 0.00047415834323159177,
      "loss": 2.2904,
      "step": 5100
    },
    {
      "epoch": 30.785498489425983,
      "grad_norm": 0.26543787121772766,
      "learning_rate": 0.0004740517952584404,
      "loss": 2.2936,
      "step": 5110
    },
    {
      "epoch": 30.845921450151057,
      "grad_norm": 0.26106515526771545,
      "learning_rate": 0.0004739450401043146,
      "loss": 2.2909,
      "step": 5120
    },
    {
      "epoch": 30.906344410876134,
      "grad_norm": 0.30276212096214294,
      "learning_rate": 0.00047383807786793115,
      "loss": 2.3037,
      "step": 5130
    },
    {
      "epoch": 30.966767371601208,
      "grad_norm": 0.26690635085105896,
      "learning_rate": 0.00047373090864819814,
      "loss": 2.2913,
      "step": 5140
    },
    {
      "epoch": 31.0,
      "eval_loss": 1.1370749473571777,
      "eval_runtime": 4.5919,
      "eval_samples_per_second": 3623.329,
      "eval_steps_per_second": 14.155,
      "step": 5146
    },
    {
      "epoch": 31.02416918429003,
      "grad_norm": 0.25025641918182373,
      "learning_rate": 0.000473623532544215,
      "loss": 2.1881,
      "step": 5150
    },
    {
      "epoch": 31.084592145015105,
      "grad_norm": 0.2906847596168518,
      "learning_rate": 0.0004735159496552727,
      "loss": 2.2881,
      "step": 5160
    },
    {
      "epoch": 31.145015105740182,
      "grad_norm": 0.28610652685165405,
      "learning_rate": 0.00047340816008085306,
      "loss": 2.2909,
      "step": 5170
    },
    {
      "epoch": 31.205438066465256,
      "grad_norm": 0.2733093500137329,
      "learning_rate": 0.00047330016392062947,
      "loss": 2.3057,
      "step": 5180
    },
    {
      "epoch": 31.265861027190333,
      "grad_norm": 0.25443965196609497,
      "learning_rate": 0.00047319196127446593,
      "loss": 2.2875,
      "step": 5190
    },
    {
      "epoch": 31.326283987915406,
      "grad_norm": 0.2503798305988312,
      "learning_rate": 0.0004730835522424176,
      "loss": 2.3038,
      "step": 5200
    },
    {
      "epoch": 31.386706948640484,
      "grad_norm": 0.2658151090145111,
      "learning_rate": 0.0004729749369247306,
      "loss": 2.2853,
      "step": 5210
    },
    {
      "epoch": 31.447129909365557,
      "grad_norm": 0.2984154224395752,
      "learning_rate": 0.0004728661154218414,
      "loss": 2.2954,
      "step": 5220
    },
    {
      "epoch": 31.507552870090635,
      "grad_norm": 0.2469407618045807,
      "learning_rate": 0.00047275708783437766,
      "loss": 2.2855,
      "step": 5230
    },
    {
      "epoch": 31.56797583081571,
      "grad_norm": 0.29509297013282776,
      "learning_rate": 0.00047264785426315704,
      "loss": 2.2892,
      "step": 5240
    },
    {
      "epoch": 31.628398791540786,
      "grad_norm": 0.25095537304878235,
      "learning_rate": 0.0004725384148091882,
      "loss": 2.2991,
      "step": 5250
    },
    {
      "epoch": 31.68882175226586,
      "grad_norm": 0.2539896070957184,
      "learning_rate": 0.00047242876957366976,
      "loss": 2.3029,
      "step": 5260
    },
    {
      "epoch": 31.749244712990937,
      "grad_norm": 0.2471267282962799,
      "learning_rate": 0.00047231891865799093,
      "loss": 2.3035,
      "step": 5270
    },
    {
      "epoch": 31.809667673716014,
      "grad_norm": 0.2490329146385193,
      "learning_rate": 0.0004722088621637309,
      "loss": 2.3061,
      "step": 5280
    },
    {
      "epoch": 31.870090634441087,
      "grad_norm": 0.25706496834754944,
      "learning_rate": 0.00047209860019265903,
      "loss": 2.2978,
      "step": 5290
    },
    {
      "epoch": 31.930513595166165,
      "grad_norm": 0.316824346780777,
      "learning_rate": 0.00047198813284673487,
      "loss": 2.2978,
      "step": 5300
    },
    {
      "epoch": 31.99093655589124,
      "grad_norm": 0.3025060296058655,
      "learning_rate": 0.0004718774602281075,
      "loss": 2.3041,
      "step": 5310
    },
    {
      "epoch": 32.0,
      "eval_loss": 1.1375795602798462,
      "eval_runtime": 4.5486,
      "eval_samples_per_second": 3657.836,
      "eval_steps_per_second": 14.29,
      "step": 5312
    },
    {
      "epoch": 32.04833836858006,
      "grad_norm": 0.2564907371997833,
      "learning_rate": 0.0004717665824391162,
      "loss": 2.1784,
      "step": 5320
    },
    {
      "epoch": 32.10876132930514,
      "grad_norm": 0.24916765093803406,
      "learning_rate": 0.00047165549958228973,
      "loss": 2.292,
      "step": 5330
    },
    {
      "epoch": 32.16918429003021,
      "grad_norm": 0.2838064134120941,
      "learning_rate": 0.0004715442117603465,
      "loss": 2.2882,
      "step": 5340
    },
    {
      "epoch": 32.229607250755286,
      "grad_norm": 0.2507980465888977,
      "learning_rate": 0.00047143271907619457,
      "loss": 2.2883,
      "step": 5350
    },
    {
      "epoch": 32.290030211480364,
      "grad_norm": 0.2630276381969452,
      "learning_rate": 0.0004713210216329313,
      "loss": 2.2982,
      "step": 5360
    },
    {
      "epoch": 32.35045317220544,
      "grad_norm": 0.295257568359375,
      "learning_rate": 0.0004712091195338436,
      "loss": 2.2861,
      "step": 5370
    },
    {
      "epoch": 32.41087613293051,
      "grad_norm": 0.28409281373023987,
      "learning_rate": 0.00047109701288240724,
      "loss": 2.3007,
      "step": 5380
    },
    {
      "epoch": 32.47129909365559,
      "grad_norm": 0.27236929535865784,
      "learning_rate": 0.0004709847017822876,
      "loss": 2.3001,
      "step": 5390
    },
    {
      "epoch": 32.531722054380666,
      "grad_norm": 0.2297242134809494,
      "learning_rate": 0.00047087218633733873,
      "loss": 2.3052,
      "step": 5400
    },
    {
      "epoch": 32.59214501510574,
      "grad_norm": 0.35006019473075867,
      "learning_rate": 0.000470759466651604,
      "loss": 2.3002,
      "step": 5410
    },
    {
      "epoch": 32.65256797583081,
      "grad_norm": 0.2984082102775574,
      "learning_rate": 0.0004706465428293152,
      "loss": 2.2929,
      "step": 5420
    },
    {
      "epoch": 32.71299093655589,
      "grad_norm": 0.2520950138568878,
      "learning_rate": 0.00047053341497489324,
      "loss": 2.292,
      "step": 5430
    },
    {
      "epoch": 32.77341389728097,
      "grad_norm": 0.274130642414093,
      "learning_rate": 0.00047042008319294763,
      "loss": 2.2919,
      "step": 5440
    },
    {
      "epoch": 32.833836858006045,
      "grad_norm": 0.26115623116493225,
      "learning_rate": 0.0004703065475882764,
      "loss": 2.2969,
      "step": 5450
    },
    {
      "epoch": 32.894259818731115,
      "grad_norm": 0.2520374357700348,
      "learning_rate": 0.0004701928082658661,
      "loss": 2.2882,
      "step": 5460
    },
    {
      "epoch": 32.95468277945619,
      "grad_norm": 0.25875359773635864,
      "learning_rate": 0.0004700788653308915,
      "loss": 2.2927,
      "step": 5470
    },
    {
      "epoch": 33.0,
      "eval_loss": 1.1346142292022705,
      "eval_runtime": 4.565,
      "eval_samples_per_second": 3644.665,
      "eval_steps_per_second": 14.239,
      "step": 5478
    },
    {
      "epoch": 33.012084592145015,
      "grad_norm": 0.2613420784473419,
      "learning_rate": 0.0004699647188887158,
      "loss": 2.1844,
      "step": 5480
    },
    {
      "epoch": 33.07250755287009,
      "grad_norm": 0.2503257691860199,
      "learning_rate": 0.0004698503690448905,
      "loss": 2.2919,
      "step": 5490
    },
    {
      "epoch": 33.13293051359516,
      "grad_norm": 0.2474384605884552,
      "learning_rate": 0.0004697358159051549,
      "loss": 2.2894,
      "step": 5500
    },
    {
      "epoch": 33.19335347432024,
      "grad_norm": 0.2585464119911194,
      "learning_rate": 0.0004696210595754364,
      "loss": 2.289,
      "step": 5510
    },
    {
      "epoch": 33.25377643504532,
      "grad_norm": 0.28802594542503357,
      "learning_rate": 0.00046950610016185045,
      "loss": 2.2896,
      "step": 5520
    },
    {
      "epoch": 33.314199395770395,
      "grad_norm": 0.31867140531539917,
      "learning_rate": 0.0004693909377707002,
      "loss": 2.2877,
      "step": 5530
    },
    {
      "epoch": 33.374622356495465,
      "grad_norm": 0.3066471517086029,
      "learning_rate": 0.00046927557250847624,
      "loss": 2.2959,
      "step": 5540
    },
    {
      "epoch": 33.43504531722054,
      "grad_norm": 0.29192617535591125,
      "learning_rate": 0.00046916000448185715,
      "loss": 2.2833,
      "step": 5550
    },
    {
      "epoch": 33.49546827794562,
      "grad_norm": 0.26882752776145935,
      "learning_rate": 0.0004690442337977088,
      "loss": 2.2883,
      "step": 5560
    },
    {
      "epoch": 33.5558912386707,
      "grad_norm": 0.2858854830265045,
      "learning_rate": 0.00046892826056308437,
      "loss": 2.2824,
      "step": 5570
    },
    {
      "epoch": 33.616314199395774,
      "grad_norm": 0.24684956669807434,
      "learning_rate": 0.00046881208488522465,
      "loss": 2.3009,
      "step": 5580
    },
    {
      "epoch": 33.676737160120844,
      "grad_norm": 0.2857086956501007,
      "learning_rate": 0.00046869570687155726,
      "loss": 2.3014,
      "step": 5590
    },
    {
      "epoch": 33.73716012084592,
      "grad_norm": 0.2674642503261566,
      "learning_rate": 0.0004685791266296971,
      "loss": 2.2967,
      "step": 5600
    },
    {
      "epoch": 33.797583081571,
      "grad_norm": 0.3015427589416504,
      "learning_rate": 0.00046846234426744626,
      "loss": 2.2976,
      "step": 5610
    },
    {
      "epoch": 33.858006042296076,
      "grad_norm": 0.26126614212989807,
      "learning_rate": 0.00046834535989279336,
      "loss": 2.2865,
      "step": 5620
    },
    {
      "epoch": 33.918429003021146,
      "grad_norm": 0.2413722574710846,
      "learning_rate": 0.000468228173613914,
      "loss": 2.2979,
      "step": 5630
    },
    {
      "epoch": 33.97885196374622,
      "grad_norm": 0.254815936088562,
      "learning_rate": 0.00046811078553917054,
      "loss": 2.2895,
      "step": 5640
    },
    {
      "epoch": 34.0,
      "eval_loss": 1.1356366872787476,
      "eval_runtime": 4.58,
      "eval_samples_per_second": 3632.757,
      "eval_steps_per_second": 14.192,
      "step": 5644
    },
    {
      "epoch": 34.036253776435046,
      "grad_norm": 0.24389885365962982,
      "learning_rate": 0.00046799319577711185,
      "loss": 2.1689,
      "step": 5650
    },
    {
      "epoch": 34.096676737160124,
      "grad_norm": 0.2674884498119354,
      "learning_rate": 0.0004678754044364734,
      "loss": 2.283,
      "step": 5660
    },
    {
      "epoch": 34.157099697885194,
      "grad_norm": 0.27295801043510437,
      "learning_rate": 0.00046775741162617684,
      "loss": 2.2864,
      "step": 5670
    },
    {
      "epoch": 34.21752265861027,
      "grad_norm": 0.26336348056793213,
      "learning_rate": 0.0004676392174553304,
      "loss": 2.2863,
      "step": 5680
    },
    {
      "epoch": 34.27794561933535,
      "grad_norm": 0.3228799104690552,
      "learning_rate": 0.0004675208220332283,
      "loss": 2.2894,
      "step": 5690
    },
    {
      "epoch": 34.338368580060425,
      "grad_norm": 0.24532096087932587,
      "learning_rate": 0.00046740222546935104,
      "loss": 2.2809,
      "step": 5700
    },
    {
      "epoch": 34.398791540785496,
      "grad_norm": 0.27116313576698303,
      "learning_rate": 0.00046728342787336486,
      "loss": 2.299,
      "step": 5710
    },
    {
      "epoch": 34.45921450151057,
      "grad_norm": 0.28924328088760376,
      "learning_rate": 0.00046716442935512215,
      "loss": 2.2998,
      "step": 5720
    },
    {
      "epoch": 34.51963746223565,
      "grad_norm": 0.3435531258583069,
      "learning_rate": 0.00046704523002466097,
      "loss": 2.2986,
      "step": 5730
    },
    {
      "epoch": 34.58006042296073,
      "grad_norm": 0.22908206284046173,
      "learning_rate": 0.00046692582999220504,
      "loss": 2.2914,
      "step": 5740
    },
    {
      "epoch": 34.6404833836858,
      "grad_norm": 0.30406785011291504,
      "learning_rate": 0.00046680622936816384,
      "loss": 2.2854,
      "step": 5750
    },
    {
      "epoch": 34.700906344410875,
      "grad_norm": 0.2570778429508209,
      "learning_rate": 0.0004666864282631321,
      "loss": 2.2949,
      "step": 5760
    },
    {
      "epoch": 34.76132930513595,
      "grad_norm": 0.38440626859664917,
      "learning_rate": 0.0004665664267878901,
      "loss": 2.2973,
      "step": 5770
    },
    {
      "epoch": 34.82175226586103,
      "grad_norm": 0.2750321626663208,
      "learning_rate": 0.0004664462250534033,
      "loss": 2.2946,
      "step": 5780
    },
    {
      "epoch": 34.8821752265861,
      "grad_norm": 0.27684536576271057,
      "learning_rate": 0.0004663258231708224,
      "loss": 2.2892,
      "step": 5790
    },
    {
      "epoch": 34.94259818731118,
      "grad_norm": 0.29240813851356506,
      "learning_rate": 0.00046620522125148325,
      "loss": 2.2947,
      "step": 5800
    },
    {
      "epoch": 35.0,
      "grad_norm": 0.36138880252838135,
      "learning_rate": 0.0004660844194069066,
      "loss": 2.181,
      "step": 5810
    },
    {
      "epoch": 35.0,
      "eval_loss": 1.1348026990890503,
      "eval_runtime": 4.5709,
      "eval_samples_per_second": 3639.97,
      "eval_steps_per_second": 14.22,
      "step": 5810
    },
    {
      "epoch": 35.06042296072508,
      "grad_norm": 0.2812497019767761,
      "learning_rate": 0.0004659634177487979,
      "loss": 2.2849,
      "step": 5820
    },
    {
      "epoch": 35.120845921450154,
      "grad_norm": 0.2830932140350342,
      "learning_rate": 0.00046584221638904774,
      "loss": 2.2863,
      "step": 5830
    },
    {
      "epoch": 35.181268882175225,
      "grad_norm": 0.28716206550598145,
      "learning_rate": 0.00046572081543973107,
      "loss": 2.293,
      "step": 5840
    },
    {
      "epoch": 35.2416918429003,
      "grad_norm": 0.27085405588150024,
      "learning_rate": 0.0004655992150131075,
      "loss": 2.3039,
      "step": 5850
    },
    {
      "epoch": 35.30211480362538,
      "grad_norm": 0.27068111300468445,
      "learning_rate": 0.0004654774152216211,
      "loss": 2.2937,
      "step": 5860
    },
    {
      "epoch": 35.362537764350456,
      "grad_norm": 0.2488502711057663,
      "learning_rate": 0.0004653554161779002,
      "loss": 2.2874,
      "step": 5870
    },
    {
      "epoch": 35.42296072507553,
      "grad_norm": 0.28159070014953613,
      "learning_rate": 0.0004652332179947577,
      "loss": 2.2922,
      "step": 5880
    },
    {
      "epoch": 35.483383685800604,
      "grad_norm": 0.26917409896850586,
      "learning_rate": 0.0004651108207851902,
      "loss": 2.2819,
      "step": 5890
    },
    {
      "epoch": 35.54380664652568,
      "grad_norm": 0.30978357791900635,
      "learning_rate": 0.00046498822466237865,
      "loss": 2.3049,
      "step": 5900
    },
    {
      "epoch": 35.60422960725076,
      "grad_norm": 0.3035391867160797,
      "learning_rate": 0.0004648654297396878,
      "loss": 2.3088,
      "step": 5910
    },
    {
      "epoch": 35.66465256797583,
      "grad_norm": 0.3013383746147156,
      "learning_rate": 0.0004647424361306663,
      "loss": 2.2922,
      "step": 5920
    },
    {
      "epoch": 35.725075528700906,
      "grad_norm": 0.890862226486206,
      "learning_rate": 0.0004646192439490465,
      "loss": 2.2882,
      "step": 5930
    },
    {
      "epoch": 35.78549848942598,
      "grad_norm": 0.41450831294059753,
      "learning_rate": 0.0004644958533087443,
      "loss": 2.2916,
      "step": 5940
    },
    {
      "epoch": 35.84592145015106,
      "grad_norm": 0.37462490797042847,
      "learning_rate": 0.00046437226432385914,
      "loss": 2.2925,
      "step": 5950
    },
    {
      "epoch": 35.90634441087613,
      "grad_norm": 0.2820715308189392,
      "learning_rate": 0.00046424847710867413,
      "loss": 2.2885,
      "step": 5960
    },
    {
      "epoch": 35.96676737160121,
      "grad_norm": 0.2896045446395874,
      "learning_rate": 0.0004641244917776553,
      "loss": 2.2826,
      "step": 5970
    },
    {
      "epoch": 36.0,
      "eval_loss": 1.1347315311431885,
      "eval_runtime": 4.5914,
      "eval_samples_per_second": 3623.694,
      "eval_steps_per_second": 14.157,
      "step": 5976
    },
    {
      "epoch": 36.02416918429003,
      "grad_norm": 0.2741846740245819,
      "learning_rate": 0.0004640003084454519,
      "loss": 2.176,
      "step": 5980
    },
    {
      "epoch": 36.08459214501511,
      "grad_norm": 0.33667439222335815,
      "learning_rate": 0.0004638759272268967,
      "loss": 2.2915,
      "step": 5990
    },
    {
      "epoch": 36.14501510574018,
      "grad_norm": 0.5927785634994507,
      "learning_rate": 0.000463751348237005,
      "loss": 2.2827,
      "step": 6000
    },
    {
      "epoch": 36.205438066465256,
      "grad_norm": 0.29274308681488037,
      "learning_rate": 0.0004636265715909752,
      "loss": 2.2864,
      "step": 6010
    },
    {
      "epoch": 36.26586102719033,
      "grad_norm": 0.2879970967769623,
      "learning_rate": 0.0004635015974041884,
      "loss": 2.2838,
      "step": 6020
    },
    {
      "epoch": 36.32628398791541,
      "grad_norm": 0.26540407538414,
      "learning_rate": 0.0004633764257922084,
      "loss": 2.2856,
      "step": 6030
    },
    {
      "epoch": 36.38670694864048,
      "grad_norm": 0.24479597806930542,
      "learning_rate": 0.0004632510568707815,
      "loss": 2.2912,
      "step": 6040
    },
    {
      "epoch": 36.44712990936556,
      "grad_norm": 0.22687961161136627,
      "learning_rate": 0.0004631254907558365,
      "loss": 2.2847,
      "step": 6050
    },
    {
      "epoch": 36.507552870090635,
      "grad_norm": 0.30195197463035583,
      "learning_rate": 0.00046299972756348474,
      "loss": 2.2758,
      "step": 6060
    },
    {
      "epoch": 36.56797583081571,
      "grad_norm": 0.2960892617702484,
      "learning_rate": 0.0004628737674100193,
      "loss": 2.296,
      "step": 6070
    },
    {
      "epoch": 36.62839879154078,
      "grad_norm": 0.35046011209487915,
      "learning_rate": 0.0004627476104119159,
      "loss": 2.2877,
      "step": 6080
    },
    {
      "epoch": 36.68882175226586,
      "grad_norm": 0.2284514605998993,
      "learning_rate": 0.00046262125668583196,
      "loss": 2.2848,
      "step": 6090
    },
    {
      "epoch": 36.74924471299094,
      "grad_norm": 0.24542811512947083,
      "learning_rate": 0.00046249470634860697,
      "loss": 2.2873,
      "step": 6100
    },
    {
      "epoch": 36.809667673716014,
      "grad_norm": 0.27495208382606506,
      "learning_rate": 0.0004623679595172622,
      "loss": 2.2978,
      "step": 6110
    },
    {
      "epoch": 36.87009063444109,
      "grad_norm": 0.2763898968696594,
      "learning_rate": 0.00046224101630900054,
      "loss": 2.2823,
      "step": 6120
    },
    {
      "epoch": 36.93051359516616,
      "grad_norm": 0.26573115587234497,
      "learning_rate": 0.00046211387684120663,
      "loss": 2.2961,
      "step": 6130
    },
    {
      "epoch": 36.99093655589124,
      "grad_norm": 0.26119309663772583,
      "learning_rate": 0.00046198654123144644,
      "loss": 2.2873,
      "step": 6140
    },
    {
      "epoch": 37.0,
      "eval_loss": 1.1344265937805176,
      "eval_runtime": 4.5912,
      "eval_samples_per_second": 3623.902,
      "eval_steps_per_second": 14.158,
      "step": 6142
    },
    {
      "epoch": 37.04833836858006,
      "grad_norm": 0.2433774322271347,
      "learning_rate": 0.00046185900959746736,
      "loss": 2.1765,
      "step": 6150
    },
    {
      "epoch": 37.10876132930514,
      "grad_norm": 0.2607598304748535,
      "learning_rate": 0.0004617312820571981,
      "loss": 2.2772,
      "step": 6160
    },
    {
      "epoch": 37.16918429003021,
      "grad_norm": 0.2719901502132416,
      "learning_rate": 0.00046160335872874836,
      "loss": 2.2766,
      "step": 6170
    },
    {
      "epoch": 37.229607250755286,
      "grad_norm": 0.2852170765399933,
      "learning_rate": 0.0004614752397304091,
      "loss": 2.2672,
      "step": 6180
    },
    {
      "epoch": 37.290030211480364,
      "grad_norm": 0.307067334651947,
      "learning_rate": 0.00046134692518065215,
      "loss": 2.2858,
      "step": 6190
    },
    {
      "epoch": 37.35045317220544,
      "grad_norm": 0.2717094421386719,
      "learning_rate": 0.00046121841519813,
      "loss": 2.276,
      "step": 6200
    },
    {
      "epoch": 37.41087613293051,
      "grad_norm": 0.28151506185531616,
      "learning_rate": 0.0004610897099016762,
      "loss": 2.2722,
      "step": 6210
    },
    {
      "epoch": 37.47129909365559,
      "grad_norm": 0.31018760800361633,
      "learning_rate": 0.0004609608094103045,
      "loss": 2.3032,
      "step": 6220
    },
    {
      "epoch": 37.531722054380666,
      "grad_norm": 0.34120550751686096,
      "learning_rate": 0.0004608317138432094,
      "loss": 2.291,
      "step": 6230
    },
    {
      "epoch": 37.59214501510574,
      "grad_norm": 0.39214712381362915,
      "learning_rate": 0.00046070242331976575,
      "loss": 2.2796,
      "step": 6240
    },
    {
      "epoch": 37.65256797583081,
      "grad_norm": 0.27612632513046265,
      "learning_rate": 0.00046057293795952864,
      "loss": 2.2919,
      "step": 6250
    },
    {
      "epoch": 37.71299093655589,
      "grad_norm": 0.2525380849838257,
      "learning_rate": 0.0004604432578822334,
      "loss": 2.2881,
      "step": 6260
    },
    {
      "epoch": 37.77341389728097,
      "grad_norm": 0.2982005476951599,
      "learning_rate": 0.0004603133832077953,
      "loss": 2.2962,
      "step": 6270
    },
    {
      "epoch": 37.833836858006045,
      "grad_norm": 0.23664765059947968,
      "learning_rate": 0.0004601833140563096,
      "loss": 2.2936,
      "step": 6280
    },
    {
      "epoch": 37.894259818731115,
      "grad_norm": 0.32018977403640747,
      "learning_rate": 0.0004600530505480515,
      "loss": 2.2841,
      "step": 6290
    },
    {
      "epoch": 37.95468277945619,
      "grad_norm": 0.30658408999443054,
      "learning_rate": 0.0004599225928034757,
      "loss": 2.2854,
      "step": 6300
    },
    {
      "epoch": 38.0,
      "eval_loss": 1.134041666984558,
      "eval_runtime": 4.5727,
      "eval_samples_per_second": 3638.517,
      "eval_steps_per_second": 14.215,
      "step": 6308
    },
    {
      "epoch": 38.012084592145015,
      "grad_norm": 0.29533132910728455,
      "learning_rate": 0.0004597919409432168,
      "loss": 2.1684,
      "step": 6310
    },
    {
      "epoch": 38.07250755287009,
      "grad_norm": 0.29931601881980896,
      "learning_rate": 0.00045966109508808854,
      "loss": 2.2813,
      "step": 6320
    },
    {
      "epoch": 38.13293051359516,
      "grad_norm": 0.2506587505340576,
      "learning_rate": 0.00045953005535908444,
      "loss": 2.2908,
      "step": 6330
    },
    {
      "epoch": 38.19335347432024,
      "grad_norm": 0.2875766456127167,
      "learning_rate": 0.00045939882187737694,
      "loss": 2.287,
      "step": 6340
    },
    {
      "epoch": 38.25377643504532,
      "grad_norm": 0.2751523554325104,
      "learning_rate": 0.0004592673947643179,
      "loss": 2.2823,
      "step": 6350
    },
    {
      "epoch": 38.314199395770395,
      "grad_norm": 0.2729828357696533,
      "learning_rate": 0.00045913577414143813,
      "loss": 2.2926,
      "step": 6360
    },
    {
      "epoch": 38.374622356495465,
      "grad_norm": 0.26664701104164124,
      "learning_rate": 0.0004590039601304473,
      "loss": 2.2772,
      "step": 6370
    },
    {
      "epoch": 38.43504531722054,
      "grad_norm": 0.3305748403072357,
      "learning_rate": 0.0004588719528532341,
      "loss": 2.2818,
      "step": 6380
    },
    {
      "epoch": 38.49546827794562,
      "grad_norm": 0.28011396527290344,
      "learning_rate": 0.0004587397524318658,
      "loss": 2.286,
      "step": 6390
    },
    {
      "epoch": 38.5558912386707,
      "grad_norm": 0.2606472969055176,
      "learning_rate": 0.00045860735898858824,
      "loss": 2.2875,
      "step": 6400
    },
    {
      "epoch": 38.616314199395774,
      "grad_norm": 0.2876010537147522,
      "learning_rate": 0.00045847477264582585,
      "loss": 2.2957,
      "step": 6410
    },
    {
      "epoch": 38.676737160120844,
      "grad_norm": 0.29725611209869385,
      "learning_rate": 0.0004583419935261813,
      "loss": 2.2747,
      "step": 6420
    },
    {
      "epoch": 38.73716012084592,
      "grad_norm": 0.2450607270002365,
      "learning_rate": 0.00045820902175243574,
      "loss": 2.2856,
      "step": 6430
    },
    {
      "epoch": 38.797583081571,
      "grad_norm": 0.2767128348350525,
      "learning_rate": 0.0004580758574475483,
      "loss": 2.2836,
      "step": 6440
    },
    {
      "epoch": 38.858006042296076,
      "grad_norm": 0.3297182321548462,
      "learning_rate": 0.0004579425007346561,
      "loss": 2.2781,
      "step": 6450
    },
    {
      "epoch": 38.918429003021146,
      "grad_norm": 0.2617732882499695,
      "learning_rate": 0.00045780895173707433,
      "loss": 2.2876,
      "step": 6460
    },
    {
      "epoch": 38.97885196374622,
      "grad_norm": 0.2601505517959595,
      "learning_rate": 0.00045767521057829585,
      "loss": 2.2887,
      "step": 6470
    },
    {
      "epoch": 39.0,
      "eval_loss": 1.133519172668457,
      "eval_runtime": 4.5623,
      "eval_samples_per_second": 3646.837,
      "eval_steps_per_second": 14.247,
      "step": 6474
    },
    {
      "epoch": 39.036253776435046,
      "grad_norm": 0.25225239992141724,
      "learning_rate": 0.00045754127738199135,
      "loss": 2.165,
      "step": 6480
    },
    {
      "epoch": 39.096676737160124,
      "grad_norm": 0.24253864586353302,
      "learning_rate": 0.00045740715227200903,
      "loss": 2.2742,
      "step": 6490
    },
    {
      "epoch": 39.157099697885194,
      "grad_norm": 0.3484880328178406,
      "learning_rate": 0.0004572728353723745,
      "loss": 2.2806,
      "step": 6500
    },
    {
      "epoch": 39.21752265861027,
      "grad_norm": 0.2632622718811035,
      "learning_rate": 0.0004571383268072907,
      "loss": 2.2872,
      "step": 6510
    },
    {
      "epoch": 39.27794561933535,
      "grad_norm": 0.27307018637657166,
      "learning_rate": 0.000457003626701138,
      "loss": 2.2718,
      "step": 6520
    },
    {
      "epoch": 39.338368580060425,
      "grad_norm": 0.24405300617218018,
      "learning_rate": 0.00045686873517847374,
      "loss": 2.2805,
      "step": 6530
    },
    {
      "epoch": 39.398791540785496,
      "grad_norm": 0.2716425955295563,
      "learning_rate": 0.00045673365236403217,
      "loss": 2.282,
      "step": 6540
    },
    {
      "epoch": 39.45921450151057,
      "grad_norm": 0.29428452253341675,
      "learning_rate": 0.0004565983783827247,
      "loss": 2.2729,
      "step": 6550
    },
    {
      "epoch": 39.51963746223565,
      "grad_norm": 0.29654961824417114,
      "learning_rate": 0.00045646291335963915,
      "loss": 2.2852,
      "step": 6560
    },
    {
      "epoch": 39.58006042296073,
      "grad_norm": 0.2795444130897522,
      "learning_rate": 0.00045632725742004033,
      "loss": 2.2818,
      "step": 6570
    },
    {
      "epoch": 39.6404833836858,
      "grad_norm": 0.26588869094848633,
      "learning_rate": 0.00045619141068936944,
      "loss": 2.2889,
      "step": 6580
    },
    {
      "epoch": 39.700906344410875,
      "grad_norm": 0.235829159617424,
      "learning_rate": 0.00045605537329324405,
      "loss": 2.2874,
      "step": 6590
    },
    {
      "epoch": 39.76132930513595,
      "grad_norm": 0.41519612073898315,
      "learning_rate": 0.0004559191453574582,
      "loss": 2.2948,
      "step": 6600
    },
    {
      "epoch": 39.82175226586103,
      "grad_norm": 0.2709008753299713,
      "learning_rate": 0.00045578272700798204,
      "loss": 2.2818,
      "step": 6610
    },
    {
      "epoch": 39.8821752265861,
      "grad_norm": 0.26757538318634033,
      "learning_rate": 0.0004556461183709617,
      "loss": 2.2835,
      "step": 6620
    },
    {
      "epoch": 39.94259818731118,
      "grad_norm": 0.2909437417984009,
      "learning_rate": 0.0004555093195727194,
      "loss": 2.2873,
      "step": 6630
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.2956254780292511,
      "learning_rate": 0.00045537233073975313,
      "loss": 2.1701,
      "step": 6640
    },
    {
      "epoch": 40.0,
      "eval_loss": 1.1323615312576294,
      "eval_runtime": 4.5679,
      "eval_samples_per_second": 3642.346,
      "eval_steps_per_second": 14.23,
      "step": 6640
    },
    {
      "epoch": 40.06042296072508,
      "grad_norm": 0.2761112153530121,
      "learning_rate": 0.0004552351519987368,
      "loss": 2.2769,
      "step": 6650
    },
    {
      "epoch": 40.120845921450154,
      "grad_norm": 0.3148011565208435,
      "learning_rate": 0.0004550977834765195,
      "loss": 2.2767,
      "step": 6660
    },
    {
      "epoch": 40.181268882175225,
      "grad_norm": 0.28363871574401855,
      "learning_rate": 0.0004549602253001263,
      "loss": 2.2812,
      "step": 6670
    },
    {
      "epoch": 40.2416918429003,
      "grad_norm": 0.2643548548221588,
      "learning_rate": 0.0004548224775967572,
      "loss": 2.2748,
      "step": 6680
    },
    {
      "epoch": 40.30211480362538,
      "grad_norm": 0.3951438367366791,
      "learning_rate": 0.00045468454049378787,
      "loss": 2.2829,
      "step": 6690
    },
    {
      "epoch": 40.362537764350456,
      "grad_norm": 0.283255398273468,
      "learning_rate": 0.00045454641411876885,
      "loss": 2.2816,
      "step": 6700
    },
    {
      "epoch": 40.42296072507553,
      "grad_norm": 0.3851885497570038,
      "learning_rate": 0.0004544080985994258,
      "loss": 2.2986,
      "step": 6710
    },
    {
      "epoch": 40.483383685800604,
      "grad_norm": 0.30755576491355896,
      "learning_rate": 0.0004542695940636591,
      "loss": 2.2826,
      "step": 6720
    },
    {
      "epoch": 40.54380664652568,
      "grad_norm": 0.2277647852897644,
      "learning_rate": 0.00045413090063954424,
      "loss": 2.2836,
      "step": 6730
    },
    {
      "epoch": 40.60422960725076,
      "grad_norm": 0.2650274634361267,
      "learning_rate": 0.00045399201845533124,
      "loss": 2.2828,
      "step": 6740
    },
    {
      "epoch": 40.66465256797583,
      "grad_norm": 0.284239262342453,
      "learning_rate": 0.0004538529476394444,
      "loss": 2.2805,
      "step": 6750
    },
    {
      "epoch": 40.725075528700906,
      "grad_norm": 0.236781507730484,
      "learning_rate": 0.00045371368832048287,
      "loss": 2.287,
      "step": 6760
    },
    {
      "epoch": 40.78549848942598,
      "grad_norm": 0.2501099109649658,
      "learning_rate": 0.00045357424062721986,
      "loss": 2.2827,
      "step": 6770
    },
    {
      "epoch": 40.84592145015106,
      "grad_norm": 0.29406148195266724,
      "learning_rate": 0.00045343460468860286,
      "loss": 2.2826,
      "step": 6780
    },
    {
      "epoch": 40.90634441087613,
      "grad_norm": 0.2568528354167938,
      "learning_rate": 0.0004532947806337533,
      "loss": 2.2796,
      "step": 6790
    },
    {
      "epoch": 40.96676737160121,
      "grad_norm": 0.24290066957473755,
      "learning_rate": 0.0004531547685919668,
      "loss": 2.2762,
      "step": 6800
    },
    {
      "epoch": 41.0,
      "eval_loss": 1.1335065364837646,
      "eval_runtime": 4.5623,
      "eval_samples_per_second": 3646.88,
      "eval_steps_per_second": 14.247,
      "step": 6806
    },
    {
      "epoch": 41.02416918429003,
      "grad_norm": 0.30947867035865784,
      "learning_rate": 0.0004530145686927125,
      "loss": 2.1649,
      "step": 6810
    },
    {
      "epoch": 41.08459214501511,
      "grad_norm": 0.3070428967475891,
      "learning_rate": 0.00045287418106563354,
      "loss": 2.2929,
      "step": 6820
    },
    {
      "epoch": 41.14501510574018,
      "grad_norm": 0.42269161343574524,
      "learning_rate": 0.00045273360584054654,
      "loss": 2.2791,
      "step": 6830
    },
    {
      "epoch": 41.205438066465256,
      "grad_norm": 0.26960718631744385,
      "learning_rate": 0.00045259284314744155,
      "loss": 2.2799,
      "step": 6840
    },
    {
      "epoch": 41.26586102719033,
      "grad_norm": 0.363300085067749,
      "learning_rate": 0.00045245189311648196,
      "loss": 2.272,
      "step": 6850
    },
    {
      "epoch": 41.32628398791541,
      "grad_norm": 0.28669288754463196,
      "learning_rate": 0.00045231075587800454,
      "loss": 2.2822,
      "step": 6860
    },
    {
      "epoch": 41.38670694864048,
      "grad_norm": 0.3205525875091553,
      "learning_rate": 0.00045216943156251894,
      "loss": 2.2734,
      "step": 6870
    },
    {
      "epoch": 41.44712990936556,
      "grad_norm": 0.32917729020118713,
      "learning_rate": 0.00045202792030070806,
      "loss": 2.2752,
      "step": 6880
    },
    {
      "epoch": 41.507552870090635,
      "grad_norm": 0.2762279510498047,
      "learning_rate": 0.00045188622222342746,
      "loss": 2.266,
      "step": 6890
    },
    {
      "epoch": 41.56797583081571,
      "grad_norm": 0.32080116868019104,
      "learning_rate": 0.00045174433746170557,
      "loss": 2.2711,
      "step": 6900
    },
    {
      "epoch": 41.62839879154078,
      "grad_norm": 0.2553248703479767,
      "learning_rate": 0.0004516022661467434,
      "loss": 2.2763,
      "step": 6910
    },
    {
      "epoch": 41.68882175226586,
      "grad_norm": 0.4368951916694641,
      "learning_rate": 0.00045146000840991447,
      "loss": 2.2877,
      "step": 6920
    },
    {
      "epoch": 41.74924471299094,
      "grad_norm": 0.2941499352455139,
      "learning_rate": 0.00045131756438276466,
      "loss": 2.2774,
      "step": 6930
    },
    {
      "epoch": 41.809667673716014,
      "grad_norm": 0.2662751376628876,
      "learning_rate": 0.00045117493419701216,
      "loss": 2.2933,
      "step": 6940
    },
    {
      "epoch": 41.87009063444109,
      "grad_norm": 0.2756083309650421,
      "learning_rate": 0.00045103211798454734,
      "loss": 2.2855,
      "step": 6950
    },
    {
      "epoch": 41.93051359516616,
      "grad_norm": 0.3199111819267273,
      "learning_rate": 0.00045088911587743243,
      "loss": 2.2778,
      "step": 6960
    },
    {
      "epoch": 41.99093655589124,
      "grad_norm": 0.3260875642299652,
      "learning_rate": 0.0004507459280079017,
      "loss": 2.2884,
      "step": 6970
    },
    {
      "epoch": 42.0,
      "eval_loss": 1.1327213048934937,
      "eval_runtime": 4.5949,
      "eval_samples_per_second": 3621.006,
      "eval_steps_per_second": 14.146,
      "step": 6972
    },
    {
      "epoch": 42.04833836858006,
      "grad_norm": 0.3875383138656616,
      "learning_rate": 0.0004506025545083611,
      "loss": 2.164,
      "step": 6980
    },
    {
      "epoch": 42.10876132930514,
      "grad_norm": 0.3182578682899475,
      "learning_rate": 0.0004504589955113884,
      "loss": 2.2772,
      "step": 6990
    },
    {
      "epoch": 42.16918429003021,
      "grad_norm": 0.28688353300094604,
      "learning_rate": 0.0004503152511497327,
      "loss": 2.2775,
      "step": 7000
    },
    {
      "epoch": 42.229607250755286,
      "grad_norm": 0.2793062925338745,
      "learning_rate": 0.0004501713215563146,
      "loss": 2.2778,
      "step": 7010
    },
    {
      "epoch": 42.290030211480364,
      "grad_norm": 0.31000155210494995,
      "learning_rate": 0.0004500272068642259,
      "loss": 2.2755,
      "step": 7020
    },
    {
      "epoch": 42.35045317220544,
      "grad_norm": 0.30346959829330444,
      "learning_rate": 0.00044988290720672985,
      "loss": 2.2797,
      "step": 7030
    },
    {
      "epoch": 42.41087613293051,
      "grad_norm": 0.33640170097351074,
      "learning_rate": 0.00044973842271726027,
      "loss": 2.2781,
      "step": 7040
    },
    {
      "epoch": 42.47129909365559,
      "grad_norm": 0.29169777035713196,
      "learning_rate": 0.0004495937535294224,
      "loss": 2.2902,
      "step": 7050
    },
    {
      "epoch": 42.531722054380666,
      "grad_norm": 0.30155321955680847,
      "learning_rate": 0.0004494488997769918,
      "loss": 2.2847,
      "step": 7060
    },
    {
      "epoch": 42.59214501510574,
      "grad_norm": 0.3335607945919037,
      "learning_rate": 0.000449303861593915,
      "loss": 2.2788,
      "step": 7070
    },
    {
      "epoch": 42.65256797583081,
      "grad_norm": 0.5240815281867981,
      "learning_rate": 0.000449158639114309,
      "loss": 2.2829,
      "step": 7080
    },
    {
      "epoch": 42.71299093655589,
      "grad_norm": 0.4392775595188141,
      "learning_rate": 0.0004490132324724612,
      "loss": 2.2692,
      "step": 7090
    },
    {
      "epoch": 42.77341389728097,
      "grad_norm": 0.29826486110687256,
      "learning_rate": 0.00044886764180282934,
      "loss": 2.2641,
      "step": 7100
    },
    {
      "epoch": 42.833836858006045,
      "grad_norm": 0.3236965239048004,
      "learning_rate": 0.0004487218672400412,
      "loss": 2.2817,
      "step": 7110
    },
    {
      "epoch": 42.894259818731115,
      "grad_norm": 0.3104695975780487,
      "learning_rate": 0.0004485759089188948,
      "loss": 2.2835,
      "step": 7120
    },
    {
      "epoch": 42.95468277945619,
      "grad_norm": 0.3161834478378296,
      "learning_rate": 0.0004484297669743579,
      "loss": 2.2904,
      "step": 7130
    },
    {
      "epoch": 43.0,
      "eval_loss": 1.1319128274917603,
      "eval_runtime": 4.5761,
      "eval_samples_per_second": 3635.839,
      "eval_steps_per_second": 14.204,
      "step": 7138
    },
    {
      "epoch": 43.012084592145015,
      "grad_norm": 0.32786720991134644,
      "learning_rate": 0.0004482834415415682,
      "loss": 2.1768,
      "step": 7140
    },
    {
      "epoch": 43.07250755287009,
      "grad_norm": 0.2529231905937195,
      "learning_rate": 0.0004481369327558329,
      "loss": 2.2779,
      "step": 7150
    },
    {
      "epoch": 43.13293051359516,
      "grad_norm": 0.27907174825668335,
      "learning_rate": 0.00044799024075262904,
      "loss": 2.2678,
      "step": 7160
    },
    {
      "epoch": 43.19335347432024,
      "grad_norm": 0.3040231764316559,
      "learning_rate": 0.00044784336566760277,
      "loss": 2.2802,
      "step": 7170
    },
    {
      "epoch": 43.25377643504532,
      "grad_norm": 0.30006319284439087,
      "learning_rate": 0.0004476963076365697,
      "loss": 2.2776,
      "step": 7180
    },
    {
      "epoch": 43.314199395770395,
      "grad_norm": 0.28081557154655457,
      "learning_rate": 0.00044754906679551453,
      "loss": 2.2779,
      "step": 7190
    },
    {
      "epoch": 43.374622356495465,
      "grad_norm": 0.2766284644603729,
      "learning_rate": 0.00044740164328059106,
      "loss": 2.273,
      "step": 7200
    },
    {
      "epoch": 43.43504531722054,
      "grad_norm": 0.2986636757850647,
      "learning_rate": 0.00044725403722812207,
      "loss": 2.2777,
      "step": 7210
    },
    {
      "epoch": 43.49546827794562,
      "grad_norm": 0.28973817825317383,
      "learning_rate": 0.000447106248774599,
      "loss": 2.2769,
      "step": 7220
    },
    {
      "epoch": 43.5558912386707,
      "grad_norm": 0.27396219968795776,
      "learning_rate": 0.0004469582780566821,
      "loss": 2.272,
      "step": 7230
    },
    {
      "epoch": 43.616314199395774,
      "grad_norm": 0.2886064648628235,
      "learning_rate": 0.0004468101252112,
      "loss": 2.2829,
      "step": 7240
    },
    {
      "epoch": 43.676737160120844,
      "grad_norm": 0.28465259075164795,
      "learning_rate": 0.00044666179037514977,
      "loss": 2.2797,
      "step": 7250
    },
    {
      "epoch": 43.73716012084592,
      "grad_norm": 0.29544517397880554,
      "learning_rate": 0.0004465132736856969,
      "loss": 2.2765,
      "step": 7260
    },
    {
      "epoch": 43.797583081571,
      "grad_norm": 0.7118789553642273,
      "learning_rate": 0.00044636457528017493,
      "loss": 2.2819,
      "step": 7270
    },
    {
      "epoch": 43.858006042296076,
      "grad_norm": 0.2735288441181183,
      "learning_rate": 0.0004462156952960855,
      "loss": 2.2825,
      "step": 7280
    },
    {
      "epoch": 43.918429003021146,
      "grad_norm": 0.6733781099319458,
      "learning_rate": 0.00044606663387109803,
      "loss": 2.287,
      "step": 7290
    },
    {
      "epoch": 43.97885196374622,
      "grad_norm": 0.2995814085006714,
      "learning_rate": 0.00044591739114304985,
      "loss": 2.2827,
      "step": 7300
    },
    {
      "epoch": 44.0,
      "eval_loss": 1.1326777935028076,
      "eval_runtime": 4.5725,
      "eval_samples_per_second": 3638.739,
      "eval_steps_per_second": 14.216,
      "step": 7304
    },
    {
      "epoch": 44.036253776435046,
      "grad_norm": 0.30189061164855957,
      "learning_rate": 0.00044576796724994595,
      "loss": 2.1642,
      "step": 7310
    },
    {
      "epoch": 44.096676737160124,
      "grad_norm": 0.3045683205127716,
      "learning_rate": 0.00044561836232995874,
      "loss": 2.2826,
      "step": 7320
    },
    {
      "epoch": 44.157099697885194,
      "grad_norm": 0.3129791021347046,
      "learning_rate": 0.000445468576521428,
      "loss": 2.2757,
      "step": 7330
    },
    {
      "epoch": 44.21752265861027,
      "grad_norm": 0.3284776210784912,
      "learning_rate": 0.0004453186099628611,
      "loss": 2.2678,
      "step": 7340
    },
    {
      "epoch": 44.27794561933535,
      "grad_norm": 0.3196171224117279,
      "learning_rate": 0.000445168462792932,
      "loss": 2.2746,
      "step": 7350
    },
    {
      "epoch": 44.338368580060425,
      "grad_norm": 0.27915382385253906,
      "learning_rate": 0.00044501813515048216,
      "loss": 2.2768,
      "step": 7360
    },
    {
      "epoch": 44.398791540785496,
      "grad_norm": 0.3196978271007538,
      "learning_rate": 0.0004448676271745197,
      "loss": 2.2786,
      "step": 7370
    },
    {
      "epoch": 44.45921450151057,
      "grad_norm": 0.29772043228149414,
      "learning_rate": 0.00044471693900421954,
      "loss": 2.2706,
      "step": 7380
    },
    {
      "epoch": 44.51963746223565,
      "grad_norm": 0.37051454186439514,
      "learning_rate": 0.00044456607077892317,
      "loss": 2.2743,
      "step": 7390
    },
    {
      "epoch": 44.58006042296073,
      "grad_norm": 0.2933253347873688,
      "learning_rate": 0.0004444150226381387,
      "loss": 2.2707,
      "step": 7400
    },
    {
      "epoch": 44.6404833836858,
      "grad_norm": 0.3056092858314514,
      "learning_rate": 0.0004442637947215405,
      "loss": 2.2785,
      "step": 7410
    },
    {
      "epoch": 44.700906344410875,
      "grad_norm": 0.3182307183742523,
      "learning_rate": 0.00044411238716896917,
      "loss": 2.2797,
      "step": 7420
    },
    {
      "epoch": 44.76132930513595,
      "grad_norm": 0.32491710782051086,
      "learning_rate": 0.00044396080012043147,
      "loss": 2.2764,
      "step": 7430
    },
    {
      "epoch": 44.82175226586103,
      "grad_norm": 0.35658589005470276,
      "learning_rate": 0.00044380903371610026,
      "loss": 2.2695,
      "step": 7440
    },
    {
      "epoch": 44.8821752265861,
      "grad_norm": 0.27150750160217285,
      "learning_rate": 0.00044365708809631396,
      "loss": 2.2751,
      "step": 7450
    },
    {
      "epoch": 44.94259818731118,
      "grad_norm": 0.2922610640525818,
      "learning_rate": 0.000443504963401577,
      "loss": 2.2782,
      "step": 7460
    },
    {
      "epoch": 45.0,
      "grad_norm": 0.38351690769195557,
      "learning_rate": 0.0004433526597725591,
      "loss": 2.1699,
      "step": 7470
    },
    {
      "epoch": 45.0,
      "eval_loss": 1.1315006017684937,
      "eval_runtime": 4.5628,
      "eval_samples_per_second": 3646.441,
      "eval_steps_per_second": 14.246,
      "step": 7470
    },
    {
      "epoch": 45.06042296072508,
      "grad_norm": 0.2717323899269104,
      "learning_rate": 0.00044320017735009575,
      "loss": 2.2646,
      "step": 7480
    },
    {
      "epoch": 45.120845921450154,
      "grad_norm": 0.302288681268692,
      "learning_rate": 0.0004430475162751877,
      "loss": 2.2784,
      "step": 7490
    },
    {
      "epoch": 45.181268882175225,
      "grad_norm": 0.36847442388534546,
      "learning_rate": 0.0004428946766890007,
      "loss": 2.2673,
      "step": 7500
    },
    {
      "epoch": 45.2416918429003,
      "grad_norm": 0.2878357172012329,
      "learning_rate": 0.0004427416587328658,
      "loss": 2.2589,
      "step": 7510
    },
    {
      "epoch": 45.30211480362538,
      "grad_norm": 0.4310837388038635,
      "learning_rate": 0.0004425884625482788,
      "loss": 2.2709,
      "step": 7520
    },
    {
      "epoch": 45.362537764350456,
      "grad_norm": 0.28067028522491455,
      "learning_rate": 0.00044243508827690047,
      "loss": 2.2787,
      "step": 7530
    },
    {
      "epoch": 45.42296072507553,
      "grad_norm": 0.32099542021751404,
      "learning_rate": 0.00044228153606055623,
      "loss": 2.2865,
      "step": 7540
    },
    {
      "epoch": 45.483383685800604,
      "grad_norm": 0.31261780858039856,
      "learning_rate": 0.00044212780604123593,
      "loss": 2.2811,
      "step": 7550
    },
    {
      "epoch": 45.54380664652568,
      "grad_norm": 0.36348584294319153,
      "learning_rate": 0.0004419738983610939,
      "loss": 2.2765,
      "step": 7560
    },
    {
      "epoch": 45.60422960725076,
      "grad_norm": 0.2736143171787262,
      "learning_rate": 0.0004418198131624488,
      "loss": 2.2684,
      "step": 7570
    },
    {
      "epoch": 45.66465256797583,
      "grad_norm": 0.3180187940597534,
      "learning_rate": 0.0004416655505877834,
      "loss": 2.2761,
      "step": 7580
    },
    {
      "epoch": 45.725075528700906,
      "grad_norm": 0.2991603910923004,
      "learning_rate": 0.0004415111107797445,
      "loss": 2.2722,
      "step": 7590
    },
    {
      "epoch": 45.78549848942598,
      "grad_norm": 0.2646641731262207,
      "learning_rate": 0.0004413564938811428,
      "loss": 2.2788,
      "step": 7600
    },
    {
      "epoch": 45.84592145015106,
      "grad_norm": 0.25825563073158264,
      "learning_rate": 0.00044120170003495275,
      "loss": 2.286,
      "step": 7610
    },
    {
      "epoch": 45.90634441087613,
      "grad_norm": 0.33630403876304626,
      "learning_rate": 0.0004410467293843123,
      "loss": 2.2698,
      "step": 7620
    },
    {
      "epoch": 45.96676737160121,
      "grad_norm": 0.25254008173942566,
      "learning_rate": 0.0004408915820725231,
      "loss": 2.2701,
      "step": 7630
    },
    {
      "epoch": 46.0,
      "eval_loss": 1.132063865661621,
      "eval_runtime": 4.5995,
      "eval_samples_per_second": 3617.328,
      "eval_steps_per_second": 14.132,
      "step": 7636
    },
    {
      "epoch": 46.02416918429003,
      "grad_norm": 0.2799074053764343,
      "learning_rate": 0.0004407362582430501,
      "loss": 2.1494,
      "step": 7640
    },
    {
      "epoch": 46.08459214501511,
      "grad_norm": 0.2430981993675232,
      "learning_rate": 0.00044058075803952133,
      "loss": 2.2656,
      "step": 7650
    },
    {
      "epoch": 46.14501510574018,
      "grad_norm": 0.2564425766468048,
      "learning_rate": 0.00044042508160572813,
      "loss": 2.2702,
      "step": 7660
    },
    {
      "epoch": 46.205438066465256,
      "grad_norm": 0.2865484058856964,
      "learning_rate": 0.0004402692290856246,
      "loss": 2.2764,
      "step": 7670
    },
    {
      "epoch": 46.26586102719033,
      "grad_norm": 0.26338326930999756,
      "learning_rate": 0.0004401132006233278,
      "loss": 2.2634,
      "step": 7680
    },
    {
      "epoch": 46.32628398791541,
      "grad_norm": 0.358216792345047,
      "learning_rate": 0.0004399569963631175,
      "loss": 2.2743,
      "step": 7690
    },
    {
      "epoch": 46.38670694864048,
      "grad_norm": 0.2849401533603668,
      "learning_rate": 0.00043980061644943583,
      "loss": 2.2667,
      "step": 7700
    },
    {
      "epoch": 46.44712990936556,
      "grad_norm": 0.2860735058784485,
      "learning_rate": 0.0004396440610268876,
      "loss": 2.2716,
      "step": 7710
    },
    {
      "epoch": 46.507552870090635,
      "grad_norm": 0.30090174078941345,
      "learning_rate": 0.0004394873302402398,
      "loss": 2.2734,
      "step": 7720
    },
    {
      "epoch": 46.56797583081571,
      "grad_norm": 0.306329607963562,
      "learning_rate": 0.0004393304242344216,
      "loss": 2.2712,
      "step": 7730
    },
    {
      "epoch": 46.62839879154078,
      "grad_norm": 0.2943403124809265,
      "learning_rate": 0.00043917334315452406,
      "loss": 2.2851,
      "step": 7740
    },
    {
      "epoch": 46.68882175226586,
      "grad_norm": 0.32917696237564087,
      "learning_rate": 0.0004390160871458004,
      "loss": 2.2779,
      "step": 7750
    },
    {
      "epoch": 46.74924471299094,
      "grad_norm": 0.29998016357421875,
      "learning_rate": 0.0004388586563536654,
      "loss": 2.2688,
      "step": 7760
    },
    {
      "epoch": 46.809667673716014,
      "grad_norm": 0.29033392667770386,
      "learning_rate": 0.0004387010509236955,
      "loss": 2.2625,
      "step": 7770
    },
    {
      "epoch": 46.87009063444109,
      "grad_norm": 0.28472596406936646,
      "learning_rate": 0.00043854327100162853,
      "loss": 2.2773,
      "step": 7780
    },
    {
      "epoch": 46.93051359516616,
      "grad_norm": 0.26064926385879517,
      "learning_rate": 0.00043838531673336394,
      "loss": 2.2695,
      "step": 7790
    },
    {
      "epoch": 46.99093655589124,
      "grad_norm": 0.2514815628528595,
      "learning_rate": 0.00043822718826496223,
      "loss": 2.2722,
      "step": 7800
    },
    {
      "epoch": 47.0,
      "eval_loss": 1.1336500644683838,
      "eval_runtime": 4.5912,
      "eval_samples_per_second": 3623.852,
      "eval_steps_per_second": 14.157,
      "step": 7802
    },
    {
      "epoch": 47.04833836858006,
      "grad_norm": 0.2686082124710083,
      "learning_rate": 0.00043806888574264493,
      "loss": 2.1389,
      "step": 7810
    },
    {
      "epoch": 47.10876132930514,
      "grad_norm": 0.19750423729419708,
      "learning_rate": 0.0004379104093127945,
      "loss": 2.2527,
      "step": 7820
    },
    {
      "epoch": 47.16918429003021,
      "grad_norm": 0.22459737956523895,
      "learning_rate": 0.00043775175912195443,
      "loss": 2.2586,
      "step": 7830
    },
    {
      "epoch": 47.229607250755286,
      "grad_norm": 0.32358014583587646,
      "learning_rate": 0.00043759293531682876,
      "loss": 2.2704,
      "step": 7840
    },
    {
      "epoch": 47.290030211480364,
      "grad_norm": 0.2997036576271057,
      "learning_rate": 0.00043743393804428194,
      "loss": 2.2739,
      "step": 7850
    },
    {
      "epoch": 47.35045317220544,
      "grad_norm": 0.24243475496768951,
      "learning_rate": 0.00043727476745133905,
      "loss": 2.2718,
      "step": 7860
    },
    {
      "epoch": 47.41087613293051,
      "grad_norm": 0.26158982515335083,
      "learning_rate": 0.00043711542368518526,
      "loss": 2.2713,
      "step": 7870
    },
    {
      "epoch": 47.47129909365559,
      "grad_norm": 0.30471912026405334,
      "learning_rate": 0.000436955906893166,
      "loss": 2.2655,
      "step": 7880
    },
    {
      "epoch": 47.531722054380666,
      "grad_norm": 0.3238392472267151,
      "learning_rate": 0.0004367962172227866,
      "loss": 2.2571,
      "step": 7890
    },
    {
      "epoch": 47.59214501510574,
      "grad_norm": 0.36281993985176086,
      "learning_rate": 0.0004366363548217124,
      "loss": 2.2834,
      "step": 7900
    },
    {
      "epoch": 47.65256797583081,
      "grad_norm": 0.25885283946990967,
      "learning_rate": 0.00043647631983776824,
      "loss": 2.2834,
      "step": 7910
    },
    {
      "epoch": 47.71299093655589,
      "grad_norm": 0.2575816810131073,
      "learning_rate": 0.0004363161124189387,
      "loss": 2.2806,
      "step": 7920
    },
    {
      "epoch": 47.77341389728097,
      "grad_norm": 0.27019202709198,
      "learning_rate": 0.0004361557327133678,
      "loss": 2.2632,
      "step": 7930
    },
    {
      "epoch": 47.833836858006045,
      "grad_norm": 0.26527953147888184,
      "learning_rate": 0.0004359951808693589,
      "loss": 2.2786,
      "step": 7940
    },
    {
      "epoch": 47.894259818731115,
      "grad_norm": 0.2947092652320862,
      "learning_rate": 0.0004358344570353744,
      "loss": 2.2776,
      "step": 7950
    },
    {
      "epoch": 47.95468277945619,
      "grad_norm": 0.2907976508140564,
      "learning_rate": 0.0004356735613600359,
      "loss": 2.2702,
      "step": 7960
    },
    {
      "epoch": 48.0,
      "eval_loss": 1.1328004598617554,
      "eval_runtime": 4.5546,
      "eval_samples_per_second": 3653.016,
      "eval_steps_per_second": 14.271,
      "step": 7968
    },
    {
      "epoch": 48.012084592145015,
      "grad_norm": 0.3021172881126404,
      "learning_rate": 0.0004355124939921238,
      "loss": 2.151,
      "step": 7970
    },
    {
      "epoch": 48.07250755287009,
      "grad_norm": 0.31146854162216187,
      "learning_rate": 0.00043535125508057727,
      "loss": 2.2525,
      "step": 7980
    },
    {
      "epoch": 48.13293051359516,
      "grad_norm": 0.2941121757030487,
      "learning_rate": 0.0004351898447744941,
      "loss": 2.2725,
      "step": 7990
    },
    {
      "epoch": 48.19335347432024,
      "grad_norm": 0.2941879332065582,
      "learning_rate": 0.0004350282632231308,
      "loss": 2.2711,
      "step": 8000
    },
    {
      "epoch": 48.25377643504532,
      "grad_norm": 0.3990216553211212,
      "learning_rate": 0.0004348665105759019,
      "loss": 2.2697,
      "step": 8010
    },
    {
      "epoch": 48.314199395770395,
      "grad_norm": 0.25576186180114746,
      "learning_rate": 0.00043470458698238013,
      "loss": 2.2528,
      "step": 8020
    },
    {
      "epoch": 48.374622356495465,
      "grad_norm": 0.2986390292644501,
      "learning_rate": 0.00043454249259229665,
      "loss": 2.2695,
      "step": 8030
    },
    {
      "epoch": 48.43504531722054,
      "grad_norm": 0.2719367742538452,
      "learning_rate": 0.0004343802275555403,
      "loss": 2.2678,
      "step": 8040
    },
    {
      "epoch": 48.49546827794562,
      "grad_norm": 0.32346364855766296,
      "learning_rate": 0.00043421779202215774,
      "loss": 2.2734,
      "step": 8050
    },
    {
      "epoch": 48.5558912386707,
      "grad_norm": 0.28404471278190613,
      "learning_rate": 0.00043405518614235324,
      "loss": 2.2772,
      "step": 8060
    },
    {
      "epoch": 48.616314199395774,
      "grad_norm": 0.38413068652153015,
      "learning_rate": 0.0004338924100664887,
      "loss": 2.26,
      "step": 8070
    },
    {
      "epoch": 48.676737160120844,
      "grad_norm": 0.2510152757167816,
      "learning_rate": 0.0004337294639450835,
      "loss": 2.27,
      "step": 8080
    },
    {
      "epoch": 48.73716012084592,
      "grad_norm": 0.28108566999435425,
      "learning_rate": 0.00043356634792881394,
      "loss": 2.2688,
      "step": 8090
    },
    {
      "epoch": 48.797583081571,
      "grad_norm": 0.2996242344379425,
      "learning_rate": 0.0004334030621685137,
      "loss": 2.2769,
      "step": 8100
    },
    {
      "epoch": 48.858006042296076,
      "grad_norm": 0.27819371223449707,
      "learning_rate": 0.0004332396068151733,
      "loss": 2.2671,
      "step": 8110
    },
    {
      "epoch": 48.918429003021146,
      "grad_norm": 0.27757495641708374,
      "learning_rate": 0.00043307598201994,
      "loss": 2.2845,
      "step": 8120
    },
    {
      "epoch": 48.97885196374622,
      "grad_norm": 0.2841085195541382,
      "learning_rate": 0.000432912187934118,
      "loss": 2.2771,
      "step": 8130
    },
    {
      "epoch": 49.0,
      "eval_loss": 1.1319823265075684,
      "eval_runtime": 4.5417,
      "eval_samples_per_second": 3663.388,
      "eval_steps_per_second": 14.312,
      "step": 8134
    },
    {
      "epoch": 49.036253776435046,
      "grad_norm": 0.33477747440338135,
      "learning_rate": 0.00043274822470916794,
      "loss": 2.1542,
      "step": 8140
    },
    {
      "epoch": 49.096676737160124,
      "grad_norm": 0.2827872037887573,
      "learning_rate": 0.00043258409249670665,
      "loss": 2.2657,
      "step": 8150
    },
    {
      "epoch": 49.157099697885194,
      "grad_norm": 0.3108938932418823,
      "learning_rate": 0.0004324197914485075,
      "loss": 2.2595,
      "step": 8160
    },
    {
      "epoch": 49.21752265861027,
      "grad_norm": 0.2899276912212372,
      "learning_rate": 0.00043225532171649984,
      "loss": 2.2727,
      "step": 8170
    },
    {
      "epoch": 49.27794561933535,
      "grad_norm": 0.31021666526794434,
      "learning_rate": 0.00043209068345276903,
      "loss": 2.2819,
      "step": 8180
    },
    {
      "epoch": 49.338368580060425,
      "grad_norm": 0.31253522634506226,
      "learning_rate": 0.0004319258768095563,
      "loss": 2.2687,
      "step": 8190
    },
    {
      "epoch": 49.398791540785496,
      "grad_norm": 0.2550555467605591,
      "learning_rate": 0.0004317609019392585,
      "loss": 2.2625,
      "step": 8200
    },
    {
      "epoch": 49.45921450151057,
      "grad_norm": 0.32194483280181885,
      "learning_rate": 0.0004315957589944283,
      "loss": 2.256,
      "step": 8210
    },
    {
      "epoch": 49.51963746223565,
      "grad_norm": 0.3067846894264221,
      "learning_rate": 0.00043143044812777334,
      "loss": 2.268,
      "step": 8220
    },
    {
      "epoch": 49.58006042296073,
      "grad_norm": 0.29102736711502075,
      "learning_rate": 0.0004312649694921568,
      "loss": 2.2704,
      "step": 8230
    },
    {
      "epoch": 49.6404833836858,
      "grad_norm": 0.2964872121810913,
      "learning_rate": 0.00043109932324059716,
      "loss": 2.2635,
      "step": 8240
    },
    {
      "epoch": 49.700906344410875,
      "grad_norm": 0.29656627774238586,
      "learning_rate": 0.0004309335095262675,
      "loss": 2.2822,
      "step": 8250
    },
    {
      "epoch": 49.76132930513595,
      "grad_norm": 0.2938641607761383,
      "learning_rate": 0.00043076752850249625,
      "loss": 2.2693,
      "step": 8260
    },
    {
      "epoch": 49.82175226586103,
      "grad_norm": 0.277123361825943,
      "learning_rate": 0.000430601380322766,
      "loss": 2.2736,
      "step": 8270
    },
    {
      "epoch": 49.8821752265861,
      "grad_norm": 0.31064414978027344,
      "learning_rate": 0.0004304350651407143,
      "loss": 2.2631,
      "step": 8280
    },
    {
      "epoch": 49.94259818731118,
      "grad_norm": 0.2669154703617096,
      "learning_rate": 0.00043026858311013297,
      "loss": 2.2679,
      "step": 8290
    },
    {
      "epoch": 50.0,
      "grad_norm": 0.3384426534175873,
      "learning_rate": 0.0004301019343849681,
      "loss": 2.1552,
      "step": 8300
    },
    {
      "epoch": 50.0,
      "eval_loss": 1.131737470626831,
      "eval_runtime": 4.619,
      "eval_samples_per_second": 3602.1,
      "eval_steps_per_second": 14.072,
      "step": 8300
    },
    {
      "epoch": 50.06042296072508,
      "grad_norm": 0.33041465282440186,
      "learning_rate": 0.00042993511911932014,
      "loss": 2.2686,
      "step": 8310
    },
    {
      "epoch": 50.120845921450154,
      "grad_norm": 0.36633461713790894,
      "learning_rate": 0.00042976813746744327,
      "loss": 2.2634,
      "step": 8320
    },
    {
      "epoch": 50.181268882175225,
      "grad_norm": 0.2908966541290283,
      "learning_rate": 0.0004296009895837456,
      "loss": 2.2656,
      "step": 8330
    },
    {
      "epoch": 50.2416918429003,
      "grad_norm": 0.27458056807518005,
      "learning_rate": 0.000429433675622789,
      "loss": 2.276,
      "step": 8340
    },
    {
      "epoch": 50.30211480362538,
      "grad_norm": 0.2992715835571289,
      "learning_rate": 0.000429266195739289,
      "loss": 2.2571,
      "step": 8350
    },
    {
      "epoch": 50.362537764350456,
      "grad_norm": 0.32552531361579895,
      "learning_rate": 0.0004290985500881143,
      "loss": 2.2716,
      "step": 8360
    },
    {
      "epoch": 50.42296072507553,
      "grad_norm": 0.3205004334449768,
      "learning_rate": 0.0004289307388242872,
      "loss": 2.2589,
      "step": 8370
    },
    {
      "epoch": 50.483383685800604,
      "grad_norm": 0.3492544889450073,
      "learning_rate": 0.00042876276210298284,
      "loss": 2.272,
      "step": 8380
    },
    {
      "epoch": 50.54380664652568,
      "grad_norm": 0.3916199803352356,
      "learning_rate": 0.0004285946200795295,
      "loss": 2.2721,
      "step": 8390
    },
    {
      "epoch": 50.60422960725076,
      "grad_norm": 0.3236001431941986,
      "learning_rate": 0.0004284263129094086,
      "loss": 2.2603,
      "step": 8400
    },
    {
      "epoch": 50.66465256797583,
      "grad_norm": 0.26818370819091797,
      "learning_rate": 0.00042825784074825365,
      "loss": 2.2691,
      "step": 8410
    },
    {
      "epoch": 50.725075528700906,
      "grad_norm": 0.24633923172950745,
      "learning_rate": 0.00042808920375185115,
      "loss": 2.2688,
      "step": 8420
    },
    {
      "epoch": 50.78549848942598,
      "grad_norm": 0.30967938899993896,
      "learning_rate": 0.00042792040207614005,
      "loss": 2.2713,
      "step": 8430
    },
    {
      "epoch": 50.84592145015106,
      "grad_norm": 0.27521637082099915,
      "learning_rate": 0.00042775143587721136,
      "loss": 2.2578,
      "step": 8440
    },
    {
      "epoch": 50.90634441087613,
      "grad_norm": 0.24334770441055298,
      "learning_rate": 0.0004275823053113085,
      "loss": 2.269,
      "step": 8450
    },
    {
      "epoch": 50.96676737160121,
      "grad_norm": 0.29438668489456177,
      "learning_rate": 0.0004274130105348265,
      "loss": 2.2709,
      "step": 8460
    },
    {
      "epoch": 51.0,
      "eval_loss": 1.1319724321365356,
      "eval_runtime": 4.5776,
      "eval_samples_per_second": 3634.63,
      "eval_steps_per_second": 14.199,
      "step": 8466
    },
    {
      "epoch": 51.02416918429003,
      "grad_norm": 0.29582345485687256,
      "learning_rate": 0.0004272435517043125,
      "loss": 2.1477,
      "step": 8470
    },
    {
      "epoch": 51.08459214501511,
      "grad_norm": 0.3175053596496582,
      "learning_rate": 0.0004270739289764654,
      "loss": 2.2598,
      "step": 8480
    },
    {
      "epoch": 51.14501510574018,
      "grad_norm": 0.31884506344795227,
      "learning_rate": 0.0004269041425081355,
      "loss": 2.2662,
      "step": 8490
    },
    {
      "epoch": 51.205438066465256,
      "grad_norm": 0.2999098300933838,
      "learning_rate": 0.0004267341924563245,
      "loss": 2.2635,
      "step": 8500
    },
    {
      "epoch": 51.26586102719033,
      "grad_norm": 0.37081587314605713,
      "learning_rate": 0.0004265640789781855,
      "loss": 2.2558,
      "step": 8510
    },
    {
      "epoch": 51.32628398791541,
      "grad_norm": 0.3570007383823395,
      "learning_rate": 0.00042639380223102267,
      "loss": 2.2676,
      "step": 8520
    },
    {
      "epoch": 51.38670694864048,
      "grad_norm": 0.29889294505119324,
      "learning_rate": 0.00042622336237229096,
      "loss": 2.2638,
      "step": 8530
    },
    {
      "epoch": 51.44712990936556,
      "grad_norm": 0.33989185094833374,
      "learning_rate": 0.0004260527595595965,
      "loss": 2.2648,
      "step": 8540
    },
    {
      "epoch": 51.507552870090635,
      "grad_norm": 0.29968130588531494,
      "learning_rate": 0.0004258819939506958,
      "loss": 2.2635,
      "step": 8550
    },
    {
      "epoch": 51.56797583081571,
      "grad_norm": 0.28697362542152405,
      "learning_rate": 0.00042571106570349614,
      "loss": 2.2726,
      "step": 8560
    },
    {
      "epoch": 51.62839879154078,
      "grad_norm": 0.3588831424713135,
      "learning_rate": 0.00042553997497605514,
      "loss": 2.2617,
      "step": 8570
    },
    {
      "epoch": 51.68882175226586,
      "grad_norm": 0.28164225816726685,
      "learning_rate": 0.00042536872192658034,
      "loss": 2.2741,
      "step": 8580
    },
    {
      "epoch": 51.74924471299094,
      "grad_norm": 0.29427042603492737,
      "learning_rate": 0.0004251973067134298,
      "loss": 2.2676,
      "step": 8590
    },
    {
      "epoch": 51.809667673716014,
      "grad_norm": 0.2857429087162018,
      "learning_rate": 0.00042502572949511155,
      "loss": 2.2841,
      "step": 8600
    },
    {
      "epoch": 51.87009063444109,
      "grad_norm": 0.28527718782424927,
      "learning_rate": 0.0004248539904302829,
      "loss": 2.2717,
      "step": 8610
    },
    {
      "epoch": 51.93051359516616,
      "grad_norm": 0.2859661877155304,
      "learning_rate": 0.00042468208967775156,
      "loss": 2.2558,
      "step": 8620
    },
    {
      "epoch": 51.99093655589124,
      "grad_norm": 0.3374694585800171,
      "learning_rate": 0.00042451002739647405,
      "loss": 2.258,
      "step": 8630
    },
    {
      "epoch": 52.0,
      "eval_loss": 1.1313995122909546,
      "eval_runtime": 4.5979,
      "eval_samples_per_second": 3618.622,
      "eval_steps_per_second": 14.137,
      "step": 8632
    },
    {
      "epoch": 52.04833836858006,
      "grad_norm": 0.5970695614814758,
      "learning_rate": 0.0004243378037455568,
      "loss": 2.1497,
      "step": 8640
    },
    {
      "epoch": 52.10876132930514,
      "grad_norm": 0.3206099271774292,
      "learning_rate": 0.00042416541888425514,
      "loss": 2.2605,
      "step": 8650
    },
    {
      "epoch": 52.16918429003021,
      "grad_norm": 0.2998126149177551,
      "learning_rate": 0.0004239928729719735,
      "loss": 2.2559,
      "step": 8660
    },
    {
      "epoch": 52.229607250755286,
      "grad_norm": 0.33435991406440735,
      "learning_rate": 0.00042382016616826544,
      "loss": 2.2612,
      "step": 8670
    },
    {
      "epoch": 52.290030211480364,
      "grad_norm": 0.31693941354751587,
      "learning_rate": 0.00042364729863283307,
      "loss": 2.274,
      "step": 8680
    },
    {
      "epoch": 52.35045317220544,
      "grad_norm": 0.32877272367477417,
      "learning_rate": 0.00042347427052552724,
      "loss": 2.263,
      "step": 8690
    },
    {
      "epoch": 52.41087613293051,
      "grad_norm": 0.33270329236984253,
      "learning_rate": 0.00042330108200634725,
      "loss": 2.2576,
      "step": 8700
    },
    {
      "epoch": 52.47129909365559,
      "grad_norm": 0.3074398636817932,
      "learning_rate": 0.0004231277332354407,
      "loss": 2.2609,
      "step": 8710
    },
    {
      "epoch": 52.531722054380666,
      "grad_norm": 0.34453609585762024,
      "learning_rate": 0.0004229542243731036,
      "loss": 2.2658,
      "step": 8720
    },
    {
      "epoch": 52.59214501510574,
      "grad_norm": 0.3221368193626404,
      "learning_rate": 0.0004227805555797795,
      "loss": 2.2688,
      "step": 8730
    },
    {
      "epoch": 52.65256797583081,
      "grad_norm": 0.2963811755180359,
      "learning_rate": 0.0004226067270160604,
      "loss": 2.2735,
      "step": 8740
    },
    {
      "epoch": 52.71299093655589,
      "grad_norm": 0.2802024185657501,
      "learning_rate": 0.0004224327388426857,
      "loss": 2.2634,
      "step": 8750
    },
    {
      "epoch": 52.77341389728097,
      "grad_norm": 0.3744300603866577,
      "learning_rate": 0.0004222585912205424,
      "loss": 2.2564,
      "step": 8760
    },
    {
      "epoch": 52.833836858006045,
      "grad_norm": 0.27319470047950745,
      "learning_rate": 0.00042208428431066527,
      "loss": 2.2654,
      "step": 8770
    },
    {
      "epoch": 52.894259818731115,
      "grad_norm": 0.26575225591659546,
      "learning_rate": 0.0004219098182742359,
      "loss": 2.2734,
      "step": 8780
    },
    {
      "epoch": 52.95468277945619,
      "grad_norm": 0.2758115231990814,
      "learning_rate": 0.0004217351932725832,
      "loss": 2.2695,
      "step": 8790
    },
    {
      "epoch": 53.0,
      "eval_loss": 1.1318546533584595,
      "eval_runtime": 4.557,
      "eval_samples_per_second": 3651.074,
      "eval_steps_per_second": 14.264,
      "step": 8798
    },
    {
      "epoch": 53.012084592145015,
      "grad_norm": 0.2964269816875458,
      "learning_rate": 0.00042156040946718344,
      "loss": 2.15,
      "step": 8800
    },
    {
      "epoch": 53.07250755287009,
      "grad_norm": 0.29260537028312683,
      "learning_rate": 0.0004213854670196591,
      "loss": 2.2717,
      "step": 8810
    },
    {
      "epoch": 53.13293051359516,
      "grad_norm": 0.27270835638046265,
      "learning_rate": 0.00042121036609177987,
      "loss": 2.2489,
      "step": 8820
    },
    {
      "epoch": 53.19335347432024,
      "grad_norm": 0.3228689134120941,
      "learning_rate": 0.00042103510684546173,
      "loss": 2.2754,
      "step": 8830
    },
    {
      "epoch": 53.25377643504532,
      "grad_norm": 0.430644690990448,
      "learning_rate": 0.000420859689442767,
      "loss": 2.2582,
      "step": 8840
    },
    {
      "epoch": 53.314199395770395,
      "grad_norm": 0.27079296112060547,
      "learning_rate": 0.00042068411404590466,
      "loss": 2.2638,
      "step": 8850
    },
    {
      "epoch": 53.374622356495465,
      "grad_norm": 0.25354576110839844,
      "learning_rate": 0.00042050838081722925,
      "loss": 2.2613,
      "step": 8860
    },
    {
      "epoch": 53.43504531722054,
      "grad_norm": 0.28989407420158386,
      "learning_rate": 0.00042033248991924166,
      "loss": 2.2589,
      "step": 8870
    },
    {
      "epoch": 53.49546827794562,
      "grad_norm": 0.4836485683917999,
      "learning_rate": 0.0004201564415145883,
      "loss": 2.2564,
      "step": 8880
    },
    {
      "epoch": 53.5558912386707,
      "grad_norm": 0.30816125869750977,
      "learning_rate": 0.0004199802357660614,
      "loss": 2.2546,
      "step": 8890
    },
    {
      "epoch": 53.616314199395774,
      "grad_norm": 0.2714792490005493,
      "learning_rate": 0.00041980387283659863,
      "loss": 2.2627,
      "step": 8900
    },
    {
      "epoch": 53.676737160120844,
      "grad_norm": 0.2799377739429474,
      "learning_rate": 0.00041962735288928306,
      "loss": 2.2652,
      "step": 8910
    },
    {
      "epoch": 53.73716012084592,
      "grad_norm": 0.3152686059474945,
      "learning_rate": 0.0004194506760873428,
      "loss": 2.2669,
      "step": 8920
    },
    {
      "epoch": 53.797583081571,
      "grad_norm": 0.2894829511642456,
      "learning_rate": 0.00041927384259415125,
      "loss": 2.2649,
      "step": 8930
    },
    {
      "epoch": 53.858006042296076,
      "grad_norm": 0.3004071116447449,
      "learning_rate": 0.0004190968525732264,
      "loss": 2.266,
      "step": 8940
    },
    {
      "epoch": 53.918429003021146,
      "grad_norm": 0.2874515652656555,
      "learning_rate": 0.0004189197061882314,
      "loss": 2.2617,
      "step": 8950
    },
    {
      "epoch": 53.97885196374622,
      "grad_norm": 0.26130589842796326,
      "learning_rate": 0.00041874240360297347,
      "loss": 2.2619,
      "step": 8960
    },
    {
      "epoch": 54.0,
      "eval_loss": 1.1329001188278198,
      "eval_runtime": 4.5702,
      "eval_samples_per_second": 3640.554,
      "eval_steps_per_second": 14.223,
      "step": 8964
    },
    {
      "epoch": 54.036253776435046,
      "grad_norm": 0.263175904750824,
      "learning_rate": 0.0004185649449814045,
      "loss": 2.1507,
      "step": 8970
    },
    {
      "epoch": 54.096676737160124,
      "grad_norm": 0.26260197162628174,
      "learning_rate": 0.00041838733048762093,
      "loss": 2.2661,
      "step": 8980
    },
    {
      "epoch": 54.157099697885194,
      "grad_norm": 0.28415799140930176,
      "learning_rate": 0.000418209560285863,
      "loss": 2.2572,
      "step": 8990
    },
    {
      "epoch": 54.21752265861027,
      "grad_norm": 0.26813796162605286,
      "learning_rate": 0.000418031634540515,
      "loss": 2.2466,
      "step": 9000
    },
    {
      "epoch": 54.27794561933535,
      "grad_norm": 0.37290260195732117,
      "learning_rate": 0.0004178535534161052,
      "loss": 2.2479,
      "step": 9010
    },
    {
      "epoch": 54.338368580060425,
      "grad_norm": 0.2971261441707611,
      "learning_rate": 0.0004176753170773052,
      "loss": 2.2636,
      "step": 9020
    },
    {
      "epoch": 54.398791540785496,
      "grad_norm": 0.296344131231308,
      "learning_rate": 0.0004174969256889307,
      "loss": 2.2607,
      "step": 9030
    },
    {
      "epoch": 54.45921450151057,
      "grad_norm": 0.3031855821609497,
      "learning_rate": 0.00041731837941594014,
      "loss": 2.2632,
      "step": 9040
    },
    {
      "epoch": 54.51963746223565,
      "grad_norm": 0.331381231546402,
      "learning_rate": 0.00041713967842343567,
      "loss": 2.2626,
      "step": 9050
    },
    {
      "epoch": 54.58006042296073,
      "grad_norm": 0.4003496468067169,
      "learning_rate": 0.00041696082287666223,
      "loss": 2.266,
      "step": 9060
    },
    {
      "epoch": 54.6404833836858,
      "grad_norm": 0.2747475504875183,
      "learning_rate": 0.0004167818129410077,
      "loss": 2.2553,
      "step": 9070
    },
    {
      "epoch": 54.700906344410875,
      "grad_norm": 0.3146434724330902,
      "learning_rate": 0.000416602648782003,
      "loss": 2.2686,
      "step": 9080
    },
    {
      "epoch": 54.76132930513595,
      "grad_norm": 0.26556840538978577,
      "learning_rate": 0.00041642333056532134,
      "loss": 2.2658,
      "step": 9090
    },
    {
      "epoch": 54.82175226586103,
      "grad_norm": 0.2726662755012512,
      "learning_rate": 0.00041624385845677843,
      "loss": 2.2658,
      "step": 9100
    },
    {
      "epoch": 54.8821752265861,
      "grad_norm": 0.24943792819976807,
      "learning_rate": 0.00041606423262233243,
      "loss": 2.2674,
      "step": 9110
    },
    {
      "epoch": 54.94259818731118,
      "grad_norm": 0.9884392023086548,
      "learning_rate": 0.0004158844532280835,
      "loss": 2.2532,
      "step": 9120
    },
    {
      "epoch": 55.0,
      "grad_norm": 0.27005890011787415,
      "learning_rate": 0.0004157045204402741,
      "loss": 2.1544,
      "step": 9130
    },
    {
      "epoch": 55.0,
      "eval_loss": 1.1315271854400635,
      "eval_runtime": 4.7199,
      "eval_samples_per_second": 3525.106,
      "eval_steps_per_second": 13.772,
      "step": 9130
    },
    {
      "epoch": 55.06042296072508,
      "grad_norm": 0.28866589069366455,
      "learning_rate": 0.00041552443442528797,
      "loss": 2.2482,
      "step": 9140
    },
    {
      "epoch": 55.120845921450154,
      "grad_norm": 0.25188732147216797,
      "learning_rate": 0.00041534419534965106,
      "loss": 2.2501,
      "step": 9150
    },
    {
      "epoch": 55.181268882175225,
      "grad_norm": 0.2919732630252838,
      "learning_rate": 0.00041516380338003066,
      "loss": 2.2573,
      "step": 9160
    },
    {
      "epoch": 55.2416918429003,
      "grad_norm": 0.28151991963386536,
      "learning_rate": 0.0004149832586832354,
      "loss": 2.2612,
      "step": 9170
    },
    {
      "epoch": 55.30211480362538,
      "grad_norm": 0.28641828894615173,
      "learning_rate": 0.00041480256142621523,
      "loss": 2.2591,
      "step": 9180
    },
    {
      "epoch": 55.362537764350456,
      "grad_norm": 0.30837222933769226,
      "learning_rate": 0.0004146217117760611,
      "loss": 2.2486,
      "step": 9190
    },
    {
      "epoch": 55.42296072507553,
      "grad_norm": 0.23520924150943756,
      "learning_rate": 0.00041444070990000496,
      "loss": 2.2619,
      "step": 9200
    },
    {
      "epoch": 55.483383685800604,
      "grad_norm": 0.31533756852149963,
      "learning_rate": 0.0004142595559654194,
      "loss": 2.2618,
      "step": 9210
    },
    {
      "epoch": 55.54380664652568,
      "grad_norm": 0.3202570676803589,
      "learning_rate": 0.0004140782501398178,
      "loss": 2.2581,
      "step": 9220
    },
    {
      "epoch": 55.60422960725076,
      "grad_norm": 0.3072432279586792,
      "learning_rate": 0.0004138967925908537,
      "loss": 2.2696,
      "step": 9230
    },
    {
      "epoch": 55.66465256797583,
      "grad_norm": 0.2988159954547882,
      "learning_rate": 0.0004137151834863213,
      "loss": 2.2665,
      "step": 9240
    },
    {
      "epoch": 55.725075528700906,
      "grad_norm": 0.24955689907073975,
      "learning_rate": 0.0004135334229941546,
      "loss": 2.2638,
      "step": 9250
    },
    {
      "epoch": 55.78549848942598,
      "grad_norm": 0.23894532024860382,
      "learning_rate": 0.0004133515112824279,
      "loss": 2.2593,
      "step": 9260
    },
    {
      "epoch": 55.84592145015106,
      "grad_norm": 0.23889274895191193,
      "learning_rate": 0.00041316944851935513,
      "loss": 2.2671,
      "step": 9270
    },
    {
      "epoch": 55.90634441087613,
      "grad_norm": 0.25415393710136414,
      "learning_rate": 0.00041298723487328995,
      "loss": 2.257,
      "step": 9280
    },
    {
      "epoch": 55.96676737160121,
      "grad_norm": 0.2481975555419922,
      "learning_rate": 0.00041280487051272556,
      "loss": 2.2744,
      "step": 9290
    },
    {
      "epoch": 56.0,
      "eval_loss": 1.1309154033660889,
      "eval_runtime": 4.7576,
      "eval_samples_per_second": 3497.148,
      "eval_steps_per_second": 13.662,
      "step": 9296
    },
    {
      "epoch": 56.02416918429003,
      "grad_norm": 0.31313520669937134,
      "learning_rate": 0.0004126223556062945,
      "loss": 2.1326,
      "step": 9300
    },
    {
      "epoch": 56.08459214501511,
      "grad_norm": 0.26110491156578064,
      "learning_rate": 0.0004124396903227685,
      "loss": 2.2428,
      "step": 9310
    },
    {
      "epoch": 56.14501510574018,
      "grad_norm": 0.3203572928905487,
      "learning_rate": 0.00041225687483105846,
      "loss": 2.2525,
      "step": 9320
    },
    {
      "epoch": 56.205438066465256,
      "grad_norm": 0.27230045199394226,
      "learning_rate": 0.000412073909300214,
      "loss": 2.255,
      "step": 9330
    },
    {
      "epoch": 56.26586102719033,
      "grad_norm": 0.269755482673645,
      "learning_rate": 0.0004118907938994236,
      "loss": 2.251,
      "step": 9340
    },
    {
      "epoch": 56.32628398791541,
      "grad_norm": 0.3510867953300476,
      "learning_rate": 0.00041170752879801436,
      "loss": 2.2641,
      "step": 9350
    },
    {
      "epoch": 56.38670694864048,
      "grad_norm": 0.2897008955478668,
      "learning_rate": 0.0004115241141654517,
      "loss": 2.2569,
      "step": 9360
    },
    {
      "epoch": 56.44712990936556,
      "grad_norm": 0.3399023711681366,
      "learning_rate": 0.00041134055017133937,
      "loss": 2.2692,
      "step": 9370
    },
    {
      "epoch": 56.507552870090635,
      "grad_norm": 0.2866964042186737,
      "learning_rate": 0.00041115683698541916,
      "loss": 2.249,
      "step": 9380
    },
    {
      "epoch": 56.56797583081571,
      "grad_norm": 0.28547418117523193,
      "learning_rate": 0.000410972974777571,
      "loss": 2.2538,
      "step": 9390
    },
    {
      "epoch": 56.62839879154078,
      "grad_norm": 0.24764981865882874,
      "learning_rate": 0.0004107889637178124,
      "loss": 2.2547,
      "step": 9400
    },
    {
      "epoch": 56.68882175226586,
      "grad_norm": 0.2639949917793274,
      "learning_rate": 0.0004106048039762987,
      "loss": 2.2546,
      "step": 9410
    },
    {
      "epoch": 56.74924471299094,
      "grad_norm": 0.3247010409832001,
      "learning_rate": 0.0004104204957233225,
      "loss": 2.2769,
      "step": 9420
    },
    {
      "epoch": 56.809667673716014,
      "grad_norm": 0.25215640664100647,
      "learning_rate": 0.00041023603912931407,
      "loss": 2.2639,
      "step": 9430
    },
    {
      "epoch": 56.87009063444109,
      "grad_norm": 0.29944488406181335,
      "learning_rate": 0.0004100514343648405,
      "loss": 2.268,
      "step": 9440
    },
    {
      "epoch": 56.93051359516616,
      "grad_norm": 0.2921864986419678,
      "learning_rate": 0.00040986668160060614,
      "loss": 2.2598,
      "step": 9450
    },
    {
      "epoch": 56.99093655589124,
      "grad_norm": 0.32458412647247314,
      "learning_rate": 0.000409681781007452,
      "loss": 2.2616,
      "step": 9460
    },
    {
      "epoch": 57.0,
      "eval_loss": 1.1313854455947876,
      "eval_runtime": 4.5692,
      "eval_samples_per_second": 3641.308,
      "eval_steps_per_second": 14.226,
      "step": 9462
    },
    {
      "epoch": 57.04833836858006,
      "grad_norm": 0.3934169411659241,
      "learning_rate": 0.000409496732756356,
      "loss": 2.1473,
      "step": 9470
    },
    {
      "epoch": 57.10876132930514,
      "grad_norm": 0.43043068051338196,
      "learning_rate": 0.0004093115370184324,
      "loss": 2.2611,
      "step": 9480
    },
    {
      "epoch": 57.16918429003021,
      "grad_norm": 0.26215609908103943,
      "learning_rate": 0.000409126193964932,
      "loss": 2.2515,
      "step": 9490
    },
    {
      "epoch": 57.229607250755286,
      "grad_norm": 0.28861600160598755,
      "learning_rate": 0.0004089407037672418,
      "loss": 2.2487,
      "step": 9500
    },
    {
      "epoch": 57.290030211480364,
      "grad_norm": 0.3405431807041168,
      "learning_rate": 0.0004087550665968846,
      "loss": 2.2604,
      "step": 9510
    },
    {
      "epoch": 57.35045317220544,
      "grad_norm": 0.2677675187587738,
      "learning_rate": 0.0004085692826255195,
      "loss": 2.2667,
      "step": 9520
    },
    {
      "epoch": 57.41087613293051,
      "grad_norm": 0.29349225759506226,
      "learning_rate": 0.00040838335202494116,
      "loss": 2.2522,
      "step": 9530
    },
    {
      "epoch": 57.47129909365559,
      "grad_norm": 0.36693626642227173,
      "learning_rate": 0.00040819727496707977,
      "loss": 2.2477,
      "step": 9540
    },
    {
      "epoch": 57.531722054380666,
      "grad_norm": 0.3713570833206177,
      "learning_rate": 0.0004080110516240011,
      "loss": 2.2507,
      "step": 9550
    },
    {
      "epoch": 57.59214501510574,
      "grad_norm": 1.4151078462600708,
      "learning_rate": 0.00040782468216790603,
      "loss": 2.2516,
      "step": 9560
    },
    {
      "epoch": 57.65256797583081,
      "grad_norm": 0.27530401945114136,
      "learning_rate": 0.00040763816677113064,
      "loss": 2.255,
      "step": 9570
    },
    {
      "epoch": 57.71299093655589,
      "grad_norm": 0.2630651593208313,
      "learning_rate": 0.00040745150560614595,
      "loss": 2.2535,
      "step": 9580
    },
    {
      "epoch": 57.77341389728097,
      "grad_norm": 0.31133630871772766,
      "learning_rate": 0.0004072646988455578,
      "loss": 2.251,
      "step": 9590
    },
    {
      "epoch": 57.833836858006045,
      "grad_norm": 0.2907821238040924,
      "learning_rate": 0.00040707774666210676,
      "loss": 2.2544,
      "step": 9600
    },
    {
      "epoch": 57.894259818731115,
      "grad_norm": 0.3106434643268585,
      "learning_rate": 0.0004068906492286675,
      "loss": 2.2647,
      "step": 9610
    },
    {
      "epoch": 57.95468277945619,
      "grad_norm": 0.26435887813568115,
      "learning_rate": 0.00040670340671824937,
      "loss": 2.2653,
      "step": 9620
    },
    {
      "epoch": 58.0,
      "eval_loss": 1.1311885118484497,
      "eval_runtime": 4.5716,
      "eval_samples_per_second": 3639.403,
      "eval_steps_per_second": 14.218,
      "step": 9628
    },
    {
      "epoch": 58.012084592145015,
      "grad_norm": 0.29172787070274353,
      "learning_rate": 0.00040651601930399573,
      "loss": 2.1364,
      "step": 9630
    },
    {
      "epoch": 58.07250755287009,
      "grad_norm": 0.2525691092014313,
      "learning_rate": 0.00040632848715918405,
      "loss": 2.2442,
      "step": 9640
    },
    {
      "epoch": 58.13293051359516,
      "grad_norm": 0.2781367301940918,
      "learning_rate": 0.0004061408104572254,
      "loss": 2.2604,
      "step": 9650
    },
    {
      "epoch": 58.19335347432024,
      "grad_norm": 0.3123961389064789,
      "learning_rate": 0.0004059529893716647,
      "loss": 2.2627,
      "step": 9660
    },
    {
      "epoch": 58.25377643504532,
      "grad_norm": 0.3878171741962433,
      "learning_rate": 0.00040576502407618044,
      "loss": 2.2526,
      "step": 9670
    },
    {
      "epoch": 58.314199395770395,
      "grad_norm": 0.26039186120033264,
      "learning_rate": 0.00040557691474458416,
      "loss": 2.2545,
      "step": 9680
    },
    {
      "epoch": 58.374622356495465,
      "grad_norm": 0.3077392280101776,
      "learning_rate": 0.000405388661550821,
      "loss": 2.2493,
      "step": 9690
    },
    {
      "epoch": 58.43504531722054,
      "grad_norm": 0.2797345221042633,
      "learning_rate": 0.00040520026466896885,
      "loss": 2.2505,
      "step": 9700
    },
    {
      "epoch": 58.49546827794562,
      "grad_norm": 0.32334885001182556,
      "learning_rate": 0.0004050117242732385,
      "loss": 2.2454,
      "step": 9710
    },
    {
      "epoch": 58.5558912386707,
      "grad_norm": 0.27775782346725464,
      "learning_rate": 0.0004048230405379736,
      "loss": 2.2553,
      "step": 9720
    },
    {
      "epoch": 58.616314199395774,
      "grad_norm": 0.27499228715896606,
      "learning_rate": 0.00040463421363765007,
      "loss": 2.2655,
      "step": 9730
    },
    {
      "epoch": 58.676737160120844,
      "grad_norm": 0.33766573667526245,
      "learning_rate": 0.00040444524374687644,
      "loss": 2.2603,
      "step": 9740
    },
    {
      "epoch": 58.73716012084592,
      "grad_norm": 0.2640170454978943,
      "learning_rate": 0.0004042561310403935,
      "loss": 2.2532,
      "step": 9750
    },
    {
      "epoch": 58.797583081571,
      "grad_norm": 0.25465884804725647,
      "learning_rate": 0.0004040668756930739,
      "loss": 2.2563,
      "step": 9760
    },
    {
      "epoch": 58.858006042296076,
      "grad_norm": 0.2960086464881897,
      "learning_rate": 0.00040387747787992234,
      "loss": 2.2614,
      "step": 9770
    },
    {
      "epoch": 58.918429003021146,
      "grad_norm": 0.2712192237377167,
      "learning_rate": 0.0004036879377760753,
      "loss": 2.2611,
      "step": 9780
    },
    {
      "epoch": 58.97885196374622,
      "grad_norm": 0.27551329135894775,
      "learning_rate": 0.00040349825555680046,
      "loss": 2.2607,
      "step": 9790
    },
    {
      "epoch": 59.0,
      "eval_loss": 1.1310749053955078,
      "eval_runtime": 4.5742,
      "eval_samples_per_second": 3637.38,
      "eval_steps_per_second": 14.21,
      "step": 9794
    },
    {
      "epoch": 59.036253776435046,
      "grad_norm": 0.3558865785598755,
      "learning_rate": 0.00040330843139749754,
      "loss": 2.137,
      "step": 9800
    },
    {
      "epoch": 59.096676737160124,
      "grad_norm": 0.3221950829029083,
      "learning_rate": 0.000403118465473697,
      "loss": 2.2428,
      "step": 9810
    },
    {
      "epoch": 59.157099697885194,
      "grad_norm": 0.3023519515991211,
      "learning_rate": 0.00040292835796106063,
      "loss": 2.2579,
      "step": 9820
    },
    {
      "epoch": 59.21752265861027,
      "grad_norm": 0.3082110583782196,
      "learning_rate": 0.00040273810903538107,
      "loss": 2.2469,
      "step": 9830
    },
    {
      "epoch": 59.27794561933535,
      "grad_norm": 0.28838273882865906,
      "learning_rate": 0.0004025477188725817,
      "loss": 2.25,
      "step": 9840
    },
    {
      "epoch": 59.338368580060425,
      "grad_norm": 0.2645514905452728,
      "learning_rate": 0.00040235718764871655,
      "loss": 2.2535,
      "step": 9850
    },
    {
      "epoch": 59.398791540785496,
      "grad_norm": 0.3210940361022949,
      "learning_rate": 0.00040216651553997006,
      "loss": 2.2551,
      "step": 9860
    },
    {
      "epoch": 59.45921450151057,
      "grad_norm": 0.3076060712337494,
      "learning_rate": 0.00040197570272265703,
      "loss": 2.2523,
      "step": 9870
    },
    {
      "epoch": 59.51963746223565,
      "grad_norm": 0.2716757357120514,
      "learning_rate": 0.0004017847493732223,
      "loss": 2.2558,
      "step": 9880
    },
    {
      "epoch": 59.58006042296073,
      "grad_norm": 0.2773534655570984,
      "learning_rate": 0.0004015936556682407,
      "loss": 2.2564,
      "step": 9890
    },
    {
      "epoch": 59.6404833836858,
      "grad_norm": 0.28965574502944946,
      "learning_rate": 0.00040140242178441667,
      "loss": 2.2575,
      "step": 9900
    },
    {
      "epoch": 59.700906344410875,
      "grad_norm": 0.39586254954338074,
      "learning_rate": 0.0004012110478985846,
      "loss": 2.2509,
      "step": 9910
    },
    {
      "epoch": 59.76132930513595,
      "grad_norm": 0.31219667196273804,
      "learning_rate": 0.00040101953418770803,
      "loss": 2.2492,
      "step": 9920
    },
    {
      "epoch": 59.82175226586103,
      "grad_norm": 0.3461100459098816,
      "learning_rate": 0.00040082788082888,
      "loss": 2.2555,
      "step": 9930
    },
    {
      "epoch": 59.8821752265861,
      "grad_norm": 0.27461740374565125,
      "learning_rate": 0.0004006360879993226,
      "loss": 2.2568,
      "step": 9940
    },
    {
      "epoch": 59.94259818731118,
      "grad_norm": 0.42951464653015137,
      "learning_rate": 0.0004004441558763869,
      "loss": 2.2519,
      "step": 9950
    },
    {
      "epoch": 60.0,
      "grad_norm": 0.2881682813167572,
      "learning_rate": 0.00040025208463755275,
      "loss": 2.1445,
      "step": 9960
    },
    {
      "epoch": 60.0,
      "eval_loss": 1.1314575672149658,
      "eval_runtime": 4.5983,
      "eval_samples_per_second": 3618.318,
      "eval_steps_per_second": 14.136,
      "step": 9960
    },
    {
      "epoch": 60.06042296072508,
      "grad_norm": 0.3422451317310333,
      "learning_rate": 0.00040005987446042863,
      "loss": 2.245,
      "step": 9970
    },
    {
      "epoch": 60.120845921450154,
      "grad_norm": 0.2979184091091156,
      "learning_rate": 0.0003998675255227516,
      "loss": 2.2498,
      "step": 9980
    },
    {
      "epoch": 60.181268882175225,
      "grad_norm": 0.3099215030670166,
      "learning_rate": 0.000399675038002387,
      "loss": 2.254,
      "step": 9990
    },
    {
      "epoch": 60.2416918429003,
      "grad_norm": 0.31131860613822937,
      "learning_rate": 0.00039948241207732815,
      "loss": 2.258,
      "step": 10000
    },
    {
      "epoch": 60.30211480362538,
      "grad_norm": 0.29882103204727173,
      "learning_rate": 0.00039928964792569654,
      "loss": 2.2585,
      "step": 10010
    },
    {
      "epoch": 60.362537764350456,
      "grad_norm": 0.387455552816391,
      "learning_rate": 0.00039909674572574145,
      "loss": 2.2612,
      "step": 10020
    },
    {
      "epoch": 60.42296072507553,
      "grad_norm": 0.2893616557121277,
      "learning_rate": 0.0003989037056558398,
      "loss": 2.2589,
      "step": 10030
    },
    {
      "epoch": 60.483383685800604,
      "grad_norm": 0.31636691093444824,
      "learning_rate": 0.0003987105278944959,
      "loss": 2.26,
      "step": 10040
    },
    {
      "epoch": 60.54380664652568,
      "grad_norm": 0.28862205147743225,
      "learning_rate": 0.00039851721262034156,
      "loss": 2.2461,
      "step": 10050
    },
    {
      "epoch": 60.60422960725076,
      "grad_norm": 0.26336807012557983,
      "learning_rate": 0.0003983237600121356,
      "loss": 2.2611,
      "step": 10060
    },
    {
      "epoch": 60.66465256797583,
      "grad_norm": 0.2711559236049652,
      "learning_rate": 0.0003981301702487639,
      "loss": 2.248,
      "step": 10070
    },
    {
      "epoch": 60.725075528700906,
      "grad_norm": 0.32610204815864563,
      "learning_rate": 0.00039793644350923915,
      "loss": 2.2451,
      "step": 10080
    },
    {
      "epoch": 60.78549848942598,
      "grad_norm": 0.3247497081756592,
      "learning_rate": 0.0003977425799727007,
      "loss": 2.2481,
      "step": 10090
    },
    {
      "epoch": 60.84592145015106,
      "grad_norm": 0.2992047667503357,
      "learning_rate": 0.00039754857981841443,
      "loss": 2.248,
      "step": 10100
    },
    {
      "epoch": 60.90634441087613,
      "grad_norm": 0.2997686266899109,
      "learning_rate": 0.00039735444322577254,
      "loss": 2.2531,
      "step": 10110
    },
    {
      "epoch": 60.96676737160121,
      "grad_norm": 0.2678465247154236,
      "learning_rate": 0.0003971601703742932,
      "loss": 2.2438,
      "step": 10120
    },
    {
      "epoch": 61.0,
      "eval_loss": 1.1312296390533447,
      "eval_runtime": 4.6007,
      "eval_samples_per_second": 3616.371,
      "eval_steps_per_second": 14.128,
      "step": 10126
    },
    {
      "epoch": 61.02416918429003,
      "grad_norm": 0.263656884431839,
      "learning_rate": 0.0003969657614436211,
      "loss": 2.1414,
      "step": 10130
    },
    {
      "epoch": 61.08459214501511,
      "grad_norm": 0.32096004486083984,
      "learning_rate": 0.00039677121661352613,
      "loss": 2.2398,
      "step": 10140
    },
    {
      "epoch": 61.14501510574018,
      "grad_norm": 0.32373350858688354,
      "learning_rate": 0.0003965765360639042,
      "loss": 2.2402,
      "step": 10150
    },
    {
      "epoch": 61.205438066465256,
      "grad_norm": 0.29584991931915283,
      "learning_rate": 0.0003963817199747768,
      "loss": 2.2393,
      "step": 10160
    },
    {
      "epoch": 61.26586102719033,
      "grad_norm": 0.3068124055862427,
      "learning_rate": 0.00039618676852629044,
      "loss": 2.2545,
      "step": 10170
    },
    {
      "epoch": 61.32628398791541,
      "grad_norm": 0.31090518832206726,
      "learning_rate": 0.000395991681898717,
      "loss": 2.2559,
      "step": 10180
    },
    {
      "epoch": 61.38670694864048,
      "grad_norm": 0.3192633390426636,
      "learning_rate": 0.0003957964602724534,
      "loss": 2.2418,
      "step": 10190
    },
    {
      "epoch": 61.44712990936556,
      "grad_norm": 0.3616589307785034,
      "learning_rate": 0.0003956011038280213,
      "loss": 2.2486,
      "step": 10200
    },
    {
      "epoch": 61.507552870090635,
      "grad_norm": 0.30340081453323364,
      "learning_rate": 0.00039540561274606703,
      "loss": 2.2562,
      "step": 10210
    },
    {
      "epoch": 61.56797583081571,
      "grad_norm": 0.3154248297214508,
      "learning_rate": 0.00039520998720736137,
      "loss": 2.2582,
      "step": 10220
    },
    {
      "epoch": 61.62839879154078,
      "grad_norm": 0.33700627088546753,
      "learning_rate": 0.0003950142273927996,
      "loss": 2.2475,
      "step": 10230
    },
    {
      "epoch": 61.68882175226586,
      "grad_norm": 0.3277541697025299,
      "learning_rate": 0.000394818333483401,
      "loss": 2.2486,
      "step": 10240
    },
    {
      "epoch": 61.74924471299094,
      "grad_norm": 0.37336277961730957,
      "learning_rate": 0.00039462230566030893,
      "loss": 2.2603,
      "step": 10250
    },
    {
      "epoch": 61.809667673716014,
      "grad_norm": 0.32977408170700073,
      "learning_rate": 0.0003944261441047906,
      "loss": 2.2601,
      "step": 10260
    },
    {
      "epoch": 61.87009063444109,
      "grad_norm": 0.30375900864601135,
      "learning_rate": 0.00039422984899823685,
      "loss": 2.2582,
      "step": 10270
    },
    {
      "epoch": 61.93051359516616,
      "grad_norm": 0.31449654698371887,
      "learning_rate": 0.0003940334205221619,
      "loss": 2.2473,
      "step": 10280
    },
    {
      "epoch": 61.99093655589124,
      "grad_norm": 0.33466899394989014,
      "learning_rate": 0.0003938368588582035,
      "loss": 2.2539,
      "step": 10290
    },
    {
      "epoch": 62.0,
      "eval_loss": 1.1307239532470703,
      "eval_runtime": 4.5697,
      "eval_samples_per_second": 3640.956,
      "eval_steps_per_second": 14.224,
      "step": 10292
    },
    {
      "epoch": 62.04833836858006,
      "grad_norm": 0.3184334635734558,
      "learning_rate": 0.00039364016418812247,
      "loss": 2.1253,
      "step": 10300
    },
    {
      "epoch": 62.10876132930514,
      "grad_norm": 0.4061092734336853,
      "learning_rate": 0.0003934433366938026,
      "loss": 2.2516,
      "step": 10310
    },
    {
      "epoch": 62.16918429003021,
      "grad_norm": 0.3550466001033783,
      "learning_rate": 0.00039324637655725053,
      "loss": 2.2446,
      "step": 10320
    },
    {
      "epoch": 62.229607250755286,
      "grad_norm": 0.37739694118499756,
      "learning_rate": 0.00039304928396059546,
      "loss": 2.2464,
      "step": 10330
    },
    {
      "epoch": 62.290030211480364,
      "grad_norm": 0.45618531107902527,
      "learning_rate": 0.00039285205908608933,
      "loss": 2.2427,
      "step": 10340
    },
    {
      "epoch": 62.35045317220544,
      "grad_norm": 0.3537452220916748,
      "learning_rate": 0.00039265470211610607,
      "loss": 2.2513,
      "step": 10350
    },
    {
      "epoch": 62.41087613293051,
      "grad_norm": 0.2909524440765381,
      "learning_rate": 0.000392457213233142,
      "loss": 2.2469,
      "step": 10360
    },
    {
      "epoch": 62.47129909365559,
      "grad_norm": 0.375241756439209,
      "learning_rate": 0.00039225959261981525,
      "loss": 2.2504,
      "step": 10370
    },
    {
      "epoch": 62.531722054380666,
      "grad_norm": 0.2866990566253662,
      "learning_rate": 0.0003920618404588659,
      "loss": 2.2506,
      "step": 10380
    },
    {
      "epoch": 62.59214501510574,
      "grad_norm": 0.3002890646457672,
      "learning_rate": 0.0003918639569331557,
      "loss": 2.2547,
      "step": 10390
    },
    {
      "epoch": 62.65256797583081,
      "grad_norm": 0.3478142321109772,
      "learning_rate": 0.00039166594222566763,
      "loss": 2.2596,
      "step": 10400
    },
    {
      "epoch": 62.71299093655589,
      "grad_norm": 0.3686518371105194,
      "learning_rate": 0.0003914677965195063,
      "loss": 2.2497,
      "step": 10410
    },
    {
      "epoch": 62.77341389728097,
      "grad_norm": 0.34341269731521606,
      "learning_rate": 0.0003912695199978972,
      "loss": 2.2422,
      "step": 10420
    },
    {
      "epoch": 62.833836858006045,
      "grad_norm": 0.29501938819885254,
      "learning_rate": 0.00039107111284418685,
      "loss": 2.2566,
      "step": 10430
    },
    {
      "epoch": 62.894259818731115,
      "grad_norm": 0.34844425320625305,
      "learning_rate": 0.0003908725752418426,
      "loss": 2.2562,
      "step": 10440
    },
    {
      "epoch": 62.95468277945619,
      "grad_norm": 0.3133307993412018,
      "learning_rate": 0.00039067390737445256,
      "loss": 2.2633,
      "step": 10450
    },
    {
      "epoch": 63.0,
      "eval_loss": 1.130874514579773,
      "eval_runtime": 4.5822,
      "eval_samples_per_second": 3630.969,
      "eval_steps_per_second": 14.185,
      "step": 10458
    },
    {
      "epoch": 63.012084592145015,
      "grad_norm": 0.3344380557537079,
      "learning_rate": 0.000390475109425725,
      "loss": 2.1356,
      "step": 10460
    },
    {
      "epoch": 63.07250755287009,
      "grad_norm": 0.3429162800312042,
      "learning_rate": 0.0003902761815794887,
      "loss": 2.2458,
      "step": 10470
    },
    {
      "epoch": 63.13293051359516,
      "grad_norm": 0.40059828758239746,
      "learning_rate": 0.0003900771240196924,
      "loss": 2.2484,
      "step": 10480
    },
    {
      "epoch": 63.19335347432024,
      "grad_norm": 0.3282054364681244,
      "learning_rate": 0.00038987793693040496,
      "loss": 2.2473,
      "step": 10490
    },
    {
      "epoch": 63.25377643504532,
      "grad_norm": 0.43842917680740356,
      "learning_rate": 0.00038967862049581496,
      "loss": 2.249,
      "step": 10500
    },
    {
      "epoch": 63.314199395770395,
      "grad_norm": 0.39911574125289917,
      "learning_rate": 0.00038947917490023045,
      "loss": 2.2502,
      "step": 10510
    },
    {
      "epoch": 63.374622356495465,
      "grad_norm": 0.3504221737384796,
      "learning_rate": 0.00038927960032807916,
      "loss": 2.2429,
      "step": 10520
    },
    {
      "epoch": 63.43504531722054,
      "grad_norm": 0.26738014817237854,
      "learning_rate": 0.0003890798969639078,
      "loss": 2.2453,
      "step": 10530
    },
    {
      "epoch": 63.49546827794562,
      "grad_norm": 0.3246113359928131,
      "learning_rate": 0.0003888800649923824,
      "loss": 2.2573,
      "step": 10540
    },
    {
      "epoch": 63.5558912386707,
      "grad_norm": 0.3694498836994171,
      "learning_rate": 0.00038868010459828774,
      "loss": 2.2488,
      "step": 10550
    },
    {
      "epoch": 63.616314199395774,
      "grad_norm": 0.3189934194087982,
      "learning_rate": 0.0003884800159665276,
      "loss": 2.2478,
      "step": 10560
    },
    {
      "epoch": 63.676737160120844,
      "grad_norm": 0.36337563395500183,
      "learning_rate": 0.0003882797992821241,
      "loss": 2.2464,
      "step": 10570
    },
    {
      "epoch": 63.73716012084592,
      "grad_norm": 0.3404882848262787,
      "learning_rate": 0.00038807945473021783,
      "loss": 2.2456,
      "step": 10580
    },
    {
      "epoch": 63.797583081571,
      "grad_norm": 0.34699371457099915,
      "learning_rate": 0.00038787898249606766,
      "loss": 2.2531,
      "step": 10590
    },
    {
      "epoch": 63.858006042296076,
      "grad_norm": 0.34434881806373596,
      "learning_rate": 0.0003876783827650506,
      "loss": 2.2484,
      "step": 10600
    },
    {
      "epoch": 63.918429003021146,
      "grad_norm": 0.3285019099712372,
      "learning_rate": 0.00038747765572266134,
      "loss": 2.2667,
      "step": 10610
    },
    {
      "epoch": 63.97885196374622,
      "grad_norm": 0.7408691048622131,
      "learning_rate": 0.0003872768015545126,
      "loss": 2.2509,
      "step": 10620
    },
    {
      "epoch": 64.0,
      "eval_loss": 1.1311956644058228,
      "eval_runtime": 4.5652,
      "eval_samples_per_second": 3644.501,
      "eval_steps_per_second": 14.238,
      "step": 10624
    },
    {
      "epoch": 64.03625377643505,
      "grad_norm": 0.3206627070903778,
      "learning_rate": 0.00038707582044633426,
      "loss": 2.1335,
      "step": 10630
    },
    {
      "epoch": 64.09667673716012,
      "grad_norm": 0.45619699358940125,
      "learning_rate": 0.0003868747125839739,
      "loss": 2.246,
      "step": 10640
    },
    {
      "epoch": 64.1570996978852,
      "grad_norm": 0.3535114526748657,
      "learning_rate": 0.00038667347815339636,
      "loss": 2.2468,
      "step": 10650
    },
    {
      "epoch": 64.21752265861028,
      "grad_norm": 0.35572704672813416,
      "learning_rate": 0.00038647211734068313,
      "loss": 2.2413,
      "step": 10660
    },
    {
      "epoch": 64.27794561933534,
      "grad_norm": 0.37132611870765686,
      "learning_rate": 0.0003862706303320329,
      "loss": 2.2448,
      "step": 10670
    },
    {
      "epoch": 64.33836858006042,
      "grad_norm": 0.3680497109889984,
      "learning_rate": 0.00038606901731376105,
      "loss": 2.2514,
      "step": 10680
    },
    {
      "epoch": 64.3987915407855,
      "grad_norm": 0.43714091181755066,
      "learning_rate": 0.0003858672784722992,
      "loss": 2.2468,
      "step": 10690
    },
    {
      "epoch": 64.45921450151057,
      "grad_norm": 0.3384784460067749,
      "learning_rate": 0.00038566541399419574,
      "loss": 2.2511,
      "step": 10700
    },
    {
      "epoch": 64.51963746223565,
      "grad_norm": 0.27344366908073425,
      "learning_rate": 0.0003854634240661148,
      "loss": 2.2528,
      "step": 10710
    },
    {
      "epoch": 64.58006042296073,
      "grad_norm": 0.3463175892829895,
      "learning_rate": 0.0003852613088748368,
      "loss": 2.248,
      "step": 10720
    },
    {
      "epoch": 64.6404833836858,
      "grad_norm": 0.31684306263923645,
      "learning_rate": 0.00038505906860725794,
      "loss": 2.2471,
      "step": 10730
    },
    {
      "epoch": 64.70090634441088,
      "grad_norm": 0.34150394797325134,
      "learning_rate": 0.00038485670345038994,
      "loss": 2.2446,
      "step": 10740
    },
    {
      "epoch": 64.76132930513594,
      "grad_norm": 0.29489290714263916,
      "learning_rate": 0.0003846542135913602,
      "loss": 2.2526,
      "step": 10750
    },
    {
      "epoch": 64.82175226586102,
      "grad_norm": 0.27983760833740234,
      "learning_rate": 0.0003844515992174114,
      "loss": 2.2509,
      "step": 10760
    },
    {
      "epoch": 64.8821752265861,
      "grad_norm": 0.2891853451728821,
      "learning_rate": 0.00038424886051590117,
      "loss": 2.2533,
      "step": 10770
    },
    {
      "epoch": 64.94259818731118,
      "grad_norm": 0.3111670911312103,
      "learning_rate": 0.0003840459976743024,
      "loss": 2.2545,
      "step": 10780
    },
    {
      "epoch": 65.0,
      "grad_norm": 0.514374852180481,
      "learning_rate": 0.00038384301088020237,
      "loss": 2.1294,
      "step": 10790
    },
    {
      "epoch": 65.0,
      "eval_loss": 1.1334466934204102,
      "eval_runtime": 4.5759,
      "eval_samples_per_second": 3636.014,
      "eval_steps_per_second": 14.205,
      "step": 10790
    },
    {
      "epoch": 65.06042296072508,
      "grad_norm": 0.33161303400993347,
      "learning_rate": 0.0003836399003213035,
      "loss": 2.2324,
      "step": 10800
    },
    {
      "epoch": 65.12084592145015,
      "grad_norm": 0.3373965620994568,
      "learning_rate": 0.00038343666618542217,
      "loss": 2.2445,
      "step": 10810
    },
    {
      "epoch": 65.18126888217523,
      "grad_norm": 0.3642345666885376,
      "learning_rate": 0.00038323330866048933,
      "loss": 2.2344,
      "step": 10820
    },
    {
      "epoch": 65.24169184290031,
      "grad_norm": 0.4273030161857605,
      "learning_rate": 0.00038302982793454987,
      "loss": 2.2417,
      "step": 10830
    },
    {
      "epoch": 65.30211480362537,
      "grad_norm": 0.6512347459793091,
      "learning_rate": 0.0003828262241957627,
      "loss": 2.2459,
      "step": 10840
    },
    {
      "epoch": 65.36253776435045,
      "grad_norm": 0.3618020713329315,
      "learning_rate": 0.00038262249763240067,
      "loss": 2.2474,
      "step": 10850
    },
    {
      "epoch": 65.42296072507553,
      "grad_norm": 0.3686537444591522,
      "learning_rate": 0.00038241864843284966,
      "loss": 2.2454,
      "step": 10860
    },
    {
      "epoch": 65.4833836858006,
      "grad_norm": 0.37233439087867737,
      "learning_rate": 0.0003822146767856094,
      "loss": 2.2492,
      "step": 10870
    },
    {
      "epoch": 65.54380664652568,
      "grad_norm": 0.4565131366252899,
      "learning_rate": 0.0003820105828792928,
      "loss": 2.2366,
      "step": 10880
    },
    {
      "epoch": 65.60422960725076,
      "grad_norm": 0.37468042969703674,
      "learning_rate": 0.00038180636690262563,
      "loss": 2.244,
      "step": 10890
    },
    {
      "epoch": 65.66465256797584,
      "grad_norm": 0.3906875550746918,
      "learning_rate": 0.00038160202904444674,
      "loss": 2.2558,
      "step": 10900
    },
    {
      "epoch": 65.72507552870091,
      "grad_norm": 0.34714818000793457,
      "learning_rate": 0.0003813975694937075,
      "loss": 2.2484,
      "step": 10910
    },
    {
      "epoch": 65.78549848942598,
      "grad_norm": 0.34471505880355835,
      "learning_rate": 0.000381192988439472,
      "loss": 2.2512,
      "step": 10920
    },
    {
      "epoch": 65.84592145015105,
      "grad_norm": 0.36303287744522095,
      "learning_rate": 0.00038098828607091676,
      "loss": 2.2598,
      "step": 10930
    },
    {
      "epoch": 65.90634441087613,
      "grad_norm": 0.373966783285141,
      "learning_rate": 0.00038078346257733,
      "loss": 2.2458,
      "step": 10940
    },
    {
      "epoch": 65.96676737160121,
      "grad_norm": 0.3400190472602844,
      "learning_rate": 0.0003805785181481123,
      "loss": 2.252,
      "step": 10950
    },
    {
      "epoch": 66.0,
      "eval_loss": 1.1318715810775757,
      "eval_runtime": 4.5781,
      "eval_samples_per_second": 3634.241,
      "eval_steps_per_second": 14.198,
      "step": 10956
    },
    {
      "epoch": 66.02416918429003,
      "grad_norm": 0.3369639813899994,
      "learning_rate": 0.00038037345297277624,
      "loss": 2.1376,
      "step": 10960
    },
    {
      "epoch": 66.08459214501511,
      "grad_norm": 0.34809577465057373,
      "learning_rate": 0.0003801682672409458,
      "loss": 2.2462,
      "step": 10970
    },
    {
      "epoch": 66.14501510574019,
      "grad_norm": 0.41172924637794495,
      "learning_rate": 0.00037996296114235637,
      "loss": 2.2364,
      "step": 10980
    },
    {
      "epoch": 66.20543806646526,
      "grad_norm": 0.34830161929130554,
      "learning_rate": 0.00037975753486685474,
      "loss": 2.2511,
      "step": 10990
    },
    {
      "epoch": 66.26586102719033,
      "grad_norm": 0.34935280680656433,
      "learning_rate": 0.00037955198860439886,
      "loss": 2.2369,
      "step": 11000
    },
    {
      "epoch": 66.3262839879154,
      "grad_norm": 0.34620675444602966,
      "learning_rate": 0.00037934632254505774,
      "loss": 2.2371,
      "step": 11010
    },
    {
      "epoch": 66.38670694864048,
      "grad_norm": 0.35729435086250305,
      "learning_rate": 0.00037914053687901095,
      "loss": 2.2558,
      "step": 11020
    },
    {
      "epoch": 66.44712990936556,
      "grad_norm": 0.3644889295101166,
      "learning_rate": 0.00037893463179654877,
      "loss": 2.2464,
      "step": 11030
    },
    {
      "epoch": 66.50755287009063,
      "grad_norm": 0.4104345142841339,
      "learning_rate": 0.00037872860748807183,
      "loss": 2.2387,
      "step": 11040
    },
    {
      "epoch": 66.56797583081571,
      "grad_norm": 0.3809286653995514,
      "learning_rate": 0.00037852246414409106,
      "loss": 2.2492,
      "step": 11050
    },
    {
      "epoch": 66.62839879154079,
      "grad_norm": 0.30786722898483276,
      "learning_rate": 0.0003783162019552276,
      "loss": 2.2461,
      "step": 11060
    },
    {
      "epoch": 66.68882175226587,
      "grad_norm": 0.33106470108032227,
      "learning_rate": 0.00037810982111221225,
      "loss": 2.2442,
      "step": 11070
    },
    {
      "epoch": 66.74924471299093,
      "grad_norm": 0.34591931104660034,
      "learning_rate": 0.0003779033218058857,
      "loss": 2.2479,
      "step": 11080
    },
    {
      "epoch": 66.809667673716,
      "grad_norm": 0.36142677068710327,
      "learning_rate": 0.00037769670422719805,
      "loss": 2.2411,
      "step": 11090
    },
    {
      "epoch": 66.87009063444108,
      "grad_norm": 0.3260241746902466,
      "learning_rate": 0.00037748996856720875,
      "loss": 2.2393,
      "step": 11100
    },
    {
      "epoch": 66.93051359516616,
      "grad_norm": 0.4311077296733856,
      "learning_rate": 0.0003772831150170868,
      "loss": 2.2551,
      "step": 11110
    },
    {
      "epoch": 66.99093655589124,
      "grad_norm": 0.3368505537509918,
      "learning_rate": 0.0003770761437681096,
      "loss": 2.2506,
      "step": 11120
    },
    {
      "epoch": 67.0,
      "eval_loss": 1.1320898532867432,
      "eval_runtime": 4.5688,
      "eval_samples_per_second": 3641.64,
      "eval_steps_per_second": 14.227,
      "step": 11122
    },
    {
      "epoch": 67.04833836858006,
      "grad_norm": 0.37370386719703674,
      "learning_rate": 0.0003768690550116639,
      "loss": 2.1232,
      "step": 11130
    },
    {
      "epoch": 67.10876132930514,
      "grad_norm": 0.3189907670021057,
      "learning_rate": 0.000376661848939245,
      "loss": 2.2439,
      "step": 11140
    },
    {
      "epoch": 67.16918429003022,
      "grad_norm": 0.43153053522109985,
      "learning_rate": 0.00037645452574245643,
      "loss": 2.2395,
      "step": 11150
    },
    {
      "epoch": 67.2296072507553,
      "grad_norm": 0.43446284532546997,
      "learning_rate": 0.00037624708561301035,
      "loss": 2.2401,
      "step": 11160
    },
    {
      "epoch": 67.29003021148036,
      "grad_norm": 0.3767445981502533,
      "learning_rate": 0.0003760395287427269,
      "loss": 2.2355,
      "step": 11170
    },
    {
      "epoch": 67.35045317220543,
      "grad_norm": 0.4914833903312683,
      "learning_rate": 0.00037583185532353414,
      "loss": 2.2326,
      "step": 11180
    },
    {
      "epoch": 67.41087613293051,
      "grad_norm": 0.3233330249786377,
      "learning_rate": 0.00037562406554746786,
      "loss": 2.2491,
      "step": 11190
    },
    {
      "epoch": 67.47129909365559,
      "grad_norm": 0.3208256661891937,
      "learning_rate": 0.00037541615960667163,
      "loss": 2.2399,
      "step": 11200
    },
    {
      "epoch": 67.53172205438067,
      "grad_norm": 0.44864028692245483,
      "learning_rate": 0.0003752081376933963,
      "loss": 2.24,
      "step": 11210
    },
    {
      "epoch": 67.59214501510574,
      "grad_norm": 0.5738153457641602,
      "learning_rate": 0.000375,
      "loss": 2.2455,
      "step": 11220
    },
    {
      "epoch": 67.65256797583082,
      "grad_norm": 0.32962849736213684,
      "learning_rate": 0.0003747917467189479,
      "loss": 2.255,
      "step": 11230
    },
    {
      "epoch": 67.7129909365559,
      "grad_norm": 0.32596394419670105,
      "learning_rate": 0.0003745833780428121,
      "loss": 2.2463,
      "step": 11240
    },
    {
      "epoch": 67.77341389728096,
      "grad_norm": 0.40872353315353394,
      "learning_rate": 0.0003743748941642714,
      "loss": 2.2463,
      "step": 11250
    },
    {
      "epoch": 67.83383685800604,
      "grad_norm": 0.3066931366920471,
      "learning_rate": 0.00037416629527611096,
      "loss": 2.2505,
      "step": 11260
    },
    {
      "epoch": 67.89425981873111,
      "grad_norm": 0.36832794547080994,
      "learning_rate": 0.0003739575815712226,
      "loss": 2.2417,
      "step": 11270
    },
    {
      "epoch": 67.95468277945619,
      "grad_norm": 0.33378469944000244,
      "learning_rate": 0.00037374875324260406,
      "loss": 2.245,
      "step": 11280
    },
    {
      "epoch": 68.0,
      "eval_loss": 1.1320263147354126,
      "eval_runtime": 4.5857,
      "eval_samples_per_second": 3628.232,
      "eval_steps_per_second": 14.174,
      "step": 11288
    },
    {
      "epoch": 68.01208459214502,
      "grad_norm": 0.365055114030838,
      "learning_rate": 0.0003735398104833592,
      "loss": 2.1388,
      "step": 11290
    },
    {
      "epoch": 68.07250755287009,
      "grad_norm": 0.3755064904689789,
      "learning_rate": 0.0003733307534866975,
      "loss": 2.2399,
      "step": 11300
    },
    {
      "epoch": 68.13293051359517,
      "grad_norm": 0.34886378049850464,
      "learning_rate": 0.00037312158244593444,
      "loss": 2.2421,
      "step": 11310
    },
    {
      "epoch": 68.19335347432025,
      "grad_norm": 0.3530891537666321,
      "learning_rate": 0.00037291229755449063,
      "loss": 2.2284,
      "step": 11320
    },
    {
      "epoch": 68.25377643504531,
      "grad_norm": 0.3380877375602722,
      "learning_rate": 0.00037270289900589207,
      "loss": 2.2418,
      "step": 11330
    },
    {
      "epoch": 68.31419939577039,
      "grad_norm": 0.3060825765132904,
      "learning_rate": 0.0003724933869937698,
      "loss": 2.2323,
      "step": 11340
    },
    {
      "epoch": 68.37462235649546,
      "grad_norm": 0.663278341293335,
      "learning_rate": 0.0003722837617118601,
      "loss": 2.2476,
      "step": 11350
    },
    {
      "epoch": 68.43504531722054,
      "grad_norm": 0.3842887878417969,
      "learning_rate": 0.0003720740233540033,
      "loss": 2.245,
      "step": 11360
    },
    {
      "epoch": 68.49546827794562,
      "grad_norm": 0.35019341111183167,
      "learning_rate": 0.00037186417211414516,
      "loss": 2.2437,
      "step": 11370
    },
    {
      "epoch": 68.5558912386707,
      "grad_norm": 0.3409145474433899,
      "learning_rate": 0.0003716542081863351,
      "loss": 2.2542,
      "step": 11380
    },
    {
      "epoch": 68.61631419939577,
      "grad_norm": 0.3316798210144043,
      "learning_rate": 0.00037144413176472713,
      "loss": 2.2445,
      "step": 11390
    },
    {
      "epoch": 68.67673716012085,
      "grad_norm": 0.31062307953834534,
      "learning_rate": 0.0003712339430435792,
      "loss": 2.2402,
      "step": 11400
    },
    {
      "epoch": 68.73716012084593,
      "grad_norm": 0.2901758849620819,
      "learning_rate": 0.00037102364221725296,
      "loss": 2.2444,
      "step": 11410
    },
    {
      "epoch": 68.79758308157099,
      "grad_norm": 0.30815914273262024,
      "learning_rate": 0.000370813229480214,
      "loss": 2.2381,
      "step": 11420
    },
    {
      "epoch": 68.85800604229607,
      "grad_norm": 0.3784676492214203,
      "learning_rate": 0.00037060270502703115,
      "loss": 2.2468,
      "step": 11430
    },
    {
      "epoch": 68.91842900302115,
      "grad_norm": 0.2896571755409241,
      "learning_rate": 0.0003703920690523766,
      "loss": 2.2517,
      "step": 11440
    },
    {
      "epoch": 68.97885196374622,
      "grad_norm": 0.32292741537094116,
      "learning_rate": 0.0003701813217510258,
      "loss": 2.2415,
      "step": 11450
    },
    {
      "epoch": 69.0,
      "eval_loss": 1.1321157217025757,
      "eval_runtime": 4.5791,
      "eval_samples_per_second": 3633.445,
      "eval_steps_per_second": 14.195,
      "step": 11454
    },
    {
      "epoch": 69.03625377643505,
      "grad_norm": 0.3515706956386566,
      "learning_rate": 0.00036997046331785696,
      "loss": 2.1318,
      "step": 11460
    },
    {
      "epoch": 69.09667673716012,
      "grad_norm": 0.35903286933898926,
      "learning_rate": 0.0003697594939478512,
      "loss": 2.2413,
      "step": 11470
    },
    {
      "epoch": 69.1570996978852,
      "grad_norm": 0.31797081232070923,
      "learning_rate": 0.00036954841383609216,
      "loss": 2.2359,
      "step": 11480
    },
    {
      "epoch": 69.21752265861028,
      "grad_norm": 0.3343598544597626,
      "learning_rate": 0.0003693372231777658,
      "loss": 2.2364,
      "step": 11490
    },
    {
      "epoch": 69.27794561933534,
      "grad_norm": 0.32869330048561096,
      "learning_rate": 0.00036912592216816045,
      "loss": 2.2383,
      "step": 11500
    },
    {
      "epoch": 69.33836858006042,
      "grad_norm": 0.31200844049453735,
      "learning_rate": 0.00036891451100266637,
      "loss": 2.2378,
      "step": 11510
    },
    {
      "epoch": 69.3987915407855,
      "grad_norm": 0.33636459708213806,
      "learning_rate": 0.0003687029898767758,
      "loss": 2.2386,
      "step": 11520
    },
    {
      "epoch": 69.45921450151057,
      "grad_norm": 0.32004424929618835,
      "learning_rate": 0.00036849135898608254,
      "loss": 2.2464,
      "step": 11530
    },
    {
      "epoch": 69.51963746223565,
      "grad_norm": 0.3330824673175812,
      "learning_rate": 0.00036827961852628195,
      "loss": 2.2331,
      "step": 11540
    },
    {
      "epoch": 69.58006042296073,
      "grad_norm": 0.3558831214904785,
      "learning_rate": 0.0003680677686931707,
      "loss": 2.2477,
      "step": 11550
    },
    {
      "epoch": 69.6404833836858,
      "grad_norm": 0.31547924876213074,
      "learning_rate": 0.00036785580968264655,
      "loss": 2.2498,
      "step": 11560
    },
    {
      "epoch": 69.70090634441088,
      "grad_norm": 0.3810640573501587,
      "learning_rate": 0.0003676437416907084,
      "loss": 2.2421,
      "step": 11570
    },
    {
      "epoch": 69.76132930513594,
      "grad_norm": 0.36034682393074036,
      "learning_rate": 0.0003674315649134556,
      "loss": 2.2428,
      "step": 11580
    },
    {
      "epoch": 69.82175226586102,
      "grad_norm": 0.31606435775756836,
      "learning_rate": 0.0003672192795470884,
      "loss": 2.2377,
      "step": 11590
    },
    {
      "epoch": 69.8821752265861,
      "grad_norm": 0.3217523396015167,
      "learning_rate": 0.0003670068857879073,
      "loss": 2.2397,
      "step": 11600
    },
    {
      "epoch": 69.94259818731118,
      "grad_norm": 0.27938124537467957,
      "learning_rate": 0.00036679438383231314,
      "loss": 2.2319,
      "step": 11610
    },
    {
      "epoch": 70.0,
      "grad_norm": 0.3887472450733185,
      "learning_rate": 0.0003665817738768066,
      "loss": 2.1346,
      "step": 11620
    },
    {
      "epoch": 70.0,
      "eval_loss": 1.1315841674804688,
      "eval_runtime": 4.6115,
      "eval_samples_per_second": 3607.938,
      "eval_steps_per_second": 14.095,
      "step": 11620
    },
    {
      "epoch": 70.06042296072508,
      "grad_norm": 0.31098365783691406,
      "learning_rate": 0.00036636905611798847,
      "loss": 2.2384,
      "step": 11630
    },
    {
      "epoch": 70.12084592145015,
      "grad_norm": 0.3248622715473175,
      "learning_rate": 0.0003661562307525591,
      "loss": 2.2411,
      "step": 11640
    },
    {
      "epoch": 70.18126888217523,
      "grad_norm": 0.2950512766838074,
      "learning_rate": 0.00036594329797731847,
      "loss": 2.2379,
      "step": 11650
    },
    {
      "epoch": 70.24169184290031,
      "grad_norm": 0.33057427406311035,
      "learning_rate": 0.00036573025798916566,
      "loss": 2.2403,
      "step": 11660
    },
    {
      "epoch": 70.30211480362537,
      "grad_norm": 0.4009626507759094,
      "learning_rate": 0.00036551711098509903,
      "loss": 2.2373,
      "step": 11670
    },
    {
      "epoch": 70.36253776435045,
      "grad_norm": 0.32548433542251587,
      "learning_rate": 0.00036530385716221597,
      "loss": 2.2494,
      "step": 11680
    },
    {
      "epoch": 70.42296072507553,
      "grad_norm": 0.3275388181209564,
      "learning_rate": 0.00036509049671771236,
      "loss": 2.2456,
      "step": 11690
    },
    {
      "epoch": 70.4833836858006,
      "grad_norm": 0.3451833724975586,
      "learning_rate": 0.00036487702984888313,
      "loss": 2.2314,
      "step": 11700
    },
    {
      "epoch": 70.54380664652568,
      "grad_norm": 0.2873525321483612,
      "learning_rate": 0.0003646634567531212,
      "loss": 2.2329,
      "step": 11710
    },
    {
      "epoch": 70.60422960725076,
      "grad_norm": 0.3737557530403137,
      "learning_rate": 0.0003644497776279178,
      "loss": 2.2393,
      "step": 11720
    },
    {
      "epoch": 70.66465256797584,
      "grad_norm": 0.27768605947494507,
      "learning_rate": 0.0003642359926708625,
      "loss": 2.2348,
      "step": 11730
    },
    {
      "epoch": 70.72507552870091,
      "grad_norm": 0.34506216645240784,
      "learning_rate": 0.0003640221020796423,
      "loss": 2.2369,
      "step": 11740
    },
    {
      "epoch": 70.78549848942598,
      "grad_norm": 0.3962365984916687,
      "learning_rate": 0.0003638081060520423,
      "loss": 2.2448,
      "step": 11750
    },
    {
      "epoch": 70.84592145015105,
      "grad_norm": 0.3253629803657532,
      "learning_rate": 0.0003635940047859447,
      "loss": 2.2306,
      "step": 11760
    },
    {
      "epoch": 70.90634441087613,
      "grad_norm": 0.32049307227134705,
      "learning_rate": 0.00036337979847932947,
      "loss": 2.2313,
      "step": 11770
    },
    {
      "epoch": 70.96676737160121,
      "grad_norm": 0.3612254559993744,
      "learning_rate": 0.0003631654873302732,
      "loss": 2.2477,
      "step": 11780
    },
    {
      "epoch": 71.0,
      "eval_loss": 1.1335786581039429,
      "eval_runtime": 4.5828,
      "eval_samples_per_second": 3630.496,
      "eval_steps_per_second": 14.183,
      "step": 11786
    },
    {
      "epoch": 71.02416918429003,
      "grad_norm": 0.45385146141052246,
      "learning_rate": 0.0003629510715369497,
      "loss": 2.1312,
      "step": 11790
    },
    {
      "epoch": 71.08459214501511,
      "grad_norm": 0.3062910735607147,
      "learning_rate": 0.00036273655129762957,
      "loss": 2.2332,
      "step": 11800
    },
    {
      "epoch": 71.14501510574019,
      "grad_norm": 0.310110867023468,
      "learning_rate": 0.00036252192681068,
      "loss": 2.2323,
      "step": 11810
    },
    {
      "epoch": 71.20543806646526,
      "grad_norm": 0.34914982318878174,
      "learning_rate": 0.0003623071982745644,
      "loss": 2.2326,
      "step": 11820
    },
    {
      "epoch": 71.26586102719033,
      "grad_norm": 0.6616182923316956,
      "learning_rate": 0.00036209236588784265,
      "loss": 2.2309,
      "step": 11830
    },
    {
      "epoch": 71.3262839879154,
      "grad_norm": 0.31494268774986267,
      "learning_rate": 0.00036187742984917045,
      "loss": 2.2437,
      "step": 11840
    },
    {
      "epoch": 71.38670694864048,
      "grad_norm": 0.29099586606025696,
      "learning_rate": 0.00036166239035729944,
      "loss": 2.24,
      "step": 11850
    },
    {
      "epoch": 71.44712990936556,
      "grad_norm": 0.3379829227924347,
      "learning_rate": 0.0003614472476110768,
      "loss": 2.2341,
      "step": 11860
    },
    {
      "epoch": 71.50755287009063,
      "grad_norm": 0.35400983691215515,
      "learning_rate": 0.0003612320018094456,
      "loss": 2.2385,
      "step": 11870
    },
    {
      "epoch": 71.56797583081571,
      "grad_norm": 0.325152724981308,
      "learning_rate": 0.00036101665315144355,
      "loss": 2.2399,
      "step": 11880
    },
    {
      "epoch": 71.62839879154079,
      "grad_norm": 0.35966143012046814,
      "learning_rate": 0.000360801201836204,
      "loss": 2.2378,
      "step": 11890
    },
    {
      "epoch": 71.68882175226587,
      "grad_norm": 0.3718567192554474,
      "learning_rate": 0.00036058564806295504,
      "loss": 2.2332,
      "step": 11900
    },
    {
      "epoch": 71.74924471299093,
      "grad_norm": 0.3173072040081024,
      "learning_rate": 0.0003603699920310195,
      "loss": 2.2442,
      "step": 11910
    },
    {
      "epoch": 71.809667673716,
      "grad_norm": 0.40504011511802673,
      "learning_rate": 0.00036015423393981474,
      "loss": 2.2432,
      "step": 11920
    },
    {
      "epoch": 71.87009063444108,
      "grad_norm": 0.3072834014892578,
      "learning_rate": 0.00035993837398885255,
      "loss": 2.2397,
      "step": 11930
    },
    {
      "epoch": 71.93051359516616,
      "grad_norm": 0.4014952778816223,
      "learning_rate": 0.0003597224123777389,
      "loss": 2.2354,
      "step": 11940
    },
    {
      "epoch": 71.99093655589124,
      "grad_norm": 0.39010950922966003,
      "learning_rate": 0.0003595063493061738,
      "loss": 2.246,
      "step": 11950
    },
    {
      "epoch": 72.0,
      "eval_loss": 1.1331095695495605,
      "eval_runtime": 4.5878,
      "eval_samples_per_second": 3626.554,
      "eval_steps_per_second": 14.168,
      "step": 11952
    },
    {
      "epoch": 72.04833836858006,
      "grad_norm": 0.3464586138725281,
      "learning_rate": 0.0003592901849739511,
      "loss": 2.1185,
      "step": 11960
    },
    {
      "epoch": 72.10876132930514,
      "grad_norm": 0.3896467983722687,
      "learning_rate": 0.0003590739195809581,
      "loss": 2.2347,
      "step": 11970
    },
    {
      "epoch": 72.16918429003022,
      "grad_norm": 0.44383782148361206,
      "learning_rate": 0.0003588575533271757,
      "loss": 2.231,
      "step": 11980
    },
    {
      "epoch": 72.2296072507553,
      "grad_norm": 0.32510003447532654,
      "learning_rate": 0.0003586410864126781,
      "loss": 2.2315,
      "step": 11990
    },
    {
      "epoch": 72.29003021148036,
      "grad_norm": 0.356879323720932,
      "learning_rate": 0.0003584245190376324,
      "loss": 2.2337,
      "step": 12000
    },
    {
      "epoch": 72.35045317220543,
      "grad_norm": 0.4056278467178345,
      "learning_rate": 0.00035820785140229896,
      "loss": 2.2272,
      "step": 12010
    },
    {
      "epoch": 72.41087613293051,
      "grad_norm": 0.4480210840702057,
      "learning_rate": 0.0003579910837070304,
      "loss": 2.2206,
      "step": 12020
    },
    {
      "epoch": 72.47129909365559,
      "grad_norm": 0.31851789355278015,
      "learning_rate": 0.0003577742161522721,
      "loss": 2.2374,
      "step": 12030
    },
    {
      "epoch": 72.53172205438067,
      "grad_norm": 0.4064043164253235,
      "learning_rate": 0.00035755724893856176,
      "loss": 2.2499,
      "step": 12040
    },
    {
      "epoch": 72.59214501510574,
      "grad_norm": 0.3662525713443756,
      "learning_rate": 0.0003573401822665294,
      "loss": 2.2315,
      "step": 12050
    },
    {
      "epoch": 72.65256797583082,
      "grad_norm": 0.43261680006980896,
      "learning_rate": 0.00035712301633689667,
      "loss": 2.2506,
      "step": 12060
    },
    {
      "epoch": 72.7129909365559,
      "grad_norm": 0.4423702657222748,
      "learning_rate": 0.0003569057513504772,
      "loss": 2.2356,
      "step": 12070
    },
    {
      "epoch": 72.77341389728096,
      "grad_norm": 0.342592716217041,
      "learning_rate": 0.0003566883875081763,
      "loss": 2.2456,
      "step": 12080
    },
    {
      "epoch": 72.83383685800604,
      "grad_norm": 0.3620409667491913,
      "learning_rate": 0.00035647092501099045,
      "loss": 2.2425,
      "step": 12090
    },
    {
      "epoch": 72.89425981873111,
      "grad_norm": 0.394628643989563,
      "learning_rate": 0.0003562533640600075,
      "loss": 2.2231,
      "step": 12100
    },
    {
      "epoch": 72.95468277945619,
      "grad_norm": 0.32225659489631653,
      "learning_rate": 0.00035603570485640647,
      "loss": 2.2518,
      "step": 12110
    },
    {
      "epoch": 73.0,
      "eval_loss": 1.1323611736297607,
      "eval_runtime": 4.5705,
      "eval_samples_per_second": 3640.328,
      "eval_steps_per_second": 14.222,
      "step": 12118
    },
    {
      "epoch": 73.01208459214502,
      "grad_norm": 0.31471553444862366,
      "learning_rate": 0.00035581794760145696,
      "loss": 2.1274,
      "step": 12120
    },
    {
      "epoch": 73.07250755287009,
      "grad_norm": 0.47052428126335144,
      "learning_rate": 0.00035560009249651937,
      "loss": 2.2332,
      "step": 12130
    },
    {
      "epoch": 73.13293051359517,
      "grad_norm": 0.3690475523471832,
      "learning_rate": 0.0003553821397430447,
      "loss": 2.2249,
      "step": 12140
    },
    {
      "epoch": 73.19335347432025,
      "grad_norm": 0.37672388553619385,
      "learning_rate": 0.00035516408954257414,
      "loss": 2.2404,
      "step": 12150
    },
    {
      "epoch": 73.25377643504531,
      "grad_norm": 0.4626544117927551,
      "learning_rate": 0.00035494594209673874,
      "loss": 2.2344,
      "step": 12160
    },
    {
      "epoch": 73.31419939577039,
      "grad_norm": 0.3498583436012268,
      "learning_rate": 0.00035472769760726004,
      "loss": 2.2269,
      "step": 12170
    },
    {
      "epoch": 73.37462235649546,
      "grad_norm": 0.42787811160087585,
      "learning_rate": 0.00035450935627594877,
      "loss": 2.2405,
      "step": 12180
    },
    {
      "epoch": 73.43504531722054,
      "grad_norm": 0.33340150117874146,
      "learning_rate": 0.0003542909183047055,
      "loss": 2.2441,
      "step": 12190
    },
    {
      "epoch": 73.49546827794562,
      "grad_norm": 0.39825567603111267,
      "learning_rate": 0.00035407238389552017,
      "loss": 2.2265,
      "step": 12200
    },
    {
      "epoch": 73.5558912386707,
      "grad_norm": 0.3231055438518524,
      "learning_rate": 0.00035385375325047166,
      "loss": 2.243,
      "step": 12210
    },
    {
      "epoch": 73.61631419939577,
      "grad_norm": 0.36049631237983704,
      "learning_rate": 0.0003536350265717281,
      "loss": 2.2454,
      "step": 12220
    },
    {
      "epoch": 73.67673716012085,
      "grad_norm": 0.3637656271457672,
      "learning_rate": 0.0003534162040615463,
      "loss": 2.2354,
      "step": 12230
    },
    {
      "epoch": 73.73716012084593,
      "grad_norm": 0.3425616919994354,
      "learning_rate": 0.00035319728592227167,
      "loss": 2.232,
      "step": 12240
    },
    {
      "epoch": 73.79758308157099,
      "grad_norm": 0.3233303129673004,
      "learning_rate": 0.0003529782723563382,
      "loss": 2.2267,
      "step": 12250
    },
    {
      "epoch": 73.85800604229607,
      "grad_norm": 0.3678576350212097,
      "learning_rate": 0.0003527591635662679,
      "loss": 2.2339,
      "step": 12260
    },
    {
      "epoch": 73.91842900302115,
      "grad_norm": 0.3451453447341919,
      "learning_rate": 0.000352539959754671,
      "loss": 2.237,
      "step": 12270
    },
    {
      "epoch": 73.97885196374622,
      "grad_norm": 0.3635857105255127,
      "learning_rate": 0.0003523206611242456,
      "loss": 2.2527,
      "step": 12280
    },
    {
      "epoch": 74.0,
      "eval_loss": 1.1330645084381104,
      "eval_runtime": 4.6144,
      "eval_samples_per_second": 3605.638,
      "eval_steps_per_second": 14.086,
      "step": 12284
    },
    {
      "epoch": 74.03625377643505,
      "grad_norm": 0.32845333218574524,
      "learning_rate": 0.0003521012678777773,
      "loss": 2.1179,
      "step": 12290
    },
    {
      "epoch": 74.09667673716012,
      "grad_norm": 0.3487478792667389,
      "learning_rate": 0.00035188178021813924,
      "loss": 2.2297,
      "step": 12300
    },
    {
      "epoch": 74.1570996978852,
      "grad_norm": 0.35326069593429565,
      "learning_rate": 0.0003516621983482921,
      "loss": 2.2353,
      "step": 12310
    },
    {
      "epoch": 74.21752265861028,
      "grad_norm": 0.37113019824028015,
      "learning_rate": 0.0003514425224712835,
      "loss": 2.2297,
      "step": 12320
    },
    {
      "epoch": 74.27794561933534,
      "grad_norm": 0.37244030833244324,
      "learning_rate": 0.00035122275279024783,
      "loss": 2.2217,
      "step": 12330
    },
    {
      "epoch": 74.33836858006042,
      "grad_norm": 0.41633158922195435,
      "learning_rate": 0.00035100288950840655,
      "loss": 2.2309,
      "step": 12340
    },
    {
      "epoch": 74.3987915407855,
      "grad_norm": 0.36302101612091064,
      "learning_rate": 0.00035078293282906747,
      "loss": 2.2333,
      "step": 12350
    },
    {
      "epoch": 74.45921450151057,
      "grad_norm": 0.40511828660964966,
      "learning_rate": 0.00035056288295562475,
      "loss": 2.2351,
      "step": 12360
    },
    {
      "epoch": 74.51963746223565,
      "grad_norm": 0.4783934950828552,
      "learning_rate": 0.00035034274009155896,
      "loss": 2.2443,
      "step": 12370
    },
    {
      "epoch": 74.58006042296073,
      "grad_norm": 0.31800639629364014,
      "learning_rate": 0.0003501225044404363,
      "loss": 2.2283,
      "step": 12380
    },
    {
      "epoch": 74.6404833836858,
      "grad_norm": 0.34123823046684265,
      "learning_rate": 0.00034990217620590894,
      "loss": 2.2398,
      "step": 12390
    },
    {
      "epoch": 74.70090634441088,
      "grad_norm": 0.3722665309906006,
      "learning_rate": 0.0003496817555917147,
      "loss": 2.2362,
      "step": 12400
    },
    {
      "epoch": 74.76132930513594,
      "grad_norm": 0.34230151772499084,
      "learning_rate": 0.0003494612428016769,
      "loss": 2.2342,
      "step": 12410
    },
    {
      "epoch": 74.82175226586102,
      "grad_norm": 0.36442312598228455,
      "learning_rate": 0.0003492406380397039,
      "loss": 2.2384,
      "step": 12420
    },
    {
      "epoch": 74.8821752265861,
      "grad_norm": 0.3638761341571808,
      "learning_rate": 0.00034901994150978924,
      "loss": 2.2348,
      "step": 12430
    },
    {
      "epoch": 74.94259818731118,
      "grad_norm": 0.3145606517791748,
      "learning_rate": 0.0003487991534160112,
      "loss": 2.2409,
      "step": 12440
    },
    {
      "epoch": 75.0,
      "grad_norm": 0.33280467987060547,
      "learning_rate": 0.00034857827396253294,
      "loss": 2.1183,
      "step": 12450
    },
    {
      "epoch": 75.0,
      "eval_loss": 1.1321825981140137,
      "eval_runtime": 4.5957,
      "eval_samples_per_second": 3620.336,
      "eval_steps_per_second": 14.144,
      "step": 12450
    },
    {
      "epoch": 75.06042296072508,
      "grad_norm": 0.3187044858932495,
      "learning_rate": 0.0003483573033536018,
      "loss": 2.2325,
      "step": 12460
    },
    {
      "epoch": 75.12084592145015,
      "grad_norm": 0.330821692943573,
      "learning_rate": 0.00034813624179354973,
      "loss": 2.2223,
      "step": 12470
    },
    {
      "epoch": 75.18126888217523,
      "grad_norm": 0.41635066270828247,
      "learning_rate": 0.0003479150894867926,
      "loss": 2.2204,
      "step": 12480
    },
    {
      "epoch": 75.24169184290031,
      "grad_norm": 0.3697262406349182,
      "learning_rate": 0.0003476938466378301,
      "loss": 2.2333,
      "step": 12490
    },
    {
      "epoch": 75.30211480362537,
      "grad_norm": 0.35759279131889343,
      "learning_rate": 0.0003474725134512459,
      "loss": 2.2187,
      "step": 12500
    },
    {
      "epoch": 75.36253776435045,
      "grad_norm": 0.3946431279182434,
      "learning_rate": 0.0003472510901317071,
      "loss": 2.2293,
      "step": 12510
    },
    {
      "epoch": 75.42296072507553,
      "grad_norm": 0.316069096326828,
      "learning_rate": 0.00034702957688396394,
      "loss": 2.2254,
      "step": 12520
    },
    {
      "epoch": 75.4833836858006,
      "grad_norm": 0.35428595542907715,
      "learning_rate": 0.00034680797391285013,
      "loss": 2.2339,
      "step": 12530
    },
    {
      "epoch": 75.54380664652568,
      "grad_norm": 0.3613109588623047,
      "learning_rate": 0.00034658628142328216,
      "loss": 2.2365,
      "step": 12540
    },
    {
      "epoch": 75.60422960725076,
      "grad_norm": 0.6133463382720947,
      "learning_rate": 0.0003463644996202594,
      "loss": 2.2267,
      "step": 12550
    },
    {
      "epoch": 75.66465256797584,
      "grad_norm": 0.42266470193862915,
      "learning_rate": 0.0003461426287088638,
      "loss": 2.242,
      "step": 12560
    },
    {
      "epoch": 75.72507552870091,
      "grad_norm": 0.3598284423351288,
      "learning_rate": 0.0003459206688942596,
      "loss": 2.2316,
      "step": 12570
    },
    {
      "epoch": 75.78549848942598,
      "grad_norm": 0.5093642473220825,
      "learning_rate": 0.0003456986203816933,
      "loss": 2.2368,
      "step": 12580
    },
    {
      "epoch": 75.84592145015105,
      "grad_norm": 0.32498103380203247,
      "learning_rate": 0.0003454764833764934,
      "loss": 2.2411,
      "step": 12590
    },
    {
      "epoch": 75.90634441087613,
      "grad_norm": 0.3127559721469879,
      "learning_rate": 0.0003452542580840704,
      "loss": 2.2457,
      "step": 12600
    },
    {
      "epoch": 75.96676737160121,
      "grad_norm": 0.5113418698310852,
      "learning_rate": 0.0003450319447099163,
      "loss": 2.24,
      "step": 12610
    },
    {
      "epoch": 76.0,
      "eval_loss": 1.1324186325073242,
      "eval_runtime": 4.5668,
      "eval_samples_per_second": 3643.289,
      "eval_steps_per_second": 14.233,
      "step": 12616
    },
    {
      "epoch": 76.02416918429003,
      "grad_norm": 0.3681958317756653,
      "learning_rate": 0.00034480954345960437,
      "loss": 2.1141,
      "step": 12620
    },
    {
      "epoch": 76.08459214501511,
      "grad_norm": 0.36078324913978577,
      "learning_rate": 0.0003445870545387895,
      "loss": 2.2226,
      "step": 12630
    },
    {
      "epoch": 76.14501510574019,
      "grad_norm": 0.3667311668395996,
      "learning_rate": 0.0003443644781532073,
      "loss": 2.2213,
      "step": 12640
    },
    {
      "epoch": 76.20543806646526,
      "grad_norm": 0.4462202489376068,
      "learning_rate": 0.00034414181450867466,
      "loss": 2.2348,
      "step": 12650
    },
    {
      "epoch": 76.26586102719033,
      "grad_norm": 0.3776291012763977,
      "learning_rate": 0.00034391906381108883,
      "loss": 2.2276,
      "step": 12660
    },
    {
      "epoch": 76.3262839879154,
      "grad_norm": 0.491370290517807,
      "learning_rate": 0.00034369622626642763,
      "loss": 2.22,
      "step": 12670
    },
    {
      "epoch": 76.38670694864048,
      "grad_norm": 0.38825035095214844,
      "learning_rate": 0.0003434733020807492,
      "loss": 2.2295,
      "step": 12680
    },
    {
      "epoch": 76.44712990936556,
      "grad_norm": 0.39409589767456055,
      "learning_rate": 0.0003432502914601919,
      "loss": 2.226,
      "step": 12690
    },
    {
      "epoch": 76.50755287009063,
      "grad_norm": 0.43803152441978455,
      "learning_rate": 0.00034302719461097375,
      "loss": 2.2283,
      "step": 12700
    },
    {
      "epoch": 76.56797583081571,
      "grad_norm": 0.6067948937416077,
      "learning_rate": 0.00034280401173939287,
      "loss": 2.2384,
      "step": 12710
    },
    {
      "epoch": 76.62839879154079,
      "grad_norm": 0.4061751663684845,
      "learning_rate": 0.0003425807430518266,
      "loss": 2.2361,
      "step": 12720
    },
    {
      "epoch": 76.68882175226587,
      "grad_norm": 0.4379178285598755,
      "learning_rate": 0.0003423573887547319,
      "loss": 2.2413,
      "step": 12730
    },
    {
      "epoch": 76.74924471299093,
      "grad_norm": 0.37865108251571655,
      "learning_rate": 0.00034213394905464477,
      "loss": 2.2282,
      "step": 12740
    },
    {
      "epoch": 76.809667673716,
      "grad_norm": 0.36513444781303406,
      "learning_rate": 0.00034191042415818,
      "loss": 2.2361,
      "step": 12750
    },
    {
      "epoch": 76.87009063444108,
      "grad_norm": 0.411624014377594,
      "learning_rate": 0.0003416868142720316,
      "loss": 2.2376,
      "step": 12760
    },
    {
      "epoch": 76.93051359516616,
      "grad_norm": 0.43981704115867615,
      "learning_rate": 0.0003414631196029717,
      "loss": 2.2358,
      "step": 12770
    },
    {
      "epoch": 76.99093655589124,
      "grad_norm": 0.33382299542427063,
      "learning_rate": 0.0003412393403578511,
      "loss": 2.2422,
      "step": 12780
    },
    {
      "epoch": 77.0,
      "eval_loss": 1.1334882974624634,
      "eval_runtime": 4.5954,
      "eval_samples_per_second": 3620.562,
      "eval_steps_per_second": 14.145,
      "step": 12782
    },
    {
      "epoch": 77.04833836858006,
      "grad_norm": 0.3940269649028778,
      "learning_rate": 0.00034101547674359877,
      "loss": 2.1131,
      "step": 12790
    },
    {
      "epoch": 77.10876132930514,
      "grad_norm": 0.3996330797672272,
      "learning_rate": 0.00034079152896722165,
      "loss": 2.2197,
      "step": 12800
    },
    {
      "epoch": 77.16918429003022,
      "grad_norm": 0.42188760638237,
      "learning_rate": 0.0003405674972358046,
      "loss": 2.2247,
      "step": 12810
    },
    {
      "epoch": 77.2296072507553,
      "grad_norm": 0.5906282067298889,
      "learning_rate": 0.0003403433817565099,
      "loss": 2.2247,
      "step": 12820
    },
    {
      "epoch": 77.29003021148036,
      "grad_norm": 0.40646710991859436,
      "learning_rate": 0.0003401191827365775,
      "loss": 2.2132,
      "step": 12830
    },
    {
      "epoch": 77.35045317220543,
      "grad_norm": 0.4396035969257355,
      "learning_rate": 0.0003398949003833246,
      "loss": 2.2322,
      "step": 12840
    },
    {
      "epoch": 77.41087613293051,
      "grad_norm": 0.40350019931793213,
      "learning_rate": 0.0003396705349041451,
      "loss": 2.2394,
      "step": 12850
    },
    {
      "epoch": 77.47129909365559,
      "grad_norm": 0.3672092854976654,
      "learning_rate": 0.0003394460865065104,
      "loss": 2.2288,
      "step": 12860
    },
    {
      "epoch": 77.53172205438067,
      "grad_norm": 0.3344307541847229,
      "learning_rate": 0.00033922155539796797,
      "loss": 2.2308,
      "step": 12870
    },
    {
      "epoch": 77.59214501510574,
      "grad_norm": 0.41802746057510376,
      "learning_rate": 0.00033899694178614207,
      "loss": 2.2306,
      "step": 12880
    },
    {
      "epoch": 77.65256797583082,
      "grad_norm": 0.4465418756008148,
      "learning_rate": 0.00033877224587873316,
      "loss": 2.2298,
      "step": 12890
    },
    {
      "epoch": 77.7129909365559,
      "grad_norm": 0.5812720656394958,
      "learning_rate": 0.00033854746788351787,
      "loss": 2.2481,
      "step": 12900
    },
    {
      "epoch": 77.77341389728096,
      "grad_norm": 0.4417446255683899,
      "learning_rate": 0.0003383226080083487,
      "loss": 2.2255,
      "step": 12910
    },
    {
      "epoch": 77.83383685800604,
      "grad_norm": 0.4756907820701599,
      "learning_rate": 0.0003380976664611538,
      "loss": 2.2362,
      "step": 12920
    },
    {
      "epoch": 77.89425981873111,
      "grad_norm": 0.44536828994750977,
      "learning_rate": 0.00033787264344993685,
      "loss": 2.2256,
      "step": 12930
    },
    {
      "epoch": 77.95468277945619,
      "grad_norm": 0.47824883460998535,
      "learning_rate": 0.00033764753918277704,
      "loss": 2.2382,
      "step": 12940
    },
    {
      "epoch": 78.0,
      "eval_loss": 1.1329951286315918,
      "eval_runtime": 4.6014,
      "eval_samples_per_second": 3615.859,
      "eval_steps_per_second": 14.126,
      "step": 12948
    },
    {
      "epoch": 78.01208459214502,
      "grad_norm": 0.3851592540740967,
      "learning_rate": 0.00033742235386782847,
      "loss": 2.1072,
      "step": 12950
    },
    {
      "epoch": 78.07250755287009,
      "grad_norm": 0.38508349657058716,
      "learning_rate": 0.00033719708771332035,
      "loss": 2.2256,
      "step": 12960
    },
    {
      "epoch": 78.13293051359517,
      "grad_norm": 0.4239301383495331,
      "learning_rate": 0.0003369717409275566,
      "loss": 2.2322,
      "step": 12970
    },
    {
      "epoch": 78.19335347432025,
      "grad_norm": 0.407367080450058,
      "learning_rate": 0.0003367463137189156,
      "loss": 2.236,
      "step": 12980
    },
    {
      "epoch": 78.25377643504531,
      "grad_norm": 0.5846806168556213,
      "learning_rate": 0.0003365208062958502,
      "loss": 2.2158,
      "step": 12990
    },
    {
      "epoch": 78.31419939577039,
      "grad_norm": 0.5365827083587646,
      "learning_rate": 0.00033629521886688736,
      "loss": 2.2337,
      "step": 13000
    },
    {
      "epoch": 78.37462235649546,
      "grad_norm": 0.4031476378440857,
      "learning_rate": 0.00033606955164062807,
      "loss": 2.2295,
      "step": 13010
    },
    {
      "epoch": 78.43504531722054,
      "grad_norm": 0.3775995969772339,
      "learning_rate": 0.0003358438048257472,
      "loss": 2.2248,
      "step": 13020
    },
    {
      "epoch": 78.49546827794562,
      "grad_norm": 0.4280972480773926,
      "learning_rate": 0.00033561797863099283,
      "loss": 2.2304,
      "step": 13030
    },
    {
      "epoch": 78.5558912386707,
      "grad_norm": 0.4358317255973816,
      "learning_rate": 0.00033539207326518705,
      "loss": 2.2307,
      "step": 13040
    },
    {
      "epoch": 78.61631419939577,
      "grad_norm": 0.43647557497024536,
      "learning_rate": 0.00033516608893722474,
      "loss": 2.2349,
      "step": 13050
    },
    {
      "epoch": 78.67673716012085,
      "grad_norm": 0.3955855369567871,
      "learning_rate": 0.0003349400258560737,
      "loss": 2.2317,
      "step": 13060
    },
    {
      "epoch": 78.73716012084593,
      "grad_norm": 0.42646974325180054,
      "learning_rate": 0.00033471388423077496,
      "loss": 2.2247,
      "step": 13070
    },
    {
      "epoch": 78.79758308157099,
      "grad_norm": 0.37573564052581787,
      "learning_rate": 0.000334487664270442,
      "loss": 2.2135,
      "step": 13080
    },
    {
      "epoch": 78.85800604229607,
      "grad_norm": 0.34430351853370667,
      "learning_rate": 0.00033426136618426046,
      "loss": 2.2367,
      "step": 13090
    },
    {
      "epoch": 78.91842900302115,
      "grad_norm": 0.4541204273700714,
      "learning_rate": 0.00033403499018148865,
      "loss": 2.2298,
      "step": 13100
    },
    {
      "epoch": 78.97885196374622,
      "grad_norm": 0.6576104760169983,
      "learning_rate": 0.0003338085364714566,
      "loss": 2.2222,
      "step": 13110
    },
    {
      "epoch": 79.0,
      "eval_loss": 1.1327812671661377,
      "eval_runtime": 4.7468,
      "eval_samples_per_second": 3505.121,
      "eval_steps_per_second": 13.694,
      "step": 13114
    },
    {
      "epoch": 79.03625377643505,
      "grad_norm": 0.3883368670940399,
      "learning_rate": 0.0003335820052635665,
      "loss": 2.1105,
      "step": 13120
    },
    {
      "epoch": 79.09667673716012,
      "grad_norm": 0.410986989736557,
      "learning_rate": 0.00033335539676729195,
      "loss": 2.2213,
      "step": 13130
    },
    {
      "epoch": 79.1570996978852,
      "grad_norm": 0.39489224553108215,
      "learning_rate": 0.00033312871119217815,
      "loss": 2.2218,
      "step": 13140
    },
    {
      "epoch": 79.21752265861028,
      "grad_norm": 0.44617822766304016,
      "learning_rate": 0.00033290194874784144,
      "loss": 2.2255,
      "step": 13150
    },
    {
      "epoch": 79.27794561933534,
      "grad_norm": 0.33156532049179077,
      "learning_rate": 0.0003326751096439694,
      "loss": 2.227,
      "step": 13160
    },
    {
      "epoch": 79.33836858006042,
      "grad_norm": 0.3472977876663208,
      "learning_rate": 0.00033244819409032053,
      "loss": 2.2354,
      "step": 13170
    },
    {
      "epoch": 79.3987915407855,
      "grad_norm": 0.35088953375816345,
      "learning_rate": 0.00033222120229672375,
      "loss": 2.2208,
      "step": 13180
    },
    {
      "epoch": 79.45921450151057,
      "grad_norm": 0.4524199366569519,
      "learning_rate": 0.0003319941344730788,
      "loss": 2.226,
      "step": 13190
    },
    {
      "epoch": 79.51963746223565,
      "grad_norm": 0.3686175048351288,
      "learning_rate": 0.00033176699082935546,
      "loss": 2.2295,
      "step": 13200
    },
    {
      "epoch": 79.58006042296073,
      "grad_norm": 0.3916463851928711,
      "learning_rate": 0.0003315397715755938,
      "loss": 2.2326,
      "step": 13210
    },
    {
      "epoch": 79.6404833836858,
      "grad_norm": 0.47049060463905334,
      "learning_rate": 0.0003313124769219037,
      "loss": 2.2216,
      "step": 13220
    },
    {
      "epoch": 79.70090634441088,
      "grad_norm": 0.5196427702903748,
      "learning_rate": 0.0003310851070784649,
      "loss": 2.2253,
      "step": 13230
    },
    {
      "epoch": 79.76132930513594,
      "grad_norm": 0.35303688049316406,
      "learning_rate": 0.0003308576622555265,
      "loss": 2.2289,
      "step": 13240
    },
    {
      "epoch": 79.82175226586102,
      "grad_norm": 0.41899386048316956,
      "learning_rate": 0.00033063014266340707,
      "loss": 2.2226,
      "step": 13250
    },
    {
      "epoch": 79.8821752265861,
      "grad_norm": 0.4260421097278595,
      "learning_rate": 0.0003304025485124942,
      "loss": 2.2292,
      "step": 13260
    },
    {
      "epoch": 79.94259818731118,
      "grad_norm": 0.38487136363983154,
      "learning_rate": 0.0003301748800132446,
      "loss": 2.2252,
      "step": 13270
    },
    {
      "epoch": 80.0,
      "grad_norm": 0.45472246408462524,
      "learning_rate": 0.00032994713737618343,
      "loss": 2.1202,
      "step": 13280
    },
    {
      "epoch": 80.0,
      "eval_loss": 1.1340298652648926,
      "eval_runtime": 4.595,
      "eval_samples_per_second": 3620.917,
      "eval_steps_per_second": 14.146,
      "step": 13280
    },
    {
      "epoch": 80.06042296072508,
      "grad_norm": 0.4174821376800537,
      "learning_rate": 0.0003297193208119047,
      "loss": 2.2225,
      "step": 13290
    },
    {
      "epoch": 80.12084592145015,
      "grad_norm": 0.44878944754600525,
      "learning_rate": 0.00032949143053107065,
      "loss": 2.2211,
      "step": 13300
    },
    {
      "epoch": 80.18126888217523,
      "grad_norm": 0.4391552209854126,
      "learning_rate": 0.0003292634667444117,
      "loss": 2.2103,
      "step": 13310
    },
    {
      "epoch": 80.24169184290031,
      "grad_norm": 0.3689577877521515,
      "learning_rate": 0.00032903542966272633,
      "loss": 2.2276,
      "step": 13320
    },
    {
      "epoch": 80.30211480362537,
      "grad_norm": 0.3994458019733429,
      "learning_rate": 0.00032880731949688064,
      "loss": 2.2279,
      "step": 13330
    },
    {
      "epoch": 80.36253776435045,
      "grad_norm": 0.44236066937446594,
      "learning_rate": 0.00032857913645780834,
      "loss": 2.2193,
      "step": 13340
    },
    {
      "epoch": 80.42296072507553,
      "grad_norm": 0.489192396402359,
      "learning_rate": 0.0003283508807565106,
      "loss": 2.2303,
      "step": 13350
    },
    {
      "epoch": 80.4833836858006,
      "grad_norm": 0.41745975613594055,
      "learning_rate": 0.00032812255260405586,
      "loss": 2.2313,
      "step": 13360
    },
    {
      "epoch": 80.54380664652568,
      "grad_norm": 0.36684301495552063,
      "learning_rate": 0.0003278941522115794,
      "loss": 2.2185,
      "step": 13370
    },
    {
      "epoch": 80.60422960725076,
      "grad_norm": 0.4095477759838104,
      "learning_rate": 0.0003276656797902833,
      "loss": 2.2297,
      "step": 13380
    },
    {
      "epoch": 80.66465256797584,
      "grad_norm": 0.3842878043651581,
      "learning_rate": 0.00032743713555143615,
      "loss": 2.2194,
      "step": 13390
    },
    {
      "epoch": 80.72507552870091,
      "grad_norm": 0.3703921139240265,
      "learning_rate": 0.00032720851970637337,
      "loss": 2.2345,
      "step": 13400
    },
    {
      "epoch": 80.78549848942598,
      "grad_norm": 0.3741932511329651,
      "learning_rate": 0.0003269798324664962,
      "loss": 2.2293,
      "step": 13410
    },
    {
      "epoch": 80.84592145015105,
      "grad_norm": 0.35263702273368835,
      "learning_rate": 0.0003267510740432719,
      "loss": 2.2132,
      "step": 13420
    },
    {
      "epoch": 80.90634441087613,
      "grad_norm": 0.38136380910873413,
      "learning_rate": 0.0003265222446482339,
      "loss": 2.2424,
      "step": 13430
    },
    {
      "epoch": 80.96676737160121,
      "grad_norm": 0.4297843873500824,
      "learning_rate": 0.0003262933444929808,
      "loss": 2.2305,
      "step": 13440
    },
    {
      "epoch": 81.0,
      "eval_loss": 1.1344271898269653,
      "eval_runtime": 4.556,
      "eval_samples_per_second": 3651.89,
      "eval_steps_per_second": 14.267,
      "step": 13446
    },
    {
      "epoch": 81.02416918429003,
      "grad_norm": 0.3761313855648041,
      "learning_rate": 0.000326064373789177,
      "loss": 2.1151,
      "step": 13450
    },
    {
      "epoch": 81.08459214501511,
      "grad_norm": 0.3855940103530884,
      "learning_rate": 0.00032583533274855203,
      "loss": 2.2236,
      "step": 13460
    },
    {
      "epoch": 81.14501510574019,
      "grad_norm": 0.3837820589542389,
      "learning_rate": 0.0003256062215829003,
      "loss": 2.2167,
      "step": 13470
    },
    {
      "epoch": 81.20543806646526,
      "grad_norm": 0.39934492111206055,
      "learning_rate": 0.0003253770405040812,
      "loss": 2.223,
      "step": 13480
    },
    {
      "epoch": 81.26586102719033,
      "grad_norm": 0.33489182591438293,
      "learning_rate": 0.00032514778972401884,
      "loss": 2.2307,
      "step": 13490
    },
    {
      "epoch": 81.3262839879154,
      "grad_norm": 0.3846248388290405,
      "learning_rate": 0.00032491846945470167,
      "loss": 2.2168,
      "step": 13500
    },
    {
      "epoch": 81.38670694864048,
      "grad_norm": 0.35545217990875244,
      "learning_rate": 0.0003246890799081824,
      "loss": 2.2312,
      "step": 13510
    },
    {
      "epoch": 81.44712990936556,
      "grad_norm": 0.35173124074935913,
      "learning_rate": 0.00032445962129657786,
      "loss": 2.2253,
      "step": 13520
    },
    {
      "epoch": 81.50755287009063,
      "grad_norm": 0.4343181550502777,
      "learning_rate": 0.00032423009383206875,
      "loss": 2.2237,
      "step": 13530
    },
    {
      "epoch": 81.56797583081571,
      "grad_norm": 0.31282839179039,
      "learning_rate": 0.00032400049772689926,
      "loss": 2.2337,
      "step": 13540
    },
    {
      "epoch": 81.62839879154079,
      "grad_norm": 0.3788640797138214,
      "learning_rate": 0.00032377083319337744,
      "loss": 2.2201,
      "step": 13550
    },
    {
      "epoch": 81.68882175226587,
      "grad_norm": 0.4196913540363312,
      "learning_rate": 0.0003235411004438741,
      "loss": 2.2302,
      "step": 13560
    },
    {
      "epoch": 81.74924471299093,
      "grad_norm": 0.3724115490913391,
      "learning_rate": 0.0003233112996908236,
      "loss": 2.2297,
      "step": 13570
    },
    {
      "epoch": 81.809667673716,
      "grad_norm": 0.33969104290008545,
      "learning_rate": 0.0003230814311467229,
      "loss": 2.2261,
      "step": 13580
    },
    {
      "epoch": 81.87009063444108,
      "grad_norm": 0.37715187668800354,
      "learning_rate": 0.0003228514950241317,
      "loss": 2.2127,
      "step": 13590
    },
    {
      "epoch": 81.93051359516616,
      "grad_norm": 0.34967002272605896,
      "learning_rate": 0.00032262149153567223,
      "loss": 2.2206,
      "step": 13600
    },
    {
      "epoch": 81.99093655589124,
      "grad_norm": 0.3572072386741638,
      "learning_rate": 0.00032239142089402904,
      "loss": 2.2212,
      "step": 13610
    },
    {
      "epoch": 82.0,
      "eval_loss": 1.1343107223510742,
      "eval_runtime": 4.7355,
      "eval_samples_per_second": 3513.468,
      "eval_steps_per_second": 13.726,
      "step": 13612
    },
    {
      "epoch": 82.0,
      "step": 13612,
      "total_flos": 1.873806051822797e+16,
      "train_loss": 2.4579355708122814,
      "train_runtime": 3743.2467,
      "train_samples_per_second": 4518.11,
      "train_steps_per_second": 8.816
    }
  ],
  "logging_steps": 10,
  "max_steps": 33000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 200,
  "save_steps": 1000,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 20,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 20
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.873806051822797e+16,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
