{
  "best_metric": 1.058334469795227,
  "best_model_checkpoint": "./ckpt/Office_Products/checkpoint-2736",
  "epoch": 56.0,
  "eval_steps": 1000,
  "global_step": 4256,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.13245033112582782,
      "grad_norm": 12.185833930969238,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 20.926,
      "step": 10
    },
    {
      "epoch": 0.26490066225165565,
      "grad_norm": 4.462977886199951,
      "learning_rate": 6.666666666666667e-05,
      "loss": 17.9484,
      "step": 20
    },
    {
      "epoch": 0.3973509933774834,
      "grad_norm": 3.8322126865386963,
      "learning_rate": 0.0001,
      "loss": 15.8304,
      "step": 30
    },
    {
      "epoch": 0.5298013245033113,
      "grad_norm": 3.39656925201416,
      "learning_rate": 0.00013333333333333334,
      "loss": 13.2934,
      "step": 40
    },
    {
      "epoch": 0.6622516556291391,
      "grad_norm": 2.6066207885742188,
      "learning_rate": 0.00016666666666666666,
      "loss": 10.3884,
      "step": 50
    },
    {
      "epoch": 0.7947019867549668,
      "grad_norm": 1.7636091709136963,
      "learning_rate": 0.0002,
      "loss": 8.2749,
      "step": 60
    },
    {
      "epoch": 0.9271523178807947,
      "grad_norm": 1.206292986869812,
      "learning_rate": 0.00023333333333333333,
      "loss": 6.962,
      "step": 70
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.9845991134643555,
      "eval_runtime": 1.5552,
      "eval_samples_per_second": 3154.036,
      "eval_steps_per_second": 12.86,
      "step": 76
    },
    {
      "epoch": 1.0529801324503312,
      "grad_norm": 1.0209394693374634,
      "learning_rate": 0.0002666666666666667,
      "loss": 6.0285,
      "step": 80
    },
    {
      "epoch": 1.185430463576159,
      "grad_norm": 0.9563973546028137,
      "learning_rate": 0.0003,
      "loss": 5.9243,
      "step": 90
    },
    {
      "epoch": 1.3178807947019868,
      "grad_norm": 0.8884422183036804,
      "learning_rate": 0.0003333333333333333,
      "loss": 5.7362,
      "step": 100
    },
    {
      "epoch": 1.4503311258278146,
      "grad_norm": 0.802571177482605,
      "learning_rate": 0.00036666666666666667,
      "loss": 5.5272,
      "step": 110
    },
    {
      "epoch": 1.5827814569536423,
      "grad_norm": 0.7399673461914062,
      "learning_rate": 0.0004,
      "loss": 5.3646,
      "step": 120
    },
    {
      "epoch": 1.7152317880794703,
      "grad_norm": 0.736685574054718,
      "learning_rate": 0.00043333333333333337,
      "loss": 5.2021,
      "step": 130
    },
    {
      "epoch": 1.847682119205298,
      "grad_norm": 0.7152050733566284,
      "learning_rate": 0.00046666666666666666,
      "loss": 5.0967,
      "step": 140
    },
    {
      "epoch": 1.980132450331126,
      "grad_norm": 0.6402746438980103,
      "learning_rate": 0.0005,
      "loss": 4.9719,
      "step": 150
    },
    {
      "epoch": 2.0,
      "eval_loss": 2.3971550464630127,
      "eval_runtime": 1.5451,
      "eval_samples_per_second": 3174.589,
      "eval_steps_per_second": 12.944,
      "step": 152
    },
    {
      "epoch": 2.1059602649006623,
      "grad_norm": 0.7911766171455383,
      "learning_rate": 0.0004999994405559115,
      "loss": 4.6025,
      "step": 160
    },
    {
      "epoch": 2.23841059602649,
      "grad_norm": 0.6332241892814636,
      "learning_rate": 0.0004999977622261499,
      "loss": 4.728,
      "step": 170
    },
    {
      "epoch": 2.370860927152318,
      "grad_norm": 0.565487802028656,
      "learning_rate": 0.0004999949650182266,
      "loss": 4.6319,
      "step": 180
    },
    {
      "epoch": 2.5033112582781456,
      "grad_norm": 1.229877233505249,
      "learning_rate": 0.0004999910489446607,
      "loss": 4.4942,
      "step": 190
    },
    {
      "epoch": 2.6357615894039736,
      "grad_norm": 0.5488918423652649,
      "learning_rate": 0.0004999860140229787,
      "loss": 4.3948,
      "step": 200
    },
    {
      "epoch": 2.7682119205298013,
      "grad_norm": 0.7128369212150574,
      "learning_rate": 0.0004999798602757148,
      "loss": 4.3222,
      "step": 210
    },
    {
      "epoch": 2.9006622516556293,
      "grad_norm": 0.5057374835014343,
      "learning_rate": 0.0004999725877304103,
      "loss": 4.2342,
      "step": 220
    },
    {
      "epoch": 3.0,
      "eval_loss": 2.040374994277954,
      "eval_runtime": 1.5463,
      "eval_samples_per_second": 3172.135,
      "eval_steps_per_second": 12.934,
      "step": 228
    },
    {
      "epoch": 3.0264900662251657,
      "grad_norm": 0.56341153383255,
      "learning_rate": 0.000499964196419614,
      "loss": 3.9376,
      "step": 230
    },
    {
      "epoch": 3.1589403973509933,
      "grad_norm": 0.5337167978286743,
      "learning_rate": 0.0004999546863808815,
      "loss": 4.0698,
      "step": 240
    },
    {
      "epoch": 3.2913907284768213,
      "grad_norm": 0.4597567021846771,
      "learning_rate": 0.0004999440576567755,
      "loss": 3.9765,
      "step": 250
    },
    {
      "epoch": 3.423841059602649,
      "grad_norm": 0.4959582984447479,
      "learning_rate": 0.0004999323102948655,
      "loss": 3.9112,
      "step": 260
    },
    {
      "epoch": 3.556291390728477,
      "grad_norm": 0.852507472038269,
      "learning_rate": 0.0004999194443477273,
      "loss": 3.8059,
      "step": 270
    },
    {
      "epoch": 3.6887417218543046,
      "grad_norm": 0.4186757504940033,
      "learning_rate": 0.0004999054598729433,
      "loss": 3.761,
      "step": 280
    },
    {
      "epoch": 3.821192052980132,
      "grad_norm": 0.42257919907569885,
      "learning_rate": 0.0004998903569331016,
      "loss": 3.6822,
      "step": 290
    },
    {
      "epoch": 3.9536423841059603,
      "grad_norm": 0.40541863441467285,
      "learning_rate": 0.0004998741355957963,
      "loss": 3.6123,
      "step": 300
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.7663938999176025,
      "eval_runtime": 1.5762,
      "eval_samples_per_second": 3111.999,
      "eval_steps_per_second": 12.689,
      "step": 304
    },
    {
      "epoch": 4.079470198675497,
      "grad_norm": 0.3714405298233032,
      "learning_rate": 0.0004998567959336269,
      "loss": 3.362,
      "step": 310
    },
    {
      "epoch": 4.211920529801325,
      "grad_norm": 0.37582626938819885,
      "learning_rate": 0.0004998383380241978,
      "loss": 3.4829,
      "step": 320
    },
    {
      "epoch": 4.344370860927152,
      "grad_norm": 0.36490359902381897,
      "learning_rate": 0.0004998187619501184,
      "loss": 3.407,
      "step": 330
    },
    {
      "epoch": 4.47682119205298,
      "grad_norm": 0.3493182957172394,
      "learning_rate": 0.0004997980677990026,
      "loss": 3.3617,
      "step": 340
    },
    {
      "epoch": 4.609271523178808,
      "grad_norm": 0.3411864936351776,
      "learning_rate": 0.000499776255663468,
      "loss": 3.3079,
      "step": 350
    },
    {
      "epoch": 4.741721854304636,
      "grad_norm": 0.3215497136116028,
      "learning_rate": 0.0004997533256411359,
      "loss": 3.2285,
      "step": 360
    },
    {
      "epoch": 4.874172185430464,
      "grad_norm": 0.3115876317024231,
      "learning_rate": 0.0004997292778346311,
      "loss": 3.1961,
      "step": 370
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.20207980275154114,
      "learning_rate": 0.0004997041123515806,
      "loss": 2.9918,
      "step": 380
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.556684970855713,
      "eval_runtime": 1.5432,
      "eval_samples_per_second": 3178.436,
      "eval_steps_per_second": 12.96,
      "step": 380
    },
    {
      "epoch": 5.132450331125828,
      "grad_norm": 0.29567062854766846,
      "learning_rate": 0.000499677829304614,
      "loss": 3.0758,
      "step": 390
    },
    {
      "epoch": 5.264900662251655,
      "grad_norm": 0.30505290627479553,
      "learning_rate": 0.0004996504288113623,
      "loss": 3.0722,
      "step": 400
    },
    {
      "epoch": 5.397350993377484,
      "grad_norm": 0.2912643551826477,
      "learning_rate": 0.0004996219109944579,
      "loss": 3.0183,
      "step": 410
    },
    {
      "epoch": 5.529801324503311,
      "grad_norm": 0.28405526280403137,
      "learning_rate": 0.0004995922759815339,
      "loss": 2.9657,
      "step": 420
    },
    {
      "epoch": 5.662251655629139,
      "grad_norm": 0.2833760380744934,
      "learning_rate": 0.0004995615239052233,
      "loss": 2.9438,
      "step": 430
    },
    {
      "epoch": 5.7947019867549665,
      "grad_norm": 0.26256638765335083,
      "learning_rate": 0.0004995296549031585,
      "loss": 2.8712,
      "step": 440
    },
    {
      "epoch": 5.927152317880795,
      "grad_norm": 0.2913384437561035,
      "learning_rate": 0.0004994966691179711,
      "loss": 2.8534,
      "step": 450
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.4160248041152954,
      "eval_runtime": 1.539,
      "eval_samples_per_second": 3187.147,
      "eval_steps_per_second": 12.996,
      "step": 456
    },
    {
      "epoch": 6.052980132450331,
      "grad_norm": 0.36440369486808777,
      "learning_rate": 0.0004994625666972907,
      "loss": 2.6914,
      "step": 460
    },
    {
      "epoch": 6.185430463576159,
      "grad_norm": 0.2509458363056183,
      "learning_rate": 0.0004994273477937443,
      "loss": 2.7874,
      "step": 470
    },
    {
      "epoch": 6.317880794701987,
      "grad_norm": 0.2540312707424164,
      "learning_rate": 0.0004993910125649561,
      "loss": 2.7753,
      "step": 480
    },
    {
      "epoch": 6.450331125827814,
      "grad_norm": 0.2523425817489624,
      "learning_rate": 0.0004993535611735463,
      "loss": 2.7282,
      "step": 490
    },
    {
      "epoch": 6.582781456953643,
      "grad_norm": 0.25006160140037537,
      "learning_rate": 0.0004993149937871307,
      "loss": 2.6981,
      "step": 500
    },
    {
      "epoch": 6.71523178807947,
      "grad_norm": 1.6539037227630615,
      "learning_rate": 0.0004992753105783193,
      "loss": 2.6788,
      "step": 510
    },
    {
      "epoch": 6.847682119205298,
      "grad_norm": 0.5539647936820984,
      "learning_rate": 0.000499234511724717,
      "loss": 2.6706,
      "step": 520
    },
    {
      "epoch": 6.9801324503311255,
      "grad_norm": 0.280659556388855,
      "learning_rate": 0.0004991925974089205,
      "loss": 2.6397,
      "step": 530
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.3247482776641846,
      "eval_runtime": 1.5461,
      "eval_samples_per_second": 3172.513,
      "eval_steps_per_second": 12.936,
      "step": 532
    },
    {
      "epoch": 7.105960264900662,
      "grad_norm": 0.2075284868478775,
      "learning_rate": 0.0004991495678185201,
      "loss": 2.4836,
      "step": 540
    },
    {
      "epoch": 7.23841059602649,
      "grad_norm": 0.20777127146720886,
      "learning_rate": 0.0004991054231460968,
      "loss": 2.5846,
      "step": 550
    },
    {
      "epoch": 7.370860927152318,
      "grad_norm": 0.20825202763080597,
      "learning_rate": 0.0004990601635892224,
      "loss": 2.5749,
      "step": 560
    },
    {
      "epoch": 7.503311258278146,
      "grad_norm": 0.20490287244319916,
      "learning_rate": 0.0004990137893504585,
      "loss": 2.5512,
      "step": 570
    },
    {
      "epoch": 7.635761589403973,
      "grad_norm": 0.253033846616745,
      "learning_rate": 0.0004989663006373553,
      "loss": 2.5502,
      "step": 580
    },
    {
      "epoch": 7.768211920529802,
      "grad_norm": 0.21579203009605408,
      "learning_rate": 0.0004989176976624511,
      "loss": 2.5225,
      "step": 590
    },
    {
      "epoch": 7.900662251655629,
      "grad_norm": 0.21704962849617004,
      "learning_rate": 0.0004988679806432712,
      "loss": 2.5059,
      "step": 600
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.2628064155578613,
      "eval_runtime": 1.5624,
      "eval_samples_per_second": 3139.38,
      "eval_steps_per_second": 12.801,
      "step": 608
    },
    {
      "epoch": 8.026490066225165,
      "grad_norm": 0.22335480153560638,
      "learning_rate": 0.0004988171498023266,
      "loss": 2.3646,
      "step": 610
    },
    {
      "epoch": 8.158940397350994,
      "grad_norm": 0.27062034606933594,
      "learning_rate": 0.0004987652053671134,
      "loss": 2.4748,
      "step": 620
    },
    {
      "epoch": 8.291390728476822,
      "grad_norm": 0.21652264893054962,
      "learning_rate": 0.0004987121475701117,
      "loss": 2.4586,
      "step": 630
    },
    {
      "epoch": 8.42384105960265,
      "grad_norm": 0.20002835988998413,
      "learning_rate": 0.0004986579766487845,
      "loss": 2.4382,
      "step": 640
    },
    {
      "epoch": 8.556291390728477,
      "grad_norm": 0.1897030919790268,
      "learning_rate": 0.0004986026928455767,
      "loss": 2.4429,
      "step": 650
    },
    {
      "epoch": 8.688741721854305,
      "grad_norm": 0.200786754488945,
      "learning_rate": 0.0004985462964079136,
      "loss": 2.4132,
      "step": 660
    },
    {
      "epoch": 8.821192052980132,
      "grad_norm": 0.2072327882051468,
      "learning_rate": 0.0004984887875882007,
      "loss": 2.4043,
      "step": 670
    },
    {
      "epoch": 8.95364238410596,
      "grad_norm": 0.20504280924797058,
      "learning_rate": 0.0004984301666438217,
      "loss": 2.4015,
      "step": 680
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.2230024337768555,
      "eval_runtime": 1.5612,
      "eval_samples_per_second": 3141.816,
      "eval_steps_per_second": 12.811,
      "step": 684
    },
    {
      "epoch": 9.079470198675496,
      "grad_norm": 0.23663562536239624,
      "learning_rate": 0.0004983704338371376,
      "loss": 2.2611,
      "step": 690
    },
    {
      "epoch": 9.211920529801324,
      "grad_norm": 0.2897343933582306,
      "learning_rate": 0.0004983095894354857,
      "loss": 2.3725,
      "step": 700
    },
    {
      "epoch": 9.344370860927153,
      "grad_norm": 0.22539015114307404,
      "learning_rate": 0.0004982476337111785,
      "loss": 2.3763,
      "step": 710
    },
    {
      "epoch": 9.47682119205298,
      "grad_norm": 0.2254980206489563,
      "learning_rate": 0.0004981845669415021,
      "loss": 2.3527,
      "step": 720
    },
    {
      "epoch": 9.609271523178808,
      "grad_norm": 0.23213468492031097,
      "learning_rate": 0.000498120389408715,
      "loss": 2.328,
      "step": 730
    },
    {
      "epoch": 9.741721854304636,
      "grad_norm": 0.19433867931365967,
      "learning_rate": 0.0004980551014000474,
      "loss": 2.3539,
      "step": 740
    },
    {
      "epoch": 9.874172185430464,
      "grad_norm": 0.20713180303573608,
      "learning_rate": 0.0004979887032076989,
      "loss": 2.3357,
      "step": 750
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.1678103357553482,
      "learning_rate": 0.0004979211951288381,
      "loss": 2.2069,
      "step": 760
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.1951769590377808,
      "eval_runtime": 1.5634,
      "eval_samples_per_second": 3137.366,
      "eval_steps_per_second": 12.793,
      "step": 760
    },
    {
      "epoch": 10.132450331125828,
      "grad_norm": 0.21970447897911072,
      "learning_rate": 0.0004978525774656014,
      "loss": 2.3219,
      "step": 770
    },
    {
      "epoch": 10.264900662251655,
      "grad_norm": 0.27856481075286865,
      "learning_rate": 0.0004977828505250904,
      "loss": 2.3017,
      "step": 780
    },
    {
      "epoch": 10.397350993377483,
      "grad_norm": 0.2523721158504486,
      "learning_rate": 0.0004977120146193717,
      "loss": 2.2932,
      "step": 790
    },
    {
      "epoch": 10.52980132450331,
      "grad_norm": 0.20491023361682892,
      "learning_rate": 0.0004976400700654752,
      "loss": 2.293,
      "step": 800
    },
    {
      "epoch": 10.66225165562914,
      "grad_norm": 0.29396963119506836,
      "learning_rate": 0.0004975670171853926,
      "loss": 2.2772,
      "step": 810
    },
    {
      "epoch": 10.794701986754967,
      "grad_norm": 0.2091573029756546,
      "learning_rate": 0.0004974928563060758,
      "loss": 2.2639,
      "step": 820
    },
    {
      "epoch": 10.927152317880795,
      "grad_norm": 0.22355319559574127,
      "learning_rate": 0.000497417587759436,
      "loss": 2.2619,
      "step": 830
    },
    {
      "epoch": 11.0,
      "eval_loss": 1.1684428453445435,
      "eval_runtime": 1.5752,
      "eval_samples_per_second": 3113.892,
      "eval_steps_per_second": 12.697,
      "step": 836
    },
    {
      "epoch": 11.052980132450331,
      "grad_norm": 0.1939454823732376,
      "learning_rate": 0.0004973412118823412,
      "loss": 2.1436,
      "step": 840
    },
    {
      "epoch": 11.185430463576159,
      "grad_norm": 0.21837617456912994,
      "learning_rate": 0.0004972637290166158,
      "loss": 2.2604,
      "step": 850
    },
    {
      "epoch": 11.317880794701987,
      "grad_norm": 0.2130471020936966,
      "learning_rate": 0.0004971851395090385,
      "loss": 2.2448,
      "step": 860
    },
    {
      "epoch": 11.450331125827814,
      "grad_norm": 0.21854256093502045,
      "learning_rate": 0.0004971054437113406,
      "loss": 2.2337,
      "step": 870
    },
    {
      "epoch": 11.582781456953642,
      "grad_norm": 0.19773264229297638,
      "learning_rate": 0.0004970246419802051,
      "loss": 2.2334,
      "step": 880
    },
    {
      "epoch": 11.71523178807947,
      "grad_norm": 0.2187894582748413,
      "learning_rate": 0.0004969427346772642,
      "loss": 2.2293,
      "step": 890
    },
    {
      "epoch": 11.847682119205299,
      "grad_norm": 0.23566821217536926,
      "learning_rate": 0.0004968597221690986,
      "loss": 2.2296,
      "step": 900
    },
    {
      "epoch": 11.980132450331126,
      "grad_norm": 0.2307043969631195,
      "learning_rate": 0.0004967756048272349,
      "loss": 2.2318,
      "step": 910
    },
    {
      "epoch": 12.0,
      "eval_loss": 1.1581439971923828,
      "eval_runtime": 1.5555,
      "eval_samples_per_second": 3153.355,
      "eval_steps_per_second": 12.858,
      "step": 912
    },
    {
      "epoch": 12.105960264900663,
      "grad_norm": 0.5066229104995728,
      "learning_rate": 0.0004966903830281448,
      "loss": 2.1011,
      "step": 920
    },
    {
      "epoch": 12.23841059602649,
      "grad_norm": 0.23446354269981384,
      "learning_rate": 0.000496604057153243,
      "loss": 2.2162,
      "step": 930
    },
    {
      "epoch": 12.370860927152318,
      "grad_norm": 0.23401817679405212,
      "learning_rate": 0.0004965166275888854,
      "loss": 2.2187,
      "step": 940
    },
    {
      "epoch": 12.503311258278146,
      "grad_norm": 0.23979906737804413,
      "learning_rate": 0.0004964280947263676,
      "loss": 2.1956,
      "step": 950
    },
    {
      "epoch": 12.635761589403973,
      "grad_norm": 0.2585345208644867,
      "learning_rate": 0.0004963384589619233,
      "loss": 2.1907,
      "step": 960
    },
    {
      "epoch": 12.7682119205298,
      "grad_norm": 0.22747556865215302,
      "learning_rate": 0.0004962477206967218,
      "loss": 2.1826,
      "step": 970
    },
    {
      "epoch": 12.900662251655628,
      "grad_norm": 0.2077598124742508,
      "learning_rate": 0.0004961558803368673,
      "loss": 2.1962,
      "step": 980
    },
    {
      "epoch": 13.0,
      "eval_loss": 1.1432368755340576,
      "eval_runtime": 1.5724,
      "eval_samples_per_second": 3119.525,
      "eval_steps_per_second": 12.72,
      "step": 988
    },
    {
      "epoch": 13.026490066225165,
      "grad_norm": 0.2813505232334137,
      "learning_rate": 0.0004960629382933959,
      "loss": 2.0772,
      "step": 990
    },
    {
      "epoch": 13.158940397350994,
      "grad_norm": 0.22428743541240692,
      "learning_rate": 0.0004959688949822749,
      "loss": 2.1836,
      "step": 1000
    },
    {
      "epoch": 13.291390728476822,
      "grad_norm": 0.2233584076166153,
      "learning_rate": 0.0004958737508243997,
      "loss": 2.1802,
      "step": 1010
    },
    {
      "epoch": 13.42384105960265,
      "grad_norm": 0.2334647923707962,
      "learning_rate": 0.0004957775062455933,
      "loss": 2.1746,
      "step": 1020
    },
    {
      "epoch": 13.556291390728477,
      "grad_norm": 0.2255958914756775,
      "learning_rate": 0.0004956801616766034,
      "loss": 2.1753,
      "step": 1030
    },
    {
      "epoch": 13.688741721854305,
      "grad_norm": 0.2618613839149475,
      "learning_rate": 0.0004955817175531005,
      "loss": 2.154,
      "step": 1040
    },
    {
      "epoch": 13.821192052980132,
      "grad_norm": 0.24318361282348633,
      "learning_rate": 0.0004954821743156767,
      "loss": 2.1656,
      "step": 1050
    },
    {
      "epoch": 13.95364238410596,
      "grad_norm": 0.22574588656425476,
      "learning_rate": 0.0004953815324098428,
      "loss": 2.1618,
      "step": 1060
    },
    {
      "epoch": 14.0,
      "eval_loss": 1.1252139806747437,
      "eval_runtime": 1.5689,
      "eval_samples_per_second": 3126.376,
      "eval_steps_per_second": 12.748,
      "step": 1064
    },
    {
      "epoch": 14.079470198675496,
      "grad_norm": 0.2257397621870041,
      "learning_rate": 0.0004952797922860273,
      "loss": 2.0351,
      "step": 1070
    },
    {
      "epoch": 14.211920529801324,
      "grad_norm": 0.25075188279151917,
      "learning_rate": 0.0004951769543995731,
      "loss": 2.1536,
      "step": 1080
    },
    {
      "epoch": 14.344370860927153,
      "grad_norm": 0.25271865725517273,
      "learning_rate": 0.0004950730192107368,
      "loss": 2.1397,
      "step": 1090
    },
    {
      "epoch": 14.47682119205298,
      "grad_norm": 0.24269616603851318,
      "learning_rate": 0.0004949679871846857,
      "loss": 2.1377,
      "step": 1100
    },
    {
      "epoch": 14.609271523178808,
      "grad_norm": 0.29611366987228394,
      "learning_rate": 0.0004948618587914963,
      "loss": 2.1596,
      "step": 1110
    },
    {
      "epoch": 14.741721854304636,
      "grad_norm": 0.24183417856693268,
      "learning_rate": 0.0004947546345061517,
      "loss": 2.1507,
      "step": 1120
    },
    {
      "epoch": 14.874172185430464,
      "grad_norm": 0.23385247588157654,
      "learning_rate": 0.00049464631480854,
      "loss": 2.1382,
      "step": 1130
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.2250566929578781,
      "learning_rate": 0.0004945369001834514,
      "loss": 2.0511,
      "step": 1140
    },
    {
      "epoch": 15.0,
      "eval_loss": 1.117463231086731,
      "eval_runtime": 1.5619,
      "eval_samples_per_second": 3140.43,
      "eval_steps_per_second": 12.805,
      "step": 1140
    },
    {
      "epoch": 15.132450331125828,
      "grad_norm": 0.27428707480430603,
      "learning_rate": 0.0004944263911205772,
      "loss": 2.1291,
      "step": 1150
    },
    {
      "epoch": 15.264900662251655,
      "grad_norm": 0.2585826516151428,
      "learning_rate": 0.0004943147881145062,
      "loss": 2.1196,
      "step": 1160
    },
    {
      "epoch": 15.397350993377483,
      "grad_norm": 0.2646113932132721,
      "learning_rate": 0.0004942020916647238,
      "loss": 2.1364,
      "step": 1170
    },
    {
      "epoch": 15.52980132450331,
      "grad_norm": 0.26430487632751465,
      "learning_rate": 0.0004940883022756088,
      "loss": 2.1101,
      "step": 1180
    },
    {
      "epoch": 15.66225165562914,
      "grad_norm": 0.25485092401504517,
      "learning_rate": 0.0004939734204564316,
      "loss": 2.1268,
      "step": 1190
    },
    {
      "epoch": 15.794701986754967,
      "grad_norm": 0.25377118587493896,
      "learning_rate": 0.0004938574467213517,
      "loss": 2.1351,
      "step": 1200
    },
    {
      "epoch": 15.927152317880795,
      "grad_norm": 0.311190664768219,
      "learning_rate": 0.000493740381589416,
      "loss": 2.1201,
      "step": 1210
    },
    {
      "epoch": 16.0,
      "eval_loss": 1.1089917421340942,
      "eval_runtime": 1.5752,
      "eval_samples_per_second": 3113.842,
      "eval_steps_per_second": 12.697,
      "step": 1216
    },
    {
      "epoch": 16.05298013245033,
      "grad_norm": 0.24027319252490997,
      "learning_rate": 0.0004936222255845554,
      "loss": 2.0045,
      "step": 1220
    },
    {
      "epoch": 16.185430463576157,
      "grad_norm": 0.33395692706108093,
      "learning_rate": 0.0004935029792355834,
      "loss": 2.1123,
      "step": 1230
    },
    {
      "epoch": 16.31788079470199,
      "grad_norm": 0.4998566806316376,
      "learning_rate": 0.0004933826430761933,
      "loss": 2.1082,
      "step": 1240
    },
    {
      "epoch": 16.450331125827816,
      "grad_norm": 0.27669471502304077,
      "learning_rate": 0.0004932612176449559,
      "loss": 2.0983,
      "step": 1250
    },
    {
      "epoch": 16.582781456953644,
      "grad_norm": 0.28672221302986145,
      "learning_rate": 0.0004931387034853173,
      "loss": 2.0939,
      "step": 1260
    },
    {
      "epoch": 16.71523178807947,
      "grad_norm": 0.2876744568347931,
      "learning_rate": 0.0004930151011455959,
      "loss": 2.1139,
      "step": 1270
    },
    {
      "epoch": 16.8476821192053,
      "grad_norm": 0.2737957239151001,
      "learning_rate": 0.0004928904111789805,
      "loss": 2.0955,
      "step": 1280
    },
    {
      "epoch": 16.980132450331126,
      "grad_norm": 0.27930429577827454,
      "learning_rate": 0.0004927646341435275,
      "loss": 2.0976,
      "step": 1290
    },
    {
      "epoch": 17.0,
      "eval_loss": 1.1034517288208008,
      "eval_runtime": 1.5829,
      "eval_samples_per_second": 3098.665,
      "eval_steps_per_second": 12.635,
      "step": 1292
    },
    {
      "epoch": 17.105960264900663,
      "grad_norm": 0.28738486766815186,
      "learning_rate": 0.000492637770602159,
      "loss": 1.9864,
      "step": 1300
    },
    {
      "epoch": 17.23841059602649,
      "grad_norm": 0.27858778834342957,
      "learning_rate": 0.0004925098211226593,
      "loss": 2.0913,
      "step": 1310
    },
    {
      "epoch": 17.370860927152318,
      "grad_norm": 0.28025996685028076,
      "learning_rate": 0.0004923807862776728,
      "loss": 2.0851,
      "step": 1320
    },
    {
      "epoch": 17.503311258278146,
      "grad_norm": 0.27542343735694885,
      "learning_rate": 0.0004922506666447021,
      "loss": 2.0861,
      "step": 1330
    },
    {
      "epoch": 17.635761589403973,
      "grad_norm": 0.391202449798584,
      "learning_rate": 0.0004921194628061043,
      "loss": 2.0771,
      "step": 1340
    },
    {
      "epoch": 17.7682119205298,
      "grad_norm": 0.2849617302417755,
      "learning_rate": 0.0004919871753490891,
      "loss": 2.1006,
      "step": 1350
    },
    {
      "epoch": 17.90066225165563,
      "grad_norm": 0.27043697237968445,
      "learning_rate": 0.000491853804865716,
      "loss": 2.0774,
      "step": 1360
    },
    {
      "epoch": 18.0,
      "eval_loss": 1.0949122905731201,
      "eval_runtime": 1.5435,
      "eval_samples_per_second": 3177.779,
      "eval_steps_per_second": 12.957,
      "step": 1368
    },
    {
      "epoch": 18.026490066225165,
      "grad_norm": 0.31252363324165344,
      "learning_rate": 0.0004917193519528917,
      "loss": 2.0044,
      "step": 1370
    },
    {
      "epoch": 18.158940397350992,
      "grad_norm": 0.2642632722854614,
      "learning_rate": 0.0004915838172123671,
      "loss": 2.0689,
      "step": 1380
    },
    {
      "epoch": 18.29139072847682,
      "grad_norm": 0.27771830558776855,
      "learning_rate": 0.0004914472012507354,
      "loss": 2.0827,
      "step": 1390
    },
    {
      "epoch": 18.423841059602648,
      "grad_norm": 0.3040080964565277,
      "learning_rate": 0.0004913095046794281,
      "loss": 2.0656,
      "step": 1400
    },
    {
      "epoch": 18.556291390728475,
      "grad_norm": 0.30349260568618774,
      "learning_rate": 0.000491170728114714,
      "loss": 2.0755,
      "step": 1410
    },
    {
      "epoch": 18.688741721854306,
      "grad_norm": 0.28427979350090027,
      "learning_rate": 0.0004910308721776945,
      "loss": 2.071,
      "step": 1420
    },
    {
      "epoch": 18.821192052980134,
      "grad_norm": 0.30756303668022156,
      "learning_rate": 0.0004908899374943023,
      "loss": 2.0791,
      "step": 1430
    },
    {
      "epoch": 18.95364238410596,
      "grad_norm": 0.29295337200164795,
      "learning_rate": 0.0004907479246952981,
      "loss": 2.0702,
      "step": 1440
    },
    {
      "epoch": 19.0,
      "eval_loss": 1.092671275138855,
      "eval_runtime": 1.5917,
      "eval_samples_per_second": 3081.549,
      "eval_steps_per_second": 12.565,
      "step": 1444
    },
    {
      "epoch": 19.079470198675498,
      "grad_norm": 0.2984641194343567,
      "learning_rate": 0.0004906048344162677,
      "loss": 1.9643,
      "step": 1450
    },
    {
      "epoch": 19.211920529801326,
      "grad_norm": 0.28191593289375305,
      "learning_rate": 0.000490460667297619,
      "loss": 2.0573,
      "step": 1460
    },
    {
      "epoch": 19.344370860927153,
      "grad_norm": 0.2926385700702667,
      "learning_rate": 0.0004903154239845797,
      "loss": 2.0558,
      "step": 1470
    },
    {
      "epoch": 19.47682119205298,
      "grad_norm": 0.28978151082992554,
      "learning_rate": 0.0004901691051271939,
      "loss": 2.0591,
      "step": 1480
    },
    {
      "epoch": 19.60927152317881,
      "grad_norm": 0.30198776721954346,
      "learning_rate": 0.0004900217113803192,
      "loss": 2.0644,
      "step": 1490
    },
    {
      "epoch": 19.741721854304636,
      "grad_norm": 0.2955893874168396,
      "learning_rate": 0.0004898732434036243,
      "loss": 2.0521,
      "step": 1500
    },
    {
      "epoch": 19.874172185430464,
      "grad_norm": 0.4420849680900574,
      "learning_rate": 0.0004897237018615854,
      "loss": 2.0662,
      "step": 1510
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.2572858929634094,
      "learning_rate": 0.0004895730874234834,
      "loss": 1.9593,
      "step": 1520
    },
    {
      "epoch": 20.0,
      "eval_loss": 1.0970336198806763,
      "eval_runtime": 1.5484,
      "eval_samples_per_second": 3167.847,
      "eval_steps_per_second": 12.917,
      "step": 1520
    },
    {
      "epoch": 20.132450331125828,
      "grad_norm": 0.328714519739151,
      "learning_rate": 0.0004894214007634014,
      "loss": 2.046,
      "step": 1530
    },
    {
      "epoch": 20.264900662251655,
      "grad_norm": 0.29916489124298096,
      "learning_rate": 0.0004892686425602207,
      "loss": 2.0568,
      "step": 1540
    },
    {
      "epoch": 20.397350993377483,
      "grad_norm": 0.31408724188804626,
      "learning_rate": 0.000489114813497619,
      "loss": 2.0546,
      "step": 1550
    },
    {
      "epoch": 20.52980132450331,
      "grad_norm": 0.34641870856285095,
      "learning_rate": 0.0004889599142640663,
      "loss": 2.0518,
      "step": 1560
    },
    {
      "epoch": 20.662251655629138,
      "grad_norm": 0.31882980465888977,
      "learning_rate": 0.0004888039455528222,
      "loss": 2.0493,
      "step": 1570
    },
    {
      "epoch": 20.794701986754966,
      "grad_norm": 0.33354127407073975,
      "learning_rate": 0.000488646908061933,
      "loss": 2.0518,
      "step": 1580
    },
    {
      "epoch": 20.927152317880793,
      "grad_norm": 0.30650556087493896,
      "learning_rate": 0.0004884888024942282,
      "loss": 2.0471,
      "step": 1590
    },
    {
      "epoch": 21.0,
      "eval_loss": 1.0885741710662842,
      "eval_runtime": 1.5618,
      "eval_samples_per_second": 3140.695,
      "eval_steps_per_second": 12.806,
      "step": 1596
    },
    {
      "epoch": 21.05298013245033,
      "grad_norm": 0.3604792654514313,
      "learning_rate": 0.0004883296295573175,
      "loss": 1.9384,
      "step": 1600
    },
    {
      "epoch": 21.185430463576157,
      "grad_norm": 0.3223859369754791,
      "learning_rate": 0.00048816938996358805,
      "loss": 2.0281,
      "step": 1610
    },
    {
      "epoch": 21.31788079470199,
      "grad_norm": 0.30304741859436035,
      "learning_rate": 0.0004880080844302004,
      "loss": 2.0394,
      "step": 1620
    },
    {
      "epoch": 21.450331125827816,
      "grad_norm": 0.3216683268547058,
      "learning_rate": 0.0004878457136790859,
      "loss": 2.0328,
      "step": 1630
    },
    {
      "epoch": 21.582781456953644,
      "grad_norm": 0.34153780341148376,
      "learning_rate": 0.00048768227843694356,
      "loss": 2.0317,
      "step": 1640
    },
    {
      "epoch": 21.71523178807947,
      "grad_norm": 0.3252021074295044,
      "learning_rate": 0.0004875177794352363,
      "loss": 2.04,
      "step": 1650
    },
    {
      "epoch": 21.8476821192053,
      "grad_norm": 0.3215957581996918,
      "learning_rate": 0.00048735221741018825,
      "loss": 2.0347,
      "step": 1660
    },
    {
      "epoch": 21.980132450331126,
      "grad_norm": 0.31055858731269836,
      "learning_rate": 0.00048718559310278076,
      "loss": 2.0396,
      "step": 1670
    },
    {
      "epoch": 22.0,
      "eval_loss": 1.0871078968048096,
      "eval_runtime": 1.5812,
      "eval_samples_per_second": 3102.116,
      "eval_steps_per_second": 12.649,
      "step": 1672
    },
    {
      "epoch": 22.105960264900663,
      "grad_norm": 0.7338990569114685,
      "learning_rate": 0.0004870179072587499,
      "loss": 1.9352,
      "step": 1680
    },
    {
      "epoch": 22.23841059602649,
      "grad_norm": 0.3418671488761902,
      "learning_rate": 0.0004868491606285823,
      "loss": 2.0234,
      "step": 1690
    },
    {
      "epoch": 22.370860927152318,
      "grad_norm": 0.2971630394458771,
      "learning_rate": 0.00048667935396751264,
      "loss": 2.0155,
      "step": 1700
    },
    {
      "epoch": 22.503311258278146,
      "grad_norm": 0.2967209815979004,
      "learning_rate": 0.0004865084880355193,
      "loss": 2.0192,
      "step": 1710
    },
    {
      "epoch": 22.635761589403973,
      "grad_norm": 0.3199155926704407,
      "learning_rate": 0.00048633656359732205,
      "loss": 2.0256,
      "step": 1720
    },
    {
      "epoch": 22.7682119205298,
      "grad_norm": 0.30864381790161133,
      "learning_rate": 0.0004861635814223775,
      "loss": 2.0404,
      "step": 1730
    },
    {
      "epoch": 22.90066225165563,
      "grad_norm": 0.3481651544570923,
      "learning_rate": 0.0004859895422848767,
      "loss": 2.0178,
      "step": 1740
    },
    {
      "epoch": 23.0,
      "eval_loss": 1.0817561149597168,
      "eval_runtime": 1.5738,
      "eval_samples_per_second": 3116.716,
      "eval_steps_per_second": 12.708,
      "step": 1748
    },
    {
      "epoch": 23.026490066225165,
      "grad_norm": 0.32782649993896484,
      "learning_rate": 0.00048581444696374086,
      "loss": 1.9297,
      "step": 1750
    },
    {
      "epoch": 23.158940397350992,
      "grad_norm": 0.33535996079444885,
      "learning_rate": 0.0004856382962426185,
      "loss": 2.0131,
      "step": 1760
    },
    {
      "epoch": 23.29139072847682,
      "grad_norm": 0.324812114238739,
      "learning_rate": 0.0004854610909098812,
      "loss": 2.019,
      "step": 1770
    },
    {
      "epoch": 23.423841059602648,
      "grad_norm": 0.304031640291214,
      "learning_rate": 0.00048528283175862093,
      "loss": 2.015,
      "step": 1780
    },
    {
      "epoch": 23.556291390728475,
      "grad_norm": 0.3345490097999573,
      "learning_rate": 0.00048510351958664586,
      "loss": 2.0158,
      "step": 1790
    },
    {
      "epoch": 23.688741721854306,
      "grad_norm": 0.3380185067653656,
      "learning_rate": 0.0004849231551964771,
      "loss": 2.0182,
      "step": 1800
    },
    {
      "epoch": 23.821192052980134,
      "grad_norm": 0.3537231981754303,
      "learning_rate": 0.000484741739395345,
      "loss": 2.0133,
      "step": 1810
    },
    {
      "epoch": 23.95364238410596,
      "grad_norm": 0.3326752185821533,
      "learning_rate": 0.0004845592729951855,
      "loss": 2.0186,
      "step": 1820
    },
    {
      "epoch": 24.0,
      "eval_loss": 1.0763882398605347,
      "eval_runtime": 1.5534,
      "eval_samples_per_second": 3157.546,
      "eval_steps_per_second": 12.875,
      "step": 1824
    },
    {
      "epoch": 24.079470198675498,
      "grad_norm": 0.33258378505706787,
      "learning_rate": 0.0004843757568126366,
      "loss": 1.9059,
      "step": 1830
    },
    {
      "epoch": 24.211920529801326,
      "grad_norm": 0.3357103765010834,
      "learning_rate": 0.00048419119166903457,
      "loss": 2.0252,
      "step": 1840
    },
    {
      "epoch": 24.344370860927153,
      "grad_norm": 0.3526267409324646,
      "learning_rate": 0.00048400557839041057,
      "loss": 2.0036,
      "step": 1850
    },
    {
      "epoch": 24.47682119205298,
      "grad_norm": 0.3554055690765381,
      "learning_rate": 0.00048381891780748665,
      "loss": 2.0034,
      "step": 1860
    },
    {
      "epoch": 24.60927152317881,
      "grad_norm": 0.35423174500465393,
      "learning_rate": 0.00048363121075567197,
      "loss": 1.9998,
      "step": 1870
    },
    {
      "epoch": 24.741721854304636,
      "grad_norm": 0.3392796814441681,
      "learning_rate": 0.00048344245807505927,
      "loss": 2.0056,
      "step": 1880
    },
    {
      "epoch": 24.874172185430464,
      "grad_norm": 0.31952670216560364,
      "learning_rate": 0.0004832526606104213,
      "loss": 2.0042,
      "step": 1890
    },
    {
      "epoch": 25.0,
      "grad_norm": 0.3250177800655365,
      "learning_rate": 0.00048306181921120643,
      "loss": 1.9159,
      "step": 1900
    },
    {
      "epoch": 25.0,
      "eval_loss": 1.0806790590286255,
      "eval_runtime": 1.5975,
      "eval_samples_per_second": 3070.512,
      "eval_steps_per_second": 12.52,
      "step": 1900
    },
    {
      "epoch": 25.132450331125828,
      "grad_norm": 0.34084436297416687,
      "learning_rate": 0.00048286993473153564,
      "loss": 1.9991,
      "step": 1910
    },
    {
      "epoch": 25.264900662251655,
      "grad_norm": 0.33731645345687866,
      "learning_rate": 0.00048267700803019775,
      "loss": 1.996,
      "step": 1920
    },
    {
      "epoch": 25.397350993377483,
      "grad_norm": 0.4722115099430084,
      "learning_rate": 0.0004824830399706466,
      "loss": 1.9919,
      "step": 1930
    },
    {
      "epoch": 25.52980132450331,
      "grad_norm": 0.35066819190979004,
      "learning_rate": 0.00048228803142099643,
      "loss": 1.9898,
      "step": 1940
    },
    {
      "epoch": 25.662251655629138,
      "grad_norm": 0.3386905789375305,
      "learning_rate": 0.00048209198325401817,
      "loss": 2.0044,
      "step": 1950
    },
    {
      "epoch": 25.794701986754966,
      "grad_norm": 0.5552430748939514,
      "learning_rate": 0.0004818948963471358,
      "loss": 2.0014,
      "step": 1960
    },
    {
      "epoch": 25.927152317880793,
      "grad_norm": 0.34356337785720825,
      "learning_rate": 0.0004816967715824222,
      "loss": 2.0083,
      "step": 1970
    },
    {
      "epoch": 26.0,
      "eval_loss": 1.0697463750839233,
      "eval_runtime": 1.5757,
      "eval_samples_per_second": 3112.862,
      "eval_steps_per_second": 12.693,
      "step": 1976
    },
    {
      "epoch": 26.05298013245033,
      "grad_norm": 0.35787156224250793,
      "learning_rate": 0.0004814976098465951,
      "loss": 1.9023,
      "step": 1980
    },
    {
      "epoch": 26.185430463576157,
      "grad_norm": 0.376035213470459,
      "learning_rate": 0.0004812974120310134,
      "loss": 1.9777,
      "step": 1990
    },
    {
      "epoch": 26.31788079470199,
      "grad_norm": 0.34346553683280945,
      "learning_rate": 0.00048109617903167303,
      "loss": 1.995,
      "step": 2000
    },
    {
      "epoch": 26.450331125827816,
      "grad_norm": 0.36487364768981934,
      "learning_rate": 0.00048089391174920275,
      "loss": 1.9983,
      "step": 2010
    },
    {
      "epoch": 26.582781456953644,
      "grad_norm": 0.3341878056526184,
      "learning_rate": 0.0004806906110888606,
      "loss": 1.9853,
      "step": 2020
    },
    {
      "epoch": 26.71523178807947,
      "grad_norm": 0.3442637026309967,
      "learning_rate": 0.0004804862779605293,
      "loss": 2.0072,
      "step": 2030
    },
    {
      "epoch": 26.8476821192053,
      "grad_norm": 0.3457210063934326,
      "learning_rate": 0.00048028091327871256,
      "loss": 1.9859,
      "step": 2040
    },
    {
      "epoch": 26.980132450331126,
      "grad_norm": 0.36473795771598816,
      "learning_rate": 0.00048007451796253076,
      "loss": 1.9839,
      "step": 2050
    },
    {
      "epoch": 27.0,
      "eval_loss": 1.0708173513412476,
      "eval_runtime": 1.5609,
      "eval_samples_per_second": 3142.37,
      "eval_steps_per_second": 12.813,
      "step": 2052
    },
    {
      "epoch": 27.105960264900663,
      "grad_norm": 0.3734350800514221,
      "learning_rate": 0.00047986709293571715,
      "loss": 1.8863,
      "step": 2060
    },
    {
      "epoch": 27.23841059602649,
      "grad_norm": 0.3544047474861145,
      "learning_rate": 0.0004796586391266134,
      "loss": 1.978,
      "step": 2070
    },
    {
      "epoch": 27.370860927152318,
      "grad_norm": 0.3623017966747284,
      "learning_rate": 0.0004794491574681653,
      "loss": 1.9845,
      "step": 2080
    },
    {
      "epoch": 27.503311258278146,
      "grad_norm": 0.3471154272556305,
      "learning_rate": 0.0004792386488979193,
      "loss": 1.9973,
      "step": 2090
    },
    {
      "epoch": 27.635761589403973,
      "grad_norm": 0.37035563588142395,
      "learning_rate": 0.0004790271143580174,
      "loss": 1.9787,
      "step": 2100
    },
    {
      "epoch": 27.7682119205298,
      "grad_norm": 0.38759350776672363,
      "learning_rate": 0.0004788145547951937,
      "loss": 1.9832,
      "step": 2110
    },
    {
      "epoch": 27.90066225165563,
      "grad_norm": 0.3548333942890167,
      "learning_rate": 0.00047860097116076973,
      "loss": 1.9882,
      "step": 2120
    },
    {
      "epoch": 28.0,
      "eval_loss": 1.0710487365722656,
      "eval_runtime": 1.5716,
      "eval_samples_per_second": 3121.036,
      "eval_steps_per_second": 12.726,
      "step": 2128
    },
    {
      "epoch": 28.026490066225165,
      "grad_norm": 0.3735310137271881,
      "learning_rate": 0.0004783863644106502,
      "loss": 1.8885,
      "step": 2130
    },
    {
      "epoch": 28.158940397350992,
      "grad_norm": 0.4404507577419281,
      "learning_rate": 0.00047817073550531907,
      "loss": 1.9715,
      "step": 2140
    },
    {
      "epoch": 28.29139072847682,
      "grad_norm": 0.3607616424560547,
      "learning_rate": 0.00047795408540983475,
      "loss": 1.9653,
      "step": 2150
    },
    {
      "epoch": 28.423841059602648,
      "grad_norm": 0.381600946187973,
      "learning_rate": 0.00047773641509382626,
      "loss": 1.9828,
      "step": 2160
    },
    {
      "epoch": 28.556291390728475,
      "grad_norm": 0.41455718874931335,
      "learning_rate": 0.0004775177255314885,
      "loss": 1.979,
      "step": 2170
    },
    {
      "epoch": 28.688741721854306,
      "grad_norm": 0.39575958251953125,
      "learning_rate": 0.00047729801770157824,
      "loss": 1.9813,
      "step": 2180
    },
    {
      "epoch": 28.821192052980134,
      "grad_norm": 0.4082276225090027,
      "learning_rate": 0.0004770772925874093,
      "loss": 1.9796,
      "step": 2190
    },
    {
      "epoch": 28.95364238410596,
      "grad_norm": 0.3534024953842163,
      "learning_rate": 0.00047685555117684867,
      "loss": 1.9829,
      "step": 2200
    },
    {
      "epoch": 29.0,
      "eval_loss": 1.0716692209243774,
      "eval_runtime": 1.5691,
      "eval_samples_per_second": 3126.052,
      "eval_steps_per_second": 12.746,
      "step": 2204
    },
    {
      "epoch": 29.079470198675498,
      "grad_norm": 0.43237587809562683,
      "learning_rate": 0.0004766327944623117,
      "loss": 1.8511,
      "step": 2210
    },
    {
      "epoch": 29.211920529801326,
      "grad_norm": 0.36915335059165955,
      "learning_rate": 0.0004764090234407577,
      "loss": 1.985,
      "step": 2220
    },
    {
      "epoch": 29.344370860927153,
      "grad_norm": 0.4156229496002197,
      "learning_rate": 0.0004761842391136859,
      "loss": 1.9674,
      "step": 2230
    },
    {
      "epoch": 29.47682119205298,
      "grad_norm": 0.3725124001502991,
      "learning_rate": 0.0004759584424871302,
      "loss": 1.9582,
      "step": 2240
    },
    {
      "epoch": 29.60927152317881,
      "grad_norm": 0.38094496726989746,
      "learning_rate": 0.0004757316345716554,
      "loss": 1.9594,
      "step": 2250
    },
    {
      "epoch": 29.741721854304636,
      "grad_norm": 0.6422455310821533,
      "learning_rate": 0.00047550381638235213,
      "loss": 1.9765,
      "step": 2260
    },
    {
      "epoch": 29.874172185430464,
      "grad_norm": 0.4027491807937622,
      "learning_rate": 0.00047527498893883293,
      "loss": 1.9729,
      "step": 2270
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.35312750935554504,
      "learning_rate": 0.00047504515326522696,
      "loss": 1.8799,
      "step": 2280
    },
    {
      "epoch": 30.0,
      "eval_loss": 1.067636489868164,
      "eval_runtime": 1.5706,
      "eval_samples_per_second": 3123.105,
      "eval_steps_per_second": 12.734,
      "step": 2280
    },
    {
      "epoch": 30.132450331125828,
      "grad_norm": 0.40403151512145996,
      "learning_rate": 0.00047481431039017596,
      "loss": 1.9521,
      "step": 2290
    },
    {
      "epoch": 30.264900662251655,
      "grad_norm": 0.39778459072113037,
      "learning_rate": 0.00047458246134682926,
      "loss": 1.9599,
      "step": 2300
    },
    {
      "epoch": 30.397350993377483,
      "grad_norm": 0.38303956389427185,
      "learning_rate": 0.0004743496071728396,
      "loss": 1.9671,
      "step": 2310
    },
    {
      "epoch": 30.52980132450331,
      "grad_norm": 0.40014412999153137,
      "learning_rate": 0.00047411574891035804,
      "loss": 1.9712,
      "step": 2320
    },
    {
      "epoch": 30.662251655629138,
      "grad_norm": 0.38114577531814575,
      "learning_rate": 0.0004738808876060297,
      "loss": 1.9687,
      "step": 2330
    },
    {
      "epoch": 30.794701986754966,
      "grad_norm": 0.384198933839798,
      "learning_rate": 0.0004736450243109884,
      "loss": 1.9668,
      "step": 2340
    },
    {
      "epoch": 30.927152317880793,
      "grad_norm": 0.38715940713882446,
      "learning_rate": 0.00047340816008085306,
      "loss": 1.9776,
      "step": 2350
    },
    {
      "epoch": 31.0,
      "eval_loss": 1.0645217895507812,
      "eval_runtime": 1.5765,
      "eval_samples_per_second": 3111.312,
      "eval_steps_per_second": 12.686,
      "step": 2356
    },
    {
      "epoch": 31.05298013245033,
      "grad_norm": 0.3937196135520935,
      "learning_rate": 0.00047317029597572193,
      "loss": 1.8608,
      "step": 2360
    },
    {
      "epoch": 31.185430463576157,
      "grad_norm": 0.4039483666419983,
      "learning_rate": 0.00047293143306016835,
      "loss": 1.939,
      "step": 2370
    },
    {
      "epoch": 31.31788079470199,
      "grad_norm": 0.40588924288749695,
      "learning_rate": 0.00047269157240323583,
      "loss": 1.9571,
      "step": 2380
    },
    {
      "epoch": 31.450331125827816,
      "grad_norm": 0.4058459401130676,
      "learning_rate": 0.0004724507150784335,
      "loss": 1.948,
      "step": 2390
    },
    {
      "epoch": 31.582781456953644,
      "grad_norm": 0.41012808680534363,
      "learning_rate": 0.0004722088621637309,
      "loss": 1.9684,
      "step": 2400
    },
    {
      "epoch": 31.71523178807947,
      "grad_norm": 0.40088552236557007,
      "learning_rate": 0.00047196601474155356,
      "loss": 1.9673,
      "step": 2410
    },
    {
      "epoch": 31.8476821192053,
      "grad_norm": 0.39937639236450195,
      "learning_rate": 0.00047172217389877786,
      "loss": 1.9562,
      "step": 2420
    },
    {
      "epoch": 31.980132450331126,
      "grad_norm": 0.4147110879421234,
      "learning_rate": 0.00047147734072672644,
      "loss": 1.9688,
      "step": 2430
    },
    {
      "epoch": 32.0,
      "eval_loss": 1.06650972366333,
      "eval_runtime": 1.5449,
      "eval_samples_per_second": 3174.945,
      "eval_steps_per_second": 12.946,
      "step": 2432
    },
    {
      "epoch": 32.10596026490066,
      "grad_norm": 0.3801765441894531,
      "learning_rate": 0.000471231516321163,
      "loss": 1.8474,
      "step": 2440
    },
    {
      "epoch": 32.23841059602649,
      "grad_norm": 0.42464107275009155,
      "learning_rate": 0.0004709847017822876,
      "loss": 1.9493,
      "step": 2450
    },
    {
      "epoch": 32.370860927152314,
      "grad_norm": 0.4089668095111847,
      "learning_rate": 0.00047073689821473173,
      "loss": 1.9478,
      "step": 2460
    },
    {
      "epoch": 32.503311258278146,
      "grad_norm": 0.41898593306541443,
      "learning_rate": 0.00047048810672755336,
      "loss": 1.9519,
      "step": 2470
    },
    {
      "epoch": 32.63576158940398,
      "grad_norm": 0.4082915782928467,
      "learning_rate": 0.00047023832843423195,
      "loss": 1.9479,
      "step": 2480
    },
    {
      "epoch": 32.7682119205298,
      "grad_norm": 0.44273772835731506,
      "learning_rate": 0.0004699875644526633,
      "loss": 1.9518,
      "step": 2490
    },
    {
      "epoch": 32.90066225165563,
      "grad_norm": 0.40280357003211975,
      "learning_rate": 0.0004697358159051549,
      "loss": 1.9436,
      "step": 2500
    },
    {
      "epoch": 33.0,
      "eval_loss": 1.0658669471740723,
      "eval_runtime": 1.5606,
      "eval_samples_per_second": 3143.004,
      "eval_steps_per_second": 12.816,
      "step": 2508
    },
    {
      "epoch": 33.026490066225165,
      "grad_norm": 0.4007827639579773,
      "learning_rate": 0.0004694830839184206,
      "loss": 1.8468,
      "step": 2510
    },
    {
      "epoch": 33.158940397350996,
      "grad_norm": 0.4087514281272888,
      "learning_rate": 0.00046922936962357577,
      "loss": 1.9509,
      "step": 2520
    },
    {
      "epoch": 33.29139072847682,
      "grad_norm": 0.443258136510849,
      "learning_rate": 0.00046897467415613205,
      "loss": 1.9274,
      "step": 2530
    },
    {
      "epoch": 33.42384105960265,
      "grad_norm": 0.43823400139808655,
      "learning_rate": 0.0004687189986559925,
      "loss": 1.9336,
      "step": 2540
    },
    {
      "epoch": 33.556291390728475,
      "grad_norm": 0.41953763365745544,
      "learning_rate": 0.00046846234426744626,
      "loss": 1.9459,
      "step": 2550
    },
    {
      "epoch": 33.688741721854306,
      "grad_norm": 0.443512499332428,
      "learning_rate": 0.0004682047121391636,
      "loss": 1.9596,
      "step": 2560
    },
    {
      "epoch": 33.82119205298013,
      "grad_norm": 0.4012635052204132,
      "learning_rate": 0.0004679461034241906,
      "loss": 1.9485,
      "step": 2570
    },
    {
      "epoch": 33.95364238410596,
      "grad_norm": 0.4462146759033203,
      "learning_rate": 0.00046768651927994433,
      "loss": 1.9473,
      "step": 2580
    },
    {
      "epoch": 34.0,
      "eval_loss": 1.069430947303772,
      "eval_runtime": 1.5707,
      "eval_samples_per_second": 3122.905,
      "eval_steps_per_second": 12.734,
      "step": 2584
    },
    {
      "epoch": 34.079470198675494,
      "grad_norm": 0.4051181674003601,
      "learning_rate": 0.0004674259608682072,
      "loss": 1.8572,
      "step": 2590
    },
    {
      "epoch": 34.211920529801326,
      "grad_norm": 0.42965543270111084,
      "learning_rate": 0.00046716442935512215,
      "loss": 1.9359,
      "step": 2600
    },
    {
      "epoch": 34.34437086092715,
      "grad_norm": 0.41883373260498047,
      "learning_rate": 0.0004669019259111873,
      "loss": 1.9257,
      "step": 2610
    },
    {
      "epoch": 34.47682119205298,
      "grad_norm": 0.4153241515159607,
      "learning_rate": 0.00046663845171125056,
      "loss": 1.9189,
      "step": 2620
    },
    {
      "epoch": 34.609271523178805,
      "grad_norm": 0.43769851326942444,
      "learning_rate": 0.0004663740079345047,
      "loss": 1.9452,
      "step": 2630
    },
    {
      "epoch": 34.741721854304636,
      "grad_norm": 0.4311639964580536,
      "learning_rate": 0.0004661085957644817,
      "loss": 1.9401,
      "step": 2640
    },
    {
      "epoch": 34.87417218543047,
      "grad_norm": 0.4273518919944763,
      "learning_rate": 0.00046584221638904774,
      "loss": 1.9499,
      "step": 2650
    },
    {
      "epoch": 35.0,
      "grad_norm": 0.39071911573410034,
      "learning_rate": 0.00046557487100039774,
      "loss": 1.8514,
      "step": 2660
    },
    {
      "epoch": 35.0,
      "eval_loss": 1.0629149675369263,
      "eval_runtime": 1.5504,
      "eval_samples_per_second": 3163.664,
      "eval_steps_per_second": 12.9,
      "step": 2660
    },
    {
      "epoch": 35.13245033112583,
      "grad_norm": 0.4736616015434265,
      "learning_rate": 0.0004653065607950502,
      "loss": 1.922,
      "step": 2670
    },
    {
      "epoch": 35.264900662251655,
      "grad_norm": 0.47875380516052246,
      "learning_rate": 0.0004650372869738414,
      "loss": 1.9205,
      "step": 2680
    },
    {
      "epoch": 35.397350993377486,
      "grad_norm": 0.47103238105773926,
      "learning_rate": 0.00046476705074192053,
      "loss": 1.9322,
      "step": 2690
    },
    {
      "epoch": 35.52980132450331,
      "grad_norm": 0.46886926889419556,
      "learning_rate": 0.0004644958533087443,
      "loss": 1.935,
      "step": 2700
    },
    {
      "epoch": 35.66225165562914,
      "grad_norm": 0.4503995180130005,
      "learning_rate": 0.0004642236958880709,
      "loss": 1.9403,
      "step": 2710
    },
    {
      "epoch": 35.794701986754966,
      "grad_norm": 0.4340498149394989,
      "learning_rate": 0.0004639505796979553,
      "loss": 1.9382,
      "step": 2720
    },
    {
      "epoch": 35.9271523178808,
      "grad_norm": 0.4627169072628021,
      "learning_rate": 0.0004636765059607434,
      "loss": 1.9348,
      "step": 2730
    },
    {
      "epoch": 36.0,
      "eval_loss": 1.058334469795227,
      "eval_runtime": 1.5741,
      "eval_samples_per_second": 3115.995,
      "eval_steps_per_second": 12.705,
      "step": 2736
    },
    {
      "epoch": 36.05298013245033,
      "grad_norm": 0.4430284798145294,
      "learning_rate": 0.0004634014759030667,
      "loss": 1.8411,
      "step": 2740
    },
    {
      "epoch": 36.18543046357616,
      "grad_norm": 0.444441020488739,
      "learning_rate": 0.0004631254907558365,
      "loss": 1.9344,
      "step": 2750
    },
    {
      "epoch": 36.317880794701985,
      "grad_norm": 0.4224946200847626,
      "learning_rate": 0.0004628485517542392,
      "loss": 1.9182,
      "step": 2760
    },
    {
      "epoch": 36.450331125827816,
      "grad_norm": 0.4604293704032898,
      "learning_rate": 0.00046257066013772973,
      "loss": 1.9313,
      "step": 2770
    },
    {
      "epoch": 36.58278145695364,
      "grad_norm": 0.45483604073524475,
      "learning_rate": 0.00046229181715002666,
      "loss": 1.9229,
      "step": 2780
    },
    {
      "epoch": 36.71523178807947,
      "grad_norm": 0.44344577193260193,
      "learning_rate": 0.00046201202403910646,
      "loss": 1.9314,
      "step": 2790
    },
    {
      "epoch": 36.847682119205295,
      "grad_norm": 0.4566013216972351,
      "learning_rate": 0.0004617312820571981,
      "loss": 1.9315,
      "step": 2800
    },
    {
      "epoch": 36.980132450331126,
      "grad_norm": 0.44201672077178955,
      "learning_rate": 0.0004614495924607769,
      "loss": 1.9326,
      "step": 2810
    },
    {
      "epoch": 37.0,
      "eval_loss": 1.0616974830627441,
      "eval_runtime": 1.5522,
      "eval_samples_per_second": 3160.117,
      "eval_steps_per_second": 12.885,
      "step": 2812
    },
    {
      "epoch": 37.10596026490066,
      "grad_norm": 0.4839176833629608,
      "learning_rate": 0.0004611669565105596,
      "loss": 1.8177,
      "step": 2820
    },
    {
      "epoch": 37.23841059602649,
      "grad_norm": 0.4288827180862427,
      "learning_rate": 0.0004608833754714983,
      "loss": 1.9204,
      "step": 2830
    },
    {
      "epoch": 37.370860927152314,
      "grad_norm": 0.46192020177841187,
      "learning_rate": 0.0004605988506127748,
      "loss": 1.9197,
      "step": 2840
    },
    {
      "epoch": 37.503311258278146,
      "grad_norm": 0.4783249795436859,
      "learning_rate": 0.0004603133832077953,
      "loss": 1.9178,
      "step": 2850
    },
    {
      "epoch": 37.63576158940398,
      "grad_norm": 0.48039835691452026,
      "learning_rate": 0.0004600269745341841,
      "loss": 1.929,
      "step": 2860
    },
    {
      "epoch": 37.7682119205298,
      "grad_norm": 0.4690193235874176,
      "learning_rate": 0.00045973962587377823,
      "loss": 1.9261,
      "step": 2870
    },
    {
      "epoch": 37.90066225165563,
      "grad_norm": 0.4411649703979492,
      "learning_rate": 0.00045945133851262184,
      "loss": 1.9316,
      "step": 2880
    },
    {
      "epoch": 38.0,
      "eval_loss": 1.0609146356582642,
      "eval_runtime": 1.5769,
      "eval_samples_per_second": 3110.569,
      "eval_steps_per_second": 12.683,
      "step": 2888
    },
    {
      "epoch": 38.026490066225165,
      "grad_norm": 0.48871055245399475,
      "learning_rate": 0.0004591621137409602,
      "loss": 1.8283,
      "step": 2890
    },
    {
      "epoch": 38.158940397350996,
      "grad_norm": 0.45285964012145996,
      "learning_rate": 0.0004588719528532341,
      "loss": 1.915,
      "step": 2900
    },
    {
      "epoch": 38.29139072847682,
      "grad_norm": 0.4612257182598114,
      "learning_rate": 0.00045858085714807386,
      "loss": 1.9034,
      "step": 2910
    },
    {
      "epoch": 38.42384105960265,
      "grad_norm": 0.47298717498779297,
      "learning_rate": 0.0004582888279282935,
      "loss": 1.9273,
      "step": 2920
    },
    {
      "epoch": 38.556291390728475,
      "grad_norm": 0.48245930671691895,
      "learning_rate": 0.0004579958665008853,
      "loss": 1.9297,
      "step": 2930
    },
    {
      "epoch": 38.688741721854306,
      "grad_norm": 0.47666433453559875,
      "learning_rate": 0.00045770197417701366,
      "loss": 1.9201,
      "step": 2940
    },
    {
      "epoch": 38.82119205298013,
      "grad_norm": 0.471296101808548,
      "learning_rate": 0.00045740715227200903,
      "loss": 1.9144,
      "step": 2950
    },
    {
      "epoch": 38.95364238410596,
      "grad_norm": 0.4660521447658539,
      "learning_rate": 0.0004571114021053624,
      "loss": 1.9228,
      "step": 2960
    },
    {
      "epoch": 39.0,
      "eval_loss": 1.0682836771011353,
      "eval_runtime": 1.5523,
      "eval_samples_per_second": 3159.792,
      "eval_steps_per_second": 12.884,
      "step": 2964
    },
    {
      "epoch": 39.079470198675494,
      "grad_norm": 0.4998651146888733,
      "learning_rate": 0.0004568147250007193,
      "loss": 1.8106,
      "step": 2970
    },
    {
      "epoch": 39.211920529801326,
      "grad_norm": 0.45151883363723755,
      "learning_rate": 0.00045651712228587374,
      "loss": 1.9191,
      "step": 2980
    },
    {
      "epoch": 39.34437086092715,
      "grad_norm": 0.5117178559303284,
      "learning_rate": 0.00045621859529276223,
      "loss": 1.9105,
      "step": 2990
    },
    {
      "epoch": 39.47682119205298,
      "grad_norm": 0.4739688038825989,
      "learning_rate": 0.0004559191453574582,
      "loss": 1.9164,
      "step": 3000
    },
    {
      "epoch": 39.609271523178805,
      "grad_norm": 0.47902604937553406,
      "learning_rate": 0.0004556187738201656,
      "loss": 1.9245,
      "step": 3010
    },
    {
      "epoch": 39.741721854304636,
      "grad_norm": 0.46504634618759155,
      "learning_rate": 0.000455317482025213,
      "loss": 1.9009,
      "step": 3020
    },
    {
      "epoch": 39.87417218543047,
      "grad_norm": 0.4643375277519226,
      "learning_rate": 0.0004550152713210478,
      "loss": 1.9208,
      "step": 3030
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.4754745364189148,
      "learning_rate": 0.0004547121430602299,
      "loss": 1.814,
      "step": 3040
    },
    {
      "epoch": 40.0,
      "eval_loss": 1.0620838403701782,
      "eval_runtime": 1.5733,
      "eval_samples_per_second": 3117.739,
      "eval_steps_per_second": 12.712,
      "step": 3040
    },
    {
      "epoch": 40.13245033112583,
      "grad_norm": 0.4563266336917877,
      "learning_rate": 0.0004544080985994258,
      "loss": 1.902,
      "step": 3050
    },
    {
      "epoch": 40.264900662251655,
      "grad_norm": 0.5140810608863831,
      "learning_rate": 0.00045410313929940244,
      "loss": 1.913,
      "step": 3060
    },
    {
      "epoch": 40.397350993377486,
      "grad_norm": 0.46741393208503723,
      "learning_rate": 0.0004537972665250214,
      "loss": 1.9035,
      "step": 3070
    },
    {
      "epoch": 40.52980132450331,
      "grad_norm": 0.47946804761886597,
      "learning_rate": 0.0004534904816452323,
      "loss": 1.9019,
      "step": 3080
    },
    {
      "epoch": 40.66225165562914,
      "grad_norm": 0.4838176667690277,
      "learning_rate": 0.00045318278603306703,
      "loss": 1.9141,
      "step": 3090
    },
    {
      "epoch": 40.794701986754966,
      "grad_norm": 0.4867642819881439,
      "learning_rate": 0.00045287418106563354,
      "loss": 1.9127,
      "step": 3100
    },
    {
      "epoch": 40.9271523178808,
      "grad_norm": 0.4385678470134735,
      "learning_rate": 0.00045256466812410967,
      "loss": 1.9138,
      "step": 3110
    },
    {
      "epoch": 41.0,
      "eval_loss": 1.0640140771865845,
      "eval_runtime": 1.548,
      "eval_samples_per_second": 3168.6,
      "eval_steps_per_second": 12.92,
      "step": 3116
    },
    {
      "epoch": 41.05298013245033,
      "grad_norm": 0.47752663493156433,
      "learning_rate": 0.0004522542485937369,
      "loss": 1.8031,
      "step": 3120
    },
    {
      "epoch": 41.18543046357616,
      "grad_norm": 0.4884687066078186,
      "learning_rate": 0.0004519429238638141,
      "loss": 1.8853,
      "step": 3130
    },
    {
      "epoch": 41.317880794701985,
      "grad_norm": 0.5154722929000854,
      "learning_rate": 0.00045163069532769165,
      "loss": 1.8995,
      "step": 3140
    },
    {
      "epoch": 41.450331125827816,
      "grad_norm": 0.49281224608421326,
      "learning_rate": 0.00045131756438276466,
      "loss": 1.8912,
      "step": 3150
    },
    {
      "epoch": 41.58278145695364,
      "grad_norm": 0.5103054046630859,
      "learning_rate": 0.00045100353243046734,
      "loss": 1.9069,
      "step": 3160
    },
    {
      "epoch": 41.71523178807947,
      "grad_norm": 0.4658816456794739,
      "learning_rate": 0.0004506886008762661,
      "loss": 1.923,
      "step": 3170
    },
    {
      "epoch": 41.847682119205295,
      "grad_norm": 0.4590417444705963,
      "learning_rate": 0.00045037277112965383,
      "loss": 1.9016,
      "step": 3180
    },
    {
      "epoch": 41.980132450331126,
      "grad_norm": 0.4938249886035919,
      "learning_rate": 0.0004500560446041432,
      "loss": 1.9038,
      "step": 3190
    },
    {
      "epoch": 42.0,
      "eval_loss": 1.0637757778167725,
      "eval_runtime": 1.5649,
      "eval_samples_per_second": 3134.425,
      "eval_steps_per_second": 12.781,
      "step": 3192
    },
    {
      "epoch": 42.10596026490066,
      "grad_norm": 0.5063269734382629,
      "learning_rate": 0.00044973842271726027,
      "loss": 1.801,
      "step": 3200
    },
    {
      "epoch": 42.23841059602649,
      "grad_norm": 0.5263745188713074,
      "learning_rate": 0.00044941990689053885,
      "loss": 1.8938,
      "step": 3210
    },
    {
      "epoch": 42.370860927152314,
      "grad_norm": 0.492294579744339,
      "learning_rate": 0.00044910049854951305,
      "loss": 1.8996,
      "step": 3220
    },
    {
      "epoch": 42.503311258278146,
      "grad_norm": 0.4837128221988678,
      "learning_rate": 0.00044878019912371195,
      "loss": 1.8829,
      "step": 3230
    },
    {
      "epoch": 42.63576158940398,
      "grad_norm": 0.5049327611923218,
      "learning_rate": 0.0004484590100466523,
      "loss": 1.8973,
      "step": 3240
    },
    {
      "epoch": 42.7682119205298,
      "grad_norm": 0.5068607926368713,
      "learning_rate": 0.0004481369327558329,
      "loss": 1.8979,
      "step": 3250
    },
    {
      "epoch": 42.90066225165563,
      "grad_norm": 0.4912656843662262,
      "learning_rate": 0.0004478139686927276,
      "loss": 1.9049,
      "step": 3260
    },
    {
      "epoch": 43.0,
      "eval_loss": 1.06218421459198,
      "eval_runtime": 1.5668,
      "eval_samples_per_second": 3130.57,
      "eval_steps_per_second": 12.765,
      "step": 3268
    },
    {
      "epoch": 43.026490066225165,
      "grad_norm": 0.5075201392173767,
      "learning_rate": 0.00044749011930277907,
      "loss": 1.8025,
      "step": 3270
    },
    {
      "epoch": 43.158940397350996,
      "grad_norm": 0.4739290773868561,
      "learning_rate": 0.00044716538603539226,
      "loss": 1.8688,
      "step": 3280
    },
    {
      "epoch": 43.29139072847682,
      "grad_norm": 0.5055672526359558,
      "learning_rate": 0.0004468397703439282,
      "loss": 1.8861,
      "step": 3290
    },
    {
      "epoch": 43.42384105960265,
      "grad_norm": 0.5056512951850891,
      "learning_rate": 0.0004465132736856969,
      "loss": 1.8866,
      "step": 3300
    },
    {
      "epoch": 43.556291390728475,
      "grad_norm": 0.5297757387161255,
      "learning_rate": 0.00044618589752195144,
      "loss": 1.8888,
      "step": 3310
    },
    {
      "epoch": 43.688741721854306,
      "grad_norm": 0.48682788014411926,
      "learning_rate": 0.00044585764331788103,
      "loss": 1.8998,
      "step": 3320
    },
    {
      "epoch": 43.82119205298013,
      "grad_norm": 0.5412037372589111,
      "learning_rate": 0.00044552851254260487,
      "loss": 1.9002,
      "step": 3330
    },
    {
      "epoch": 43.95364238410596,
      "grad_norm": 0.5168581008911133,
      "learning_rate": 0.00044519850666916485,
      "loss": 1.9037,
      "step": 3340
    },
    {
      "epoch": 44.0,
      "eval_loss": 1.0583916902542114,
      "eval_runtime": 1.5587,
      "eval_samples_per_second": 3146.823,
      "eval_steps_per_second": 12.831,
      "step": 3344
    },
    {
      "epoch": 44.079470198675494,
      "grad_norm": 0.512458324432373,
      "learning_rate": 0.0004448676271745197,
      "loss": 1.7873,
      "step": 3350
    },
    {
      "epoch": 44.211920529801326,
      "grad_norm": 0.5277374982833862,
      "learning_rate": 0.0004445358755395382,
      "loss": 1.8848,
      "step": 3360
    },
    {
      "epoch": 44.34437086092715,
      "grad_norm": 0.5136415958404541,
      "learning_rate": 0.0004442032532489921,
      "loss": 1.875,
      "step": 3370
    },
    {
      "epoch": 44.47682119205298,
      "grad_norm": 0.4913055896759033,
      "learning_rate": 0.00044386976179155004,
      "loss": 1.8875,
      "step": 3380
    },
    {
      "epoch": 44.609271523178805,
      "grad_norm": 0.5454219579696655,
      "learning_rate": 0.00044353540265977065,
      "loss": 1.8822,
      "step": 3390
    },
    {
      "epoch": 44.741721854304636,
      "grad_norm": 0.5250447988510132,
      "learning_rate": 0.00044320017735009575,
      "loss": 1.891,
      "step": 3400
    },
    {
      "epoch": 44.87417218543047,
      "grad_norm": 0.5321816205978394,
      "learning_rate": 0.0004428640873628441,
      "loss": 1.9009,
      "step": 3410
    },
    {
      "epoch": 45.0,
      "grad_norm": 0.49811723828315735,
      "learning_rate": 0.00044252713420220394,
      "loss": 1.813,
      "step": 3420
    },
    {
      "epoch": 45.0,
      "eval_loss": 1.0651519298553467,
      "eval_runtime": 1.5648,
      "eval_samples_per_second": 3134.683,
      "eval_steps_per_second": 12.782,
      "step": 3420
    },
    {
      "epoch": 45.13245033112583,
      "grad_norm": 0.5389775037765503,
      "learning_rate": 0.00044218931937622697,
      "loss": 1.8799,
      "step": 3430
    },
    {
      "epoch": 45.264900662251655,
      "grad_norm": 0.5316805243492126,
      "learning_rate": 0.00044185064439682126,
      "loss": 1.8726,
      "step": 3440
    },
    {
      "epoch": 45.397350993377486,
      "grad_norm": 0.5172908902168274,
      "learning_rate": 0.0004415111107797445,
      "loss": 1.8799,
      "step": 3450
    },
    {
      "epoch": 45.52980132450331,
      "grad_norm": 0.5269562005996704,
      "learning_rate": 0.00044117072004459736,
      "loss": 1.8872,
      "step": 3460
    },
    {
      "epoch": 45.66225165562914,
      "grad_norm": 0.5230698585510254,
      "learning_rate": 0.00044082947371481646,
      "loss": 1.8888,
      "step": 3470
    },
    {
      "epoch": 45.794701986754966,
      "grad_norm": 0.5615084767341614,
      "learning_rate": 0.0004404873733176677,
      "loss": 1.8879,
      "step": 3480
    },
    {
      "epoch": 45.9271523178808,
      "grad_norm": 0.5066052675247192,
      "learning_rate": 0.0004401444203842395,
      "loss": 1.878,
      "step": 3490
    },
    {
      "epoch": 46.0,
      "eval_loss": 1.0632059574127197,
      "eval_runtime": 1.57,
      "eval_samples_per_second": 3124.238,
      "eval_steps_per_second": 12.739,
      "step": 3496
    },
    {
      "epoch": 46.05298013245033,
      "grad_norm": 0.507695734500885,
      "learning_rate": 0.00043980061644943583,
      "loss": 1.7925,
      "step": 3500
    },
    {
      "epoch": 46.18543046357616,
      "grad_norm": 0.5410239100456238,
      "learning_rate": 0.0004394559630519692,
      "loss": 1.8613,
      "step": 3510
    },
    {
      "epoch": 46.317880794701985,
      "grad_norm": 0.5226796269416809,
      "learning_rate": 0.00043911046173435414,
      "loss": 1.8755,
      "step": 3520
    },
    {
      "epoch": 46.450331125827816,
      "grad_norm": 0.5092834234237671,
      "learning_rate": 0.00043876411404290003,
      "loss": 1.859,
      "step": 3530
    },
    {
      "epoch": 46.58278145695364,
      "grad_norm": 0.537072479724884,
      "learning_rate": 0.00043841692152770415,
      "loss": 1.8694,
      "step": 3540
    },
    {
      "epoch": 46.71523178807947,
      "grad_norm": 0.5527091026306152,
      "learning_rate": 0.00043806888574264493,
      "loss": 1.8738,
      "step": 3550
    },
    {
      "epoch": 46.847682119205295,
      "grad_norm": 0.5652727484703064,
      "learning_rate": 0.0004377200082453748,
      "loss": 1.8919,
      "step": 3560
    },
    {
      "epoch": 46.980132450331126,
      "grad_norm": 0.510670006275177,
      "learning_rate": 0.00043737029059731354,
      "loss": 1.8816,
      "step": 3570
    },
    {
      "epoch": 47.0,
      "eval_loss": 1.0621594190597534,
      "eval_runtime": 1.5563,
      "eval_samples_per_second": 3151.66,
      "eval_steps_per_second": 12.851,
      "step": 3572
    },
    {
      "epoch": 47.10596026490066,
      "grad_norm": 0.5482839941978455,
      "learning_rate": 0.0004370197343636408,
      "loss": 1.7623,
      "step": 3580
    },
    {
      "epoch": 47.23841059602649,
      "grad_norm": 0.5487307906150818,
      "learning_rate": 0.00043666834111328944,
      "loss": 1.868,
      "step": 3590
    },
    {
      "epoch": 47.370860927152314,
      "grad_norm": 0.5357214212417603,
      "learning_rate": 0.0004363161124189387,
      "loss": 1.864,
      "step": 3600
    },
    {
      "epoch": 47.503311258278146,
      "grad_norm": 0.5495577454566956,
      "learning_rate": 0.0004359630498570064,
      "loss": 1.8656,
      "step": 3610
    },
    {
      "epoch": 47.63576158940398,
      "grad_norm": 0.5480139851570129,
      "learning_rate": 0.00043560915500764284,
      "loss": 1.8654,
      "step": 3620
    },
    {
      "epoch": 47.7682119205298,
      "grad_norm": 0.5264220237731934,
      "learning_rate": 0.0004352544294547229,
      "loss": 1.8728,
      "step": 3630
    },
    {
      "epoch": 47.90066225165563,
      "grad_norm": 0.5261523127555847,
      "learning_rate": 0.00043489887478583966,
      "loss": 1.8659,
      "step": 3640
    },
    {
      "epoch": 48.0,
      "eval_loss": 1.0652908086776733,
      "eval_runtime": 1.5802,
      "eval_samples_per_second": 3104.012,
      "eval_steps_per_second": 12.657,
      "step": 3648
    },
    {
      "epoch": 48.026490066225165,
      "grad_norm": 0.5037404298782349,
      "learning_rate": 0.00043454249259229665,
      "loss": 1.7838,
      "step": 3650
    },
    {
      "epoch": 48.158940397350996,
      "grad_norm": 0.5834878087043762,
      "learning_rate": 0.00043418528446910123,
      "loss": 1.8505,
      "step": 3660
    },
    {
      "epoch": 48.29139072847682,
      "grad_norm": 0.5519403219223022,
      "learning_rate": 0.0004338272520149572,
      "loss": 1.8623,
      "step": 3670
    },
    {
      "epoch": 48.42384105960265,
      "grad_norm": 0.5580110549926758,
      "learning_rate": 0.0004334683968322576,
      "loss": 1.8634,
      "step": 3680
    },
    {
      "epoch": 48.556291390728475,
      "grad_norm": 0.5512064099311829,
      "learning_rate": 0.0004331087205270777,
      "loss": 1.8658,
      "step": 3690
    },
    {
      "epoch": 48.688741721854306,
      "grad_norm": 0.5670040845870972,
      "learning_rate": 0.00043274822470916794,
      "loss": 1.8586,
      "step": 3700
    },
    {
      "epoch": 48.82119205298013,
      "grad_norm": 0.5290822386741638,
      "learning_rate": 0.00043238691099194615,
      "loss": 1.8656,
      "step": 3710
    },
    {
      "epoch": 48.95364238410596,
      "grad_norm": 0.5662782788276672,
      "learning_rate": 0.00043202478099249104,
      "loss": 1.864,
      "step": 3720
    },
    {
      "epoch": 49.0,
      "eval_loss": 1.0622730255126953,
      "eval_runtime": 1.5754,
      "eval_samples_per_second": 3113.443,
      "eval_steps_per_second": 12.695,
      "step": 3724
    },
    {
      "epoch": 49.079470198675494,
      "grad_norm": 0.553170382976532,
      "learning_rate": 0.0004316618363315344,
      "loss": 1.7683,
      "step": 3730
    },
    {
      "epoch": 49.211920529801326,
      "grad_norm": 0.5428368449211121,
      "learning_rate": 0.0004312980786334544,
      "loss": 1.8515,
      "step": 3740
    },
    {
      "epoch": 49.34437086092715,
      "grad_norm": 0.5614309310913086,
      "learning_rate": 0.0004309335095262675,
      "loss": 1.8531,
      "step": 3750
    },
    {
      "epoch": 49.47682119205298,
      "grad_norm": 0.524740993976593,
      "learning_rate": 0.00043056813064162224,
      "loss": 1.8595,
      "step": 3760
    },
    {
      "epoch": 49.609271523178805,
      "grad_norm": 0.5446119904518127,
      "learning_rate": 0.0004302019436147908,
      "loss": 1.8566,
      "step": 3770
    },
    {
      "epoch": 49.741721854304636,
      "grad_norm": 0.556148886680603,
      "learning_rate": 0.0004298349500846628,
      "loss": 1.8712,
      "step": 3780
    },
    {
      "epoch": 49.87417218543047,
      "grad_norm": 0.5539830327033997,
      "learning_rate": 0.00042946715169373694,
      "loss": 1.8587,
      "step": 3790
    },
    {
      "epoch": 50.0,
      "grad_norm": 0.5603061318397522,
      "learning_rate": 0.0004290985500881143,
      "loss": 1.7701,
      "step": 3800
    },
    {
      "epoch": 50.0,
      "eval_loss": 1.067627191543579,
      "eval_runtime": 1.5582,
      "eval_samples_per_second": 3147.907,
      "eval_steps_per_second": 12.836,
      "step": 3800
    },
    {
      "epoch": 50.13245033112583,
      "grad_norm": 0.5472177267074585,
      "learning_rate": 0.00042872914691749085,
      "loss": 1.8465,
      "step": 3810
    },
    {
      "epoch": 50.264900662251655,
      "grad_norm": 0.570549488067627,
      "learning_rate": 0.00042835894383515006,
      "loss": 1.847,
      "step": 3820
    },
    {
      "epoch": 50.397350993377486,
      "grad_norm": 0.5597425103187561,
      "learning_rate": 0.0004279879424979551,
      "loss": 1.8543,
      "step": 3830
    },
    {
      "epoch": 50.52980132450331,
      "grad_norm": 0.5544357299804688,
      "learning_rate": 0.00042761614456634226,
      "loss": 1.8547,
      "step": 3840
    },
    {
      "epoch": 50.66225165562914,
      "grad_norm": 0.5345036387443542,
      "learning_rate": 0.0004272435517043125,
      "loss": 1.8553,
      "step": 3850
    },
    {
      "epoch": 50.794701986754966,
      "grad_norm": 0.5263144969940186,
      "learning_rate": 0.00042687016557942505,
      "loss": 1.8654,
      "step": 3860
    },
    {
      "epoch": 50.9271523178808,
      "grad_norm": 0.5555644631385803,
      "learning_rate": 0.0004264959878627891,
      "loss": 1.8467,
      "step": 3870
    },
    {
      "epoch": 51.0,
      "eval_loss": 1.0670583248138428,
      "eval_runtime": 1.5612,
      "eval_samples_per_second": 3141.729,
      "eval_steps_per_second": 12.81,
      "step": 3876
    },
    {
      "epoch": 51.05298013245033,
      "grad_norm": 0.5312318205833435,
      "learning_rate": 0.0004261210202290567,
      "loss": 1.7606,
      "step": 3880
    },
    {
      "epoch": 51.18543046357616,
      "grad_norm": 0.5858826637268066,
      "learning_rate": 0.0004257452643564155,
      "loss": 1.8284,
      "step": 3890
    },
    {
      "epoch": 51.317880794701985,
      "grad_norm": 0.5796921253204346,
      "learning_rate": 0.00042536872192658034,
      "loss": 1.8433,
      "step": 3900
    },
    {
      "epoch": 51.450331125827816,
      "grad_norm": 0.5882108211517334,
      "learning_rate": 0.000424991394624787,
      "loss": 1.8498,
      "step": 3910
    },
    {
      "epoch": 51.58278145695364,
      "grad_norm": 0.5778848528862,
      "learning_rate": 0.0004246132841397835,
      "loss": 1.8516,
      "step": 3920
    },
    {
      "epoch": 51.71523178807947,
      "grad_norm": 0.5608619451522827,
      "learning_rate": 0.00042423439216382345,
      "loss": 1.8544,
      "step": 3930
    },
    {
      "epoch": 51.847682119205295,
      "grad_norm": 0.5648797154426575,
      "learning_rate": 0.0004238547203926576,
      "loss": 1.8581,
      "step": 3940
    },
    {
      "epoch": 51.980132450331126,
      "grad_norm": 0.5575576424598694,
      "learning_rate": 0.00042347427052552724,
      "loss": 1.8549,
      "step": 3950
    },
    {
      "epoch": 52.0,
      "eval_loss": 1.0648343563079834,
      "eval_runtime": 1.558,
      "eval_samples_per_second": 3148.351,
      "eval_steps_per_second": 12.837,
      "step": 3952
    },
    {
      "epoch": 52.10596026490066,
      "grad_norm": 0.6203452944755554,
      "learning_rate": 0.0004230930442651557,
      "loss": 1.7453,
      "step": 3960
    },
    {
      "epoch": 52.23841059602649,
      "grad_norm": 0.6081958413124084,
      "learning_rate": 0.00042271104331774125,
      "loss": 1.832,
      "step": 3970
    },
    {
      "epoch": 52.370860927152314,
      "grad_norm": 0.5616388320922852,
      "learning_rate": 0.00042232826939294906,
      "loss": 1.8217,
      "step": 3980
    },
    {
      "epoch": 52.503311258278146,
      "grad_norm": 0.5957764387130737,
      "learning_rate": 0.0004219447242039043,
      "loss": 1.8426,
      "step": 3990
    },
    {
      "epoch": 52.63576158940398,
      "grad_norm": 0.6074648499488831,
      "learning_rate": 0.00042156040946718344,
      "loss": 1.8548,
      "step": 4000
    },
    {
      "epoch": 52.7682119205298,
      "grad_norm": 0.5738332271575928,
      "learning_rate": 0.0004211753269028075,
      "loss": 1.8483,
      "step": 4010
    },
    {
      "epoch": 52.90066225165563,
      "grad_norm": 0.5760337710380554,
      "learning_rate": 0.00042078947823423365,
      "loss": 1.8333,
      "step": 4020
    },
    {
      "epoch": 53.0,
      "eval_loss": 1.0590711832046509,
      "eval_runtime": 1.5564,
      "eval_samples_per_second": 3151.452,
      "eval_steps_per_second": 12.85,
      "step": 4028
    },
    {
      "epoch": 53.026490066225165,
      "grad_norm": 0.5651885867118835,
      "learning_rate": 0.00042040286518834805,
      "loss": 1.7633,
      "step": 4030
    },
    {
      "epoch": 53.158940397350996,
      "grad_norm": 0.5645769834518433,
      "learning_rate": 0.00042001548949545777,
      "loss": 1.8353,
      "step": 4040
    },
    {
      "epoch": 53.29139072847682,
      "grad_norm": 0.5707347393035889,
      "learning_rate": 0.00041962735288928306,
      "loss": 1.835,
      "step": 4050
    },
    {
      "epoch": 53.42384105960265,
      "grad_norm": 0.5809392929077148,
      "learning_rate": 0.00041923845710694984,
      "loss": 1.8239,
      "step": 4060
    },
    {
      "epoch": 53.556291390728475,
      "grad_norm": 0.5982301235198975,
      "learning_rate": 0.0004188488038889816,
      "loss": 1.8324,
      "step": 4070
    },
    {
      "epoch": 53.688741721854306,
      "grad_norm": 0.5904814600944519,
      "learning_rate": 0.00041845839497929203,
      "loss": 1.8262,
      "step": 4080
    },
    {
      "epoch": 53.82119205298013,
      "grad_norm": 0.6935204267501831,
      "learning_rate": 0.0004180672321251765,
      "loss": 1.85,
      "step": 4090
    },
    {
      "epoch": 53.95364238410596,
      "grad_norm": 0.5552741289138794,
      "learning_rate": 0.0004176753170773052,
      "loss": 1.8486,
      "step": 4100
    },
    {
      "epoch": 54.0,
      "eval_loss": 1.0657154321670532,
      "eval_runtime": 1.5788,
      "eval_samples_per_second": 3106.715,
      "eval_steps_per_second": 12.668,
      "step": 4104
    },
    {
      "epoch": 54.079470198675494,
      "grad_norm": 0.6115543246269226,
      "learning_rate": 0.0004172826515897146,
      "loss": 1.7378,
      "step": 4110
    },
    {
      "epoch": 54.211920529801326,
      "grad_norm": 0.6129856705665588,
      "learning_rate": 0.0004168892374197996,
      "loss": 1.8233,
      "step": 4120
    },
    {
      "epoch": 54.34437086092715,
      "grad_norm": 0.624546229839325,
      "learning_rate": 0.0004164950763283062,
      "loss": 1.8261,
      "step": 4130
    },
    {
      "epoch": 54.47682119205298,
      "grad_norm": 0.5721480846405029,
      "learning_rate": 0.0004161001700793231,
      "loss": 1.8312,
      "step": 4140
    },
    {
      "epoch": 54.609271523178805,
      "grad_norm": 0.5794053673744202,
      "learning_rate": 0.0004157045204402741,
      "loss": 1.8313,
      "step": 4150
    },
    {
      "epoch": 54.741721854304636,
      "grad_norm": 0.5659310221672058,
      "learning_rate": 0.0004153081291819099,
      "loss": 1.8387,
      "step": 4160
    },
    {
      "epoch": 54.87417218543047,
      "grad_norm": 0.5610171556472778,
      "learning_rate": 0.0004149109980783004,
      "loss": 1.8295,
      "step": 4170
    },
    {
      "epoch": 55.0,
      "grad_norm": 0.5491277575492859,
      "learning_rate": 0.00041451312890682703,
      "loss": 1.7476,
      "step": 4180
    },
    {
      "epoch": 55.0,
      "eval_loss": 1.0691463947296143,
      "eval_runtime": 1.5726,
      "eval_samples_per_second": 3119.017,
      "eval_steps_per_second": 12.718,
      "step": 4180
    },
    {
      "epoch": 55.13245033112583,
      "grad_norm": 0.5681048631668091,
      "learning_rate": 0.000414114523448174,
      "loss": 1.8341,
      "step": 4190
    },
    {
      "epoch": 55.264900662251655,
      "grad_norm": 0.5737702250480652,
      "learning_rate": 0.0004137151834863213,
      "loss": 1.8078,
      "step": 4200
    },
    {
      "epoch": 55.397350993377486,
      "grad_norm": 0.5974533557891846,
      "learning_rate": 0.0004133151108085357,
      "loss": 1.826,
      "step": 4210
    },
    {
      "epoch": 55.52980132450331,
      "grad_norm": 0.5667087435722351,
      "learning_rate": 0.0004129143072053638,
      "loss": 1.8187,
      "step": 4220
    },
    {
      "epoch": 55.66225165562914,
      "grad_norm": 0.5801354050636292,
      "learning_rate": 0.00041251277447062313,
      "loss": 1.8122,
      "step": 4230
    },
    {
      "epoch": 55.794701986754966,
      "grad_norm": 0.5787196159362793,
      "learning_rate": 0.0004121105144013946,
      "loss": 1.8304,
      "step": 4240
    },
    {
      "epoch": 55.9271523178808,
      "grad_norm": 0.5717300772666931,
      "learning_rate": 0.00041170752879801436,
      "loss": 1.8298,
      "step": 4250
    },
    {
      "epoch": 56.0,
      "eval_loss": 1.0680559873580933,
      "eval_runtime": 1.6017,
      "eval_samples_per_second": 3062.362,
      "eval_steps_per_second": 12.487,
      "step": 4256
    },
    {
      "epoch": 56.0,
      "step": 4256,
      "total_flos": 5832695923343360.0,
      "train_loss": 2.372205384691855,
      "train_runtime": 1243.1064,
      "train_samples_per_second": 6201.078,
      "train_steps_per_second": 12.067
    }
  ],
  "logging_steps": 10,
  "max_steps": 15000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 200,
  "save_steps": 1000,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 20,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 20
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5832695923343360.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
